Soft limit: 1024
Hard limit: 1048576
Soft limit: 20000
Hard limit: 1048576
Rlow=78000.000000
Rhigh=202000.000000
Horizontal partitions = [13, 4, 3]
Vertical partitions = [4, 3, 1]
Created folder: separated_csvs_5_5_25
Folder already exists: pwl_files
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 0 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 0 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 0 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.3238, 0.0044741, 0.054219, 0.18889, 0.0049443, 0.0029589, 0.0011568, 0.79868, 0.7575, 0.25641]
Predicted label: 7
Correct prediction
Energy consumption = 169.776354 pJ
sum error= 0
Actual label: 2
Output voltages: [0.47215, 0.39022, 0.79753, 0.26691, 0.0047933, 0.0012837, 0.38646, 0.0021066, 0.10845, 0.0060571]
Predicted label: 2
Correct prediction
Energy consumption = 150.836524 pJ
sum error= 0
Actual label: 1
Output voltages: [0.014638, 0.79849, 0.021679, 0.023961, 0.018646, 0.0030773, 0.71963, 0.01272, 0.31406, 0.046301]
Predicted label: 1
Correct prediction
Energy consumption = 153.773070 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79877, 0.039664, 0.0074866, 0.014211, 0.099651, 0.024536, 0.57044, 0.014994, 0.041689, 0.036541]
Predicted label: 0
Correct prediction
Energy consumption = 154.269220 pJ
sum error= 0
Actual label: 4
Output voltages: [0.016167, 0.0073505, 0.15028, 0.011997, 0.79867, 0.0011042, 0.036965, 0.051361, 0.037684, 0.094365]
Predicted label: 4
Correct prediction
Energy consumption = 157.809957 pJ
sum error= 0
Actual label: 1
Output voltages: [0.022177, 0.79857, 0.021623, 0.016585, 0.19809, 0.003706, 0.72944, 0.019047, 0.15472, 0.037674]
Predicted label: 1
Correct prediction
Energy consumption = 160.685692 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0010718, 0.024984, 0.023614, 0.001193, 0.78147, 0.014813, 0.0074466, 0.0027067, 0.7504, 0.12129]
Predicted label: 4
Correct prediction
Energy consumption = 144.751864 pJ
sum error= 0
Actual label: 9
Output voltages: [0.45479, 0.0031474, 0.66136, 0.022155, 0.17065, 0.0040594, 0.014531, 0.043477, 0.33444, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 154.619638 pJ
sum error= 0
Actual label: 5
Output voltages: [0.21931, 0.0011099, 0.0063707, 0.036605, 0.33227, 0.79879, 0.73968, 0.0058704, 0.75606, 0.031863]
Predicted label: 5
Correct prediction
Energy consumption = 150.254203 pJ
sum error= 0
Actual label: 9
Output voltages: [0.43943, 0.007426, 0.038257, 0.019608, 0.16029, 0.032339, 0.0022896, 0.035535, 0.55262, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 134.724361 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 1 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 1 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 1 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79876, 0.042047, 0.1667, 0.008496, 0.0074546, 0.0059949, 0.30169, 0.0095758, 0.1154, 0.19027]
Predicted label: 0
Correct prediction
Energy consumption = 174.172797 pJ
sum error= 0
Actual label: 6
Output voltages: [0.16595, 0.16958, 0.29771, 0.0024695, 0.32022, 0.097099, 0.79869, 0.00151, 0.44032, 0.022988]
Predicted label: 6
Correct prediction
Energy consumption = 142.176774 pJ
sum error= 0
Actual label: 9
Output voltages: [0.27779, 0.0042087, 0.010254, 0.030054, 0.44982, 0.0048208, 0.0049627, 0.016945, 0.4358, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 153.747022 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79879, 0.15495, 0.0088733, 0.01666, 0.016758, 0.02612, 0.72277, 0.01714, 0.16426, 0.047204]
Predicted label: 0
Correct prediction
Energy consumption = 157.940372 pJ
sum error= 0
Actual label: 1
Output voltages: [0.020089, 0.79847, 0.13592, 0.070123, 0.0087122, 0.0013382, 0.53061, 0.0042039, 0.1355, 0.037143]
Predicted label: 1
Correct prediction
Energy consumption = 160.784402 pJ
sum error= 0
Actual label: 5
Output voltages: [0.19685, 0.001077, 0.010466, 0.23183, 0.0024775, 0.79861, 0.039285, 0.19723, 0.77407, 0.0039555]
Predicted label: 5
Correct prediction
Energy consumption = 148.938859 pJ
sum error= 0
Actual label: 9
Output voltages: [0.38401, 0.0046736, 0.059935, 0.032398, 0.4739, 0.010308, 0.016488, 0.0073563, 0.16114, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 153.529903 pJ
sum error= 0
Actual label: 7
Output voltages: [0.30909, 0.0058253, 0.13869, 0.36252, 0.0014892, 0.015786, 0.001066, 0.79865, 0.29157, 0.2831]
Predicted label: 7
Correct prediction
Energy consumption = 148.546325 pJ
sum error= 0
Actual label: 3
Output voltages: [0.033611, 0.0032621, 0.74034, 0.79674, 0.0063997, 0.0011059, 0.029344, 0.14319, 0.62644, 0.015122]
Predicted label: 3
Correct prediction
Energy consumption = 149.027313 pJ
sum error= 0
Actual label: 4
Output voltages: [0.024524, 0.012962, 0.40861, 0.027018, 0.7986, 0.0015152, 0.093765, 0.057174, 0.017904, 0.061227]
Predicted label: 4
Correct prediction
Energy consumption = 155.166437 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 2 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 2 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 2 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.19084, 0.016796, 0.027628, 0.06187, 0.43689, 0.004468, 0.0020659, 0.017672, 0.35229, 0.79758]
Predicted label: 9
Correct prediction
Energy consumption = 169.611059 pJ
sum error= 0
Actual label: 6
Output voltages: [0.2067, 0.15676, 0.17392, 0.0029319, 0.22202, 0.46436, 0.79878, 0.0011094, 0.31836, 0.0082434]
Predicted label: 6
Correct prediction
Energy consumption = 153.530371 pJ
sum error= 0
Actual label: 6
Output voltages: [0.47188, 0.059889, 0.17576, 0.01591, 0.40668, 0.33218, 0.79876, 0.0050933, 0.26339, 0.021705]
Predicted label: 6
Correct prediction
Energy consumption = 142.701384 pJ
sum error= 0
Actual label: 5
Output voltages: [0.40869, 0.0011435, 0.0019138, 0.13192, 0.028696, 0.79876, 0.57209, 0.016191, 0.74282, 0.0085308]
Predicted label: 5
Correct prediction
Energy consumption = 140.447182 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0084469, 0.0019212, 0.5293, 0.014244, 0.79874, 0.0011218, 0.24978, 0.4704, 0.010784, 0.12407]
Predicted label: 4
Correct prediction
Energy consumption = 150.536191 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79852, 0.065383, 0.050108, 0.005998, 0.0060949, 0.0012353, 0.739, 0.019545, 0.13596, 0.094851]
Predicted label: 0
Correct prediction
Energy consumption = 150.225012 pJ
sum error= 0
Actual label: 7
Output voltages: [0.6622, 0.2075, 0.028945, 0.33769, 0.0047558, 0.012781, 0.001127, 0.79878, 0.0143, 0.39949]
Predicted label: 7
Correct prediction
Energy consumption = 155.920380 pJ
sum error= 0
Actual label: 4
Output voltages: [0.009268, 0.012476, 0.19084, 0.02143, 0.79867, 0.0012023, 0.13283, 0.07574, 0.018816, 0.060707]
Predicted label: 4
Correct prediction
Energy consumption = 152.423773 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79879, 0.036353, 0.47028, 0.19089, 0.02582, 0.0023194, 0.33391, 0.023212, 0.074952, 0.054551]
Predicted label: 0
Correct prediction
Energy consumption = 161.358757 pJ
sum error= 0
Actual label: 1
Output voltages: [0.054135, 0.79857, 0.03554, 0.36291, 0.0099404, 0.0023324, 0.27086, 0.0013855, 0.47023, 0.048696]
Predicted label: 1
Correct prediction
Energy consumption = 161.587718 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 3 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 3 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 3 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.15085, 0.010356, 0.10379, 0.79868, 0.034202, 0.006255, 0.0076508, 0.079034, 0.36582, 0.16507]
Predicted label: 3
Correct prediction
Energy consumption = 164.613471 pJ
sum error= 0
Actual label: 1
Output voltages: [0.0040086, 0.79844, 0.048166, 0.12037, 0.047955, 0.014624, 0.11679, 0.0093796, 0.0105, 0.19288]
Predicted label: 1
Correct prediction
Energy consumption = 161.451624 pJ
sum error= 0
Actual label: 3
Output voltages: [0.27981, 0.013861, 0.11098, 0.79866, 0.027911, 0.0041301, 0.022988, 0.038825, 0.75239, 0.012511]
Predicted label: 3
Correct prediction
Energy consumption = 147.442188 pJ
sum error= 0
Actual label: 4
Output voltages: [0.44911, 0.01832, 0.41219, 0.001078, 0.7978, 0.0021478, 0.73304, 0.022222, 0.15293, 0.0038194]
Predicted label: 4
Correct prediction
Energy consumption = 156.269083 pJ
sum error= 0
Actual label: 7
Output voltages: [0.02826, 0.17764, 0.7447, 0.034784, 0.0026974, 0.0012131, 0.001066, 0.79872, 0.23761, 0.42065]
Predicted label: 7
Correct prediction
Energy consumption = 152.979249 pJ
sum error= 0
Actual label: 2
Output voltages: [0.35114, 0.018779, 0.79869, 0.040018, 0.0067518, 0.0010674, 0.18954, 0.0093942, 0.36717, 0.015591]
Predicted label: 2
Correct prediction
Energy consumption = 138.211065 pJ
sum error= 0
Actual label: 7
Output voltages: [0.065172, 0.039947, 0.61914, 0.042325, 0.0026342, 0.0012274, 0.0030608, 0.79875, 0.29994, 0.038767]
Predicted label: 7
Correct prediction
Energy consumption = 143.195325 pJ
sum error= 0
Actual label: 1
Output voltages: [0.057087, 0.79847, 0.0618, 0.049648, 0.039514, 0.011825, 0.3648, 0.0074272, 0.23363, 0.048829]
Predicted label: 1
Correct prediction
Energy consumption = 162.496485 pJ
sum error= 0
Actual label: 2
Output voltages: [0.27191, 0.32573, 0.78234, 0.36395, 0.0016495, 0.0011739, 0.3181, 0.19841, 0.31072, 0.01722]
Predicted label: 2
Correct prediction
Energy consumption = 154.456316 pJ
sum error= 0
Actual label: 1
Output voltages: [0.017452, 0.79846, 0.0098663, 0.13888, 0.011953, 0.0017487, 0.76973, 0.0033764, 0.32611, 0.08274]
Predicted label: 1
Correct prediction
Energy consumption = 153.369234 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 4 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 4 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 4 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23852, 0.79835, 0.072205, 0.2091, 0.041345, 0.002414, 0.45035, 0.19266, 0.012809, 0.19441]
Predicted label: 1
Correct prediction
Energy consumption = 181.590254 pJ
sum error= 0
Actual label: 7
Output voltages: [0.18907, 0.26455, 0.74463, 0.022822, 0.011378, 0.0012782, 0.0012645, 0.79879, 0.020872, 0.21524]
Predicted label: 7
Correct prediction
Energy consumption = 148.992061 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0038985, 0.013574, 0.18492, 0.0056342, 0.79869, 0.001353, 0.059837, 0.031445, 0.049223, 0.041918]
Predicted label: 4
Correct prediction
Energy consumption = 162.115044 pJ
sum error= 0
Actual label: 2
Output voltages: [0.020492, 0.031536, 0.79634, 0.23, 0.39582, 0.0011296, 0.08912, 0.24767, 0.045019, 0.0072392]
Predicted label: 2
Correct prediction
Energy consumption = 141.881843 pJ
sum error= 0
Actual label: 3
Output voltages: [0.041057, 0.051868, 0.069413, 0.79858, 0.21426, 0.015149, 0.046145, 0.24087, 0.45629, 0.036479]
Predicted label: 3
Correct prediction
Energy consumption = 154.952663 pJ
sum error= 0
Actual label: 5
Output voltages: [0.21931, 0.0010708, 0.0028451, 0.41927, 0.0073848, 0.79871, 0.12891, 0.029317, 0.75846, 0.040545]
Predicted label: 5
Correct prediction
Energy consumption = 152.169935 pJ
sum error= 0
Actual label: 1
Output voltages: [0.0105, 0.79829, 0.008823, 0.76027, 0.016305, 0.010149, 0.0037765, 0.036835, 0.35664, 0.12269]
Predicted label: 1
Correct prediction
Energy consumption = 159.041578 pJ
sum error= 0
Actual label: 2
Output voltages: [0.56043, 0.29508, 0.7987, 0.070089, 0.023332, 0.0011914, 0.26087, 0.038639, 0.39215, 0.050303]
Predicted label: 2
Correct prediction
Energy consumption = 143.155439 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0038932, 0.020792, 0.058415, 0.0053666, 0.79879, 0.011538, 0.20564, 0.086217, 0.28125, 0.046796]
Predicted label: 4
Correct prediction
Energy consumption = 155.029449 pJ
sum error= 0
Actual label: 4
Output voltages: [0.015911, 0.0034604, 0.14461, 0.0093368, 0.79851, 0.015022, 0.11232, 0.054832, 0.026356, 0.032917]
Predicted label: 4
Correct prediction
Energy consumption = 144.632823 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 5 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 5 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 5 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.040554, 0.039535, 0.076347, 0.0026975, 0.033495, 0.08174, 0.79879, 0.020331, 0.76607, 0.0040826]
Predicted label: 6
Correct prediction
Energy consumption = 170.306129 pJ
sum error= 0
Actual label: 3
Output voltages: [0.63028, 0.0076884, 0.10118, 0.79871, 0.01195, 0.15576, 0.013806, 0.041277, 0.76711, 0.049463]
Predicted label: 3
Correct prediction
Energy consumption = 142.162252 pJ
sum error= 0
Actual label: 5
Output voltages: [0.053018, 0.0010956, 0.0017209, 0.2969, 0.21741, 0.7987, 0.74824, 0.010843, 0.71279, 0.017606]
Predicted label: 5
Correct prediction
Energy consumption = 136.279219 pJ
sum error= 0
Actual label: 5
Output voltages: [0.15746, 0.0011128, 0.013018, 0.32657, 0.0019301, 0.79876, 0.043081, 0.15195, 0.76731, 0.019225]
Predicted label: 5
Correct prediction
Energy consumption = 129.170422 pJ
sum error= 0
Actual label: 6
Output voltages: [0.13478, 0.21499, 0.38424, 0.001066, 0.21055, 0.082742, 0.79872, 0.0012395, 0.48486, 0.010671]
Predicted label: 6
Correct prediction
Energy consumption = 141.724338 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79866, 0.058092, 0.048056, 0.024115, 0.025615, 0.026755, 0.71955, 0.025629, 0.33295, 0.023791]
Predicted label: 0
Correct prediction
Energy consumption = 155.238176 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0032088, 0.014778, 0.3317, 0.0069734, 0.79864, 0.0025252, 0.06149, 0.046333, 0.023353, 0.16303]
Predicted label: 4
Correct prediction
Energy consumption = 156.004787 pJ
sum error= 0
Actual label: 1
Output voltages: [0.009962, 0.79852, 0.027985, 0.044307, 0.037859, 0.0020454, 0.46554, 0.013978, 0.47633, 0.045989]
Predicted label: 1
Correct prediction
Energy consumption = 160.721860 pJ
sum error= 0
Actual label: 9
Output voltages: [0.37949, 0.0019861, 0.046413, 0.025506, 0.26145, 0.050549, 0.021376, 0.087228, 0.26543, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.760432 pJ
sum error= 0
Actual label: 5
Output voltages: [0.1348, 0.0019606, 0.001162, 0.46563, 0.26845, 0.7982, 0.13463, 0.0038662, 0.3127, 0.041865]
Predicted label: 5
Correct prediction
Energy consumption = 145.620528 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 6 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 6 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 6 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.29583, 0.035847, 0.0011347, 0.73635, 0.0017924, 0.027359, 0.0010691, 0.79876, 0.071961, 0.50869]
Predicted label: 7
Correct prediction
Energy consumption = 175.755028 pJ
sum error= 0
Actual label: 8
Output voltages: [0.028823, 0.0090088, 0.73516, 0.17182, 0.0079014, 0.01537, 0.006083, 0.024482, 0.79867, 0.015704]
Predicted label: 8
Correct prediction
Energy consumption = 135.179196 pJ
sum error= 0
Actual label: 9
Output voltages: [0.083418, 0.028249, 0.013662, 0.044651, 0.024408, 0.082246, 0.02606, 0.04924, 0.49729, 0.79815]
Predicted label: 9
Correct prediction
Energy consumption = 152.592866 pJ
sum error= 0
Actual label: 3
Output voltages: [0.074591, 0.0045731, 0.37765, 0.79845, 0.006337, 0.0026884, 0.0013463, 0.027398, 0.76967, 0.085397]
Predicted label: 3
Correct prediction
Energy consumption = 144.401564 pJ
sum error= 0
Actual label: 7
Output voltages: [0.014237, 0.0028779, 0.063858, 0.62412, 0.0040151, 0.020137, 0.0011132, 0.79816, 0.76763, 0.42796]
Predicted label: 7
Correct prediction
Energy consumption = 136.172659 pJ
sum error= 0
Actual label: 4
Output voltages: [0.054896, 0.090759, 0.030099, 0.033995, 0.79879, 0.0011671, 0.027205, 0.018431, 0.021724, 0.65398]
Predicted label: 4
Correct prediction
Energy consumption = 159.703707 pJ
sum error= 0
Actual label: 6
Output voltages: [0.63726, 0.33391, 0.17313, 0.0085249, 0.013782, 0.0041637, 0.79782, 0.001072, 0.49135, 0.050968]
Predicted label: 6
Correct prediction
Energy consumption = 157.023926 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0043885, 0.018771, 0.1743, 0.023222, 0.79862, 0.0067519, 0.32179, 0.21398, 0.022392, 0.042505]
Predicted label: 4
Correct prediction
Energy consumption = 149.059582 pJ
sum error= 0
Actual label: 3
Output voltages: [0.036679, 0.0030527, 0.22782, 0.79879, 0.017567, 0.012909, 0.0064691, 0.045782, 0.46757, 0.32597]
Predicted label: 3
Correct prediction
Energy consumption = 149.707991 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79869, 0.037701, 0.054187, 0.031945, 0.0010722, 0.011807, 0.44482, 0.012367, 0.18705, 0.035363]
Predicted label: 0
Correct prediction
Energy consumption = 144.432780 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 7 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 7 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 7 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.70165, 0.0016991, 0.10929, 0.2569, 0.0040477, 0.0012186, 0.0010947, 0.79879, 0.71668, 0.20806]
Predicted label: 7
Correct prediction
Energy consumption = 170.955361 pJ
sum error= 0
Actual label: 0
Output voltages: [0.7987, 0.043573, 0.024432, 0.0064457, 0.014552, 0.02011, 0.48447, 0.004596, 0.14517, 0.026112]
Predicted label: 0
Correct prediction
Energy consumption = 151.063569 pJ
sum error= 0
Actual label: 2
Output voltages: [0.71396, 0.028328, 0.79873, 0.022107, 0.0028318, 0.0011605, 0.082676, 0.031374, 0.21697, 0.0072538]
Predicted label: 2
Correct prediction
Energy consumption = 143.068885 pJ
sum error= 0
Actual label: 9
Output voltages: [0.14461, 0.003923, 0.01667, 0.02143, 0.22044, 0.0022757, 0.0023357, 0.0081513, 0.61975, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 145.840368 pJ
sum error= 0
Actual label: 1
Output voltages: [0.087311, 0.79851, 0.023926, 0.24567, 0.036466, 0.0082837, 0.54798, 0.0024475, 0.11613, 0.13101]
Predicted label: 1
Correct prediction
Energy consumption = 161.739100 pJ
sum error= 0
Actual label: 7
Output voltages: [0.06507, 0.0028921, 0.40486, 0.51019, 0.020761, 0.0010692, 0.001165, 0.79659, 0.41362, 0.21825]
Predicted label: 7
Correct prediction
Energy consumption = 153.919613 pJ
sum error= 0
Actual label: 3
Output voltages: [0.33651, 0.035839, 0.061954, 0.79859, 0.030933, 0.026341, 0.026005, 0.022662, 0.65523, 0.083499]
Predicted label: 3
Correct prediction
Energy consumption = 142.172495 pJ
sum error= 0
Actual label: 2
Output voltages: [0.69568, 0.18224, 0.79866, 0.078766, 0.0076868, 0.0011422, 0.044237, 0.25293, 0.33179, 0.028441]
Predicted label: 2
Correct prediction
Energy consumption = 138.474417 pJ
sum error= 0
Actual label: 9
Output voltages: [0.04613, 0.014727, 0.030042, 0.051596, 0.35259, 0.0013632, 0.0032233, 0.0063519, 0.61381, 0.79421]
Predicted label: 9
Correct prediction
Energy consumption = 148.660725 pJ
sum error= 0
Actual label: 7
Output voltages: [0.45675, 0.0111, 0.03194, 0.637, 0.0027555, 0.01303, 0.0012718, 0.79862, 0.52461, 0.47635]
Predicted label: 7
Correct prediction
Energy consumption = 137.680021 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 8 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 8 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 8 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.38603, 0.0088662, 0.075092, 0.016528, 0.038148, 0.015233, 0.0013315, 0.79878, 0.2611, 0.77405]
Predicted label: 7
Correct prediction
Energy consumption = 176.756702 pJ
sum error= 0
Actual label: 6
Output voltages: [0.11568, 0.028811, 0.21586, 0.0014843, 0.39569, 0.23842, 0.79875, 0.0040746, 0.47511, 0.0046178]
Predicted label: 6
Correct prediction
Energy consumption = 155.454982 pJ
sum error= 0
Actual label: 2
Output voltages: [0.61349, 0.062005, 0.79868, 0.062126, 0.043404, 0.0011597, 0.3396, 0.076037, 0.3743, 0.053334]
Predicted label: 2
Correct prediction
Energy consumption = 150.027891 pJ
sum error= 0
Actual label: 7
Output voltages: [0.069558, 0.026096, 0.0092165, 0.054087, 0.031135, 0.013127, 0.0010697, 0.79867, 0.058989, 0.34111]
Predicted label: 7
Correct prediction
Energy consumption = 155.286954 pJ
sum error= 0
Actual label: 8
Output voltages: [0.027517, 0.032495, 0.13262, 0.070669, 0.038182, 0.011884, 0.19964, 0.0079222, 0.79875, 0.036196]
Predicted label: 8
Correct prediction
Energy consumption = 149.042012 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0018256, 0.024983, 0.020313, 0.0060981, 0.79859, 0.0027212, 0.1957, 0.47721, 0.14434, 0.015774]
Predicted label: 4
Correct prediction
Energy consumption = 154.542416 pJ
sum error= 0
Actual label: 7
Output voltages: [0.29176, 0.0656, 0.1551, 0.44716, 0.0013988, 0.0017298, 0.0011544, 0.79874, 0.71051, 0.43133]
Predicted label: 7
Correct prediction
Energy consumption = 153.616688 pJ
sum error= 0
Actual label: 3
Output voltages: [0.73884, 0.065217, 0.046219, 0.79872, 0.0613, 0.020852, 0.028721, 0.22182, 0.25415, 0.011014]
Predicted label: 3
Correct prediction
Energy consumption = 142.168653 pJ
sum error= 0
Actual label: 6
Output voltages: [0.22517, 0.15213, 0.27578, 0.024618, 0.25233, 0.22311, 0.79864, 0.0041227, 0.21263, 0.029692]
Predicted label: 6
Correct prediction
Energy consumption = 150.198506 pJ
sum error= 0
Actual label: 1
Output voltages: [0.029092, 0.79876, 0.32869, 0.036336, 0.40922, 0.0010807, 0.61322, 0.0044725, 0.22836, 0.00291]
Predicted label: 1
Correct prediction
Energy consumption = 160.763793 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 9 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 9 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 9 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.089858, 0.036718, 0.022489, 0.7987, 0.010014, 0.0022856, 0.018826, 0.011572, 0.52126, 0.062943]
Predicted label: 3
Correct prediction
Energy consumption = 169.399337 pJ
sum error= 0
Actual label: 6
Output voltages: [0.27059, 0.054664, 0.15571, 0.011585, 0.32403, 0.20364, 0.79878, 0.0012492, 0.47234, 0.016159]
Predicted label: 6
Correct prediction
Energy consumption = 147.079658 pJ
sum error= 0
Actual label: 9
Output voltages: [0.30189, 0.0020039, 0.018474, 0.052593, 0.74964, 0.0011787, 0.0010753, 0.0012585, 0.36563, 0.76917]
Predicted label: 9
Correct prediction
Energy consumption = 150.363693 pJ
sum error= 0
Actual label: 3
Output voltages: [0.1551, 0.014973, 0.17221, 0.79879, 0.23029, 0.031755, 0.025635, 0.0035816, 0.49994, 0.27703]
Predicted label: 3
Correct prediction
Energy consumption = 153.561656 pJ
sum error= 0
Actual label: 1
Output voltages: [0.026835, 0.79876, 0.28753, 0.0081192, 0.073647, 0.0010959, 0.76454, 0.0010704, 0.032937, 0.075659]
Predicted label: 1
Correct prediction
Energy consumption = 163.316600 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0028402, 0.017109, 0.014438, 0.015053, 0.79866, 0.0049404, 0.19694, 0.03651, 0.083268, 0.013351]
Predicted label: 4
Correct prediction
Energy consumption = 139.765475 pJ
sum error= 0
Actual label: 1
Output voltages: [0.0044626, 0.79837, 0.020479, 0.37653, 0.087204, 0.002792, 0.015435, 0.0010761, 0.08967, 0.21492]
Predicted label: 1
Correct prediction
Energy consumption = 156.416990 pJ
sum error= 0
Actual label: 7
Output voltages: [0.047246, 0.01136, 0.2536, 0.16804, 0.0027803, 0.0010815, 0.0011689, 0.79866, 0.79294, 0.016242]
Predicted label: 7
Correct prediction
Energy consumption = 150.315481 pJ
sum error= 0
Actual label: 6
Output voltages: [0.040473, 0.027149, 0.25084, 0.0013723, 0.3164, 0.082963, 0.79878, 0.0024365, 0.64398, 0.0014494]
Predicted label: 6
Correct prediction
Energy consumption = 152.222463 pJ
sum error= 0
Actual label: 9
Output voltages: [0.063454, 0.020469, 0.035999, 0.1311, 0.17844, 0.2273, 0.04407, 0.033634, 0.39469, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 154.003421 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 10 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 10 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 10 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.043729, 0.12697, 0.28214, 0.0015953, 0.17532, 0.40105, 0.79864, 0.01285, 0.38493, 0.026586]
Predicted label: 6
Correct prediction
Energy consumption = 165.076102 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79879, 0.12874, 0.015079, 0.035492, 0.016066, 0.044441, 0.55115, 0.010655, 0.037041, 0.035397]
Predicted label: 0
Correct prediction
Energy consumption = 149.734852 pJ
sum error= 0
Actual label: 5
Output voltages: [0.25957, 0.0010719, 0.013026, 0.48736, 0.0028695, 0.79741, 0.014572, 0.11774, 0.78434, 0.098525]
Predicted label: 5
Correct prediction
Energy consumption = 142.227744 pJ
sum error= 0
Actual label: 4
Output voltages: [0.017597, 0.011988, 0.4403, 0.010431, 0.79859, 0.0034458, 0.053053, 0.038172, 0.016205, 0.054324]
Predicted label: 4
Correct prediction
Energy consumption = 155.348928 pJ
sum error= 0
Actual label: 9
Output voltages: [0.12969, 0.001085, 0.0021172, 0.13525, 0.033572, 0.67749, 0.0019268, 0.077307, 0.72927, 0.7811]
Predicted label: 9
Correct prediction
Energy consumption = 149.847235 pJ
sum error= 0
Actual label: 9
Output voltages: [0.11017, 0.019247, 0.025368, 0.042954, 0.044554, 0.06006, 0.023259, 0.051145, 0.45726, 0.79558]
Predicted label: 9
Correct prediction
Energy consumption = 142.871099 pJ
sum error= 0
Actual label: 2
Output voltages: [0.51225, 0.0041821, 0.79879, 0.20438, 0.019297, 0.0011339, 0.021729, 0.034804, 0.47199, 0.0061033]
Predicted label: 2
Correct prediction
Energy consumption = 149.455639 pJ
sum error= 0
Actual label: 1
Output voltages: [0.53632, 0.79857, 0.20862, 0.29458, 0.061471, 0.0015992, 0.72685, 0.0010736, 0.069635, 0.10429]
Predicted label: 1
Correct prediction
Energy consumption = 151.852378 pJ
sum error= 0
Actual label: 9
Output voltages: [0.4035, 0.037615, 0.008247, 0.040022, 0.04151, 0.0095352, 0.0071689, 0.022051, 0.26588, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 158.651332 pJ
sum error= 0
Actual label: 4
Output voltages: [0.027087, 0.0075884, 0.095678, 0.0064848, 0.79857, 0.02578, 0.5254, 0.081295, 0.040603, 0.0026893]
Predicted label: 4
Correct prediction
Energy consumption = 150.241495 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 11 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 11 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 11 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.13957, 0.028352, 0.068661, 0.28381, 0.0066546, 0.31587, 0.026142, 0.0077491, 0.79876, 0.26177]
Predicted label: 8
Correct prediction
Energy consumption = 168.320029 pJ
sum error= 0
Actual label: 7
Output voltages: [0.12516, 0.28374, 0.24228, 0.15516, 0.002085, 0.0010828, 0.0010659, 0.79855, 0.46915, 0.52597]
Predicted label: 7
Correct prediction
Energy consumption = 162.889133 pJ
sum error= 0
Actual label: 3
Output voltages: [0.22481, 0.034705, 0.030688, 0.79864, 0.0083075, 0.01691, 0.02513, 0.022769, 0.44691, 0.096197]
Predicted label: 3
Correct prediction
Energy consumption = 150.562536 pJ
sum error= 0
Actual label: 9
Output voltages: [0.28494, 0.052071, 0.022843, 0.7158, 0.028593, 0.053448, 0.014123, 0.052932, 0.071775, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 150.284435 pJ
sum error= 0
Actual label: 7
Output voltages: [0.28974, 0.0030822, 0.33339, 0.30623, 0.011263, 0.0011041, 0.001111, 0.79208, 0.17563, 0.60983]
Predicted label: 7
Correct prediction
Energy consumption = 143.241929 pJ
sum error= 0
Actual label: 4
Output voltages: [0.039601, 0.03973, 0.018988, 0.0025667, 0.77961, 0.0075214, 0.13357, 0.016168, 0.056028, 0.75324]
Predicted label: 4
Correct prediction
Energy consumption = 156.022498 pJ
sum error= 0
Actual label: 4
Output voltages: [0.012396, 0.039751, 0.32049, 0.0044114, 0.79878, 0.0011378, 0.026731, 0.057959, 0.024438, 0.66305]
Predicted label: 4
Correct prediction
Energy consumption = 147.676489 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0025185, 0.0066927, 0.30386, 0.0060847, 0.79856, 0.0039067, 0.1417, 0.019704, 0.038776, 0.054442]
Predicted label: 4
Correct prediction
Energy consumption = 135.525202 pJ
sum error= 0
Actual label: 9
Output voltages: [0.41204, 0.0042646, 0.053443, 0.031127, 0.48505, 0.0087974, 0.0029458, 0.057037, 0.037096, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 151.400037 pJ
sum error= 0
Actual label: 2
Output voltages: [0.096554, 0.03638, 0.79877, 0.061704, 0.0073348, 0.0012288, 0.022967, 0.76302, 0.64138, 0.0061128]
Predicted label: 2
Correct prediction
Energy consumption = 146.231206 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 12 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 12 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 12 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.052339, 0.0010713, 0.017492, 0.37189, 0.030712, 0.79792, 0.017372, 0.033846, 0.77847, 0.1835]
Predicted label: 5
Correct prediction
Energy consumption = 164.866993 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0047067, 0.018725, 0.0096021, 0.002344, 0.79036, 0.024725, 0.12124, 0.04657, 0.42918, 0.15403]
Predicted label: 4
Correct prediction
Energy consumption = 150.890303 pJ
sum error= 0
Actual label: 7
Output voltages: [0.081885, 0.011191, 0.045996, 0.11459, 0.0015921, 0.015882, 0.0010717, 0.79843, 0.20016, 0.64582]
Predicted label: 7
Correct prediction
Energy consumption = 161.354461 pJ
sum error= 0
Actual label: 6
Output voltages: [0.040294, 0.29015, 0.42221, 0.003426, 0.12767, 0.049801, 0.79866, 0.0041673, 0.40599, 0.010597]
Predicted label: 6
Correct prediction
Energy consumption = 153.527304 pJ
sum error= 0
Actual label: 7
Output voltages: [0.028111, 0.046874, 0.018766, 0.0078963, 0.46625, 0.0027536, 0.001066, 0.79383, 0.54853, 0.58544]
Predicted label: 7
Correct prediction
Energy consumption = 148.083683 pJ
sum error= 0
Actual label: 9
Output voltages: [0.25228, 0.026804, 0.041069, 0.006926, 0.79879, 0.0059312, 0.29655, 0.01813, 0.020446, 0.7747]
Predicted label: 4
Wrong prediction!
Energy consumption = 149.855278 pJ
sum error= 1
Actual label: 0
Output voltages: [0.79878, 0.028931, 0.21076, 0.0049806, 0.037646, 0.025416, 0.22934, 0.0029625, 0.33104, 0.035183]
Predicted label: 0
Correct prediction
Energy consumption = 152.165173 pJ
sum error= 1
Actual label: 5
Output voltages: [0.020935, 0.0011236, 0.0021683, 0.13889, 0.028001, 0.79877, 0.27952, 0.012317, 0.76326, 0.013807]
Predicted label: 5
Correct prediction
Energy consumption = 146.712452 pJ
sum error= 1
Actual label: 8
Output voltages: [0.031202, 0.0053277, 0.027688, 0.21213, 0.0031619, 0.047881, 0.018534, 0.0032547, 0.79873, 0.28071]
Predicted label: 8
Correct prediction
Energy consumption = 143.034457 pJ
sum error= 1
Actual label: 5
Output voltages: [0.065862, 0.0013219, 0.0011755, 0.45656, 0.025929, 0.79868, 0.18074, 0.013236, 0.73612, 0.16237]
Predicted label: 5
Correct prediction
Energy consumption = 140.679553 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 13 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 13 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 13 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.22406, 0.028106, 0.040259, 0.0122, 0.38024, 0.4706, 0.79869, 0.0011848, 0.70151, 0.020527]
Predicted label: 6
Correct prediction
Energy consumption = 165.912738 pJ
sum error= 1
Actual label: 6
Output voltages: [0.10162, 0.03564, 0.036939, 0.012499, 0.37663, 0.14147, 0.79878, 0.0017669, 0.74518, 0.0098164]
Predicted label: 6
Correct prediction
Energy consumption = 139.363442 pJ
sum error= 1
Actual label: 5
Output voltages: [0.023885, 0.0010689, 0.001781, 0.26556, 0.19366, 0.79778, 0.18124, 0.033837, 0.79096, 0.070901]
Predicted label: 5
Correct prediction
Energy consumption = 142.018415 pJ
sum error= 1
Actual label: 7
Output voltages: [0.077971, 0.0035585, 0.035529, 0.52772, 0.0016646, 0.025159, 0.0011508, 0.79871, 0.45042, 0.28615]
Predicted label: 7
Correct prediction
Energy consumption = 146.445312 pJ
sum error= 1
Actual label: 8
Output voltages: [0.029188, 0.044935, 0.082852, 0.23073, 0.0026175, 0.032254, 0.040396, 0.016853, 0.79868, 0.10929]
Predicted label: 8
Correct prediction
Energy consumption = 152.596298 pJ
sum error= 1
Actual label: 1
Output voltages: [0.002137, 0.79858, 0.049627, 0.032588, 0.041527, 0.0012678, 0.43636, 0.0081231, 0.22755, 0.044892]
Predicted label: 1
Correct prediction
Energy consumption = 163.982725 pJ
sum error= 1
Actual label: 0
Output voltages: [0.79866, 0.095932, 0.26352, 0.006696, 0.012836, 0.0046773, 0.605, 0.022422, 0.23196, 0.34971]
Predicted label: 0
Correct prediction
Energy consumption = 161.429109 pJ
sum error= 1
Actual label: 1
Output voltages: [0.033407, 0.79857, 0.23605, 0.049256, 0.14145, 0.0010671, 0.3701, 0.0091869, 0.035409, 0.042574]
Predicted label: 1
Correct prediction
Energy consumption = 158.027739 pJ
sum error= 1
Actual label: 6
Output voltages: [0.28362, 0.09511, 0.32969, 0.0018518, 0.49599, 0.26006, 0.79869, 0.0026313, 0.1146, 0.016468]
Predicted label: 6
Correct prediction
Energy consumption = 148.576940 pJ
sum error= 1
Actual label: 4
Output voltages: [0.011649, 0.0098543, 0.034638, 0.011537, 0.7935, 0.0065797, 0.044469, 0.0014041, 0.19389, 0.035554]
Predicted label: 4
Correct prediction
Energy consumption = 151.796211 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 14 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 14 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 14 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.10878, 0.0086721, 0.090943, 0.0018443, 0.36446, 0.082842, 0.79879, 0.0039068, 0.71958, 0.0065758]
Predicted label: 6
Correct prediction
Energy consumption = 170.530924 pJ
sum error= 1
Actual label: 7
Output voltages: [0.36809, 0.097483, 0.049535, 0.048512, 0.0015839, 0.0038611, 0.0010742, 0.79873, 0.20532, 0.48605]
Predicted label: 7
Correct prediction
Energy consumption = 163.892593 pJ
sum error= 1
Actual label: 3
Output voltages: [0.047589, 0.013743, 0.39477, 0.79853, 0.022732, 0.0010669, 0.0016706, 0.0011432, 0.70781, 0.03425]
Predicted label: 3
Correct prediction
Energy consumption = 144.095825 pJ
sum error= 1
Actual label: 1
Output voltages: [0.019137, 0.79852, 0.040142, 0.031764, 0.061304, 0.0020129, 0.49472, 0.021781, 0.10682, 0.039456]
Predicted label: 1
Correct prediction
Energy consumption = 163.903691 pJ
sum error= 1
Actual label: 7
Output voltages: [0.45353, 0.0010663, 0.30349, 0.052064, 0.1792, 0.0011779, 0.0010995, 0.78134, 0.5378, 0.088962]
Predicted label: 7
Correct prediction
Energy consumption = 146.403227 pJ
sum error= 1
Actual label: 1
Output voltages: [0.0019089, 0.79873, 0.0051088, 0.59287, 0.20344, 0.02588, 0.0052922, 0.021963, 0.013194, 0.65841]
Predicted label: 1
Correct prediction
Energy consumption = 164.864418 pJ
sum error= 1
Actual label: 8
Output voltages: [0.030843, 0.037855, 0.15927, 0.1818, 0.0029386, 0.016403, 0.014197, 0.011039, 0.79879, 0.57334]
Predicted label: 8
Correct prediction
Energy consumption = 148.691366 pJ
sum error= 1
Actual label: 2
Output voltages: [0.46512, 0.018684, 0.79879, 0.042443, 0.017149, 0.0011025, 0.030338, 0.023087, 0.52114, 0.0080337]
Predicted label: 2
Correct prediction
Energy consumption = 148.859808 pJ
sum error= 1
Actual label: 0
Output voltages: [0.79879, 0.19197, 0.13328, 0.043671, 0.031901, 0.0067702, 0.64511, 0.0084758, 0.1696, 0.044223]
Predicted label: 0
Correct prediction
Energy consumption = 157.158177 pJ
sum error= 1
Actual label: 2
Output voltages: [0.46324, 0.0015187, 0.79777, 0.16507, 0.40171, 0.0011159, 0.022979, 0.0022929, 0.44118, 0.26694]
Predicted label: 2
Correct prediction
Energy consumption = 145.146307 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 15 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 15 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 15 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.095687, 0.034988, 0.023829, 0.2841, 0.25841, 0.044416, 0.11242, 0.022781, 0.31928, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 176.988609 pJ
sum error= 1
Actual label: 9
Output voltages: [0.76698, 0.0010926, 0.21928, 0.025218, 0.42527, 0.0031662, 0.0010665, 0.0027228, 0.29411, 0.76232]
Predicted label: 0
Wrong prediction!
Energy consumption = 147.907738 pJ
sum error= 2
Actual label: 5
Output voltages: [0.052288, 0.013743, 0.012742, 0.40093, 0.051613, 0.79876, 0.38762, 0.004126, 0.39112, 0.051773]
Predicted label: 5
Correct prediction
Energy consumption = 142.450921 pJ
sum error= 2
Actual label: 5
Output voltages: [0.031061, 0.0010724, 0.0034319, 0.29657, 0.01248, 0.79495, 0.066653, 0.01132, 0.77169, 0.085508]
Predicted label: 5
Correct prediction
Energy consumption = 139.694440 pJ
sum error= 2
Actual label: 1
Output voltages: [0.04269, 0.79872, 0.035161, 0.10129, 0.0021915, 0.0010792, 0.18625, 0.0028226, 0.14524, 0.085828]
Predicted label: 1
Correct prediction
Energy consumption = 170.363785 pJ
sum error= 2
Actual label: 5
Output voltages: [0.032318, 0.0011328, 0.0012556, 0.21025, 0.24041, 0.79877, 0.3283, 0.03204, 0.77635, 0.02277]
Predicted label: 5
Correct prediction
Energy consumption = 148.388101 pJ
sum error= 2
Actual label: 6
Output voltages: [0.03276, 0.034952, 0.50987, 0.0011033, 0.40694, 0.11527, 0.79879, 0.0010856, 0.28967, 0.0029683]
Predicted label: 6
Correct prediction
Energy consumption = 145.307857 pJ
sum error= 2
Actual label: 0
Output voltages: [0.79879, 0.041074, 0.054429, 0.019315, 0.029493, 0.0039484, 0.70313, 0.0076002, 0.044671, 0.44485]
Predicted label: 0
Correct prediction
Energy consumption = 151.031358 pJ
sum error= 2
Actual label: 3
Output voltages: [0.77993, 0.02722, 0.13749, 0.79877, 0.0035115, 0.023914, 0.11871, 0.028227, 0.20621, 0.0098324]
Predicted label: 3
Correct prediction
Energy consumption = 148.084657 pJ
sum error= 2
Actual label: 4
Output voltages: [0.016642, 0.28079, 0.031104, 0.55439, 0.79879, 0.0016919, 0.022267, 0.03001, 0.0016494, 0.31094]
Predicted label: 4
Correct prediction
Energy consumption = 148.719987 pJ
sum error= 2
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 16 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 16 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 16 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0039633, 0.034881, 0.50073, 0.01269, 0.7987, 0.0012304, 0.33389, 0.001379, 0.1381, 0.17898]
Predicted label: 4
Correct prediction
Energy consumption = 175.599995 pJ
sum error= 2
Actual label: 6
Output voltages: [0.25418, 0.005791, 0.044937, 0.004287, 0.34679, 0.10739, 0.79772, 0.0010977, 0.7298, 0.0061468]
Predicted label: 6
Correct prediction
Energy consumption = 141.278507 pJ
sum error= 2
Actual label: 5
Output voltages: [0.029115, 0.0023239, 0.010999, 0.60609, 0.0362, 0.79832, 0.23057, 0.041565, 0.74287, 0.26532]
Predicted label: 5
Correct prediction
Energy consumption = 147.138510 pJ
sum error= 2
Actual label: 4
Output voltages: [0.0097868, 0.010187, 0.27213, 0.025851, 0.79862, 0.0026085, 0.069502, 0.10107, 0.034119, 0.038323]
Predicted label: 4
Correct prediction
Energy consumption = 157.221047 pJ
sum error= 2
Actual label: 6
Output voltages: [0.066649, 0.063234, 0.45307, 0.0013294, 0.18113, 0.015997, 0.79848, 0.0028643, 0.1955, 0.0030415]
Predicted label: 6
Correct prediction
Energy consumption = 152.248344 pJ
sum error= 2
Actual label: 5
Output voltages: [0.045244, 0.0010853, 0.0020294, 0.45062, 0.016319, 0.79689, 0.041983, 0.1836, 0.76215, 0.070952]
Predicted label: 5
Correct prediction
Energy consumption = 145.096401 pJ
sum error= 2
Actual label: 4
Output voltages: [0.0023439, 0.031323, 0.04347, 0.003091, 0.79874, 0.0021348, 0.59808, 0.27123, 0.022612, 0.022619]
Predicted label: 4
Correct prediction
Energy consumption = 156.462579 pJ
sum error= 2
Actual label: 5
Output voltages: [0.39653, 0.0018541, 0.0011097, 0.65695, 0.090236, 0.79874, 0.22433, 0.0093063, 0.32891, 0.0073936]
Predicted label: 5
Correct prediction
Energy consumption = 134.358693 pJ
sum error= 2
Actual label: 1
Output voltages: [0.036641, 0.79863, 0.077504, 0.054931, 0.011515, 0.0016559, 0.2327, 0.0016838, 0.60401, 0.023274]
Predicted label: 1
Correct prediction
Energy consumption = 162.270784 pJ
sum error= 2
Actual label: 4
Output voltages: [0.015716, 0.0094904, 0.041591, 0.02553, 0.79868, 0.0014847, 0.057941, 0.18709, 0.11558, 0.016821]
Predicted label: 4
Correct prediction
Energy consumption = 156.476725 pJ
sum error= 2
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 17 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 17 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 17 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.069194, 0.023419, 0.3658, 0.11027, 0.79876, 0.010659, 0.032072, 0.014333, 0.015571, 0.53771]
Predicted label: 4
Correct prediction
Energy consumption = 173.128364 pJ
sum error= 2
Actual label: 7
Output voltages: [0.32695, 0.004495, 0.68887, 0.089992, 0.028555, 0.0011552, 0.0010815, 0.77073, 0.79415, 0.32686]
Predicted label: 8
Wrong prediction!
Energy consumption = 154.340177 pJ
sum error= 3
Actual label: 2
Output voltages: [0.53523, 0.13099, 0.79879, 0.54043, 0.0011571, 0.0010667, 0.04138, 0.021198, 0.67179, 0.0011544]
Predicted label: 2
Correct prediction
Energy consumption = 139.157739 pJ
sum error= 3
Actual label: 3
Output voltages: [0.52526, 0.015578, 0.045346, 0.79875, 0.0076822, 0.063825, 0.0071807, 0.023879, 0.21942, 0.01324]
Predicted label: 3
Correct prediction
Energy consumption = 139.314689 pJ
sum error= 3
Actual label: 2
Output voltages: [0.73127, 0.052343, 0.79874, 0.22862, 0.025611, 0.0011468, 0.22961, 0.034281, 0.46861, 0.066476]
Predicted label: 2
Correct prediction
Energy consumption = 148.253101 pJ
sum error= 3
Actual label: 7
Output voltages: [0.44534, 0.65454, 0.25191, 0.44736, 0.0020415, 0.0011009, 0.0015305, 0.79218, 0.68523, 0.13123]
Predicted label: 7
Correct prediction
Energy consumption = 161.692940 pJ
sum error= 3
Actual label: 1
Output voltages: [0.32989, 0.79836, 0.072624, 0.071243, 0.0068538, 0.0020227, 0.74704, 0.0099952, 0.035142, 0.076854]
Predicted label: 1
Correct prediction
Energy consumption = 156.271372 pJ
sum error= 3
Actual label: 8
Output voltages: [0.50957, 0.021502, 0.07545, 0.28572, 0.040898, 0.0015222, 0.038688, 0.0010671, 0.7984, 0.41813]
Predicted label: 8
Correct prediction
Energy consumption = 163.533992 pJ
sum error= 3
Actual label: 1
Output voltages: [0.015874, 0.79855, 0.10807, 0.14715, 0.0048263, 0.0011276, 0.68244, 0.010219, 0.018644, 0.012126]
Predicted label: 1
Correct prediction
Energy consumption = 161.460554 pJ
sum error= 3
Actual label: 8
Output voltages: [0.031024, 0.045465, 0.39492, 0.028861, 0.035329, 0.0029272, 0.36664, 0.0048378, 0.79878, 0.35607]
Predicted label: 8
Correct prediction
Energy consumption = 150.326967 pJ
sum error= 3
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 18 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 18 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 18 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.027044, 0.79856, 0.026733, 0.16329, 0.12092, 0.0030767, 0.32365, 0.0010794, 0.25855, 0.29471]
Predicted label: 1
Correct prediction
Energy consumption = 183.500991 pJ
sum error= 3
Actual label: 8
Output voltages: [0.047145, 0.024439, 0.75609, 0.047742, 0.0081312, 0.0019382, 0.1777, 0.013166, 0.79874, 0.10381]
Predicted label: 8
Correct prediction
Energy consumption = 152.455120 pJ
sum error= 3
Actual label: 5
Output voltages: [0.025273, 0.0014909, 0.0084451, 0.27639, 0.016145, 0.79851, 0.080944, 0.0039667, 0.73682, 0.02889]
Predicted label: 5
Correct prediction
Energy consumption = 148.046141 pJ
sum error= 3
Actual label: 0
Output voltages: [0.79879, 0.049466, 0.036253, 0.0050274, 0.0043675, 0.0038308, 0.51834, 0.0054915, 0.04468, 0.036232]
Predicted label: 0
Correct prediction
Energy consumption = 149.636484 pJ
sum error= 3
Actual label: 8
Output voltages: [0.52194, 0.0010707, 0.65081, 0.79325, 0.0025813, 0.0010666, 0.0017493, 0.24581, 0.7487, 0.015581]
Predicted label: 3
Wrong prediction!
Energy consumption = 150.059467 pJ
sum error= 4
Actual label: 9
Output voltages: [0.070954, 0.011724, 0.0014537, 0.066067, 0.62635, 0.0040676, 0.25693, 0.0073716, 0.028373, 0.784]
Predicted label: 9
Correct prediction
Energy consumption = 151.018846 pJ
sum error= 4
Actual label: 2
Output voltages: [0.46236, 0.045119, 0.79879, 0.18794, 0.021504, 0.0012778, 0.17156, 0.031724, 0.51718, 0.038116]
Predicted label: 2
Correct prediction
Energy consumption = 147.335828 pJ
sum error= 4
Actual label: 5
Output voltages: [0.032719, 0.0011093, 0.01575, 0.23839, 0.011479, 0.79817, 0.11426, 0.036613, 0.78433, 0.094693]
Predicted label: 5
Correct prediction
Energy consumption = 145.606679 pJ
sum error= 4
Actual label: 0
Output voltages: [0.79731, 0.026625, 0.066072, 0.026269, 0.021353, 0.032343, 0.47779, 0.0036975, 0.38516, 0.011925]
Predicted label: 0
Correct prediction
Energy consumption = 155.454728 pJ
sum error= 4
Actual label: 1
Output voltages: [0.0010943, 0.7986, 0.025192, 0.72467, 0.37468, 0.0017682, 0.0046489, 0.051297, 0.20054, 0.036706]
Predicted label: 1
Correct prediction
Energy consumption = 165.345980 pJ
sum error= 4
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 19 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 19 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 19 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.068928, 0.79856, 0.0098265, 0.20507, 0.0263, 0.0011425, 0.038552, 0.0019297, 0.63748, 0.22765]
Predicted label: 1
Correct prediction
Energy consumption = 180.245453 pJ
sum error= 4
Actual label: 1
Output voltages: [0.0010746, 0.79879, 0.70932, 0.59593, 0.13572, 0.002974, 0.0037669, 0.23332, 0.019547, 0.10422]
Predicted label: 1
Correct prediction
Energy consumption = 157.443905 pJ
sum error= 4
Actual label: 0
Output voltages: [0.79876, 0.030925, 0.06844, 0.024318, 0.010943, 0.0064034, 0.38383, 0.030324, 0.17816, 0.02458]
Predicted label: 0
Correct prediction
Energy consumption = 151.597186 pJ
sum error= 4
Actual label: 9
Output voltages: [0.1795, 0.0029909, 0.030194, 0.031108, 0.38946, 0.003951, 0.0010679, 0.25075, 0.23134, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 157.636936 pJ
sum error= 4
Actual label: 0
Output voltages: [0.79875, 0.088965, 0.12841, 0.03814, 0.021106, 0.0066189, 0.34212, 0.026023, 0.14945, 0.36775]
Predicted label: 0
Correct prediction
Energy consumption = 162.513657 pJ
sum error= 4
Actual label: 3
Output voltages: [0.029559, 0.007597, 0.17324, 0.7987, 0.029602, 0.0011387, 0.037002, 0.029303, 0.5525, 0.18552]
Predicted label: 3
Correct prediction
Energy consumption = 153.878587 pJ
sum error= 4
Actual label: 1
Output voltages: [0.02469, 0.79844, 0.10707, 0.030413, 0.015815, 0.0012744, 0.61126, 0.0042322, 0.077176, 0.12189]
Predicted label: 1
Correct prediction
Energy consumption = 163.466609 pJ
sum error= 4
Actual label: 6
Output voltages: [0.14984, 0.044949, 0.3539, 0.0011702, 0.1731, 0.13281, 0.79875, 0.0066646, 0.69316, 0.014506]
Predicted label: 6
Correct prediction
Energy consumption = 147.585899 pJ
sum error= 4
Actual label: 4
Output voltages: [0.0022867, 0.0052682, 0.04947, 0.028011, 0.79871, 0.0015884, 0.067322, 0.084764, 0.042458, 0.015288]
Predicted label: 4
Correct prediction
Energy consumption = 156.559503 pJ
sum error= 4
Actual label: 2
Output voltages: [0.05175, 0.018155, 0.79865, 0.48579, 0.006454, 0.001095, 0.20063, 0.36171, 0.75705, 0.0033755]
Predicted label: 2
Correct prediction
Energy consumption = 147.648509 pJ
sum error= 4
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 20 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 20 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 20 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.74738, 0.0024054, 0.060678, 0.79879, 0.022425, 0.0026525, 0.003656, 0.011657, 0.68645, 0.0030458]
Predicted label: 3
Correct prediction
Energy consumption = 166.032236 pJ
sum error= 4
Actual label: 6
Output voltages: [0.22899, 0.049301, 0.25578, 0.0071854, 0.32676, 0.22046, 0.79876, 0.0014229, 0.42246, 0.021667]
Predicted label: 6
Correct prediction
Energy consumption = 140.776196 pJ
sum error= 4
Actual label: 1
Output voltages: [0.014229, 0.79868, 0.016362, 0.071024, 0.016978, 0.0051256, 0.59996, 0.0014361, 0.2924, 0.014674]
Predicted label: 1
Correct prediction
Energy consumption = 154.923864 pJ
sum error= 4
Actual label: 1
Output voltages: [0.074366, 0.79861, 0.0020805, 0.061897, 0.30832, 0.031609, 0.34324, 0.0013275, 0.017122, 0.57009]
Predicted label: 1
Correct prediction
Energy consumption = 160.941848 pJ
sum error= 4
Actual label: 1
Output voltages: [0.0087503, 0.79863, 0.0059338, 0.005838, 0.12897, 0.0024086, 0.42903, 0.0026941, 0.58135, 0.075717]
Predicted label: 1
Correct prediction
Energy consumption = 151.906817 pJ
sum error= 4
Actual label: 3
Output voltages: [0.12103, 0.022962, 0.044649, 0.79858, 0.028597, 0.011934, 0.026725, 0.043093, 0.43229, 0.1586]
Predicted label: 3
Correct prediction
Energy consumption = 150.849509 pJ
sum error= 4
Actual label: 9
Output voltages: [0.074886, 0.014285, 0.11102, 0.019526, 0.0064371, 0.024383, 0.0029214, 0.047627, 0.78922, 0.77189]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.449213 pJ
sum error= 5
Actual label: 5
Output voltages: [0.26945, 0.0011491, 0.0010849, 0.27851, 0.0056883, 0.79736, 0.042427, 0.39578, 0.76907, 0.0093542]
Predicted label: 5
Correct prediction
Energy consumption = 145.620023 pJ
sum error= 5
Actual label: 2
Output voltages: [0.53333, 0.00522, 0.79869, 0.17294, 0.027926, 0.0010688, 0.073893, 0.34772, 0.38501, 0.0036237]
Predicted label: 2
Correct prediction
Energy consumption = 145.011790 pJ
sum error= 5
Actual label: 9
Output voltages: [0.27729, 0.0010659, 0.0017463, 0.23895, 0.26183, 0.028422, 0.0024498, 0.045928, 0.32922, 0.79186]
Predicted label: 9
Correct prediction
Energy consumption = 154.891538 pJ
sum error= 5
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 21 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 21 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 21 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0078985, 0.0048427, 0.20535, 0.010729, 0.79867, 0.0013975, 0.27189, 0.032167, 0.084386, 0.044671]
Predicted label: 4
Correct prediction
Energy consumption = 176.773719 pJ
sum error= 5
Actual label: 5
Output voltages: [0.023231, 0.0073197, 0.0016865, 0.4311, 0.12134, 0.79813, 0.049383, 0.0010967, 0.57894, 0.010991]
Predicted label: 5
Correct prediction
Energy consumption = 142.530992 pJ
sum error= 5
Actual label: 9
Output voltages: [0.24564, 0.0022567, 0.031139, 0.18579, 0.028604, 0.1803, 0.0012329, 0.20166, 0.047656, 0.79765]
Predicted label: 9
Correct prediction
Energy consumption = 155.523915 pJ
sum error= 5
Actual label: 3
Output voltages: [0.2843, 0.069556, 0.3962, 0.79874, 0.0056431, 0.0031866, 0.0042298, 0.042499, 0.35289, 0.17371]
Predicted label: 3
Correct prediction
Energy consumption = 144.846979 pJ
sum error= 5
Actual label: 9
Output voltages: [0.28984, 0.0031472, 0.03634, 0.018268, 0.053506, 0.0015127, 0.0011953, 0.042288, 0.68813, 0.78895]
Predicted label: 9
Correct prediction
Energy consumption = 151.991060 pJ
sum error= 5
Actual label: 0
Output voltages: [0.79879, 0.084008, 0.12392, 0.035917, 0.015006, 0.016521, 0.29967, 0.012296, 0.039234, 0.14339]
Predicted label: 0
Correct prediction
Energy consumption = 158.217197 pJ
sum error= 5
Actual label: 3
Output voltages: [0.3341, 0.016184, 0.07101, 0.79873, 0.00764, 0.0026062, 0.011377, 0.008727, 0.5001, 0.03306]
Predicted label: 3
Correct prediction
Energy consumption = 147.617596 pJ
sum error= 5
Actual label: 6
Output voltages: [0.57259, 0.0021862, 0.0029806, 0.26073, 0.19973, 0.79852, 0.78758, 0.0057907, 0.67672, 0.014631]
Predicted label: 5
Wrong prediction!
Energy consumption = 147.263850 pJ
sum error= 6
Actual label: 5
Output voltages: [0.038334, 0.0051194, 0.0010661, 0.072308, 0.028727, 0.79877, 0.37095, 0.016632, 0.66243, 0.021329]
Predicted label: 5
Correct prediction
Energy consumption = 150.134727 pJ
sum error= 6
Actual label: 5
Output voltages: [0.23121, 0.0019043, 0.0011126, 0.68402, 0.024125, 0.7984, 0.24091, 0.017734, 0.70238, 0.33467]
Predicted label: 5
Correct prediction
Energy consumption = 140.584674 pJ
sum error= 6
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 22 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 22 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 22 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.2075, 0.039618, 0.018474, 0.0068531, 0.059401, 0.010162, 0.0012204, 0.79855, 0.28029, 0.13245]
Predicted label: 7
Correct prediction
Energy consumption = 174.706848 pJ
sum error= 6
Actual label: 2
Output voltages: [0.7373, 0.0010664, 0.79664, 0.75849, 0.0019667, 0.002828, 0.0019408, 0.031749, 0.37455, 0.028042]
Predicted label: 2
Correct prediction
Energy consumption = 148.338409 pJ
sum error= 6
Actual label: 2
Output voltages: [0.37145, 0.0015509, 0.7987, 0.025299, 0.021544, 0.0012514, 0.074906, 0.16426, 0.73053, 0.016448]
Predicted label: 2
Correct prediction
Energy consumption = 139.116465 pJ
sum error= 6
Actual label: 7
Output voltages: [0.26389, 0.28821, 0.065779, 0.079121, 0.013381, 0.0036403, 0.0026663, 0.79858, 0.16024, 0.26036]
Predicted label: 7
Correct prediction
Energy consumption = 152.306182 pJ
sum error= 6
Actual label: 1
Output voltages: [0.04706, 0.79878, 0.010917, 0.0071262, 0.085685, 0.0016612, 0.44425, 0.0016421, 0.46435, 0.0089175]
Predicted label: 1
Correct prediction
Energy consumption = 156.832566 pJ
sum error= 6
Actual label: 2
Output voltages: [0.11916, 0.11171, 0.79878, 0.026768, 0.0016543, 0.0013093, 0.048737, 0.063686, 0.57933, 0.01564]
Predicted label: 2
Correct prediction
Energy consumption = 139.001561 pJ
sum error= 6
Actual label: 8
Output voltages: [0.015417, 0.24204, 0.14329, 0.10201, 0.0083312, 0.019008, 0.0076778, 0.029839, 0.7987, 0.44829]
Predicted label: 8
Correct prediction
Energy consumption = 140.297781 pJ
sum error= 6
Actual label: 4
Output voltages: [0.0060211, 0.025391, 0.024954, 0.058902, 0.79865, 0.0012026, 0.20795, 0.12366, 0.044504, 0.0060718]
Predicted label: 4
Correct prediction
Energy consumption = 153.898728 pJ
sum error= 6
Actual label: 1
Output voltages: [0.0070607, 0.79858, 0.052976, 0.033484, 0.085302, 0.001572, 0.48419, 0.020738, 0.5324, 0.017577]
Predicted label: 1
Correct prediction
Energy consumption = 163.786188 pJ
sum error= 6
Actual label: 7
Output voltages: [0.36598, 0.049063, 0.29613, 0.21021, 0.0079182, 0.0011228, 0.0010741, 0.79879, 0.026214, 0.20024]
Predicted label: 7
Correct prediction
Energy consumption = 150.082313 pJ
sum error= 6
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 23 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 23 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 23 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.061545, 0.0029089, 0.043371, 0.79878, 0.27767, 0.15178, 0.085258, 0.010969, 0.28984, 0.044298]
Predicted label: 3
Correct prediction
Energy consumption = 169.852282 pJ
sum error= 6
Actual label: 3
Output voltages: [0.23268, 0.029177, 0.05682, 0.79863, 0.012245, 0.025661, 0.014356, 0.0033158, 0.43629, 0.054698]
Predicted label: 3
Correct prediction
Energy consumption = 139.775957 pJ
sum error= 6
Actual label: 8
Output voltages: [0.034903, 0.00119, 0.1034, 0.14611, 0.0034861, 0.43671, 0.28895, 0.0010833, 0.79784, 0.17928]
Predicted label: 8
Correct prediction
Energy consumption = 151.477929 pJ
sum error= 6
Actual label: 8
Output voltages: [0.0074514, 0.021877, 0.042997, 0.032974, 0.011586, 0.0020909, 0.015981, 0.04772, 0.79879, 0.6013]
Predicted label: 8
Correct prediction
Energy consumption = 144.340424 pJ
sum error= 6
Actual label: 7
Output voltages: [0.19923, 0.25122, 0.30726, 0.42375, 0.0011416, 0.0015141, 0.0010675, 0.79878, 0.31693, 0.19375]
Predicted label: 7
Correct prediction
Energy consumption = 157.773968 pJ
sum error= 6
Actual label: 9
Output voltages: [0.62769, 0.0041432, 0.11737, 0.012656, 0.054093, 0.044885, 0.016834, 0.039651, 0.53806, 0.79642]
Predicted label: 9
Correct prediction
Energy consumption = 150.374351 pJ
sum error= 6
Actual label: 2
Output voltages: [0.68031, 0.2474, 0.79879, 0.020439, 0.013825, 0.0013346, 0.32147, 0.055976, 0.37425, 0.054615]
Predicted label: 2
Correct prediction
Energy consumption = 148.412211 pJ
sum error= 6
Actual label: 2
Output voltages: [0.27133, 0.62886, 0.79879, 0.030399, 0.042763, 0.0013271, 0.34994, 0.041623, 0.038029, 0.14077]
Predicted label: 2
Correct prediction
Energy consumption = 135.276333 pJ
sum error= 6
Actual label: 4
Output voltages: [0.010108, 0.02764, 0.1129, 0.0067762, 0.79875, 0.0034381, 0.31987, 0.14507, 0.048118, 0.050556]
Predicted label: 4
Correct prediction
Energy consumption = 148.493798 pJ
sum error= 6
Actual label: 1
Output voltages: [0.014377, 0.79867, 0.058873, 0.75804, 0.013851, 0.023299, 0.050468, 0.0057255, 0.043172, 0.26189]
Predicted label: 1
Correct prediction
Energy consumption = 166.647574 pJ
sum error= 6
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 24 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 24 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 24 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.01782, 0.0010715, 0.0019174, 0.13237, 0.10895, 0.79549, 0.24141, 0.014643, 0.77567, 0.076367]
Predicted label: 5
Correct prediction
Energy consumption = 162.787281 pJ
sum error= 6
Actual label: 9
Output voltages: [0.623, 0.0011072, 0.062423, 0.012713, 0.15991, 0.032185, 0.017067, 0.0010993, 0.73789, 0.5991]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.550190 pJ
sum error= 7
Actual label: 8
Output voltages: [0.033263, 0.18558, 0.27775, 0.024095, 0.025589, 0.001074, 0.05777, 0.004162, 0.79862, 0.47236]
Predicted label: 8
Correct prediction
Energy consumption = 141.884490 pJ
sum error= 7
Actual label: 7
Output voltages: [0.04366, 0.0088354, 0.21602, 0.56154, 0.05936, 0.001087, 0.0010726, 0.79721, 0.30825, 0.66499]
Predicted label: 7
Correct prediction
Energy consumption = 144.857843 pJ
sum error= 7
Actual label: 2
Output voltages: [0.46337, 0.031142, 0.79879, 0.18216, 0.0048192, 0.0017434, 0.01156, 0.7266, 0.56252, 0.028914]
Predicted label: 2
Correct prediction
Energy consumption = 144.418853 pJ
sum error= 7
Actual label: 3
Output voltages: [0.42765, 0.00423, 0.021433, 0.79758, 0.0010704, 0.48833, 0.27652, 0.2727, 0.48304, 0.0010972]
Predicted label: 3
Correct prediction
Energy consumption = 140.082460 pJ
sum error= 7
Actual label: 0
Output voltages: [0.79785, 0.045047, 0.08354, 0.0057658, 0.0154, 0.15327, 0.4933, 0.0011129, 0.03621, 0.55533]
Predicted label: 0
Correct prediction
Energy consumption = 151.576923 pJ
sum error= 7
Actual label: 4
Output voltages: [0.50992, 0.35339, 0.43098, 0.0032576, 0.47385, 0.01151, 0.77784, 0.0012123, 0.19573, 0.0020996]
Predicted label: 6
Wrong prediction!
Energy consumption = 145.548729 pJ
sum error= 8
Actual label: 4
Output voltages: [0.0032095, 0.014579, 0.094993, 0.015749, 0.79867, 0.0011722, 0.12222, 0.044548, 0.020778, 0.074121]
Predicted label: 4
Correct prediction
Energy consumption = 148.527743 pJ
sum error= 8
Actual label: 2
Output voltages: [0.060186, 0.30864, 0.79879, 0.23417, 0.0072546, 0.0013134, 0.12829, 0.020936, 0.50903, 0.022988]
Predicted label: 2
Correct prediction
Energy consumption = 149.918114 pJ
sum error= 8
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 25 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 25 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 25 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.10555, 0.032626, 0.31171, 0.040564, 0.79831, 0.0010732, 0.023566, 0.032667, 0.043818, 0.65516]
Predicted label: 4
Correct prediction
Energy consumption = 178.906833 pJ
sum error= 8
Actual label: 1
Output voltages: [0.0373, 0.79872, 0.027294, 0.02689, 0.09038, 0.011718, 0.50405, 0.0012317, 0.19205, 0.010468]
Predicted label: 1
Correct prediction
Energy consumption = 161.904047 pJ
sum error= 8
Actual label: 9
Output voltages: [0.1718, 0.023108, 0.061292, 0.046013, 0.040024, 0.012696, 0.0091739, 0.023831, 0.64457, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 157.950031 pJ
sum error= 8
Actual label: 5
Output voltages: [0.0353, 0.0010661, 0.0038451, 0.56474, 0.012477, 0.7982, 0.02266, 0.056037, 0.75637, 0.22183]
Predicted label: 5
Correct prediction
Energy consumption = 148.777617 pJ
sum error= 8
Actual label: 7
Output voltages: [0.17788, 0.030547, 0.11976, 0.35076, 0.0061884, 0.0010759, 0.003258, 0.79866, 0.035053, 0.37999]
Predicted label: 7
Correct prediction
Energy consumption = 160.072854 pJ
sum error= 8
Actual label: 7
Output voltages: [0.33258, 0.15631, 0.76064, 0.30841, 0.0018836, 0.0012802, 0.0052999, 0.79079, 0.26853, 0.057633]
Predicted label: 7
Correct prediction
Energy consumption = 151.001918 pJ
sum error= 8
Actual label: 2
Output voltages: [0.26872, 0.49482, 0.79869, 0.29449, 0.004319, 0.0011892, 0.15664, 0.0091624, 0.29597, 0.042332]
Predicted label: 2
Correct prediction
Energy consumption = 142.911770 pJ
sum error= 8
Actual label: 8
Output voltages: [0.20438, 0.10177, 0.069203, 0.40786, 0.0014228, 0.0022932, 0.67711, 0.003416, 0.79764, 0.032432]
Predicted label: 8
Correct prediction
Energy consumption = 152.376515 pJ
sum error= 8
Actual label: 2
Output voltages: [0.73776, 0.079867, 0.79841, 0.49417, 0.0062339, 0.0010676, 0.33225, 0.01326, 0.20529, 0.040251]
Predicted label: 2
Correct prediction
Energy consumption = 141.975949 pJ
sum error= 8
Actual label: 6
Output voltages: [0.78226, 0.015546, 0.016837, 0.0026543, 0.1606, 0.48121, 0.79738, 0.013063, 0.31535, 0.018546]
Predicted label: 6
Correct prediction
Energy consumption = 149.181198 pJ
sum error= 8
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 26 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 26 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 26 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.018678, 0.04188, 0.46261, 0.024047, 0.017487, 0.027318, 0.023414, 0.0058935, 0.7987, 0.062242]
Predicted label: 8
Correct prediction
Energy consumption = 155.638913 pJ
sum error= 8
Actual label: 5
Output voltages: [0.31221, 0.01796, 0.0011919, 0.069373, 0.0041128, 0.7987, 0.013034, 0.0016171, 0.78919, 0.0013892]
Predicted label: 5
Correct prediction
Energy consumption = 153.016138 pJ
sum error= 8
Actual label: 7
Output voltages: [0.20712, 0.032313, 0.011492, 0.29207, 0.0075538, 0.0047096, 0.0011112, 0.79877, 0.63827, 0.74107]
Predicted label: 7
Correct prediction
Energy consumption = 154.677101 pJ
sum error= 8
Actual label: 7
Output voltages: [0.12363, 0.049715, 0.098962, 0.10826, 0.010316, 0.0010928, 0.0010679, 0.79869, 0.17253, 0.41264]
Predicted label: 7
Correct prediction
Energy consumption = 141.696651 pJ
sum error= 8
Actual label: 9
Output voltages: [0.02537, 0.14053, 0.24369, 0.039494, 0.66955, 0.031862, 0.0053972, 0.0069949, 0.064221, 0.79843]
Predicted label: 9
Correct prediction
Energy consumption = 158.925117 pJ
sum error= 8
Actual label: 1
Output voltages: [0.004295, 0.79842, 0.10515, 0.051938, 0.013642, 0.0071751, 0.35829, 0.0091028, 0.15228, 0.048918]
Predicted label: 1
Correct prediction
Energy consumption = 159.420917 pJ
sum error= 8
Actual label: 8
Output voltages: [0.63412, 0.019559, 0.051784, 0.74129, 0.001175, 0.019274, 0.032757, 0.0024826, 0.76941, 0.17818]
Predicted label: 8
Correct prediction
Energy consumption = 158.122809 pJ
sum error= 8
Actual label: 1
Output voltages: [0.041025, 0.79852, 0.068923, 0.27439, 0.045944, 0.0051201, 0.76199, 0.0019638, 0.029183, 0.11805]
Predicted label: 1
Correct prediction
Energy consumption = 158.632991 pJ
sum error= 8
Actual label: 8
Output voltages: [0.22534, 0.0010676, 0.32647, 0.009327, 0.01566, 0.33533, 0.019157, 0.001786, 0.79849, 0.25517]
Predicted label: 8
Correct prediction
Energy consumption = 151.512742 pJ
sum error= 8
Actual label: 0
Output voltages: [0.79879, 0.0093926, 0.068452, 0.013654, 0.0015044, 0.021204, 0.49237, 0.032627, 0.18789, 0.012511]
Predicted label: 0
Correct prediction
Energy consumption = 140.767633 pJ
sum error= 8
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 27 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 27 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 27 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.54777, 0.0064944, 0.20349, 0.79867, 0.027761, 0.14457, 0.004606, 0.018767, 0.35916, 0.047583]
Predicted label: 3
Correct prediction
Energy consumption = 161.644375 pJ
sum error= 8
Actual label: 0
Output voltages: [0.79879, 0.091775, 0.19798, 0.011415, 0.031921, 0.0014554, 0.75699, 0.0087029, 0.14246, 0.29342]
Predicted label: 0
Correct prediction
Energy consumption = 160.517471 pJ
sum error= 8
Actual label: 1
Output voltages: [0.0081545, 0.79851, 0.051338, 0.09045, 0.028182, 0.014467, 0.31057, 0.017976, 0.49919, 0.050793]
Predicted label: 1
Correct prediction
Energy consumption = 166.601136 pJ
sum error= 8
Actual label: 9
Output voltages: [0.049553, 0.003151, 0.027861, 0.028283, 0.068626, 0.02049, 0.015108, 0.047972, 0.60718, 0.79558]
Predicted label: 9
Correct prediction
Energy consumption = 155.075558 pJ
sum error= 8
Actual label: 9
Output voltages: [0.14065, 0.015608, 0.018038, 0.69019, 0.25488, 0.32616, 0.0087576, 0.035847, 0.23586, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 145.952676 pJ
sum error= 8
Actual label: 4
Output voltages: [0.0035271, 0.028283, 0.22444, 0.019787, 0.79863, 0.0016927, 0.11406, 0.027393, 0.023457, 0.17014]
Predicted label: 4
Correct prediction
Energy consumption = 151.603778 pJ
sum error= 8
Actual label: 1
Output voltages: [0.032533, 0.79869, 0.35953, 0.034761, 0.050047, 0.0010859, 0.57249, 0.0015148, 0.089044, 0.020853]
Predicted label: 1
Correct prediction
Energy consumption = 165.262596 pJ
sum error= 8
Actual label: 8
Output voltages: [0.018671, 0.077231, 0.11378, 0.021837, 0.018723, 0.0035377, 0.039168, 0.010032, 0.79879, 0.40206]
Predicted label: 8
Correct prediction
Energy consumption = 146.365400 pJ
sum error= 8
Actual label: 2
Output voltages: [0.087063, 0.052735, 0.7987, 0.0407, 0.030678, 0.0012145, 0.36553, 0.037792, 0.39348, 0.011466]
Predicted label: 2
Correct prediction
Energy consumption = 150.597369 pJ
sum error= 8
Actual label: 1
Output voltages: [0.15743, 0.79838, 0.027497, 0.044769, 0.011224, 0.004333, 0.40863, 0.002105, 0.17839, 0.26957]
Predicted label: 1
Correct prediction
Energy consumption = 161.008472 pJ
sum error= 8
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 28 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 28 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 28 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.39006, 0.20592, 0.79877, 0.15194, 0.011603, 0.0012163, 0.30919, 0.0211, 0.65691, 0.03634]
Predicted label: 2
Correct prediction
Energy consumption = 167.857443 pJ
sum error= 8
Actual label: 9
Output voltages: [0.21517, 0.015604, 0.013352, 0.021034, 0.16529, 0.023145, 0.004012, 0.0073673, 0.44744, 0.79711]
Predicted label: 9
Correct prediction
Energy consumption = 151.674349 pJ
sum error= 8
Actual label: 7
Output voltages: [0.0017456, 0.29407, 0.28972, 0.79398, 0.0033094, 0.0012899, 0.016412, 0.7701, 0.68826, 0.046938]
Predicted label: 3
Wrong prediction!
Energy consumption = 155.583161 pJ
sum error= 9
Actual label: 5
Output voltages: [0.011733, 0.011202, 0.002966, 0.46704, 0.010666, 0.79879, 0.38314, 0.0080319, 0.7409, 0.0044742]
Predicted label: 5
Correct prediction
Energy consumption = 140.398234 pJ
sum error= 9
Actual label: 9
Output voltages: [0.43482, 0.0013125, 0.35539, 0.022476, 0.3954, 0.0027717, 0.055365, 0.008046, 0.031546, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 156.459705 pJ
sum error= 9
Actual label: 2
Output voltages: [0.63609, 0.16786, 0.79855, 0.19986, 0.03156, 0.0012313, 0.20321, 0.036666, 0.43947, 0.031046]
Predicted label: 2
Correct prediction
Energy consumption = 154.279614 pJ
sum error= 9
Actual label: 6
Output voltages: [0.26772, 0.026604, 0.026977, 0.008804, 0.11446, 0.16529, 0.7976, 0.011046, 0.77523, 0.012285]
Predicted label: 6
Correct prediction
Energy consumption = 150.217402 pJ
sum error= 9
Actual label: 4
Output voltages: [0.013822, 0.021594, 0.12119, 0.055529, 0.79876, 0.0014337, 0.033215, 0.32702, 0.011922, 0.42919]
Predicted label: 4
Correct prediction
Energy consumption = 146.992916 pJ
sum error= 9
Actual label: 1
Output voltages: [0.0011633, 0.79876, 0.0012277, 0.019289, 0.026433, 0.016281, 0.49287, 0.21143, 0.60676, 0.0072859]
Predicted label: 1
Correct prediction
Energy consumption = 159.675236 pJ
sum error= 9
Actual label: 5
Output voltages: [0.016846, 0.0013401, 0.037236, 0.066996, 0.0095359, 0.73912, 0.36395, 0.0050982, 0.78491, 0.047484]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.332030 pJ
sum error= 10
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 29 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 29 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 29 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.037115, 0.0019602, 0.0015594, 0.38794, 0.58052, 0.54516, 0.2889, 0.0012628, 0.7555, 0.033708]
Predicted label: 8
Correct prediction
Energy consumption = 170.518556 pJ
sum error= 10
Actual label: 2
Output voltages: [0.26411, 0.3062, 0.79844, 0.19075, 0.0027397, 0.0012502, 0.10047, 0.0015422, 0.33253, 0.011388]
Predicted label: 2
Correct prediction
Energy consumption = 146.403055 pJ
sum error= 10
Actual label: 9
Output voltages: [0.28597, 0.020654, 0.17102, 0.045282, 0.17538, 0.027386, 0.010838, 0.014565, 0.067517, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 157.549113 pJ
sum error= 10
Actual label: 2
Output voltages: [0.46071, 0.048565, 0.79861, 0.028933, 0.0080467, 0.0010692, 0.15364, 0.068321, 0.4075, 0.071698]
Predicted label: 2
Correct prediction
Energy consumption = 144.742401 pJ
sum error= 10
Actual label: 0
Output voltages: [0.79879, 0.028385, 0.051525, 0.026929, 0.016874, 0.015617, 0.41991, 0.026879, 0.043139, 0.03373]
Predicted label: 0
Correct prediction
Energy consumption = 160.622263 pJ
sum error= 10
Actual label: 4
Output voltages: [0.014724, 0.002196, 0.21594, 0.03409, 0.79866, 0.024031, 0.17235, 0.024373, 0.016973, 0.52338]
Predicted label: 4
Correct prediction
Energy consumption = 159.493062 pJ
sum error= 10
Actual label: 0
Output voltages: [0.79876, 0.051214, 0.14264, 0.020205, 0.011811, 0.0047107, 0.35185, 0.013309, 0.044502, 0.026936]
Predicted label: 0
Correct prediction
Energy consumption = 148.804656 pJ
sum error= 10
Actual label: 0
Output voltages: [0.79847, 0.020108, 0.040444, 0.077351, 0.0010802, 0.055842, 0.43978, 0.0025685, 0.43553, 0.12436]
Predicted label: 0
Correct prediction
Energy consumption = 140.978047 pJ
sum error= 10
Actual label: 2
Output voltages: [0.24626, 0.069485, 0.79809, 0.50643, 0.0014083, 0.0011272, 0.24712, 0.0074042, 0.72459, 0.0097299]
Predicted label: 2
Correct prediction
Energy consumption = 141.598098 pJ
sum error= 10
Actual label: 8
Output voltages: [0.028455, 0.048708, 0.13909, 0.35744, 0.0051691, 0.3589, 0.023398, 0.029249, 0.7987, 0.020069]
Predicted label: 8
Correct prediction
Energy consumption = 150.781051 pJ
sum error= 10
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 30 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 30 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 30 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.023759, 0.27173, 0.66777, 0.0012112, 0.78673, 0.001104, 0.79136, 0.0068802, 0.016095, 0.0048122]
Predicted label: 6
Wrong prediction!
Energy consumption = 167.084185 pJ
sum error= 11
Actual label: 7
Output voltages: [0.27932, 0.0017471, 0.041992, 0.68134, 0.026874, 0.0017003, 0.0010825, 0.79802, 0.45647, 0.56425]
Predicted label: 7
Correct prediction
Energy consumption = 148.895477 pJ
sum error= 11
Actual label: 1
Output voltages: [0.0061719, 0.79853, 0.050572, 0.065412, 0.049847, 0.012922, 0.76521, 0.0010948, 0.03654, 0.44604]
Predicted label: 1
Correct prediction
Energy consumption = 161.521038 pJ
sum error= 11
Actual label: 2
Output voltages: [0.52743, 0.011266, 0.79875, 0.24037, 0.018741, 0.0010822, 0.16026, 0.18364, 0.5787, 0.018687]
Predicted label: 2
Correct prediction
Energy consumption = 139.409040 pJ
sum error= 11
Actual label: 4
Output voltages: [0.0024495, 0.013276, 0.0062922, 0.0013344, 0.79879, 0.0016547, 0.044963, 0.17918, 0.34066, 0.013478]
Predicted label: 4
Correct prediction
Energy consumption = 156.987448 pJ
sum error= 11
Actual label: 0
Output voltages: [0.79247, 0.051244, 0.18968, 0.0050455, 0.0010674, 0.12833, 0.12537, 0.0011396, 0.5494, 0.22083]
Predicted label: 0
Correct prediction
Energy consumption = 157.782063 pJ
sum error= 11
Actual label: 2
Output voltages: [0.26923, 0.24329, 0.79866, 0.021513, 0.021763, 0.0014263, 0.39087, 0.023318, 0.42467, 0.0375]
Predicted label: 2
Correct prediction
Energy consumption = 147.719046 pJ
sum error= 11
Actual label: 7
Output voltages: [0.043673, 0.0062371, 0.18892, 0.51702, 0.022866, 0.0011953, 0.0010939, 0.79758, 0.52515, 0.11246]
Predicted label: 7
Correct prediction
Energy consumption = 144.686101 pJ
sum error= 11
Actual label: 4
Output voltages: [0.0014199, 0.036091, 0.027234, 0.0069848, 0.79797, 0.001356, 0.039057, 0.020962, 0.31292, 0.022893]
Predicted label: 4
Correct prediction
Energy consumption = 152.082472 pJ
sum error= 11
Actual label: 3
Output voltages: [0.53447, 0.021552, 0.18013, 0.79859, 0.019685, 0.019823, 0.02301, 0.018651, 0.59462, 0.023815]
Predicted label: 3
Correct prediction
Energy consumption = 150.151046 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 31 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 31 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 31 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.19207, 0.033916, 0.11358, 0.79868, 0.037788, 0.006486, 0.021961, 0.010145, 0.50447, 0.1072]
Predicted label: 3
Correct prediction
Energy consumption = 168.617425 pJ
sum error= 11
Actual label: 0
Output voltages: [0.79767, 0.022976, 0.097274, 0.004496, 0.027957, 0.0065645, 0.74771, 0.022981, 0.11363, 0.046752]
Predicted label: 0
Correct prediction
Energy consumption = 157.944258 pJ
sum error= 11
Actual label: 0
Output voltages: [0.79879, 0.09007, 0.17708, 0.033449, 0.029093, 0.0016258, 0.5661, 0.015315, 0.087147, 0.2239]
Predicted label: 0
Correct prediction
Energy consumption = 150.593398 pJ
sum error= 11
Actual label: 3
Output voltages: [0.018741, 0.0011362, 0.11066, 0.79829, 0.15803, 0.49841, 0.014949, 0.0017474, 0.56892, 0.0043451]
Predicted label: 3
Correct prediction
Energy consumption = 144.833766 pJ
sum error= 11
Actual label: 1
Output voltages: [0.016296, 0.79842, 0.101, 0.60165, 0.36437, 0.0078095, 0.35316, 0.17097, 0.015197, 0.1345]
Predicted label: 1
Correct prediction
Energy consumption = 165.234788 pJ
sum error= 11
Actual label: 9
Output voltages: [0.2216, 0.026124, 0.024491, 0.058566, 0.12016, 0.058483, 0.12127, 0.041634, 0.44326, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 156.218780 pJ
sum error= 11
Actual label: 6
Output voltages: [0.043897, 0.024255, 0.024774, 0.010922, 0.060546, 0.48989, 0.79879, 0.0063687, 0.65057, 0.012909]
Predicted label: 6
Correct prediction
Energy consumption = 147.725044 pJ
sum error= 11
Actual label: 5
Output voltages: [0.046452, 0.0011175, 0.00128, 0.33137, 0.22918, 0.79872, 0.28902, 0.05268, 0.79277, 0.0030562]
Predicted label: 5
Correct prediction
Energy consumption = 132.519776 pJ
sum error= 11
Actual label: 2
Output voltages: [0.7666, 0.0010728, 0.7836, 0.7675, 0.0043424, 0.0028603, 0.015233, 0.088941, 0.78651, 0.024846]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.037040 pJ
sum error= 12
Actual label: 5
Output voltages: [0.023545, 0.0010698, 0.019245, 0.30311, 0.034758, 0.79826, 0.18478, 0.017984, 0.78012, 0.040598]
Predicted label: 5
Correct prediction
Energy consumption = 140.606294 pJ
sum error= 12
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 32 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 32 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 32 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.018409, 0.78407, 0.01794, 0.38491, 0.0061931, 0.029765, 0.0024925, 0.021177, 0.78626, 0.75942]
Predicted label: 8
Wrong prediction!
Energy consumption = 178.387125 pJ
sum error= 13
Actual label: 2
Output voltages: [0.31365, 0.22603, 0.68792, 0.75541, 0.0011122, 0.0010993, 0.025991, 0.51116, 0.73682, 0.1252]
Predicted label: 3
Wrong prediction!
Energy consumption = 150.296148 pJ
sum error= 14
Actual label: 9
Output voltages: [0.44134, 0.013744, 0.044484, 0.02177, 0.1456, 0.018652, 0.0077135, 0.010519, 0.39718, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 147.556987 pJ
sum error= 14
Actual label: 3
Output voltages: [0.29658, 0.013617, 0.037145, 0.79867, 0.0075149, 0.027365, 0.0065248, 0.022603, 0.57999, 0.052733]
Predicted label: 3
Correct prediction
Energy consumption = 146.339596 pJ
sum error= 14
Actual label: 0
Output voltages: [0.7873, 0.17782, 0.0010848, 0.16682, 0.021626, 0.41861, 0.76692, 0.0010748, 0.033217, 0.049208]
Predicted label: 0
Correct prediction
Energy consumption = 162.873097 pJ
sum error= 14
Actual label: 4
Output voltages: [0.0049359, 0.026865, 0.017617, 0.015491, 0.79879, 0.0011327, 0.27091, 0.050631, 0.039775, 0.010226]
Predicted label: 4
Correct prediction
Energy consumption = 148.073962 pJ
sum error= 14
Actual label: 2
Output voltages: [0.041255, 0.76396, 0.77977, 0.053064, 0.13614, 0.0010712, 0.43729, 0.012237, 0.051691, 0.0065593]
Predicted label: 2
Correct prediction
Energy consumption = 151.479049 pJ
sum error= 14
Actual label: 0
Output voltages: [0.79877, 0.041708, 0.041212, 0.014866, 0.023033, 0.0021222, 0.55556, 0.016546, 0.25383, 0.18656]
Predicted label: 0
Correct prediction
Energy consumption = 153.446343 pJ
sum error= 14
Actual label: 7
Output voltages: [0.013546, 0.032857, 0.29451, 0.02044, 0.0082739, 0.0010726, 0.0013287, 0.79857, 0.10087, 0.041679]
Predicted label: 7
Correct prediction
Energy consumption = 149.331173 pJ
sum error= 14
Actual label: 1
Output voltages: [0.0017255, 0.79849, 0.045522, 0.046031, 0.0079966, 0.0020284, 0.63347, 0.019941, 0.33323, 0.019907]
Predicted label: 1
Correct prediction
Energy consumption = 160.608478 pJ
sum error= 14
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 33 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 33 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 33 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.034374, 0.7985, 0.36053, 0.69461, 0.010496, 0.0010679, 0.63981, 0.0066212, 0.022278, 0.19234]
Predicted label: 1
Correct prediction
Energy consumption = 184.511441 pJ
sum error= 14
Actual label: 2
Output voltages: [0.085815, 0.42173, 0.79879, 0.071635, 0.0042032, 0.0013722, 0.39797, 0.020942, 0.33597, 0.2272]
Predicted label: 2
Correct prediction
Energy consumption = 147.791740 pJ
sum error= 14
Actual label: 1
Output voltages: [0.012111, 0.79846, 0.10928, 0.036175, 0.0084582, 0.0015943, 0.57228, 0.0018666, 0.16037, 0.15756]
Predicted label: 1
Correct prediction
Energy consumption = 159.341491 pJ
sum error= 14
Actual label: 5
Output voltages: [0.050583, 0.0012762, 0.011859, 0.048671, 0.0084453, 0.79879, 0.14515, 0.015184, 0.78009, 0.030779]
Predicted label: 5
Correct prediction
Energy consumption = 152.068837 pJ
sum error= 14
Actual label: 3
Output voltages: [0.21637, 0.031797, 0.031954, 0.79871, 0.0059383, 0.0047703, 0.021119, 0.011877, 0.52651, 0.060473]
Predicted label: 3
Correct prediction
Energy consumption = 151.343084 pJ
sum error= 14
Actual label: 3
Output voltages: [0.37948, 0.048552, 0.072627, 0.79867, 0.023861, 0.0018727, 0.019646, 0.0093595, 0.46267, 0.045598]
Predicted label: 3
Correct prediction
Energy consumption = 136.367998 pJ
sum error= 14
Actual label: 9
Output voltages: [0.41061, 0.0081826, 0.0099722, 0.01984, 0.7778, 0.026574, 0.016904, 0.017106, 0.023864, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 149.754130 pJ
sum error= 14
Actual label: 7
Output voltages: [0.60235, 0.037767, 0.069942, 0.71271, 0.0010697, 0.0011703, 0.0013107, 0.79874, 0.042816, 0.37443]
Predicted label: 7
Correct prediction
Energy consumption = 146.632083 pJ
sum error= 14
Actual label: 8
Output voltages: [0.7179, 0.0020873, 0.26951, 0.01662, 0.012595, 0.030705, 0.010249, 0.0011375, 0.79878, 0.04811]
Predicted label: 8
Correct prediction
Energy consumption = 150.287277 pJ
sum error= 14
Actual label: 6
Output voltages: [0.041095, 0.042026, 0.17241, 0.0026377, 0.12364, 0.2265, 0.79877, 0.0016493, 0.4256, 0.012768]
Predicted label: 6
Correct prediction
Energy consumption = 137.298816 pJ
sum error= 14
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 34 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 34 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 34 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.047326, 0.004392, 0.060894, 0.082257, 0.0052793, 0.64145, 0.56721, 0.0012276, 0.43581, 0.0082426]
Predicted label: 5
Correct prediction
Energy consumption = 175.409338 pJ
sum error= 14
Actual label: 6
Output voltages: [0.036009, 0.0051712, 0.030768, 0.0034816, 0.11062, 0.15585, 0.79867, 0.0068427, 0.7335, 0.010408]
Predicted label: 6
Correct prediction
Energy consumption = 148.278777 pJ
sum error= 14
Actual label: 1
Output voltages: [0.01507, 0.79851, 0.042162, 0.086053, 0.013632, 0.0011008, 0.74484, 0.0071298, 0.043286, 0.24814]
Predicted label: 1
Correct prediction
Energy consumption = 166.740149 pJ
sum error= 14
Actual label: 3
Output voltages: [0.26625, 0.02309, 0.038422, 0.79875, 0.063365, 0.46149, 0.045144, 0.0027983, 0.3501, 0.087586]
Predicted label: 3
Correct prediction
Energy consumption = 148.254187 pJ
sum error= 14
Actual label: 8
Output voltages: [0.038307, 0.016071, 0.13309, 0.11549, 0.0063051, 0.053475, 0.72181, 0.001096, 0.79711, 0.022945]
Predicted label: 8
Correct prediction
Energy consumption = 152.416885 pJ
sum error= 14
Actual label: 1
Output voltages: [0.031908, 0.79855, 0.18636, 0.17928, 0.31739, 0.0037817, 0.22913, 0.0079901, 0.046659, 0.10442]
Predicted label: 1
Correct prediction
Energy consumption = 167.164420 pJ
sum error= 14
Actual label: 0
Output voltages: [0.79873, 0.33061, 0.38335, 0.020625, 0.0067322, 0.0028822, 0.16493, 0.037739, 0.42398, 0.2097]
Predicted label: 0
Correct prediction
Energy consumption = 159.556233 pJ
sum error= 14
Actual label: 5
Output voltages: [0.00448, 0.0014781, 0.0011437, 0.49848, 0.18379, 0.78506, 0.33967, 0.0016489, 0.67712, 0.026945]
Predicted label: 5
Correct prediction
Energy consumption = 143.573339 pJ
sum error= 14
Actual label: 1
Output voltages: [0.01418, 0.79867, 0.0063081, 0.035672, 0.031155, 0.0020791, 0.53145, 0.0040257, 0.43034, 0.038196]
Predicted label: 1
Correct prediction
Energy consumption = 163.777844 pJ
sum error= 14
Actual label: 3
Output voltages: [0.023378, 0.077931, 0.22105, 0.79875, 0.015982, 0.0014913, 0.0032925, 0.036858, 0.54974, 0.024908]
Predicted label: 3
Correct prediction
Energy consumption = 147.994198 pJ
sum error= 14
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 35 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 35 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 35 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0012736, 0.79878, 0.22865, 0.57422, 0.44462, 0.0010664, 0.020043, 0.023716, 0.082397, 0.09549]
Predicted label: 1
Correct prediction
Energy consumption = 183.769235 pJ
sum error= 14
Actual label: 5
Output voltages: [0.18325, 0.0012454, 0.010936, 0.26382, 0.0066957, 0.79879, 0.17009, 0.092023, 0.77915, 0.025524]
Predicted label: 5
Correct prediction
Energy consumption = 150.757928 pJ
sum error= 14
Actual label: 5
Output voltages: [0.54493, 0.012806, 0.0016328, 0.38155, 0.007383, 0.79873, 0.14588, 0.011057, 0.74422, 0.051415]
Predicted label: 5
Correct prediction
Energy consumption = 137.213430 pJ
sum error= 14
Actual label: 6
Output voltages: [0.46671, 0.12898, 0.13354, 0.014568, 0.14333, 0.060987, 0.79879, 0.001074, 0.36285, 0.023326]
Predicted label: 6
Correct prediction
Energy consumption = 151.001373 pJ
sum error= 14
Actual label: 1
Output voltages: [0.042285, 0.7983, 0.25648, 0.0066438, 0.3064, 0.0011925, 0.18137, 0.0055846, 0.12833, 0.01524]
Predicted label: 1
Correct prediction
Energy consumption = 156.608789 pJ
sum error= 14
Actual label: 8
Output voltages: [0.018046, 0.0033365, 0.0020779, 0.23351, 0.011215, 0.32163, 0.39991, 0.0013381, 0.79867, 0.049504]
Predicted label: 8
Correct prediction
Energy consumption = 146.587768 pJ
sum error= 14
Actual label: 5
Output voltages: [0.035568, 0.002966, 0.0032667, 0.48462, 0.019452, 0.79868, 0.2084, 0.16178, 0.75582, 0.036589]
Predicted label: 5
Correct prediction
Energy consumption = 140.520659 pJ
sum error= 14
Actual label: 1
Output voltages: [0.032545, 0.79853, 0.01237, 0.016475, 0.013388, 0.017349, 0.25812, 0.0027918, 0.48722, 0.018113]
Predicted label: 1
Correct prediction
Energy consumption = 168.406684 pJ
sum error= 14
Actual label: 7
Output voltages: [0.22459, 0.52233, 0.27761, 0.055712, 0.055177, 0.0013043, 0.0010659, 0.79771, 0.0015135, 0.373]
Predicted label: 7
Correct prediction
Energy consumption = 158.545114 pJ
sum error= 14
Actual label: 9
Output voltages: [0.061901, 0.016102, 0.10841, 0.012768, 0.50114, 0.0016316, 0.0015486, 0.0022324, 0.36223, 0.79545]
Predicted label: 9
Correct prediction
Energy consumption = 147.321900 pJ
sum error= 14
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 36 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 36 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 36 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0081697, 0.0053382, 0.17973, 0.014843, 0.79876, 0.021584, 0.28605, 0.07107, 0.028182, 0.15971]
Predicted label: 4
Correct prediction
Energy consumption = 167.091823 pJ
sum error= 14
Actual label: 6
Output voltages: [0.050275, 0.053172, 0.047362, 0.0075871, 0.12883, 0.52362, 0.79869, 0.016736, 0.46162, 0.020742]
Predicted label: 6
Correct prediction
Energy consumption = 147.471404 pJ
sum error= 14
Actual label: 2
Output voltages: [0.56882, 0.12551, 0.79876, 0.10125, 0.0016844, 0.0012912, 0.47754, 0.45604, 0.33354, 0.011221]
Predicted label: 2
Correct prediction
Energy consumption = 153.617258 pJ
sum error= 14
Actual label: 2
Output voltages: [0.31586, 0.75594, 0.79836, 0.031827, 0.0056534, 0.0012654, 0.19951, 0.0099717, 0.094791, 0.035097]
Predicted label: 2
Correct prediction
Energy consumption = 140.700439 pJ
sum error= 14
Actual label: 5
Output voltages: [0.030468, 0.0011583, 0.01206, 0.1369, 0.030436, 0.79401, 0.053912, 0.0061826, 0.78886, 0.076833]
Predicted label: 5
Correct prediction
Energy consumption = 143.601509 pJ
sum error= 14
Actual label: 0
Output voltages: [0.79711, 0.018753, 0.011263, 0.16418, 0.082428, 0.0089059, 0.33318, 0.028657, 0.7331, 0.1602]
Predicted label: 0
Correct prediction
Energy consumption = 160.001518 pJ
sum error= 14
Actual label: 6
Output voltages: [0.74476, 0.063407, 0.021503, 0.00357, 0.032558, 0.21552, 0.79865, 0.020231, 0.15985, 0.019617]
Predicted label: 6
Correct prediction
Energy consumption = 144.396108 pJ
sum error= 14
Actual label: 5
Output voltages: [0.011102, 0.0010993, 0.20705, 0.69769, 0.040312, 0.6035, 0.0016724, 0.0052877, 0.78812, 0.1219]
Predicted label: 8
Wrong prediction!
Energy consumption = 145.416314 pJ
sum error= 15
Actual label: 6
Output voltages: [0.21367, 0.23782, 0.05303, 0.010044, 0.30767, 0.22515, 0.79874, 0.0011442, 0.52234, 0.010287]
Predicted label: 6
Correct prediction
Energy consumption = 151.427331 pJ
sum error= 15
Actual label: 3
Output voltages: [0.39648, 0.024128, 0.072737, 0.79872, 0.0040895, 0.020872, 0.0013376, 0.055513, 0.55052, 0.064638]
Predicted label: 3
Correct prediction
Energy consumption = 148.286885 pJ
sum error= 15
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 37 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 37 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 37 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.50697, 0.55774, 0.12715, 0.50777, 0.0012023, 0.0010699, 0.002831, 0.79874, 0.028307, 0.59467]
Predicted label: 7
Correct prediction
Energy consumption = 176.162033 pJ
sum error= 15
Actual label: 2
Output voltages: [0.28036, 0.022988, 0.79866, 0.031241, 0.02648, 0.0011602, 0.28663, 0.022827, 0.65219, 0.020313]
Predicted label: 2
Correct prediction
Energy consumption = 140.341431 pJ
sum error= 15
Actual label: 0
Output voltages: [0.79694, 0.020864, 0.021517, 0.0041997, 0.0035093, 0.12865, 0.6274, 0.016041, 0.035375, 0.18377]
Predicted label: 0
Correct prediction
Energy consumption = 158.496002 pJ
sum error= 15
Actual label: 8
Output voltages: [0.22424, 0.042781, 0.2201, 0.028437, 0.031389, 0.0016579, 0.47654, 0.0041481, 0.79879, 0.18457]
Predicted label: 8
Correct prediction
Energy consumption = 153.533008 pJ
sum error= 15
Actual label: 8
Output voltages: [0.020314, 0.043966, 0.32576, 0.020373, 0.015441, 0.016073, 0.021109, 0.0037062, 0.79872, 0.13597]
Predicted label: 8
Correct prediction
Energy consumption = 148.414776 pJ
sum error= 15
Actual label: 5
Output voltages: [0.029808, 0.0010834, 0.0042806, 0.20969, 0.029107, 0.79879, 0.32346, 0.028907, 0.77205, 0.01548]
Predicted label: 5
Correct prediction
Energy consumption = 147.550820 pJ
sum error= 15
Actual label: 4
Output voltages: [0.052937, 0.064057, 0.029062, 0.11787, 0.79875, 0.0056325, 0.040801, 0.016657, 0.025414, 0.53013]
Predicted label: 4
Correct prediction
Energy consumption = 158.426156 pJ
sum error= 15
Actual label: 1
Output voltages: [0.02963, 0.79834, 0.019624, 0.13875, 0.046937, 0.0041816, 0.53985, 0.028364, 0.036318, 0.26715]
Predicted label: 1
Correct prediction
Energy consumption = 166.448101 pJ
sum error= 15
Actual label: 1
Output voltages: [0.01392, 0.79858, 0.192, 0.039543, 0.033957, 0.0012713, 0.63927, 0.0031028, 0.18148, 0.032279]
Predicted label: 1
Correct prediction
Energy consumption = 156.438110 pJ
sum error= 15
Actual label: 4
Output voltages: [0.0088261, 0.019999, 0.18768, 0.013568, 0.79857, 0.0057526, 0.075001, 0.030446, 0.040509, 0.036001]
Predicted label: 4
Correct prediction
Energy consumption = 151.418430 pJ
sum error= 15
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 38 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 38 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 38 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.78845, 0.020355, 0.73416, 0.0025604, 0.0014581, 0.0055664, 0.39034, 0.0014855, 0.307, 0.027851]
Predicted label: 0
Correct prediction
Energy consumption = 170.455815 pJ
sum error= 15
Actual label: 3
Output voltages: [0.22061, 0.022295, 0.65456, 0.79812, 0.0010718, 0.0011056, 0.00286, 0.42951, 0.77478, 0.010874]
Predicted label: 3
Correct prediction
Energy consumption = 143.865127 pJ
sum error= 15
Actual label: 3
Output voltages: [0.1155, 0.0096228, 0.1302, 0.79872, 0.0169, 0.012091, 0.013083, 0.06106, 0.70593, 0.10471]
Predicted label: 3
Correct prediction
Energy consumption = 134.980188 pJ
sum error= 15
Actual label: 7
Output voltages: [0.13195, 0.15487, 0.16517, 0.51104, 0.0018962, 0.0016224, 0.0010861, 0.79869, 0.34037, 0.64641]
Predicted label: 7
Correct prediction
Energy consumption = 151.288435 pJ
sum error= 15
Actual label: 6
Output voltages: [0.030122, 0.27598, 0.49709, 0.0030746, 0.16267, 0.019883, 0.79874, 0.0010927, 0.45699, 0.021269]
Predicted label: 6
Correct prediction
Energy consumption = 145.347088 pJ
sum error= 15
Actual label: 1
Output voltages: [0.0061265, 0.79842, 0.022604, 0.050206, 0.023367, 0.0086402, 0.7419, 0.0057669, 0.38486, 0.041049]
Predicted label: 1
Correct prediction
Energy consumption = 164.269883 pJ
sum error= 15
Actual label: 6
Output voltages: [0.47951, 0.03291, 0.019524, 0.0055261, 0.30572, 0.45305, 0.79879, 0.01743, 0.52972, 0.010044]
Predicted label: 6
Correct prediction
Energy consumption = 150.182534 pJ
sum error= 15
Actual label: 2
Output voltages: [0.2148, 0.38151, 0.7987, 0.20819, 0.025396, 0.0011594, 0.22095, 0.0080511, 0.2838, 0.051936]
Predicted label: 2
Correct prediction
Energy consumption = 146.260329 pJ
sum error= 15
Actual label: 1
Output voltages: [0.42983, 0.7983, 0.54296, 0.0011179, 0.21107, 0.0011542, 0.036585, 0.022071, 0.048921, 0.071303]
Predicted label: 1
Correct prediction
Energy consumption = 155.382951 pJ
sum error= 15
Actual label: 9
Output voltages: [0.17252, 0.0025699, 0.020804, 0.0058747, 0.13836, 0.028009, 0.0021745, 0.046504, 0.74738, 0.78653]
Predicted label: 9
Correct prediction
Energy consumption = 150.738914 pJ
sum error= 15
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 39 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 39 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 39 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.56887, 0.011225, 0.79876, 0.15375, 0.0052609, 0.0010779, 0.21122, 0.029506, 0.26966, 0.014388]
Predicted label: 2
Correct prediction
Energy consumption = 162.215858 pJ
sum error= 15
Actual label: 8
Output voltages: [0.15655, 0.0058307, 0.18076, 0.13498, 0.031246, 0.0058183, 0.030456, 0.0023703, 0.79879, 0.012002]
Predicted label: 8
Correct prediction
Energy consumption = 147.693548 pJ
sum error= 15
Actual label: 6
Output voltages: [0.19623, 0.050048, 0.2106, 0.014041, 0.28192, 0.31539, 0.79879, 0.00288, 0.37717, 0.019771]
Predicted label: 6
Correct prediction
Energy consumption = 145.777303 pJ
sum error= 15
Actual label: 1
Output voltages: [0.048967, 0.79841, 0.05236, 0.1822, 0.16223, 0.0015204, 0.2997, 0.0038738, 0.036137, 0.34945]
Predicted label: 1
Correct prediction
Energy consumption = 169.631888 pJ
sum error= 15
Actual label: 9
Output voltages: [0.74706, 0.01022, 0.0073207, 0.14851, 0.73272, 0.0061287, 0.0075973, 0.0049005, 0.049964, 0.79678]
Predicted label: 9
Correct prediction
Energy consumption = 151.838630 pJ
sum error= 15
Actual label: 5
Output voltages: [0.049702, 0.0010768, 0.012106, 0.45027, 0.02238, 0.79843, 0.093436, 0.11066, 0.77209, 0.1894]
Predicted label: 5
Correct prediction
Energy consumption = 147.295494 pJ
sum error= 15
Actual label: 2
Output voltages: [0.54483, 0.025491, 0.79868, 0.155, 0.033008, 0.0011597, 0.29627, 0.20415, 0.32461, 0.015078]
Predicted label: 2
Correct prediction
Energy consumption = 149.114873 pJ
sum error= 15
Actual label: 5
Output voltages: [0.0096161, 0.0014246, 0.035774, 0.35703, 0.05886, 0.77289, 0.11971, 0.0016726, 0.79513, 0.27246]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.117411 pJ
sum error= 16
Actual label: 4
Output voltages: [0.014387, 0.01735, 0.16986, 0.012223, 0.7986, 0.0026321, 0.13239, 0.049222, 0.04406, 0.051527]
Predicted label: 4
Correct prediction
Energy consumption = 153.069546 pJ
sum error= 16
Actual label: 4
Output voltages: [0.0034533, 0.026797, 0.26044, 0.0038768, 0.79869, 0.0019592, 0.13265, 0.2625, 0.020246, 0.035971]
Predicted label: 4
Correct prediction
Energy consumption = 138.903226 pJ
sum error= 16
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 40 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 40 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 40 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.49672, 0.013952, 0.79875, 0.14204, 0.0093557, 0.0010873, 0.015503, 0.032173, 0.50646, 0.0079516]
Predicted label: 2
Correct prediction
Energy consumption = 172.390082 pJ
sum error= 16
Actual label: 8
Output voltages: [0.073678, 0.0055458, 0.41326, 0.62596, 0.014991, 0.0012871, 0.038769, 0.0038771, 0.7984, 0.10988]
Predicted label: 8
Correct prediction
Energy consumption = 147.747057 pJ
sum error= 16
Actual label: 3
Output voltages: [0.47486, 0.0021428, 0.26194, 0.79879, 0.29457, 0.13007, 0.021728, 0.0014492, 0.5101, 0.020223]
Predicted label: 3
Correct prediction
Energy consumption = 143.877447 pJ
sum error= 16
Actual label: 8
Output voltages: [0.0039871, 0.028917, 0.22317, 0.038936, 0.003543, 0.011352, 0.06524, 0.020649, 0.79878, 0.28501]
Predicted label: 8
Correct prediction
Energy consumption = 145.115788 pJ
sum error= 16
Actual label: 2
Output voltages: [0.12441, 0.03545, 0.79879, 0.040822, 0.0026618, 0.0012898, 0.02702, 0.40168, 0.69449, 0.091124]
Predicted label: 2
Correct prediction
Energy consumption = 148.753162 pJ
sum error= 16
Actual label: 4
Output voltages: [0.041474, 0.0036029, 0.17011, 0.01161, 0.79879, 0.035502, 0.032149, 0.0020004, 0.055104, 0.60989]
Predicted label: 4
Correct prediction
Energy consumption = 156.259298 pJ
sum error= 16
Actual label: 5
Output voltages: [0.41572, 0.0010881, 0.0010885, 0.30768, 0.028814, 0.74824, 0.033455, 0.0057564, 0.77451, 0.26422]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.717476 pJ
sum error= 17
Actual label: 0
Output voltages: [0.79876, 0.12457, 0.044195, 0.028717, 0.0022774, 0.040503, 0.52795, 0.01997, 0.13124, 0.017007]
Predicted label: 0
Correct prediction
Energy consumption = 149.864676 pJ
sum error= 17
Actual label: 3
Output voltages: [0.52578, 0.022886, 0.043048, 0.79868, 0.01775, 0.010947, 0.14168, 0.023617, 0.45589, 0.012016]
Predicted label: 3
Correct prediction
Energy consumption = 154.893354 pJ
sum error= 17
Actual label: 1
Output voltages: [0.0080708, 0.79861, 0.0018579, 0.20689, 0.034373, 0.022048, 0.42372, 0.006902, 0.21773, 0.25059]
Predicted label: 1
Correct prediction
Energy consumption = 159.655789 pJ
sum error= 17
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 41 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 41 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 41 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.33304, 0.12109, 0.006124, 0.37503, 0.016646, 0.023457, 0.0011071, 0.79877, 0.12832, 0.74156]
Predicted label: 7
Correct prediction
Energy consumption = 171.220635 pJ
sum error= 17
Actual label: 7
Output voltages: [0.048994, 0.3122, 0.52413, 0.10764, 0.0036657, 0.0010809, 0.0033208, 0.79567, 0.59415, 0.062119]
Predicted label: 7
Correct prediction
Energy consumption = 152.628872 pJ
sum error= 17
Actual label: 5
Output voltages: [0.013369, 0.0018396, 0.0013027, 0.43182, 0.024246, 0.79715, 0.013683, 0.031652, 0.63603, 0.24204]
Predicted label: 5
Correct prediction
Energy consumption = 149.746312 pJ
sum error= 17
Actual label: 7
Output voltages: [0.27808, 0.014207, 0.017318, 0.06107, 0.020462, 0.0059194, 0.0011136, 0.79862, 0.6958, 0.25996]
Predicted label: 7
Correct prediction
Energy consumption = 151.292776 pJ
sum error= 17
Actual label: 9
Output voltages: [0.34944, 0.037494, 0.007902, 0.036973, 0.7325, 0.00904, 0.029505, 0.12924, 0.015288, 0.79791]
Predicted label: 9
Correct prediction
Energy consumption = 152.994241 pJ
sum error= 17
Actual label: 7
Output voltages: [0.020562, 0.019215, 0.010441, 0.27599, 0.035581, 0.016001, 0.0010861, 0.79876, 0.042378, 0.12348]
Predicted label: 7
Correct prediction
Energy consumption = 152.335443 pJ
sum error= 17
Actual label: 1
Output voltages: [0.0029906, 0.79852, 0.038052, 0.03283, 0.0085782, 0.0017695, 0.73817, 0.0068573, 0.2683, 0.025517]
Predicted label: 1
Correct prediction
Energy consumption = 158.951045 pJ
sum error= 17
Actual label: 9
Output voltages: [0.02823, 0.014618, 0.004968, 0.35186, 0.010178, 0.0093432, 0.0011362, 0.38088, 0.74539, 0.77008]
Predicted label: 9
Correct prediction
Energy consumption = 155.577244 pJ
sum error= 17
Actual label: 2
Output voltages: [0.45451, 0.0058074, 0.7987, 0.28713, 0.022024, 0.0011065, 0.057302, 0.069697, 0.66531, 0.0091301]
Predicted label: 2
Correct prediction
Energy consumption = 145.938921 pJ
sum error= 17
Actual label: 1
Output voltages: [0.0086011, 0.79833, 0.036895, 0.10377, 0.0090093, 0.038658, 0.64793, 0.04972, 0.084832, 0.045165]
Predicted label: 1
Correct prediction
Energy consumption = 163.651529 pJ
sum error= 17
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 42 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 42 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 42 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.20577, 0.026334, 0.26018, 0.0086509, 0.79859, 0.0016168, 0.011979, 0.036209, 0.048343, 0.034538]
Predicted label: 4
Correct prediction
Energy consumption = 160.134548 pJ
sum error= 17
Actual label: 2
Output voltages: [0.46017, 0.02642, 0.79872, 0.060136, 0.013858, 0.0010938, 0.32884, 0.026752, 0.44883, 0.032965]
Predicted label: 2
Correct prediction
Energy consumption = 143.464067 pJ
sum error= 17
Actual label: 9
Output voltages: [0.41667, 0.012255, 0.017301, 0.030796, 0.06764, 0.0099124, 0.0043744, 0.21702, 0.33385, 0.79651]
Predicted label: 9
Correct prediction
Energy consumption = 156.373526 pJ
sum error= 17
Actual label: 2
Output voltages: [0.58065, 0.21978, 0.79872, 0.10574, 0.01514, 0.0012004, 0.25347, 0.10049, 0.62811, 0.10345]
Predicted label: 2
Correct prediction
Energy consumption = 148.710119 pJ
sum error= 17
Actual label: 0
Output voltages: [0.7987, 0.21599, 0.034429, 0.0018306, 0.031176, 0.0039741, 0.43467, 0.0040025, 0.024833, 0.30777]
Predicted label: 0
Correct prediction
Energy consumption = 156.817450 pJ
sum error= 17
Actual label: 4
Output voltages: [0.039443, 0.03292, 0.38929, 0.0010802, 0.79879, 0.0019505, 0.63034, 0.044279, 0.033596, 0.037098]
Predicted label: 4
Correct prediction
Energy consumption = 154.411720 pJ
sum error= 17
Actual label: 9
Output voltages: [0.26634, 0.0065643, 0.018596, 0.091043, 0.48102, 0.0070009, 0.0017692, 0.0090871, 0.2613, 0.79704]
Predicted label: 9
Correct prediction
Energy consumption = 148.454506 pJ
sum error= 17
Actual label: 1
Output voltages: [0.045307, 0.79865, 0.30233, 0.21717, 0.099997, 0.0078249, 0.39235, 0.0010866, 0.020727, 0.15054]
Predicted label: 1
Correct prediction
Energy consumption = 163.490424 pJ
sum error= 17
Actual label: 4
Output voltages: [0.027997, 0.039651, 0.16206, 0.0087219, 0.79874, 0.0010951, 0.63355, 0.018856, 0.019815, 0.011843]
Predicted label: 4
Correct prediction
Energy consumption = 153.240638 pJ
sum error= 17
Actual label: 8
Output voltages: [0.028323, 0.030807, 0.065137, 0.14078, 0.007506, 0.031399, 0.027303, 0.0065464, 0.79879, 0.33559]
Predicted label: 8
Correct prediction
Energy consumption = 152.124194 pJ
sum error= 17
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 43 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 43 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 43 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.018851, 0.7986, 0.02786, 0.042798, 0.02129, 0.001258, 0.74715, 0.0013281, 0.13521, 0.036792]
Predicted label: 1
Correct prediction
Energy consumption = 182.246183 pJ
sum error= 17
Actual label: 8
Output voltages: [0.061884, 0.007342, 0.57189, 0.022106, 0.016978, 0.020036, 0.02831, 0.0015574, 0.79878, 0.52617]
Predicted label: 8
Correct prediction
Energy consumption = 146.554259 pJ
sum error= 17
Actual label: 4
Output voltages: [0.012732, 0.030407, 0.2691, 0.14278, 0.79865, 0.056429, 0.29888, 0.1084, 0.022365, 0.036435]
Predicted label: 4
Correct prediction
Energy consumption = 151.943636 pJ
sum error= 17
Actual label: 5
Output voltages: [0.03753, 0.001207, 0.001075, 0.59544, 0.049839, 0.79804, 0.22016, 0.0036087, 0.66659, 0.0056277]
Predicted label: 5
Correct prediction
Energy consumption = 137.493105 pJ
sum error= 17
Actual label: 9
Output voltages: [0.42599, 0.013876, 0.044262, 0.20396, 0.38222, 0.016356, 0.029936, 0.022493, 0.31404, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 160.379721 pJ
sum error= 17
Actual label: 8
Output voltages: [0.014005, 0.12707, 0.33802, 0.34398, 0.0062637, 0.0010746, 0.0044613, 0.24269, 0.79876, 0.014465]
Predicted label: 8
Correct prediction
Energy consumption = 148.536874 pJ
sum error= 17
Actual label: 8
Output voltages: [0.019963, 0.13135, 0.27719, 0.022411, 0.025203, 0.0089662, 0.024045, 0.016745, 0.79877, 0.14118]
Predicted label: 8
Correct prediction
Energy consumption = 146.290628 pJ
sum error= 17
Actual label: 3
Output voltages: [0.086097, 0.0072423, 0.11455, 0.79868, 0.02365, 0.04669, 0.0089352, 0.10841, 0.77415, 0.021316]
Predicted label: 3
Correct prediction
Energy consumption = 143.121215 pJ
sum error= 17
Actual label: 7
Output voltages: [0.055737, 0.023028, 0.015505, 0.12386, 0.016722, 0.0018401, 0.0010665, 0.79868, 0.061196, 0.20523]
Predicted label: 7
Correct prediction
Energy consumption = 152.550246 pJ
sum error= 17
Actual label: 6
Output voltages: [0.62022, 0.023048, 0.026521, 0.0030009, 0.15744, 0.48576, 0.79869, 0.012736, 0.44339, 0.013498]
Predicted label: 6
Correct prediction
Energy consumption = 151.269208 pJ
sum error= 17
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 44 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 44 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 44 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.16555, 0.036117, 0.0075673, 0.0085818, 0.0020202, 0.46239, 0.013899, 0.051446, 0.039341]
Predicted label: 0
Correct prediction
Energy consumption = 166.166296 pJ
sum error= 17
Actual label: 0
Output voltages: [0.79564, 0.028678, 0.018, 0.013378, 0.041373, 0.0045056, 0.7393, 0.023441, 0.048675, 0.012308]
Predicted label: 0
Correct prediction
Energy consumption = 146.956970 pJ
sum error= 17
Actual label: 3
Output voltages: [0.17525, 0.0076301, 0.05022, 0.79866, 0.033452, 0.047323, 0.043686, 0.013461, 0.56782, 0.23051]
Predicted label: 3
Correct prediction
Energy consumption = 151.716252 pJ
sum error= 17
Actual label: 0
Output voltages: [0.77704, 0.03684, 0.18772, 0.042041, 0.003336, 0.0024247, 0.29839, 0.01912, 0.77682, 0.3621]
Predicted label: 0
Correct prediction
Energy consumption = 164.519201 pJ
sum error= 17
Actual label: 2
Output voltages: [0.20042, 0.0010736, 0.76797, 0.74396, 0.0015116, 0.0070745, 0.0012508, 0.059996, 0.78694, 0.0062743]
Predicted label: 8
Wrong prediction!
Energy consumption = 142.677135 pJ
sum error= 18
Actual label: 6
Output voltages: [0.79009, 0.0010922, 0.0056609, 0.0011555, 0.45181, 0.19746, 0.7546, 0.025849, 0.24893, 0.018834]
Predicted label: 0
Wrong prediction!
Energy consumption = 144.105866 pJ
sum error= 19
Actual label: 6
Output voltages: [0.15595, 0.039009, 0.023865, 0.050393, 0.042638, 0.37568, 0.79875, 0.0010983, 0.44912, 0.16487]
Predicted label: 6
Correct prediction
Energy consumption = 144.555436 pJ
sum error= 19
Actual label: 4
Output voltages: [0.022236, 0.0042249, 0.032695, 0.012904, 0.79877, 0.0010765, 0.01102, 0.23034, 0.16715, 0.12745]
Predicted label: 4
Correct prediction
Energy consumption = 141.262397 pJ
sum error= 19
Actual label: 9
Output voltages: [0.039168, 0.032661, 0.031524, 0.75292, 0.0014077, 0.064668, 0.020215, 0.0011656, 0.79724, 0.41159]
Predicted label: 8
Wrong prediction!
Energy consumption = 155.564723 pJ
sum error= 20
Actual label: 3
Output voltages: [0.16085, 0.0010659, 0.043881, 0.79513, 0.049369, 0.77425, 0.027458, 0.14938, 0.72646, 0.018762]
Predicted label: 3
Correct prediction
Energy consumption = 142.834118 pJ
sum error= 20
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 45 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 45 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 45 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.02523, 0.0043106, 0.11689, 0.79877, 0.28064, 0.039904, 0.04356, 0.0037545, 0.20986, 0.23435]
Predicted label: 3
Correct prediction
Energy consumption = 171.470403 pJ
sum error= 20
Actual label: 3
Output voltages: [0.048925, 0.013183, 0.086511, 0.79879, 0.014307, 0.0041025, 0.00157, 0.024598, 0.71774, 0.041329]
Predicted label: 3
Correct prediction
Energy consumption = 133.891573 pJ
sum error= 20
Actual label: 2
Output voltages: [0.35074, 0.54014, 0.79878, 0.20209, 0.011893, 0.0013254, 0.11968, 0.02079, 0.044474, 0.092245]
Predicted label: 2
Correct prediction
Energy consumption = 148.559101 pJ
sum error= 20
Actual label: 3
Output voltages: [0.11417, 0.011324, 0.1651, 0.7987, 0.0093551, 0.0059324, 0.019506, 0.020609, 0.35623, 0.067309]
Predicted label: 3
Correct prediction
Energy consumption = 142.377825 pJ
sum error= 20
Actual label: 9
Output voltages: [0.68227, 0.0093334, 0.03043, 0.03953, 0.42793, 0.043686, 0.014548, 0.0072557, 0.17426, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 148.094440 pJ
sum error= 20
Actual label: 1
Output voltages: [0.052692, 0.79864, 0.29551, 0.031712, 0.14914, 0.0011049, 0.62128, 0.0035465, 0.087048, 0.034452]
Predicted label: 1
Correct prediction
Energy consumption = 168.648879 pJ
sum error= 20
Actual label: 2
Output voltages: [0.32017, 0.57902, 0.79825, 0.014127, 0.011986, 0.0013893, 0.051854, 0.30705, 0.06017, 0.020705]
Predicted label: 2
Correct prediction
Energy consumption = 145.199676 pJ
sum error= 20
Actual label: 6
Output voltages: [0.034649, 0.018397, 0.043379, 0.01792, 0.38296, 0.21902, 0.79873, 0.0011952, 0.7741, 0.017873]
Predicted label: 6
Correct prediction
Energy consumption = 149.994317 pJ
sum error= 20
Actual label: 8
Output voltages: [0.0043611, 0.27361, 0.22676, 0.04853, 0.010926, 0.010864, 0.016067, 0.034445, 0.79871, 0.32221]
Predicted label: 8
Correct prediction
Energy consumption = 144.176238 pJ
sum error= 20
Actual label: 0
Output voltages: [0.79387, 0.034844, 0.040206, 0.0070763, 0.0039003, 0.10024, 0.73339, 0.016472, 0.019852, 0.01036]
Predicted label: 0
Correct prediction
Energy consumption = 159.335716 pJ
sum error= 20
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 46 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 46 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 46 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.023379, 0.013422, 0.0062124, 0.56699, 0.016828, 0.79877, 0.025218, 0.01814, 0.76054, 0.018918]
Predicted label: 5
Correct prediction
Energy consumption = 165.666690 pJ
sum error= 20
Actual label: 6
Output voltages: [0.39593, 0.042185, 0.39461, 0.0011352, 0.34079, 0.021826, 0.79879, 0.0010943, 0.16441, 0.017733]
Predicted label: 6
Correct prediction
Energy consumption = 144.782889 pJ
sum error= 20
Actual label: 6
Output voltages: [0.033491, 0.0035878, 0.10916, 0.022387, 0.040622, 0.7649, 0.79826, 0.0010704, 0.76027, 0.050517]
Predicted label: 6
Correct prediction
Energy consumption = 140.542408 pJ
sum error= 20
Actual label: 6
Output voltages: [0.38562, 0.031303, 0.16437, 0.0041965, 0.26311, 0.14649, 0.79879, 0.0010733, 0.52817, 0.022987]
Predicted label: 6
Correct prediction
Energy consumption = 134.137656 pJ
sum error= 20
Actual label: 3
Output voltages: [0.15367, 0.030784, 0.12309, 0.79878, 0.0011024, 0.013045, 0.0017217, 0.11848, 0.79049, 0.0077966]
Predicted label: 3
Correct prediction
Energy consumption = 145.581578 pJ
sum error= 20
Actual label: 8
Output voltages: [0.0093116, 0.13043, 0.078473, 0.43856, 0.0011404, 0.022829, 0.0017988, 0.12316, 0.79876, 0.18997]
Predicted label: 8
Correct prediction
Energy consumption = 145.743071 pJ
sum error= 20
Actual label: 8
Output voltages: [0.023416, 0.041394, 0.72221, 0.030486, 0.017623, 0.0087279, 0.02747, 0.0073201, 0.7987, 0.047431]
Predicted label: 8
Correct prediction
Energy consumption = 140.414900 pJ
sum error= 20
Actual label: 2
Output voltages: [0.46766, 0.14713, 0.79877, 0.050169, 0.0039499, 0.0013104, 0.15125, 0.14488, 0.44212, 0.023046]
Predicted label: 2
Correct prediction
Energy consumption = 143.130225 pJ
sum error= 20
Actual label: 7
Output voltages: [0.41759, 0.0083173, 0.63309, 0.52285, 0.004372, 0.0011534, 0.0011058, 0.7288, 0.74634, 0.3585]
Predicted label: 8
Wrong prediction!
Energy consumption = 135.708904 pJ
sum error= 21
Actual label: 5
Output voltages: [0.086192, 0.0010678, 0.024835, 0.093943, 0.0058678, 0.74667, 0.016266, 0.001525, 0.79551, 0.22671]
Predicted label: 8
Wrong prediction!
Energy consumption = 141.413700 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 47 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 47 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 47 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.029858, 0.006735, 0.33689, 0.73903, 0.0011773, 0.087625, 0.0042597, 0.01092, 0.79879, 0.036639]
Predicted label: 8
Correct prediction
Energy consumption = 166.178652 pJ
sum error= 22
Actual label: 9
Output voltages: [0.45819, 0.0088583, 0.0050839, 0.23707, 0.032292, 0.024434, 0.0012466, 0.74573, 0.74461, 0.78523]
Predicted label: 9
Correct prediction
Energy consumption = 151.447090 pJ
sum error= 22
Actual label: 6
Output voltages: [0.3442, 0.048434, 0.35052, 0.0011925, 0.10095, 0.12939, 0.79879, 0.0018385, 0.36379, 0.015596]
Predicted label: 6
Correct prediction
Energy consumption = 151.000351 pJ
sum error= 22
Actual label: 1
Output voltages: [0.0095424, 0.79836, 0.020251, 0.2182, 0.01162, 0.012107, 0.27518, 0.013743, 0.047412, 0.21409]
Predicted label: 1
Correct prediction
Energy consumption = 162.217324 pJ
sum error= 22
Actual label: 8
Output voltages: [0.011912, 0.2676, 0.064964, 0.26515, 0.0015177, 0.0044776, 0.0018357, 0.0086699, 0.79877, 0.48355]
Predicted label: 8
Correct prediction
Energy consumption = 146.776877 pJ
sum error= 22
Actual label: 4
Output voltages: [0.015385, 0.0039544, 0.073283, 0.0021135, 0.79863, 0.053489, 0.1399, 0.15041, 0.055492, 0.28803]
Predicted label: 4
Correct prediction
Energy consumption = 156.091377 pJ
sum error= 22
Actual label: 1
Output voltages: [0.19604, 0.79847, 0.22293, 0.062651, 0.011781, 0.0010984, 0.41392, 0.002949, 0.25637, 0.22263]
Predicted label: 1
Correct prediction
Energy consumption = 162.938087 pJ
sum error= 22
Actual label: 2
Output voltages: [0.14472, 0.032975, 0.79876, 0.044181, 0.0047529, 0.0011477, 0.053524, 0.0142, 0.74003, 0.013025]
Predicted label: 2
Correct prediction
Energy consumption = 143.042175 pJ
sum error= 22
Actual label: 5
Output voltages: [0.29572, 0.0010663, 0.0039998, 0.58259, 0.065236, 0.78519, 0.57088, 0.0012603, 0.7517, 0.0048976]
Predicted label: 5
Correct prediction
Energy consumption = 150.646066 pJ
sum error= 22
Actual label: 9
Output voltages: [0.11772, 0.0021538, 0.039184, 0.31275, 0.033178, 0.031768, 0.002988, 0.022024, 0.75598, 0.79102]
Predicted label: 9
Correct prediction
Energy consumption = 148.871376 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 48 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 48 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 48 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0069571, 0.79861, 0.02135, 0.015272, 0.013833, 0.0053861, 0.60924, 0.005779, 0.50478, 0.0058881]
Predicted label: 1
Correct prediction
Energy consumption = 175.855609 pJ
sum error= 22
Actual label: 9
Output voltages: [0.40315, 0.015816, 0.012481, 0.027967, 0.19473, 0.015645, 0.0082007, 0.018203, 0.38682, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 161.617987 pJ
sum error= 22
Actual label: 7
Output voltages: [0.54335, 0.44766, 0.0086647, 0.59949, 0.0015648, 0.0047852, 0.0010738, 0.79879, 0.050217, 0.5174]
Predicted label: 7
Correct prediction
Energy consumption = 153.991365 pJ
sum error= 22
Actual label: 5
Output voltages: [0.04761, 0.0021361, 0.0010685, 0.024196, 0.057562, 0.79871, 0.15515, 0.01204, 0.65602, 0.0065791]
Predicted label: 5
Correct prediction
Energy consumption = 143.762534 pJ
sum error= 22
Actual label: 4
Output voltages: [0.017608, 0.0096876, 0.17286, 0.0080469, 0.79868, 0.0018752, 0.1127, 0.47911, 0.017002, 0.023761]
Predicted label: 4
Correct prediction
Energy consumption = 153.273333 pJ
sum error= 22
Actual label: 0
Output voltages: [0.79879, 0.29566, 0.10823, 0.044937, 0.010642, 0.0079867, 0.60065, 0.0031745, 0.19033, 0.50168]
Predicted label: 0
Correct prediction
Energy consumption = 161.188938 pJ
sum error= 22
Actual label: 8
Output voltages: [0.012417, 0.053872, 0.030668, 0.056273, 0.010234, 0.011533, 0.016572, 0.018123, 0.79874, 0.41647]
Predicted label: 8
Correct prediction
Energy consumption = 144.479644 pJ
sum error= 22
Actual label: 9
Output voltages: [0.57479, 0.0020703, 0.023151, 0.0039155, 0.17056, 0.0060658, 0.0056932, 0.20707, 0.40451, 0.79386]
Predicted label: 9
Correct prediction
Energy consumption = 145.322237 pJ
sum error= 22
Actual label: 9
Output voltages: [0.048277, 0.0050949, 0.038122, 0.011089, 0.034035, 0.0050909, 0.0015653, 0.027308, 0.77333, 0.79022]
Predicted label: 9
Correct prediction
Energy consumption = 141.812101 pJ
sum error= 22
Actual label: 1
Output voltages: [0.032205, 0.79843, 0.028532, 0.027397, 0.027405, 0.011435, 0.59916, 0.0013996, 0.38762, 0.025078]
Predicted label: 1
Correct prediction
Energy consumption = 162.031207 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 49 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 49 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 49 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79486, 0.029239, 0.2725, 0.0051363, 0.11286, 0.0010965, 0.70276, 0.017444, 0.022445, 0.022614]
Predicted label: 0
Correct prediction
Energy consumption = 163.004488 pJ
sum error= 22
Actual label: 5
Output voltages: [0.035846, 0.0011059, 0.0015829, 0.30919, 0.045638, 0.79879, 0.030433, 0.047493, 0.66748, 0.051398]
Predicted label: 5
Correct prediction
Energy consumption = 145.597692 pJ
sum error= 22
Actual label: 2
Output voltages: [0.019228, 0.038392, 0.79532, 0.48391, 0.0011776, 0.0010769, 0.20061, 0.020017, 0.7712, 0.0025736]
Predicted label: 2
Correct prediction
Energy consumption = 143.258702 pJ
sum error= 22
Actual label: 3
Output voltages: [0.30086, 0.014324, 0.11773, 0.79872, 0.025122, 0.0015108, 0.019215, 0.043864, 0.63924, 0.011108]
Predicted label: 3
Correct prediction
Energy consumption = 137.831570 pJ
sum error= 22
Actual label: 7
Output voltages: [0.086197, 0.033747, 0.034072, 0.22662, 0.0022616, 0.0032559, 0.0011236, 0.79873, 0.55734, 0.37761]
Predicted label: 7
Correct prediction
Energy consumption = 151.642755 pJ
sum error= 22
Actual label: 8
Output voltages: [0.37055, 0.037503, 0.2706, 0.051445, 0.021546, 0.0011055, 0.6679, 0.001084, 0.78108, 0.039334]
Predicted label: 8
Correct prediction
Energy consumption = 153.056711 pJ
sum error= 22
Actual label: 9
Output voltages: [0.20796, 0.0066478, 0.015341, 0.34843, 0.01921, 0.23051, 0.0020611, 0.6626, 0.080314, 0.76198]
Predicted label: 9
Correct prediction
Energy consumption = 159.022693 pJ
sum error= 22
Actual label: 4
Output voltages: [0.054056, 0.16557, 0.19714, 0.0011252, 0.79707, 0.0011102, 0.01372, 0.0054448, 0.41354, 0.48319]
Predicted label: 4
Correct prediction
Energy consumption = 152.949689 pJ
sum error= 22
Actual label: 0
Output voltages: [0.79865, 0.0082489, 0.044524, 0.043688, 0.023173, 0.001879, 0.04059, 0.057703, 0.46658, 0.050248]
Predicted label: 0
Correct prediction
Energy consumption = 158.952826 pJ
sum error= 22
Actual label: 6
Output voltages: [0.081617, 0.025002, 0.042988, 0.0026691, 0.079872, 0.30605, 0.79879, 0.014576, 0.75758, 0.0034853]
Predicted label: 6
Correct prediction
Energy consumption = 140.957818 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 50 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 50 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 50 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.35778, 0.030855, 0.03143, 0.79862, 0.019395, 0.0056301, 0.012549, 0.019952, 0.60706, 0.040744]
Predicted label: 3
Correct prediction
Energy consumption = 167.287496 pJ
sum error= 22
Actual label: 9
Output voltages: [0.42635, 0.0051247, 0.10394, 0.0228, 0.25138, 0.0066735, 0.060565, 0.0019664, 0.028176, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 152.474018 pJ
sum error= 22
Actual label: 5
Output voltages: [0.048496, 0.0014562, 0.035249, 0.60721, 0.029333, 0.79849, 0.013929, 0.016324, 0.77612, 0.027218]
Predicted label: 5
Correct prediction
Energy consumption = 145.147658 pJ
sum error= 22
Actual label: 2
Output voltages: [0.45092, 0.0056607, 0.79821, 0.24734, 0.02627, 0.0011274, 0.057488, 0.029919, 0.70523, 0.022643]
Predicted label: 2
Correct prediction
Energy consumption = 144.650074 pJ
sum error= 22
Actual label: 1
Output voltages: [0.012473, 0.79854, 0.014425, 0.094015, 0.018704, 0.0014297, 0.12882, 0.015977, 0.74848, 0.039085]
Predicted label: 1
Correct prediction
Energy consumption = 164.495852 pJ
sum error= 22
Actual label: 3
Output voltages: [0.068174, 0.02762, 0.17756, 0.79872, 0.011826, 0.0021271, 0.0034018, 0.0021109, 0.72608, 0.039812]
Predicted label: 3
Correct prediction
Energy consumption = 141.263010 pJ
sum error= 22
Actual label: 1
Output voltages: [0.02996, 0.7986, 0.0011538, 0.025818, 0.44521, 0.034289, 0.50662, 0.0037245, 0.19043, 0.090585]
Predicted label: 1
Correct prediction
Energy consumption = 159.769475 pJ
sum error= 22
Actual label: 3
Output voltages: [0.18121, 0.024166, 0.064785, 0.79879, 0.22927, 0.11658, 0.023534, 0.0068143, 0.47434, 0.014609]
Predicted label: 3
Correct prediction
Energy consumption = 147.353373 pJ
sum error= 22
Actual label: 6
Output voltages: [0.011327, 0.013732, 0.074316, 0.0121, 0.04326, 0.25313, 0.79858, 0.0018211, 0.77176, 0.038953]
Predicted label: 6
Correct prediction
Energy consumption = 147.660319 pJ
sum error= 22
Actual label: 5
Output voltages: [0.027431, 0.0010715, 0.01489, 0.34244, 0.0095994, 0.79753, 0.024922, 0.042483, 0.77561, 0.17625]
Predicted label: 5
Correct prediction
Energy consumption = 141.120690 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 51 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 51 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 51 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.22522, 0.0016276, 0.47326, 0.089664, 0.0025799, 0.0010729, 0.0010834, 0.77692, 0.45344, 0.50656]
Predicted label: 7
Correct prediction
Energy consumption = 164.951621 pJ
sum error= 22
Actual label: 4
Output voltages: [0.0010682, 0.070284, 0.017779, 0.0037778, 0.7888, 0.0087324, 0.023362, 0.0098794, 0.54936, 0.3064]
Predicted label: 4
Correct prediction
Energy consumption = 154.903191 pJ
sum error= 22
Actual label: 2
Output voltages: [0.25396, 0.19482, 0.79876, 0.12621, 0.026391, 0.0013106, 0.15022, 0.034515, 0.4268, 0.049209]
Predicted label: 2
Correct prediction
Energy consumption = 151.054837 pJ
sum error= 22
Actual label: 2
Output voltages: [0.44196, 0.051474, 0.79875, 0.24926, 0.016996, 0.0011345, 0.37245, 0.016194, 0.12616, 0.031032]
Predicted label: 2
Correct prediction
Energy consumption = 142.885212 pJ
sum error= 22
Actual label: 6
Output voltages: [0.42039, 0.043625, 0.20081, 0.0075169, 0.049779, 0.028505, 0.79878, 0.0010904, 0.63023, 0.018738]
Predicted label: 6
Correct prediction
Energy consumption = 155.763462 pJ
sum error= 22
Actual label: 3
Output voltages: [0.029676, 0.01887, 0.047277, 0.7987, 0.028282, 0.015746, 0.0022325, 0.11899, 0.50514, 0.27257]
Predicted label: 3
Correct prediction
Energy consumption = 151.151408 pJ
sum error= 22
Actual label: 2
Output voltages: [0.33459, 0.0053238, 0.79879, 0.17133, 0.17293, 0.0026467, 0.034512, 0.039834, 0.43157, 0.031287]
Predicted label: 2
Correct prediction
Energy consumption = 141.922489 pJ
sum error= 22
Actual label: 6
Output voltages: [0.079467, 0.049671, 0.16696, 0.0079172, 0.18549, 0.32041, 0.79872, 0.0027975, 0.49424, 0.0058316]
Predicted label: 6
Correct prediction
Energy consumption = 152.329028 pJ
sum error= 22
Actual label: 5
Output voltages: [0.013223, 0.0010696, 0.0013761, 0.232, 0.048022, 0.78841, 0.16244, 0.013734, 0.78483, 0.021755]
Predicted label: 5
Correct prediction
Energy consumption = 145.994732 pJ
sum error= 22
Actual label: 4
Output voltages: [0.028941, 0.014856, 0.23103, 0.028323, 0.79877, 0.0053176, 0.020672, 0.038352, 0.038313, 0.37835]
Predicted label: 4
Correct prediction
Energy consumption = 159.677768 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 52 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 52 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 52 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0030605, 0.25785, 0.086075, 0.092744, 0.0023011, 0.029888, 0.017019, 0.01396, 0.79877, 0.28082]
Predicted label: 8
Correct prediction
Energy consumption = 173.797217 pJ
sum error= 22
Actual label: 9
Output voltages: [0.1533, 0.072802, 0.056426, 0.017241, 0.56382, 0.022808, 0.003324, 0.022527, 0.1526, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 160.220733 pJ
sum error= 22
Actual label: 7
Output voltages: [0.091727, 0.0023462, 0.029755, 0.63728, 0.0074689, 0.002045, 0.0010716, 0.79868, 0.21837, 0.73243]
Predicted label: 7
Correct prediction
Energy consumption = 147.512182 pJ
sum error= 22
Actual label: 1
Output voltages: [0.0016035, 0.79874, 0.011335, 0.0039574, 0.064333, 0.0019897, 0.14419, 0.0074093, 0.42431, 0.029255]
Predicted label: 1
Correct prediction
Energy consumption = 140.228507 pJ
sum error= 22
Actual label: 3
Output voltages: [0.56743, 0.021294, 0.12716, 0.79867, 0.013397, 0.013788, 0.023537, 0.03388, 0.67722, 0.0028527]
Predicted label: 3
Correct prediction
Energy consumption = 144.094100 pJ
sum error= 22
Actual label: 0
Output voltages: [0.79878, 0.032839, 0.018524, 0.002203, 0.019312, 0.017046, 0.53312, 0.010423, 0.12466, 0.031126]
Predicted label: 0
Correct prediction
Energy consumption = 158.447056 pJ
sum error= 22
Actual label: 3
Output voltages: [0.035506, 0.0033977, 0.0078351, 0.79759, 0.020296, 0.27349, 0.030687, 0.015891, 0.64228, 0.029034]
Predicted label: 3
Correct prediction
Energy consumption = 154.911005 pJ
sum error= 22
Actual label: 8
Output voltages: [0.74546, 0.016307, 0.47695, 0.22766, 0.012438, 0.054214, 0.0089086, 0.0028529, 0.79879, 0.46383]
Predicted label: 8
Correct prediction
Energy consumption = 146.107212 pJ
sum error= 22
Actual label: 3
Output voltages: [0.29391, 0.0022063, 0.2062, 0.79877, 0.0011854, 0.0017952, 0.018723, 0.030749, 0.74683, 0.0080557]
Predicted label: 3
Correct prediction
Energy consumption = 138.737608 pJ
sum error= 22
Actual label: 1
Output voltages: [0.0058765, 0.79856, 0.10498, 0.26815, 0.012914, 0.0022608, 0.77677, 0.0087029, 0.031782, 0.119]
Predicted label: 1
Correct prediction
Energy consumption = 153.602284 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 53 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 53 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 53 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.15578, 0.068197, 0.018324, 0.031204, 0.7762, 0.0011509, 0.0024034, 0.0010736, 0.099538, 0.79695]
Predicted label: 9
Correct prediction
Energy consumption = 170.998940 pJ
sum error= 22
Actual label: 3
Output voltages: [0.20175, 0.0041472, 0.23928, 0.79875, 0.0012611, 0.0015846, 0.24254, 0.039302, 0.51717, 0.0050042]
Predicted label: 3
Correct prediction
Energy consumption = 153.230718 pJ
sum error= 22
Actual label: 4
Output voltages: [0.085073, 0.058655, 0.04114, 0.0097775, 0.79864, 0.0013554, 0.44794, 0.020085, 0.012789, 0.023633]
Predicted label: 4
Correct prediction
Energy consumption = 166.195447 pJ
sum error= 22
Actual label: 4
Output voltages: [0.0117, 0.025494, 0.49469, 0.0010722, 0.79868, 0.0010738, 0.16117, 0.0038294, 0.017873, 0.34519]
Predicted label: 4
Correct prediction
Energy consumption = 149.353239 pJ
sum error= 22
Actual label: 6
Output voltages: [0.039694, 0.058067, 0.13263, 0.0037323, 0.12046, 0.11808, 0.79878, 0.0086505, 0.71281, 0.0065955]
Predicted label: 6
Correct prediction
Energy consumption = 151.145781 pJ
sum error= 22
Actual label: 4
Output voltages: [0.014824, 0.0073427, 0.31433, 0.0034163, 0.79868, 0.0063465, 0.31404, 0.29905, 0.025572, 0.010252]
Predicted label: 4
Correct prediction
Energy consumption = 150.735303 pJ
sum error= 22
Actual label: 2
Output voltages: [0.25914, 0.16172, 0.79879, 0.035893, 0.039482, 0.0012628, 0.25525, 0.53389, 0.37596, 0.027121]
Predicted label: 2
Correct prediction
Energy consumption = 153.762562 pJ
sum error= 22
Actual label: 1
Output voltages: [0.01159, 0.79869, 0.070043, 0.0085523, 0.020771, 0.0011259, 0.51346, 0.0011377, 0.48555, 0.019912]
Predicted label: 1
Correct prediction
Energy consumption = 157.852388 pJ
sum error= 22
Actual label: 8
Output voltages: [0.077869, 0.04145, 0.4698, 0.073843, 0.032446, 0.034366, 0.075027, 0.0013026, 0.79879, 0.049395]
Predicted label: 8
Correct prediction
Energy consumption = 151.756671 pJ
sum error= 22
Actual label: 2
Output voltages: [0.74244, 0.012554, 0.79879, 0.048376, 0.056352, 0.0010895, 0.021209, 0.036596, 0.63175, 0.0056433]
Predicted label: 2
Correct prediction
Energy consumption = 139.198833 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 54 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 54 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 54 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.043458, 0.0016379, 0.0044962, 0.47886, 0.020704, 0.7986, 0.030635, 0.0453, 0.77394, 0.081911]
Predicted label: 5
Correct prediction
Energy consumption = 166.988439 pJ
sum error= 22
Actual label: 4
Output voltages: [0.0024028, 0.016647, 0.18374, 0.027566, 0.79864, 0.0014283, 0.086599, 0.093575, 0.021533, 0.13587]
Predicted label: 4
Correct prediction
Energy consumption = 155.685644 pJ
sum error= 22
Actual label: 8
Output voltages: [0.0051605, 0.032756, 0.049683, 0.25513, 0.0038452, 0.016717, 0.01704, 0.022819, 0.79878, 0.35276]
Predicted label: 8
Correct prediction
Energy consumption = 149.743886 pJ
sum error= 22
Actual label: 8
Output voltages: [0.005382, 0.012688, 0.044044, 0.52357, 0.0053073, 0.025328, 0.0032815, 0.059119, 0.79813, 0.42848]
Predicted label: 8
Correct prediction
Energy consumption = 147.770050 pJ
sum error= 22
Actual label: 4
Output voltages: [0.0056325, 0.073543, 0.073232, 0.015372, 0.79865, 0.013409, 0.21591, 0.16856, 0.0401, 0.036002]
Predicted label: 4
Correct prediction
Energy consumption = 159.769008 pJ
sum error= 22
Actual label: 0
Output voltages: [0.79876, 0.026695, 0.23194, 0.012231, 0.010167, 0.0032681, 0.34334, 0.015015, 0.27073, 0.22244]
Predicted label: 0
Correct prediction
Energy consumption = 152.829218 pJ
sum error= 22
Actual label: 0
Output voltages: [0.79869, 0.026941, 0.024889, 0.0025008, 0.013132, 0.0056454, 0.73393, 0.0096532, 0.08552, 0.059203]
Predicted label: 0
Correct prediction
Energy consumption = 139.527430 pJ
sum error= 22
Actual label: 2
Output voltages: [0.033251, 0.11706, 0.79877, 0.36371, 0.0015376, 0.0010733, 0.37575, 0.0083065, 0.76965, 0.013733]
Predicted label: 2
Correct prediction
Energy consumption = 140.245139 pJ
sum error= 22
Actual label: 3
Output voltages: [0.52209, 0.012362, 0.42536, 0.79865, 0.014549, 0.040248, 0.0056412, 0.039958, 0.60801, 0.011795]
Predicted label: 3
Correct prediction
Energy consumption = 145.014570 pJ
sum error= 22
Actual label: 2
Output voltages: [0.56752, 0.024865, 0.79869, 0.10412, 0.0045063, 0.001071, 0.40849, 0.037574, 0.29794, 0.009341]
Predicted label: 2
Correct prediction
Energy consumption = 140.554850 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 55 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 55 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 55 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.24761, 0.011363, 0.028068, 0.76636, 0.27617, 0.0011405, 0.0011698, 0.69783, 0.46348, 0.24651]
Predicted label: 3
Wrong prediction!
Energy consumption = 166.502875 pJ
sum error= 23
Actual label: 7
Output voltages: [0.049206, 0.039986, 0.05432, 0.47081, 0.0012561, 0.0012334, 0.001132, 0.79559, 0.19198, 0.21736]
Predicted label: 7
Correct prediction
Energy consumption = 142.689312 pJ
sum error= 23
Actual label: 0
Output voltages: [0.79775, 0.0028427, 0.0011631, 0.014056, 0.037587, 0.17044, 0.68459, 0.049317, 0.091834, 0.31721]
Predicted label: 0
Correct prediction
Energy consumption = 159.410047 pJ
sum error= 23
Actual label: 8
Output voltages: [0.014333, 0.018238, 0.0051213, 0.1527, 0.024596, 0.11514, 0.17823, 0.024157, 0.79879, 0.011153]
Predicted label: 8
Correct prediction
Energy consumption = 145.825124 pJ
sum error= 23
Actual label: 7
Output voltages: [0.0036979, 0.036358, 0.6672, 0.021869, 0.048721, 0.0010987, 0.0010726, 0.79864, 0.69853, 0.0083143]
Predicted label: 7
Correct prediction
Energy consumption = 151.548847 pJ
sum error= 23
Actual label: 4
Output voltages: [0.0078906, 0.030137, 0.095632, 0.0011283, 0.79878, 0.0013489, 0.10241, 0.029784, 0.03482, 0.047286]
Predicted label: 4
Correct prediction
Energy consumption = 153.736027 pJ
sum error= 23
Actual label: 4
Output voltages: [0.0052339, 0.034108, 0.063435, 0.0058491, 0.79859, 0.0055123, 0.0883, 0.026622, 0.035521, 0.14042]
Predicted label: 4
Correct prediction
Energy consumption = 141.802834 pJ
sum error= 23
Actual label: 7
Output voltages: [0.036267, 0.586, 0.2858, 0.030526, 0.010404, 0.0011473, 0.0010807, 0.79876, 0.050068, 0.34028]
Predicted label: 7
Correct prediction
Energy consumption = 158.485647 pJ
sum error= 23
Actual label: 9
Output voltages: [0.23091, 0.02971, 0.013078, 0.045624, 0.069633, 0.011016, 0.014088, 0.026091, 0.25116, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 155.765410 pJ
sum error= 23
Actual label: 6
Output voltages: [0.29956, 0.009008, 0.18183, 0.0010715, 0.30881, 0.019946, 0.79804, 0.0011099, 0.25616, 0.0037018]
Predicted label: 6
Correct prediction
Energy consumption = 139.000691 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 56 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 56 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 56 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39896, 0.015008, 0.02844, 0.051042, 0.38301, 0.030106, 0.0084232, 0.0021851, 0.33361, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 167.016569 pJ
sum error= 23
Actual label: 0
Output voltages: [0.7874, 0.032648, 0.050078, 0.013585, 0.001067, 0.015131, 0.72443, 0.026213, 0.13596, 0.03191]
Predicted label: 0
Correct prediction
Energy consumption = 148.185428 pJ
sum error= 23
Actual label: 9
Output voltages: [0.24045, 0.049433, 0.026784, 0.45302, 0.22931, 0.025377, 0.17711, 0.031958, 0.044656, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 153.074565 pJ
sum error= 23
Actual label: 8
Output voltages: [0.022101, 0.018274, 0.095622, 0.032158, 0.025489, 0.018476, 0.04426, 0.0090872, 0.79876, 0.28037]
Predicted label: 8
Correct prediction
Energy consumption = 149.311053 pJ
sum error= 23
Actual label: 0
Output voltages: [0.79866, 0.19513, 0.027185, 0.0069011, 0.014297, 0.0025966, 0.61711, 0.030801, 0.052108, 0.25189]
Predicted label: 0
Correct prediction
Energy consumption = 157.427501 pJ
sum error= 23
Actual label: 4
Output voltages: [0.0011257, 0.0085057, 0.024613, 0.0042822, 0.79865, 0.015489, 0.050756, 0.061419, 0.26298, 0.024018]
Predicted label: 4
Correct prediction
Energy consumption = 150.437871 pJ
sum error= 23
Actual label: 6
Output voltages: [0.050137, 0.030023, 0.032235, 0.018403, 0.3171, 0.11876, 0.79875, 0.0049856, 0.72626, 0.0012149]
Predicted label: 6
Correct prediction
Energy consumption = 146.281373 pJ
sum error= 23
Actual label: 0
Output voltages: [0.79875, 0.036877, 0.20672, 0.019852, 0.00332, 0.028291, 0.30159, 0.019479, 0.27474, 0.13079]
Predicted label: 0
Correct prediction
Energy consumption = 154.486024 pJ
sum error= 23
Actual label: 6
Output voltages: [0.15246, 0.3576, 0.069641, 0.037002, 0.19127, 0.19202, 0.79879, 0.0016306, 0.74982, 0.0043404]
Predicted label: 6
Correct prediction
Energy consumption = 148.764053 pJ
sum error= 23
Actual label: 3
Output voltages: [0.0047214, 0.0022564, 0.027188, 0.79879, 0.045736, 0.059184, 0.045267, 0.075799, 0.66454, 0.0054668]
Predicted label: 3
Correct prediction
Energy consumption = 143.214349 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 57 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 57 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 57 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.2439, 0.0098036, 0.014053, 0.66849, 0.026303, 0.79877, 0.049402, 0.03331, 0.77399, 0.46768]
Predicted label: 5
Correct prediction
Energy consumption = 164.476323 pJ
sum error= 23
Actual label: 4
Output voltages: [0.22145, 0.0069364, 0.0090603, 0.010024, 0.79879, 0.0018638, 0.016332, 0.018858, 0.0081758, 0.70382]
Predicted label: 4
Correct prediction
Energy consumption = 153.773373 pJ
sum error= 23
Actual label: 8
Output voltages: [0.13349, 0.0011609, 0.15738, 0.23611, 0.015854, 0.04746, 0.0011387, 0.0067424, 0.79876, 0.10959]
Predicted label: 8
Correct prediction
Energy consumption = 158.956497 pJ
sum error= 23
Actual label: 3
Output voltages: [0.49468, 0.011027, 0.018968, 0.79869, 0.013939, 0.021111, 0.057045, 0.0086403, 0.4991, 0.03185]
Predicted label: 3
Correct prediction
Energy consumption = 147.284995 pJ
sum error= 23
Actual label: 3
Output voltages: [0.61551, 0.046173, 0.069055, 0.79875, 0.0010746, 0.29091, 0.0012813, 0.21877, 0.67244, 0.0067785]
Predicted label: 3
Correct prediction
Energy consumption = 142.602876 pJ
sum error= 23
Actual label: 9
Output voltages: [0.29833, 0.0070718, 0.0087134, 0.029066, 0.10087, 0.0077153, 0.0011204, 0.02753, 0.56706, 0.79336]
Predicted label: 9
Correct prediction
Energy consumption = 150.043495 pJ
sum error= 23
Actual label: 3
Output voltages: [0.27622, 0.0097707, 0.012598, 0.79866, 0.0054445, 0.055682, 0.014974, 0.031986, 0.68844, 0.038235]
Predicted label: 3
Correct prediction
Energy consumption = 140.367949 pJ
sum error= 23
Actual label: 3
Output voltages: [0.035668, 0.11464, 0.0078963, 0.79868, 0.010023, 0.0010866, 0.0036753, 0.1029, 0.44738, 0.053796]
Predicted label: 3
Correct prediction
Energy consumption = 130.734891 pJ
sum error= 23
Actual label: 3
Output voltages: [0.18205, 0.024527, 0.12668, 0.79806, 0.0021421, 0.0095852, 0.0018058, 0.084686, 0.79181, 0.017765]
Predicted label: 3
Correct prediction
Energy consumption = 130.381884 pJ
sum error= 23
Actual label: 7
Output voltages: [0.58012, 0.025092, 0.010862, 0.36066, 0.074953, 0.014069, 0.0011089, 0.79862, 0.21082, 0.29965]
Predicted label: 7
Correct prediction
Energy consumption = 149.959990 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 58 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 58 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 58 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0038246, 0.27993, 0.053217, 0.21253, 0.0045636, 0.0052233, 0.0046429, 0.042341, 0.79875, 0.30543]
Predicted label: 8
Correct prediction
Energy consumption = 165.153660 pJ
sum error= 23
Actual label: 0
Output voltages: [0.79871, 0.012677, 0.038884, 0.0019078, 0.0074876, 0.01292, 0.59642, 0.0052617, 0.087391, 0.0368]
Predicted label: 0
Correct prediction
Energy consumption = 154.279999 pJ
sum error= 23
Actual label: 8
Output voltages: [0.012908, 0.045239, 0.76552, 0.68292, 0.058173, 0.0012106, 0.069608, 0.0010989, 0.69138, 0.049314]
Predicted label: 2
Wrong prediction!
Energy consumption = 149.930110 pJ
sum error= 24
Actual label: 2
Output voltages: [0.10252, 0.0050066, 0.65434, 0.42643, 0.0013578, 0.001132, 0.0011984, 0.7415, 0.7741, 0.0061605]
Predicted label: 8
Wrong prediction!
Energy consumption = 138.853047 pJ
sum error= 25
Actual label: 1
Output voltages: [0.011489, 0.79869, 0.0042787, 0.46328, 0.095329, 0.019331, 0.037465, 0.30502, 0.026317, 0.046143]
Predicted label: 1
Correct prediction
Energy consumption = 163.815603 pJ
sum error= 25
Actual label: 7
Output voltages: [0.1648, 0.26892, 0.019934, 0.34166, 0.0064039, 0.0029754, 0.0010937, 0.79876, 0.16082, 0.38339]
Predicted label: 7
Correct prediction
Energy consumption = 157.103211 pJ
sum error= 25
Actual label: 0
Output voltages: [0.79875, 0.058743, 0.032904, 0.034206, 0.010896, 0.019125, 0.33069, 0.015321, 0.043596, 0.036468]
Predicted label: 0
Correct prediction
Energy consumption = 152.179105 pJ
sum error= 25
Actual label: 6
Output voltages: [0.16343, 0.0436, 0.055166, 0.0050447, 0.33623, 0.16297, 0.79873, 0.0020327, 0.59636, 0.013782]
Predicted label: 6
Correct prediction
Energy consumption = 142.343312 pJ
sum error= 25
Actual label: 5
Output voltages: [0.098456, 0.0013102, 0.0018539, 0.62472, 0.026281, 0.79879, 0.14278, 0.063953, 0.7405, 0.072022]
Predicted label: 5
Correct prediction
Energy consumption = 142.396829 pJ
sum error= 25
Actual label: 4
Output voltages: [0.0034918, 0.049615, 0.10779, 0.0048456, 0.79873, 0.0015504, 0.028714, 0.023687, 0.37559, 0.18561]
Predicted label: 4
Correct prediction
Energy consumption = 157.251926 pJ
sum error= 25
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 59 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 59 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 59 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.50691, 0.050741, 0.076608, 0.79868, 0.023817, 0.0027208, 0.0052507, 0.0167, 0.41821, 0.0338]
Predicted label: 3
Correct prediction
Energy consumption = 165.464011 pJ
sum error= 25
Actual label: 8
Output voltages: [0.42356, 0.36265, 0.36051, 0.76623, 0.001076, 0.0010665, 0.36989, 0.026254, 0.75101, 0.0085267]
Predicted label: 3
Wrong prediction!
Energy consumption = 153.300045 pJ
sum error= 26
Actual label: 0
Output voltages: [0.79878, 0.13501, 0.024696, 0.056136, 0.0094591, 0.026436, 0.57979, 0.0095667, 0.08322, 0.073904]
Predicted label: 0
Correct prediction
Energy consumption = 150.536689 pJ
sum error= 26
Actual label: 9
Output voltages: [0.17792, 0.011883, 0.0057292, 0.01837, 0.037703, 0.0011616, 0.001072, 0.010245, 0.67124, 0.79638]
Predicted label: 9
Correct prediction
Energy consumption = 149.685551 pJ
sum error= 26
Actual label: 6
Output voltages: [0.11538, 0.12592, 0.13813, 0.017983, 0.19641, 0.06326, 0.79878, 0.0055185, 0.68962, 0.012598]
Predicted label: 6
Correct prediction
Energy consumption = 157.039260 pJ
sum error= 26
Actual label: 3
Output voltages: [0.26287, 0.0086134, 0.24644, 0.79878, 0.18164, 0.040999, 0.029044, 0.013733, 0.68441, 0.0047224]
Predicted label: 3
Correct prediction
Energy consumption = 146.309462 pJ
sum error= 26
Actual label: 8
Output voltages: [0.031977, 0.002387, 0.049007, 0.047617, 0.026193, 0.18749, 0.018084, 0.015176, 0.79862, 0.50139]
Predicted label: 8
Correct prediction
Energy consumption = 139.768190 pJ
sum error= 26
Actual label: 0
Output voltages: [0.79712, 0.0012304, 0.41827, 0.0014094, 0.1946, 0.022668, 0.65264, 0.14727, 0.0019167, 0.015089]
Predicted label: 0
Correct prediction
Energy consumption = 140.866748 pJ
sum error= 26
Actual label: 9
Output voltages: [0.28638, 0.0086756, 0.045467, 0.0030955, 0.16424, 0.0051497, 0.0010808, 0.042602, 0.58493, 0.79835]
Predicted label: 9
Correct prediction
Energy consumption = 151.958558 pJ
sum error= 26
Actual label: 9
Output voltages: [0.74647, 0.0069662, 0.026624, 0.10515, 0.13179, 0.02826, 0.0015488, 0.12108, 0.044184, 0.79847]
Predicted label: 9
Correct prediction
Energy consumption = 145.044570 pJ
sum error= 26
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 60 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 60 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 60 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.050644, 0.049986, 0.34688, 0.0037636, 0.41763, 0.37102, 0.79875, 0.0010911, 0.38723, 0.035872]
Predicted label: 6
Correct prediction
Energy consumption = 163.499018 pJ
sum error= 26
Actual label: 8
Output voltages: [0.20724, 0.060874, 0.061765, 0.14452, 0.031542, 0.0010659, 0.012565, 0.029476, 0.79803, 0.25385]
Predicted label: 8
Correct prediction
Energy consumption = 154.339092 pJ
sum error= 26
Actual label: 6
Output voltages: [0.39411, 0.031025, 0.24012, 0.0020582, 0.25401, 0.09751, 0.79877, 0.0012179, 0.58866, 0.02228]
Predicted label: 6
Correct prediction
Energy consumption = 138.762260 pJ
sum error= 26
Actual label: 8
Output voltages: [0.015187, 0.015768, 0.037985, 0.42684, 0.014257, 0.33405, 0.04912, 0.0015991, 0.79879, 0.20131]
Predicted label: 8
Correct prediction
Energy consumption = 147.089324 pJ
sum error= 26
Actual label: 5
Output voltages: [0.04073, 0.0029236, 0.014871, 0.31921, 0.011079, 0.79868, 0.17595, 0.028737, 0.74393, 0.034967]
Predicted label: 5
Correct prediction
Energy consumption = 143.568389 pJ
sum error= 26
Actual label: 7
Output voltages: [0.17188, 0.025442, 0.086971, 0.7311, 0.018952, 0.0010892, 0.0011535, 0.79811, 0.41829, 0.21007]
Predicted label: 7
Correct prediction
Energy consumption = 146.227852 pJ
sum error= 26
Actual label: 8
Output voltages: [0.030111, 0.038803, 0.13889, 0.69123, 0.0015397, 0.012903, 0.058584, 0.0025651, 0.79751, 0.38568]
Predicted label: 8
Correct prediction
Energy consumption = 147.658522 pJ
sum error= 26
Actual label: 6
Output voltages: [0.024861, 0.20992, 0.3339, 0.012139, 0.04011, 0.28361, 0.79876, 0.0032984, 0.58064, 0.017192]
Predicted label: 6
Correct prediction
Energy consumption = 145.901510 pJ
sum error= 26
Actual label: 0
Output voltages: [0.79876, 0.21168, 0.087322, 0.029064, 0.011784, 0.017013, 0.08453, 0.02585, 0.04813, 0.30932]
Predicted label: 0
Correct prediction
Energy consumption = 157.152798 pJ
sum error= 26
Actual label: 2
Output voltages: [0.36571, 0.22046, 0.79879, 0.038408, 0.022908, 0.0012927, 0.4576, 0.021351, 0.47258, 0.046786]
Predicted label: 2
Correct prediction
Energy consumption = 147.008801 pJ
sum error= 26
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 61 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 61 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 61 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.022972, 0.0033577, 0.13984, 0.0011323, 0.79873, 0.0011228, 0.17609, 0.0081943, 0.54661, 0.0023522]
Predicted label: 4
Correct prediction
Energy consumption = 165.854246 pJ
sum error= 26
Actual label: 0
Output voltages: [0.79876, 0.022784, 0.16498, 0.019476, 0.020716, 0.0024581, 0.62944, 0.070996, 0.10746, 0.037102]
Predicted label: 0
Correct prediction
Energy consumption = 162.985025 pJ
sum error= 26
Actual label: 2
Output voltages: [0.4427, 0.041196, 0.79868, 0.095399, 0.03226, 0.0010876, 0.20196, 0.21146, 0.43161, 0.020014]
Predicted label: 2
Correct prediction
Energy consumption = 141.523154 pJ
sum error= 26
Actual label: 2
Output voltages: [0.29443, 0.15508, 0.78324, 0.75886, 0.0010812, 0.0011341, 0.031587, 0.0088217, 0.55838, 0.17023]
Predicted label: 2
Correct prediction
Energy consumption = 150.668272 pJ
sum error= 26
Actual label: 3
Output voltages: [0.30593, 0.17614, 0.045815, 0.79865, 0.017173, 0.0011817, 0.0028267, 0.011636, 0.28281, 0.27149]
Predicted label: 3
Correct prediction
Energy consumption = 144.514851 pJ
sum error= 26
Actual label: 1
Output voltages: [0.053671, 0.79879, 0.33131, 0.028644, 0.26522, 0.0010687, 0.53219, 0.0014982, 0.22778, 0.0062199]
Predicted label: 1
Correct prediction
Energy consumption = 150.997770 pJ
sum error= 26
Actual label: 9
Output voltages: [0.20781, 0.0078765, 0.016511, 0.17461, 0.37904, 0.19417, 0.0027649, 0.093002, 0.042731, 0.79811]
Predicted label: 9
Correct prediction
Energy consumption = 160.911503 pJ
sum error= 26
Actual label: 7
Output voltages: [0.08878, 0.0019442, 0.48014, 0.42473, 0.036867, 0.0011806, 0.0011101, 0.79775, 0.73823, 0.01499]
Predicted label: 7
Correct prediction
Energy consumption = 143.867157 pJ
sum error= 26
Actual label: 5
Output voltages: [0.10182, 0.0013135, 0.0020799, 0.71193, 0.016218, 0.79876, 0.054344, 0.044644, 0.74693, 0.036079]
Predicted label: 5
Correct prediction
Energy consumption = 145.443618 pJ
sum error= 26
Actual label: 1
Output voltages: [0.004609, 0.42424, 0.024456, 0.022391, 0.001616, 0.0038775, 0.025284, 0.048368, 0.79877, 0.29582]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.769316 pJ
sum error= 27
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 62 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 62 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 62 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7987, 0.064145, 0.11273, 0.014949, 0.017818, 0.0020459, 0.411, 0.025664, 0.21089, 0.032593]
Predicted label: 0
Correct prediction
Energy consumption = 177.621384 pJ
sum error= 27
Actual label: 8
Output voltages: [0.013405, 0.13461, 0.21058, 0.16636, 0.0089012, 0.013821, 0.029913, 0.0030347, 0.79879, 0.3968]
Predicted label: 8
Correct prediction
Energy consumption = 157.866040 pJ
sum error= 27
Actual label: 4
Output voltages: [0.026574, 0.025052, 0.044185, 0.012656, 0.79862, 0.004038, 0.18852, 0.033225, 0.0427, 0.067029]
Predicted label: 4
Correct prediction
Energy consumption = 158.883409 pJ
sum error= 27
Actual label: 6
Output voltages: [0.040926, 0.011493, 0.34759, 0.0015805, 0.30983, 0.066394, 0.79879, 0.0017842, 0.45426, 0.0061672]
Predicted label: 6
Correct prediction
Energy consumption = 146.304779 pJ
sum error= 27
Actual label: 2
Output voltages: [0.010123, 0.30801, 0.79864, 0.0094082, 0.0037247, 0.001219, 0.17945, 0.017408, 0.73778, 0.15532]
Predicted label: 2
Correct prediction
Energy consumption = 148.751957 pJ
sum error= 27
Actual label: 6
Output voltages: [0.030539, 0.055795, 0.46443, 0.0011736, 0.78422, 0.02844, 0.79755, 0.00222, 0.048485, 0.015813]
Predicted label: 6
Correct prediction
Energy consumption = 145.757396 pJ
sum error= 27
Actual label: 7
Output voltages: [0.063439, 0.22596, 0.57986, 0.1054, 0.016614, 0.0010745, 0.0010736, 0.79871, 0.26561, 0.21785]
Predicted label: 7
Correct prediction
Energy consumption = 155.901586 pJ
sum error= 27
Actual label: 9
Output voltages: [0.14802, 0.0092812, 0.048388, 0.042043, 0.046625, 0.040768, 0.031867, 0.053057, 0.40905, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 149.926210 pJ
sum error= 27
Actual label: 3
Output voltages: [0.023902, 0.030585, 0.28781, 0.79878, 0.011646, 0.0010661, 0.0022421, 0.025156, 0.34354, 0.41213]
Predicted label: 3
Correct prediction
Energy consumption = 143.294885 pJ
sum error= 27
Actual label: 2
Output voltages: [0.64219, 0.0036363, 0.79838, 0.16175, 0.004507, 0.0010664, 0.056366, 0.065501, 0.45713, 0.0029517]
Predicted label: 2
Correct prediction
Energy consumption = 138.802752 pJ
sum error= 27
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 63 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 63 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 63 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.11085, 0.040226, 0.031585, 0.30523, 0.034247, 0.061198, 0.031935, 0.065842, 0.3369, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 171.393259 pJ
sum error= 27
Actual label: 8
Output voltages: [0.11591, 0.017349, 0.25247, 0.012143, 0.03055, 0.01846, 0.032626, 0.030869, 0.79878, 0.28147]
Predicted label: 8
Correct prediction
Energy consumption = 150.966213 pJ
sum error= 27
Actual label: 2
Output voltages: [0.42965, 0.012659, 0.79876, 0.40703, 0.0022128, 0.0010677, 0.030852, 0.2857, 0.59858, 0.0070715]
Predicted label: 2
Correct prediction
Energy consumption = 147.630385 pJ
sum error= 27
Actual label: 2
Output voltages: [0.46774, 0.11449, 0.79866, 0.023524, 0.02339, 0.0012184, 0.31176, 0.033336, 0.31449, 0.027708]
Predicted label: 2
Correct prediction
Energy consumption = 136.576817 pJ
sum error= 27
Actual label: 9
Output voltages: [0.35871, 0.0090671, 0.023941, 0.018261, 0.17559, 0.099899, 0.0051829, 0.18313, 0.21168, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.702151 pJ
sum error= 27
Actual label: 2
Output voltages: [0.2858, 0.056385, 0.79879, 0.036383, 0.013098, 0.0012663, 0.42798, 0.023307, 0.48063, 0.062829]
Predicted label: 2
Correct prediction
Energy consumption = 148.762249 pJ
sum error= 27
Actual label: 7
Output voltages: [0.23081, 0.011211, 0.0054874, 0.024065, 0.02431, 0.0052317, 0.0010682, 0.7987, 0.71888, 0.41798]
Predicted label: 7
Correct prediction
Energy consumption = 150.833259 pJ
sum error= 27
Actual label: 3
Output voltages: [0.44659, 0.017174, 0.40381, 0.79879, 0.01369, 0.0010853, 0.010342, 0.026668, 0.72168, 0.0037975]
Predicted label: 3
Correct prediction
Energy consumption = 143.194639 pJ
sum error= 27
Actual label: 5
Output voltages: [0.19168, 0.0029037, 0.0010783, 0.48232, 0.026413, 0.79876, 0.10345, 0.068171, 0.52564, 0.0050358]
Predicted label: 5
Correct prediction
Energy consumption = 156.569092 pJ
sum error= 27
Actual label: 9
Output voltages: [0.32444, 0.011394, 0.030238, 0.042057, 0.4971, 0.0043314, 0.0046799, 0.0056584, 0.48057, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 148.941463 pJ
sum error= 27
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 64 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 64 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 64 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0050084, 0.79863, 0.030488, 0.24634, 0.021353, 0.0019961, 0.0055079, 0.07226, 0.14744, 0.15885]
Predicted label: 1
Correct prediction
Energy consumption = 184.442918 pJ
sum error= 27
Actual label: 8
Output voltages: [0.07761, 0.0098314, 0.039977, 0.74699, 0.0034749, 0.017364, 0.31258, 0.0010737, 0.79751, 0.08805]
Predicted label: 8
Correct prediction
Energy consumption = 151.730102 pJ
sum error= 27
Actual label: 0
Output voltages: [0.79875, 0.0017921, 0.0075794, 0.026911, 0.0070947, 0.20759, 0.031973, 0.19566, 0.012032, 0.15903]
Predicted label: 0
Correct prediction
Energy consumption = 137.761181 pJ
sum error= 27
Actual label: 2
Output voltages: [0.16551, 0.15489, 0.79878, 0.10014, 0.017843, 0.0013359, 0.082439, 0.022045, 0.31715, 0.039425]
Predicted label: 2
Correct prediction
Energy consumption = 148.880715 pJ
sum error= 27
Actual label: 0
Output voltages: [0.79879, 0.092196, 0.096003, 0.012584, 0.028045, 0.0015035, 0.41254, 0.016392, 0.059978, 0.34188]
Predicted label: 0
Correct prediction
Energy consumption = 155.512048 pJ
sum error= 27
Actual label: 5
Output voltages: [0.031258, 0.0010934, 0.024228, 0.28441, 0.056666, 0.79058, 0.59492, 0.0021904, 0.75116, 0.058206]
Predicted label: 5
Correct prediction
Energy consumption = 153.691362 pJ
sum error= 27
Actual label: 2
Output voltages: [0.068016, 0.44711, 0.72437, 0.050921, 0.27854, 0.0043375, 0.78457, 0.0030014, 0.2927, 0.0011096]
Predicted label: 6
Wrong prediction!
Energy consumption = 149.563975 pJ
sum error= 28
Actual label: 1
Output voltages: [0.035535, 0.79844, 0.034808, 0.040034, 0.052767, 0.0074302, 0.27581, 0.032656, 0.042591, 0.29595]
Predicted label: 1
Correct prediction
Energy consumption = 166.351605 pJ
sum error= 28
Actual label: 3
Output voltages: [0.11949, 0.025496, 0.040842, 0.79875, 0.011372, 0.0059064, 0.0051263, 0.0089879, 0.75006, 0.040911]
Predicted label: 3
Correct prediction
Energy consumption = 141.701300 pJ
sum error= 28
Actual label: 7
Output voltages: [0.19556, 0.038557, 0.38372, 0.68837, 0.0017577, 0.0010838, 0.0032336, 0.79849, 0.039005, 0.69643]
Predicted label: 7
Correct prediction
Energy consumption = 154.555688 pJ
sum error= 28
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 65 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 65 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 65 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.116, 0.040616, 0.036161, 0.0020416, 0.13431, 0.49124, 0.79874, 0.011387, 0.39203, 0.0069938]
Predicted label: 6
Correct prediction
Energy consumption = 168.259642 pJ
sum error= 28
Actual label: 7
Output voltages: [0.13583, 0.021612, 0.037768, 0.27777, 0.0065573, 0.0041187, 0.0010868, 0.79862, 0.1648, 0.39025]
Predicted label: 7
Correct prediction
Energy consumption = 163.827232 pJ
sum error= 28
Actual label: 1
Output voltages: [0.014468, 0.79853, 0.043916, 0.082543, 0.026946, 0.0017411, 0.43485, 0.001449, 0.36285, 0.076735]
Predicted label: 1
Correct prediction
Energy consumption = 163.142891 pJ
sum error= 28
Actual label: 2
Output voltages: [0.62019, 0.36501, 0.79878, 0.034169, 0.0065004, 0.0012675, 0.39826, 0.10029, 0.33039, 0.046781]
Predicted label: 2
Correct prediction
Energy consumption = 151.632381 pJ
sum error= 28
Actual label: 5
Output voltages: [0.10426, 0.0027165, 0.0011205, 0.51211, 0.0032332, 0.79877, 0.018019, 0.011071, 0.70086, 0.1055]
Predicted label: 5
Correct prediction
Energy consumption = 152.280045 pJ
sum error= 28
Actual label: 8
Output voltages: [0.17049, 0.0036002, 0.49499, 0.11466, 0.0066187, 0.027225, 0.0072474, 0.010856, 0.79877, 0.028695]
Predicted label: 8
Correct prediction
Energy consumption = 143.100201 pJ
sum error= 28
Actual label: 0
Output voltages: [0.79872, 0.20278, 0.020444, 0.029195, 0.001887, 0.17605, 0.424, 0.014534, 0.30578, 0.0206]
Predicted label: 0
Correct prediction
Energy consumption = 152.729677 pJ
sum error= 28
Actual label: 3
Output voltages: [0.49026, 0.047347, 0.16189, 0.79862, 0.011824, 0.013269, 0.015214, 0.020414, 0.56766, 0.037702]
Predicted label: 3
Correct prediction
Energy consumption = 144.525235 pJ
sum error= 28
Actual label: 7
Output voltages: [0.48426, 0.016348, 0.0062435, 0.037038, 0.645, 0.0021197, 0.0010713, 0.79878, 0.1358, 0.052459]
Predicted label: 7
Correct prediction
Energy consumption = 145.922889 pJ
sum error= 28
Actual label: 2
Output voltages: [0.074091, 0.58836, 0.78064, 0.012847, 0.022818, 0.0012869, 0.014728, 0.57254, 0.45801, 0.0069734]
Predicted label: 2
Correct prediction
Energy consumption = 150.045735 pJ
sum error= 28
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 66 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 66 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 66 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.023305, 0.023411, 0.26803, 0.019883, 0.79873, 0.0010694, 0.54026, 0.071931, 0.0027731, 0.035601]
Predicted label: 4
Correct prediction
Energy consumption = 170.680236 pJ
sum error= 28
Actual label: 0
Output voltages: [0.79876, 0.078948, 0.05257, 0.029802, 0.0090491, 0.0046582, 0.72201, 0.12827, 0.11345, 0.34583]
Predicted label: 0
Correct prediction
Energy consumption = 165.501618 pJ
sum error= 28
Actual label: 9
Output voltages: [0.49703, 0.0053307, 0.026869, 0.25996, 0.17211, 0.0092272, 0.018651, 0.072428, 0.20358, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 156.121482 pJ
sum error= 28
Actual label: 1
Output voltages: [0.047786, 0.79854, 0.29643, 0.2961, 0.31045, 0.0016958, 0.55201, 0.012817, 0.022915, 0.066199]
Predicted label: 1
Correct prediction
Energy consumption = 171.343073 pJ
sum error= 28
Actual label: 8
Output voltages: [0.010923, 0.027292, 0.28629, 0.056581, 0.029244, 0.035383, 0.01372, 0.064301, 0.79863, 0.035747]
Predicted label: 8
Correct prediction
Energy consumption = 144.048093 pJ
sum error= 28
Actual label: 6
Output voltages: [0.26339, 0.036351, 0.32448, 0.0010859, 0.45374, 0.1117, 0.79875, 0.0018857, 0.2607, 0.011941]
Predicted label: 6
Correct prediction
Energy consumption = 146.037885 pJ
sum error= 28
Actual label: 7
Output voltages: [0.096462, 0.060209, 0.029611, 0.016027, 0.016747, 0.0010691, 0.0010707, 0.79879, 0.032273, 0.54613]
Predicted label: 7
Correct prediction
Energy consumption = 155.547764 pJ
sum error= 28
Actual label: 7
Output voltages: [0.58104, 0.7323, 0.043568, 0.79135, 0.0010685, 0.0010713, 0.0012122, 0.75644, 0.55576, 0.027404]
Predicted label: 3
Wrong prediction!
Energy consumption = 155.503985 pJ
sum error= 29
Actual label: 4
Output voltages: [0.0010704, 0.13945, 0.2961, 0.011624, 0.79878, 0.0013106, 0.32785, 0.03558, 0.020869, 0.26628]
Predicted label: 4
Correct prediction
Energy consumption = 157.920258 pJ
sum error= 29
Actual label: 3
Output voltages: [0.025391, 0.039622, 0.10371, 0.79862, 0.01553, 0.002674, 0.011888, 0.02096, 0.21435, 0.48143]
Predicted label: 3
Correct prediction
Energy consumption = 149.916157 pJ
sum error= 29
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 67 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 67 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 67 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0013342, 0.016847, 0.01538, 0.0028265, 0.79865, 0.025113, 0.0090466, 0.030643, 0.27338, 0.056058]
Predicted label: 4
Correct prediction
Energy consumption = 165.040707 pJ
sum error= 29
Actual label: 9
Output voltages: [0.066973, 0.0015434, 0.011739, 0.47108, 0.27572, 0.11023, 0.12786, 0.020117, 0.12662, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 147.295859 pJ
sum error= 29
Actual label: 1
Output voltages: [0.04805, 0.79856, 0.28268, 0.14825, 0.12791, 0.0017768, 0.62166, 0.0033015, 0.057575, 0.019084]
Predicted label: 1
Correct prediction
Energy consumption = 169.680060 pJ
sum error= 29
Actual label: 9
Output voltages: [0.36347, 0.0052443, 0.033915, 0.017046, 0.037216, 0.015057, 0.0085164, 0.010309, 0.74784, 0.79519]
Predicted label: 9
Correct prediction
Energy consumption = 143.009191 pJ
sum error= 29
Actual label: 5
Output voltages: [0.042198, 0.0011122, 0.0020886, 0.79672, 0.138, 0.77672, 0.1832, 0.016899, 0.45892, 0.0026968]
Predicted label: 3
Wrong prediction!
Energy consumption = 151.602591 pJ
sum error= 30
Actual label: 1
Output voltages: [0.053111, 0.79848, 0.067424, 0.046001, 0.020672, 0.0022995, 0.7017, 0.019916, 0.12566, 0.048234]
Predicted label: 1
Correct prediction
Energy consumption = 168.846339 pJ
sum error= 30
Actual label: 7
Output voltages: [0.10276, 0.26131, 0.37987, 0.042528, 0.001249, 0.0011554, 0.0011373, 0.79878, 0.64465, 0.38029]
Predicted label: 7
Correct prediction
Energy consumption = 151.743575 pJ
sum error= 30
Actual label: 3
Output voltages: [0.6697, 0.024359, 0.040913, 0.7987, 0.0087747, 0.018493, 0.015968, 0.011943, 0.56302, 0.022193]
Predicted label: 3
Correct prediction
Energy consumption = 144.434444 pJ
sum error= 30
Actual label: 9
Output voltages: [0.026873, 0.013979, 0.023356, 0.037358, 0.62585, 0.02495, 0.19447, 0.17263, 0.088053, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 155.238875 pJ
sum error= 30
Actual label: 7
Output voltages: [0.21992, 0.1264, 0.61187, 0.2081, 0.0030316, 0.0011405, 0.0036477, 0.79879, 0.033858, 0.33027]
Predicted label: 7
Correct prediction
Energy consumption = 158.199342 pJ
sum error= 30
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 68 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 68 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 68 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.26686, 0.033603, 0.54455, 0.001066, 0.36678, 0.054923, 0.79878, 0.0027397, 0.4286, 0.008486]
Predicted label: 6
Correct prediction
Energy consumption = 160.804543 pJ
sum error= 30
Actual label: 9
Output voltages: [0.10986, 0.0027419, 0.043795, 0.060889, 0.056822, 0.040079, 0.0042471, 0.22241, 0.48853, 0.79813]
Predicted label: 9
Correct prediction
Energy consumption = 152.023619 pJ
sum error= 30
Actual label: 1
Output voltages: [0.049289, 0.79837, 0.21186, 0.067398, 0.017968, 0.0055553, 0.73449, 0.010312, 0.03464, 0.049566]
Predicted label: 1
Correct prediction
Energy consumption = 170.116269 pJ
sum error= 30
Actual label: 3
Output voltages: [0.46724, 0.021844, 0.038629, 0.79876, 0.0055384, 0.26141, 0.024586, 0.0036163, 0.34775, 0.03004]
Predicted label: 3
Correct prediction
Energy consumption = 153.033991 pJ
sum error= 30
Actual label: 7
Output voltages: [0.0025167, 0.26935, 0.4284, 0.75974, 0.0019858, 0.0090744, 0.0046861, 0.76889, 0.031159, 0.22653]
Predicted label: 7
Correct prediction
Energy consumption = 147.915892 pJ
sum error= 30
Actual label: 8
Output voltages: [0.017622, 0.047138, 0.59953, 0.082585, 0.017414, 0.0056492, 0.02905, 0.035124, 0.79877, 0.39091]
Predicted label: 8
Correct prediction
Energy consumption = 144.202277 pJ
sum error= 30
Actual label: 3
Output voltages: [0.48665, 0.021404, 0.19851, 0.79869, 0.03383, 0.0036778, 0.012031, 0.015468, 0.59161, 0.034718]
Predicted label: 3
Correct prediction
Energy consumption = 145.437801 pJ
sum error= 30
Actual label: 3
Output voltages: [0.042783, 0.04309, 0.10936, 0.79877, 0.0069204, 0.0022211, 0.021607, 0.0017218, 0.55868, 0.2147]
Predicted label: 3
Correct prediction
Energy consumption = 133.233318 pJ
sum error= 30
Actual label: 6
Output voltages: [0.0038095, 0.0074251, 0.04455, 0.017068, 0.13169, 0.23766, 0.7987, 0.0022337, 0.78016, 0.066007]
Predicted label: 6
Correct prediction
Energy consumption = 150.499716 pJ
sum error= 30
Actual label: 7
Output voltages: [0.63003, 0.11081, 0.0010851, 0.027086, 0.73875, 0.0072274, 0.0040282, 0.78039, 0.058343, 0.54256]
Predicted label: 7
Correct prediction
Energy consumption = 162.909452 pJ
sum error= 30
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 69 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 69 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 69 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.11014, 0.030111, 0.79876, 0.39112, 0.024928, 0.0013582, 0.044226, 0.044066, 0.41631, 0.019071]
Predicted label: 2
Correct prediction
Energy consumption = 166.370266 pJ
sum error= 30
Actual label: 8
Output voltages: [0.0015424, 0.0015145, 0.086022, 0.012957, 0.75806, 0.0054285, 0.021897, 0.37429, 0.79575, 0.01572]
Predicted label: 8
Correct prediction
Energy consumption = 144.495894 pJ
sum error= 30
Actual label: 5
Output voltages: [0.027065, 0.016627, 0.0010702, 0.74682, 0.0038635, 0.79869, 0.1669, 0.08602, 0.56919, 0.0095712]
Predicted label: 5
Correct prediction
Energy consumption = 154.152755 pJ
sum error= 30
Actual label: 8
Output voltages: [0.031208, 0.01706, 0.015061, 0.23042, 0.018498, 0.020379, 0.014927, 0.0082822, 0.79877, 0.041024]
Predicted label: 8
Correct prediction
Energy consumption = 146.020115 pJ
sum error= 30
Actual label: 5
Output voltages: [0.024605, 0.02376, 0.0011131, 0.74654, 0.074226, 0.79869, 0.076851, 0.028829, 0.65067, 0.0084859]
Predicted label: 5
Correct prediction
Energy consumption = 152.593801 pJ
sum error= 30
Actual label: 1
Output voltages: [0.0080164, 0.79848, 0.027086, 0.10411, 0.12891, 0.0015768, 0.53537, 0.032559, 0.1448, 0.055064]
Predicted label: 1
Correct prediction
Energy consumption = 163.071853 pJ
sum error= 30
Actual label: 1
Output voltages: [0.038204, 0.79844, 0.0043462, 0.26766, 0.006163, 0.029248, 0.25873, 0.036915, 0.43805, 0.17337]
Predicted label: 1
Correct prediction
Energy consumption = 149.886893 pJ
sum error= 30
Actual label: 4
Output voltages: [0.010992, 0.015397, 0.23217, 0.013378, 0.79851, 0.0090151, 0.10466, 0.051504, 0.037303, 0.033417]
Predicted label: 4
Correct prediction
Energy consumption = 152.508827 pJ
sum error= 30
Actual label: 4
Output voltages: [0.0012708, 0.0036284, 0.45676, 0.0018477, 0.79527, 0.0053284, 0.037041, 0.01266, 0.62503, 0.021131]
Predicted label: 4
Correct prediction
Energy consumption = 147.790147 pJ
sum error= 30
Actual label: 3
Output voltages: [0.084339, 0.017719, 0.2161, 0.79874, 0.021221, 0.013866, 0.0020164, 0.045796, 0.42798, 0.030996]
Predicted label: 3
Correct prediction
Energy consumption = 141.494825 pJ
sum error= 30
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 70 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 70 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 70 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.015256, 0.79841, 0.17502, 0.44342, 0.12027, 0.001079, 0.0079718, 0.010191, 0.11192, 0.14245]
Predicted label: 1
Correct prediction
Energy consumption = 182.665586 pJ
sum error= 30
Actual label: 0
Output voltages: [0.79877, 0.094881, 0.027245, 0.1072, 0.0030837, 0.032379, 0.44757, 0.040209, 0.15111, 0.018881]
Predicted label: 0
Correct prediction
Energy consumption = 152.934253 pJ
sum error= 30
Actual label: 7
Output voltages: [0.022853, 0.37524, 0.5433, 0.031436, 0.0049472, 0.001114, 0.0010867, 0.79878, 0.64795, 0.27999]
Predicted label: 7
Correct prediction
Energy consumption = 160.017530 pJ
sum error= 30
Actual label: 7
Output voltages: [0.35885, 0.09135, 0.049568, 0.55395, 0.0013959, 0.0028055, 0.0011035, 0.79873, 0.024136, 0.53031]
Predicted label: 7
Correct prediction
Energy consumption = 145.147776 pJ
sum error= 30
Actual label: 0
Output voltages: [0.79879, 0.055794, 0.029903, 0.03035, 0.014645, 0.011907, 0.476, 0.026671, 0.055133, 0.041461]
Predicted label: 0
Correct prediction
Energy consumption = 148.551951 pJ
sum error= 30
Actual label: 7
Output voltages: [0.037838, 0.076893, 0.025021, 0.17988, 0.0057668, 0.0016231, 0.0010862, 0.79865, 0.064441, 0.41452]
Predicted label: 7
Correct prediction
Energy consumption = 157.709836 pJ
sum error= 30
Actual label: 9
Output voltages: [0.53392, 0.0023117, 0.019932, 0.011811, 0.03096, 0.055087, 0.0025541, 0.59311, 0.299, 0.79333]
Predicted label: 9
Correct prediction
Energy consumption = 147.924423 pJ
sum error= 30
Actual label: 4
Output voltages: [0.0010659, 0.062567, 0.063598, 0.0013181, 0.79404, 0.0011999, 0.0073791, 0.02273, 0.63409, 0.17933]
Predicted label: 4
Correct prediction
Energy consumption = 146.172572 pJ
sum error= 30
Actual label: 4
Output voltages: [0.021889, 0.015263, 0.063621, 0.0027407, 0.79865, 0.0056029, 0.20009, 0.036767, 0.060909, 0.019212]
Predicted label: 4
Correct prediction
Energy consumption = 151.418180 pJ
sum error= 30
Actual label: 8
Output voltages: [0.040895, 0.050245, 0.1993, 0.67994, 0.0012314, 0.025474, 0.071091, 0.0046425, 0.79878, 0.13443]
Predicted label: 8
Correct prediction
Energy consumption = 154.373831 pJ
sum error= 30
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 71 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 71 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 71 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.028125, 0.0010692, 0.0013663, 0.36267, 0.014619, 0.79826, 0.079911, 0.041191, 0.79289, 0.0051782]
Predicted label: 5
Correct prediction
Energy consumption = 164.360721 pJ
sum error= 30
Actual label: 5
Output voltages: [0.25343, 0.0011152, 0.034552, 0.38283, 0.015816, 0.7955, 0.023488, 0.019559, 0.79614, 0.05396]
Predicted label: 8
Wrong prediction!
Energy consumption = 130.731852 pJ
sum error= 31
Actual label: 4
Output voltages: [0.023515, 0.021357, 0.032559, 0.029368, 0.7986, 0.0068684, 0.086745, 0.042981, 0.054575, 0.47562]
Predicted label: 4
Correct prediction
Energy consumption = 157.542047 pJ
sum error= 31
Actual label: 0
Output voltages: [0.79879, 0.10285, 0.038041, 0.016577, 0.0083956, 0.012951, 0.44888, 0.017719, 0.066607, 0.056369]
Predicted label: 0
Correct prediction
Energy consumption = 157.086244 pJ
sum error= 31
Actual label: 8
Output voltages: [0.40541, 0.0026405, 0.31914, 0.061027, 0.010401, 0.042582, 0.0024635, 0.0075295, 0.79876, 0.36064]
Predicted label: 8
Correct prediction
Energy consumption = 149.103148 pJ
sum error= 31
Actual label: 2
Output voltages: [0.29623, 0.024633, 0.7987, 0.27447, 0.0028138, 0.001111, 0.1037, 0.036909, 0.69488, 0.024068]
Predicted label: 2
Correct prediction
Energy consumption = 143.269843 pJ
sum error= 31
Actual label: 1
Output voltages: [0.14714, 0.78649, 0.46602, 0.74795, 0.0011954, 0.0011932, 0.080664, 0.061098, 0.13399, 0.025358]
Predicted label: 1
Correct prediction
Energy consumption = 150.036542 pJ
sum error= 31
Actual label: 0
Output voltages: [0.4797, 0.0023565, 0.10075, 0.26605, 0.052784, 0.001075, 0.74871, 0.0036252, 0.028387, 0.0075647]
Predicted label: 6
Wrong prediction!
Energy consumption = 143.084852 pJ
sum error= 32
Actual label: 8
Output voltages: [0.2886, 0.016423, 0.71262, 0.023665, 0.036026, 0.0025846, 0.055386, 0.003161, 0.79879, 0.31056]
Predicted label: 8
Correct prediction
Energy consumption = 157.167172 pJ
sum error= 32
Actual label: 4
Output voltages: [0.0239, 0.012615, 0.056366, 0.0022983, 0.79867, 0.01842, 0.073201, 0.025866, 0.12474, 0.1274]
Predicted label: 4
Correct prediction
Energy consumption = 150.412060 pJ
sum error= 32
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 72 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 72 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 72 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.022356, 0.0015887, 0.049326, 0.37729, 0.033012, 0.79339, 0.42312, 0.0070213, 0.794, 0.026882]
Predicted label: 8
Wrong prediction!
Energy consumption = 165.215674 pJ
sum error= 33
Actual label: 0
Output voltages: [0.79876, 0.041301, 0.04243, 0.049185, 0.0083537, 0.29648, 0.50871, 0.0014055, 0.024084, 0.4035]
Predicted label: 0
Correct prediction
Energy consumption = 150.643003 pJ
sum error= 33
Actual label: 4
Output voltages: [0.028943, 0.018416, 0.15134, 0.015019, 0.79865, 0.0082146, 0.2278, 0.25042, 0.046612, 0.024492]
Predicted label: 4
Correct prediction
Energy consumption = 156.007570 pJ
sum error= 33
Actual label: 0
Output voltages: [0.79867, 0.044263, 0.036011, 0.015134, 0.029258, 0.0024917, 0.75964, 0.03978, 0.2103, 0.07721]
Predicted label: 0
Correct prediction
Energy consumption = 158.357823 pJ
sum error= 33
Actual label: 6
Output voltages: [0.12125, 0.087616, 0.20204, 0.0072044, 0.25863, 0.17649, 0.7987, 0.0023937, 0.51585, 0.011326]
Predicted label: 6
Correct prediction
Energy consumption = 142.749795 pJ
sum error= 33
Actual label: 1
Output voltages: [0.0036245, 0.79864, 0.0041497, 0.046463, 0.10388, 0.0026467, 0.41708, 0.004981, 0.38761, 0.053985]
Predicted label: 1
Correct prediction
Energy consumption = 166.315898 pJ
sum error= 33
Actual label: 7
Output voltages: [0.022367, 0.020284, 0.071215, 0.052629, 0.063439, 0.051042, 0.0010683, 0.79422, 0.021096, 0.44581]
Predicted label: 7
Correct prediction
Energy consumption = 155.088230 pJ
sum error= 33
Actual label: 3
Output voltages: [0.19455, 0.023496, 0.051682, 0.79878, 0.0011198, 0.011026, 0.014218, 0.0084101, 0.28796, 0.039926]
Predicted label: 3
Correct prediction
Energy consumption = 141.838112 pJ
sum error= 33
Actual label: 2
Output voltages: [0.2467, 0.047185, 0.79879, 0.06582, 0.0039546, 0.0010714, 0.16256, 0.17898, 0.78978, 0.047347]
Predicted label: 2
Correct prediction
Energy consumption = 143.779847 pJ
sum error= 33
Actual label: 6
Output voltages: [0.24305, 0.0034166, 0.067171, 0.014012, 0.37369, 0.58375, 0.79863, 0.0011143, 0.72777, 0.024033]
Predicted label: 6
Correct prediction
Energy consumption = 143.882348 pJ
sum error= 33
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 73 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 73 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 73 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.46638, 0.061393, 0.13867, 0.010739, 0.085585, 0.0027809, 0.0072817, 0.79879, 0.045129, 0.47272]
Predicted label: 7
Correct prediction
Energy consumption = 174.735761 pJ
sum error= 33
Actual label: 2
Output voltages: [0.70793, 0.0041333, 0.79878, 0.18261, 0.026352, 0.0011157, 0.048717, 0.047597, 0.58478, 0.013242]
Predicted label: 2
Correct prediction
Energy consumption = 145.437063 pJ
sum error= 33
Actual label: 6
Output voltages: [0.27398, 0.036775, 0.18117, 0.0030083, 0.25955, 0.16164, 0.79879, 0.001494, 0.53166, 0.021738]
Predicted label: 6
Correct prediction
Energy consumption = 147.268903 pJ
sum error= 33
Actual label: 9
Output voltages: [0.048768, 0.024603, 0.018987, 0.1612, 0.058516, 0.0068417, 0.0016548, 0.034924, 0.43146, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 150.195269 pJ
sum error= 33
Actual label: 3
Output voltages: [0.47056, 0.0045632, 0.12062, 0.79872, 0.011094, 0.057866, 0.011936, 0.020923, 0.49257, 0.01286]
Predicted label: 3
Correct prediction
Energy consumption = 147.721259 pJ
sum error= 33
Actual label: 1
Output voltages: [0.03615, 0.79838, 0.07288, 0.18133, 0.058404, 0.035253, 0.50661, 0.0088713, 0.2226, 0.056059]
Predicted label: 1
Correct prediction
Energy consumption = 163.485933 pJ
sum error= 33
Actual label: 4
Output voltages: [0.013916, 0.0039294, 0.20907, 0.0031807, 0.79854, 0.0023602, 0.34757, 0.056332, 0.11233, 0.047569]
Predicted label: 4
Correct prediction
Energy consumption = 151.125314 pJ
sum error= 33
Actual label: 6
Output voltages: [0.40191, 0.012004, 0.35173, 0.0010764, 0.25429, 0.21164, 0.79878, 0.0069997, 0.43673, 0.013008]
Predicted label: 6
Correct prediction
Energy consumption = 140.689089 pJ
sum error= 33
Actual label: 2
Output voltages: [0.31417, 0.097325, 0.79849, 0.42003, 0.0044249, 0.0012796, 0.16571, 0.004306, 0.37813, 0.021296]
Predicted label: 2
Correct prediction
Energy consumption = 150.256704 pJ
sum error= 33
Actual label: 5
Output voltages: [0.17944, 0.0026421, 0.002056, 0.35338, 0.028849, 0.79875, 0.53591, 0.030862, 0.74388, 0.036184]
Predicted label: 5
Correct prediction
Energy consumption = 145.271990 pJ
sum error= 33
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 74 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 74 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 74 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.11167, 0.10876, 0.014817, 0.13318, 0.55633, 0.0029054, 0.0010967, 0.0018618, 0.020355, 0.79878]
Predicted label: 9
Wrong prediction!
Energy consumption = 174.120565 pJ
sum error= 34
Actual label: 2
Output voltages: [0.22918, 0.33561, 0.79877, 0.040692, 0.005976, 0.0012463, 0.1765, 0.13251, 0.67647, 0.30083]
Predicted label: 2
Correct prediction
Energy consumption = 150.882967 pJ
sum error= 34
Actual label: 0
Output voltages: [0.79868, 0.034177, 0.22896, 0.010305, 0.0085016, 0.012674, 0.17727, 0.0088555, 0.042095, 0.049904]
Predicted label: 0
Correct prediction
Energy consumption = 147.206617 pJ
sum error= 34
Actual label: 6
Output voltages: [0.4174, 0.012216, 0.18802, 0.002605, 0.66105, 0.27335, 0.79878, 0.01204, 0.60783, 0.018076]
Predicted label: 6
Correct prediction
Energy consumption = 147.202841 pJ
sum error= 34
Actual label: 2
Output voltages: [0.3564, 0.18366, 0.79873, 0.10444, 0.018873, 0.0011106, 0.32891, 0.010925, 0.10201, 0.016432]
Predicted label: 2
Correct prediction
Energy consumption = 152.389271 pJ
sum error= 34
Actual label: 1
Output voltages: [0.011036, 0.79877, 0.0048864, 0.013504, 0.31211, 0.0099248, 0.66177, 0.0016298, 0.64326, 0.029722]
Predicted label: 1
Correct prediction
Energy consumption = 162.922075 pJ
sum error= 34
Actual label: 7
Output voltages: [0.022689, 0.43356, 0.049979, 0.066012, 0.0020845, 0.0010659, 0.0010675, 0.79871, 0.051163, 0.26477]
Predicted label: 7
Correct prediction
Energy consumption = 156.934646 pJ
sum error= 34
Actual label: 3
Output voltages: [0.047276, 0.027298, 0.053382, 0.79875, 0.014157, 0.0028316, 0.01127, 0.022876, 0.66837, 0.11201]
Predicted label: 3
Correct prediction
Energy consumption = 144.646867 pJ
sum error= 34
Actual label: 4
Output voltages: [0.055617, 0.015797, 0.093121, 0.019781, 0.79857, 0.0086383, 0.044462, 0.014378, 0.030988, 0.30191]
Predicted label: 4
Correct prediction
Energy consumption = 150.358100 pJ
sum error= 34
Actual label: 1
Output voltages: [0.01283, 0.79845, 0.04368, 0.027827, 0.011667, 0.0027299, 0.65728, 0.0029108, 0.3965, 0.027086]
Predicted label: 1
Correct prediction
Energy consumption = 164.459542 pJ
sum error= 34
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 75 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 75 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 75 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79861, 0.24974, 0.017915, 0.042441, 0.010585, 0.040393, 0.75377, 0.023972, 0.23069, 0.016868]
Predicted label: 0
Correct prediction
Energy consumption = 174.693267 pJ
sum error= 34
Actual label: 5
Output voltages: [0.027946, 0.0010686, 0.003215, 0.37746, 0.30325, 0.79871, 0.058645, 0.045539, 0.77033, 0.40586]
Predicted label: 5
Correct prediction
Energy consumption = 145.999156 pJ
sum error= 34
Actual label: 4
Output voltages: [0.02464, 0.048798, 0.047653, 0.0079607, 0.79877, 0.0010661, 0.17906, 0.16126, 0.012189, 0.031097]
Predicted label: 4
Correct prediction
Energy consumption = 160.868781 pJ
sum error= 34
Actual label: 3
Output voltages: [0.755, 0.0010704, 0.58154, 0.79862, 0.014859, 0.0043959, 0.0062184, 0.031378, 0.70751, 0.015258]
Predicted label: 3
Correct prediction
Energy consumption = 145.190936 pJ
sum error= 34
Actual label: 1
Output voltages: [0.016124, 0.79853, 0.012947, 0.027019, 0.024108, 0.0024972, 0.50958, 0.009835, 0.68825, 0.030932]
Predicted label: 1
Correct prediction
Energy consumption = 164.609282 pJ
sum error= 34
Actual label: 1
Output voltages: [0.0095566, 0.79855, 0.033155, 0.22685, 0.047555, 0.03054, 0.055875, 0.010187, 0.022953, 0.32972]
Predicted label: 1
Correct prediction
Energy consumption = 160.438129 pJ
sum error= 34
Actual label: 7
Output voltages: [0.42819, 0.076585, 0.32968, 0.39437, 0.0069612, 0.0011571, 0.0010673, 0.79879, 0.26486, 0.14853]
Predicted label: 7
Correct prediction
Energy consumption = 155.180652 pJ
sum error= 34
Actual label: 4
Output voltages: [0.001879, 0.0064014, 0.14978, 0.0099149, 0.79872, 0.0011188, 0.24796, 0.034348, 0.047127, 0.018328]
Predicted label: 4
Correct prediction
Energy consumption = 154.847333 pJ
sum error= 34
Actual label: 9
Output voltages: [0.55991, 0.028256, 0.028094, 0.19508, 0.45942, 0.031692, 0.0048334, 0.018824, 0.22277, 0.79849]
Predicted label: 9
Correct prediction
Energy consumption = 149.102942 pJ
sum error= 34
Actual label: 9
Output voltages: [0.083421, 0.011901, 0.013598, 0.031583, 0.03259, 0.0062934, 0.0012382, 0.028103, 0.75602, 0.79668]
Predicted label: 9
Correct prediction
Energy consumption = 137.155733 pJ
sum error= 34
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 76 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 76 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 76 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.032832, 0.014756, 0.058429, 0.234, 0.7965, 0.0010697, 0.001066, 0.0038144, 0.033021, 0.7245]
Predicted label: 4
Correct prediction
Energy consumption = 170.519505 pJ
sum error= 34
Actual label: 8
Output voltages: [0.021088, 0.030011, 0.33288, 0.053291, 0.012683, 0.015581, 0.068798, 0.0033139, 0.79879, 0.51798]
Predicted label: 8
Correct prediction
Energy consumption = 147.802943 pJ
sum error= 34
Actual label: 4
Output voltages: [0.035628, 0.0037997, 0.52627, 0.020807, 0.79873, 0.0015201, 0.17888, 0.041957, 0.019901, 0.10578]
Predicted label: 4
Correct prediction
Energy consumption = 154.820283 pJ
sum error= 34
Actual label: 0
Output voltages: [0.79018, 0.058145, 0.74426, 0.029406, 0.0010964, 0.003808, 0.093696, 0.013114, 0.57389, 0.0085508]
Predicted label: 0
Correct prediction
Energy consumption = 148.587236 pJ
sum error= 34
Actual label: 2
Output voltages: [0.55282, 0.0029146, 0.79879, 0.1691, 0.013267, 0.0010698, 0.070296, 0.097587, 0.70444, 0.010956]
Predicted label: 2
Correct prediction
Energy consumption = 134.332374 pJ
sum error= 34
Actual label: 4
Output voltages: [0.0016297, 0.002545, 0.031083, 0.0059924, 0.7987, 0.0010744, 0.16157, 0.04795, 0.060004, 0.025195]
Predicted label: 4
Correct prediction
Energy consumption = 159.740538 pJ
sum error= 34
Actual label: 5
Output voltages: [0.038101, 0.0011334, 0.052006, 0.086271, 0.0020099, 0.79536, 0.025178, 0.016708, 0.79822, 0.019451]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.763194 pJ
sum error= 35
Actual label: 1
Output voltages: [0.24956, 0.79858, 0.2285, 0.027166, 0.4582, 0.001066, 0.076288, 0.0073701, 0.013647, 0.14795]
Predicted label: 1
Correct prediction
Energy consumption = 166.093102 pJ
sum error= 35
Actual label: 1
Output voltages: [0.024021, 0.79851, 0.046982, 0.077911, 0.0028529, 0.0015947, 0.78235, 0.001903, 0.043082, 0.085947]
Predicted label: 1
Correct prediction
Energy consumption = 148.753305 pJ
sum error= 35
Actual label: 6
Output voltages: [0.17549, 0.013455, 0.010143, 0.047614, 0.036405, 0.7668, 0.79828, 0.0064421, 0.70937, 0.018838]
Predicted label: 6
Correct prediction
Energy consumption = 150.302463 pJ
sum error= 35
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 77 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 77 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 77 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.015374, 0.032654, 0.080964, 0.0026797, 0.79878, 0.0016382, 0.47521, 0.20124, 0.048554, 0.016592]
Predicted label: 4
Correct prediction
Energy consumption = 172.211890 pJ
sum error= 35
Actual label: 7
Output voltages: [0.26956, 0.080553, 0.023276, 0.0099144, 0.005998, 0.020613, 0.0026363, 0.79879, 0.19213, 0.74835]
Predicted label: 7
Correct prediction
Energy consumption = 158.185566 pJ
sum error= 35
Actual label: 1
Output voltages: [0.016321, 0.79867, 0.0024456, 0.056439, 0.0024296, 0.0011258, 0.11795, 0.024264, 0.66128, 0.16296]
Predicted label: 1
Correct prediction
Energy consumption = 163.129893 pJ
sum error= 35
Actual label: 9
Output voltages: [0.49375, 0.019614, 0.033339, 0.074497, 0.1732, 0.015798, 0.0065842, 0.069497, 0.081384, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 157.510862 pJ
sum error= 35
Actual label: 4
Output voltages: [0.015187, 0.039231, 0.1629, 0.0053745, 0.79866, 0.001156, 0.0016218, 0.05039, 0.025352, 0.58329]
Predicted label: 4
Correct prediction
Energy consumption = 158.025311 pJ
sum error= 35
Actual label: 2
Output voltages: [0.52822, 0.034873, 0.79879, 0.070571, 0.011478, 0.0011821, 0.4532, 0.062197, 0.74991, 0.044241]
Predicted label: 2
Correct prediction
Energy consumption = 149.980774 pJ
sum error= 35
Actual label: 4
Output voltages: [0.0138, 0.0020658, 0.33754, 0.0061464, 0.79875, 0.091008, 0.15843, 0.011711, 0.026552, 0.75178]
Predicted label: 4
Correct prediction
Energy consumption = 153.008421 pJ
sum error= 35
Actual label: 1
Output voltages: [0.35478, 0.79854, 0.047056, 0.2929, 0.0211, 0.0042047, 0.5193, 0.012902, 0.054554, 0.09571]
Predicted label: 1
Correct prediction
Energy consumption = 164.826743 pJ
sum error= 35
Actual label: 5
Output voltages: [0.027912, 0.0010703, 0.0020984, 0.14868, 0.08008, 0.79849, 0.16998, 0.026492, 0.78885, 0.038411]
Predicted label: 5
Correct prediction
Energy consumption = 145.364370 pJ
sum error= 35
Actual label: 5
Output voltages: [0.40532, 0.026689, 0.0011109, 0.56559, 0.16486, 0.79869, 0.30146, 0.0011725, 0.3757, 0.035243]
Predicted label: 5
Correct prediction
Energy consumption = 144.884076 pJ
sum error= 35
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 78 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 78 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 78 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.72551, 0.028632, 0.0022866, 0.79824, 0.015266, 0.75204, 0.013236, 0.29363, 0.48338, 0.0016638]
Predicted label: 3
Correct prediction
Energy consumption = 166.548116 pJ
sum error= 35
Actual label: 8
Output voltages: [0.41742, 0.32514, 0.029357, 0.052204, 0.0022019, 0.04436, 0.66274, 0.0012603, 0.79222, 0.013206]
Predicted label: 8
Correct prediction
Energy consumption = 153.941301 pJ
sum error= 35
Actual label: 3
Output voltages: [0.50718, 0.02012, 0.1274, 0.79871, 0.020539, 0.0083664, 0.017788, 0.020728, 0.60537, 0.016751]
Predicted label: 3
Correct prediction
Energy consumption = 144.006231 pJ
sum error= 35
Actual label: 1
Output voltages: [0.02027, 0.79855, 0.02419, 0.039089, 0.031049, 0.0042317, 0.38073, 0.0019176, 0.36589, 0.026466]
Predicted label: 1
Correct prediction
Energy consumption = 161.946226 pJ
sum error= 35
Actual label: 4
Output voltages: [0.029753, 0.0011487, 0.47104, 0.033658, 0.79862, 0.036042, 0.062351, 0.018264, 0.024414, 0.60315]
Predicted label: 4
Correct prediction
Energy consumption = 163.454268 pJ
sum error= 35
Actual label: 5
Output voltages: [0.061912, 0.0010697, 0.01173, 0.61198, 0.015017, 0.79871, 0.033073, 0.4516, 0.71455, 0.14052]
Predicted label: 5
Correct prediction
Energy consumption = 144.871298 pJ
sum error= 35
Actual label: 6
Output voltages: [0.42002, 0.03664, 0.037354, 0.015851, 0.04026, 0.71098, 0.79876, 0.0043523, 0.47641, 0.0083214]
Predicted label: 6
Correct prediction
Energy consumption = 148.724455 pJ
sum error= 35
Actual label: 8
Output voltages: [0.31137, 0.0063541, 0.20585, 0.088155, 0.019872, 0.031259, 0.0099683, 0.0030109, 0.79878, 0.51115]
Predicted label: 8
Correct prediction
Energy consumption = 143.448737 pJ
sum error= 35
Actual label: 9
Output voltages: [0.044317, 0.0021517, 0.015524, 0.33398, 0.058807, 0.018889, 0.0026438, 0.4226, 0.38106, 0.79737]
Predicted label: 9
Correct prediction
Energy consumption = 159.841083 pJ
sum error= 35
Actual label: 4
Output voltages: [0.015924, 0.030495, 0.21714, 0.036267, 0.7987, 0.0011292, 0.12117, 0.060183, 0.0071978, 0.23246]
Predicted label: 4
Correct prediction
Energy consumption = 152.615037 pJ
sum error= 35
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 79 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 79 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 79 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.036968, 0.7985, 0.017356, 0.20774, 0.012272, 0.0018333, 0.6272, 0.0040361, 0.17822, 0.030174]
Predicted label: 1
Correct prediction
Energy consumption = 181.896302 pJ
sum error= 35
Actual label: 5
Output voltages: [0.0026045, 0.0011687, 0.031362, 0.10913, 0.16998, 0.79383, 0.04126, 0.12169, 0.76727, 0.24873]
Predicted label: 5
Correct prediction
Energy consumption = 150.911680 pJ
sum error= 35
Actual label: 3
Output voltages: [0.093191, 0.0095745, 0.036858, 0.79875, 0.011228, 0.010674, 0.0079175, 0.045017, 0.73213, 0.055851]
Predicted label: 3
Correct prediction
Energy consumption = 138.368894 pJ
sum error= 35
Actual label: 8
Output voltages: [0.020517, 0.032037, 0.31142, 0.06923, 0.0043049, 0.026339, 0.014136, 0.02143, 0.79878, 0.33248]
Predicted label: 8
Correct prediction
Energy consumption = 145.309396 pJ
sum error= 35
Actual label: 0
Output voltages: [0.79876, 0.24647, 0.015068, 0.015287, 0.0047079, 0.010462, 0.63948, 0.022948, 0.10476, 0.041323]
Predicted label: 0
Correct prediction
Energy consumption = 153.462828 pJ
sum error= 35
Actual label: 3
Output voltages: [0.74787, 0.23824, 0.15557, 0.79852, 0.010648, 0.054228, 0.02837, 0.024196, 0.3258, 0.011189]
Predicted label: 3
Correct prediction
Energy consumption = 155.260408 pJ
sum error= 35
Actual label: 2
Output voltages: [0.5629, 0.0032453, 0.79879, 0.056254, 0.026605, 0.0010995, 0.022067, 0.036694, 0.33942, 0.0092151]
Predicted label: 2
Correct prediction
Energy consumption = 145.008275 pJ
sum error= 35
Actual label: 5
Output voltages: [0.36744, 0.69366, 0.0010718, 0.083284, 0.0011624, 0.73613, 0.022751, 0.0011284, 0.7754, 0.011702]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.303289 pJ
sum error= 36
Actual label: 1
Output voltages: [0.041835, 0.79845, 0.1673, 0.23609, 0.035981, 0.0034271, 0.69015, 0.0013411, 0.02328, 0.36944]
Predicted label: 1
Correct prediction
Energy consumption = 157.236117 pJ
sum error= 36
Actual label: 2
Output voltages: [0.40015, 0.42851, 0.79876, 0.38944, 0.025764, 0.0011744, 0.24976, 0.11005, 0.33136, 0.056858]
Predicted label: 2
Correct prediction
Energy consumption = 145.782899 pJ
sum error= 36
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 80 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 80 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 80 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.59784, 0.031584, 0.50788, 0.42828, 0.047517, 0.001438, 0.033055, 0.0010695, 0.79807, 0.36227]
Predicted label: 8
Correct prediction
Energy consumption = 174.033235 pJ
sum error= 36
Actual label: 3
Output voltages: [0.27511, 0.0091673, 0.049698, 0.79874, 0.023156, 0.023344, 0.039475, 0.031472, 0.67494, 0.022016]
Predicted label: 3
Correct prediction
Energy consumption = 141.408615 pJ
sum error= 36
Actual label: 4
Output voltages: [0.0015485, 0.0279, 0.058566, 0.0046776, 0.79868, 0.0019788, 0.35283, 0.34141, 0.015099, 0.048548]
Predicted label: 4
Correct prediction
Energy consumption = 152.224146 pJ
sum error= 36
Actual label: 4
Output voltages: [0.016357, 0.0082647, 0.22646, 0.0010731, 0.79865, 0.0012202, 0.22533, 0.026444, 0.025985, 0.025483]
Predicted label: 4
Correct prediction
Energy consumption = 145.308006 pJ
sum error= 36
Actual label: 0
Output voltages: [0.79567, 0.0061689, 0.43197, 0.051827, 0.0017161, 0.0092103, 0.33671, 0.015929, 0.61244, 0.27538]
Predicted label: 0
Correct prediction
Energy consumption = 147.567588 pJ
sum error= 36
Actual label: 8
Output voltages: [0.058843, 0.0096592, 0.28302, 0.090718, 0.015376, 0.024381, 0.0087878, 0.026103, 0.79865, 0.038861]
Predicted label: 8
Correct prediction
Energy consumption = 147.781836 pJ
sum error= 36
Actual label: 8
Output voltages: [0.024892, 0.040039, 0.077354, 0.038743, 0.014233, 0.046234, 0.22611, 0.0099069, 0.79878, 0.27274]
Predicted label: 8
Correct prediction
Energy consumption = 147.634163 pJ
sum error= 36
Actual label: 3
Output voltages: [0.59178, 0.0069981, 0.32734, 0.79864, 0.032452, 0.01967, 0.01136, 0.016005, 0.57799, 0.010591]
Predicted label: 3
Correct prediction
Energy consumption = 146.809590 pJ
sum error= 36
Actual label: 3
Output voltages: [0.33732, 0.0051405, 0.025915, 0.79865, 0.03207, 0.021067, 0.0541, 0.020653, 0.36618, 0.024074]
Predicted label: 3
Correct prediction
Energy consumption = 138.532783 pJ
sum error= 36
Actual label: 1
Output voltages: [0.036683, 0.79844, 0.0024794, 0.046716, 0.075213, 0.023086, 0.1876, 0.0058488, 0.14391, 0.081769]
Predicted label: 1
Correct prediction
Energy consumption = 167.779440 pJ
sum error= 36
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 81 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 81 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 81 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.15386, 0.019607, 0.79529, 0.14533, 0.0012811, 0.0010847, 0.0098838, 0.79512, 0.38763, 0.045896]
Predicted label: 2
Wrong prediction!
Energy consumption = 167.695343 pJ
sum error= 37
Actual label: 3
Output voltages: [0.16486, 0.046212, 0.044842, 0.79864, 0.02103, 0.0021904, 0.0050394, 0.037823, 0.56424, 0.043469]
Predicted label: 3
Correct prediction
Energy consumption = 141.615273 pJ
sum error= 37
Actual label: 5
Output voltages: [0.041846, 0.0010828, 0.0034742, 0.26378, 0.039034, 0.79842, 0.16173, 0.027908, 0.78579, 0.17313]
Predicted label: 5
Correct prediction
Energy consumption = 145.292128 pJ
sum error= 37
Actual label: 9
Output voltages: [0.59454, 0.0028494, 0.080206, 0.0093697, 0.20395, 0.010615, 0.0038444, 0.018025, 0.76493, 0.79625]
Predicted label: 9
Correct prediction
Energy consumption = 142.374166 pJ
sum error= 37
Actual label: 6
Output voltages: [0.12886, 0.053965, 0.094147, 0.0061824, 0.36823, 0.28201, 0.79872, 0.0050877, 0.43076, 0.01133]
Predicted label: 6
Correct prediction
Energy consumption = 153.674823 pJ
sum error= 37
Actual label: 3
Output voltages: [0.45408, 0.0070743, 0.087406, 0.79869, 0.0086647, 0.026798, 0.016705, 0.0052851, 0.55012, 0.11755]
Predicted label: 3
Correct prediction
Energy consumption = 152.376766 pJ
sum error= 37
Actual label: 2
Output voltages: [0.3157, 0.035524, 0.79878, 0.056281, 0.019497, 0.0012559, 0.48014, 0.023942, 0.75641, 0.074992]
Predicted label: 2
Correct prediction
Energy consumption = 144.748393 pJ
sum error= 37
Actual label: 6
Output voltages: [0.30042, 0.013981, 0.10203, 0.0052361, 0.45584, 0.028987, 0.79879, 0.0010663, 0.65617, 0.017301]
Predicted label: 6
Correct prediction
Energy consumption = 141.414709 pJ
sum error= 37
Actual label: 1
Output voltages: [0.073313, 0.79863, 0.026817, 0.078618, 0.0046211, 0.0011525, 0.73592, 0.0015535, 0.31691, 0.038405]
Predicted label: 1
Correct prediction
Energy consumption = 155.634513 pJ
sum error= 37
Actual label: 3
Output voltages: [0.72747, 0.0065002, 0.069987, 0.79879, 0.030873, 0.0051323, 0.0026362, 0.026366, 0.1806, 0.0029845]
Predicted label: 3
Correct prediction
Energy consumption = 141.986764 pJ
sum error= 37
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 82 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 82 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 82 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.31481, 0.058276, 0.45598, 0.0016669, 0.35703, 0.033339, 0.79879, 0.0010676, 0.42128, 0.031124]
Predicted label: 6
Correct prediction
Energy consumption = 163.965789 pJ
sum error= 37
Actual label: 0
Output voltages: [0.79879, 0.25356, 0.040338, 0.019726, 0.015091, 0.0064607, 0.32335, 0.011148, 0.037052, 0.37395]
Predicted label: 0
Correct prediction
Energy consumption = 154.723768 pJ
sum error= 37
Actual label: 7
Output voltages: [0.62292, 0.013387, 0.0067778, 0.38276, 0.0050795, 0.032537, 0.0011221, 0.79875, 0.72997, 0.42037]
Predicted label: 7
Correct prediction
Energy consumption = 151.838440 pJ
sum error= 37
Actual label: 2
Output voltages: [0.12438, 0.036527, 0.79855, 0.07022, 0.047412, 0.0011351, 0.2056, 0.016152, 0.778, 0.033937]
Predicted label: 2
Correct prediction
Energy consumption = 145.501463 pJ
sum error= 37
Actual label: 1
Output voltages: [0.0053007, 0.79852, 0.051491, 0.031037, 0.039476, 0.0015028, 0.37287, 0.0078629, 0.24915, 0.016186]
Predicted label: 1
Correct prediction
Energy consumption = 159.509771 pJ
sum error= 37
Actual label: 7
Output voltages: [0.18908, 0.013515, 0.022423, 0.3664, 0.001994, 0.0034673, 0.0011421, 0.79878, 0.61467, 0.59314]
Predicted label: 7
Correct prediction
Energy consumption = 161.286360 pJ
sum error= 37
Actual label: 1
Output voltages: [0.013088, 0.7984, 0.011067, 0.37505, 0.007345, 0.0017738, 0.78457, 0.024132, 0.07491, 0.087607]
Predicted label: 1
Correct prediction
Energy consumption = 160.008544 pJ
sum error= 37
Actual label: 4
Output voltages: [0.0026235, 0.0055925, 0.018025, 0.034532, 0.79818, 0.035944, 0.017883, 0.010795, 0.12809, 0.20748]
Predicted label: 4
Correct prediction
Energy consumption = 144.845240 pJ
sum error= 37
Actual label: 2
Output voltages: [0.36591, 0.036614, 0.79875, 0.11741, 0.022848, 0.0012264, 0.22555, 0.016362, 0.5472, 0.028912]
Predicted label: 2
Correct prediction
Energy consumption = 148.800123 pJ
sum error= 37
Actual label: 4
Output voltages: [0.25021, 0.012069, 0.28598, 0.023736, 0.79862, 0.0010665, 0.062068, 0.018213, 0.7652, 0.0043951]
Predicted label: 4
Correct prediction
Energy consumption = 136.673777 pJ
sum error= 37
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 83 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 83 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 83 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.38568, 0.016449, 0.79877, 0.1454, 0.036217, 0.0011896, 0.04765, 0.16806, 0.32665, 0.034473]
Predicted label: 2
Correct prediction
Energy consumption = 170.514102 pJ
sum error= 37
Actual label: 1
Output voltages: [0.037416, 0.79852, 0.20208, 0.055274, 0.024235, 0.0010659, 0.50578, 0.0013178, 0.22691, 0.25203]
Predicted label: 1
Correct prediction
Energy consumption = 163.523871 pJ
sum error= 37
Actual label: 7
Output voltages: [0.019512, 0.004867, 0.054618, 0.2549, 0.041831, 0.0010851, 0.001339, 0.79879, 0.20904, 0.35477]
Predicted label: 7
Correct prediction
Energy consumption = 148.794424 pJ
sum error= 37
Actual label: 9
Output voltages: [0.7066, 0.011176, 0.0013294, 0.22519, 0.5221, 0.029059, 0.0028514, 0.0019361, 0.068254, 0.79786]
Predicted label: 9
Correct prediction
Energy consumption = 148.915456 pJ
sum error= 37
Actual label: 6
Output voltages: [0.060352, 0.36399, 0.054553, 0.03965, 0.05621, 0.018408, 0.79874, 0.001066, 0.73263, 0.0073698]
Predicted label: 6
Correct prediction
Energy consumption = 157.965954 pJ
sum error= 37
Actual label: 1
Output voltages: [0.035939, 0.79838, 0.032197, 0.06349, 0.04522, 0.0089262, 0.61582, 0.0096527, 0.10671, 0.055707]
Predicted label: 1
Correct prediction
Energy consumption = 161.624324 pJ
sum error= 37
Actual label: 1
Output voltages: [0.012448, 0.79866, 0.48498, 0.34385, 0.072837, 0.0011084, 0.17952, 0.015343, 0.11143, 0.050994]
Predicted label: 1
Correct prediction
Energy consumption = 149.918817 pJ
sum error= 37
Actual label: 2
Output voltages: [0.25341, 0.38909, 0.79877, 0.018825, 0.010178, 0.0013355, 0.11765, 0.071664, 0.30015, 0.013818]
Predicted label: 2
Correct prediction
Energy consumption = 144.344407 pJ
sum error= 37
Actual label: 4
Output voltages: [0.014345, 0.015965, 0.048376, 0.011195, 0.79861, 0.0011908, 0.022317, 0.17888, 0.017197, 0.33693]
Predicted label: 4
Correct prediction
Energy consumption = 154.115983 pJ
sum error= 37
Actual label: 8
Output voltages: [0.24701, 0.0010801, 0.00705, 0.26886, 0.08396, 0.027834, 0.56136, 0.0010676, 0.79685, 0.02259]
Predicted label: 8
Correct prediction
Energy consumption = 145.881060 pJ
sum error= 37
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 84 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 84 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 84 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.01697, 0.79869, 0.15382, 0.17627, 0.059491, 0.0014041, 0.60186, 0.0039897, 0.38244, 0.11202]
Predicted label: 1
Correct prediction
Energy consumption = 180.332798 pJ
sum error= 37
Actual label: 7
Output voltages: [0.10481, 0.010079, 0.22872, 0.030396, 0.034153, 0.0011604, 0.001163, 0.79856, 0.27953, 0.3866]
Predicted label: 7
Correct prediction
Energy consumption = 150.421200 pJ
sum error= 37
Actual label: 7
Output voltages: [0.185, 0.053365, 0.76706, 0.026754, 0.0041501, 0.0014022, 0.013206, 0.78429, 0.087887, 0.16714]
Predicted label: 7
Correct prediction
Energy consumption = 146.846162 pJ
sum error= 37
Actual label: 4
Output voltages: [0.010077, 0.0051243, 0.28838, 0.0064679, 0.79856, 0.002035, 0.15326, 0.020155, 0.035857, 0.089418]
Predicted label: 4
Correct prediction
Energy consumption = 154.143081 pJ
sum error= 37
Actual label: 8
Output voltages: [0.0058588, 0.12957, 0.036337, 0.062782, 0.0010946, 0.021266, 0.0017034, 0.50706, 0.79878, 0.07036]
Predicted label: 8
Correct prediction
Energy consumption = 148.954588 pJ
sum error= 37
Actual label: 0
Output voltages: [0.79876, 0.050075, 0.027399, 0.045692, 0.0021071, 0.037912, 0.1606, 0.043465, 0.29649, 0.027137]
Predicted label: 0
Correct prediction
Energy consumption = 147.832574 pJ
sum error= 37
Actual label: 7
Output voltages: [0.79774, 0.020631, 0.050351, 0.03307, 0.10319, 0.0092599, 0.01525, 0.10106, 0.019267, 0.75181]
Predicted label: 0
Wrong prediction!
Energy consumption = 147.927963 pJ
sum error= 38
Actual label: 3
Output voltages: [0.23643, 0.041736, 0.28984, 0.79876, 0.027478, 0.0012768, 0.0053574, 0.0050238, 0.63732, 0.057863]
Predicted label: 3
Correct prediction
Energy consumption = 140.891743 pJ
sum error= 38
Actual label: 1
Output voltages: [0.011738, 0.79853, 0.061838, 0.18062, 0.097276, 0.0022869, 0.65269, 0.0047239, 0.034452, 0.037123]
Predicted label: 1
Correct prediction
Energy consumption = 158.975805 pJ
sum error= 38
Actual label: 3
Output voltages: [0.31945, 0.023955, 0.3955, 0.79878, 0.057571, 0.0014422, 0.0065713, 0.0034825, 0.64228, 0.011451]
Predicted label: 3
Correct prediction
Energy consumption = 145.414794 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 85 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 85 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 85 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.37628, 0.79869, 0.1723, 0.018411, 0.33384, 0.0020493, 0.16203, 0.001706, 0.28874, 0.056736]
Predicted label: 1
Correct prediction
Energy consumption = 182.109267 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79879, 0.050546, 0.062652, 0.032683, 0.029065, 0.0030273, 0.38238, 0.0075181, 0.33762, 0.057721]
Predicted label: 0
Correct prediction
Energy consumption = 157.036389 pJ
sum error= 38
Actual label: 7
Output voltages: [0.030396, 0.085556, 0.05167, 0.027211, 0.010234, 0.0010695, 0.0021609, 0.79855, 0.11883, 0.035112]
Predicted label: 7
Correct prediction
Energy consumption = 155.441222 pJ
sum error= 38
Actual label: 7
Output voltages: [0.1181, 0.21209, 0.51118, 0.15261, 0.0010828, 0.0010734, 0.0010659, 0.79873, 0.75645, 0.040464]
Predicted label: 7
Correct prediction
Energy consumption = 137.174395 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79842, 0.25878, 0.025675, 0.016149, 0.0027708, 0.0067673, 0.7242, 0.051988, 0.15789, 0.049282]
Predicted label: 0
Correct prediction
Energy consumption = 153.232287 pJ
sum error= 38
Actual label: 3
Output voltages: [0.11645, 0.016599, 0.11067, 0.79875, 0.016862, 0.0030834, 0.0030044, 0.020054, 0.59847, 0.043673]
Predicted label: 3
Correct prediction
Energy consumption = 148.876905 pJ
sum error= 38
Actual label: 5
Output voltages: [0.10937, 0.0010814, 0.0011257, 0.04946, 0.14975, 0.79849, 0.02665, 0.015789, 0.78222, 0.048511]
Predicted label: 5
Correct prediction
Energy consumption = 131.668655 pJ
sum error= 38
Actual label: 5
Output voltages: [0.028737, 0.021801, 0.0011438, 0.68794, 0.0013132, 0.79872, 0.028675, 0.072487, 0.60121, 0.023161]
Predicted label: 5
Correct prediction
Energy consumption = 145.331376 pJ
sum error= 38
Actual label: 2
Output voltages: [0.37656, 0.016817, 0.79876, 0.048029, 0.0080372, 0.001129, 0.030888, 0.03968, 0.48091, 0.010332]
Predicted label: 2
Correct prediction
Energy consumption = 152.823649 pJ
sum error= 38
Actual label: 7
Output voltages: [0.033799, 0.05077, 0.013112, 0.038619, 0.010012, 0.001143, 0.0010846, 0.79872, 0.03001, 0.54623]
Predicted label: 7
Correct prediction
Energy consumption = 156.022515 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 86 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 86 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 86 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.044702, 0.14252, 0.67354, 0.0013359, 0.20614, 0.16638, 0.79871, 0.0014037, 0.48, 0.026017]
Predicted label: 6
Correct prediction
Energy consumption = 162.866116 pJ
sum error= 38
Actual label: 6
Output voltages: [0.42989, 0.011214, 0.22652, 0.0021735, 0.29625, 0.25007, 0.79879, 0.0023932, 0.43678, 0.0087468]
Predicted label: 6
Correct prediction
Energy consumption = 138.857840 pJ
sum error= 38
Actual label: 9
Output voltages: [0.42235, 0.011629, 0.037604, 0.025386, 0.02156, 0.015642, 0.0095461, 0.32984, 0.43303, 0.78836]
Predicted label: 9
Correct prediction
Energy consumption = 159.909770 pJ
sum error= 38
Actual label: 2
Output voltages: [0.69476, 0.0066811, 0.79878, 0.21031, 0.001455, 0.001078, 0.036042, 0.36777, 0.72262, 0.0038533]
Predicted label: 2
Correct prediction
Energy consumption = 147.102828 pJ
sum error= 38
Actual label: 8
Output voltages: [0.056844, 0.042308, 0.27808, 0.02605, 0.025094, 0.026693, 0.023793, 0.002928, 0.79878, 0.22857]
Predicted label: 8
Correct prediction
Energy consumption = 143.758336 pJ
sum error= 38
Actual label: 3
Output voltages: [0.6796, 0.025346, 0.03682, 0.79864, 0.0080252, 0.019941, 0.018826, 0.018674, 0.49874, 0.041301]
Predicted label: 3
Correct prediction
Energy consumption = 152.309968 pJ
sum error= 38
Actual label: 5
Output voltages: [0.016411, 0.0011499, 0.0054435, 0.36149, 0.039614, 0.79785, 0.42562, 0.033098, 0.61639, 0.3274]
Predicted label: 5
Correct prediction
Energy consumption = 147.892708 pJ
sum error= 38
Actual label: 2
Output voltages: [0.49658, 0.19824, 0.79876, 0.026653, 0.012234, 0.0014237, 0.28215, 0.054392, 0.30214, 0.030356]
Predicted label: 2
Correct prediction
Energy consumption = 155.648186 pJ
sum error= 38
Actual label: 2
Output voltages: [0.77878, 0.022458, 0.79807, 0.13005, 0.0038273, 0.0010682, 0.11956, 0.050864, 0.20103, 0.014995]
Predicted label: 2
Correct prediction
Energy consumption = 145.941133 pJ
sum error= 38
Actual label: 5
Output voltages: [0.04932, 0.0024463, 0.0065866, 0.3912, 0.017383, 0.79872, 0.084822, 0.0083013, 0.71702, 0.064668]
Predicted label: 5
Correct prediction
Energy consumption = 150.537916 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 87 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 87 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 87 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.05029, 0.021558, 0.021716, 0.0099581, 0.077155, 0.12601, 0.7983, 0.023871, 0.79041, 0.029788]
Predicted label: 6
Correct prediction
Energy consumption = 165.431603 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79868, 0.024406, 0.055847, 0.02871, 0.030959, 0.0026896, 0.38345, 0.070299, 0.087033, 0.09979]
Predicted label: 0
Correct prediction
Energy consumption = 146.367414 pJ
sum error= 38
Actual label: 8
Output voltages: [0.027218, 0.019836, 0.018454, 0.38711, 0.0030916, 0.01909, 0.0066487, 0.0032303, 0.79873, 0.36733]
Predicted label: 8
Correct prediction
Energy consumption = 158.599013 pJ
sum error= 38
Actual label: 2
Output voltages: [0.24533, 0.045952, 0.79873, 0.063836, 0.031947, 0.0012256, 0.029926, 0.65271, 0.18181, 0.16933]
Predicted label: 2
Correct prediction
Energy consumption = 149.240939 pJ
sum error= 38
Actual label: 9
Output voltages: [0.3295, 0.0085859, 0.018116, 0.050281, 0.52069, 0.0014574, 0.0062078, 0.0021394, 0.46945, 0.79379]
Predicted label: 9
Correct prediction
Energy consumption = 158.268814 pJ
sum error= 38
Actual label: 2
Output voltages: [0.40698, 0.0047486, 0.79877, 0.19992, 0.001086, 0.0011338, 0.01006, 0.29917, 0.74354, 0.0020327]
Predicted label: 2
Correct prediction
Energy consumption = 149.990104 pJ
sum error= 38
Actual label: 8
Output voltages: [0.16768, 0.030242, 0.32791, 0.24828, 0.0027646, 0.27491, 0.017811, 0.0044811, 0.79869, 0.44647]
Predicted label: 8
Correct prediction
Energy consumption = 143.952199 pJ
sum error= 38
Actual label: 8
Output voltages: [0.084123, 0.02063, 0.33382, 0.061542, 0.026445, 0.004489, 0.747, 0.0018024, 0.79871, 0.11514]
Predicted label: 8
Correct prediction
Energy consumption = 142.703297 pJ
sum error= 38
Actual label: 8
Output voltages: [0.20005, 0.012139, 0.57613, 0.033875, 0.047705, 0.015348, 0.30472, 0.0040009, 0.79879, 0.45563]
Predicted label: 8
Correct prediction
Energy consumption = 148.857168 pJ
sum error= 38
Actual label: 8
Output voltages: [0.076365, 0.10245, 0.13572, 0.055229, 0.0017427, 0.026491, 0.052971, 0.0064426, 0.79879, 0.014019]
Predicted label: 8
Correct prediction
Energy consumption = 144.103042 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 88 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 88 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 88 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28613, 0.10831, 0.27572, 0.011319, 0.0077539, 0.033898, 0.001146, 0.79879, 0.24118, 0.74197]
Predicted label: 7
Correct prediction
Energy consumption = 165.514342 pJ
sum error= 38
Actual label: 4
Output voltages: [0.013324, 0.024101, 0.082948, 0.13985, 0.79824, 0.045659, 0.023776, 0.0030345, 0.1709, 0.77231]
Predicted label: 4
Correct prediction
Energy consumption = 160.368831 pJ
sum error= 38
Actual label: 9
Output voltages: [0.3706, 0.019397, 0.01907, 0.058226, 0.32649, 0.015907, 0.02386, 0.024798, 0.11696, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 147.831262 pJ
sum error= 38
Actual label: 3
Output voltages: [0.46336, 0.0015082, 0.25316, 0.79858, 0.017192, 0.31593, 0.01248, 0.025057, 0.039764, 0.1768]
Predicted label: 3
Correct prediction
Energy consumption = 152.207474 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79874, 0.039649, 0.026627, 0.0022325, 0.03958, 0.0046557, 0.47899, 0.046937, 0.4317, 0.11757]
Predicted label: 0
Correct prediction
Energy consumption = 164.592571 pJ
sum error= 38
Actual label: 6
Output voltages: [0.19818, 0.014115, 0.077846, 0.0077079, 0.7233, 0.45972, 0.79879, 0.016984, 0.2235, 0.002948]
Predicted label: 6
Correct prediction
Energy consumption = 142.496264 pJ
sum error= 38
Actual label: 6
Output voltages: [0.23696, 0.20437, 0.23327, 0.038636, 0.09882, 0.33886, 0.79869, 0.0021175, 0.43443, 0.026101]
Predicted label: 6
Correct prediction
Energy consumption = 141.784585 pJ
sum error= 38
Actual label: 3
Output voltages: [0.28041, 0.029288, 0.051378, 0.79864, 0.02716, 0.0048855, 0.011297, 0.023922, 0.48921, 0.086057]
Predicted label: 3
Correct prediction
Energy consumption = 148.494215 pJ
sum error= 38
Actual label: 2
Output voltages: [0.19944, 0.005059, 0.79879, 0.26565, 0.013037, 0.0011014, 0.011341, 0.17217, 0.48067, 0.013394]
Predicted label: 2
Correct prediction
Energy consumption = 143.703827 pJ
sum error= 38
Actual label: 1
Output voltages: [0.0068164, 0.79845, 0.032635, 0.096141, 0.021243, 0.0088172, 0.77185, 0.011314, 0.27817, 0.053661]
Predicted label: 1
Correct prediction
Energy consumption = 161.585867 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 89 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 89 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 89 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.2511, 0.0068493, 0.057212, 0.79872, 0.03196, 0.36019, 0.047263, 0.0096259, 0.60783, 0.032842]
Predicted label: 3
Correct prediction
Energy consumption = 166.183126 pJ
sum error= 38
Actual label: 2
Output voltages: [0.43416, 0.71776, 0.79878, 0.083386, 0.009205, 0.0012412, 0.33476, 0.0022976, 0.52459, 0.27981]
Predicted label: 2
Correct prediction
Energy consumption = 149.641485 pJ
sum error= 38
Actual label: 2
Output voltages: [0.56339, 0.012832, 0.79871, 0.055926, 0.023968, 0.0011497, 0.19271, 0.029212, 0.49411, 0.056057]
Predicted label: 2
Correct prediction
Energy consumption = 144.851848 pJ
sum error= 38
Actual label: 9
Output voltages: [0.5736, 0.013396, 0.0066213, 0.029966, 0.068898, 0.13608, 0.048316, 0.043863, 0.27838, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 154.668544 pJ
sum error= 38
Actual label: 3
Output voltages: [0.45994, 0.021435, 0.45994, 0.79638, 0.011824, 0.0032102, 0.4404, 0.0017174, 0.74283, 0.0028629]
Predicted label: 3
Correct prediction
Energy consumption = 150.698792 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79416, 0.030548, 0.039419, 0.023094, 0.071836, 0.20186, 0.75832, 0.013765, 0.097809, 0.0093659]
Predicted label: 0
Correct prediction
Energy consumption = 159.361635 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79815, 0.022056, 0.028385, 0.0077452, 0.022878, 0.0055151, 0.75411, 0.017164, 0.052347, 0.033544]
Predicted label: 0
Correct prediction
Energy consumption = 138.175163 pJ
sum error= 38
Actual label: 5
Output voltages: [0.011903, 0.001331, 0.0053663, 0.41831, 0.062567, 0.79695, 0.43648, 0.012084, 0.77889, 0.040985]
Predicted label: 5
Correct prediction
Energy consumption = 140.294807 pJ
sum error= 38
Actual label: 7
Output voltages: [0.23046, 0.0060685, 0.16262, 0.66949, 0.0042907, 0.0011113, 0.0010677, 0.79558, 0.45055, 0.10003]
Predicted label: 7
Correct prediction
Energy consumption = 148.812037 pJ
sum error= 38
Actual label: 8
Output voltages: [0.02786, 0.022305, 0.10055, 0.29146, 0.0041997, 0.2457, 0.018499, 0.0034629, 0.79876, 0.16315]
Predicted label: 8
Correct prediction
Energy consumption = 144.048488 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 90 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 90 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 90 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.012081, 0.79468, 0.013803, 0.78917, 0.29313, 0.71509, 0.15742, 0.0018654, 0.017804, 0.13961]
Predicted label: 1
Correct prediction
Energy consumption = 182.621528 pJ
sum error= 38
Actual label: 4
Output voltages: [0.010477, 0.090827, 0.088355, 0.025466, 0.79873, 0.011446, 0.032004, 0.030477, 0.0082706, 0.32805]
Predicted label: 4
Correct prediction
Energy consumption = 159.134111 pJ
sum error= 38
Actual label: 4
Output voltages: [0.010193, 0.013741, 0.01678, 0.0010897, 0.79846, 0.0074315, 0.010998, 0.058735, 0.43592, 0.14985]
Predicted label: 4
Correct prediction
Energy consumption = 152.104883 pJ
sum error= 38
Actual label: 6
Output voltages: [0.26593, 0.022381, 0.20825, 0.013963, 0.2136, 0.46923, 0.79877, 0.001751, 0.45832, 0.013216]
Predicted label: 6
Correct prediction
Energy consumption = 147.433047 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79814, 0.11737, 0.028116, 0.02229, 0.0039375, 0.011024, 0.73766, 0.019554, 0.081335, 0.15138]
Predicted label: 0
Correct prediction
Energy consumption = 156.044855 pJ
sum error= 38
Actual label: 2
Output voltages: [0.54009, 0.023891, 0.79875, 0.032536, 0.020032, 0.0011927, 0.11588, 0.025633, 0.36753, 0.029558]
Predicted label: 2
Correct prediction
Energy consumption = 151.769665 pJ
sum error= 38
Actual label: 9
Output voltages: [0.080454, 0.0010823, 0.034033, 0.057852, 0.76246, 0.011701, 0.0020405, 0.73828, 0.019192, 0.78215]
Predicted label: 9
Correct prediction
Energy consumption = 150.549761 pJ
sum error= 38
Actual label: 1
Output voltages: [0.009391, 0.79879, 0.019358, 0.0085067, 0.073346, 0.001073, 0.52799, 0.014436, 0.36504, 0.10124]
Predicted label: 1
Correct prediction
Energy consumption = 156.336735 pJ
sum error= 38
Actual label: 4
Output voltages: [0.0014689, 0.018521, 0.2153, 0.038392, 0.79869, 0.0011054, 0.016482, 0.042046, 0.019529, 0.036756]
Predicted label: 4
Correct prediction
Energy consumption = 147.838859 pJ
sum error= 38
Actual label: 7
Output voltages: [0.21373, 0.060816, 0.023061, 0.19951, 0.0086126, 0.0030639, 0.0012529, 0.79879, 0.050682, 0.65063]
Predicted label: 7
Correct prediction
Energy consumption = 145.755905 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 91 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 91 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 91 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0014128, 0.016119, 0.049366, 0.0033562, 0.7986, 0.0031956, 0.30686, 0.32672, 0.052013, 0.030131]
Predicted label: 4
Correct prediction
Energy consumption = 169.822374 pJ
sum error= 38
Actual label: 7
Output voltages: [0.31318, 0.20693, 0.59011, 0.14669, 0.0013504, 0.0011602, 0.0019805, 0.79877, 0.35774, 0.026555]
Predicted label: 7
Correct prediction
Energy consumption = 160.174044 pJ
sum error= 38
Actual label: 3
Output voltages: [0.037695, 0.012554, 0.046113, 0.79869, 0.041497, 0.0060558, 0.019979, 0.019723, 0.61194, 0.22379]
Predicted label: 3
Correct prediction
Energy consumption = 143.175691 pJ
sum error= 38
Actual label: 9
Output voltages: [0.44418, 0.0044249, 0.099775, 0.045714, 0.55196, 0.015686, 0.014092, 0.013716, 0.062738, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 144.737118 pJ
sum error= 38
Actual label: 8
Output voltages: [0.032211, 0.028057, 0.081579, 0.35502, 0.0025727, 0.082784, 0.041908, 0.021651, 0.79875, 0.055872]
Predicted label: 8
Correct prediction
Energy consumption = 161.631472 pJ
sum error= 38
Actual label: 8
Output voltages: [0.040046, 0.029256, 0.049635, 0.24663, 0.0023783, 0.019591, 0.041826, 0.021992, 0.79864, 0.058761]
Predicted label: 8
Correct prediction
Energy consumption = 148.461357 pJ
sum error= 38
Actual label: 4
Output voltages: [0.36222, 0.0012135, 0.3372, 0.0011033, 0.79879, 0.0010807, 0.34426, 0.0049643, 0.1731, 0.20938]
Predicted label: 4
Correct prediction
Energy consumption = 152.500759 pJ
sum error= 38
Actual label: 7
Output voltages: [0.039901, 0.089842, 0.025693, 0.10301, 0.012406, 0.0020406, 0.0010659, 0.79855, 0.051105, 0.13311]
Predicted label: 7
Correct prediction
Energy consumption = 156.053526 pJ
sum error= 38
Actual label: 1
Output voltages: [0.27974, 0.79865, 0.31879, 0.090959, 0.17066, 0.0077077, 0.49126, 0.00153, 0.0097755, 0.090333]
Predicted label: 1
Correct prediction
Energy consumption = 163.676748 pJ
sum error= 38
Actual label: 2
Output voltages: [0.48841, 0.01032, 0.79875, 0.20015, 0.002524, 0.001131, 0.061412, 0.24024, 0.60056, 0.045783]
Predicted label: 2
Correct prediction
Energy consumption = 145.548724 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 92 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 92 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 92 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.019712, 0.79839, 0.006183, 0.19203, 0.1517, 0.0014078, 0.097222, 0.033444, 0.12082, 0.38564]
Predicted label: 1
Correct prediction
Energy consumption = 184.865917 pJ
sum error= 38
Actual label: 2
Output voltages: [0.71299, 0.007992, 0.79473, 0.30178, 0.013509, 0.0010915, 0.23285, 0.032055, 0.71298, 0.022276]
Predicted label: 2
Correct prediction
Energy consumption = 150.998852 pJ
sum error= 38
Actual label: 2
Output voltages: [0.20273, 0.39836, 0.79879, 0.095427, 0.0018682, 0.0012605, 0.14361, 0.044411, 0.5457, 0.069173]
Predicted label: 2
Correct prediction
Energy consumption = 140.405472 pJ
sum error= 38
Actual label: 3
Output voltages: [0.19336, 0.022083, 0.053428, 0.79875, 0.005766, 0.0011258, 0.0137, 0.020777, 0.66262, 0.018756]
Predicted label: 3
Correct prediction
Energy consumption = 134.887041 pJ
sum error= 38
Actual label: 2
Output voltages: [0.18253, 0.2863, 0.79873, 0.022668, 0.0011067, 0.0012068, 0.0077364, 0.75917, 0.50162, 0.035634]
Predicted label: 2
Correct prediction
Energy consumption = 140.501385 pJ
sum error= 38
Actual label: 3
Output voltages: [0.30952, 0.012679, 0.214, 0.79871, 0.11506, 0.003399, 0.0051286, 0.018809, 0.42428, 0.041407]
Predicted label: 3
Correct prediction
Energy consumption = 140.784631 pJ
sum error= 38
Actual label: 2
Output voltages: [0.71596, 0.33009, 0.73925, 0.014436, 0.052636, 0.0010708, 0.24526, 0.021068, 0.36145, 0.013762]
Predicted label: 2
Correct prediction
Energy consumption = 152.564784 pJ
sum error= 38
Actual label: 3
Output voltages: [0.50596, 0.022973, 0.15657, 0.79872, 0.0059883, 0.0096423, 0.02275, 0.015436, 0.36792, 0.046911]
Predicted label: 3
Correct prediction
Energy consumption = 150.019620 pJ
sum error= 38
Actual label: 9
Output voltages: [0.22424, 0.0073186, 0.021953, 0.017603, 0.13537, 0.027729, 0.0087106, 0.04054, 0.681, 0.79322]
Predicted label: 9
Correct prediction
Energy consumption = 149.444248 pJ
sum error= 38
Actual label: 1
Output voltages: [0.0075557, 0.79845, 0.0067084, 0.31982, 0.051091, 0.046551, 0.13386, 0.016102, 0.16582, 0.062725]
Predicted label: 1
Correct prediction
Energy consumption = 168.600164 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 93 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 93 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 93 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28846, 0.034207, 0.14096, 0.77274, 0.008081, 0.0011819, 0.001635, 0.74066, 0.37072, 0.2669]
Predicted label: 3
Wrong prediction!
Energy consumption = 170.680819 pJ
sum error= 39
Actual label: 4
Output voltages: [0.23302, 0.01392, 0.059371, 0.045745, 0.75058, 0.0068278, 0.039403, 0.10398, 0.03256, 0.769]
Predicted label: 9
Wrong prediction!
Energy consumption = 157.722484 pJ
sum error= 40
Actual label: 0
Output voltages: [0.79853, 0.10404, 0.22952, 0.01254, 0.0015608, 0.051273, 0.26929, 0.0020425, 0.1764, 0.19933]
Predicted label: 0
Correct prediction
Energy consumption = 159.674129 pJ
sum error= 40
Actual label: 3
Output voltages: [0.62403, 0.02481, 0.033163, 0.79855, 0.043559, 0.037085, 0.04731, 0.018438, 0.62045, 0.02395]
Predicted label: 3
Correct prediction
Energy consumption = 150.640809 pJ
sum error= 40
Actual label: 5
Output voltages: [0.0049171, 0.002225, 0.0054918, 0.19264, 0.054499, 0.78971, 0.18874, 0.10187, 0.30146, 0.54584]
Predicted label: 5
Correct prediction
Energy consumption = 152.610752 pJ
sum error= 40
Actual label: 5
Output voltages: [0.099976, 0.0016414, 0.0010812, 0.45176, 0.010531, 0.79876, 0.045137, 0.023289, 0.78309, 0.0043009]
Predicted label: 5
Correct prediction
Energy consumption = 132.978628 pJ
sum error= 40
Actual label: 8
Output voltages: [0.32623, 0.0012638, 0.19768, 0.15597, 0.029473, 0.75331, 0.011115, 0.0012824, 0.79877, 0.043122]
Predicted label: 8
Correct prediction
Energy consumption = 144.851406 pJ
sum error= 40
Actual label: 6
Output voltages: [0.2097, 0.012914, 0.41238, 0.0010667, 0.30776, 0.028229, 0.79875, 0.0023188, 0.41623, 0.0064622]
Predicted label: 6
Correct prediction
Energy consumption = 149.000835 pJ
sum error= 40
Actual label: 3
Output voltages: [0.0045824, 0.0035409, 0.014594, 0.76378, 0.044401, 0.60536, 0.12654, 0.0012901, 0.785, 0.11575]
Predicted label: 8
Wrong prediction!
Energy consumption = 145.552513 pJ
sum error= 41
Actual label: 2
Output voltages: [0.48998, 0.017391, 0.79861, 0.14269, 0.01074, 0.0012761, 0.16865, 0.38728, 0.47251, 0.0044852]
Predicted label: 2
Correct prediction
Energy consumption = 148.624689 pJ
sum error= 41
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 94 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 94 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 94 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.42354, 0.0061761, 0.048336, 0.038438, 0.061733, 0.73716, 0.79815, 0.0010788, 0.43404, 0.11581]
Predicted label: 6
Correct prediction
Energy consumption = 164.535501 pJ
sum error= 41
Actual label: 7
Output voltages: [0.10793, 0.010636, 0.040084, 0.58041, 0.0079381, 0.00704, 0.0011291, 0.79863, 0.49921, 0.51662]
Predicted label: 7
Correct prediction
Energy consumption = 159.486261 pJ
sum error= 41
Actual label: 6
Output voltages: [0.17749, 0.01972, 0.26451, 0.0015402, 0.31256, 0.35347, 0.79877, 0.0011984, 0.42924, 0.0085759]
Predicted label: 6
Correct prediction
Energy consumption = 150.321672 pJ
sum error= 41
Actual label: 6
Output voltages: [0.16053, 0.0042179, 0.091665, 0.0033937, 0.28237, 0.62217, 0.79828, 0.0079485, 0.57498, 0.0027485]
Predicted label: 6
Correct prediction
Energy consumption = 134.304812 pJ
sum error= 41
Actual label: 3
Output voltages: [0.1922, 0.12143, 0.025181, 0.79864, 0.016995, 0.012238, 0.016993, 0.015726, 0.73321, 0.050837]
Predicted label: 3
Correct prediction
Energy consumption = 158.046817 pJ
sum error= 41
Actual label: 2
Output voltages: [0.5268, 0.14477, 0.79876, 0.10526, 0.03466, 0.0012173, 0.41982, 0.0096246, 0.48626, 0.050535]
Predicted label: 2
Correct prediction
Energy consumption = 143.893251 pJ
sum error= 41
Actual label: 7
Output voltages: [0.043605, 0.30228, 0.44838, 0.33243, 0.0013548, 0.0012597, 0.0013313, 0.79728, 0.039316, 0.31467]
Predicted label: 7
Correct prediction
Energy consumption = 156.401334 pJ
sum error= 41
Actual label: 8
Output voltages: [0.10223, 0.031516, 0.01433, 0.13644, 0.024122, 0.0020961, 0.015465, 0.020341, 0.59263, 0.79654]
Predicted label: 9
Wrong prediction!
Energy consumption = 157.037001 pJ
sum error= 42
Actual label: 1
Output voltages: [0.013216, 0.79871, 0.043232, 0.083506, 0.029451, 0.0013344, 0.3638, 0.003986, 0.045276, 0.032037]
Predicted label: 1
Correct prediction
Energy consumption = 165.661034 pJ
sum error= 42
Actual label: 1
Output voltages: [0.037265, 0.79866, 0.056314, 0.081816, 0.098607, 0.0017194, 0.2762, 0.0038244, 0.14456, 0.045292]
Predicted label: 1
Correct prediction
Energy consumption = 150.055058 pJ
sum error= 42
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 95 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 95 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 95 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.050393, 0.0057939, 0.5841, 0.30013, 0.022312, 0.001202, 0.0013979, 0.79018, 0.50046, 0.068663]
Predicted label: 7
Correct prediction
Energy consumption = 168.132744 pJ
sum error= 42
Actual label: 5
Output voltages: [0.046994, 0.0010745, 0.0010667, 0.011995, 0.16882, 0.78996, 0.037987, 0.063655, 0.75076, 0.40413]
Predicted label: 5
Correct prediction
Energy consumption = 156.914277 pJ
sum error= 42
Actual label: 6
Output voltages: [0.11181, 0.027372, 0.2192, 0.0013181, 0.16671, 0.40886, 0.79874, 0.0081005, 0.40392, 0.01263]
Predicted label: 6
Correct prediction
Energy consumption = 146.614324 pJ
sum error= 42
Actual label: 4
Output voltages: [0.0047861, 0.016048, 0.095323, 0.011167, 0.79868, 0.0016457, 0.037079, 0.022021, 0.034213, 0.023505]
Predicted label: 4
Correct prediction
Energy consumption = 145.732616 pJ
sum error= 42
Actual label: 9
Output voltages: [0.48149, 0.021816, 0.024156, 0.045771, 0.045182, 0.05164, 0.0016795, 0.038501, 0.27164, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 151.278274 pJ
sum error= 42
Actual label: 5
Output voltages: [0.035573, 0.0011376, 0.0096329, 0.38741, 0.025041, 0.79235, 0.23382, 0.021685, 0.78593, 0.016396]
Predicted label: 5
Correct prediction
Energy consumption = 147.502907 pJ
sum error= 42
Actual label: 1
Output voltages: [0.046771, 0.79143, 0.40254, 0.18576, 0.0096843, 0.0024772, 0.60449, 0.0021587, 0.44769, 0.0012841]
Predicted label: 1
Correct prediction
Energy consumption = 153.786479 pJ
sum error= 42
Actual label: 3
Output voltages: [0.040666, 0.0023726, 0.042373, 0.79867, 0.067165, 0.042363, 0.13201, 0.0076453, 0.55488, 0.074894]
Predicted label: 3
Correct prediction
Energy consumption = 141.538138 pJ
sum error= 42
Actual label: 3
Output voltages: [0.66776, 0.040855, 0.067096, 0.79877, 0.0087436, 0.010431, 0.0049308, 0.029434, 0.16648, 0.014617]
Predicted label: 3
Correct prediction
Energy consumption = 142.313190 pJ
sum error= 42
Actual label: 4
Output voltages: [0.0025052, 0.093329, 0.086799, 0.40862, 0.79878, 0.0052345, 0.097083, 0.010997, 0.025952, 0.46313]
Predicted label: 4
Correct prediction
Energy consumption = 151.754203 pJ
sum error= 42
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 96 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 96 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 96 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.16868, 0.0010663, 0.031831, 0.098549, 0.0065635, 0.016377, 0.0010686, 0.64279, 0.77838, 0.77224]
Predicted label: 8
Wrong prediction!
Energy consumption = 164.008497 pJ
sum error= 43
Actual label: 8
Output voltages: [0.010857, 0.036585, 0.082223, 0.29044, 0.0027599, 0.01412, 0.0078824, 0.0069018, 0.79877, 0.066406]
Predicted label: 8
Correct prediction
Energy consumption = 143.583276 pJ
sum error= 43
Actual label: 9
Output voltages: [0.27535, 0.0014073, 0.01107, 0.0066359, 0.2655, 0.011145, 0.0025562, 0.21215, 0.30972, 0.79782]
Predicted label: 9
Correct prediction
Energy consumption = 151.141714 pJ
sum error= 43
Actual label: 1
Output voltages: [0.012481, 0.79872, 0.0014126, 0.031098, 0.62336, 0.0012457, 0.24124, 0.0025127, 0.29624, 0.43534]
Predicted label: 1
Correct prediction
Energy consumption = 161.662575 pJ
sum error= 43
Actual label: 1
Output voltages: [0.049737, 0.79874, 0.031006, 0.0030674, 0.17903, 0.0019571, 0.61059, 0.0064637, 0.34306, 0.01246]
Predicted label: 1
Correct prediction
Energy consumption = 148.038178 pJ
sum error= 43
Actual label: 6
Output voltages: [0.79165, 0.20915, 0.020316, 0.011953, 0.066066, 0.36994, 0.79404, 0.098426, 0.37476, 0.0010822]
Predicted label: 6
Correct prediction
Energy consumption = 142.683339 pJ
sum error= 43
Actual label: 9
Output voltages: [0.054238, 0.0048394, 0.01754, 0.022874, 0.017449, 0.0026055, 0.0010881, 0.080075, 0.7695, 0.78834]
Predicted label: 9
Correct prediction
Energy consumption = 152.028836 pJ
sum error= 43
Actual label: 1
Output voltages: [0.02313, 0.79844, 0.035244, 0.04077, 0.0074573, 0.0037281, 0.65651, 0.002238, 0.27121, 0.036032]
Predicted label: 1
Correct prediction
Energy consumption = 165.057187 pJ
sum error= 43
Actual label: 4
Output voltages: [0.0085656, 0.0081331, 0.51708, 0.002466, 0.79861, 0.0010866, 0.045036, 0.032077, 0.014516, 0.35406]
Predicted label: 4
Correct prediction
Energy consumption = 156.403254 pJ
sum error= 43
Actual label: 4
Output voltages: [0.0033048, 0.0013309, 0.026427, 0.31785, 0.79779, 0.0051141, 0.019849, 0.036392, 0.39118, 0.032245]
Predicted label: 4
Correct prediction
Energy consumption = 140.865433 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 97 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 97 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 97 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.0024751, 0.0010968, 0.0048732, 0.23903, 0.17001, 0.79336, 0.12172, 0.026431, 0.74534, 0.17616]
Predicted label: 5
Correct prediction
Energy consumption = 158.412693 pJ
sum error= 43
Actual label: 4
Output voltages: [0.0023712, 0.014172, 0.43725, 0.02602, 0.79873, 0.035514, 0.038225, 0.023036, 0.050604, 0.054272]
Predicted label: 4
Correct prediction
Energy consumption = 154.746455 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79876, 0.11922, 0.019949, 0.010731, 0.022349, 0.020542, 0.5434, 0.0069067, 0.047694, 0.035641]
Predicted label: 0
Correct prediction
Energy consumption = 153.403836 pJ
sum error= 43
Actual label: 6
Output voltages: [0.033981, 0.32907, 0.41364, 0.0014976, 0.26105, 0.18107, 0.79866, 0.0016345, 0.36862, 0.020126]
Predicted label: 6
Correct prediction
Energy consumption = 144.103205 pJ
sum error= 43
Actual label: 2
Output voltages: [0.21223, 0.043982, 0.79879, 0.086541, 0.015339, 0.0013428, 0.17034, 0.031358, 0.44169, 0.024879]
Predicted label: 2
Correct prediction
Energy consumption = 154.004791 pJ
sum error= 43
Actual label: 2
Output voltages: [0.56622, 0.0051833, 0.79758, 0.40803, 0.002577, 0.0010992, 0.043833, 0.020085, 0.52605, 0.0051026]
Predicted label: 2
Correct prediction
Energy consumption = 137.918964 pJ
sum error= 43
Actual label: 3
Output voltages: [0.037015, 0.26329, 0.34107, 0.79879, 0.052784, 0.0010708, 0.0023333, 0.0012522, 0.5876, 0.14425]
Predicted label: 3
Correct prediction
Energy consumption = 143.378297 pJ
sum error= 43
Actual label: 1
Output voltages: [0.010945, 0.7986, 0.33451, 0.02569, 0.25156, 0.0085718, 0.79604, 0.0035605, 0.011234, 0.036541]
Predicted label: 1
Correct prediction
Energy consumption = 164.300708 pJ
sum error= 43
Actual label: 5
Output voltages: [0.054806, 0.0048265, 0.036173, 0.43316, 0.018302, 0.79866, 0.020772, 0.011596, 0.77293, 0.24526]
Predicted label: 5
Correct prediction
Energy consumption = 153.215561 pJ
sum error= 43
Actual label: 1
Output voltages: [0.0048359, 0.79851, 0.030714, 0.064237, 0.009514, 0.0010945, 0.41145, 0.0045781, 0.23193, 0.20693]
Predicted label: 1
Correct prediction
Energy consumption = 159.042868 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 98 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 98 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 98 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.64383, 0.016514, 0.79879, 0.10459, 0.033807, 0.001122, 0.18452, 0.046163, 0.46707, 0.029605]
Predicted label: 2
Correct prediction
Energy consumption = 169.395278 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79856, 0.037666, 0.021183, 0.028325, 0.020117, 0.0067352, 0.72294, 0.016089, 0.22, 0.045925]
Predicted label: 0
Correct prediction
Energy consumption = 151.562376 pJ
sum error= 43
Actual label: 3
Output voltages: [0.15143, 0.034239, 0.12748, 0.79879, 0.010238, 0.003085, 0.024311, 0.0021536, 0.70367, 0.044833]
Predicted label: 3
Correct prediction
Energy consumption = 154.480216 pJ
sum error= 43
Actual label: 8
Output voltages: [0.27945, 0.039505, 0.30872, 0.128, 0.027711, 0.025813, 0.05033, 0.0013053, 0.79869, 0.077557]
Predicted label: 8
Correct prediction
Energy consumption = 149.591936 pJ
sum error= 43
Actual label: 1
Output voltages: [0.050452, 0.79858, 0.56512, 0.030336, 0.10236, 0.0039912, 0.65594, 0.0010837, 0.016145, 0.12891]
Predicted label: 1
Correct prediction
Energy consumption = 163.621765 pJ
sum error= 43
Actual label: 2
Output voltages: [0.24454, 0.024558, 0.79878, 0.11364, 0.022007, 0.0012634, 0.32926, 0.030252, 0.54611, 0.023072]
Predicted label: 2
Correct prediction
Energy consumption = 150.193533 pJ
sum error= 43
Actual label: 6
Output voltages: [0.038803, 0.1568, 0.38216, 0.0015799, 0.1709, 0.099909, 0.79876, 0.0011168, 0.4921, 0.029752]
Predicted label: 6
Correct prediction
Energy consumption = 151.784854 pJ
sum error= 43
Actual label: 7
Output voltages: [0.036019, 0.0022305, 0.023541, 0.16783, 0.035883, 0.021192, 0.0011264, 0.79858, 0.6237, 0.1369]
Predicted label: 7
Correct prediction
Energy consumption = 153.398389 pJ
sum error= 43
Actual label: 1
Output voltages: [0.0046179, 0.79873, 0.019345, 0.039186, 0.52731, 0.0038719, 0.009944, 0.18864, 0.036113, 0.43755]
Predicted label: 1
Correct prediction
Energy consumption = 160.423682 pJ
sum error= 43
Actual label: 6
Output voltages: [0.38786, 0.045152, 0.34524, 0.0022683, 0.24683, 0.039193, 0.79875, 0.0034348, 0.33919, 0.0062311]
Predicted label: 6
Correct prediction
Energy consumption = 153.685385 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 99 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 99 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 99 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.56591, 0.023815, 0.78695, 0.52987, 0.095125, 0.0012209, 0.029448, 0.046459, 0.67865, 0.027954]
Predicted label: 2
Correct prediction
Energy consumption = 169.895601 pJ
sum error= 43
Actual label: 3
Output voltages: [0.16212, 0.020704, 0.032553, 0.7987, 0.0062834, 0.035852, 0.0040538, 0.038791, 0.71125, 0.016951]
Predicted label: 3
Correct prediction
Energy consumption = 137.871482 pJ
sum error= 43
Actual label: 9
Output voltages: [0.36436, 0.0010824, 0.033597, 0.009949, 0.2948, 0.0012578, 0.0010664, 0.37512, 0.56311, 0.73736]
Predicted label: 9
Correct prediction
Energy consumption = 155.683616 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79864, 0.04003, 0.053105, 0.035078, 0.064057, 0.022602, 0.11961, 0.026685, 0.1884, 0.051276]
Predicted label: 0
Correct prediction
Energy consumption = 154.165332 pJ
sum error= 43
Actual label: 1
Output voltages: [0.0037798, 0.79874, 0.31736, 0.23725, 0.0030034, 0.0025311, 0.017719, 0.046443, 0.65121, 0.016521]
Predicted label: 1
Correct prediction
Energy consumption = 167.258824 pJ
sum error= 43
Actual label: 2
Output voltages: [0.76514, 0.018106, 0.79871, 0.29123, 0.0023427, 0.0015427, 0.046115, 0.28962, 0.35019, 0.018994]
Predicted label: 2
Correct prediction
Energy consumption = 151.564170 pJ
sum error= 43
Actual label: 2
Output voltages: [0.48721, 0.16529, 0.79868, 0.044661, 0.02521, 0.0011689, 0.42559, 0.037199, 0.66654, 0.036644]
Predicted label: 2
Correct prediction
Energy consumption = 131.653806 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79874, 0.092696, 0.027295, 0.014507, 0.013965, 0.0076414, 0.45747, 0.010244, 0.087368, 0.030648]
Predicted label: 0
Correct prediction
Energy consumption = 143.890309 pJ
sum error= 43
Actual label: 8
Output voltages: [0.015599, 0.055894, 0.052673, 0.017243, 0.0088413, 0.028909, 0.027765, 0.032427, 0.79868, 0.032058]
Predicted label: 8
Correct prediction
Energy consumption = 141.461417 pJ
sum error= 43
Actual label: 9
Output voltages: [0.61532, 0.0020472, 0.23017, 0.043013, 0.21637, 0.059733, 0.035488, 0.36369, 0.048833, 0.79807]
Predicted label: 9
Correct prediction
Energy consumption = 161.017876 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 100 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 100 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 100 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.50385, 0.029796, 0.013042, 0.2048, 0.53064, 0.010041, 0.011551, 0.0019111, 0.098494, 0.7984]
Predicted label: 9
Correct prediction
Energy consumption = 167.669502 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79726, 0.12379, 0.013761, 0.012424, 0.039062, 0.016686, 0.77787, 0.018802, 0.071328, 0.022747]
Predicted label: 0
Correct prediction
Energy consumption = 156.921793 pJ
sum error= 43
Actual label: 2
Output voltages: [0.21102, 0.046991, 0.79878, 0.1446, 0.0079798, 0.0010892, 0.34861, 0.041481, 0.78882, 0.019816]
Predicted label: 2
Correct prediction
Energy consumption = 152.455053 pJ
sum error= 43
Actual label: 5
Output voltages: [0.00371, 0.00107, 0.0077177, 0.74099, 0.081501, 0.76104, 0.29711, 0.030323, 0.64092, 0.15052]
Predicted label: 5
Correct prediction
Energy consumption = 148.592792 pJ
sum error= 43
Actual label: 1
Output voltages: [0.34928, 0.79871, 0.017562, 0.2231, 0.51667, 0.0056959, 0.028146, 0.013732, 0.05927, 0.28232]
Predicted label: 1
Correct prediction
Energy consumption = 164.720065 pJ
sum error= 43
Actual label: 9
Output voltages: [0.046137, 0.005127, 0.0098524, 0.10591, 0.055597, 0.0013247, 0.0072817, 0.19773, 0.47438, 0.79839]
Predicted label: 9
Correct prediction
Energy consumption = 159.620003 pJ
sum error= 43
Actual label: 7
Output voltages: [0.075226, 0.028383, 0.0054028, 0.1878, 0.015657, 0.010143, 0.0010659, 0.79878, 0.15176, 0.57185]
Predicted label: 7
Correct prediction
Energy consumption = 154.341934 pJ
sum error= 43
Actual label: 8
Output voltages: [0.026165, 0.032559, 0.0097446, 0.43468, 0.0071843, 0.017798, 0.025293, 0.0016466, 0.79878, 0.50508]
Predicted label: 8
Correct prediction
Energy consumption = 152.500775 pJ
sum error= 43
Actual label: 1
Output voltages: [0.011885, 0.79843, 0.037455, 0.067808, 0.057192, 0.012278, 0.55116, 0.0016057, 0.14534, 0.42172]
Predicted label: 1
Correct prediction
Energy consumption = 161.990167 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79832, 0.031976, 0.0088481, 0.0056568, 0.0053795, 0.18109, 0.5842, 0.0048319, 0.21316, 0.048369]
Predicted label: 0
Correct prediction
Energy consumption = 151.714732 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 101 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 101 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 101 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.013135, 0.0042798, 0.30747, 0.0016675, 0.79576, 0.0011622, 0.0097039, 0.44647, 0.33986, 0.050023]
Predicted label: 4
Correct prediction
Energy consumption = 173.688693 pJ
sum error= 43
Actual label: 1
Output voltages: [0.027903, 0.79855, 0.081638, 0.052798, 0.023757, 0.0047439, 0.47325, 0.0026715, 0.077574, 0.057227]
Predicted label: 1
Correct prediction
Energy consumption = 163.394815 pJ
sum error= 43
Actual label: 7
Output voltages: [0.22173, 0.011541, 0.043755, 0.67423, 0.14803, 0.0010849, 0.001159, 0.79437, 0.28345, 0.43887]
Predicted label: 7
Correct prediction
Energy consumption = 149.016623 pJ
sum error= 43
Actual label: 9
Output voltages: [0.44273, 0.014966, 0.029126, 0.021802, 0.60789, 0.028913, 0.022203, 0.020357, 0.36833, 0.79798]
Predicted label: 9
Correct prediction
Energy consumption = 152.621576 pJ
sum error= 43
Actual label: 6
Output voltages: [0.7543, 0.001146, 0.0040711, 0.38113, 0.012521, 0.79857, 0.19891, 0.01711, 0.74633, 0.0070944]
Predicted label: 5
Wrong prediction!
Energy consumption = 142.111676 pJ
sum error= 44
Actual label: 4
Output voltages: [0.010539, 0.035986, 0.049966, 0.018639, 0.79879, 0.0010961, 0.0043969, 0.056852, 0.43413, 0.022521]
Predicted label: 4
Correct prediction
Energy consumption = 158.647948 pJ
sum error= 44
Actual label: 2
Output voltages: [0.3077, 0.011205, 0.79879, 0.31066, 0.0057848, 0.0010785, 0.036749, 0.014545, 0.51647, 0.014393]
Predicted label: 2
Correct prediction
Energy consumption = 147.165257 pJ
sum error= 44
Actual label: 6
Output voltages: [0.046153, 0.017038, 0.77687, 0.0012063, 0.11144, 0.0055993, 0.79799, 0.0012641, 0.028959, 0.0054695]
Predicted label: 6
Correct prediction
Energy consumption = 143.361753 pJ
sum error= 44
Actual label: 8
Output voltages: [0.055401, 0.0032579, 0.033608, 0.10512, 0.011558, 0.18886, 0.02276, 0.0012412, 0.79878, 0.28491]
Predicted label: 8
Correct prediction
Energy consumption = 154.541758 pJ
sum error= 44
Actual label: 1
Output voltages: [0.028288, 0.79879, 0.0068745, 0.020613, 0.40119, 0.0038101, 0.18204, 0.0093815, 0.070028, 0.020683]
Predicted label: 1
Correct prediction
Energy consumption = 153.195108 pJ
sum error= 44
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 102 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 102 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 102 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.14575, 0.0089541, 0.34366, 0.79879, 0.021371, 0.0011771, 0.011708, 0.0028255, 0.72222, 0.026429]
Predicted label: 3
Correct prediction
Energy consumption = 160.340743 pJ
sum error= 44
Actual label: 7
Output voltages: [0.75545, 0.063494, 0.3568, 0.0016405, 0.001543, 0.002283, 0.0040301, 0.79572, 0.76981, 0.23158]
Predicted label: 7
Correct prediction
Energy consumption = 137.731853 pJ
sum error= 44
Actual label: 5
Output voltages: [0.034755, 0.0010845, 0.0039971, 0.28381, 0.23937, 0.79875, 0.03655, 0.039028, 0.77494, 0.31917]
Predicted label: 5
Correct prediction
Energy consumption = 147.329181 pJ
sum error= 44
Actual label: 4
Output voltages: [0.018032, 0.013701, 0.10131, 0.0084552, 0.79874, 0.0054217, 0.41196, 0.044992, 0.034279, 0.035152]
Predicted label: 4
Correct prediction
Energy consumption = 155.035900 pJ
sum error= 44
Actual label: 4
Output voltages: [0.0092246, 0.021643, 0.080774, 0.014573, 0.79857, 0.033274, 0.062921, 0.19782, 0.11338, 0.015336]
Predicted label: 4
Correct prediction
Energy consumption = 144.437616 pJ
sum error= 44
Actual label: 1
Output voltages: [0.029585, 0.79868, 0.047735, 0.072246, 0.081784, 0.0011802, 0.7257, 0.0039999, 0.1702, 0.027217]
Predicted label: 1
Correct prediction
Energy consumption = 155.594901 pJ
sum error= 44
Actual label: 8
Output voltages: [0.097311, 0.0013116, 0.0024421, 0.17675, 0.0073292, 0.75209, 0.037412, 0.0042508, 0.79872, 0.050442]
Predicted label: 8
Correct prediction
Energy consumption = 156.872492 pJ
sum error= 44
Actual label: 1
Output voltages: [0.075645, 0.79869, 0.34435, 0.0338, 0.071306, 0.0011496, 0.41233, 0.0038631, 0.13104, 0.027603]
Predicted label: 1
Correct prediction
Energy consumption = 167.608877 pJ
sum error= 44
Actual label: 3
Output voltages: [0.13557, 0.0070608, 0.14371, 0.79838, 0.03613, 0.016972, 0.012249, 0.0069464, 0.7375, 0.056275]
Predicted label: 3
Correct prediction
Energy consumption = 150.667408 pJ
sum error= 44
Actual label: 8
Output voltages: [0.028681, 0.2444, 0.022962, 0.069099, 0.010131, 0.017775, 0.010715, 0.055188, 0.79871, 0.0624]
Predicted label: 8
Correct prediction
Energy consumption = 148.494648 pJ
sum error= 44
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 103 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 103 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 103 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0030104, 0.79854, 0.11931, 0.046158, 0.010762, 0.001106, 0.32424, 0.0049146, 0.42767, 0.020025]
Predicted label: 1
Correct prediction
Energy consumption = 179.256386 pJ
sum error= 44
Actual label: 2
Output voltages: [0.048041, 0.015686, 0.79877, 0.085677, 0.07783, 0.0011324, 0.048922, 0.059441, 0.34183, 0.028557]
Predicted label: 2
Correct prediction
Energy consumption = 139.310890 pJ
sum error= 44
Actual label: 5
Output voltages: [0.041557, 0.0011027, 0.012375, 0.057623, 0.03404, 0.79879, 0.43925, 0.034757, 0.79302, 0.015857]
Predicted label: 5
Correct prediction
Energy consumption = 152.165951 pJ
sum error= 44
Actual label: 8
Output voltages: [0.048835, 0.74685, 0.052858, 0.18351, 0.019055, 0.0011042, 0.070834, 0.0011148, 0.76337, 0.2117]
Predicted label: 8
Correct prediction
Energy consumption = 159.022944 pJ
sum error= 44
Actual label: 0
Output voltages: [0.79876, 0.22151, 0.19581, 0.019018, 0.0040021, 0.0053139, 0.31114, 0.00983, 0.21237, 0.11809]
Predicted label: 0
Correct prediction
Energy consumption = 151.760997 pJ
sum error= 44
Actual label: 6
Output voltages: [0.058817, 0.025058, 0.35313, 0.0013623, 0.33431, 0.017044, 0.79875, 0.0035533, 0.09746, 0.022118]
Predicted label: 6
Correct prediction
Energy consumption = 144.793573 pJ
sum error= 44
Actual label: 2
Output voltages: [0.36278, 0.28021, 0.79878, 0.022636, 0.012924, 0.0013936, 0.30922, 0.072749, 0.27875, 0.031299]
Predicted label: 2
Correct prediction
Energy consumption = 151.627862 pJ
sum error= 44
Actual label: 1
Output voltages: [0.0098521, 0.79841, 0.11292, 0.015625, 0.0080679, 0.003485, 0.57943, 0.032093, 0.41153, 0.036958]
Predicted label: 1
Correct prediction
Energy consumption = 160.759887 pJ
sum error= 44
Actual label: 1
Output voltages: [0.072282, 0.79848, 0.026112, 0.12027, 0.0046641, 0.0032108, 0.67864, 0.0012528, 0.070121, 0.055048]
Predicted label: 1
Correct prediction
Energy consumption = 150.889152 pJ
sum error= 44
Actual label: 7
Output voltages: [0.0012162, 0.72097, 0.62109, 0.76587, 0.58435, 0.0010797, 0.12725, 0.067343, 0.0033221, 0.27661]
Predicted label: 3
Wrong prediction!
Energy consumption = 147.665909 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 104 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 104 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 104 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.041559, 0.7984, 0.029498, 0.19824, 0.021783, 0.015483, 0.71663, 0.0079872, 0.020121, 0.053495]
Predicted label: 1
Correct prediction
Energy consumption = 182.018247 pJ
sum error= 45
Actual label: 5
Output voltages: [0.0032642, 0.001132, 0.0027606, 0.065012, 0.20068, 0.79869, 0.35137, 0.0084654, 0.78041, 0.036664]
Predicted label: 5
Correct prediction
Energy consumption = 148.116104 pJ
sum error= 45
Actual label: 3
Output voltages: [0.04762, 0.012535, 0.075102, 0.79873, 0.26576, 0.030841, 0.042982, 0.0094149, 0.42992, 0.2077]
Predicted label: 3
Correct prediction
Energy consumption = 148.232775 pJ
sum error= 45
Actual label: 4
Output voltages: [0.028047, 0.018226, 0.17135, 0.0015213, 0.79872, 0.03302, 0.016251, 0.13795, 0.28593, 0.04712]
Predicted label: 4
Correct prediction
Energy consumption = 155.125356 pJ
sum error= 45
Actual label: 6
Output voltages: [0.5555, 0.13268, 0.51792, 0.0027266, 0.0061667, 0.001066, 0.76295, 0.0067732, 0.71588, 0.026052]
Predicted label: 6
Correct prediction
Energy consumption = 150.977353 pJ
sum error= 45
Actual label: 9
Output voltages: [0.22827, 0.14757, 0.14406, 0.049387, 0.74538, 0.0014958, 0.0010774, 0.0032924, 0.18575, 0.78067]
Predicted label: 9
Correct prediction
Energy consumption = 160.877749 pJ
sum error= 45
Actual label: 5
Output voltages: [0.040519, 0.0010707, 0.0020567, 0.38525, 0.046481, 0.79845, 0.041978, 0.010736, 0.7311, 0.32305]
Predicted label: 5
Correct prediction
Energy consumption = 148.598223 pJ
sum error= 45
Actual label: 0
Output voltages: [0.79879, 0.049847, 0.02821, 0.010787, 0.018441, 0.0053464, 0.74164, 0.010713, 0.19022, 0.098383]
Predicted label: 0
Correct prediction
Energy consumption = 141.998708 pJ
sum error= 45
Actual label: 9
Output voltages: [0.025341, 0.0023465, 0.017748, 0.05876, 0.4812, 0.26685, 0.28378, 0.027868, 0.034255, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 144.745599 pJ
sum error= 45
Actual label: 2
Output voltages: [0.56643, 0.016229, 0.79874, 0.15857, 0.030354, 0.0011455, 0.27426, 0.037908, 0.41342, 0.01864]
Predicted label: 2
Correct prediction
Energy consumption = 141.917915 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 105 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 105 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 105 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.63675, 0.0012001, 0.79879, 0.18667, 0.010785, 0.001072, 0.0040018, 0.24469, 0.76367, 0.018473]
Predicted label: 2
Correct prediction
Energy consumption = 158.084544 pJ
sum error= 45
Actual label: 4
Output voltages: [0.011498, 0.095166, 0.035877, 0.009114, 0.79877, 0.0030875, 0.18565, 0.37061, 0.041992, 0.04386]
Predicted label: 4
Correct prediction
Energy consumption = 153.218507 pJ
sum error= 45
Actual label: 8
Output voltages: [0.042349, 0.019609, 0.045705, 0.25247, 0.018821, 0.053803, 0.04784, 0.0028505, 0.79879, 0.25387]
Predicted label: 8
Correct prediction
Energy consumption = 150.488745 pJ
sum error= 45
Actual label: 2
Output voltages: [0.75266, 0.0063228, 0.79878, 0.23471, 0.016619, 0.0010659, 0.029446, 0.1165, 0.43889, 0.0077681]
Predicted label: 2
Correct prediction
Energy consumption = 150.360869 pJ
sum error= 45
Actual label: 1
Output voltages: [0.0075889, 0.79845, 0.04274, 0.055904, 0.013558, 0.0035609, 0.58868, 0.020372, 0.13558, 0.025671]
Predicted label: 1
Correct prediction
Energy consumption = 163.689707 pJ
sum error= 45
Actual label: 7
Output voltages: [0.085323, 0.044295, 0.060348, 0.046022, 0.0030727, 0.001133, 0.0010688, 0.79872, 0.14609, 0.29074]
Predicted label: 7
Correct prediction
Energy consumption = 161.591369 pJ
sum error= 45
Actual label: 2
Output voltages: [0.6109, 0.049665, 0.79876, 0.22558, 0.026994, 0.0011683, 0.16536, 0.027607, 0.69726, 0.028217]
Predicted label: 2
Correct prediction
Energy consumption = 146.224643 pJ
sum error= 45
Actual label: 4
Output voltages: [0.0056243, 0.0090236, 0.27983, 0.0042431, 0.79875, 0.0014815, 0.35749, 0.082707, 0.017178, 0.054159]
Predicted label: 4
Correct prediction
Energy consumption = 152.082017 pJ
sum error= 45
Actual label: 9
Output voltages: [0.49659, 0.017895, 0.037575, 0.017272, 0.16444, 0.0069268, 0.0011056, 0.032773, 0.30362, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 150.523221 pJ
sum error= 45
Actual label: 4
Output voltages: [0.019284, 0.027818, 0.13774, 0.020961, 0.79879, 0.0011342, 0.69032, 0.047151, 0.0040721, 0.033559]
Predicted label: 4
Correct prediction
Energy consumption = 154.842460 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 106 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 106 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 106 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.050028, 0.011664, 0.4157, 0.023649, 0.79872, 0.0011109, 0.28334, 0.013071, 0.01275, 0.4659]
Predicted label: 4
Correct prediction
Energy consumption = 166.928907 pJ
sum error= 45
Actual label: 0
Output voltages: [0.79867, 0.070311, 0.015813, 0.032028, 0.021692, 0.020865, 0.37642, 0.015206, 0.11685, 0.037269]
Predicted label: 0
Correct prediction
Energy consumption = 152.091830 pJ
sum error= 45
Actual label: 3
Output voltages: [0.0041101, 0.0087589, 0.093128, 0.7982, 0.0022034, 0.0035441, 0.0010836, 0.4044, 0.74114, 0.413]
Predicted label: 3
Correct prediction
Energy consumption = 151.936428 pJ
sum error= 45
Actual label: 9
Output voltages: [0.17625, 0.028952, 0.027364, 0.12767, 0.31507, 0.010278, 0.005475, 0.019132, 0.25828, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 145.503631 pJ
sum error= 45
Actual label: 2
Output voltages: [0.30939, 0.0089099, 0.79639, 0.75105, 0.016177, 0.0012314, 0.030114, 0.41529, 0.43493, 0.010311]
Predicted label: 2
Correct prediction
Energy consumption = 149.568714 pJ
sum error= 45
Actual label: 2
Output voltages: [0.28049, 0.028976, 0.79874, 0.067826, 0.022385, 0.0012875, 0.32468, 0.033005, 0.54646, 0.025674]
Predicted label: 2
Correct prediction
Energy consumption = 137.011343 pJ
sum error= 45
Actual label: 3
Output voltages: [0.036517, 0.14294, 0.027846, 0.79863, 0.017238, 0.0016722, 0.005942, 0.24543, 0.10414, 0.11793]
Predicted label: 3
Correct prediction
Energy consumption = 150.550991 pJ
sum error= 45
Actual label: 3
Output voltages: [0.042942, 0.02965, 0.046635, 0.79875, 0.017228, 0.011324, 0.0057995, 0.015876, 0.58596, 0.0588]
Predicted label: 3
Correct prediction
Energy consumption = 136.614570 pJ
sum error= 45
Actual label: 8
Output voltages: [0.0011646, 0.7892, 0.021175, 0.031748, 0.36763, 0.2597, 0.041781, 0.0017805, 0.79741, 0.029231]
Predicted label: 8
Correct prediction
Energy consumption = 150.570284 pJ
sum error= 45
Actual label: 3
Output voltages: [0.042748, 0.0066226, 0.089521, 0.7987, 0.0061466, 0.032035, 0.0058782, 0.0078343, 0.7735, 0.19689]
Predicted label: 3
Correct prediction
Energy consumption = 145.305398 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 107 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 107 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 107 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.32301, 0.0011271, 0.0096313, 0.30113, 0.01081, 0.7976, 0.036893, 0.047572, 0.78688, 0.052819]
Predicted label: 5
Correct prediction
Energy consumption = 154.438971 pJ
sum error= 45
Actual label: 7
Output voltages: [0.2261, 0.17662, 0.12689, 0.030975, 0.019622, 0.0010809, 0.0010841, 0.79868, 0.1161, 0.11226]
Predicted label: 7
Correct prediction
Energy consumption = 156.804783 pJ
sum error= 45
Actual label: 3
Output voltages: [0.42997, 0.01587, 0.0367, 0.79865, 0.0016694, 0.56297, 0.0040193, 0.073186, 0.7601, 0.19277]
Predicted label: 3
Correct prediction
Energy consumption = 151.213566 pJ
sum error= 45
Actual label: 5
Output voltages: [0.019142, 0.0010683, 0.0012589, 0.18543, 0.12419, 0.79698, 0.10114, 0.0051843, 0.7756, 0.17916]
Predicted label: 5
Correct prediction
Energy consumption = 136.360919 pJ
sum error= 45
Actual label: 8
Output voltages: [0.010751, 0.0027086, 0.044488, 0.48657, 0.017067, 0.037239, 0.0020134, 0.048088, 0.79875, 0.13437]
Predicted label: 8
Correct prediction
Energy consumption = 143.988618 pJ
sum error= 45
Actual label: 1
Output voltages: [0.029671, 0.7984, 0.028383, 0.10868, 0.027057, 0.0054629, 0.68206, 0.0012102, 0.029696, 0.057509]
Predicted label: 1
Correct prediction
Energy consumption = 168.506056 pJ
sum error= 45
Actual label: 2
Output voltages: [0.2678, 0.053539, 0.79879, 0.07404, 0.0046972, 0.0012668, 0.097836, 0.17951, 0.46995, 0.037186]
Predicted label: 2
Correct prediction
Energy consumption = 143.211619 pJ
sum error= 45
Actual label: 4
Output voltages: [0.013303, 0.0047217, 0.024648, 0.005942, 0.79878, 0.0011822, 0.10728, 0.23611, 0.41901, 0.0026005]
Predicted label: 4
Correct prediction
Energy consumption = 157.926990 pJ
sum error= 45
Actual label: 4
Output voltages: [0.085047, 0.011702, 0.12427, 0.0082404, 0.79859, 0.0011812, 0.56233, 0.019235, 0.057771, 0.027119]
Predicted label: 4
Correct prediction
Energy consumption = 142.760564 pJ
sum error= 45
Actual label: 6
Output voltages: [0.37033, 0.05022, 0.22082, 0.0015573, 0.15406, 0.067882, 0.79879, 0.0032177, 0.47821, 0.0083167]
Predicted label: 6
Correct prediction
Energy consumption = 147.771260 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 108 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 108 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 108 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.031192, 0.011791, 0.089987, 0.0065582, 0.79879, 0.001138, 0.011619, 0.059229, 0.059832, 0.34481]
Predicted label: 4
Correct prediction
Energy consumption = 175.906303 pJ
sum error= 45
Actual label: 9
Output voltages: [0.31363, 0.0014247, 0.18107, 0.2034, 0.18013, 0.011522, 0.001348, 0.46014, 0.056089, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 152.289090 pJ
sum error= 45
Actual label: 5
Output voltages: [0.068886, 0.0024875, 0.001618, 0.28249, 0.0016128, 0.79878, 0.39613, 0.047433, 0.75683, 0.0057012]
Predicted label: 5
Correct prediction
Energy consumption = 155.531910 pJ
sum error= 45
Actual label: 1
Output voltages: [0.0086257, 0.79855, 0.10585, 0.49814, 0.083599, 0.028934, 0.28922, 0.0076201, 0.02937, 0.33566]
Predicted label: 1
Correct prediction
Energy consumption = 165.375295 pJ
sum error= 45
Actual label: 0
Output voltages: [0.79863, 0.085146, 0.095473, 0.010555, 0.015358, 0.013228, 0.25415, 0.042435, 0.21771, 0.029351]
Predicted label: 0
Correct prediction
Energy consumption = 147.925903 pJ
sum error= 45
Actual label: 6
Output voltages: [0.019566, 0.090852, 0.19165, 0.0043313, 0.171, 0.3716, 0.79868, 0.0022312, 0.49478, 0.0056723]
Predicted label: 6
Correct prediction
Energy consumption = 148.163384 pJ
sum error= 45
Actual label: 9
Output voltages: [0.55634, 0.0017533, 0.09663, 0.0040799, 0.1656, 0.017075, 0.0085145, 0.058412, 0.48441, 0.78663]
Predicted label: 9
Correct prediction
Energy consumption = 147.613768 pJ
sum error= 45
Actual label: 5
Output voltages: [0.020573, 0.0029511, 0.025465, 0.048009, 0.0037934, 0.79684, 0.22418, 0.0028336, 0.74826, 0.027163]
Predicted label: 5
Correct prediction
Energy consumption = 153.891149 pJ
sum error= 45
Actual label: 9
Output voltages: [0.40801, 0.012138, 0.024403, 0.044329, 0.084073, 0.045234, 0.0045715, 0.2109, 0.67619, 0.79865]
Predicted label: 9
Correct prediction
Energy consumption = 147.053312 pJ
sum error= 45
Actual label: 5
Output voltages: [0.25741, 0.0010688, 0.0010759, 0.70958, 0.28671, 0.79877, 0.51334, 0.027929, 0.55157, 0.40166]
Predicted label: 5
Correct prediction
Energy consumption = 147.510178 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 109 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 109 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 109 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.556, 0.0052786, 0.046256, 0.019604, 0.052513, 0.011178, 0.029196, 0.021815, 0.3769, 0.7984]
Predicted label: 9
Correct prediction
Energy consumption = 170.977426 pJ
sum error= 45
Actual label: 7
Output voltages: [0.03288, 0.009493, 0.18575, 0.23807, 0.0038054, 0.0012019, 0.0010659, 0.79868, 0.1735, 0.55117]
Predicted label: 7
Correct prediction
Energy consumption = 143.374996 pJ
sum error= 45
Actual label: 3
Output voltages: [0.053989, 0.01547, 0.15771, 0.79857, 0.32633, 0.47866, 0.018381, 0.035027, 0.27457, 0.025023]
Predicted label: 3
Correct prediction
Energy consumption = 144.990921 pJ
sum error= 45
Actual label: 8
Output voltages: [0.2047, 0.040874, 0.51854, 0.21808, 0.023348, 0.0023089, 0.062479, 0.0011452, 0.79877, 0.27593]
Predicted label: 8
Correct prediction
Energy consumption = 154.270998 pJ
sum error= 45
Actual label: 0
Output voltages: [0.79874, 0.039188, 0.024081, 0.030636, 0.036308, 0.0079981, 0.45932, 0.010876, 0.11564, 0.18939]
Predicted label: 0
Correct prediction
Energy consumption = 160.604213 pJ
sum error= 45
Actual label: 3
Output voltages: [0.42355, 0.042826, 0.02587, 0.79867, 0.014373, 0.013905, 0.013177, 0.010868, 0.4512, 0.07575]
Predicted label: 3
Correct prediction
Energy consumption = 152.158201 pJ
sum error= 45
Actual label: 7
Output voltages: [0.76007, 0.018479, 0.015078, 0.0011358, 0.0077056, 0.024463, 0.0069706, 0.7885, 0.24049, 0.48152]
Predicted label: 7
Correct prediction
Energy consumption = 155.659670 pJ
sum error= 45
Actual label: 1
Output voltages: [0.014364, 0.79857, 0.18682, 0.07935, 0.030665, 0.0012697, 0.55519, 0.0058001, 0.039727, 0.030868]
Predicted label: 1
Correct prediction
Energy consumption = 167.868921 pJ
sum error= 45
Actual label: 3
Output voltages: [0.67482, 0.026312, 0.018237, 0.79855, 0.03207, 0.20557, 0.031565, 0.011616, 0.49086, 0.038759]
Predicted label: 3
Correct prediction
Energy consumption = 149.760624 pJ
sum error= 45
Actual label: 6
Output voltages: [0.11348, 0.039886, 0.11332, 0.019596, 0.24083, 0.16085, 0.79853, 0.0027077, 0.48264, 0.0026066]
Predicted label: 6
Correct prediction
Energy consumption = 137.935882 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 110 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 110 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 110 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.050761, 0.016533, 0.18824, 0.0043674, 0.0078664, 0.0011539, 0.0012065, 0.79879, 0.76605, 0.10706]
Predicted label: 7
Correct prediction
Energy consumption = 170.532607 pJ
sum error= 45
Actual label: 8
Output voltages: [0.12243, 0.014571, 0.016174, 0.76125, 0.13164, 0.034614, 0.033055, 0.0015634, 0.79851, 0.051674]
Predicted label: 8
Correct prediction
Energy consumption = 153.515668 pJ
sum error= 45
Actual label: 5
Output voltages: [0.032479, 0.0010881, 0.0026776, 0.032462, 0.070446, 0.79873, 0.30527, 0.020619, 0.78194, 0.034361]
Predicted label: 5
Correct prediction
Energy consumption = 138.759079 pJ
sum error= 45
Actual label: 9
Output voltages: [0.45418, 0.0061432, 0.045565, 0.23574, 0.61838, 0.020814, 0.0063867, 0.15624, 0.065633, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 142.643618 pJ
sum error= 45
Actual label: 7
Output voltages: [0.021613, 0.10481, 0.1587, 0.22204, 0.0069711, 0.001088, 0.001165, 0.79862, 0.24819, 0.12044]
Predicted label: 7
Correct prediction
Energy consumption = 151.638642 pJ
sum error= 45
Actual label: 9
Output voltages: [0.080479, 0.004947, 0.02604, 0.033979, 0.35807, 0.01933, 0.013763, 0.036872, 0.62957, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 143.179242 pJ
sum error= 45
Actual label: 6
Output voltages: [0.18368, 0.30793, 0.29259, 0.0072115, 0.0334, 0.39916, 0.79863, 0.0060097, 0.051833, 0.033485]
Predicted label: 6
Correct prediction
Energy consumption = 142.462651 pJ
sum error= 45
Actual label: 9
Output voltages: [0.75268, 0.0010892, 0.013397, 0.59796, 0.35902, 0.11884, 0.055207, 0.0010672, 0.67806, 0.70625]
Predicted label: 0
Wrong prediction!
Energy consumption = 151.725348 pJ
sum error= 46
Actual label: 6
Output voltages: [0.61728, 0.037041, 0.034322, 0.016408, 0.06937, 0.75042, 0.7987, 0.0010734, 0.10428, 0.040222]
Predicted label: 6
Correct prediction
Energy consumption = 146.687128 pJ
sum error= 46
Actual label: 3
Output voltages: [0.58838, 0.025902, 0.40255, 0.79876, 0.042295, 0.0041613, 0.046383, 0.0023482, 0.49724, 0.034239]
Predicted label: 3
Correct prediction
Energy consumption = 145.210991 pJ
sum error= 46
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 111 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 111 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 111 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.27677, 0.01473, 0.022948, 0.26635, 0.025773, 0.015451, 0.0010699, 0.79857, 0.053978, 0.37332]
Predicted label: 7
Correct prediction
Energy consumption = 173.968059 pJ
sum error= 46
Actual label: 4
Output voltages: [0.0023176, 0.0062215, 0.050438, 0.0044052, 0.79864, 0.0020939, 0.13185, 0.087166, 0.057385, 0.021775]
Predicted label: 4
Correct prediction
Energy consumption = 151.031709 pJ
sum error= 46
Actual label: 4
Output voltages: [0.71642, 0.42371, 0.060448, 0.061563, 0.77801, 0.0011326, 0.76475, 0.0026875, 0.042685, 0.0064117]
Predicted label: 4
Correct prediction
Energy consumption = 149.033169 pJ
sum error= 46
Actual label: 5
Output voltages: [0.027557, 0.0010665, 0.01538, 0.21258, 0.053202, 0.79874, 0.46651, 0.012863, 0.78954, 0.0091707]
Predicted label: 5
Correct prediction
Energy consumption = 145.981217 pJ
sum error= 46
Actual label: 3
Output voltages: [0.056522, 0.013483, 0.16853, 0.78857, 0.0011435, 0.0011603, 0.030332, 0.0051168, 0.79663, 0.051629]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.551575 pJ
sum error= 47
Actual label: 5
Output voltages: [0.0057932, 0.006428, 0.011365, 0.47416, 0.021665, 0.79786, 0.026668, 0.034467, 0.74312, 0.2593]
Predicted label: 5
Correct prediction
Energy consumption = 144.408542 pJ
sum error= 47
Actual label: 4
Output voltages: [0.0011165, 0.022388, 0.032118, 0.028573, 0.79878, 0.0014136, 0.018285, 0.021306, 0.053188, 0.081201]
Predicted label: 4
Correct prediction
Energy consumption = 139.763379 pJ
sum error= 47
Actual label: 7
Output voltages: [0.041428, 0.32629, 0.56877, 0.27487, 0.0012671, 0.001075, 0.0011509, 0.79869, 0.14735, 0.5469]
Predicted label: 7
Correct prediction
Energy consumption = 151.335482 pJ
sum error= 47
Actual label: 8
Output voltages: [0.088808, 0.049583, 0.38949, 0.044624, 0.0049633, 0.0019138, 0.048596, 0.017791, 0.79879, 0.12002]
Predicted label: 8
Correct prediction
Energy consumption = 146.367173 pJ
sum error= 47
Actual label: 7
Output voltages: [0.26247, 0.0011145, 0.79578, 0.17116, 0.0035082, 0.001101, 0.0018946, 0.77345, 0.79756, 0.0032536]
Predicted label: 8
Wrong prediction!
Energy consumption = 134.781129 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 112 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 112 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 112 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.033916, 0.072064, 0.054478, 0.56115, 0.001264, 0.062163, 0.021287, 0.0010665, 0.79879, 0.26397]
Predicted label: 8
Correct prediction
Energy consumption = 169.642659 pJ
sum error= 48
Actual label: 0
Output voltages: [0.79827, 0.028956, 0.034478, 0.032835, 0.036421, 0.0047124, 0.73847, 0.013248, 0.093118, 0.03789]
Predicted label: 0
Correct prediction
Energy consumption = 160.415261 pJ
sum error= 48
Actual label: 7
Output voltages: [0.43465, 0.043394, 0.061256, 0.41544, 0.0071253, 0.0012585, 0.0011152, 0.79867, 0.053481, 0.41867]
Predicted label: 7
Correct prediction
Energy consumption = 162.229491 pJ
sum error= 48
Actual label: 6
Output voltages: [0.04085, 0.13758, 0.29705, 0.0019808, 0.25381, 0.076508, 0.79868, 0.0032484, 0.53252, 0.0058973]
Predicted label: 6
Correct prediction
Energy consumption = 148.285484 pJ
sum error= 48
Actual label: 8
Output voltages: [0.047414, 0.029774, 0.027481, 0.48288, 0.0011139, 0.032057, 0.022421, 0.018765, 0.79879, 0.29961]
Predicted label: 8
Correct prediction
Energy consumption = 148.645168 pJ
sum error= 48
Actual label: 8
Output voltages: [0.010378, 0.008926, 0.018038, 0.10948, 0.017031, 0.01144, 0.0153, 0.034512, 0.79878, 0.38586]
Predicted label: 8
Correct prediction
Energy consumption = 144.288000 pJ
sum error= 48
Actual label: 7
Output voltages: [0.31525, 0.19116, 0.032194, 0.31399, 0.0065653, 0.0073603, 0.0010732, 0.79865, 0.040185, 0.17724]
Predicted label: 7
Correct prediction
Energy consumption = 147.173997 pJ
sum error= 48
Actual label: 3
Output voltages: [0.04646, 0.031171, 0.045844, 0.79878, 0.0069064, 0.0088481, 0.0014805, 0.013161, 0.75876, 0.027573]
Predicted label: 3
Correct prediction
Energy consumption = 139.881686 pJ
sum error= 48
Actual label: 3
Output voltages: [0.74743, 0.0011142, 0.46427, 0.7986, 0.0011184, 0.020117, 0.0075827, 0.05204, 0.75793, 0.025899]
Predicted label: 3
Correct prediction
Energy consumption = 139.447030 pJ
sum error= 48
Actual label: 1
Output voltages: [0.050908, 0.7987, 0.027584, 0.028804, 0.0047921, 0.0012483, 0.69638, 0.0013824, 0.44194, 0.016049]
Predicted label: 1
Correct prediction
Energy consumption = 158.097462 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 113 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 113 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 113 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.031174, 0.0025375, 0.27797, 0.086858, 0.065742, 0.011433, 0.16181, 0.044627, 0.03093, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 171.542001 pJ
sum error= 48
Actual label: 5
Output voltages: [0.036307, 0.0010673, 0.0014125, 0.021067, 0.49631, 0.79877, 0.54926, 0.02891, 0.74105, 0.10893]
Predicted label: 5
Correct prediction
Energy consumption = 148.343548 pJ
sum error= 48
Actual label: 2
Output voltages: [0.55668, 0.0030614, 0.79842, 0.40491, 0.0059029, 0.0010738, 0.046548, 0.23115, 0.65447, 0.0041877]
Predicted label: 2
Correct prediction
Energy consumption = 154.695341 pJ
sum error= 48
Actual label: 7
Output voltages: [0.22251, 0.31044, 0.56516, 0.01915, 0.0064655, 0.0011929, 0.0011229, 0.79874, 0.029786, 0.035086]
Predicted label: 7
Correct prediction
Energy consumption = 153.321711 pJ
sum error= 48
Actual label: 3
Output voltages: [0.14343, 0.010468, 0.29287, 0.79871, 0.03024, 0.025927, 0.011483, 0.036634, 0.64773, 0.085403]
Predicted label: 3
Correct prediction
Energy consumption = 144.253832 pJ
sum error= 48
Actual label: 5
Output voltages: [0.68044, 0.029583, 0.0010665, 0.42453, 0.014232, 0.79877, 0.019301, 0.0026219, 0.58284, 0.030115]
Predicted label: 5
Correct prediction
Energy consumption = 149.824172 pJ
sum error= 48
Actual label: 1
Output voltages: [0.055202, 0.79863, 0.0021085, 0.13662, 0.037982, 0.0017461, 0.57668, 0.0010663, 0.23066, 0.16344]
Predicted label: 1
Correct prediction
Energy consumption = 158.738660 pJ
sum error= 48
Actual label: 1
Output voltages: [0.014249, 0.79844, 0.064808, 0.022183, 0.017041, 0.0049192, 0.53439, 0.0022175, 0.19792, 0.027598]
Predicted label: 1
Correct prediction
Energy consumption = 152.515498 pJ
sum error= 48
Actual label: 2
Output voltages: [0.5121, 0.5801, 0.79871, 0.17232, 0.049599, 0.0013146, 0.20992, 0.20326, 0.10729, 0.045142]
Predicted label: 2
Correct prediction
Energy consumption = 147.587049 pJ
sum error= 48
Actual label: 1
Output voltages: [0.015687, 0.79868, 0.14617, 0.039586, 0.030433, 0.0011161, 0.5333, 0.0044104, 0.25068, 0.028233]
Predicted label: 1
Correct prediction
Energy consumption = 154.877932 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 114 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 114 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 114 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0091812, 0.0068305, 0.48218, 0.018447, 0.79864, 0.0019364, 0.12217, 0.037668, 0.010117, 0.35295]
Predicted label: 4
Correct prediction
Energy consumption = 174.179231 pJ
sum error= 48
Actual label: 7
Output voltages: [0.15002, 0.054162, 0.61441, 0.082017, 0.0024136, 0.0011142, 0.0018857, 0.79877, 0.050202, 0.27935]
Predicted label: 7
Correct prediction
Energy consumption = 169.746761 pJ
sum error= 48
Actual label: 4
Output voltages: [0.033805, 0.05125, 0.084026, 0.0099964, 0.79875, 0.0010757, 0.17884, 0.15166, 0.010512, 0.19518]
Predicted label: 4
Correct prediction
Energy consumption = 160.487421 pJ
sum error= 48
Actual label: 7
Output voltages: [0.015886, 0.017483, 0.041542, 0.70058, 0.014606, 0.0010852, 0.0011066, 0.79339, 0.75457, 0.01169]
Predicted label: 7
Correct prediction
Energy consumption = 147.715028 pJ
sum error= 48
Actual label: 5
Output voltages: [0.10677, 0.0010714, 0.0022602, 0.55317, 0.015456, 0.79879, 0.023513, 0.11173, 0.76657, 0.06592]
Predicted label: 5
Correct prediction
Energy consumption = 146.409422 pJ
sum error= 48
Actual label: 4
Output voltages: [0.037431, 0.030562, 0.049476, 0.015667, 0.79879, 0.002211, 0.050203, 0.023953, 0.016546, 0.2896]
Predicted label: 4
Correct prediction
Energy consumption = 157.740591 pJ
sum error= 48
Actual label: 5
Output voltages: [0.019693, 0.0011536, 0.0045642, 0.60596, 0.014285, 0.79853, 0.14562, 0.017608, 0.59048, 0.056421]
Predicted label: 5
Correct prediction
Energy consumption = 151.450211 pJ
sum error= 48
Actual label: 4
Output voltages: [0.011538, 0.017479, 0.019611, 0.0013533, 0.79874, 0.026922, 0.0016933, 0.40603, 0.018382, 0.43675]
Predicted label: 4
Correct prediction
Energy consumption = 154.036055 pJ
sum error= 48
Actual label: 0
Output voltages: [0.79876, 0.056125, 0.042563, 0.031364, 0.021164, 0.0027591, 0.68479, 0.019472, 0.19634, 0.09331]
Predicted label: 0
Correct prediction
Energy consumption = 159.305489 pJ
sum error= 48
Actual label: 8
Output voltages: [0.0066826, 0.050911, 0.17578, 0.023055, 0.0061338, 0.0045752, 0.028406, 0.029604, 0.79878, 0.41539]
Predicted label: 8
Correct prediction
Energy consumption = 148.513887 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 115 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 115 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 115 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.1336, 0.005947, 0.01665, 0.79869, 0.018283, 0.042093, 0.2958, 0.018463, 0.37227, 0.024977]
Predicted label: 3
Correct prediction
Energy consumption = 166.800356 pJ
sum error= 48
Actual label: 6
Output voltages: [0.084204, 0.066692, 0.019544, 0.014878, 0.2391, 0.22102, 0.79879, 0.011424, 0.7426, 0.015021]
Predicted label: 6
Correct prediction
Energy consumption = 154.869391 pJ
sum error= 48
Actual label: 9
Output voltages: [0.45901, 0.0032107, 0.021844, 0.018398, 0.03707, 0.036791, 0.0016949, 0.38274, 0.48217, 0.79574]
Predicted label: 9
Correct prediction
Energy consumption = 151.238373 pJ
sum error= 48
Actual label: 6
Output voltages: [0.13823, 0.020704, 0.062329, 0.12165, 0.016304, 0.72345, 0.77145, 0.0025677, 0.79026, 0.013114]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.610268 pJ
sum error= 49
Actual label: 0
Output voltages: [0.79879, 0.024219, 0.08322, 0.0063332, 0.041042, 0.0065421, 0.69841, 0.02399, 0.11217, 0.038427]
Predicted label: 0
Correct prediction
Energy consumption = 157.728492 pJ
sum error= 49
Actual label: 2
Output voltages: [0.46439, 0.27257, 0.79874, 0.069166, 0.027393, 0.0012636, 0.17136, 0.18095, 0.2113, 0.064025]
Predicted label: 2
Correct prediction
Energy consumption = 155.826619 pJ
sum error= 49
Actual label: 7
Output voltages: [0.031443, 0.21743, 0.1768, 0.41281, 0.0010695, 0.011172, 0.0012525, 0.79861, 0.72133, 0.066817]
Predicted label: 7
Correct prediction
Energy consumption = 144.884855 pJ
sum error= 49
Actual label: 4
Output voltages: [0.024108, 0.056438, 0.017317, 0.098771, 0.79872, 0.0011263, 0.10807, 0.035329, 0.0060275, 0.16421]
Predicted label: 4
Correct prediction
Energy consumption = 158.670728 pJ
sum error= 49
Actual label: 4
Output voltages: [0.0020911, 0.0079217, 0.2705, 0.010797, 0.79871, 0.0042039, 0.11005, 0.18425, 0.026702, 0.031149]
Predicted label: 4
Correct prediction
Energy consumption = 144.372099 pJ
sum error= 49
Actual label: 4
Output voltages: [0.010669, 0.014249, 0.031054, 0.014423, 0.79879, 0.0010893, 0.61942, 0.041843, 0.11218, 0.0076968]
Predicted label: 4
Correct prediction
Energy consumption = 141.799872 pJ
sum error= 49
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 116 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 116 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 116 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.016024, 0.0044218, 0.30264, 0.02054, 0.79859, 0.014227, 0.64539, 0.045982, 0.017617, 0.03942]
Predicted label: 4
Correct prediction
Energy consumption = 172.155548 pJ
sum error= 49
Actual label: 6
Output voltages: [0.41942, 0.016913, 0.011442, 0.034198, 0.27935, 0.59409, 0.79858, 0.001267, 0.43177, 0.17803]
Predicted label: 6
Correct prediction
Energy consumption = 147.144788 pJ
sum error= 49
Actual label: 6
Output voltages: [0.29064, 0.016193, 0.14463, 0.0033287, 0.11349, 0.037784, 0.79879, 0.0010871, 0.69345, 0.064783]
Predicted label: 6
Correct prediction
Energy consumption = 135.027713 pJ
sum error= 49
Actual label: 4
Output voltages: [0.0056451, 0.0024001, 0.028899, 0.0048348, 0.7987, 0.0019621, 0.34689, 0.57722, 0.18647, 0.0049381]
Predicted label: 4
Correct prediction
Energy consumption = 150.355120 pJ
sum error= 49
Actual label: 7
Output voltages: [0.27035, 0.0082029, 0.028652, 0.028286, 0.0078381, 0.0066084, 0.012309, 0.79827, 0.72773, 0.69218]
Predicted label: 7
Correct prediction
Energy consumption = 157.176317 pJ
sum error= 49
Actual label: 9
Output voltages: [0.58652, 0.0058276, 0.029678, 0.022016, 0.18397, 0.0066113, 0.0055276, 0.09643, 0.24866, 0.79781]
Predicted label: 9
Correct prediction
Energy consumption = 148.232968 pJ
sum error= 49
Actual label: 3
Output voltages: [0.095906, 0.0032889, 0.06113, 0.78929, 0.0049466, 0.038754, 0.24069, 0.0079609, 0.15903, 0.0023222]
Predicted label: 3
Correct prediction
Energy consumption = 154.436857 pJ
sum error= 49
Actual label: 4
Output voltages: [0.0072883, 0.0093566, 0.026961, 0.013145, 0.79862, 0.0032876, 0.061336, 0.19372, 0.056374, 0.027795]
Predicted label: 4
Correct prediction
Energy consumption = 148.331665 pJ
sum error= 49
Actual label: 5
Output voltages: [0.048784, 0.0011263, 0.0014234, 0.32667, 0.018775, 0.79878, 0.36895, 0.03104, 0.77216, 0.0052909]
Predicted label: 5
Correct prediction
Energy consumption = 148.040257 pJ
sum error= 49
Actual label: 5
Output voltages: [0.13923, 0.0016461, 0.0023146, 0.044383, 0.017979, 0.78089, 0.21873, 0.0010738, 0.76452, 0.047559]
Predicted label: 5
Correct prediction
Energy consumption = 139.755305 pJ
sum error= 49
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 117 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 117 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 117 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.032666, 0.0065578, 0.0056185, 0.3248, 0.012859, 0.045554, 0.025835, 0.014338, 0.79873, 0.035567]
Predicted label: 8
Correct prediction
Energy consumption = 164.912974 pJ
sum error= 49
Actual label: 7
Output voltages: [0.063825, 0.047176, 0.034542, 0.28205, 0.0028051, 0.0040813, 0.0011428, 0.79877, 0.56181, 0.57618]
Predicted label: 7
Correct prediction
Energy consumption = 155.414756 pJ
sum error= 49
Actual label: 3
Output voltages: [0.18115, 0.023194, 0.052053, 0.79864, 0.037417, 0.0060906, 0.013395, 0.013889, 0.48457, 0.091347]
Predicted label: 3
Correct prediction
Energy consumption = 141.757246 pJ
sum error= 49
Actual label: 7
Output voltages: [0.3434, 0.050519, 0.012381, 0.0045756, 0.37387, 0.0011716, 0.00107, 0.75661, 0.3889, 0.19589]
Predicted label: 7
Correct prediction
Energy consumption = 160.921368 pJ
sum error= 49
Actual label: 2
Output voltages: [0.33833, 0.19981, 0.79842, 0.64663, 0.0035552, 0.0011078, 0.26924, 0.0031636, 0.67475, 0.021831]
Predicted label: 2
Correct prediction
Energy consumption = 152.311123 pJ
sum error= 49
Actual label: 7
Output voltages: [0.028587, 0.22118, 0.045267, 0.03966, 0.024179, 0.0011224, 0.0011957, 0.79862, 0.082743, 0.21984]
Predicted label: 7
Correct prediction
Energy consumption = 154.850357 pJ
sum error= 49
Actual label: 0
Output voltages: [0.79879, 0.062594, 0.083122, 0.13366, 0.024942, 0.0025853, 0.36031, 0.0097375, 0.32255, 0.047461]
Predicted label: 0
Correct prediction
Energy consumption = 151.677862 pJ
sum error= 49
Actual label: 2
Output voltages: [0.40855, 0.15708, 0.79879, 0.1327, 0.019899, 0.0013014, 0.33046, 0.027319, 0.41996, 0.092338]
Predicted label: 2
Correct prediction
Energy consumption = 147.343959 pJ
sum error= 49
Actual label: 4
Output voltages: [0.76056, 0.0010663, 0.0080843, 0.021117, 0.75742, 0.001072, 0.19084, 0.0016692, 0.67707, 0.0053888]
Predicted label: 0
Wrong prediction!
Energy consumption = 146.647474 pJ
sum error= 50
Actual label: 1
Output voltages: [0.027217, 0.79845, 0.022099, 0.11918, 0.0095432, 0.0016596, 0.57147, 0.0017231, 0.27209, 0.032525]
Predicted label: 1
Correct prediction
Energy consumption = 162.414636 pJ
sum error= 50
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 118 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 118 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 118 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.02112, 0.79868, 0.01676, 0.23707, 0.032532, 0.0045474, 0.2962, 0.003772, 0.094069, 0.10459]
Predicted label: 1
Correct prediction
Energy consumption = 179.722677 pJ
sum error= 50
Actual label: 6
Output voltages: [0.22464, 0.41901, 0.078006, 0.069225, 0.0079782, 0.090329, 0.79792, 0.003112, 0.74998, 0.0022396]
Predicted label: 6
Correct prediction
Energy consumption = 146.971619 pJ
sum error= 50
Actual label: 6
Output voltages: [0.070711, 0.0012082, 0.010013, 0.040716, 0.021694, 0.77009, 0.78224, 0.0019435, 0.54749, 0.02037]
Predicted label: 6
Correct prediction
Energy consumption = 154.900142 pJ
sum error= 50
Actual label: 9
Output voltages: [0.17084, 0.14462, 0.024018, 0.19857, 0.23325, 0.020237, 0.0086098, 0.0053543, 0.16491, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 152.563726 pJ
sum error= 50
Actual label: 2
Output voltages: [0.026746, 0.25694, 0.79878, 0.047604, 0.018619, 0.0011076, 0.36368, 0.10962, 0.47251, 0.045855]
Predicted label: 2
Correct prediction
Energy consumption = 150.882228 pJ
sum error= 50
Actual label: 8
Output voltages: [0.068853, 0.040179, 0.16352, 0.13128, 0.01803, 0.01983, 0.081926, 0.0036704, 0.79877, 0.16494]
Predicted label: 8
Correct prediction
Energy consumption = 142.910908 pJ
sum error= 50
Actual label: 7
Output voltages: [0.049944, 0.02149, 0.03298, 0.027863, 0.027338, 0.033178, 0.0010778, 0.79849, 0.0702, 0.030349]
Predicted label: 7
Correct prediction
Energy consumption = 149.418911 pJ
sum error= 50
Actual label: 2
Output voltages: [0.045349, 0.38556, 0.79868, 0.27262, 0.0015544, 0.0013768, 0.25927, 0.0041215, 0.35042, 0.023101]
Predicted label: 2
Correct prediction
Energy consumption = 143.351111 pJ
sum error= 50
Actual label: 0
Output voltages: [0.79879, 0.11677, 0.02686, 0.0065524, 0.021997, 0.0055894, 0.32136, 0.012543, 0.27427, 0.14993]
Predicted label: 0
Correct prediction
Energy consumption = 153.842846 pJ
sum error= 50
Actual label: 1
Output voltages: [0.029344, 0.79838, 0.028143, 0.052941, 0.011813, 0.0023711, 0.41611, 0.0042287, 0.46355, 0.052875]
Predicted label: 1
Correct prediction
Energy consumption = 162.700745 pJ
sum error= 50
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 119 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 119 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 119 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.037773, 0.0014205, 0.008552, 0.60406, 0.012266, 0.79877, 0.020394, 0.093898, 0.75308, 0.057892]
Predicted label: 5
Correct prediction
Energy consumption = 166.781443 pJ
sum error= 50
Actual label: 0
Output voltages: [0.79878, 0.0019225, 0.24552, 0.0049528, 0.33106, 0.37131, 0.76437, 0.13989, 0.0075643, 0.048058]
Predicted label: 0
Correct prediction
Energy consumption = 137.286998 pJ
sum error= 50
Actual label: 9
Output voltages: [0.011267, 0.0037781, 0.089831, 0.011023, 0.01068, 0.070047, 0.0035561, 0.021559, 0.7874, 0.75517]
Predicted label: 8
Wrong prediction!
Energy consumption = 154.777075 pJ
sum error= 51
Actual label: 1
Output voltages: [0.13841, 0.7984, 0.009662, 0.1233, 0.02899, 0.015818, 0.40725, 0.023126, 0.025655, 0.23786]
Predicted label: 1
Correct prediction
Energy consumption = 164.182940 pJ
sum error= 51
Actual label: 7
Output voltages: [0.49676, 0.0018972, 0.090627, 0.12171, 0.50967, 0.001066, 0.0010743, 0.6304, 0.37835, 0.42897]
Predicted label: 7
Correct prediction
Energy consumption = 147.732928 pJ
sum error= 51
Actual label: 0
Output voltages: [0.79879, 0.14488, 0.0284, 0.013797, 0.0074485, 0.0090752, 0.30426, 0.028114, 0.25372, 0.28545]
Predicted label: 0
Correct prediction
Energy consumption = 154.531151 pJ
sum error= 51
Actual label: 6
Output voltages: [0.048047, 0.075371, 0.14601, 0.0023017, 0.17823, 0.038228, 0.79878, 0.0038901, 0.74565, 0.0048501]
Predicted label: 6
Correct prediction
Energy consumption = 143.289691 pJ
sum error= 51
Actual label: 0
Output voltages: [0.79879, 0.16132, 0.12933, 0.030994, 0.010729, 0.0095139, 0.74986, 0.03838, 0.16, 0.077938]
Predicted label: 0
Correct prediction
Energy consumption = 153.044290 pJ
sum error= 51
Actual label: 8
Output voltages: [0.019231, 0.031686, 0.020241, 0.021551, 0.029116, 0.065542, 0.024911, 0.021586, 0.79873, 0.095439]
Predicted label: 8
Correct prediction
Energy consumption = 147.925907 pJ
sum error= 51
Actual label: 6
Output voltages: [0.19727, 0.032121, 0.19855, 0.0030835, 0.20017, 0.69896, 0.79866, 0.0016726, 0.15227, 0.035668]
Predicted label: 6
Correct prediction
Energy consumption = 145.503619 pJ
sum error= 51
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 120 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 120 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 120 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.41874, 0.040175, 0.015428, 0.5677, 0.020882, 0.032273, 0.7448, 0.0011043, 0.7668, 0.34991]
Predicted label: 8
Correct prediction
Energy consumption = 177.670606 pJ
sum error= 51
Actual label: 1
Output voltages: [0.027035, 0.79852, 0.028, 0.24064, 0.05503, 0.0074406, 0.59004, 0.0059212, 0.21643, 0.15983]
Predicted label: 1
Correct prediction
Energy consumption = 159.390149 pJ
sum error= 51
Actual label: 8
Output voltages: [0.16544, 0.0010731, 0.051808, 0.39675, 0.003216, 0.71893, 0.017771, 0.0014922, 0.79877, 0.019529]
Predicted label: 8
Correct prediction
Energy consumption = 150.704052 pJ
sum error= 51
Actual label: 0
Output voltages: [0.79875, 0.086072, 0.049688, 0.014557, 0.024377, 0.011103, 0.50877, 0.023062, 0.11424, 0.0048851]
Predicted label: 0
Correct prediction
Energy consumption = 148.773065 pJ
sum error= 51
Actual label: 3
Output voltages: [0.0010955, 0.029092, 0.44007, 0.77613, 0.013851, 0.0011904, 0.001093, 0.75402, 0.75006, 0.013179]
Predicted label: 3
Correct prediction
Energy consumption = 148.180343 pJ
sum error= 51
Actual label: 3
Output voltages: [0.53155, 0.025567, 0.21614, 0.79864, 0.005842, 0.028297, 0.0036297, 0.041277, 0.28735, 0.044885]
Predicted label: 3
Correct prediction
Energy consumption = 140.879749 pJ
sum error= 51
Actual label: 7
Output voltages: [0.31671, 0.0017567, 0.79368, 0.085474, 0.0032226, 0.0011394, 0.0018169, 0.74234, 0.77489, 0.25281]
Predicted label: 2
Wrong prediction!
Energy consumption = 142.579652 pJ
sum error= 52
Actual label: 2
Output voltages: [0.64473, 0.05457, 0.79866, 0.04841, 0.013572, 0.0011367, 0.080993, 0.066924, 0.42613, 0.012432]
Predicted label: 2
Correct prediction
Energy consumption = 143.249656 pJ
sum error= 52
Actual label: 3
Output voltages: [0.014383, 0.020876, 0.075058, 0.7987, 0.021739, 0.0021743, 0.015364, 0.069386, 0.60057, 0.11107]
Predicted label: 3
Correct prediction
Energy consumption = 147.569805 pJ
sum error= 52
Actual label: 6
Output voltages: [0.093101, 0.28154, 0.026737, 0.14666, 0.032567, 0.77567, 0.79549, 0.010361, 0.46366, 0.0010676]
Predicted label: 6
Correct prediction
Energy consumption = 148.021338 pJ
sum error= 52
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 121 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 121 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 121 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.68895, 0.027698, 0.79878, 0.18109, 0.013346, 0.0011257, 0.052205, 0.032442, 0.70959, 0.016643]
Predicted label: 2
Correct prediction
Energy consumption = 165.644221 pJ
sum error= 52
Actual label: 1
Output voltages: [0.0058423, 0.79879, 0.15822, 0.027348, 0.5248, 0.0011125, 0.033102, 0.017424, 0.047796, 0.20078]
Predicted label: 1
Correct prediction
Energy consumption = 154.350614 pJ
sum error= 52
Actual label: 6
Output voltages: [0.20535, 0.040428, 0.026167, 0.027698, 0.060639, 0.13923, 0.77817, 0.016555, 0.79849, 0.001066]
Predicted label: 8
Wrong prediction!
Energy consumption = 151.169415 pJ
sum error= 53
Actual label: 1
Output voltages: [0.0068318, 0.79849, 0.039929, 0.18468, 0.012441, 0.0015662, 0.69589, 0.011836, 0.038521, 0.030144]
Predicted label: 1
Correct prediction
Energy consumption = 162.050312 pJ
sum error= 53
Actual label: 1
Output voltages: [0.02965, 0.79862, 0.026513, 0.018236, 0.019252, 0.0010777, 0.42059, 0.0012287, 0.42304, 0.037539]
Predicted label: 1
Correct prediction
Energy consumption = 152.243073 pJ
sum error= 53
Actual label: 3
Output voltages: [0.30946, 0.015123, 0.21597, 0.79872, 0.024733, 0.0058036, 0.0045893, 0.012057, 0.731, 0.0096567]
Predicted label: 3
Correct prediction
Energy consumption = 150.152807 pJ
sum error= 53
Actual label: 7
Output voltages: [0.031192, 0.19429, 0.019493, 0.12975, 0.011744, 0.0031077, 0.0011047, 0.79876, 0.02824, 0.68411]
Predicted label: 7
Correct prediction
Energy consumption = 158.765796 pJ
sum error= 53
Actual label: 9
Output voltages: [0.1646, 0.33261, 0.0032135, 0.34306, 0.010599, 0.0020589, 0.0016513, 0.045551, 0.52594, 0.79775]
Predicted label: 9
Correct prediction
Energy consumption = 150.846039 pJ
sum error= 53
Actual label: 0
Output voltages: [0.79875, 0.31888, 0.032274, 0.034399, 0.0022554, 0.014881, 0.60376, 0.1069, 0.23735, 0.030126]
Predicted label: 0
Correct prediction
Energy consumption = 146.290574 pJ
sum error= 53
Actual label: 8
Output voltages: [0.0732, 0.050388, 0.066592, 0.57249, 0.0014525, 0.017371, 0.031276, 0.012217, 0.79879, 0.18529]
Predicted label: 8
Correct prediction
Energy consumption = 150.447815 pJ
sum error= 53
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 122 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 122 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 122 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.080126, 0.012112, 0.0055628, 0.021605, 0.01177, 0.62516, 0.0056904, 0.10701, 0.19945]
Predicted label: 0
Correct prediction
Energy consumption = 176.528752 pJ
sum error= 53
Actual label: 5
Output voltages: [0.0051846, 0.0017435, 0.0065544, 0.31741, 0.015586, 0.78741, 0.046014, 0.013481, 0.73188, 0.12357]
Predicted label: 5
Correct prediction
Energy consumption = 140.674050 pJ
sum error= 53
Actual label: 4
Output voltages: [0.0012087, 0.0016036, 0.091572, 0.022343, 0.79868, 0.0010992, 0.20651, 0.042125, 0.045668, 0.013778]
Predicted label: 4
Correct prediction
Energy consumption = 155.773416 pJ
sum error= 53
Actual label: 0
Output voltages: [0.78861, 0.003174, 0.05224, 0.0038487, 0.004221, 0.11793, 0.75489, 0.002002, 0.048115, 0.080644]
Predicted label: 0
Correct prediction
Energy consumption = 153.095179 pJ
sum error= 53
Actual label: 2
Output voltages: [0.67433, 0.029707, 0.75029, 0.19784, 0.71439, 0.0011646, 0.42437, 0.32381, 0.022521, 0.0011262]
Predicted label: 2
Correct prediction
Energy consumption = 145.929129 pJ
sum error= 53
Actual label: 8
Output voltages: [0.004126, 0.062631, 0.16337, 0.027841, 0.018067, 0.0072521, 0.027338, 0.031948, 0.7987, 0.30287]
Predicted label: 8
Correct prediction
Energy consumption = 150.275737 pJ
sum error= 53
Actual label: 7
Output voltages: [0.20728, 0.28164, 0.79807, 0.47681, 0.011633, 0.0013548, 0.02314, 0.28308, 0.25124, 0.05407]
Predicted label: 2
Wrong prediction!
Energy consumption = 148.561441 pJ
sum error= 54
Actual label: 2
Output voltages: [0.049184, 0.34331, 0.79875, 0.28626, 0.031401, 0.001301, 0.011339, 0.54886, 0.19611, 0.038333]
Predicted label: 2
Correct prediction
Energy consumption = 131.616255 pJ
sum error= 54
Actual label: 9
Output voltages: [0.05389, 0.0012771, 0.14502, 0.70817, 0.16433, 0.027884, 0.0011016, 0.13099, 0.51298, 0.74973]
Predicted label: 9
Correct prediction
Energy consumption = 151.838743 pJ
sum error= 54
Actual label: 8
Output voltages: [0.044492, 0.020948, 0.11406, 0.34904, 0.0016207, 0.04891, 0.0044103, 0.015393, 0.79879, 0.39065]
Predicted label: 8
Correct prediction
Energy consumption = 146.759600 pJ
sum error= 54
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 123 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 123 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 123 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.058605, 0.0031776, 0.21722, 0.0056272, 0.79867, 0.0010934, 0.036618, 0.041777, 0.029864, 0.11115]
Predicted label: 4
Correct prediction
Energy consumption = 172.440848 pJ
sum error= 54
Actual label: 0
Output voltages: [0.79811, 0.087609, 0.063222, 0.018062, 0.011767, 0.0011155, 0.59901, 0.0044694, 0.050455, 0.3408]
Predicted label: 0
Correct prediction
Energy consumption = 157.506983 pJ
sum error= 54
Actual label: 9
Output voltages: [0.038077, 0.34921, 0.0012499, 0.025258, 0.76146, 0.0011638, 0.31947, 0.031432, 0.28701, 0.064468]
Predicted label: 4
Wrong prediction!
Energy consumption = 163.339951 pJ
sum error= 55
Actual label: 5
Output voltages: [0.042689, 0.0014399, 0.0010795, 0.54206, 0.056343, 0.7982, 0.54774, 0.0061581, 0.56922, 0.16069]
Predicted label: 5
Correct prediction
Energy consumption = 148.337435 pJ
sum error= 55
Actual label: 8
Output voltages: [0.185, 0.0010784, 0.040592, 0.019102, 0.13905, 0.30693, 0.25971, 0.0020727, 0.79875, 0.0020725]
Predicted label: 8
Correct prediction
Energy consumption = 146.767405 pJ
sum error= 55
Actual label: 5
Output voltages: [0.016304, 0.0010724, 0.0053048, 0.060723, 0.11929, 0.79728, 0.16168, 0.025225, 0.7965, 0.038623]
Predicted label: 5
Correct prediction
Energy consumption = 138.395683 pJ
sum error= 55
Actual label: 1
Output voltages: [0.020469, 0.79869, 0.052241, 0.60538, 0.098319, 0.00923, 0.058757, 0.0011507, 0.022012, 0.58974]
Predicted label: 1
Correct prediction
Energy consumption = 163.006027 pJ
sum error= 55
Actual label: 2
Output voltages: [0.16411, 0.21036, 0.79879, 0.093203, 0.018017, 0.0013126, 0.39385, 0.0045576, 0.46648, 0.05137]
Predicted label: 2
Correct prediction
Energy consumption = 150.573574 pJ
sum error= 55
Actual label: 1
Output voltages: [0.03083, 0.79855, 0.033077, 0.028453, 0.016357, 0.0044082, 0.44464, 0.0023797, 0.34503, 0.029422]
Predicted label: 1
Correct prediction
Energy consumption = 160.252503 pJ
sum error= 55
Actual label: 3
Output voltages: [0.1426, 0.018071, 0.036127, 0.79872, 0.1223, 0.030727, 0.034974, 0.011145, 0.35818, 0.20445]
Predicted label: 3
Correct prediction
Energy consumption = 149.575773 pJ
sum error= 55
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 124 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 124 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 124 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.070173, 0.79868, 0.019342, 0.34436, 0.0010704, 0.0027174, 0.68306, 0.001794, 0.19198, 0.005461]
Predicted label: 1
Correct prediction
Energy consumption = 182.757247 pJ
sum error= 55
Actual label: 7
Output voltages: [0.02107, 0.13489, 0.77634, 0.0060383, 0.019415, 0.0011281, 0.0010786, 0.79878, 0.31254, 0.10167]
Predicted label: 7
Correct prediction
Energy consumption = 140.863224 pJ
sum error= 55
Actual label: 4
Output voltages: [0.73144, 0.0051086, 0.0027751, 0.026382, 0.79878, 0.017093, 0.043626, 0.0012378, 0.019637, 0.75477]
Predicted label: 4
Correct prediction
Energy consumption = 155.994227 pJ
sum error= 55
Actual label: 5
Output voltages: [0.20355, 0.0013646, 0.0011374, 0.30362, 0.27763, 0.79516, 0.38064, 0.0011902, 0.56671, 0.053182]
Predicted label: 5
Correct prediction
Energy consumption = 149.783763 pJ
sum error= 55
Actual label: 7
Output voltages: [0.02093, 0.61798, 0.23914, 0.034225, 0.0059128, 0.0013117, 0.0011616, 0.79878, 0.0567, 0.23504]
Predicted label: 7
Correct prediction
Energy consumption = 167.552466 pJ
sum error= 55
Actual label: 2
Output voltages: [0.41238, 0.0014123, 0.79835, 0.24879, 0.004743, 0.0011214, 0.040389, 0.061896, 0.68361, 0.0042203]
Predicted label: 2
Correct prediction
Energy consumption = 144.284579 pJ
sum error= 55
Actual label: 0
Output voltages: [0.79879, 0.30667, 0.01291, 0.035942, 0.013814, 0.28626, 0.76478, 0.042723, 0.10068, 0.019271]
Predicted label: 0
Correct prediction
Energy consumption = 151.263642 pJ
sum error= 55
Actual label: 9
Output voltages: [0.78659, 0.0011661, 0.03853, 0.5251, 0.0011142, 0.11196, 0.0010802, 0.33175, 0.12376, 0.40588]
Predicted label: 0
Wrong prediction!
Energy consumption = 147.677737 pJ
sum error= 56
Actual label: 8
Output voltages: [0.33435, 0.0025001, 0.058689, 0.61849, 0.0027029, 0.77174, 0.5849, 0.0069595, 0.7924, 0.0053606]
Predicted label: 8
Correct prediction
Energy consumption = 155.698426 pJ
sum error= 56
Actual label: 8
Output voltages: [0.3339, 0.035538, 0.057563, 0.014827, 0.032632, 0.10594, 0.011857, 0.014157, 0.79878, 0.064079]
Predicted label: 8
Correct prediction
Energy consumption = 143.101508 pJ
sum error= 56
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 125 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 125 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 125 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.38115, 0.59576, 0.043312, 0.16275, 0.015418, 0.15382, 0.79877, 0.022786, 0.65566, 0.0050683]
Predicted label: 6
Correct prediction
Energy consumption = 169.945241 pJ
sum error= 56
Actual label: 2
Output voltages: [0.73326, 0.065755, 0.79824, 0.5279, 0.0080872, 0.0010852, 0.45027, 0.036852, 0.053661, 0.010526]
Predicted label: 2
Correct prediction
Energy consumption = 144.543920 pJ
sum error= 56
Actual label: 5
Output voltages: [0.053918, 0.0010683, 0.042124, 0.13739, 0.0041627, 0.7986, 0.16485, 0.0042747, 0.78373, 0.0084403]
Predicted label: 5
Correct prediction
Energy consumption = 143.365567 pJ
sum error= 56
Actual label: 4
Output voltages: [0.17167, 0.01004, 0.45245, 0.0058176, 0.79879, 0.0011297, 0.6915, 0.007872, 0.033933, 0.2219]
Predicted label: 4
Correct prediction
Energy consumption = 153.800566 pJ
sum error= 56
Actual label: 1
Output voltages: [0.03627, 0.79845, 0.02564, 0.056792, 0.052549, 0.0060303, 0.13309, 0.0018259, 0.41257, 0.041681]
Predicted label: 1
Correct prediction
Energy consumption = 166.634924 pJ
sum error= 56
Actual label: 9
Output voltages: [0.28511, 0.017989, 0.019673, 0.14585, 0.37725, 0.022789, 0.013431, 0.017876, 0.050694, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 159.835093 pJ
sum error= 56
Actual label: 2
Output voltages: [0.46149, 0.36973, 0.79863, 0.077995, 0.002425, 0.0010715, 0.027135, 0.17517, 0.17268, 0.038836]
Predicted label: 2
Correct prediction
Energy consumption = 144.917054 pJ
sum error= 56
Actual label: 1
Output voltages: [0.023416, 0.79876, 0.0011362, 0.0019337, 0.47398, 0.04192, 0.671, 0.0073493, 0.021155, 0.010246]
Predicted label: 1
Correct prediction
Energy consumption = 152.161896 pJ
sum error= 56
Actual label: 5
Output voltages: [0.036467, 0.0025251, 0.010389, 0.33437, 0.011151, 0.79818, 0.014443, 0.012598, 0.77937, 0.24271]
Predicted label: 5
Correct prediction
Energy consumption = 156.281967 pJ
sum error= 56
Actual label: 8
Output voltages: [0.041216, 0.022025, 0.034645, 0.012151, 0.042457, 0.26901, 0.03382, 0.007393, 0.79874, 0.12657]
Predicted label: 8
Correct prediction
Energy consumption = 142.320227 pJ
sum error= 56
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 126 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 126 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 126 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.074363, 0.79717, 0.01573, 0.033375, 0.0011212, 0.0012036, 0.0023146, 0.5998, 0.73234, 0.23768]
Predicted label: 1
Wrong prediction!
Energy consumption = 180.562412 pJ
sum error= 57
Actual label: 0
Output voltages: [0.79879, 0.041186, 0.029918, 0.014134, 0.014352, 0.014836, 0.5513, 0.024783, 0.076807, 0.02606]
Predicted label: 0
Correct prediction
Energy consumption = 156.213670 pJ
sum error= 57
Actual label: 2
Output voltages: [0.67682, 0.13981, 0.79869, 0.037803, 0.012873, 0.001206, 0.1608, 0.049021, 0.46375, 0.023705]
Predicted label: 2
Correct prediction
Energy consumption = 151.625452 pJ
sum error= 57
Actual label: 4
Output voltages: [0.0025775, 0.0022531, 0.03809, 0.021209, 0.79866, 0.023713, 0.1453, 0.054543, 0.020264, 0.53634]
Predicted label: 4
Correct prediction
Energy consumption = 153.067598 pJ
sum error= 57
Actual label: 4
Output voltages: [0.025864, 0.005397, 0.020556, 0.03788, 0.79879, 0.0084581, 0.043332, 0.34571, 0.035658, 0.044218]
Predicted label: 4
Correct prediction
Energy consumption = 150.370674 pJ
sum error= 57
Actual label: 3
Output voltages: [0.17504, 0.013881, 0.4664, 0.79877, 0.038403, 0.0010669, 0.0081815, 0.0047613, 0.53611, 0.040767]
Predicted label: 3
Correct prediction
Energy consumption = 145.432587 pJ
sum error= 57
Actual label: 6
Output voltages: [0.076392, 0.012698, 0.30205, 0.0018944, 0.098818, 0.033282, 0.79868, 0.0033719, 0.25169, 0.027062]
Predicted label: 6
Correct prediction
Energy consumption = 149.691829 pJ
sum error= 57
Actual label: 8
Output voltages: [0.028401, 0.01974, 0.093315, 0.035521, 0.035927, 0.034978, 0.019509, 0.0039076, 0.79877, 0.26427]
Predicted label: 8
Correct prediction
Energy consumption = 154.818020 pJ
sum error= 57
Actual label: 8
Output voltages: [0.0049134, 0.03712, 0.49794, 0.14103, 0.0064625, 0.0061632, 0.025887, 0.16522, 0.79879, 0.085508]
Predicted label: 8
Correct prediction
Energy consumption = 143.513462 pJ
sum error= 57
Actual label: 2
Output voltages: [0.50026, 0.045885, 0.79879, 0.045179, 0.050177, 0.0011148, 0.15847, 0.024173, 0.055512, 0.30085]
Predicted label: 2
Correct prediction
Energy consumption = 150.208228 pJ
sum error= 57
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 127 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 127 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 127 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.011878, 0.0087814, 0.060456, 0.013251, 0.79874, 0.0011743, 0.0085575, 0.14191, 0.10539, 0.024553]
Predicted label: 4
Correct prediction
Energy consumption = 170.421753 pJ
sum error= 57
Actual label: 0
Output voltages: [0.79124, 0.046015, 0.068312, 0.001264, 0.021351, 0.021664, 0.54102, 0.0049895, 0.02479, 0.24973]
Predicted label: 0
Correct prediction
Energy consumption = 157.372979 pJ
sum error= 57
Actual label: 5
Output voltages: [0.14953, 0.0011317, 0.0016394, 0.032616, 0.15279, 0.79876, 0.023751, 0.053008, 0.78066, 0.21107]
Predicted label: 5
Correct prediction
Energy consumption = 141.633943 pJ
sum error= 57
Actual label: 0
Output voltages: [0.79877, 0.0098567, 0.0082175, 0.015545, 0.0947, 0.0066097, 0.73457, 0.038572, 0.19263, 0.1955]
Predicted label: 0
Correct prediction
Energy consumption = 148.571583 pJ
sum error= 57
Actual label: 4
Output voltages: [0.23067, 0.041764, 0.061767, 0.0071316, 0.79878, 0.0010703, 0.087071, 0.017197, 0.028628, 0.030179]
Predicted label: 4
Correct prediction
Energy consumption = 155.368881 pJ
sum error= 57
Actual label: 4
Output voltages: [0.038721, 0.013758, 0.11562, 0.096483, 0.79879, 0.001066, 0.010137, 0.011908, 0.033214, 0.22305]
Predicted label: 4
Correct prediction
Energy consumption = 153.046640 pJ
sum error= 57
Actual label: 7
Output voltages: [0.21206, 0.0042346, 0.095617, 0.72479, 0.032484, 0.001159, 0.001119, 0.79305, 0.4715, 0.43422]
Predicted label: 7
Correct prediction
Energy consumption = 144.269690 pJ
sum error= 57
Actual label: 9
Output voltages: [0.26062, 0.0077125, 0.016421, 0.029004, 0.43164, 0.077222, 0.027757, 0.044062, 0.27181, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 140.916169 pJ
sum error= 57
Actual label: 3
Output voltages: [0.28546, 0.026774, 0.041937, 0.79858, 0.026792, 0.015018, 0.023001, 0.033667, 0.58887, 0.08155]
Predicted label: 3
Correct prediction
Energy consumption = 144.968080 pJ
sum error= 57
Actual label: 4
Output voltages: [0.010499, 0.023378, 0.098811, 0.0052612, 0.79877, 0.0013945, 0.31839, 0.44741, 0.023178, 0.0068718]
Predicted label: 4
Correct prediction
Energy consumption = 137.427493 pJ
sum error= 57
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 128 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 128 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 128 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.007399, 0.79867, 0.09072, 0.091346, 0.13795, 0.0019498, 0.31647, 0.029407, 0.25737, 0.021059]
Predicted label: 1
Correct prediction
Energy consumption = 188.264090 pJ
sum error= 57
Actual label: 5
Output voltages: [0.27943, 0.0020185, 0.002914, 0.076555, 0.0024381, 0.79879, 0.12968, 0.060385, 0.75089, 0.0062894]
Predicted label: 5
Correct prediction
Energy consumption = 153.765928 pJ
sum error= 57
Actual label: 9
Output voltages: [0.46432, 0.0010752, 0.23584, 0.017161, 0.61822, 0.0025532, 0.023116, 0.015568, 0.27185, 0.79408]
Predicted label: 9
Correct prediction
Energy consumption = 151.492328 pJ
sum error= 57
Actual label: 7
Output voltages: [0.16136, 0.0011378, 0.74042, 0.75111, 0.020727, 0.0011069, 0.0011011, 0.055911, 0.75347, 0.048701]
Predicted label: 8
Wrong prediction!
Energy consumption = 139.751278 pJ
sum error= 58
Actual label: 3
Output voltages: [0.038401, 0.0097155, 0.035854, 0.79869, 0.048892, 0.016446, 0.05705, 0.017357, 0.60046, 0.10115]
Predicted label: 3
Correct prediction
Energy consumption = 133.552285 pJ
sum error= 58
Actual label: 5
Output voltages: [0.029819, 0.0087339, 0.0011825, 0.72949, 0.034952, 0.79873, 0.14584, 0.0080557, 0.49003, 0.012064]
Predicted label: 5
Correct prediction
Energy consumption = 138.576545 pJ
sum error= 58
Actual label: 8
Output voltages: [0.017897, 0.075932, 0.284, 0.15919, 0.011877, 0.0050281, 0.032607, 0.019592, 0.79877, 0.17191]
Predicted label: 8
Correct prediction
Energy consumption = 152.312182 pJ
sum error= 58
Actual label: 8
Output voltages: [0.022385, 0.027435, 0.029397, 0.34737, 0.012975, 0.0028258, 0.014017, 0.014996, 0.79876, 0.12191]
Predicted label: 8
Correct prediction
Energy consumption = 144.114542 pJ
sum error= 58
Actual label: 0
Output voltages: [0.79839, 0.0041817, 0.047264, 0.086775, 0.024298, 0.0018757, 0.37925, 0.1608, 0.27598, 0.20976]
Predicted label: 0
Correct prediction
Energy consumption = 158.214521 pJ
sum error= 58
Actual label: 5
Output voltages: [0.29537, 0.036518, 0.0010823, 0.79207, 0.022034, 0.79771, 0.11893, 0.010868, 0.39155, 0.29534]
Predicted label: 5
Correct prediction
Energy consumption = 144.264324 pJ
sum error= 58
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 129 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 129 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 129 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.22483, 0.0027306, 0.023776, 0.79878, 0.29775, 0.19776, 0.047876, 0.0021113, 0.067444, 0.0202]
Predicted label: 3
Correct prediction
Energy consumption = 173.895863 pJ
sum error= 58
Actual label: 3
Output voltages: [0.074784, 0.0098992, 0.027987, 0.79878, 0.041891, 0.01064, 0.051031, 0.068681, 0.462, 0.0037636]
Predicted label: 3
Correct prediction
Energy consumption = 135.618008 pJ
sum error= 58
Actual label: 6
Output voltages: [0.0317, 0.0027219, 0.089529, 0.032186, 0.025957, 0.27018, 0.79785, 0.0011443, 0.26986, 0.11525]
Predicted label: 6
Correct prediction
Energy consumption = 149.208797 pJ
sum error= 58
Actual label: 6
Output voltages: [0.012168, 0.054211, 0.63591, 0.0014208, 0.23503, 0.39157, 0.79864, 0.0011844, 0.46872, 0.014698]
Predicted label: 6
Correct prediction
Energy consumption = 130.288839 pJ
sum error= 58
Actual label: 0
Output voltages: [0.79879, 0.12842, 0.048645, 0.022841, 0.027088, 0.0028226, 0.66921, 0.008221, 0.18008, 0.058465]
Predicted label: 0
Correct prediction
Energy consumption = 156.506177 pJ
sum error= 58
Actual label: 1
Output voltages: [0.013626, 0.79865, 0.042588, 0.029913, 0.09129, 0.0011306, 0.62026, 0.005068, 0.34995, 0.022275]
Predicted label: 1
Correct prediction
Energy consumption = 164.428340 pJ
sum error= 58
Actual label: 6
Output voltages: [0.03147, 0.0027279, 0.0019857, 0.37811, 0.03093, 0.48825, 0.7818, 0.0023688, 0.61109, 0.01139]
Predicted label: 6
Correct prediction
Energy consumption = 153.887154 pJ
sum error= 58
Actual label: 0
Output voltages: [0.7984, 0.29283, 0.017134, 0.0065594, 0.018545, 0.0041598, 0.75758, 0.012587, 0.14624, 0.27967]
Predicted label: 0
Correct prediction
Energy consumption = 153.827424 pJ
sum error= 58
Actual label: 3
Output voltages: [0.19494, 0.0083832, 0.087989, 0.79872, 0.049447, 0.0016325, 0.020303, 0.030004, 0.61849, 0.027448]
Predicted label: 3
Correct prediction
Energy consumption = 144.666475 pJ
sum error= 58
Actual label: 5
Output voltages: [0.051908, 0.048539, 0.016677, 0.79838, 0.0020302, 0.59618, 0.0011343, 0.41747, 0.20878, 0.036278]
Predicted label: 3
Wrong prediction!
Energy consumption = 144.160969 pJ
sum error= 59
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 130 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 130 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 130 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.02514, 0.01034, 0.13604, 0.0067473, 0.79868, 0.0010683, 0.013164, 0.041414, 0.021353, 0.39889]
Predicted label: 4
Correct prediction
Energy consumption = 170.995296 pJ
sum error= 59
Actual label: 4
Output voltages: [0.0094157, 0.022794, 0.20796, 0.0056614, 0.79868, 0.0010697, 0.041399, 0.027262, 0.020285, 0.28625]
Predicted label: 4
Correct prediction
Energy consumption = 145.835260 pJ
sum error= 59
Actual label: 1
Output voltages: [0.021879, 0.7984, 0.036499, 0.057908, 0.20677, 0.0028898, 0.3942, 0.0082736, 0.039184, 0.46337]
Predicted label: 1
Correct prediction
Energy consumption = 166.219712 pJ
sum error= 59
Actual label: 2
Output voltages: [0.76462, 0.12946, 0.79879, 0.058267, 0.02311, 0.0011491, 0.19951, 0.041049, 0.27628, 0.026507]
Predicted label: 2
Correct prediction
Energy consumption = 154.118363 pJ
sum error= 59
Actual label: 9
Output voltages: [0.30879, 0.040486, 0.28829, 0.22686, 0.043517, 0.048841, 0.011963, 0.14256, 0.13975, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 156.068709 pJ
sum error= 59
Actual label: 1
Output voltages: [0.0022863, 0.79847, 0.037449, 0.046007, 0.082774, 0.010625, 0.73941, 0.011816, 0.043398, 0.020004]
Predicted label: 1
Correct prediction
Energy consumption = 160.806901 pJ
sum error= 59
Actual label: 4
Output voltages: [0.0090924, 0.023777, 0.41639, 0.0034431, 0.7987, 0.0010742, 0.040989, 0.017284, 0.015901, 0.52077]
Predicted label: 4
Correct prediction
Energy consumption = 156.013815 pJ
sum error= 59
Actual label: 6
Output voltages: [0.19828, 0.046982, 0.09066, 0.004224, 0.47971, 0.46488, 0.79878, 0.0021751, 0.41205, 0.0021838]
Predicted label: 6
Correct prediction
Energy consumption = 145.150617 pJ
sum error= 59
Actual label: 9
Output voltages: [0.72915, 0.0010924, 0.053175, 0.11919, 0.19927, 0.0079502, 0.0010888, 0.080651, 0.026567, 0.79277]
Predicted label: 9
Correct prediction
Energy consumption = 153.605384 pJ
sum error= 59
Actual label: 9
Output voltages: [0.233, 0.0077955, 0.048211, 0.094672, 0.11234, 0.083911, 0.054668, 0.031302, 0.12209, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 147.630280 pJ
sum error= 59
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 131 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 131 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 131 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.12906, 0.012967, 0.045898, 0.79873, 0.0082769, 0.069112, 0.0090255, 0.040156, 0.34272, 0.01525]
Predicted label: 3
Correct prediction
Energy consumption = 173.665304 pJ
sum error= 59
Actual label: 9
Output voltages: [0.36603, 0.027096, 0.01888, 0.064696, 0.038603, 0.023206, 0.011404, 0.066564, 0.34025, 0.79831]
Predicted label: 9
Correct prediction
Energy consumption = 155.349459 pJ
sum error= 59
Actual label: 8
Output voltages: [0.48991, 0.0016372, 0.024263, 0.034673, 0.067383, 0.0027312, 0.011179, 0.0043573, 0.77967, 0.56973]
Predicted label: 8
Correct prediction
Energy consumption = 147.557346 pJ
sum error= 59
Actual label: 4
Output voltages: [0.0019105, 0.0028192, 0.033907, 0.0073606, 0.79866, 0.0044274, 0.091612, 0.49216, 0.54479, 0.0038509]
Predicted label: 4
Correct prediction
Energy consumption = 153.740823 pJ
sum error= 59
Actual label: 4
Output voltages: [0.026977, 0.0020788, 0.28538, 0.0012802, 0.79863, 0.01043, 0.30956, 0.080225, 0.05419, 0.023739]
Predicted label: 4
Correct prediction
Energy consumption = 145.820211 pJ
sum error= 59
Actual label: 3
Output voltages: [0.091162, 0.0039342, 0.1, 0.79871, 0.26734, 0.70594, 0.042474, 0.014267, 0.38125, 0.037005]
Predicted label: 3
Correct prediction
Energy consumption = 146.906619 pJ
sum error= 59
Actual label: 1
Output voltages: [0.035677, 0.79868, 0.57298, 0.097292, 0.017953, 0.0011124, 0.31256, 0.0013964, 0.25711, 0.018083]
Predicted label: 1
Correct prediction
Energy consumption = 165.936477 pJ
sum error= 59
Actual label: 3
Output voltages: [0.036161, 0.027042, 0.064702, 0.79872, 0.017597, 0.0022111, 0.0063246, 0.0091424, 0.66342, 0.06151]
Predicted label: 3
Correct prediction
Energy consumption = 137.217660 pJ
sum error= 59
Actual label: 1
Output voltages: [0.019759, 0.79872, 0.024094, 0.0093352, 0.10678, 0.0018489, 0.60885, 0.013694, 0.13814, 0.053991]
Predicted label: 1
Correct prediction
Energy consumption = 162.035892 pJ
sum error= 59
Actual label: 8
Output voltages: [0.79869, 0.006601, 0.0033556, 0.52709, 0.0051709, 0.010215, 0.60063, 0.013839, 0.24979, 0.020958]
Predicted label: 0
Wrong prediction!
Energy consumption = 152.443081 pJ
sum error= 60
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 132 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 132 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 132 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.033595, 0.058228, 0.35998, 0.068201, 0.0065028, 0.0013684, 0.029697, 0.0026072, 0.79878, 0.19768]
Predicted label: 8
Correct prediction
Energy consumption = 169.960174 pJ
sum error= 60
Actual label: 7
Output voltages: [0.14927, 0.083173, 0.020428, 0.053041, 0.0028553, 0.0037203, 0.0010666, 0.79877, 0.36637, 0.53268]
Predicted label: 7
Correct prediction
Energy consumption = 163.022440 pJ
sum error= 60
Actual label: 9
Output voltages: [0.35574, 0.036197, 0.033689, 0.19109, 0.27176, 0.019158, 0.03158, 0.026957, 0.54097, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 143.744427 pJ
sum error= 60
Actual label: 4
Output voltages: [0.0016445, 0.0074012, 0.34803, 0.0089295, 0.79863, 0.0013782, 0.141, 0.041962, 0.02213, 0.096934]
Predicted label: 4
Correct prediction
Energy consumption = 152.446085 pJ
sum error= 60
Actual label: 8
Output voltages: [0.097366, 0.11414, 0.096846, 0.012581, 0.024772, 0.0088359, 0.012954, 0.026944, 0.79862, 0.11497]
Predicted label: 8
Correct prediction
Energy consumption = 157.272402 pJ
sum error= 60
Actual label: 8
Output voltages: [0.032126, 0.02938, 0.50324, 0.0075387, 0.204, 0.024393, 0.081728, 0.0013186, 0.79872, 0.11279]
Predicted label: 8
Correct prediction
Energy consumption = 138.289797 pJ
sum error= 60
Actual label: 7
Output voltages: [0.21595, 0.037035, 0.76603, 0.019326, 0.0077534, 0.0012053, 0.0067415, 0.71292, 0.69287, 0.5937]
Predicted label: 2
Wrong prediction!
Energy consumption = 149.752319 pJ
sum error= 61
Actual label: 9
Output voltages: [0.60681, 0.0073347, 0.069627, 0.14193, 0.038735, 0.21188, 0.0031245, 0.41764, 0.26354, 0.79764]
Predicted label: 9
Correct prediction
Energy consumption = 151.769889 pJ
sum error= 61
Actual label: 7
Output voltages: [0.050917, 0.14292, 0.018045, 0.10598, 0.035179, 0.0012793, 0.0032799, 0.79877, 0.30319, 0.54217]
Predicted label: 7
Correct prediction
Energy consumption = 158.537157 pJ
sum error= 61
Actual label: 1
Output voltages: [0.17233, 0.79845, 0.026482, 0.09224, 0.0013619, 0.013431, 0.68968, 0.0015797, 0.35824, 0.028476]
Predicted label: 1
Correct prediction
Energy consumption = 160.057969 pJ
sum error= 61
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 133 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 133 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 133 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.021699, 0.0097106, 0.06588, 0.034537, 0.79869, 0.016003, 0.022309, 0.01331, 0.20065, 0.034718]
Predicted label: 4
Correct prediction
Energy consumption = 175.051536 pJ
sum error= 61
Actual label: 5
Output voltages: [0.0014921, 0.001066, 0.01799, 0.44026, 0.070621, 0.73708, 0.13023, 0.016897, 0.77781, 0.17516]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.373013 pJ
sum error= 62
Actual label: 6
Output voltages: [0.15103, 0.041947, 0.13432, 0.0040092, 0.41623, 0.42531, 0.79871, 0.0026261, 0.47507, 0.013849]
Predicted label: 6
Correct prediction
Energy consumption = 144.973579 pJ
sum error= 62
Actual label: 0
Output voltages: [0.79876, 0.093584, 0.025155, 0.015893, 0.013293, 0.015647, 0.50519, 0.01534, 0.13761, 0.022489]
Predicted label: 0
Correct prediction
Energy consumption = 150.279822 pJ
sum error= 62
Actual label: 5
Output voltages: [0.0092924, 0.0010661, 0.0018653, 0.1395, 0.052016, 0.76507, 0.16143, 0.019535, 0.75421, 0.4594]
Predicted label: 5
Correct prediction
Energy consumption = 149.807516 pJ
sum error= 62
Actual label: 2
Output voltages: [0.40765, 0.19243, 0.79874, 0.23094, 0.036596, 0.0011847, 0.42814, 0.014565, 0.28755, 0.055211]
Predicted label: 2
Correct prediction
Energy consumption = 152.971020 pJ
sum error= 62
Actual label: 2
Output voltages: [0.24065, 0.36889, 0.79877, 0.044029, 0.017642, 0.0013733, 0.30948, 0.036177, 0.19867, 0.033396]
Predicted label: 2
Correct prediction
Energy consumption = 141.002104 pJ
sum error= 62
Actual label: 2
Output voltages: [0.57695, 0.020785, 0.59875, 0.15553, 0.13176, 0.033436, 0.79613, 0.53573, 0.24144, 0.001094]
Predicted label: 6
Wrong prediction!
Energy consumption = 147.005807 pJ
sum error= 63
Actual label: 1
Output voltages: [0.020262, 0.79854, 0.21061, 0.16303, 0.16213, 0.0025824, 0.16931, 0.022998, 0.028661, 0.22473]
Predicted label: 1
Correct prediction
Energy consumption = 160.959407 pJ
sum error= 63
Actual label: 5
Output voltages: [0.044316, 0.0011533, 0.0056654, 0.35402, 0.0087303, 0.79879, 0.088854, 0.052064, 0.67378, 0.027992]
Predicted label: 5
Correct prediction
Energy consumption = 145.467935 pJ
sum error= 63
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 134 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 134 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 134 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.036552, 0.0010811, 0.012721, 0.059952, 0.016682, 0.7976, 0.2499, 0.01125, 0.7907, 0.014256]
Predicted label: 5
Correct prediction
Energy consumption = 164.445141 pJ
sum error= 63
Actual label: 2
Output voltages: [0.46382, 0.042589, 0.79872, 0.11744, 0.019754, 0.0011718, 0.048519, 0.19396, 0.21486, 0.026482]
Predicted label: 2
Correct prediction
Energy consumption = 146.465074 pJ
sum error= 63
Actual label: 4
Output voltages: [0.048017, 0.0065377, 0.25603, 0.0073378, 0.79868, 0.0088648, 0.011218, 0.040234, 0.0179, 0.35774]
Predicted label: 4
Correct prediction
Energy consumption = 163.027762 pJ
sum error= 63
Actual label: 9
Output voltages: [0.46993, 0.0075435, 0.039191, 0.012283, 0.051643, 0.020268, 0.0068188, 0.19634, 0.36246, 0.79769]
Predicted label: 9
Correct prediction
Energy consumption = 143.874053 pJ
sum error= 63
Actual label: 6
Output voltages: [0.41323, 0.20175, 0.082224, 0.0038043, 0.052602, 0.27283, 0.79872, 0.039424, 0.5667, 0.0040716]
Predicted label: 6
Correct prediction
Energy consumption = 152.225097 pJ
sum error= 63
Actual label: 2
Output voltages: [0.30643, 0.002255, 0.79874, 0.068577, 0.0094832, 0.0011442, 0.035365, 0.74981, 0.50735, 0.0092273]
Predicted label: 2
Correct prediction
Energy consumption = 135.646892 pJ
sum error= 63
Actual label: 7
Output voltages: [0.094697, 0.011219, 0.05075, 0.27465, 0.0039442, 0.014956, 0.0011716, 0.79856, 0.39372, 0.26866]
Predicted label: 7
Correct prediction
Energy consumption = 149.009547 pJ
sum error= 63
Actual label: 7
Output voltages: [0.21039, 0.028587, 0.0065549, 0.0023872, 0.15226, 0.0058003, 0.0010794, 0.79879, 0.33587, 0.55897]
Predicted label: 7
Correct prediction
Energy consumption = 143.007191 pJ
sum error= 63
Actual label: 2
Output voltages: [0.60178, 0.20388, 0.79863, 0.25849, 0.010366, 0.0010661, 0.18356, 0.023618, 0.049963, 0.057711]
Predicted label: 2
Correct prediction
Energy consumption = 148.980668 pJ
sum error= 63
Actual label: 2
Output voltages: [0.11732, 0.082992, 0.79829, 0.24928, 0.0028751, 0.0012161, 0.010741, 0.18523, 0.68534, 0.012737]
Predicted label: 2
Correct prediction
Energy consumption = 137.154395 pJ
sum error= 63
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 135 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 135 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 135 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.019643, 0.79835, 0.085613, 0.063116, 0.011583, 0.0026481, 0.56633, 0.0086681, 0.36921, 0.13352]
Predicted label: 1
Correct prediction
Energy consumption = 180.033304 pJ
sum error= 63
Actual label: 1
Output voltages: [0.026761, 0.79871, 0.058085, 0.013722, 0.038864, 0.0010661, 0.56486, 0.0010717, 0.35616, 0.008837]
Predicted label: 1
Correct prediction
Energy consumption = 153.472110 pJ
sum error= 63
Actual label: 2
Output voltages: [0.67136, 0.0092665, 0.79879, 0.043159, 0.0033258, 0.0010894, 0.28393, 0.031484, 0.56574, 0.0076433]
Predicted label: 2
Correct prediction
Energy consumption = 144.398621 pJ
sum error= 63
Actual label: 8
Output voltages: [0.010739, 0.1198, 0.21882, 0.058481, 0.013946, 0.013714, 0.036348, 0.032912, 0.79876, 0.35784]
Predicted label: 8
Correct prediction
Energy consumption = 156.432024 pJ
sum error= 63
Actual label: 3
Output voltages: [0.40851, 0.07252, 0.19319, 0.79879, 0.0030904, 0.0011531, 0.0054486, 0.0050402, 0.28702, 0.023684]
Predicted label: 3
Correct prediction
Energy consumption = 145.737724 pJ
sum error= 63
Actual label: 7
Output voltages: [0.019465, 0.040645, 0.060463, 0.0059007, 0.71193, 0.0011921, 0.0011674, 0.71425, 0.50676, 0.49914]
Predicted label: 7
Correct prediction
Energy consumption = 159.548805 pJ
sum error= 63
Actual label: 2
Output voltages: [0.75459, 0.39186, 0.79873, 0.11975, 0.011636, 0.0011453, 0.075124, 0.053087, 0.31418, 0.029954]
Predicted label: 2
Correct prediction
Energy consumption = 153.501317 pJ
sum error= 63
Actual label: 4
Output voltages: [0.17158, 0.018286, 0.058252, 0.0039459, 0.79729, 0.0010862, 0.36129, 0.12585, 0.0019784, 0.69567]
Predicted label: 4
Correct prediction
Energy consumption = 160.556087 pJ
sum error= 63
Actual label: 1
Output voltages: [0.037081, 0.79864, 0.40995, 0.53166, 0.0056766, 0.0010663, 0.3436, 0.01531, 0.030331, 0.024539]
Predicted label: 1
Correct prediction
Energy consumption = 165.528179 pJ
sum error= 63
Actual label: 7
Output voltages: [0.077071, 0.023514, 0.41992, 0.078284, 0.0016965, 0.0012733, 0.001066, 0.79866, 0.47981, 0.02246]
Predicted label: 7
Correct prediction
Energy consumption = 151.930392 pJ
sum error= 63
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 136 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 136 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 136 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.034596, 0.79862, 0.029013, 0.31885, 0.0025076, 0.021323, 0.34844, 0.05683, 0.55959, 0.03447]
Predicted label: 1
Correct prediction
Energy consumption = 182.755995 pJ
sum error= 63
Actual label: 7
Output voltages: [0.032388, 0.25986, 0.37669, 0.36915, 0.0041487, 0.001386, 0.0010948, 0.79871, 0.50357, 0.18648]
Predicted label: 7
Correct prediction
Energy consumption = 153.215966 pJ
sum error= 63
Actual label: 6
Output voltages: [0.05831, 0.12903, 0.3248, 0.0015571, 0.55225, 0.24037, 0.79865, 0.0023228, 0.035503, 0.011469]
Predicted label: 6
Correct prediction
Energy consumption = 151.253099 pJ
sum error= 63
Actual label: 7
Output voltages: [0.1452, 0.29981, 0.76259, 0.099432, 0.054702, 0.0014039, 0.010006, 0.78976, 0.0026986, 0.46155]
Predicted label: 7
Correct prediction
Energy consumption = 148.134820 pJ
sum error= 63
Actual label: 8
Output voltages: [0.41328, 0.0011521, 0.23085, 0.16385, 0.009481, 0.017673, 0.0096525, 0.020451, 0.79878, 0.16785]
Predicted label: 8
Correct prediction
Energy consumption = 149.270824 pJ
sum error= 63
Actual label: 2
Output voltages: [0.24046, 0.53802, 0.79856, 0.053824, 0.0089217, 0.0010662, 0.040876, 0.30035, 0.21854, 0.033797]
Predicted label: 2
Correct prediction
Energy consumption = 144.831732 pJ
sum error= 63
Actual label: 7
Output voltages: [0.040857, 0.0096617, 0.033513, 0.032075, 0.0029991, 0.017574, 0.0011055, 0.79867, 0.63653, 0.14701]
Predicted label: 7
Correct prediction
Energy consumption = 149.698690 pJ
sum error= 63
Actual label: 3
Output voltages: [0.49308, 0.010078, 0.39002, 0.79877, 0.016054, 0.0061624, 0.010492, 0.032263, 0.68943, 0.021831]
Predicted label: 3
Correct prediction
Energy consumption = 138.028027 pJ
sum error= 63
Actual label: 1
Output voltages: [0.077131, 0.7985, 0.01276, 0.099782, 0.0038117, 0.024656, 0.26926, 0.0019526, 0.034614, 0.052324]
Predicted label: 1
Correct prediction
Energy consumption = 167.390109 pJ
sum error= 63
Actual label: 7
Output voltages: [0.086198, 0.007263, 0.053666, 0.40767, 0.0021982, 0.043544, 0.0011328, 0.79856, 0.38312, 0.28454]
Predicted label: 7
Correct prediction
Energy consumption = 148.224117 pJ
sum error= 63
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 137 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 137 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 137 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.024797, 0.001133, 0.0038301, 0.17584, 0.016218, 0.78269, 0.079772, 0.017838, 0.77406, 0.06388]
Predicted label: 5
Correct prediction
Energy consumption = 166.906796 pJ
sum error= 63
Actual label: 8
Output voltages: [0.045166, 0.012178, 0.028998, 0.08521, 0.0083043, 0.035696, 0.010781, 0.0016301, 0.79879, 0.55785]
Predicted label: 8
Correct prediction
Energy consumption = 148.133339 pJ
sum error= 63
Actual label: 2
Output voltages: [0.21751, 0.068382, 0.79876, 0.33701, 0.0033461, 0.0013172, 0.31366, 0.28763, 0.40933, 0.027447]
Predicted label: 2
Correct prediction
Energy consumption = 144.675596 pJ
sum error= 63
Actual label: 6
Output voltages: [0.14612, 0.07369, 0.047533, 0.006723, 0.2099, 0.25484, 0.79879, 0.0027286, 0.45356, 0.0020493]
Predicted label: 6
Correct prediction
Energy consumption = 149.943333 pJ
sum error= 63
Actual label: 2
Output voltages: [0.42799, 0.0044275, 0.79876, 0.16655, 0.0033005, 0.0010698, 0.022949, 0.028423, 0.71131, 0.0023684]
Predicted label: 2
Correct prediction
Energy consumption = 144.535659 pJ
sum error= 63
Actual label: 2
Output voltages: [0.28695, 0.35475, 0.79879, 0.07115, 0.011831, 0.0012355, 0.12465, 0.015631, 0.46109, 0.060333]
Predicted label: 2
Correct prediction
Energy consumption = 142.951197 pJ
sum error= 63
Actual label: 5
Output voltages: [0.022153, 0.0010667, 0.0011675, 0.046841, 0.025756, 0.78947, 0.087665, 0.0082942, 0.79085, 0.074568]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.859734 pJ
sum error= 64
Actual label: 6
Output voltages: [0.019337, 0.0096808, 0.21731, 0.011262, 0.06946, 0.4603, 0.79859, 0.0011201, 0.69975, 0.062709]
Predicted label: 6
Correct prediction
Energy consumption = 138.977210 pJ
sum error= 64
Actual label: 5
Output voltages: [0.18943, 0.0076894, 0.0011865, 0.27918, 0.004737, 0.78531, 0.78553, 0.0011758, 0.68856, 0.0012302]
Predicted label: 6
Wrong prediction!
Energy consumption = 140.071197 pJ
sum error= 65
Actual label: 0
Output voltages: [0.79877, 0.26439, 0.013339, 0.032971, 0.0051727, 0.038808, 0.62693, 0.026254, 0.22939, 0.042187]
Predicted label: 0
Correct prediction
Energy consumption = 144.798391 pJ
sum error= 65
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 138 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 138 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 138 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33519, 0.01223, 0.018523, 0.15306, 0.05532, 0.092701, 0.018234, 0.011122, 0.37037, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 174.462011 pJ
sum error= 65
Actual label: 2
Output voltages: [0.30185, 0.041759, 0.79875, 0.1902, 0.0083239, 0.0012093, 0.15858, 0.0096229, 0.68074, 0.0084677]
Predicted label: 2
Correct prediction
Energy consumption = 148.320535 pJ
sum error= 65
Actual label: 4
Output voltages: [0.0078495, 0.013521, 0.21908, 0.0046223, 0.79854, 0.0082439, 0.090063, 0.045588, 0.045885, 0.031273]
Predicted label: 4
Correct prediction
Energy consumption = 154.244893 pJ
sum error= 65
Actual label: 3
Output voltages: [0.624, 0.038244, 0.28261, 0.79878, 0.0112, 0.055186, 0.06046, 0.0019506, 0.17598, 0.0027059]
Predicted label: 3
Correct prediction
Energy consumption = 149.134594 pJ
sum error= 65
Actual label: 3
Output voltages: [0.043673, 0.21177, 0.028123, 0.79863, 0.0057036, 0.0022988, 0.0069267, 0.046534, 0.38791, 0.17921]
Predicted label: 3
Correct prediction
Energy consumption = 144.532486 pJ
sum error= 65
Actual label: 9
Output voltages: [0.27845, 0.010694, 0.082825, 0.010412, 0.068012, 0.012722, 0.0038182, 0.04558, 0.59829, 0.79667]
Predicted label: 9
Correct prediction
Energy consumption = 151.511733 pJ
sum error= 65
Actual label: 7
Output voltages: [0.044117, 0.0039979, 0.19846, 0.026554, 0.03857, 0.018721, 0.001066, 0.79876, 0.029037, 0.54317]
Predicted label: 7
Correct prediction
Energy consumption = 146.686865 pJ
sum error= 65
Actual label: 6
Output voltages: [0.16312, 0.050001, 0.32858, 0.0022423, 0.44831, 0.36827, 0.79867, 0.0020354, 0.38553, 0.0060492]
Predicted label: 6
Correct prediction
Energy consumption = 153.080549 pJ
sum error= 65
Actual label: 6
Output voltages: [0.21251, 0.054065, 0.55529, 0.0026315, 0.3163, 0.15232, 0.79878, 0.003145, 0.63716, 0.071579]
Predicted label: 6
Correct prediction
Energy consumption = 141.843873 pJ
sum error= 65
Actual label: 8
Output voltages: [0.030831, 0.037784, 0.046016, 0.32618, 0.0072093, 0.011569, 0.027765, 0.0047974, 0.79878, 0.058573]
Predicted label: 8
Correct prediction
Energy consumption = 143.526091 pJ
sum error= 65
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 139 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 139 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 139 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.044985, 0.045456, 0.015492, 0.030394, 0.0033247, 0.71386, 0.015732, 0.042739, 0.30345]
Predicted label: 0
Correct prediction
Energy consumption = 170.417487 pJ
sum error= 65
Actual label: 4
Output voltages: [0.010019, 0.017124, 0.15171, 0.0032526, 0.79878, 0.06836, 0.18291, 0.010334, 0.061145, 0.30409]
Predicted label: 4
Correct prediction
Energy consumption = 165.168263 pJ
sum error= 65
Actual label: 1
Output voltages: [0.052288, 0.79865, 0.20907, 0.033914, 0.016262, 0.0029175, 0.081196, 0.010619, 0.35172, 0.019277]
Predicted label: 1
Correct prediction
Energy consumption = 171.280546 pJ
sum error= 65
Actual label: 5
Output voltages: [0.1545, 0.0010667, 0.027005, 0.77979, 0.0010936, 0.47564, 0.0093843, 0.53236, 0.51214, 0.001644]
Predicted label: 3
Wrong prediction!
Energy consumption = 148.987454 pJ
sum error= 66
Actual label: 8
Output voltages: [0.013134, 0.012763, 0.12469, 0.74482, 0.0016695, 0.0091554, 0.022431, 0.0057153, 0.79812, 0.47751]
Predicted label: 8
Correct prediction
Energy consumption = 151.179083 pJ
sum error= 66
Actual label: 2
Output voltages: [0.3758, 0.0022585, 0.76412, 0.74641, 0.033411, 0.0013213, 0.029307, 0.13381, 0.64196, 0.023929]
Predicted label: 2
Correct prediction
Energy consumption = 145.165896 pJ
sum error= 66
Actual label: 9
Output voltages: [0.041799, 0.038806, 0.022418, 0.062111, 0.13744, 0.0079147, 0.0049816, 0.01431, 0.44715, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 151.991606 pJ
sum error= 66
Actual label: 1
Output voltages: [0.0041661, 0.7986, 0.021404, 0.10735, 0.15125, 0.0052513, 0.12254, 0.015491, 0.26085, 0.33527]
Predicted label: 1
Correct prediction
Energy consumption = 161.612610 pJ
sum error= 66
Actual label: 8
Output voltages: [0.080606, 0.060855, 0.31312, 0.089512, 0.0052515, 0.026626, 0.031487, 0.024538, 0.7987, 0.45632]
Predicted label: 8
Correct prediction
Energy consumption = 156.488103 pJ
sum error= 66
Actual label: 0
Output voltages: [0.79868, 0.11103, 0.0422, 0.0028474, 0.011759, 0.02526, 0.75152, 0.021334, 0.055921, 0.014018]
Predicted label: 0
Correct prediction
Energy consumption = 150.385039 pJ
sum error= 66
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 140 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 140 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 140 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.053485, 0.020293, 0.086239, 0.0031342, 0.39583, 0.19391, 0.79879, 0.0097771, 0.68077, 0.012675]
Predicted label: 6
Correct prediction
Energy consumption = 166.713119 pJ
sum error= 66
Actual label: 7
Output voltages: [0.32806, 0.046012, 0.006174, 0.20188, 0.022804, 0.012045, 0.0014224, 0.79877, 0.093768, 0.64341]
Predicted label: 7
Correct prediction
Energy consumption = 160.218737 pJ
sum error= 66
Actual label: 2
Output voltages: [0.23198, 0.031256, 0.7983, 0.024566, 0.029262, 0.001456, 0.043158, 0.67961, 0.31993, 0.016475]
Predicted label: 2
Correct prediction
Energy consumption = 137.559681 pJ
sum error= 66
Actual label: 1
Output voltages: [0.029048, 0.79868, 0.13949, 0.018685, 0.035392, 0.0081027, 0.78674, 0.0010682, 0.4517, 0.049309]
Predicted label: 1
Correct prediction
Energy consumption = 149.395716 pJ
sum error= 66
Actual label: 0
Output voltages: [0.79774, 0.064084, 0.14642, 0.039158, 0.018738, 0.003528, 0.50001, 0.014318, 0.52644, 0.049401]
Predicted label: 0
Correct prediction
Energy consumption = 156.704840 pJ
sum error= 66
Actual label: 5
Output voltages: [0.10397, 0.0019242, 0.0011311, 0.49846, 0.030821, 0.79874, 0.39013, 0.016555, 0.76317, 0.0035413]
Predicted label: 5
Correct prediction
Energy consumption = 149.313043 pJ
sum error= 66
Actual label: 5
Output voltages: [0.043148, 0.0081368, 0.0063279, 0.037611, 0.021319, 0.79879, 0.19579, 0.037416, 0.77964, 0.055839]
Predicted label: 5
Correct prediction
Energy consumption = 142.880041 pJ
sum error= 66
Actual label: 2
Output voltages: [0.54514, 0.0031597, 0.79875, 0.056861, 0.034037, 0.0011157, 0.072745, 0.050061, 0.56431, 0.015485]
Predicted label: 2
Correct prediction
Energy consumption = 145.619885 pJ
sum error= 66
Actual label: 0
Output voltages: [0.79407, 0.027712, 0.024033, 0.0030447, 0.0095034, 0.0048522, 0.75399, 0.11338, 0.038028, 0.062432]
Predicted label: 0
Correct prediction
Energy consumption = 143.985475 pJ
sum error= 66
Actual label: 2
Output voltages: [0.7474, 0.35246, 0.79878, 0.015787, 0.0061048, 0.0013685, 0.64238, 0.2101, 0.31394, 0.031934]
Predicted label: 2
Correct prediction
Energy consumption = 145.900387 pJ
sum error= 66
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 141 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 141 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 141 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.22297, 0.2111, 0.79212, 0.41451, 0.035693, 0.0010714, 0.65285, 0.188, 0.11492, 0.0020645]
Predicted label: 2
Correct prediction
Energy consumption = 173.284931 pJ
sum error= 66
Actual label: 0
Output voltages: [0.79777, 0.025819, 0.019022, 0.19134, 0.16841, 0.019267, 0.37791, 0.029883, 0.48235, 0.41447]
Predicted label: 0
Correct prediction
Energy consumption = 169.517507 pJ
sum error= 66
Actual label: 2
Output voltages: [0.24419, 0.47504, 0.79877, 0.049045, 0.023051, 0.0012962, 0.30502, 0.014538, 0.11302, 0.056754]
Predicted label: 2
Correct prediction
Energy consumption = 150.786523 pJ
sum error= 66
Actual label: 4
Output voltages: [0.022766, 0.081509, 0.049622, 0.0054814, 0.79864, 0.005348, 0.39521, 0.018835, 0.054993, 0.14257]
Predicted label: 4
Correct prediction
Energy consumption = 157.315149 pJ
sum error= 66
Actual label: 9
Output voltages: [0.53546, 0.53489, 0.0019481, 0.36501, 0.053334, 0.038652, 0.0081309, 0.049304, 0.01429, 0.79702]
Predicted label: 9
Correct prediction
Energy consumption = 164.530805 pJ
sum error= 66
Actual label: 8
Output voltages: [0.020958, 0.0012837, 0.035093, 0.061487, 0.018125, 0.20854, 0.7011, 0.0010824, 0.79112, 0.042458]
Predicted label: 8
Correct prediction
Energy consumption = 152.192261 pJ
sum error= 66
Actual label: 0
Output voltages: [0.79879, 0.022391, 0.023144, 0.031632, 0.027479, 0.0038942, 0.64351, 0.0017133, 0.019533, 0.52451]
Predicted label: 0
Correct prediction
Energy consumption = 155.950423 pJ
sum error= 66
Actual label: 9
Output voltages: [0.3949, 0.021426, 0.034274, 0.29271, 0.03381, 0.072083, 0.003248, 0.42235, 0.20816, 0.7967]
Predicted label: 9
Correct prediction
Energy consumption = 147.537189 pJ
sum error= 66
Actual label: 9
Output voltages: [0.37133, 0.015596, 0.004722, 0.19982, 0.041333, 0.086229, 0.010439, 0.040741, 0.05298, 0.7979]
Predicted label: 9
Correct prediction
Energy consumption = 143.094887 pJ
sum error= 66
Actual label: 4
Output voltages: [0.024426, 0.017607, 0.055779, 0.010922, 0.79861, 0.0041655, 0.24358, 0.30927, 0.043784, 0.065667]
Predicted label: 4
Correct prediction
Energy consumption = 143.677208 pJ
sum error= 66
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 142 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 142 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 142 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.055105, 0.040898, 0.21756, 0.0038465, 0.2089, 0.41139, 0.79874, 0.010078, 0.55616, 0.011815]
Predicted label: 6
Correct prediction
Energy consumption = 167.894911 pJ
sum error= 66
Actual label: 5
Output voltages: [0.035591, 0.0011277, 0.0011058, 0.067901, 0.23701, 0.78339, 0.43571, 0.0012011, 0.78683, 0.02645]
Predicted label: 8
Wrong prediction!
Energy consumption = 139.104420 pJ
sum error= 67
Actual label: 4
Output voltages: [0.082086, 0.01297, 0.1597, 0.016248, 0.79877, 0.0030945, 0.25251, 0.017664, 0.015255, 0.14612]
Predicted label: 4
Correct prediction
Energy consumption = 155.169555 pJ
sum error= 67
Actual label: 9
Output voltages: [0.087461, 0.0014307, 0.045584, 0.22611, 0.17059, 0.0054586, 0.0017118, 0.16778, 0.5601, 0.7942]
Predicted label: 9
Correct prediction
Energy consumption = 139.414980 pJ
sum error= 67
Actual label: 1
Output voltages: [0.027771, 0.79844, 0.0033718, 0.18865, 0.012397, 0.0012059, 0.66982, 0.003839, 0.34061, 0.081507]
Predicted label: 1
Correct prediction
Energy consumption = 161.032944 pJ
sum error= 67
Actual label: 8
Output voltages: [0.017574, 0.032411, 0.22931, 0.022472, 0.51693, 0.059277, 0.463, 0.0011503, 0.75543, 0.0084834]
Predicted label: 8
Correct prediction
Energy consumption = 150.455691 pJ
sum error= 67
Actual label: 3
Output voltages: [0.1712, 0.026898, 0.038133, 0.79866, 0.024646, 0.0040355, 0.012262, 0.01533, 0.54746, 0.083069]
Predicted label: 3
Correct prediction
Energy consumption = 139.391730 pJ
sum error= 67
Actual label: 4
Output voltages: [0.034758, 0.0020996, 0.37922, 0.0085284, 0.79874, 0.0010689, 0.33291, 0.013599, 0.072618, 0.034249]
Predicted label: 4
Correct prediction
Energy consumption = 144.292278 pJ
sum error= 67
Actual label: 9
Output voltages: [0.34803, 0.012922, 0.2916, 0.01122, 0.2936, 0.0062091, 0.0044254, 0.0092486, 0.25375, 0.79689]
Predicted label: 9
Correct prediction
Energy consumption = 147.052388 pJ
sum error= 67
Actual label: 9
Output voltages: [0.43149, 0.0028189, 0.022549, 0.0085257, 0.15094, 0.009231, 0.028949, 0.018288, 0.38082, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 141.310359 pJ
sum error= 67
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 143 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 143 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 143 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.017901, 0.79849, 0.014234, 0.08562, 0.0065416, 0.0013308, 0.48724, 0.0032567, 0.53938, 0.018022]
Predicted label: 1
Correct prediction
Energy consumption = 178.904725 pJ
sum error= 67
Actual label: 2
Output voltages: [0.23854, 0.15391, 0.79855, 0.3011, 0.0056999, 0.0013353, 0.14628, 0.077621, 0.5871, 0.075016]
Predicted label: 2
Correct prediction
Energy consumption = 153.805834 pJ
sum error= 67
Actual label: 2
Output voltages: [0.37934, 0.13925, 0.79879, 0.072907, 0.0095972, 0.001324, 0.50287, 0.0083273, 0.52215, 0.029041]
Predicted label: 2
Correct prediction
Energy consumption = 137.454600 pJ
sum error= 67
Actual label: 8
Output voltages: [0.024951, 0.77603, 0.0056745, 0.61044, 0.0021149, 0.0078768, 0.010387, 0.057118, 0.79399, 0.069399]
Predicted label: 8
Correct prediction
Energy consumption = 152.906346 pJ
sum error= 67
Actual label: 1
Output voltages: [0.044603, 0.79848, 0.034758, 0.034932, 0.028867, 0.0027594, 0.43728, 0.0014913, 0.25832, 0.030966]
Predicted label: 1
Correct prediction
Energy consumption = 153.910147 pJ
sum error= 67
Actual label: 9
Output voltages: [0.31254, 0.0010855, 0.088131, 0.017323, 0.14019, 0.015872, 0.001237, 0.28843, 0.41151, 0.79575]
Predicted label: 9
Correct prediction
Energy consumption = 160.414885 pJ
sum error= 67
Actual label: 6
Output voltages: [0.063179, 0.019127, 0.024806, 0.010198, 0.064691, 0.05144, 0.79483, 0.010497, 0.78511, 0.0037407]
Predicted label: 6
Correct prediction
Energy consumption = 150.607254 pJ
sum error= 67
Actual label: 4
Output voltages: [0.042146, 0.021728, 0.0539, 0.011054, 0.79697, 0.046871, 0.020436, 0.0058765, 0.09741, 0.73844]
Predicted label: 4
Correct prediction
Energy consumption = 158.286351 pJ
sum error= 67
Actual label: 0
Output voltages: [0.79871, 0.24233, 0.045637, 0.0072312, 0.040899, 0.025979, 0.77155, 0.025674, 0.18071, 0.0064895]
Predicted label: 0
Correct prediction
Energy consumption = 156.150823 pJ
sum error= 67
Actual label: 9
Output voltages: [0.26448, 0.019659, 0.013328, 0.051973, 0.51373, 0.0014558, 0.0012453, 0.0011436, 0.16859, 0.79792]
Predicted label: 9
Correct prediction
Energy consumption = 154.485925 pJ
sum error= 67
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 144 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 144 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 144 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.013895, 0.037305, 0.032722, 0.004812, 0.797, 0.014867, 0.03017, 0.0042475, 0.51316, 0.039124]
Predicted label: 4
Correct prediction
Energy consumption = 156.899818 pJ
sum error= 67
Actual label: 8
Output voltages: [0.037418, 0.0070169, 0.038627, 0.17162, 0.04345, 0.0045993, 0.0056756, 0.017599, 0.79748, 0.55832]
Predicted label: 8
Correct prediction
Energy consumption = 155.287380 pJ
sum error= 67
Actual label: 3
Output voltages: [0.54966, 0.010798, 0.14867, 0.79872, 0.022995, 0.0083856, 0.0048609, 0.01594, 0.54992, 0.040874]
Predicted label: 3
Correct prediction
Energy consumption = 145.657900 pJ
sum error= 67
Actual label: 8
Output voltages: [0.03223, 0.083899, 0.14705, 0.307, 0.02252, 0.022959, 0.032331, 0.014048, 0.79868, 0.31169]
Predicted label: 8
Correct prediction
Energy consumption = 145.481187 pJ
sum error= 67
Actual label: 6
Output voltages: [0.59607, 0.0034643, 0.051108, 0.001096, 0.65915, 0.019608, 0.79743, 0.033291, 0.14631, 0.0045219]
Predicted label: 6
Correct prediction
Energy consumption = 156.871920 pJ
sum error= 67
Actual label: 0
Output voltages: [0.79869, 0.060163, 0.13271, 0.012996, 0.021586, 0.0048603, 0.63435, 0.0095938, 0.14337, 0.4084]
Predicted label: 0
Correct prediction
Energy consumption = 157.350910 pJ
sum error= 67
Actual label: 2
Output voltages: [0.35434, 0.015882, 0.79878, 0.049858, 0.01202, 0.0011319, 0.10601, 0.02954, 0.74583, 0.0093507]
Predicted label: 2
Correct prediction
Energy consumption = 142.430000 pJ
sum error= 67
Actual label: 5
Output voltages: [0.050193, 0.0010716, 0.0011048, 0.28981, 0.4072, 0.79875, 0.61114, 0.014278, 0.77938, 0.047117]
Predicted label: 5
Correct prediction
Energy consumption = 150.742045 pJ
sum error= 67
Actual label: 1
Output voltages: [0.042122, 0.79854, 0.15764, 0.019269, 0.037834, 0.0017291, 0.50012, 0.0077823, 0.083744, 0.11516]
Predicted label: 1
Correct prediction
Energy consumption = 168.595218 pJ
sum error= 67
Actual label: 9
Output voltages: [0.72112, 0.0034283, 0.029074, 0.016818, 0.018932, 0.030508, 0.0027605, 0.31028, 0.44019, 0.79723]
Predicted label: 9
Correct prediction
Energy consumption = 154.704140 pJ
sum error= 67
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 145 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 145 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 145 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.39241, 0.035995, 0.23581, 0.016349, 0.23756, 0.28233, 0.79878, 0.0012792, 0.37157, 0.029553]
Predicted label: 6
Correct prediction
Energy consumption = 161.268854 pJ
sum error= 67
Actual label: 2
Output voltages: [0.78544, 0.014329, 0.79879, 0.3173, 0.0032114, 0.0012613, 0.14065, 0.33324, 0.68739, 0.011039]
Predicted label: 2
Correct prediction
Energy consumption = 151.878779 pJ
sum error= 67
Actual label: 9
Output voltages: [0.52711, 0.0053529, 0.027029, 0.012944, 0.4569, 0.017049, 0.0015094, 0.011274, 0.3514, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 157.273266 pJ
sum error= 67
Actual label: 4
Output voltages: [0.019012, 0.026141, 0.095382, 0.0092092, 0.79865, 0.0038091, 0.039758, 0.0098662, 0.021591, 0.29658]
Predicted label: 4
Correct prediction
Energy consumption = 144.185645 pJ
sum error= 67
Actual label: 0
Output voltages: [0.79877, 0.20101, 0.078753, 0.0059831, 0.0025549, 0.012189, 0.33914, 0.042198, 0.42074, 0.18523]
Predicted label: 0
Correct prediction
Energy consumption = 161.474252 pJ
sum error= 67
Actual label: 9
Output voltages: [0.22642, 0.0020354, 0.02952, 0.187, 0.77647, 0.0012007, 0.0014373, 0.0044023, 0.052517, 0.79702]
Predicted label: 9
Correct prediction
Energy consumption = 153.497601 pJ
sum error= 67
Actual label: 6
Output voltages: [0.15608, 0.1768, 0.33421, 0.002218, 0.24879, 0.18501, 0.79869, 0.0093426, 0.27328, 0.0053278]
Predicted label: 6
Correct prediction
Energy consumption = 152.791328 pJ
sum error= 67
Actual label: 0
Output voltages: [0.79873, 0.21767, 0.026324, 0.0085042, 0.017364, 0.016006, 0.37525, 0.014459, 0.12921, 0.054672]
Predicted label: 0
Correct prediction
Energy consumption = 144.022675 pJ
sum error= 67
Actual label: 6
Output voltages: [0.26708, 0.057713, 0.28203, 0.019866, 0.065425, 0.45538, 0.79873, 0.0065662, 0.33726, 0.06813]
Predicted label: 6
Correct prediction
Energy consumption = 143.336434 pJ
sum error= 67
Actual label: 2
Output voltages: [0.046462, 0.023208, 0.79878, 0.32607, 0.017807, 0.0010662, 0.0085455, 0.6594, 0.51457, 0.0092588]
Predicted label: 2
Correct prediction
Energy consumption = 151.146095 pJ
sum error= 67
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 146 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 146 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 146 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.0088073, 0.0010819, 0.0029444, 0.089676, 0.037176, 0.77632, 0.047935, 0.0033355, 0.78389, 0.14581]
Predicted label: 8
Wrong prediction!
Energy consumption = 161.922872 pJ
sum error= 68
Actual label: 4
Output voltages: [0.027849, 0.011227, 0.3885, 0.0028258, 0.79856, 0.0094042, 0.36626, 0.035628, 0.030531, 0.095883]
Predicted label: 4
Correct prediction
Energy consumption = 151.875618 pJ
sum error= 68
Actual label: 2
Output voltages: [0.71309, 0.0013681, 0.76954, 0.73721, 0.010739, 0.0011277, 0.0040913, 0.021352, 0.55697, 0.002007]
Predicted label: 2
Correct prediction
Energy consumption = 151.957452 pJ
sum error= 68
Actual label: 3
Output voltages: [0.084585, 0.016162, 0.027089, 0.7987, 0.017304, 0.0091793, 0.0093401, 0.010323, 0.39285, 0.042666]
Predicted label: 3
Correct prediction
Energy consumption = 136.022467 pJ
sum error= 68
Actual label: 8
Output voltages: [0.021213, 0.12853, 0.020555, 0.03117, 0.017117, 0.057572, 0.021443, 0.099131, 0.79865, 0.30381]
Predicted label: 8
Correct prediction
Energy consumption = 152.071904 pJ
sum error= 68
Actual label: 4
Output voltages: [0.0017575, 0.065804, 0.32965, 0.015103, 0.79879, 0.0011785, 0.37925, 0.032901, 0.034866, 0.025932]
Predicted label: 4
Correct prediction
Energy consumption = 152.871528 pJ
sum error= 68
Actual label: 5
Output voltages: [0.48769, 0.028952, 0.0011607, 0.73238, 0.0057452, 0.79868, 0.014929, 0.0084535, 0.7417, 0.13819]
Predicted label: 5
Correct prediction
Energy consumption = 154.752352 pJ
sum error= 68
Actual label: 5
Output voltages: [0.019965, 0.0019489, 0.001428, 0.20818, 0.10676, 0.79739, 0.027646, 0.13244, 0.72491, 0.55256]
Predicted label: 5
Correct prediction
Energy consumption = 143.751159 pJ
sum error= 68
Actual label: 0
Output voltages: [0.79846, 0.028435, 0.18135, 0.0042391, 0.010021, 0.0019052, 0.47293, 0.0055278, 0.29021, 0.027311]
Predicted label: 0
Correct prediction
Energy consumption = 145.624644 pJ
sum error= 68
Actual label: 3
Output voltages: [0.023645, 0.020141, 0.47024, 0.7986, 0.0038259, 0.4657, 0.47171, 0.042307, 0.013937, 0.0016716]
Predicted label: 3
Correct prediction
Energy consumption = 145.512524 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 147 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 147 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 147 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.017779, 0.0048022, 0.082782, 0.18806, 0.0011194, 0.27254, 0.0026587, 0.044858, 0.79874, 0.0044661]
Predicted label: 8
Correct prediction
Energy consumption = 162.070551 pJ
sum error= 68
Actual label: 5
Output voltages: [0.019137, 0.0017371, 0.0020212, 0.48705, 0.0075987, 0.79868, 0.2203, 0.014802, 0.75297, 0.041299]
Predicted label: 5
Correct prediction
Energy consumption = 143.448663 pJ
sum error= 68
Actual label: 3
Output voltages: [0.35537, 0.001066, 0.040904, 0.79879, 0.031976, 0.43755, 0.0050757, 0.011555, 0.4551, 0.024086]
Predicted label: 3
Correct prediction
Energy consumption = 138.624346 pJ
sum error= 68
Actual label: 5
Output voltages: [0.031778, 0.0060548, 0.0020107, 0.14094, 0.02072, 0.79865, 0.34004, 0.034744, 0.52957, 0.058412]
Predicted label: 5
Correct prediction
Energy consumption = 148.518958 pJ
sum error= 68
Actual label: 8
Output voltages: [0.023582, 0.056176, 0.11003, 0.34811, 0.018686, 0.0070856, 0.0069344, 0.025567, 0.79874, 0.2566]
Predicted label: 8
Correct prediction
Energy consumption = 150.843618 pJ
sum error= 68
Actual label: 6
Output voltages: [0.35298, 0.024719, 0.059792, 0.0019479, 0.15509, 0.027291, 0.79874, 0.0022351, 0.68336, 0.012382]
Predicted label: 6
Correct prediction
Energy consumption = 155.271132 pJ
sum error= 68
Actual label: 5
Output voltages: [0.55675, 0.0016264, 0.0027124, 0.72351, 0.073147, 0.79879, 0.35246, 0.050987, 0.36043, 0.63598]
Predicted label: 5
Correct prediction
Energy consumption = 150.780657 pJ
sum error= 68
Actual label: 7
Output voltages: [0.13455, 0.046749, 0.03954, 0.15694, 0.032655, 0.0015605, 0.001834, 0.79849, 0.038173, 0.027383]
Predicted label: 7
Correct prediction
Energy consumption = 148.722226 pJ
sum error= 68
Actual label: 6
Output voltages: [0.058641, 0.024726, 0.026737, 0.014981, 0.36038, 0.11881, 0.79879, 0.0042029, 0.75446, 0.0061204]
Predicted label: 6
Correct prediction
Energy consumption = 157.652585 pJ
sum error= 68
Actual label: 3
Output voltages: [0.048977, 0.02036, 0.16189, 0.79877, 0.016696, 0.002328, 0.0068708, 0.027076, 0.72781, 0.020659]
Predicted label: 3
Correct prediction
Energy consumption = 144.035774 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 148 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 148 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 148 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.12123, 0.0027733, 0.046709, 0.79879, 0.1196, 0.0024215, 0.012048, 0.033254, 0.66246, 0.055711]
Predicted label: 3
Correct prediction
Energy consumption = 160.950735 pJ
sum error= 68
Actual label: 9
Output voltages: [0.40718, 0.0031277, 0.0071494, 0.12432, 0.071666, 0.18255, 0.0013436, 0.46244, 0.080132, 0.7915]
Predicted label: 9
Correct prediction
Energy consumption = 150.664767 pJ
sum error= 68
Actual label: 6
Output voltages: [0.045328, 0.028006, 0.26375, 0.0015017, 0.047591, 0.43986, 0.79879, 0.0027363, 0.46836, 0.001296]
Predicted label: 6
Correct prediction
Energy consumption = 148.663352 pJ
sum error= 68
Actual label: 1
Output voltages: [0.042886, 0.79838, 0.033506, 0.22529, 0.019494, 0.012832, 0.43485, 0.0056096, 0.11002, 0.049785]
Predicted label: 1
Correct prediction
Energy consumption = 163.647346 pJ
sum error= 68
Actual label: 1
Output voltages: [0.038453, 0.79869, 0.001066, 0.023202, 0.25663, 0.031235, 0.17145, 0.0091953, 0.2804, 0.12897]
Predicted label: 1
Correct prediction
Energy consumption = 157.528186 pJ
sum error= 68
Actual label: 2
Output voltages: [0.44513, 0.012895, 0.79876, 0.23501, 0.025434, 0.0011923, 0.023078, 0.04763, 0.29326, 0.012701]
Predicted label: 2
Correct prediction
Energy consumption = 150.190936 pJ
sum error= 68
Actual label: 9
Output voltages: [0.28746, 0.0066512, 0.019332, 0.01375, 0.17693, 0.0029969, 0.013943, 0.012524, 0.088027, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 152.660953 pJ
sum error= 68
Actual label: 0
Output voltages: [0.79871, 0.045594, 0.082195, 0.0084357, 0.015036, 0.0083955, 0.29702, 0.01517, 0.041304, 0.027868]
Predicted label: 0
Correct prediction
Energy consumption = 148.796520 pJ
sum error= 68
Actual label: 4
Output voltages: [0.011678, 0.011296, 0.46832, 0.0013842, 0.7986, 0.0048101, 0.46335, 0.046232, 0.045024, 0.045806]
Predicted label: 4
Correct prediction
Energy consumption = 150.827904 pJ
sum error= 68
Actual label: 3
Output voltages: [0.076331, 0.0022367, 0.2125, 0.79878, 0.057614, 0.13139, 0.022515, 0.035189, 0.74432, 0.040395]
Predicted label: 3
Correct prediction
Energy consumption = 140.588585 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 149 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 149 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 149 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.63462, 0.019895, 0.15719, 0.79863, 0.022922, 0.0047895, 0.047594, 0.02435, 0.48067, 0.012427]
Predicted label: 3
Correct prediction
Energy consumption = 161.175706 pJ
sum error= 68
Actual label: 6
Output voltages: [0.1359, 0.022435, 0.15846, 0.0020099, 0.4581, 0.15673, 0.79872, 0.0020098, 0.54003, 0.01325]
Predicted label: 6
Correct prediction
Energy consumption = 150.946834 pJ
sum error= 68
Actual label: 9
Output voltages: [0.25673, 0.0064688, 0.015185, 0.043143, 0.04161, 0.014397, 0.0010823, 0.30952, 0.12441, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 161.340419 pJ
sum error= 68
Actual label: 5
Output voltages: [0.021061, 0.0011483, 0.0018642, 0.060806, 0.042333, 0.78615, 0.016114, 0.0035891, 0.7759, 0.24714]
Predicted label: 5
Correct prediction
Energy consumption = 145.062406 pJ
sum error= 68
Actual label: 7
Output voltages: [0.79868, 0.02865, 0.037822, 0.0012689, 0.012931, 0.0063353, 0.035698, 0.44293, 0.61495, 0.33408]
Predicted label: 0
Wrong prediction!
Energy consumption = 157.103366 pJ
sum error= 69
Actual label: 3
Output voltages: [0.52609, 0.44112, 0.20191, 0.79851, 0.0035578, 0.061638, 0.1058, 0.037528, 0.14264, 0.028524]
Predicted label: 3
Correct prediction
Energy consumption = 161.910491 pJ
sum error= 69
Actual label: 7
Output voltages: [0.14657, 0.040051, 0.06077, 0.049847, 0.0016972, 0.0015416, 0.001079, 0.79875, 0.042234, 0.62714]
Predicted label: 7
Correct prediction
Energy consumption = 157.041918 pJ
sum error= 69
Actual label: 7
Output voltages: [0.57867, 0.026445, 0.15128, 0.03408, 0.011665, 0.0010707, 0.0011202, 0.79875, 0.51068, 0.050137]
Predicted label: 7
Correct prediction
Energy consumption = 141.045526 pJ
sum error= 69
Actual label: 7
Output voltages: [0.051312, 0.39407, 0.081328, 0.027237, 0.067266, 0.0014789, 0.0011828, 0.7987, 0.028546, 0.026175]
Predicted label: 7
Correct prediction
Energy consumption = 138.647920 pJ
sum error= 69
Actual label: 8
Output voltages: [0.3953, 0.012934, 0.33948, 0.054648, 0.027688, 0.5439, 0.01514, 0.026264, 0.79869, 0.0085846]
Predicted label: 8
Correct prediction
Energy consumption = 144.523773 pJ
sum error= 69
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 150 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 150 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 150 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.74467, 0.19959, 0.28688, 0.79874, 0.0016979, 0.0011291, 0.0010753, 0.29833, 0.39919, 0.21721]
Predicted label: 3
Wrong prediction!
Energy consumption = 178.222226 pJ
sum error= 70
Actual label: 9
Output voltages: [0.059887, 0.019236, 0.20102, 0.084107, 0.062396, 0.011435, 0.04782, 0.018233, 0.05517, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 148.137293 pJ
sum error= 70
Actual label: 8
Output voltages: [0.039046, 0.019455, 0.035826, 0.41669, 0.0070688, 0.04346, 0.3081, 0.0029227, 0.79878, 0.053103]
Predicted label: 8
Correct prediction
Energy consumption = 153.755221 pJ
sum error= 70
Actual label: 3
Output voltages: [0.47545, 0.029502, 0.066228, 0.79869, 0.036431, 0.051519, 0.053488, 0.0038232, 0.5133, 0.30279]
Predicted label: 3
Correct prediction
Energy consumption = 147.568897 pJ
sum error= 70
Actual label: 0
Output voltages: [0.79868, 0.030589, 0.039125, 0.026641, 0.058643, 0.0093878, 0.28486, 0.028122, 0.08137, 0.25402]
Predicted label: 0
Correct prediction
Energy consumption = 155.251744 pJ
sum error= 70
Actual label: 7
Output voltages: [0.47422, 0.13758, 0.75643, 0.13444, 0.0013319, 0.0011227, 0.0089881, 0.77478, 0.33973, 0.066476]
Predicted label: 7
Correct prediction
Energy consumption = 159.542144 pJ
sum error= 70
Actual label: 2
Output voltages: [0.60458, 0.031985, 0.79876, 0.036683, 0.01602, 0.0012305, 0.11266, 0.038226, 0.37233, 0.023176]
Predicted label: 2
Correct prediction
Energy consumption = 138.354499 pJ
sum error= 70
Actual label: 7
Output voltages: [0.46742, 0.28506, 0.72557, 0.059478, 0.0068094, 0.001185, 0.0015454, 0.79879, 0.031682, 0.34424]
Predicted label: 7
Correct prediction
Energy consumption = 150.673848 pJ
sum error= 70
Actual label: 9
Output voltages: [0.0075308, 0.0063629, 0.037321, 0.014502, 0.10399, 0.17452, 0.03166, 0.015085, 0.77273, 0.67323]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.498614 pJ
sum error= 71
Actual label: 4
Output voltages: [0.0015645, 0.0015551, 0.26932, 0.0046002, 0.79847, 0.0078373, 0.027096, 0.2253, 0.71559, 0.025997]
Predicted label: 4
Correct prediction
Energy consumption = 147.604680 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 151 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 151 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 151 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.043858, 0.0011708, 0.013901, 0.40519, 0.0044742, 0.79848, 0.12379, 0.090631, 0.76329, 0.20274]
Predicted label: 5
Correct prediction
Energy consumption = 163.703995 pJ
sum error= 71
Actual label: 4
Output voltages: [0.017984, 0.020914, 0.052917, 0.0021493, 0.79879, 0.010576, 0.14636, 0.041378, 0.3197, 0.0059711]
Predicted label: 4
Correct prediction
Energy consumption = 149.222218 pJ
sum error= 71
Actual label: 9
Output voltages: [0.49716, 0.018177, 0.0078471, 0.066982, 0.32916, 0.010344, 0.034666, 0.032945, 0.047249, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 150.876065 pJ
sum error= 71
Actual label: 3
Output voltages: [0.28182, 0.0072504, 0.018623, 0.79874, 0.066872, 0.035942, 0.03265, 0.0039997, 0.62732, 0.033359]
Predicted label: 3
Correct prediction
Energy consumption = 145.980103 pJ
sum error= 71
Actual label: 2
Output voltages: [0.050047, 0.31209, 0.79879, 0.11943, 0.0022483, 0.0012321, 0.13883, 0.021128, 0.62692, 0.070116]
Predicted label: 2
Correct prediction
Energy consumption = 145.403922 pJ
sum error= 71
Actual label: 1
Output voltages: [0.042091, 0.79855, 0.11777, 0.028995, 0.040386, 0.0012532, 0.47277, 0.0012626, 0.18537, 0.054769]
Predicted label: 1
Correct prediction
Energy consumption = 157.722086 pJ
sum error= 71
Actual label: 4
Output voltages: [0.034104, 0.013027, 0.082922, 0.064323, 0.79872, 0.0096551, 0.070385, 0.04346, 0.01075, 0.48199]
Predicted label: 4
Correct prediction
Energy consumption = 156.115991 pJ
sum error= 71
Actual label: 0
Output voltages: [0.79878, 0.13754, 0.021555, 0.022028, 0.011737, 0.0082367, 0.4, 0.0058239, 0.043501, 0.25242]
Predicted label: 0
Correct prediction
Energy consumption = 159.584894 pJ
sum error= 71
Actual label: 2
Output voltages: [0.10386, 0.055348, 0.79871, 0.23574, 0.019197, 0.0013414, 0.024198, 0.11015, 0.4662, 0.031138]
Predicted label: 2
Correct prediction
Energy consumption = 149.022972 pJ
sum error= 71
Actual label: 3
Output voltages: [0.54409, 0.028532, 0.061343, 0.79863, 0.013705, 0.030263, 0.015612, 0.0078647, 0.46624, 0.026281]
Predicted label: 3
Correct prediction
Energy consumption = 139.341868 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 152 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 152 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 152 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.52287, 0.0014339, 0.68297, 0.0017503, 0.0014358, 0.004866, 0.0010787, 0.77901, 0.77509, 0.023047]
Predicted label: 7
Correct prediction
Energy consumption = 157.593229 pJ
sum error= 71
Actual label: 5
Output voltages: [0.04697, 0.0010948, 0.0062402, 0.54958, 0.022026, 0.79801, 0.029047, 0.045978, 0.77284, 0.14701]
Predicted label: 5
Correct prediction
Energy consumption = 147.163988 pJ
sum error= 71
Actual label: 7
Output voltages: [0.053942, 0.091496, 0.0010771, 0.040411, 0.32155, 0.0022514, 0.0010968, 0.48732, 0.37875, 0.57575]
Predicted label: 9
Wrong prediction!
Energy consumption = 172.357003 pJ
sum error= 72
Actual label: 8
Output voltages: [0.017085, 0.0031784, 0.011459, 0.10383, 0.01339, 0.73081, 0.23192, 0.0078867, 0.7987, 0.029419]
Predicted label: 8
Correct prediction
Energy consumption = 146.815951 pJ
sum error= 72
Actual label: 8
Output voltages: [0.030263, 0.043869, 0.048878, 0.60391, 0.0010662, 0.17248, 0.0063691, 0.048335, 0.79878, 0.043584]
Predicted label: 8
Correct prediction
Energy consumption = 147.404931 pJ
sum error= 72
Actual label: 5
Output voltages: [0.71804, 0.0053037, 0.0046072, 0.38004, 0.0043076, 0.79879, 0.28322, 0.056064, 0.36584, 0.010834]
Predicted label: 5
Correct prediction
Energy consumption = 153.096007 pJ
sum error= 72
Actual label: 0
Output voltages: [0.75337, 0.014453, 0.29173, 0.28899, 0.14336, 0.0013075, 0.30335, 0.0011132, 0.79628, 0.096394]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.130990 pJ
sum error= 73
Actual label: 1
Output voltages: [0.0020218, 0.74819, 0.3337, 0.046563, 0.0013042, 0.4748, 0.72345, 0.0013812, 0.031533, 0.0094894]
Predicted label: 1
Correct prediction
Energy consumption = 155.324172 pJ
sum error= 73
Actual label: 1
Output voltages: [0.10572, 0.79848, 0.11962, 0.11313, 0.0063715, 0.0024762, 0.71547, 0.0015142, 0.071754, 0.040826]
Predicted label: 1
Correct prediction
Energy consumption = 158.776406 pJ
sum error= 73
Actual label: 4
Output voltages: [0.0014278, 0.046982, 0.099393, 0.002129, 0.79871, 0.0029951, 0.37114, 0.15803, 0.13395, 0.255]
Predicted label: 4
Correct prediction
Energy consumption = 152.237885 pJ
sum error= 73
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 153 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 153 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 153 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.03428, 0.029182, 0.013276, 0.18964, 0.0010864, 0.20533, 0.0010689, 0.46249, 0.79858, 0.27611]
Predicted label: 8
Correct prediction
Energy consumption = 167.169904 pJ
sum error= 73
Actual label: 3
Output voltages: [0.1037, 0.0011608, 0.15724, 0.79877, 0.025713, 0.24281, 0.0093594, 0.0013736, 0.48963, 0.018436]
Predicted label: 3
Correct prediction
Energy consumption = 148.896485 pJ
sum error= 73
Actual label: 9
Output voltages: [0.24265, 0.016983, 0.026263, 0.048651, 0.20403, 0.015236, 0.0036844, 0.011013, 0.60228, 0.79864]
Predicted label: 9
Correct prediction
Energy consumption = 149.359739 pJ
sum error= 73
Actual label: 0
Output voltages: [0.7984, 0.039141, 0.010415, 0.022091, 0.029355, 0.020307, 0.74392, 0.059466, 0.10961, 0.022157]
Predicted label: 0
Correct prediction
Energy consumption = 148.337278 pJ
sum error= 73
Actual label: 0
Output voltages: [0.79723, 0.02433, 0.17935, 0.010338, 0.058757, 0.001305, 0.7345, 0.039767, 0.16132, 0.041201]
Predicted label: 0
Correct prediction
Energy consumption = 149.497695 pJ
sum error= 73
Actual label: 0
Output voltages: [0.79878, 0.042395, 0.11677, 0.057158, 0.027503, 0.0059659, 0.44923, 0.023387, 0.15423, 0.059389]
Predicted label: 0
Correct prediction
Energy consumption = 152.729453 pJ
sum error= 73
Actual label: 6
Output voltages: [0.032949, 0.019753, 0.50653, 0.0016769, 0.012895, 0.36338, 0.79859, 0.0015571, 0.76212, 0.018503]
Predicted label: 6
Correct prediction
Energy consumption = 146.018811 pJ
sum error= 73
Actual label: 6
Output voltages: [0.22585, 0.027905, 0.15188, 0.0024969, 0.36571, 0.13284, 0.79879, 0.0027148, 0.74221, 0.0027114]
Predicted label: 6
Correct prediction
Energy consumption = 139.404898 pJ
sum error= 73
Actual label: 2
Output voltages: [0.14359, 0.21439, 0.76385, 0.68139, 0.040109, 0.0013278, 0.03944, 0.028141, 0.39147, 0.024289]
Predicted label: 2
Correct prediction
Energy consumption = 153.993508 pJ
sum error= 73
Actual label: 3
Output voltages: [0.73504, 0.014087, 0.047145, 0.79867, 0.0055266, 0.042438, 0.0093465, 0.037609, 0.44199, 0.047612]
Predicted label: 3
Correct prediction
Energy consumption = 145.815924 pJ
sum error= 73
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 154 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 154 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 154 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25051, 0.0498, 0.03423, 0.35396, 0.0086216, 0.028343, 0.0010878, 0.79861, 0.029094, 0.2261]
Predicted label: 7
Correct prediction
Energy consumption = 168.949077 pJ
sum error= 73
Actual label: 8
Output voltages: [0.27477, 0.030246, 0.1369, 0.46851, 0.029007, 0.0031729, 0.14791, 0.0089149, 0.79879, 0.049081]
Predicted label: 8
Correct prediction
Energy consumption = 157.528684 pJ
sum error= 73
Actual label: 4
Output voltages: [0.015541, 0.0084051, 0.574, 0.0068228, 0.79863, 0.0015249, 0.21114, 0.034326, 0.015771, 0.18243]
Predicted label: 4
Correct prediction
Energy consumption = 164.246713 pJ
sum error= 73
Actual label: 7
Output voltages: [0.30197, 0.0070646, 0.033829, 0.78602, 0.016438, 0.0012059, 0.0010745, 0.72844, 0.41452, 0.42019]
Predicted label: 3
Wrong prediction!
Energy consumption = 142.058527 pJ
sum error= 74
Actual label: 7
Output voltages: [0.14193, 0.17672, 0.041967, 0.53345, 0.0020397, 0.0084729, 0.0011011, 0.79876, 0.52489, 0.65793]
Predicted label: 7
Correct prediction
Energy consumption = 150.480209 pJ
sum error= 74
Actual label: 9
Output voltages: [0.21421, 0.0059805, 0.0084876, 0.27243, 0.15807, 0.11914, 0.0053496, 0.026394, 0.093586, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 146.065495 pJ
sum error= 74
Actual label: 2
Output voltages: [0.057409, 0.0064159, 0.77269, 0.65579, 0.042349, 0.0011686, 0.083491, 0.01146, 0.76813, 0.24408]
Predicted label: 2
Correct prediction
Energy consumption = 150.101766 pJ
sum error= 74
Actual label: 4
Output voltages: [0.066163, 0.50788, 0.022191, 0.24658, 0.78805, 0.0029535, 0.023945, 0.0025515, 0.01755, 0.77911]
Predicted label: 4
Correct prediction
Energy consumption = 162.411222 pJ
sum error= 74
Actual label: 1
Output voltages: [0.027436, 0.79855, 0.056059, 0.034115, 0.0071764, 0.0039941, 0.32307, 0.023231, 0.50921, 0.016892]
Predicted label: 1
Correct prediction
Energy consumption = 170.963456 pJ
sum error= 74
Actual label: 4
Output voltages: [0.14806, 0.27614, 0.48418, 0.0063741, 0.47239, 0.0097159, 0.78785, 0.0012482, 0.38515, 0.0010663]
Predicted label: 6
Wrong prediction!
Energy consumption = 143.399559 pJ
sum error= 75
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 155 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 155 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 155 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.027232, 0.0011344, 0.0021451, 0.037418, 0.028212, 0.79875, 0.098639, 0.040803, 0.7672, 0.044427]
Predicted label: 5
Correct prediction
Energy consumption = 172.974626 pJ
sum error= 75
Actual label: 2
Output voltages: [0.065718, 0.73066, 0.79707, 0.74306, 0.0027738, 0.0011142, 0.039239, 0.0047147, 0.18966, 0.031327]
Predicted label: 2
Correct prediction
Energy consumption = 162.598072 pJ
sum error= 75
Actual label: 4
Output voltages: [0.0037159, 0.0074373, 0.040923, 0.015845, 0.79877, 0.0010667, 0.20592, 0.18074, 0.019431, 0.043274]
Predicted label: 4
Correct prediction
Energy consumption = 159.310354 pJ
sum error= 75
Actual label: 9
Output voltages: [0.0045615, 0.0035816, 0.15623, 0.7549, 0.5685, 0.044013, 0.015159, 0.001492, 0.56111, 0.61845]
Predicted label: 3
Wrong prediction!
Energy consumption = 153.192835 pJ
sum error= 76
Actual label: 9
Output voltages: [0.019473, 0.022385, 0.006894, 0.023516, 0.013013, 0.0014014, 0.0010921, 0.054631, 0.76371, 0.79219]
Predicted label: 9
Correct prediction
Energy consumption = 152.945347 pJ
sum error= 76
Actual label: 1
Output voltages: [0.025259, 0.79851, 0.14568, 0.029627, 0.04377, 0.0021338, 0.48195, 0.0031597, 0.30188, 0.024404]
Predicted label: 1
Correct prediction
Energy consumption = 165.550236 pJ
sum error= 76
Actual label: 8
Output voltages: [0.069101, 0.012008, 0.43749, 0.0076913, 0.037741, 0.0016767, 0.033282, 0.015196, 0.79879, 0.18585]
Predicted label: 8
Correct prediction
Energy consumption = 148.628902 pJ
sum error= 76
Actual label: 4
Output voltages: [0.0076407, 0.021589, 0.11954, 0.014222, 0.79871, 0.007975, 0.083805, 0.10611, 0.064891, 0.007506]
Predicted label: 4
Correct prediction
Energy consumption = 144.186081 pJ
sum error= 76
Actual label: 0
Output voltages: [0.79879, 0.14237, 0.036564, 0.033349, 0.011905, 0.0092295, 0.67573, 0.11298, 0.26825, 0.082371]
Predicted label: 0
Correct prediction
Energy consumption = 161.133770 pJ
sum error= 76
Actual label: 9
Output voltages: [0.17735, 0.0052326, 0.016339, 0.79758, 0.040254, 0.016081, 0.0041174, 0.013823, 0.033191, 0.75124]
Predicted label: 3
Wrong prediction!
Energy consumption = 156.386178 pJ
sum error= 77
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 156 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 156 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 156 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.059738, 0.01104, 0.073572, 0.23661, 0.0034225, 0.012143, 0.055064, 0.0017973, 0.79872, 0.05288]
Predicted label: 8
Correct prediction
Energy consumption = 170.377825 pJ
sum error= 77
Actual label: 4
Output voltages: [0.035072, 0.029237, 0.073171, 0.0092275, 0.79865, 0.0046657, 0.057534, 0.029631, 0.047747, 0.040134]
Predicted label: 4
Correct prediction
Energy consumption = 154.117262 pJ
sum error= 77
Actual label: 8
Output voltages: [0.73216, 0.0022454, 0.48277, 0.20724, 0.05312, 0.019548, 0.34577, 0.0013212, 0.79458, 0.063954]
Predicted label: 8
Correct prediction
Energy consumption = 162.589065 pJ
sum error= 77
Actual label: 7
Output voltages: [0.20633, 0.03674, 0.17181, 0.020075, 0.041649, 0.0031093, 0.0010965, 0.79864, 0.34743, 0.23842]
Predicted label: 7
Correct prediction
Energy consumption = 150.315836 pJ
sum error= 77
Actual label: 7
Output voltages: [0.18325, 0.060394, 0.014817, 0.034618, 0.0052563, 0.0032183, 0.0011493, 0.79867, 0.099043, 0.43355]
Predicted label: 7
Correct prediction
Energy consumption = 137.876709 pJ
sum error= 77
Actual label: 0
Output voltages: [0.79874, 0.05146, 0.037384, 0.0064535, 0.056608, 0.0088077, 0.7713, 0.0041041, 0.060572, 0.11966]
Predicted label: 0
Correct prediction
Energy consumption = 156.342827 pJ
sum error= 77
Actual label: 7
Output voltages: [0.06498, 0.081026, 0.025531, 0.033245, 0.019365, 0.0089191, 0.0011293, 0.79436, 0.0099572, 0.77729]
Predicted label: 7
Correct prediction
Energy consumption = 157.415134 pJ
sum error= 77
Actual label: 8
Output voltages: [0.041109, 0.011045, 0.053856, 0.19733, 0.0089385, 0.13269, 0.026127, 0.016266, 0.7987, 0.033176]
Predicted label: 8
Correct prediction
Energy consumption = 152.134728 pJ
sum error= 77
Actual label: 8
Output voltages: [0.0095706, 0.0066644, 0.047354, 0.34732, 0.0030352, 0.15581, 0.037691, 0.011218, 0.79879, 0.077144]
Predicted label: 8
Correct prediction
Energy consumption = 147.439202 pJ
sum error= 77
Actual label: 6
Output voltages: [0.29898, 0.0014542, 0.48643, 0.001069, 0.74879, 0.32609, 0.79865, 0.0012371, 0.12391, 0.020758]
Predicted label: 6
Correct prediction
Energy consumption = 142.445539 pJ
sum error= 77
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 157 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 157 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 157 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7866, 0.099341, 0.53586, 0.029477, 0.0286, 0.0010675, 0.59884, 0.025407, 0.22795, 0.014201]
Predicted label: 0
Correct prediction
Energy consumption = 170.314030 pJ
sum error= 77
Actual label: 4
Output voltages: [0.003464, 0.028096, 0.38501, 0.016209, 0.79878, 0.023834, 0.081252, 0.021611, 0.032631, 0.54317]
Predicted label: 4
Correct prediction
Energy consumption = 157.181937 pJ
sum error= 77
Actual label: 8
Output voltages: [0.0072102, 0.10142, 0.16999, 0.17665, 0.012994, 0.014276, 0.009896, 0.025054, 0.79875, 0.16403]
Predicted label: 8
Correct prediction
Energy consumption = 156.147113 pJ
sum error= 77
Actual label: 8
Output voltages: [0.099373, 0.021465, 0.56484, 0.074595, 0.026008, 0.0029136, 0.17464, 0.0011449, 0.79879, 0.15589]
Predicted label: 8
Correct prediction
Energy consumption = 154.258274 pJ
sum error= 77
Actual label: 2
Output voltages: [0.52612, 0.047146, 0.79875, 0.021452, 0.042241, 0.0012178, 0.40316, 0.042138, 0.29163, 0.0184]
Predicted label: 2
Correct prediction
Energy consumption = 146.359052 pJ
sum error= 77
Actual label: 4
Output voltages: [0.014935, 0.017679, 0.2211, 0.013052, 0.79862, 0.0045365, 0.023523, 0.18883, 0.054209, 0.044082]
Predicted label: 4
Correct prediction
Energy consumption = 151.679130 pJ
sum error= 77
Actual label: 7
Output voltages: [0.6939, 0.36402, 0.12203, 0.49812, 0.003261, 0.0010876, 0.009495, 0.79841, 0.033336, 0.13307]
Predicted label: 7
Correct prediction
Energy consumption = 158.045341 pJ
sum error= 77
Actual label: 6
Output voltages: [0.089374, 0.031828, 0.23552, 0.0035041, 0.1904, 0.35416, 0.79878, 0.0045527, 0.52596, 0.0019947]
Predicted label: 6
Correct prediction
Energy consumption = 148.468558 pJ
sum error= 77
Actual label: 6
Output voltages: [0.052283, 0.085491, 0.094507, 0.0074868, 0.17327, 0.50741, 0.79867, 0.0090381, 0.48735, 0.006374]
Predicted label: 6
Correct prediction
Energy consumption = 137.369922 pJ
sum error= 77
Actual label: 6
Output voltages: [0.36161, 0.31139, 0.020446, 0.024817, 0.09696, 0.40692, 0.79879, 0.012963, 0.53175, 0.0036918]
Predicted label: 6
Correct prediction
Energy consumption = 144.356461 pJ
sum error= 77
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 158 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 158 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 158 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.025001, 0.0076853, 0.05255, 0.047202, 0.79872, 0.0010847, 0.012417, 0.17784, 0.16833, 0.014713]
Predicted label: 4
Correct prediction
Energy consumption = 172.456050 pJ
sum error= 77
Actual label: 7
Output voltages: [0.14777, 0.0014043, 0.39489, 0.7613, 0.0064641, 0.0011296, 0.0011267, 0.73285, 0.53319, 0.59274]
Predicted label: 3
Wrong prediction!
Energy consumption = 143.802947 pJ
sum error= 78
Actual label: 1
Output voltages: [0.0094167, 0.79856, 0.0035688, 0.023223, 0.0080935, 0.0014878, 0.76095, 0.013921, 0.54221, 0.015827]
Predicted label: 1
Correct prediction
Energy consumption = 160.705739 pJ
sum error= 78
Actual label: 8
Output voltages: [0.027017, 0.028835, 0.05057, 0.16466, 0.012858, 0.015386, 0.034339, 0.030211, 0.79876, 0.45769]
Predicted label: 8
Correct prediction
Energy consumption = 151.763334 pJ
sum error= 78
Actual label: 8
Output voltages: [0.39551, 0.056381, 0.19443, 0.15677, 0.079718, 0.0020717, 0.030647, 0.0010731, 0.79879, 0.11226]
Predicted label: 8
Correct prediction
Energy consumption = 153.786397 pJ
sum error= 78
Actual label: 2
Output voltages: [0.67681, 0.027432, 0.79875, 0.087057, 0.026825, 0.001164, 0.034965, 0.16536, 0.32003, 0.017615]
Predicted label: 2
Correct prediction
Energy consumption = 140.586428 pJ
sum error= 78
Actual label: 3
Output voltages: [0.50761, 0.059299, 0.058712, 0.79854, 0.095952, 0.0071741, 0.019346, 0.014951, 0.60129, 0.073733]
Predicted label: 3
Correct prediction
Energy consumption = 144.111084 pJ
sum error= 78
Actual label: 6
Output voltages: [0.15961, 0.0066737, 0.078336, 0.011903, 0.10973, 0.44845, 0.79849, 0.0010965, 0.58077, 0.27212]
Predicted label: 6
Correct prediction
Energy consumption = 146.672555 pJ
sum error= 78
Actual label: 3
Output voltages: [0.40582, 0.024626, 0.10253, 0.7986, 0.075103, 0.010883, 0.025055, 0.022798, 0.71907, 0.045754]
Predicted label: 3
Correct prediction
Energy consumption = 147.007519 pJ
sum error= 78
Actual label: 0
Output voltages: [0.79779, 0.086158, 0.47691, 0.003706, 0.0011164, 0.010966, 0.43686, 0.0016441, 0.30378, 0.021798]
Predicted label: 0
Correct prediction
Energy consumption = 151.842680 pJ
sum error= 78
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 159 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 159 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 159 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.041968, 0.10087, 0.042838, 0.048115, 0.0026858, 0.17907, 0.023843, 0.76982, 0.02035]
Predicted label: 0
Correct prediction
Energy consumption = 173.464998 pJ
sum error= 78
Actual label: 3
Output voltages: [0.15488, 0.021294, 0.10199, 0.79877, 0.0014402, 0.0011343, 0.021262, 0.01041, 0.73418, 0.0076421]
Predicted label: 3
Correct prediction
Energy consumption = 151.181252 pJ
sum error= 78
Actual label: 7
Output voltages: [0.21319, 0.32485, 0.14954, 0.32968, 0.003293, 0.0010669, 0.0010945, 0.79866, 0.47324, 0.023679]
Predicted label: 7
Correct prediction
Energy consumption = 153.959720 pJ
sum error= 78
Actual label: 6
Output voltages: [0.3698, 0.057072, 0.063407, 0.0014017, 0.28899, 0.21417, 0.79879, 0.011443, 0.65489, 0.0013814]
Predicted label: 6
Correct prediction
Energy consumption = 152.562567 pJ
sum error= 78
Actual label: 9
Output voltages: [0.30994, 0.0098904, 0.066061, 0.22557, 0.7332, 0.012565, 0.0040958, 0.027883, 0.15933, 0.77322]
Predicted label: 9
Correct prediction
Energy consumption = 158.827384 pJ
sum error= 78
Actual label: 7
Output voltages: [0.31852, 0.18755, 0.77823, 0.46029, 0.0025975, 0.0011402, 0.006187, 0.79874, 0.14087, 0.075372]
Predicted label: 7
Correct prediction
Energy consumption = 156.116221 pJ
sum error= 78
Actual label: 9
Output voltages: [0.27306, 0.010163, 0.025698, 0.032758, 0.14741, 0.0043908, 0.033202, 0.033343, 0.29593, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 156.586234 pJ
sum error= 78
Actual label: 9
Output voltages: [0.11388, 0.033816, 0.02196, 0.032483, 0.015631, 0.0023094, 0.0010732, 0.029082, 0.77175, 0.79683]
Predicted label: 9
Correct prediction
Energy consumption = 148.252698 pJ
sum error= 78
Actual label: 5
Output voltages: [0.16599, 0.0015024, 0.0083637, 0.40519, 0.029741, 0.7982, 0.03095, 0.011529, 0.79351, 0.13161]
Predicted label: 5
Correct prediction
Energy consumption = 143.853209 pJ
sum error= 78
Actual label: 4
Output voltages: [0.0077417, 0.023782, 0.22005, 0.0079119, 0.79876, 0.0024336, 0.066925, 0.021629, 0.14829, 0.25676]
Predicted label: 4
Correct prediction
Energy consumption = 153.544034 pJ
sum error= 78
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 160 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 160 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 160 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.21571, 0.0015739, 0.10879, 0.79876, 0.047722, 0.31265, 0.014509, 0.0064347, 0.4808, 0.031879]
Predicted label: 3
Correct prediction
Energy consumption = 162.227699 pJ
sum error= 78
Actual label: 3
Output voltages: [0.17365, 0.0010925, 0.51897, 0.79381, 0.0011906, 0.011623, 0.0023924, 0.087212, 0.79701, 0.0025374]
Predicted label: 8
Wrong prediction!
Energy consumption = 135.395574 pJ
sum error= 79
Actual label: 6
Output voltages: [0.01882, 0.036682, 0.042034, 0.0036048, 0.16159, 0.43106, 0.79876, 0.026022, 0.64728, 0.0018154]
Predicted label: 6
Correct prediction
Energy consumption = 153.459298 pJ
sum error= 79
Actual label: 1
Output voltages: [0.024888, 0.79847, 0.01804, 0.03769, 0.0028063, 0.0012219, 0.6758, 0.0022823, 0.24888, 0.082438]
Predicted label: 1
Correct prediction
Energy consumption = 157.961656 pJ
sum error= 79
Actual label: 2
Output voltages: [0.50359, 0.049278, 0.79853, 0.088568, 0.015085, 0.0011971, 0.30117, 0.020621, 0.72754, 0.021058]
Predicted label: 2
Correct prediction
Energy consumption = 151.381268 pJ
sum error= 79
Actual label: 3
Output voltages: [0.10059, 0.018825, 0.15863, 0.79873, 0.040027, 0.0017322, 0.017759, 0.015503, 0.64875, 0.030635]
Predicted label: 3
Correct prediction
Energy consumption = 145.250730 pJ
sum error= 79
Actual label: 7
Output voltages: [0.025091, 0.023257, 0.054609, 0.035682, 0.022059, 0.0050658, 0.0010677, 0.79864, 0.24632, 0.27333]
Predicted label: 7
Correct prediction
Energy consumption = 153.449975 pJ
sum error= 79
Actual label: 3
Output voltages: [0.031032, 0.032545, 0.12178, 0.79867, 0.021444, 0.021379, 0.013874, 0.0020362, 0.39407, 0.1529]
Predicted label: 3
Correct prediction
Energy consumption = 150.908607 pJ
sum error= 79
Actual label: 3
Output voltages: [0.40316, 0.0081018, 0.025691, 0.79863, 0.018768, 0.034227, 0.037589, 0.01584, 0.5948, 0.058035]
Predicted label: 3
Correct prediction
Energy consumption = 138.741376 pJ
sum error= 79
Actual label: 2
Output voltages: [0.28416, 0.0012634, 0.78352, 0.14946, 0.047524, 0.001093, 0.39124, 0.013535, 0.65853, 0.005058]
Predicted label: 2
Correct prediction
Energy consumption = 139.162695 pJ
sum error= 79
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 161 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 161 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 161 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79856, 0.27873, 0.011384, 0.010275, 0.020933, 0.013641, 0.75085, 0.035784, 0.23981, 0.077492]
Predicted label: 0
Correct prediction
Energy consumption = 175.028626 pJ
sum error= 79
Actual label: 3
Output voltages: [0.75421, 0.029963, 0.012516, 0.79876, 0.0037829, 0.17388, 0.45379, 0.0015429, 0.5671, 0.0053775]
Predicted label: 3
Correct prediction
Energy consumption = 150.743237 pJ
sum error= 79
Actual label: 3
Output voltages: [0.25118, 0.012256, 0.026492, 0.79879, 0.014299, 0.63442, 0.0064055, 0.042206, 0.55557, 0.010897]
Predicted label: 3
Correct prediction
Energy consumption = 139.698448 pJ
sum error= 79
Actual label: 8
Output voltages: [0.012759, 0.12373, 0.17406, 0.059969, 0.00429, 0.01731, 0.0071598, 0.021412, 0.79875, 0.59591]
Predicted label: 8
Correct prediction
Energy consumption = 147.858514 pJ
sum error= 79
Actual label: 4
Output voltages: [0.21881, 0.017434, 0.30891, 0.045757, 0.79878, 0.0011237, 0.56881, 0.0035189, 0.0033737, 0.5026]
Predicted label: 4
Correct prediction
Energy consumption = 154.089647 pJ
sum error= 79
Actual label: 3
Output voltages: [0.19204, 0.064183, 0.4161, 0.79878, 0.064419, 0.0013324, 0.0029235, 0.0088503, 0.26875, 0.0086625]
Predicted label: 3
Correct prediction
Energy consumption = 150.203557 pJ
sum error= 79
Actual label: 6
Output voltages: [0.35973, 0.033048, 0.40611, 0.0043068, 0.4643, 0.091017, 0.79879, 0.0022913, 0.51796, 0.035656]
Predicted label: 6
Correct prediction
Energy consumption = 139.928982 pJ
sum error= 79
Actual label: 3
Output voltages: [0.25303, 0.0068032, 0.687, 0.79826, 0.022124, 0.00334, 0.0037777, 0.0017894, 0.64072, 0.040559]
Predicted label: 3
Correct prediction
Energy consumption = 144.191341 pJ
sum error= 79
Actual label: 5
Output voltages: [0.023006, 0.0058322, 0.0062318, 0.52238, 0.058141, 0.79875, 0.043861, 0.0072198, 0.73941, 0.0055189]
Predicted label: 5
Correct prediction
Energy consumption = 144.747335 pJ
sum error= 79
Actual label: 0
Output voltages: [0.79879, 0.13877, 0.033644, 0.053826, 0.040426, 0.0093132, 0.67004, 0.016158, 0.09969, 0.12665]
Predicted label: 0
Correct prediction
Energy consumption = 157.721362 pJ
sum error= 79
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 162 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 162 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 162 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.51167, 0.016173, 0.7775, 0.58706, 0.016408, 0.0011968, 0.052734, 0.015665, 0.78283, 0.018208]
Predicted label: 8
Wrong prediction!
Energy consumption = 166.398217 pJ
sum error= 80
Actual label: 0
Output voltages: [0.75893, 0.029804, 0.035119, 0.0046793, 0.054536, 0.071205, 0.79676, 0.0020059, 0.15126, 0.016657]
Predicted label: 6
Wrong prediction!
Energy consumption = 154.185287 pJ
sum error= 81
Actual label: 9
Output voltages: [0.57595, 0.01408, 0.028291, 0.040191, 0.33189, 0.01367, 0.0087542, 0.015883, 0.18474, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.073460 pJ
sum error= 81
Actual label: 0
Output voltages: [0.79878, 0.26609, 0.10936, 0.014076, 0.0066709, 0.018617, 0.26054, 0.013648, 0.038631, 0.15096]
Predicted label: 0
Correct prediction
Energy consumption = 147.826219 pJ
sum error= 81
Actual label: 7
Output voltages: [0.068509, 0.52431, 0.026322, 0.00422, 0.0021205, 0.0010836, 0.0010771, 0.79847, 0.39756, 0.65465]
Predicted label: 7
Correct prediction
Energy consumption = 151.173445 pJ
sum error= 81
Actual label: 4
Output voltages: [0.0051589, 0.010944, 0.29542, 0.025825, 0.79857, 0.011193, 0.28256, 0.092578, 0.031635, 0.053166]
Predicted label: 4
Correct prediction
Energy consumption = 150.450849 pJ
sum error= 81
Actual label: 6
Output voltages: [0.045848, 0.0027407, 0.056631, 0.022135, 0.35573, 0.27297, 0.79791, 0.001076, 0.77073, 0.037854]
Predicted label: 6
Correct prediction
Energy consumption = 148.172459 pJ
sum error= 81
Actual label: 9
Output voltages: [0.74233, 0.0040246, 0.50999, 0.0080759, 0.1869, 0.0058097, 0.040696, 0.011656, 0.22806, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 147.673356 pJ
sum error= 81
Actual label: 3
Output voltages: [0.24579, 0.0035133, 0.04395, 0.79867, 0.013771, 0.12574, 0.027735, 0.012537, 0.48554, 0.058191]
Predicted label: 3
Correct prediction
Energy consumption = 152.844152 pJ
sum error= 81
Actual label: 5
Output voltages: [0.022258, 0.0012519, 0.0095658, 0.37285, 0.039626, 0.79845, 0.046073, 0.0031949, 0.7715, 0.050632]
Predicted label: 5
Correct prediction
Energy consumption = 140.665863 pJ
sum error= 81
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 163 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 163 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 163 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.011863, 0.79858, 0.1419, 0.038424, 0.0019422, 0.001075, 0.59748, 0.0033254, 0.14186, 0.0035542]
Predicted label: 1
Correct prediction
Energy consumption = 181.787205 pJ
sum error= 81
Actual label: 9
Output voltages: [0.27489, 0.01993, 0.025134, 0.029402, 0.056461, 0.026443, 0.0037488, 0.049618, 0.5653, 0.79705]
Predicted label: 9
Correct prediction
Energy consumption = 157.655523 pJ
sum error= 81
Actual label: 6
Output voltages: [0.15185, 0.03564, 0.3201, 0.0018327, 0.30066, 0.13749, 0.79878, 0.0023157, 0.25061, 0.0043461]
Predicted label: 6
Correct prediction
Energy consumption = 149.935623 pJ
sum error= 81
Actual label: 1
Output voltages: [0.011479, 0.79863, 0.052936, 0.0090561, 0.017358, 0.014979, 0.37437, 0.0034333, 0.73767, 0.019989]
Predicted label: 1
Correct prediction
Energy consumption = 160.773571 pJ
sum error= 81
Actual label: 4
Output voltages: [0.0010818, 0.27757, 0.028302, 0.0016646, 0.79219, 0.0024629, 0.0063167, 0.066432, 0.58429, 0.057003]
Predicted label: 4
Correct prediction
Energy consumption = 151.524575 pJ
sum error= 81
Actual label: 5
Output voltages: [0.065492, 0.0032959, 0.0010824, 0.59392, 0.031689, 0.79877, 0.33995, 0.0012855, 0.51002, 0.0041482]
Predicted label: 5
Correct prediction
Energy consumption = 153.159369 pJ
sum error= 81
Actual label: 4
Output voltages: [0.0062295, 0.019961, 0.36539, 0.019072, 0.79874, 0.004034, 0.040417, 0.30083, 0.046515, 0.0040438]
Predicted label: 4
Correct prediction
Energy consumption = 138.504557 pJ
sum error= 81
Actual label: 5
Output voltages: [0.03427, 0.0017039, 0.0010763, 0.74346, 0.04981, 0.78684, 0.43866, 0.001374, 0.39681, 0.071919]
Predicted label: 5
Correct prediction
Energy consumption = 151.361188 pJ
sum error= 81
Actual label: 0
Output voltages: [0.79629, 0.025706, 0.19559, 0.011493, 0.0059684, 0.0011564, 0.33841, 0.023856, 0.22601, 0.05153]
Predicted label: 0
Correct prediction
Energy consumption = 165.425415 pJ
sum error= 81
Actual label: 5
Output voltages: [0.02833, 0.0030888, 0.0052193, 0.56418, 0.02729, 0.79877, 0.14188, 0.033377, 0.69695, 0.079027]
Predicted label: 5
Correct prediction
Energy consumption = 147.522101 pJ
sum error= 81
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 164 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 164 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 164 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.4078, 0.0010686, 0.044264, 0.012429, 0.38754, 0.038029, 0.0013909, 0.46256, 0.31204, 0.79802]
Predicted label: 9
Correct prediction
Energy consumption = 167.924967 pJ
sum error= 81
Actual label: 5
Output voltages: [0.036237, 0.001066, 0.011359, 0.012526, 0.030917, 0.77242, 0.56669, 0.033788, 0.71491, 0.029848]
Predicted label: 5
Correct prediction
Energy consumption = 144.091797 pJ
sum error= 81
Actual label: 2
Output voltages: [0.11321, 0.093093, 0.79869, 0.055013, 0.023944, 0.0011365, 0.23481, 0.055694, 0.48475, 0.023991]
Predicted label: 2
Correct prediction
Energy consumption = 151.919855 pJ
sum error= 81
Actual label: 1
Output voltages: [0.050144, 0.79861, 0.37739, 0.042704, 0.021746, 0.0010716, 0.43645, 0.0011017, 0.16268, 0.015559]
Predicted label: 1
Correct prediction
Energy consumption = 158.906443 pJ
sum error= 81
Actual label: 2
Output voltages: [0.42713, 0.050446, 0.79878, 0.16658, 0.021152, 0.0012543, 0.48205, 0.028873, 0.58104, 0.03948]
Predicted label: 2
Correct prediction
Energy consumption = 145.929866 pJ
sum error= 81
Actual label: 9
Output voltages: [0.60601, 0.0050465, 0.043527, 0.034581, 0.24613, 0.021272, 0.016827, 0.28701, 0.032242, 0.79815]
Predicted label: 9
Correct prediction
Energy consumption = 156.310298 pJ
sum error= 81
Actual label: 1
Output voltages: [0.045141, 0.79875, 0.056402, 0.0030247, 0.77066, 0.0045537, 0.46131, 0.0010881, 0.044906, 0.28434]
Predicted label: 1
Correct prediction
Energy consumption = 156.577409 pJ
sum error= 81
Actual label: 9
Output voltages: [0.41454, 0.0064416, 0.016315, 0.021412, 0.42691, 0.019093, 0.0039682, 0.0014869, 0.39801, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 151.402370 pJ
sum error= 81
Actual label: 9
Output voltages: [0.23604, 0.0031826, 0.024229, 0.034065, 0.040627, 0.0045486, 0.0011166, 0.1123, 0.61002, 0.79841]
Predicted label: 9
Correct prediction
Energy consumption = 142.515693 pJ
sum error= 81
Actual label: 4
Output voltages: [0.0044237, 0.0046244, 0.27856, 0.012036, 0.79872, 0.0089472, 0.11407, 0.13791, 0.24568, 0.011499]
Predicted label: 4
Correct prediction
Energy consumption = 152.807041 pJ
sum error= 81
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 165 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 165 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 165 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79836, 0.14808, 0.20442, 0.010803, 0.0018145, 0.0033934, 0.67392, 0.012261, 0.33882, 0.066459]
Predicted label: 0
Correct prediction
Energy consumption = 173.366330 pJ
sum error= 81
Actual label: 8
Output voltages: [0.02351, 0.028676, 0.14738, 0.02264, 0.037137, 0.01796, 0.038457, 0.0053675, 0.79874, 0.25556]
Predicted label: 8
Correct prediction
Energy consumption = 150.737988 pJ
sum error= 81
Actual label: 4
Output voltages: [0.0037068, 0.0026366, 0.20226, 0.022433, 0.7986, 0.012174, 0.1171, 0.019104, 0.030829, 0.14506]
Predicted label: 4
Correct prediction
Energy consumption = 154.177997 pJ
sum error= 81
Actual label: 5
Output voltages: [0.022614, 0.0013807, 0.0011141, 0.27293, 0.060176, 0.79821, 0.13165, 0.02131, 0.72465, 0.35084]
Predicted label: 5
Correct prediction
Energy consumption = 145.305405 pJ
sum error= 81
Actual label: 2
Output voltages: [0.10731, 0.041509, 0.79873, 0.43014, 0.02134, 0.0011517, 0.017093, 0.37657, 0.30476, 0.037684]
Predicted label: 2
Correct prediction
Energy consumption = 155.450599 pJ
sum error= 81
Actual label: 9
Output voltages: [0.44211, 0.0081562, 0.020275, 0.014511, 0.33031, 0.016667, 0.0042429, 0.0084489, 0.50881, 0.79776]
Predicted label: 9
Correct prediction
Energy consumption = 152.048907 pJ
sum error= 81
Actual label: 2
Output voltages: [0.12426, 0.039117, 0.79873, 0.16442, 0.021556, 0.0012164, 0.39334, 0.015333, 0.59648, 0.035647]
Predicted label: 2
Correct prediction
Energy consumption = 150.259217 pJ
sum error= 81
Actual label: 1
Output voltages: [0.0020125, 0.79863, 0.23601, 0.12195, 0.18632, 0.0011247, 0.66556, 0.0028243, 0.036064, 0.055662]
Predicted label: 1
Correct prediction
Energy consumption = 160.697402 pJ
sum error= 81
Actual label: 2
Output voltages: [0.34085, 0.57568, 0.79871, 0.059333, 0.015706, 0.0012435, 0.14439, 0.0076386, 0.038009, 0.035981]
Predicted label: 2
Correct prediction
Energy consumption = 150.820186 pJ
sum error= 81
Actual label: 1
Output voltages: [0.015213, 0.79848, 0.0052704, 0.065547, 0.29088, 0.018228, 0.3976, 0.0055667, 0.14091, 0.25082]
Predicted label: 1
Correct prediction
Energy consumption = 158.548652 pJ
sum error= 81
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 166 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 166 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 166 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.03606, 0.17093, 0.48998, 0.23049, 0.0016751, 0.0011002, 0.0010719, 0.79856, 0.24625, 0.38156]
Predicted label: 7
Correct prediction
Energy consumption = 174.620322 pJ
sum error= 81
Actual label: 3
Output voltages: [0.28904, 0.020347, 0.087332, 0.79871, 0.045523, 0.0084664, 0.016069, 0.007198, 0.62704, 0.23684]
Predicted label: 3
Correct prediction
Energy consumption = 142.532650 pJ
sum error= 81
Actual label: 6
Output voltages: [0.050451, 0.021924, 0.095148, 0.0045794, 0.32884, 0.34751, 0.79876, 0.0013684, 0.67645, 0.0044419]
Predicted label: 6
Correct prediction
Energy consumption = 146.735551 pJ
sum error= 81
Actual label: 8
Output voltages: [0.017791, 0.018297, 0.051342, 0.047905, 0.020838, 0.11134, 0.011458, 0.044742, 0.79868, 0.026737]
Predicted label: 8
Correct prediction
Energy consumption = 155.480660 pJ
sum error= 81
Actual label: 8
Output voltages: [0.083688, 0.043776, 0.2587, 0.18232, 0.015751, 0.0096633, 0.16757, 0.0095657, 0.79879, 0.32485]
Predicted label: 8
Correct prediction
Energy consumption = 151.280117 pJ
sum error= 81
Actual label: 4
Output voltages: [0.019224, 0.025746, 0.1612, 0.0025729, 0.79866, 0.036931, 0.28346, 0.059208, 0.065838, 0.035577]
Predicted label: 4
Correct prediction
Energy consumption = 158.050976 pJ
sum error= 81
Actual label: 9
Output voltages: [0.21414, 0.028414, 0.043504, 0.1679, 0.2512, 0.030856, 0.029219, 0.0063451, 0.14208, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 150.454873 pJ
sum error= 81
Actual label: 1
Output voltages: [0.022797, 0.79868, 0.41082, 0.1418, 0.17474, 0.001257, 0.5651, 0.0027013, 0.038765, 0.032525]
Predicted label: 1
Correct prediction
Energy consumption = 164.113707 pJ
sum error= 81
Actual label: 9
Output voltages: [0.039657, 0.02201, 0.023912, 0.44885, 0.0083962, 0.0039285, 0.0018358, 0.23136, 0.40676, 0.79805]
Predicted label: 9
Correct prediction
Energy consumption = 159.779184 pJ
sum error= 81
Actual label: 8
Output voltages: [0.035242, 0.0089469, 0.04175, 0.18912, 0.0070849, 0.031183, 0.016215, 0.012725, 0.79874, 0.22038]
Predicted label: 8
Correct prediction
Energy consumption = 140.258637 pJ
sum error= 81
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 167 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 167 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 167 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.27279, 0.0011347, 0.0026512, 0.14027, 0.027438, 0.79624, 0.051348, 0.0075578, 0.78105, 0.15395]
Predicted label: 5
Correct prediction
Energy consumption = 164.273198 pJ
sum error= 81
Actual label: 7
Output voltages: [0.0032995, 0.0047057, 0.048372, 0.77375, 0.01042, 0.053969, 0.0011822, 0.76701, 0.60938, 0.75718]
Predicted label: 3
Wrong prediction!
Energy consumption = 146.819508 pJ
sum error= 82
Actual label: 5
Output voltages: [0.017222, 0.001228, 0.0046295, 0.28402, 0.039187, 0.79879, 0.2621, 0.0095621, 0.70911, 0.041575]
Predicted label: 5
Correct prediction
Energy consumption = 143.503476 pJ
sum error= 82
Actual label: 1
Output voltages: [0.037314, 0.79857, 0.019018, 0.17789, 0.033814, 0.0012189, 0.084145, 0.063073, 0.098205, 0.4823]
Predicted label: 1
Correct prediction
Energy consumption = 167.182148 pJ
sum error= 82
Actual label: 1
Output voltages: [0.10344, 0.79837, 0.043195, 0.27482, 0.010987, 0.0021698, 0.57991, 0.0021528, 0.1116, 0.33559]
Predicted label: 1
Correct prediction
Energy consumption = 151.999205 pJ
sum error= 82
Actual label: 8
Output voltages: [0.050285, 0.035556, 0.061529, 0.17155, 0.001965, 0.046552, 0.026489, 0.0014043, 0.79874, 0.16343]
Predicted label: 8
Correct prediction
Energy consumption = 155.467678 pJ
sum error= 82
Actual label: 6
Output voltages: [0.10071, 0.0011846, 0.0011092, 0.20688, 0.203, 0.79523, 0.78923, 0.0016542, 0.77376, 0.026179]
Predicted label: 5
Wrong prediction!
Energy consumption = 149.173081 pJ
sum error= 83
Actual label: 5
Output voltages: [0.060524, 0.0015731, 0.0011024, 0.041355, 0.031213, 0.79853, 0.046386, 0.0017298, 0.76337, 0.021539]
Predicted label: 5
Correct prediction
Energy consumption = 138.845326 pJ
sum error= 83
Actual label: 2
Output voltages: [0.79854, 0.5597, 0.42357, 0.0010754, 0.30828, 0.0010806, 0.052653, 0.10186, 0.036794, 0.40281]
Predicted label: 0
Wrong prediction!
Energy consumption = 159.985180 pJ
sum error= 84
Actual label: 4
Output voltages: [0.0057856, 0.048948, 0.045772, 0.0029238, 0.7987, 0.0019984, 0.11283, 0.083495, 0.040114, 0.24756]
Predicted label: 4
Correct prediction
Energy consumption = 156.200222 pJ
sum error= 84
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 168 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 168 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 168 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.006581, 0.0049803, 0.089114, 0.24046, 0.79879, 0.0011213, 0.0023747, 0.0030351, 0.28374, 0.045096]
Predicted label: 4
Correct prediction
Energy consumption = 165.728481 pJ
sum error= 84
Actual label: 3
Output voltages: [0.17715, 0.02, 0.46673, 0.73677, 0.0010809, 0.0010878, 0.0010929, 0.79804, 0.74158, 0.34951]
Predicted label: 7
Wrong prediction!
Energy consumption = 143.298961 pJ
sum error= 85
Actual label: 2
Output voltages: [0.76959, 0.055091, 0.79865, 0.45267, 0.016463, 0.0010919, 0.28486, 0.084503, 0.27505, 0.15376]
Predicted label: 2
Correct prediction
Energy consumption = 144.027629 pJ
sum error= 85
Actual label: 3
Output voltages: [0.23468, 0.020755, 0.020252, 0.79869, 0.01222, 0.0049074, 0.0062817, 0.0074254, 0.53766, 0.042089]
Predicted label: 3
Correct prediction
Energy consumption = 143.278443 pJ
sum error= 85
Actual label: 5
Output voltages: [0.42052, 0.048856, 0.0016629, 0.56913, 0.0014943, 0.79875, 0.017374, 0.0012322, 0.48206, 0.019666]
Predicted label: 5
Correct prediction
Energy consumption = 154.236854 pJ
sum error= 85
Actual label: 6
Output voltages: [0.0359, 0.051388, 0.11207, 0.010786, 0.094484, 0.44916, 0.79875, 0.0069847, 0.63902, 0.0025125]
Predicted label: 6
Correct prediction
Energy consumption = 144.902047 pJ
sum error= 85
Actual label: 8
Output voltages: [0.034479, 0.020722, 0.070129, 0.084118, 0.0083783, 0.1047, 0.74406, 0.018598, 0.78908, 0.0024234]
Predicted label: 8
Correct prediction
Energy consumption = 156.227205 pJ
sum error= 85
Actual label: 8
Output voltages: [0.044772, 0.36017, 0.026975, 0.039544, 0.034259, 0.00202, 0.041278, 0.0013003, 0.79879, 0.69516]
Predicted label: 8
Correct prediction
Energy consumption = 152.957890 pJ
sum error= 85
Actual label: 6
Output voltages: [0.045163, 0.019806, 0.041929, 0.010081, 0.095449, 0.43082, 0.79875, 0.015422, 0.76113, 0.0051374]
Predicted label: 6
Correct prediction
Energy consumption = 153.282930 pJ
sum error= 85
Actual label: 2
Output voltages: [0.29582, 0.023133, 0.79877, 0.43958, 0.015488, 0.0011662, 0.19256, 0.20756, 0.45423, 0.013573]
Predicted label: 2
Correct prediction
Energy consumption = 146.665517 pJ
sum error= 85
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 169 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 169 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 169 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.11507, 0.0094528, 0.089882, 0.79873, 0.030978, 0.027885, 0.012208, 0.010141, 0.24142, 0.22999]
Predicted label: 3
Correct prediction
Energy consumption = 163.715388 pJ
sum error= 85
Actual label: 1
Output voltages: [0.021267, 0.79871, 0.21064, 0.016536, 0.0010753, 0.0011858, 0.129, 0.30814, 0.71889, 0.0048006]
Predicted label: 1
Correct prediction
Energy consumption = 156.916596 pJ
sum error= 85
Actual label: 0
Output voltages: [0.79879, 0.052493, 0.46458, 0.0055896, 0.0013487, 0.0028575, 0.13544, 0.026592, 0.052536, 0.043186]
Predicted label: 0
Correct prediction
Energy consumption = 160.194525 pJ
sum error= 85
Actual label: 5
Output voltages: [0.014996, 0.0029811, 0.0010661, 0.7303, 0.031549, 0.79874, 0.10328, 0.02921, 0.63513, 0.10605]
Predicted label: 5
Correct prediction
Energy consumption = 146.910653 pJ
sum error= 85
Actual label: 8
Output voltages: [0.37643, 0.15294, 0.50361, 0.77279, 0.0012435, 0.0013945, 0.023376, 0.068827, 0.79675, 0.094736]
Predicted label: 8
Correct prediction
Energy consumption = 158.140855 pJ
sum error= 85
Actual label: 9
Output voltages: [0.063973, 0.014707, 0.031253, 0.029427, 0.0053391, 0.0034137, 0.0015714, 0.046084, 0.79753, 0.78003]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.635992 pJ
sum error= 86
Actual label: 2
Output voltages: [0.71458, 0.37805, 0.79842, 0.10715, 0.0015374, 0.0012646, 0.27527, 0.057606, 0.049901, 0.17806]
Predicted label: 2
Correct prediction
Energy consumption = 144.535084 pJ
sum error= 86
Actual label: 9
Output voltages: [0.26649, 0.014136, 0.011087, 0.38567, 0.60278, 0.0023143, 0.0036933, 0.0077491, 0.18737, 0.79819]
Predicted label: 9
Correct prediction
Energy consumption = 146.395312 pJ
sum error= 86
Actual label: 6
Output voltages: [0.051878, 0.025514, 0.4961, 0.001459, 0.043103, 0.22822, 0.79876, 0.0067181, 0.62609, 0.0076374]
Predicted label: 6
Correct prediction
Energy consumption = 146.330979 pJ
sum error= 86
Actual label: 7
Output voltages: [0.28235, 0.018774, 0.024456, 0.28046, 0.021391, 0.0036009, 0.0010724, 0.7986, 0.14602, 0.37255]
Predicted label: 7
Correct prediction
Energy consumption = 161.249170 pJ
sum error= 86
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 170 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 170 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 170 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.19163, 0.029199, 0.028604, 0.0025608, 0.037788, 0.42761, 0.016985, 0.12646, 0.041572]
Predicted label: 0
Correct prediction
Energy consumption = 169.685427 pJ
sum error= 86
Actual label: 4
Output voltages: [0.042932, 0.0095269, 0.0049257, 0.0028593, 0.73983, 0.017442, 0.006538, 0.051684, 0.3601, 0.78437]
Predicted label: 9
Wrong prediction!
Energy consumption = 160.780100 pJ
sum error= 87
Actual label: 8
Output voltages: [0.15932, 0.018437, 0.074172, 0.057033, 0.0017406, 0.76364, 0.0222, 0.0031957, 0.79879, 0.013642]
Predicted label: 8
Correct prediction
Energy consumption = 151.838303 pJ
sum error= 87
Actual label: 7
Output voltages: [0.46215, 0.048469, 0.31743, 0.50791, 0.0010698, 0.0010785, 0.0010674, 0.79721, 0.31086, 0.3953]
Predicted label: 7
Correct prediction
Energy consumption = 146.749189 pJ
sum error= 87
Actual label: 1
Output voltages: [0.0018334, 0.79864, 0.015988, 0.032891, 0.024265, 0.00504, 0.36339, 0.0021035, 0.47776, 0.16509]
Predicted label: 1
Correct prediction
Energy consumption = 162.897690 pJ
sum error= 87
Actual label: 7
Output voltages: [0.10888, 0.61201, 0.079746, 0.28519, 0.011482, 0.0010812, 0.0010667, 0.79867, 0.037257, 0.048073]
Predicted label: 7
Correct prediction
Energy consumption = 150.310685 pJ
sum error= 87
Actual label: 4
Output voltages: [0.0092071, 0.029852, 0.15898, 0.0027461, 0.79867, 0.0044207, 0.0096069, 0.14604, 0.1198, 0.45591]
Predicted label: 4
Correct prediction
Energy consumption = 151.701707 pJ
sum error= 87
Actual label: 1
Output voltages: [0.039845, 0.79859, 0.053073, 0.23115, 0.29953, 0.0052477, 0.045792, 0.0018645, 0.027833, 0.18327]
Predicted label: 1
Correct prediction
Energy consumption = 162.666414 pJ
sum error= 87
Actual label: 0
Output voltages: [0.79866, 0.13789, 0.028062, 0.0096299, 0.012899, 0.021733, 0.7503, 0.011503, 0.27114, 0.15188]
Predicted label: 0
Correct prediction
Energy consumption = 149.815009 pJ
sum error= 87
Actual label: 9
Output voltages: [0.0010715, 0.052939, 0.045107, 0.77674, 0.1918, 0.0014574, 0.0091012, 0.0034914, 0.50945, 0.6206]
Predicted label: 3
Wrong prediction!
Energy consumption = 150.724198 pJ
sum error= 88
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 171 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 171 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 171 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.11152, 0.0168, 0.0131, 0.011665, 0.015948, 0.010026, 0.0010717, 0.79871, 0.27519, 0.37951]
Predicted label: 7
Correct prediction
Energy consumption = 171.980226 pJ
sum error= 88
Actual label: 2
Output voltages: [0.45003, 0.041287, 0.79879, 0.036178, 0.015768, 0.0012658, 0.44917, 0.010157, 0.65033, 0.021649]
Predicted label: 2
Correct prediction
Energy consumption = 146.327537 pJ
sum error= 88
Actual label: 0
Output voltages: [0.79354, 0.13048, 0.28056, 0.0066608, 0.0012127, 0.0013151, 0.050791, 0.0046084, 0.43604, 0.045849]
Predicted label: 0
Correct prediction
Energy consumption = 154.015485 pJ
sum error= 88
Actual label: 0
Output voltages: [0.79868, 0.29733, 0.027231, 0.036318, 0.017029, 0.11246, 0.51504, 0.021953, 0.21873, 0.061344]
Predicted label: 0
Correct prediction
Energy consumption = 145.102605 pJ
sum error= 88
Actual label: 9
Output voltages: [0.55103, 0.0058971, 0.026524, 0.010234, 0.29622, 0.0072664, 0.0016442, 0.033884, 0.4985, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 153.328404 pJ
sum error= 88
Actual label: 1
Output voltages: [0.18534, 0.79862, 0.32712, 0.038891, 0.0071442, 0.0017088, 0.18831, 0.0012988, 0.058669, 0.09611]
Predicted label: 1
Correct prediction
Energy consumption = 168.183496 pJ
sum error= 88
Actual label: 7
Output voltages: [0.037539, 0.26788, 0.30105, 0.036909, 0.0029135, 0.0010682, 0.0011175, 0.79878, 0.42621, 0.16789]
Predicted label: 7
Correct prediction
Energy consumption = 149.974874 pJ
sum error= 88
Actual label: 8
Output voltages: [0.50615, 0.013822, 0.13581, 0.070718, 0.036622, 0.019859, 0.46149, 0.0021164, 0.79661, 0.20045]
Predicted label: 8
Correct prediction
Energy consumption = 150.558654 pJ
sum error= 88
Actual label: 7
Output voltages: [0.14084, 0.0015274, 0.43125, 0.62024, 0.66371, 0.0010868, 0.0011648, 0.58711, 0.24264, 0.045486]
Predicted label: 4
Wrong prediction!
Energy consumption = 147.094600 pJ
sum error= 89
Actual label: 8
Output voltages: [0.018935, 0.029798, 0.056532, 0.051992, 0.015491, 0.01185, 0.020512, 0.022839, 0.79869, 0.18887]
Predicted label: 8
Correct prediction
Energy consumption = 145.113289 pJ
sum error= 89
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 172 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 172 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 172 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0041303, 0.007063, 0.04261, 0.0021834, 0.79862, 0.010483, 0.33728, 0.16962, 0.2251, 0.0047377]
Predicted label: 4
Correct prediction
Energy consumption = 165.883900 pJ
sum error= 89
Actual label: 7
Output voltages: [0.045482, 0.0384, 0.054994, 0.090706, 0.3869, 0.0012099, 0.0010758, 0.59956, 0.74391, 0.76834]
Predicted label: 9
Wrong prediction!
Energy consumption = 161.579944 pJ
sum error= 90
Actual label: 2
Output voltages: [0.0067226, 0.0085752, 0.79872, 0.64705, 0.0034805, 0.0010962, 0.22964, 0.49639, 0.51212, 0.018582]
Predicted label: 2
Correct prediction
Energy consumption = 140.620945 pJ
sum error= 90
Actual label: 0
Output voltages: [0.79873, 0.022245, 0.035218, 0.0080958, 0.02834, 0.0084125, 0.7544, 0.020675, 0.15704, 0.050882]
Predicted label: 0
Correct prediction
Energy consumption = 157.835642 pJ
sum error= 90
Actual label: 4
Output voltages: [0.0013107, 0.001306, 0.58061, 0.021927, 0.79878, 0.0010713, 0.21851, 0.29101, 0.048569, 0.014907]
Predicted label: 4
Correct prediction
Energy consumption = 154.071016 pJ
sum error= 90
Actual label: 6
Output voltages: [0.067859, 0.050605, 0.023038, 0.005853, 0.037208, 0.31226, 0.79861, 0.050166, 0.7848, 0.0042105]
Predicted label: 6
Correct prediction
Energy consumption = 151.612558 pJ
sum error= 90
Actual label: 0
Output voltages: [0.79878, 0.046454, 0.010903, 0.0057977, 0.021477, 0.0099047, 0.59021, 0.013803, 0.12953, 0.027476]
Predicted label: 0
Correct prediction
Energy consumption = 142.538520 pJ
sum error= 90
Actual label: 3
Output voltages: [0.038088, 0.32514, 0.027095, 0.79873, 0.0010937, 0.010081, 0.0030041, 0.10536, 0.74389, 0.032533]
Predicted label: 3
Correct prediction
Energy consumption = 146.987658 pJ
sum error= 90
Actual label: 1
Output voltages: [0.021876, 0.79836, 0.053042, 0.20611, 0.0070316, 0.01017, 0.75653, 0.014608, 0.12754, 0.15346]
Predicted label: 1
Correct prediction
Energy consumption = 164.060979 pJ
sum error= 90
Actual label: 1
Output voltages: [0.0031273, 0.79879, 0.30984, 0.24331, 0.019822, 0.001136, 0.37743, 0.0014846, 0.21395, 0.20284]
Predicted label: 1
Correct prediction
Energy consumption = 153.460934 pJ
sum error= 90
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 173 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 173 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 173 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.3401, 0.077125, 0.024434, 0.79633, 0.0011663, 0.33908, 0.25527, 0.001653, 0.75132, 0.015199]
Predicted label: 3
Correct prediction
Energy consumption = 179.728197 pJ
sum error= 90
Actual label: 3
Output voltages: [0.035786, 0.0011706, 0.50441, 0.79813, 0.0095598, 0.057341, 0.003047, 0.0078289, 0.77072, 0.045692]
Predicted label: 3
Correct prediction
Energy consumption = 141.880355 pJ
sum error= 90
Actual label: 9
Output voltages: [0.53357, 0.023854, 0.040713, 0.061097, 0.13006, 0.051124, 0.0026482, 0.0060903, 0.30734, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 155.632134 pJ
sum error= 90
Actual label: 6
Output voltages: [0.32189, 0.35097, 0.077604, 0.0018221, 0.24401, 0.25293, 0.79871, 0.0012388, 0.045102, 0.045916]
Predicted label: 6
Correct prediction
Energy consumption = 143.164415 pJ
sum error= 90
Actual label: 7
Output voltages: [0.75432, 0.028249, 0.0065778, 0.0026035, 0.040599, 0.027503, 0.016666, 0.79878, 0.33409, 0.18469]
Predicted label: 7
Correct prediction
Energy consumption = 153.161343 pJ
sum error= 90
Actual label: 4
Output voltages: [0.026919, 0.050014, 0.035831, 0.03252, 0.79868, 0.0015007, 0.18164, 0.22844, 0.02698, 0.25435]
Predicted label: 4
Correct prediction
Energy consumption = 154.306570 pJ
sum error= 90
Actual label: 1
Output voltages: [0.03414, 0.7984, 0.21188, 0.077734, 0.02737, 0.0080512, 0.58365, 0.0012669, 0.067447, 0.35459]
Predicted label: 1
Correct prediction
Energy consumption = 161.686337 pJ
sum error= 90
Actual label: 5
Output voltages: [0.020124, 0.034969, 0.4028, 0.056561, 0.0013204, 0.32111, 0.71879, 0.0017782, 0.73005, 0.0016165]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.055391 pJ
sum error= 91
Actual label: 3
Output voltages: [0.50496, 0.032017, 0.028294, 0.79858, 0.024576, 0.0080344, 0.022491, 0.011779, 0.50977, 0.048781]
Predicted label: 3
Correct prediction
Energy consumption = 147.963068 pJ
sum error= 91
Actual label: 0
Output voltages: [0.79878, 0.092108, 0.090788, 0.09527, 0.037219, 0.004691, 0.57964, 0.013802, 0.254, 0.032819]
Predicted label: 0
Correct prediction
Energy consumption = 156.279348 pJ
sum error= 91
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 174 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 174 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 174 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.031895, 0.0013279, 0.023994, 0.034227, 0.026395, 0.48359, 0.39623, 0.012025, 0.79853, 0.0016629]
Predicted label: 8
Correct prediction
Energy consumption = 169.493726 pJ
sum error= 91
Actual label: 7
Output voltages: [0.36402, 0.76704, 0.031704, 0.59218, 0.0012331, 0.0013998, 0.0015481, 0.79196, 0.66423, 0.030704]
Predicted label: 7
Correct prediction
Energy consumption = 159.132230 pJ
sum error= 91
Actual label: 3
Output voltages: [0.70455, 0.021197, 0.042343, 0.7986, 0.027395, 0.0051985, 0.017627, 0.01545, 0.46405, 0.029387]
Predicted label: 3
Correct prediction
Energy consumption = 148.672679 pJ
sum error= 91
Actual label: 9
Output voltages: [0.15982, 0.032774, 0.098255, 0.30798, 0.028337, 0.029405, 0.043715, 0.086984, 0.13288, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 153.609581 pJ
sum error= 91
Actual label: 6
Output voltages: [0.017562, 0.19538, 0.19741, 0.010122, 0.12188, 0.37242, 0.79866, 0.0049049, 0.75857, 0.0069151]
Predicted label: 6
Correct prediction
Energy consumption = 146.487426 pJ
sum error= 91
Actual label: 9
Output voltages: [0.53062, 0.01699, 0.021172, 0.026321, 0.24864, 0.020045, 0.0031595, 0.01832, 0.41966, 0.79866]
Predicted label: 9
Correct prediction
Energy consumption = 151.691676 pJ
sum error= 91
Actual label: 3
Output voltages: [0.43829, 0.074586, 0.022348, 0.79871, 0.01405, 0.016252, 0.058079, 0.1238, 0.36429, 0.0067336]
Predicted label: 3
Correct prediction
Energy consumption = 144.846240 pJ
sum error= 91
Actual label: 5
Output voltages: [0.35289, 0.014983, 0.0010843, 0.39718, 0.018463, 0.7976, 0.10191, 0.0039265, 0.75257, 0.0041722]
Predicted label: 5
Correct prediction
Energy consumption = 144.295572 pJ
sum error= 91
Actual label: 0
Output voltages: [0.79751, 0.021109, 0.030716, 0.0044941, 0.023213, 0.0038432, 0.6907, 0.083793, 0.044703, 0.040064]
Predicted label: 0
Correct prediction
Energy consumption = 142.216006 pJ
sum error= 91
Actual label: 2
Output voltages: [0.5414, 0.18679, 0.79873, 0.070938, 0.0014468, 0.0012355, 0.051021, 0.3597, 0.47035, 0.24102]
Predicted label: 2
Correct prediction
Energy consumption = 143.023216 pJ
sum error= 91
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 175 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 175 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 175 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.10559, 0.030703, 0.36807, 0.42855, 0.075446, 0.001232, 0.0010754, 0.79856, 0.54594, 0.037322]
Predicted label: 7
Correct prediction
Energy consumption = 171.307093 pJ
sum error= 91
Actual label: 4
Output voltages: [0.032089, 0.027307, 0.13284, 0.57973, 0.79878, 0.001067, 0.038586, 0.029579, 0.0020485, 0.049252]
Predicted label: 4
Correct prediction
Energy consumption = 150.265369 pJ
sum error= 91
Actual label: 5
Output voltages: [0.029364, 0.0011115, 0.019149, 0.54433, 0.0084683, 0.79869, 0.052447, 0.10811, 0.73516, 0.11327]
Predicted label: 5
Correct prediction
Energy consumption = 152.836672 pJ
sum error= 91
Actual label: 1
Output voltages: [0.0339, 0.79862, 0.038988, 0.34802, 0.041371, 0.014604, 0.10051, 0.0082706, 0.039013, 0.20944]
Predicted label: 1
Correct prediction
Energy consumption = 163.841221 pJ
sum error= 91
Actual label: 7
Output voltages: [0.051337, 0.23856, 0.79236, 0.69067, 0.026872, 0.0013167, 0.019119, 0.46272, 0.32643, 0.0013055]
Predicted label: 2
Wrong prediction!
Energy consumption = 154.553505 pJ
sum error= 92
Actual label: 5
Output voltages: [0.044745, 0.0014161, 0.069373, 0.10871, 0.0024089, 0.78506, 0.18342, 0.13505, 0.75058, 0.057862]
Predicted label: 5
Correct prediction
Energy consumption = 147.832661 pJ
sum error= 92
Actual label: 8
Output voltages: [0.015935, 0.004934, 0.0176, 0.39739, 0.0016302, 0.36627, 0.028714, 0.0018056, 0.79875, 0.039551]
Predicted label: 8
Correct prediction
Energy consumption = 142.349472 pJ
sum error= 92
Actual label: 0
Output voltages: [0.79853, 0.046709, 0.045306, 0.033313, 0.0068583, 0.0031019, 0.60368, 0.089326, 0.36632, 0.18151]
Predicted label: 0
Correct prediction
Energy consumption = 157.189273 pJ
sum error= 92
Actual label: 8
Output voltages: [0.26391, 0.022779, 0.10906, 0.15417, 0.0039005, 0.070371, 0.0032762, 0.0052785, 0.79869, 0.054794]
Predicted label: 8
Correct prediction
Energy consumption = 143.323552 pJ
sum error= 92
Actual label: 8
Output voltages: [0.044365, 0.017367, 0.027243, 0.0040262, 0.057192, 0.082782, 0.62199, 0.0022858, 0.79642, 0.016961]
Predicted label: 8
Correct prediction
Energy consumption = 134.472244 pJ
sum error= 92
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 176 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 176 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 176 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.016404, 0.79858, 0.030812, 0.16493, 0.079753, 0.0098282, 0.55635, 0.0014271, 0.43319, 0.035864]
Predicted label: 1
Correct prediction
Energy consumption = 176.717615 pJ
sum error= 92
Actual label: 5
Output voltages: [0.01778, 0.0011573, 0.0011103, 0.036258, 0.087978, 0.79423, 0.033274, 0.0091657, 0.7845, 0.053117]
Predicted label: 5
Correct prediction
Energy consumption = 151.830726 pJ
sum error= 92
Actual label: 0
Output voltages: [0.79833, 0.029332, 0.1214, 0.010245, 0.019687, 0.002547, 0.59932, 0.013042, 0.33351, 0.57104]
Predicted label: 0
Correct prediction
Energy consumption = 155.368345 pJ
sum error= 92
Actual label: 3
Output voltages: [0.2022, 0.034427, 0.053542, 0.79855, 0.01157, 0.033695, 0.017632, 0.030699, 0.47061, 0.043376]
Predicted label: 3
Correct prediction
Energy consumption = 147.533942 pJ
sum error= 92
Actual label: 0
Output voltages: [0.79819, 0.035105, 0.036357, 0.011802, 0.021969, 0.0013198, 0.76569, 0.0074084, 0.27523, 0.05782]
Predicted label: 0
Correct prediction
Energy consumption = 155.701989 pJ
sum error= 92
Actual label: 3
Output voltages: [0.016261, 0.0011734, 0.017076, 0.79878, 0.04072, 0.20507, 0.062773, 0.015365, 0.74585, 0.0026579]
Predicted label: 3
Correct prediction
Energy consumption = 145.066482 pJ
sum error= 92
Actual label: 1
Output voltages: [0.035928, 0.79875, 0.10091, 0.031541, 0.037507, 0.022395, 0.75535, 0.0018266, 0.048942, 0.0010749]
Predicted label: 1
Correct prediction
Energy consumption = 155.373688 pJ
sum error= 92
Actual label: 4
Output voltages: [0.01142, 0.0073404, 0.12763, 0.031838, 0.79866, 0.0012779, 0.049075, 0.026328, 0.021238, 0.041504]
Predicted label: 4
Correct prediction
Energy consumption = 149.696412 pJ
sum error= 92
Actual label: 0
Output voltages: [0.79877, 0.054894, 0.024971, 0.021463, 0.017359, 0.017226, 0.38693, 0.0074985, 0.064086, 0.12842]
Predicted label: 0
Correct prediction
Energy consumption = 156.612099 pJ
sum error= 92
Actual label: 3
Output voltages: [0.029608, 0.0012081, 0.7825, 0.76479, 0.0094308, 0.0010676, 0.0066132, 0.093089, 0.78095, 0.017593]
Predicted label: 2
Wrong prediction!
Energy consumption = 140.857420 pJ
sum error= 93
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 177 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 177 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 177 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.04277, 0.13091, 0.51487, 0.33018, 0.0030001, 0.0010715, 0.0011012, 0.79872, 0.4304, 0.231]
Predicted label: 7
Correct prediction
Energy consumption = 167.751798 pJ
sum error= 93
Actual label: 2
Output voltages: [0.41575, 0.29128, 0.79872, 0.04876, 0.010698, 0.0012196, 0.24552, 0.15621, 0.45067, 0.076959]
Predicted label: 2
Correct prediction
Energy consumption = 145.640026 pJ
sum error= 93
Actual label: 7
Output voltages: [0.013946, 0.0020663, 0.0012748, 0.41789, 0.76446, 0.4761, 0.0030484, 0.798, 0.16128, 0.040616]
Predicted label: 7
Correct prediction
Energy consumption = 150.241598 pJ
sum error= 93
Actual label: 1
Output voltages: [0.13247, 0.79875, 0.011511, 0.010747, 0.046925, 0.033944, 0.79756, 0.0012472, 0.08679, 0.081359]
Predicted label: 1
Correct prediction
Energy consumption = 161.370850 pJ
sum error= 93
Actual label: 8
Output voltages: [0.026646, 0.0015204, 0.018041, 0.47353, 0.0072609, 0.63352, 0.11654, 0.0022327, 0.79879, 0.21478]
Predicted label: 8
Correct prediction
Energy consumption = 154.266351 pJ
sum error= 93
Actual label: 0
Output voltages: [0.79876, 0.02751, 0.029065, 0.0014033, 0.027029, 0.070946, 0.10623, 0.024878, 0.56679, 0.26312]
Predicted label: 0
Correct prediction
Energy consumption = 156.596842 pJ
sum error= 93
Actual label: 7
Output voltages: [0.40327, 0.026682, 0.5599, 0.57974, 0.0022727, 0.001226, 0.0010768, 0.77371, 0.037982, 0.51883]
Predicted label: 7
Correct prediction
Energy consumption = 154.034787 pJ
sum error= 93
Actual label: 0
Output voltages: [0.79878, 0.25799, 0.020247, 0.0062736, 0.037175, 0.01324, 0.53783, 0.0077997, 0.028336, 0.10423]
Predicted label: 0
Correct prediction
Energy consumption = 155.072178 pJ
sum error= 93
Actual label: 4
Output voltages: [0.015416, 0.019239, 0.11594, 0.0096413, 0.7987, 0.0016268, 0.58224, 0.0059583, 0.018333, 0.26045]
Predicted label: 4
Correct prediction
Energy consumption = 153.605247 pJ
sum error= 93
Actual label: 3
Output voltages: [0.22996, 0.021429, 0.061604, 0.79877, 0.015664, 0.0017786, 0.006548, 0.0032525, 0.50454, 0.04976]
Predicted label: 3
Correct prediction
Energy consumption = 144.276495 pJ
sum error= 93
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 178 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 178 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 178 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0063399, 0.79863, 0.034213, 0.034325, 0.0023008, 0.0013671, 0.73041, 0.0091382, 0.31318, 0.0056696]
Predicted label: 1
Correct prediction
Energy consumption = 182.714509 pJ
sum error= 93
Actual label: 9
Output voltages: [0.77064, 0.0056897, 0.023727, 0.012267, 0.48584, 0.0029272, 0.084319, 0.0013558, 0.16422, 0.79682]
Predicted label: 9
Correct prediction
Energy consumption = 156.799445 pJ
sum error= 93
Actual label: 8
Output voltages: [0.31294, 0.009429, 0.15434, 0.01041, 0.0097924, 0.10144, 0.015081, 0.038148, 0.79849, 0.49513]
Predicted label: 8
Correct prediction
Energy consumption = 154.999055 pJ
sum error= 93
Actual label: 7
Output voltages: [0.33382, 0.10363, 0.026205, 0.027127, 0.0044648, 0.035922, 0.0010896, 0.79869, 0.05175, 0.55078]
Predicted label: 7
Correct prediction
Energy consumption = 145.326478 pJ
sum error= 93
Actual label: 7
Output voltages: [0.10722, 0.19772, 0.20988, 0.01215, 0.008538, 0.0053873, 0.0011332, 0.79862, 0.42536, 0.50792]
Predicted label: 7
Correct prediction
Energy consumption = 147.098552 pJ
sum error= 93
Actual label: 1
Output voltages: [0.021147, 0.79799, 0.035255, 0.30746, 0.056569, 0.004858, 0.005473, 0.0036658, 0.41948, 0.048162]
Predicted label: 1
Correct prediction
Energy consumption = 165.963220 pJ
sum error= 93
Actual label: 4
Output voltages: [0.026322, 0.022362, 0.13505, 0.014754, 0.79868, 0.010944, 0.06112, 0.079327, 0.023187, 0.0050995]
Predicted label: 4
Correct prediction
Energy consumption = 152.239433 pJ
sum error= 93
Actual label: 9
Output voltages: [0.23328, 0.003672, 0.019749, 0.058618, 0.47842, 0.09375, 0.033054, 0.040655, 0.078538, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 149.109685 pJ
sum error= 93
Actual label: 9
Output voltages: [0.46627, 0.029292, 0.0097704, 0.062261, 0.4712, 0.022893, 0.012946, 0.0025162, 0.37658, 0.79831]
Predicted label: 9
Correct prediction
Energy consumption = 156.671529 pJ
sum error= 93
Actual label: 3
Output voltages: [0.54349, 0.027962, 0.072199, 0.79874, 0.0086376, 0.0083272, 0.076265, 0.0014307, 0.44609, 0.038794]
Predicted label: 3
Correct prediction
Energy consumption = 148.877853 pJ
sum error= 93
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 179 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 179 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 179 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.57688, 0.17584, 0.55109, 0.0010906, 0.052289, 0.0011927, 0.0014484, 0.70012, 0.58234, 0.11936]
Predicted label: 7
Wrong prediction!
Energy consumption = 162.283124 pJ
sum error= 94
Actual label: 1
Output voltages: [0.002406, 0.79863, 0.0012462, 0.055497, 0.014173, 0.0010686, 0.39284, 0.048979, 0.3262, 0.032984]
Predicted label: 1
Correct prediction
Energy consumption = 156.842960 pJ
sum error= 94
Actual label: 7
Output voltages: [0.28347, 0.0090992, 0.035109, 0.76812, 0.010508, 0.0022409, 0.0011589, 0.79876, 0.20043, 0.37007]
Predicted label: 7
Correct prediction
Energy consumption = 146.558105 pJ
sum error= 94
Actual label: 9
Output voltages: [0.70292, 0.0027381, 0.048581, 0.010789, 0.57839, 0.019048, 0.0050543, 0.018312, 0.056946, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 137.660996 pJ
sum error= 94
Actual label: 0
Output voltages: [0.79879, 0.026602, 0.18139, 0.039256, 0.0038742, 0.0052054, 0.51546, 0.020297, 0.058037, 0.1708]
Predicted label: 0
Correct prediction
Energy consumption = 145.181893 pJ
sum error= 94
Actual label: 2
Output voltages: [0.65068, 0.019207, 0.79879, 0.13701, 0.019957, 0.0011654, 0.051213, 0.10174, 0.53702, 0.01841]
Predicted label: 2
Correct prediction
Energy consumption = 143.425630 pJ
sum error= 94
Actual label: 0
Output voltages: [0.79878, 0.031024, 0.037711, 0.0014557, 0.01112, 0.0051014, 0.41649, 0.0025229, 0.03929, 0.036981]
Predicted label: 0
Correct prediction
Energy consumption = 148.183052 pJ
sum error= 94
Actual label: 3
Output voltages: [0.49727, 0.011142, 0.028388, 0.79879, 0.01698, 0.041356, 0.28483, 0.015679, 0.19983, 0.10935]
Predicted label: 3
Correct prediction
Energy consumption = 152.291184 pJ
sum error= 94
Actual label: 3
Output voltages: [0.048367, 0.011767, 0.029727, 0.79873, 0.02731, 0.0061132, 0.051724, 0.015483, 0.44149, 0.14892]
Predicted label: 3
Correct prediction
Energy consumption = 137.801179 pJ
sum error= 94
Actual label: 7
Output voltages: [0.2206, 0.02326, 0.042158, 0.35842, 0.0090871, 0.0011928, 0.0011212, 0.79861, 0.35118, 0.20257]
Predicted label: 7
Correct prediction
Energy consumption = 153.323925 pJ
sum error= 94
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 180 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 180 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 180 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.23816, 0.0040812, 0.15728, 0.021464, 0.22147, 0.017371, 0.79848, 0.004879, 0.03445, 0.48709]
Predicted label: 6
Correct prediction
Energy consumption = 153.166543 pJ
sum error= 94
Actual label: 9
Output voltages: [0.45765, 0.0011469, 0.048895, 0.035269, 0.063149, 0.030953, 0.002217, 0.020812, 0.72452, 0.79149]
Predicted label: 9
Correct prediction
Energy consumption = 145.933284 pJ
sum error= 94
Actual label: 2
Output voltages: [0.43937, 0.089916, 0.79878, 0.1742, 0.0081225, 0.001206, 0.23339, 0.2211, 0.37837, 0.023365]
Predicted label: 2
Correct prediction
Energy consumption = 147.140717 pJ
sum error= 94
Actual label: 3
Output voltages: [0.13512, 0.034885, 0.057258, 0.79868, 0.023242, 0.019718, 0.018561, 0.018368, 0.32312, 0.17054]
Predicted label: 3
Correct prediction
Energy consumption = 142.669942 pJ
sum error= 94
Actual label: 3
Output voltages: [0.18632, 0.017097, 0.042306, 0.79867, 0.028801, 0.0037725, 0.0084718, 0.012866, 0.67688, 0.041259]
Predicted label: 3
Correct prediction
Energy consumption = 132.995457 pJ
sum error= 94
Actual label: 7
Output voltages: [0.24614, 0.15937, 0.043506, 0.32847, 0.0067465, 0.0061616, 0.0010697, 0.79865, 0.020279, 0.38247]
Predicted label: 7
Correct prediction
Energy consumption = 147.624044 pJ
sum error= 94
Actual label: 7
Output voltages: [0.36297, 0.050334, 0.46615, 0.25144, 0.0029405, 0.0011297, 0.0014129, 0.79873, 0.046186, 0.37948]
Predicted label: 7
Correct prediction
Energy consumption = 147.851236 pJ
sum error= 94
Actual label: 0
Output voltages: [0.7987, 0.046284, 0.19918, 0.023055, 0.001474, 0.043721, 0.35822, 0.028755, 0.35804, 0.022466]
Predicted label: 0
Correct prediction
Energy consumption = 143.294384 pJ
sum error= 94
Actual label: 0
Output voltages: [0.77153, 0.02545, 0.31224, 0.0056342, 0.77872, 0.0010694, 0.61284, 0.019668, 0.015193, 0.024618]
Predicted label: 4
Wrong prediction!
Energy consumption = 141.260729 pJ
sum error= 95
Actual label: 7
Output voltages: [0.25442, 0.40135, 0.041354, 0.38938, 0.019713, 0.0011402, 0.0010873, 0.78845, 0.010144, 0.52714]
Predicted label: 7
Correct prediction
Energy consumption = 155.994961 pJ
sum error= 95
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 181 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 181 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 181 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.1157, 0.0010795, 0.016897, 0.38735, 0.0093191, 0.79875, 0.053224, 0.01844, 0.78325, 0.027798]
Predicted label: 5
Correct prediction
Energy consumption = 162.042971 pJ
sum error= 95
Actual label: 2
Output voltages: [0.63848, 0.0010925, 0.76382, 0.78083, 0.013068, 0.0014587, 0.0032368, 0.049846, 0.71978, 0.027009]
Predicted label: 3
Wrong prediction!
Energy consumption = 150.454542 pJ
sum error= 96
Actual label: 9
Output voltages: [0.77063, 0.0014851, 0.0042102, 0.014717, 0.50251, 0.094116, 0.027788, 0.061898, 0.096769, 0.7979]
Predicted label: 9
Correct prediction
Energy consumption = 163.254345 pJ
sum error= 96
Actual label: 8
Output voltages: [0.31348, 0.0011813, 0.023062, 0.54629, 0.0026262, 0.62092, 0.0089163, 0.0013333, 0.79879, 0.14376]
Predicted label: 8
Correct prediction
Energy consumption = 149.635450 pJ
sum error= 96
Actual label: 7
Output voltages: [0.069652, 0.07899, 0.33102, 0.016827, 0.0020722, 0.0017165, 0.0010678, 0.79827, 0.79586, 0.013163]
Predicted label: 7
Correct prediction
Energy consumption = 143.276171 pJ
sum error= 96
Actual label: 4
Output voltages: [0.0055671, 0.0080548, 0.23683, 0.01246, 0.79854, 0.0029386, 0.044635, 0.025877, 0.040859, 0.048974]
Predicted label: 4
Correct prediction
Energy consumption = 153.441719 pJ
sum error= 96
Actual label: 4
Output voltages: [0.0013396, 0.0025001, 0.19331, 0.0044667, 0.79876, 0.0014263, 0.16606, 0.054049, 0.031433, 0.081011]
Predicted label: 4
Correct prediction
Energy consumption = 143.926606 pJ
sum error= 96
Actual label: 2
Output voltages: [0.75339, 0.21078, 0.79876, 0.46629, 0.0098831, 0.0011462, 0.30736, 0.068137, 0.49085, 0.043642]
Predicted label: 2
Correct prediction
Energy consumption = 148.514467 pJ
sum error= 96
Actual label: 6
Output voltages: [0.10619, 0.22219, 0.047587, 0.017914, 0.070999, 0.35001, 0.79877, 0.0016759, 0.40358, 0.029414]
Predicted label: 6
Correct prediction
Energy consumption = 155.473388 pJ
sum error= 96
Actual label: 6
Output voltages: [0.19527, 0.0078222, 0.24056, 0.0073362, 0.26298, 0.3528, 0.79764, 0.0015686, 0.74025, 0.0030145]
Predicted label: 6
Correct prediction
Energy consumption = 133.412884 pJ
sum error= 96
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 182 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 182 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 182 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.28776, 0.79865, 0.025635, 0.0068299, 0.35846, 0.0059595, 0.33564, 0.0051542, 0.0034833, 0.22104]
Predicted label: 1
Correct prediction
Energy consumption = 174.084884 pJ
sum error= 96
Actual label: 9
Output voltages: [0.37963, 0.010018, 0.025088, 0.02321, 0.24316, 0.063578, 0.0085957, 0.037292, 0.29449, 0.79751]
Predicted label: 9
Correct prediction
Energy consumption = 159.686193 pJ
sum error= 96
Actual label: 6
Output voltages: [0.33322, 0.0066782, 0.012747, 0.20963, 0.051082, 0.79668, 0.78853, 0.0040472, 0.67314, 0.0092514]
Predicted label: 5
Wrong prediction!
Energy consumption = 156.345990 pJ
sum error= 97
Actual label: 8
Output voltages: [0.0072145, 0.023005, 0.12514, 0.048069, 0.0335, 0.03481, 0.1274, 0.0011444, 0.7973, 0.34015]
Predicted label: 8
Correct prediction
Energy consumption = 147.344502 pJ
sum error= 97
Actual label: 2
Output voltages: [0.61872, 0.075373, 0.79878, 0.035019, 0.0039854, 0.0013086, 0.26185, 0.22081, 0.48174, 0.036211]
Predicted label: 2
Correct prediction
Energy consumption = 152.171315 pJ
sum error= 97
Actual label: 9
Output voltages: [0.32068, 0.0059503, 0.031635, 0.037753, 0.22242, 0.0051541, 0.0018786, 0.018176, 0.41487, 0.79809]
Predicted label: 9
Correct prediction
Energy consumption = 151.639715 pJ
sum error= 97
Actual label: 0
Output voltages: [0.7986, 0.04197, 0.047559, 0.0066606, 0.0039959, 0.0018294, 0.62802, 0.010233, 0.050403, 0.046314]
Predicted label: 0
Correct prediction
Energy consumption = 149.119617 pJ
sum error= 97
Actual label: 8
Output voltages: [0.02787, 0.15708, 0.20755, 0.37212, 0.0088283, 0.0098164, 0.24471, 0.0036024, 0.79877, 0.10839]
Predicted label: 8
Correct prediction
Energy consumption = 155.203179 pJ
sum error= 97
Actual label: 3
Output voltages: [0.27251, 0.023364, 0.0072293, 0.79848, 0.0013725, 0.25899, 0.017124, 0.74568, 0.036698, 0.013483]
Predicted label: 3
Correct prediction
Energy consumption = 159.186089 pJ
sum error= 97
Actual label: 1
Output voltages: [0.13374, 0.79835, 0.029957, 0.051719, 0.0027815, 0.0021917, 0.35485, 0.015605, 0.04862, 0.30644]
Predicted label: 1
Correct prediction
Energy consumption = 161.234062 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 183 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 183 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 183 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0035304, 0.79858, 0.031674, 0.048051, 0.034808, 0.0016359, 0.76877, 0.011038, 0.32857, 0.029038]
Predicted label: 1
Correct prediction
Energy consumption = 185.614345 pJ
sum error= 97
Actual label: 6
Output voltages: [0.32162, 0.021038, 0.0448, 0.015452, 0.14758, 0.57124, 0.79875, 0.0011098, 0.51611, 0.044059]
Predicted label: 6
Correct prediction
Energy consumption = 148.090478 pJ
sum error= 97
Actual label: 3
Output voltages: [0.42751, 0.0034321, 0.016439, 0.79869, 0.024412, 0.20062, 0.0095611, 0.023872, 0.41832, 0.043849]
Predicted label: 3
Correct prediction
Energy consumption = 148.381040 pJ
sum error= 97
Actual label: 5
Output voltages: [0.06096, 0.0013136, 0.0063584, 0.72018, 0.0091817, 0.79859, 0.01409, 0.085583, 0.75671, 0.06005]
Predicted label: 5
Correct prediction
Energy consumption = 138.969011 pJ
sum error= 97
Actual label: 1
Output voltages: [0.048617, 0.7985, 0.1417, 0.10071, 0.17051, 0.001092, 0.54025, 0.023185, 0.021249, 0.041802]
Predicted label: 1
Correct prediction
Energy consumption = 172.657559 pJ
sum error= 97
Actual label: 1
Output voltages: [0.072814, 0.79852, 0.019778, 0.13806, 0.018375, 0.0058684, 0.5962, 0.0011937, 0.17282, 0.12403]
Predicted label: 1
Correct prediction
Energy consumption = 159.645782 pJ
sum error= 97
Actual label: 1
Output voltages: [0.0057587, 0.79856, 0.023533, 0.26989, 0.017629, 0.0011079, 0.51761, 0.011625, 0.29357, 0.045174]
Predicted label: 1
Correct prediction
Energy consumption = 153.057845 pJ
sum error= 97
Actual label: 3
Output voltages: [0.23142, 0.0074183, 0.025623, 0.79872, 0.036186, 0.35193, 0.055815, 0.0051125, 0.64944, 0.047127]
Predicted label: 3
Correct prediction
Energy consumption = 147.589645 pJ
sum error= 97
Actual label: 1
Output voltages: [0.023308, 0.78773, 0.67, 0.65372, 0.19318, 0.00128, 0.29756, 0.0012752, 0.036825, 0.22811]
Predicted label: 1
Correct prediction
Energy consumption = 156.699068 pJ
sum error= 97
Actual label: 2
Output voltages: [0.13118, 0.059171, 0.79767, 0.54874, 0.0038313, 0.001263, 0.096786, 0.0071749, 0.51237, 0.022647]
Predicted label: 2
Correct prediction
Energy consumption = 143.204805 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 184 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 184 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 184 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.4727, 0.06675, 0.20447, 0.79871, 0.0087323, 0.0096566, 0.047762, 0.037688, 0.18373, 0.007223]
Predicted label: 3
Correct prediction
Energy consumption = 170.269933 pJ
sum error= 97
Actual label: 0
Output voltages: [0.79878, 0.101, 0.0091091, 0.0056803, 0.017468, 0.037273, 0.71725, 0.016036, 0.12536, 0.19814]
Predicted label: 0
Correct prediction
Energy consumption = 155.317048 pJ
sum error= 97
Actual label: 2
Output voltages: [0.038188, 0.062032, 0.79879, 0.10351, 0.020459, 0.0012416, 0.38398, 0.027547, 0.68843, 0.11383]
Predicted label: 2
Correct prediction
Energy consumption = 155.129295 pJ
sum error= 97
Actual label: 0
Output voltages: [0.79878, 0.0089542, 0.43387, 0.021937, 0.027488, 0.0024994, 0.038897, 0.01978, 0.46458, 0.26958]
Predicted label: 0
Correct prediction
Energy consumption = 149.172239 pJ
sum error= 97
Actual label: 1
Output voltages: [0.013462, 0.7984, 0.10286, 0.48599, 0.0059702, 0.0013734, 0.28176, 0.045195, 0.36659, 0.027309]
Predicted label: 1
Correct prediction
Energy consumption = 165.905709 pJ
sum error= 97
Actual label: 3
Output voltages: [0.13764, 0.018843, 0.019763, 0.7987, 0.0079842, 0.0058877, 0.010841, 0.012056, 0.64095, 0.041501]
Predicted label: 3
Correct prediction
Energy consumption = 143.740758 pJ
sum error= 97
Actual label: 5
Output voltages: [0.027272, 0.0012805, 0.013294, 0.29307, 0.015702, 0.78916, 0.012002, 0.0021032, 0.78225, 0.019266]
Predicted label: 5
Correct prediction
Energy consumption = 137.161767 pJ
sum error= 97
Actual label: 5
Output voltages: [0.44845, 0.0012556, 0.0031378, 0.004624, 0.0022146, 0.78797, 0.36214, 0.0045795, 0.63357, 0.028735]
Predicted label: 5
Correct prediction
Energy consumption = 138.311904 pJ
sum error= 97
Actual label: 7
Output voltages: [0.053186, 0.20645, 0.77103, 0.01732, 0.0048625, 0.0011166, 0.0010928, 0.79875, 0.4254, 0.1396]
Predicted label: 7
Correct prediction
Energy consumption = 149.946898 pJ
sum error= 97
Actual label: 4
Output voltages: [0.035385, 0.0021213, 0.54989, 0.27395, 0.79879, 0.0069038, 0.015432, 0.0071284, 0.059467, 0.050344]
Predicted label: 4
Correct prediction
Energy consumption = 138.862995 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 185 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 185 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 185 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.071656, 0.034146, 0.035441, 0.19103, 0.004564, 0.0015605, 0.016099, 0.012337, 0.79854, 0.58217]
Predicted label: 8
Correct prediction
Energy consumption = 167.183719 pJ
sum error= 97
Actual label: 9
Output voltages: [0.48761, 0.0048427, 0.018739, 0.014956, 0.36834, 0.0056717, 0.0015013, 0.021579, 0.47705, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 148.798184 pJ
sum error= 97
Actual label: 6
Output voltages: [0.31191, 0.036929, 0.0064566, 0.021412, 0.44181, 0.49437, 0.79877, 0.0012496, 0.57447, 0.011404]
Predicted label: 6
Correct prediction
Energy consumption = 156.841008 pJ
sum error= 97
Actual label: 9
Output voltages: [0.59129, 0.0014301, 0.09731, 0.028949, 0.42759, 0.018755, 0.025947, 0.23291, 0.036887, 0.79465]
Predicted label: 9
Correct prediction
Energy consumption = 155.309323 pJ
sum error= 97
Actual label: 6
Output voltages: [0.037315, 0.081952, 0.36884, 0.0011201, 0.44155, 0.13338, 0.7987, 0.0011872, 0.52061, 0.0085591]
Predicted label: 6
Correct prediction
Energy consumption = 147.459205 pJ
sum error= 97
Actual label: 8
Output voltages: [0.013614, 0.018769, 0.1158, 0.39755, 0.001432, 0.016641, 0.0051613, 0.010404, 0.79871, 0.34741]
Predicted label: 8
Correct prediction
Energy consumption = 151.120616 pJ
sum error= 97
Actual label: 3
Output voltages: [0.35213, 0.040485, 0.78319, 0.79852, 0.066377, 0.0010663, 0.007093, 0.0014317, 0.32413, 0.018997]
Predicted label: 3
Correct prediction
Energy consumption = 132.457404 pJ
sum error= 97
Actual label: 6
Output voltages: [0.029682, 0.0065388, 0.4703, 0.0030284, 0.72084, 0.2102, 0.7987, 0.0039977, 0.40586, 0.0082112]
Predicted label: 6
Correct prediction
Energy consumption = 147.700378 pJ
sum error= 97
Actual label: 6
Output voltages: [0.050674, 0.015605, 0.28858, 0.0023318, 0.40687, 0.20186, 0.79878, 0.0012082, 0.72283, 0.010407]
Predicted label: 6
Correct prediction
Energy consumption = 142.083681 pJ
sum error= 97
Actual label: 8
Output voltages: [0.012331, 0.050978, 0.35944, 0.016846, 0.013619, 0.0075087, 0.13606, 0.0094418, 0.79878, 0.26648]
Predicted label: 8
Correct prediction
Energy consumption = 138.168751 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 186 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 186 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 186 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.031194, 0.0010663, 0.00347, 0.21617, 0.034207, 0.79876, 0.16072, 0.072526, 0.77752, 0.059389]
Predicted label: 5
Correct prediction
Energy consumption = 166.974095 pJ
sum error= 97
Actual label: 1
Output voltages: [0.032104, 0.79878, 0.019156, 0.31853, 0.033854, 0.0017603, 0.0022316, 0.34417, 0.35689, 0.096483]
Predicted label: 1
Correct prediction
Energy consumption = 161.626956 pJ
sum error= 97
Actual label: 4
Output voltages: [0.010605, 0.0029566, 0.086479, 0.0080327, 0.79879, 0.0010721, 0.0097705, 0.033324, 0.063824, 0.34331]
Predicted label: 4
Correct prediction
Energy consumption = 162.953002 pJ
sum error= 97
Actual label: 2
Output voltages: [0.24895, 0.0013161, 0.79806, 0.52466, 0.017689, 0.0011481, 0.040762, 0.1463, 0.67258, 0.020797]
Predicted label: 2
Correct prediction
Energy consumption = 147.199988 pJ
sum error= 97
Actual label: 4
Output voltages: [0.0042216, 0.016727, 0.21868, 0.01283, 0.79863, 0.0035809, 0.032525, 0.026459, 0.053196, 0.022174]
Predicted label: 4
Correct prediction
Energy consumption = 156.857389 pJ
sum error= 97
Actual label: 4
Output voltages: [0.0016888, 0.021519, 0.027058, 0.053936, 0.79875, 0.0012137, 0.040466, 0.13453, 0.056744, 0.044454]
Predicted label: 4
Correct prediction
Energy consumption = 136.193970 pJ
sum error= 97
Actual label: 5
Output voltages: [0.14128, 0.0011095, 0.0019805, 0.25072, 0.082326, 0.79695, 0.051994, 0.048114, 0.79073, 0.20106]
Predicted label: 5
Correct prediction
Energy consumption = 144.769236 pJ
sum error= 97
Actual label: 1
Output voltages: [0.022458, 0.79839, 0.25163, 0.047092, 0.023408, 0.0034844, 0.58893, 0.0063916, 0.22057, 0.10997]
Predicted label: 1
Correct prediction
Energy consumption = 167.895147 pJ
sum error= 97
Actual label: 1
Output voltages: [0.0021196, 0.79875, 0.027003, 0.024067, 0.53631, 0.0010806, 0.028665, 0.076993, 0.074631, 0.060284]
Predicted label: 1
Correct prediction
Energy consumption = 142.353686 pJ
sum error= 97
Actual label: 9
Output voltages: [0.32811, 0.0031057, 0.012819, 0.29076, 0.04003, 0.0055172, 0.0011839, 0.026572, 0.19476, 0.79601]
Predicted label: 9
Correct prediction
Energy consumption = 152.172466 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 187 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 187 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 187 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.24054, 0.038002, 0.011841, 0.012683, 0.012924, 0.45289, 0.011822, 0.15163, 0.12172]
Predicted label: 0
Correct prediction
Energy consumption = 168.721257 pJ
sum error= 97
Actual label: 2
Output voltages: [0.078804, 0.031995, 0.76499, 0.54179, 0.038301, 0.001087, 0.28094, 0.0020496, 0.79798, 0.027593]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.620185 pJ
sum error= 98
Actual label: 4
Output voltages: [0.0073146, 0.013137, 0.046331, 0.013729, 0.79872, 0.0010823, 0.027617, 0.11041, 0.042306, 0.22768]
Predicted label: 4
Correct prediction
Energy consumption = 158.450957 pJ
sum error= 98
Actual label: 9
Output voltages: [0.20655, 0.029036, 0.025161, 0.46975, 0.04918, 0.010597, 0.029054, 0.023516, 0.05207, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 145.197511 pJ
sum error= 98
Actual label: 5
Output voltages: [0.019388, 0.0022522, 0.0015414, 0.67973, 0.13444, 0.79822, 0.62984, 0.010764, 0.60162, 0.39934]
Predicted label: 5
Correct prediction
Energy consumption = 144.405608 pJ
sum error= 98
Actual label: 7
Output voltages: [0.22681, 0.11216, 0.038346, 0.031072, 0.010017, 0.0012133, 0.0010673, 0.79859, 0.12713, 0.12844]
Predicted label: 7
Correct prediction
Energy consumption = 156.254763 pJ
sum error= 98
Actual label: 1
Output voltages: [0.0030269, 0.79851, 0.13798, 0.10368, 0.050863, 0.0015161, 0.59504, 0.0047585, 0.081017, 0.29577]
Predicted label: 1
Correct prediction
Energy consumption = 160.103731 pJ
sum error= 98
Actual label: 8
Output voltages: [0.064712, 0.050067, 0.046664, 0.67513, 0.0015473, 0.031944, 0.0059719, 0.0031001, 0.79874, 0.28737]
Predicted label: 8
Correct prediction
Energy consumption = 154.522943 pJ
sum error= 98
Actual label: 8
Output voltages: [0.13615, 0.042202, 0.045756, 0.79866, 0.034557, 0.0035384, 0.084193, 0.1111, 0.69791, 0.042855]
Predicted label: 3
Wrong prediction!
Energy consumption = 151.241317 pJ
sum error= 99
Actual label: 5
Output voltages: [0.088165, 0.0014021, 0.0032163, 0.67196, 0.010541, 0.79866, 0.33077, 0.0074717, 0.69289, 0.041957]
Predicted label: 5
Correct prediction
Energy consumption = 137.558472 pJ
sum error= 99
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 188 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 188 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 188 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.67552, 0.028254, 0.21795, 0.0010722, 0.061632, 0.0012013, 0.79683, 0.0043465, 0.35693, 0.017212]
Predicted label: 6
Correct prediction
Energy consumption = 178.223344 pJ
sum error= 99
Actual label: 9
Output voltages: [0.32435, 0.012274, 0.0091883, 0.027459, 0.058656, 0.0059519, 0.0010857, 0.018531, 0.52783, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 155.006584 pJ
sum error= 99
Actual label: 8
Output voltages: [0.042814, 0.0024762, 0.34527, 0.53029, 0.0019096, 0.26475, 0.016441, 0.036726, 0.79874, 0.3571]
Predicted label: 8
Correct prediction
Energy consumption = 142.658719 pJ
sum error= 99
Actual label: 7
Output voltages: [0.3147, 0.11125, 0.027358, 0.15472, 0.17025, 0.029707, 0.0020226, 0.78485, 0.0013425, 0.74388]
Predicted label: 7
Correct prediction
Energy consumption = 156.014843 pJ
sum error= 99
Actual label: 1
Output voltages: [0.030902, 0.79851, 0.026203, 0.047654, 0.031692, 0.0015511, 0.7228, 0.0012626, 0.30175, 0.14546]
Predicted label: 1
Correct prediction
Energy consumption = 165.864661 pJ
sum error= 99
Actual label: 1
Output voltages: [0.136, 0.79875, 0.16129, 0.010207, 0.37781, 0.0027286, 0.6978, 0.0019943, 0.16379, 0.022922]
Predicted label: 1
Correct prediction
Energy consumption = 140.103828 pJ
sum error= 99
Actual label: 6
Output voltages: [0.16415, 0.34544, 0.038146, 0.10528, 0.011, 0.29961, 0.79875, 0.016134, 0.7142, 0.0020011]
Predicted label: 6
Correct prediction
Energy consumption = 143.758329 pJ
sum error= 99
Actual label: 7
Output voltages: [0.15427, 0.038913, 0.028824, 0.0060036, 0.014518, 0.01037, 0.0010844, 0.79872, 0.30049, 0.48598]
Predicted label: 7
Correct prediction
Energy consumption = 158.345546 pJ
sum error= 99
Actual label: 6
Output voltages: [0.10931, 0.045273, 0.0097946, 0.038289, 0.074031, 0.48786, 0.7987, 0.015921, 0.65097, 0.0024658]
Predicted label: 6
Correct prediction
Energy consumption = 150.368002 pJ
sum error= 99
Actual label: 3
Output voltages: [0.38395, 0.021828, 0.099295, 0.79859, 0.019645, 0.016693, 0.015291, 0.032804, 0.69606, 0.015235]
Predicted label: 3
Correct prediction
Energy consumption = 147.294159 pJ
sum error= 99
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 189 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 189 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 189 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.65041, 0.17257, 0.79877, 0.15031, 0.04084, 0.0012235, 0.32514, 0.035557, 0.45044, 0.044287]
Predicted label: 2
Correct prediction
Energy consumption = 166.310493 pJ
sum error= 99
Actual label: 2
Output voltages: [0.38659, 0.044483, 0.79871, 0.064525, 0.039618, 0.0012244, 0.20144, 0.022258, 0.2711, 0.026454]
Predicted label: 2
Correct prediction
Energy consumption = 135.156873 pJ
sum error= 99
Actual label: 0
Output voltages: [0.79876, 0.28661, 0.043685, 0.011375, 0.0064356, 0.007232, 0.39729, 0.0061815, 0.058042, 0.44323]
Predicted label: 0
Correct prediction
Energy consumption = 146.911430 pJ
sum error= 99
Actual label: 8
Output voltages: [0.031627, 0.011391, 0.64557, 0.26638, 0.016167, 0.0016438, 0.15616, 0.0071014, 0.79874, 0.093109]
Predicted label: 8
Correct prediction
Energy consumption = 150.862266 pJ
sum error= 99
Actual label: 9
Output voltages: [0.022708, 0.015963, 0.01038, 0.031368, 0.0085248, 0.041544, 0.0056576, 0.016911, 0.7843, 0.76783]
Predicted label: 8
Wrong prediction!
Energy consumption = 158.440096 pJ
sum error= 100
Actual label: 2
Output voltages: [0.50361, 0.027698, 0.79855, 0.13793, 0.026181, 0.003615, 0.076691, 0.040194, 0.37167, 0.014697]
Predicted label: 2
Correct prediction
Energy consumption = 143.102753 pJ
sum error= 100
Actual label: 5
Output voltages: [0.022458, 0.0010662, 0.0094712, 0.1417, 0.020141, 0.79374, 0.20897, 0.022858, 0.77674, 0.26705]
Predicted label: 5
Correct prediction
Energy consumption = 140.772748 pJ
sum error= 100
Actual label: 1
Output voltages: [0.0026925, 0.7985, 0.041459, 0.030287, 0.28301, 0.040019, 0.28536, 0.0084541, 0.37635, 0.058124]
Predicted label: 1
Correct prediction
Energy consumption = 170.884333 pJ
sum error= 100
Actual label: 0
Output voltages: [0.79868, 0.17359, 0.0073672, 0.010972, 0.010059, 0.042726, 0.50822, 0.010493, 0.052918, 0.051627]
Predicted label: 0
Correct prediction
Energy consumption = 153.376181 pJ
sum error= 100
Actual label: 8
Output voltages: [0.0090538, 0.0061678, 0.03344, 0.78516, 0.024643, 0.0088622, 0.0033096, 0.028423, 0.79828, 0.13115]
Predicted label: 8
Correct prediction
Energy consumption = 155.218127 pJ
sum error= 100
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 190 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 190 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 190 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.040527, 0.79303, 0.040998, 0.030087, 0.25962, 0.0016902, 0.42646, 0.0012135, 0.063803, 0.0019237]
Predicted label: 1
Correct prediction
Energy consumption = 172.134460 pJ
sum error= 100
Actual label: 9
Output voltages: [0.0094274, 0.0059725, 0.033724, 0.0015787, 0.78529, 0.37036, 0.026801, 0.028894, 0.50932, 0.37967]
Predicted label: 4
Wrong prediction!
Energy consumption = 157.697166 pJ
sum error= 101
Actual label: 5
Output voltages: [0.024938, 0.0017613, 0.0040564, 0.42659, 0.022639, 0.79869, 0.30585, 0.043225, 0.67217, 0.35221]
Predicted label: 5
Correct prediction
Energy consumption = 150.024762 pJ
sum error= 101
Actual label: 7
Output voltages: [0.0055864, 0.070058, 0.77079, 0.35694, 0.040432, 0.0014013, 0.014319, 0.78258, 0.44448, 0.0084677]
Predicted label: 7
Correct prediction
Energy consumption = 142.711325 pJ
sum error= 101
Actual label: 9
Output voltages: [0.23096, 0.013865, 0.039361, 0.0051124, 0.55652, 0.0095023, 0.0030927, 0.015685, 0.19273, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 155.852648 pJ
sum error= 101
Actual label: 6
Output voltages: [0.41771, 0.033341, 0.035013, 0.015413, 0.44019, 0.41738, 0.79879, 0.001729, 0.49174, 0.0095441]
Predicted label: 6
Correct prediction
Energy consumption = 153.973899 pJ
sum error= 101
Actual label: 9
Output voltages: [0.11189, 0.026765, 0.027964, 0.026872, 0.081431, 0.025591, 0.0043114, 0.010399, 0.44548, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 153.019493 pJ
sum error= 101
Actual label: 0
Output voltages: [0.79879, 0.029371, 0.33216, 0.059296, 0.057102, 0.0040715, 0.064439, 0.040317, 0.25144, 0.067943]
Predicted label: 0
Correct prediction
Energy consumption = 159.662121 pJ
sum error= 101
Actual label: 6
Output voltages: [0.34115, 0.020783, 0.18556, 0.0011508, 0.36635, 0.033589, 0.79867, 0.019776, 0.10296, 0.0039295]
Predicted label: 6
Correct prediction
Energy consumption = 147.566533 pJ
sum error= 101
Actual label: 1
Output voltages: [0.063656, 0.76052, 0.053854, 0.7223, 0.031732, 0.0011814, 0.0033199, 0.043416, 0.73902, 0.057973]
Predicted label: 1
Correct prediction
Energy consumption = 162.963892 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 191 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 191 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 191 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.035739, 0.0010693, 0.0060525, 0.15984, 0.016489, 0.79801, 0.26413, 0.046817, 0.75407, 0.085193]
Predicted label: 5
Correct prediction
Energy consumption = 164.915307 pJ
sum error= 101
Actual label: 5
Output voltages: [0.75474, 0.0016051, 0.011839, 0.16623, 0.0079085, 0.78776, 0.75881, 0.017644, 0.38514, 0.032022]
Predicted label: 5
Correct prediction
Energy consumption = 148.735862 pJ
sum error= 101
Actual label: 8
Output voltages: [0.023126, 0.060596, 0.022923, 0.011054, 0.024202, 0.45783, 0.0082427, 0.058556, 0.79868, 0.025116]
Predicted label: 8
Correct prediction
Energy consumption = 156.101554 pJ
sum error= 101
Actual label: 3
Output voltages: [0.52072, 0.0099601, 0.023558, 0.79867, 0.0038299, 0.010506, 0.027397, 0.061894, 0.56185, 0.063222]
Predicted label: 3
Correct prediction
Energy consumption = 151.795242 pJ
sum error= 101
Actual label: 8
Output voltages: [0.013904, 0.023655, 0.27778, 0.14292, 0.012506, 0.31739, 0.029337, 0.017743, 0.79863, 0.026319]
Predicted label: 8
Correct prediction
Energy consumption = 147.166236 pJ
sum error= 101
Actual label: 2
Output voltages: [0.15576, 0.088221, 0.79875, 0.25102, 0.013806, 0.0013777, 0.22425, 0.050525, 0.49703, 0.18044]
Predicted label: 2
Correct prediction
Energy consumption = 149.582823 pJ
sum error= 101
Actual label: 6
Output voltages: [0.20332, 0.022068, 0.030285, 0.0026917, 0.20202, 0.10948, 0.79872, 0.012011, 0.78267, 0.002259]
Predicted label: 6
Correct prediction
Energy consumption = 149.287239 pJ
sum error= 101
Actual label: 5
Output voltages: [0.030914, 0.001108, 0.011715, 0.32233, 0.020084, 0.79813, 0.042493, 0.040975, 0.79661, 0.01247]
Predicted label: 5
Correct prediction
Energy consumption = 140.434151 pJ
sum error= 101
Actual label: 0
Output voltages: [0.798, 0.046548, 0.16564, 0.020126, 0.019297, 0.0023091, 0.67957, 0.036011, 0.17611, 0.13762]
Predicted label: 0
Correct prediction
Energy consumption = 160.219310 pJ
sum error= 101
Actual label: 7
Output voltages: [0.038418, 0.056548, 0.14705, 0.17868, 0.0024996, 0.0038934, 0.0011119, 0.79871, 0.62286, 0.3596]
Predicted label: 7
Correct prediction
Energy consumption = 152.072693 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 192 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 192 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 192 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.01925, 0.026303, 0.094901, 0.13654, 0.79876, 0.0010921, 0.012636, 0.25816, 0.0050497, 0.22521]
Predicted label: 4
Correct prediction
Energy consumption = 165.935926 pJ
sum error= 101
Actual label: 6
Output voltages: [0.043032, 0.063884, 0.20181, 0.0012749, 0.33805, 0.2512, 0.79876, 0.0014603, 0.71356, 0.0043457]
Predicted label: 6
Correct prediction
Energy consumption = 147.480161 pJ
sum error= 101
Actual label: 1
Output voltages: [0.037317, 0.79845, 0.010116, 0.060223, 0.011132, 0.0040216, 0.72465, 0.0011727, 0.15594, 0.029039]
Predicted label: 1
Correct prediction
Energy consumption = 160.337865 pJ
sum error= 101
Actual label: 3
Output voltages: [0.35502, 0.05627, 0.035621, 0.79866, 0.013777, 0.0020938, 0.045229, 0.020905, 0.70476, 0.030803]
Predicted label: 3
Correct prediction
Energy consumption = 146.053461 pJ
sum error= 101
Actual label: 4
Output voltages: [0.0057246, 0.0011953, 0.35451, 0.0051962, 0.7986, 0.0050564, 0.056689, 0.0064614, 0.23879, 0.54077]
Predicted label: 4
Correct prediction
Energy consumption = 153.308315 pJ
sum error= 101
Actual label: 7
Output voltages: [0.15189, 0.025188, 0.069646, 0.050908, 0.015751, 0.0011583, 0.0010668, 0.79861, 0.088393, 0.205]
Predicted label: 7
Correct prediction
Energy consumption = 157.987125 pJ
sum error= 101
Actual label: 3
Output voltages: [0.047781, 0.0066109, 0.070957, 0.79877, 0.049264, 0.041419, 0.043013, 0.099941, 0.68128, 0.04514]
Predicted label: 3
Correct prediction
Energy consumption = 136.453591 pJ
sum error= 101
Actual label: 2
Output voltages: [0.31725, 0.078111, 0.79878, 0.043329, 0.0043507, 0.0012933, 0.1784, 0.049848, 0.73641, 0.020707]
Predicted label: 2
Correct prediction
Energy consumption = 146.526810 pJ
sum error= 101
Actual label: 3
Output voltages: [0.221, 0.021219, 0.074583, 0.79863, 0.013755, 0.054497, 0.0067529, 0.12682, 0.67392, 0.061492]
Predicted label: 3
Correct prediction
Energy consumption = 136.109225 pJ
sum error= 101
Actual label: 4
Output voltages: [0.04238, 0.012484, 0.049526, 0.01252, 0.79876, 0.0010711, 0.050989, 0.19515, 0.021158, 0.28322]
Predicted label: 4
Correct prediction
Energy consumption = 154.523450 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 193 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 193 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 193 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.22623, 0.016824, 0.79872, 0.32953, 0.37996, 0.0010745, 0.030084, 0.19158, 0.35637, 0.023817]
Predicted label: 2
Correct prediction
Energy consumption = 159.507044 pJ
sum error= 101
Actual label: 5
Output voltages: [0.051591, 0.0011226, 0.011081, 0.35436, 0.048637, 0.79874, 0.23906, 0.056096, 0.77053, 0.087672]
Predicted label: 5
Correct prediction
Energy consumption = 151.440369 pJ
sum error= 101
Actual label: 2
Output voltages: [0.34731, 0.028261, 0.79875, 0.33207, 0.022932, 0.0011208, 0.042178, 0.50146, 0.44532, 0.025855]
Predicted label: 2
Correct prediction
Energy consumption = 148.197417 pJ
sum error= 101
Actual label: 7
Output voltages: [0.23725, 0.0041991, 0.10538, 0.51666, 0.01432, 0.0011865, 0.0010663, 0.79443, 0.46877, 0.18329]
Predicted label: 7
Correct prediction
Energy consumption = 145.317121 pJ
sum error= 101
Actual label: 1
Output voltages: [0.02345, 0.79853, 0.017462, 0.024907, 0.0087768, 0.0017223, 0.52265, 0.020963, 0.39936, 0.017173]
Predicted label: 1
Correct prediction
Energy consumption = 161.947564 pJ
sum error= 101
Actual label: 7
Output voltages: [0.28031, 0.022099, 0.04099, 0.057807, 0.0052129, 0.0068459, 0.0011609, 0.79867, 0.47432, 0.4041]
Predicted label: 7
Correct prediction
Energy consumption = 150.558134 pJ
sum error= 101
Actual label: 2
Output voltages: [0.72832, 0.0098511, 0.79879, 0.16223, 0.025643, 0.0010946, 0.047817, 0.063338, 0.50922, 0.021434]
Predicted label: 2
Correct prediction
Energy consumption = 146.333586 pJ
sum error= 101
Actual label: 6
Output voltages: [0.084545, 0.017095, 0.023535, 0.003739, 0.3565, 0.44161, 0.79878, 0.010335, 0.75957, 0.0059389]
Predicted label: 6
Correct prediction
Energy consumption = 156.029743 pJ
sum error= 101
Actual label: 4
Output voltages: [0.033779, 0.0024539, 0.25996, 0.010251, 0.79877, 0.0013457, 0.72753, 0.026137, 0.012386, 0.048433]
Predicted label: 4
Correct prediction
Energy consumption = 151.616962 pJ
sum error= 101
Actual label: 1
Output voltages: [0.015499, 0.79848, 0.035224, 0.056812, 0.022645, 0.0091551, 0.64324, 0.026687, 0.41913, 0.032247]
Predicted label: 1
Correct prediction
Energy consumption = 160.644876 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 194 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 194 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 194 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.62842, 0.0052887, 0.0011123, 0.14908, 0.030418, 0.79879, 0.36269, 0.0061283, 0.57854, 0.054735]
Predicted label: 5
Correct prediction
Energy consumption = 169.522703 pJ
sum error= 101
Actual label: 7
Output voltages: [0.045811, 0.0017013, 0.69438, 0.099672, 0.0058127, 0.0023735, 0.0017485, 0.79879, 0.22456, 0.076959]
Predicted label: 7
Correct prediction
Energy consumption = 139.169525 pJ
sum error= 101
Actual label: 8
Output voltages: [0.0018557, 0.022773, 0.17672, 0.0057242, 0.22925, 0.027574, 0.037797, 0.0087604, 0.79877, 0.066934]
Predicted label: 8
Correct prediction
Energy consumption = 154.681126 pJ
sum error= 101
Actual label: 6
Output voltages: [0.30912, 0.033304, 0.019625, 0.019683, 0.13514, 0.38131, 0.79848, 0.068835, 0.78042, 0.0031157]
Predicted label: 6
Correct prediction
Energy consumption = 150.328682 pJ
sum error= 101
Actual label: 0
Output voltages: [0.79859, 0.10698, 0.034983, 0.01346, 0.0020064, 0.0035491, 0.58332, 0.034729, 0.23385, 0.10016]
Predicted label: 0
Correct prediction
Energy consumption = 136.755286 pJ
sum error= 101
Actual label: 1
Output voltages: [0.027281, 0.79859, 0.10215, 0.16811, 0.041412, 0.0010725, 0.43508, 0.0021094, 0.34621, 0.0063103]
Predicted label: 1
Correct prediction
Energy consumption = 162.016809 pJ
sum error= 101
Actual label: 8
Output voltages: [0.014521, 0.011441, 0.056452, 0.045711, 0.010555, 0.06311, 0.016179, 0.018175, 0.79868, 0.016018]
Predicted label: 8
Correct prediction
Energy consumption = 150.660916 pJ
sum error= 101
Actual label: 2
Output voltages: [0.29854, 0.021143, 0.79863, 0.01413, 0.0088669, 0.0011365, 0.1483, 0.046705, 0.50602, 0.0045112]
Predicted label: 2
Correct prediction
Energy consumption = 138.547343 pJ
sum error= 101
Actual label: 5
Output voltages: [0.42576, 0.0015062, 0.0014646, 0.54348, 0.17539, 0.77085, 0.001097, 0.77868, 0.41859, 0.15847]
Predicted label: 7
Wrong prediction!
Energy consumption = 149.229303 pJ
sum error= 102
Actual label: 7
Output voltages: [0.31801, 0.020543, 0.4309, 0.014077, 0.0071204, 0.0011145, 0.00128, 0.79879, 0.11702, 0.02984]
Predicted label: 7
Correct prediction
Energy consumption = 146.240028 pJ
sum error= 102
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 195 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 195 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 195 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.21427, 0.015605, 0.017373, 0.049338, 0.013748, 0.010651, 0.0011069, 0.79859, 0.13753, 0.25791]
Predicted label: 7
Correct prediction
Energy consumption = 168.987625 pJ
sum error= 102
Actual label: 6
Output voltages: [0.040109, 0.019657, 0.4042, 0.0010782, 0.61528, 0.27498, 0.79871, 0.0014096, 0.49533, 0.0036301]
Predicted label: 6
Correct prediction
Energy consumption = 153.318782 pJ
sum error= 102
Actual label: 9
Output voltages: [0.15057, 0.0044827, 0.041351, 0.54535, 0.30859, 0.0060259, 0.0010848, 0.012652, 0.059515, 0.7983]
Predicted label: 9
Correct prediction
Energy consumption = 160.510609 pJ
sum error= 102
Actual label: 3
Output voltages: [0.19731, 0.023467, 0.056613, 0.79874, 0.0066155, 0.032701, 0.0086925, 0.041133, 0.71716, 0.085395]
Predicted label: 3
Correct prediction
Energy consumption = 148.985781 pJ
sum error= 102
Actual label: 5
Output voltages: [0.12654, 0.0011344, 0.0095754, 0.2385, 0.0023025, 0.79853, 0.10783, 0.02911, 0.69252, 0.055246]
Predicted label: 5
Correct prediction
Energy consumption = 146.015026 pJ
sum error= 102
Actual label: 8
Output voltages: [0.33697, 0.013213, 0.24653, 0.63585, 0.0073216, 0.0011554, 0.040035, 0.0010797, 0.79618, 0.32364]
Predicted label: 8
Correct prediction
Energy consumption = 153.761896 pJ
sum error= 102
Actual label: 4
Output voltages: [0.048001, 0.020165, 0.23782, 0.004954, 0.79873, 0.0011216, 0.34114, 0.025674, 0.015907, 0.34694]
Predicted label: 4
Correct prediction
Energy consumption = 148.642319 pJ
sum error= 102
Actual label: 2
Output voltages: [0.55726, 0.18404, 0.79876, 0.047354, 0.13274, 0.0010662, 0.23269, 0.019614, 0.27272, 0.017798]
Predicted label: 2
Correct prediction
Energy consumption = 141.429396 pJ
sum error= 102
Actual label: 4
Output voltages: [0.0064438, 0.017688, 0.19665, 0.0063659, 0.7986, 0.0028144, 0.036363, 0.1682, 0.027248, 0.12495]
Predicted label: 4
Correct prediction
Energy consumption = 158.969648 pJ
sum error= 102
Actual label: 0
Output voltages: [0.79875, 0.039529, 0.11934, 0.014957, 0.029145, 0.011046, 0.60568, 0.037228, 0.034953, 0.21424]
Predicted label: 0
Correct prediction
Energy consumption = 160.844988 pJ
sum error= 102
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 196 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 196 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 196 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.023311, 0.024583, 0.47733, 0.083096, 0.01021, 0.033198, 0.020905, 0.0043912, 0.79871, 0.17576]
Predicted label: 8
Correct prediction
Energy consumption = 164.938722 pJ
sum error= 102
Actual label: 8
Output voltages: [0.1494, 0.022561, 0.20489, 0.29002, 0.0096563, 0.017149, 0.045233, 0.0080602, 0.79879, 0.011719]
Predicted label: 8
Correct prediction
Energy consumption = 149.422149 pJ
sum error= 102
Actual label: 3
Output voltages: [0.082141, 0.0072057, 0.079438, 0.79873, 0.006748, 0.040064, 0.0045813, 0.033329, 0.7563, 0.024048]
Predicted label: 3
Correct prediction
Energy consumption = 143.598463 pJ
sum error= 102
Actual label: 4
Output voltages: [0.0069053, 0.0089628, 0.29364, 0.027838, 0.7987, 0.0012286, 0.2702, 0.21616, 0.016474, 0.29523]
Predicted label: 4
Correct prediction
Energy consumption = 157.548838 pJ
sum error= 102
Actual label: 9
Output voltages: [0.22876, 0.030283, 0.018293, 0.12243, 0.2677, 0.020928, 0.015492, 0.10218, 0.022188, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 156.620059 pJ
sum error= 102
Actual label: 2
Output voltages: [0.27532, 0.72105, 0.79879, 0.053785, 0.012894, 0.0011793, 0.041686, 0.13647, 0.025543, 0.029002]
Predicted label: 2
Correct prediction
Energy consumption = 159.810133 pJ
sum error= 102
Actual label: 7
Output voltages: [0.28661, 0.0052328, 0.031596, 0.34276, 0.0047357, 0.0044987, 0.0011461, 0.79876, 0.74817, 0.39443]
Predicted label: 7
Correct prediction
Energy consumption = 146.026480 pJ
sum error= 102
Actual label: 5
Output voltages: [0.074353, 0.0013104, 0.011455, 0.26509, 0.0059005, 0.79865, 0.12486, 0.017532, 0.70849, 0.04599]
Predicted label: 5
Correct prediction
Energy consumption = 144.348860 pJ
sum error= 102
Actual label: 8
Output voltages: [0.011978, 0.14015, 0.022328, 0.51161, 0.0024875, 0.036119, 0.037702, 0.0010758, 0.79873, 0.39247]
Predicted label: 8
Correct prediction
Energy consumption = 146.170670 pJ
sum error= 102
Actual label: 6
Output voltages: [0.47891, 0.086971, 0.11834, 0.0082555, 0.055256, 0.034709, 0.79848, 0.0011427, 0.39889, 0.0025386]
Predicted label: 6
Correct prediction
Energy consumption = 153.051210 pJ
sum error= 102
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 197 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 197 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 197 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.034745, 0.0013352, 0.0092358, 0.19162, 0.036748, 0.79871, 0.095728, 0.025354, 0.77347, 0.3399]
Predicted label: 5
Correct prediction
Energy consumption = 161.325374 pJ
sum error= 102
Actual label: 6
Output voltages: [0.022114, 0.094883, 0.27277, 0.0010711, 0.057153, 0.2114, 0.79875, 0.0021921, 0.73303, 0.011627]
Predicted label: 6
Correct prediction
Energy consumption = 144.950249 pJ
sum error= 102
Actual label: 0
Output voltages: [0.79874, 0.16431, 0.1135, 0.048835, 0.0034848, 0.0026309, 0.2904, 0.0048928, 0.27423, 0.094338]
Predicted label: 0
Correct prediction
Energy consumption = 152.083255 pJ
sum error= 102
Actual label: 8
Output voltages: [0.45766, 0.0048675, 0.36839, 0.60467, 0.0091687, 0.25624, 0.017951, 0.0029957, 0.79878, 0.054195]
Predicted label: 8
Correct prediction
Energy consumption = 148.735789 pJ
sum error= 102
Actual label: 6
Output voltages: [0.050401, 0.022389, 0.21361, 0.0082074, 0.34937, 0.092516, 0.79876, 0.0028521, 0.59742, 0.012175]
Predicted label: 6
Correct prediction
Energy consumption = 150.648283 pJ
sum error= 102
Actual label: 7
Output voltages: [0.026046, 0.086035, 0.25094, 0.015017, 0.061286, 0.0010727, 0.0011628, 0.79855, 0.1237, 0.059444]
Predicted label: 7
Correct prediction
Energy consumption = 149.054851 pJ
sum error= 102
Actual label: 3
Output voltages: [0.22677, 0.0098486, 0.28534, 0.79877, 0.04102, 0.03795, 0.013987, 0.02693, 0.4288, 0.27985]
Predicted label: 3
Correct prediction
Energy consumption = 146.562709 pJ
sum error= 102
Actual label: 6
Output voltages: [0.23675, 0.014739, 0.029376, 0.0013128, 0.3283, 0.2978, 0.79869, 0.0011413, 0.37767, 0.011082]
Predicted label: 6
Correct prediction
Energy consumption = 146.509951 pJ
sum error= 102
Actual label: 4
Output voltages: [0.0043245, 0.018632, 0.026867, 0.0075867, 0.7987, 0.0032956, 0.20507, 0.39096, 0.27822, 0.0045792]
Predicted label: 4
Correct prediction
Energy consumption = 154.791713 pJ
sum error= 102
Actual label: 9
Output voltages: [0.38339, 0.007176, 0.042802, 0.05039, 0.50375, 0.046414, 0.054955, 0.044329, 0.021886, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 151.029547 pJ
sum error= 102
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 198 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 198 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 198 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.010622, 0.0096806, 0.015621, 0.015503, 0.79862, 0.0010672, 0.042851, 0.13878, 0.029171, 0.017511]
Predicted label: 4
Correct prediction
Energy consumption = 174.910959 pJ
sum error= 102
Actual label: 6
Output voltages: [0.20031, 0.090256, 0.16186, 0.0013779, 0.047209, 0.17152, 0.79875, 0.0020303, 0.036486, 0.015205]
Predicted label: 6
Correct prediction
Energy consumption = 148.819125 pJ
sum error= 102
Actual label: 6
Output voltages: [0.045015, 0.0012176, 0.015354, 0.024665, 0.29468, 0.57615, 0.78101, 0.004796, 0.78494, 0.011062]
Predicted label: 8
Wrong prediction!
Energy consumption = 138.949896 pJ
sum error= 103
Actual label: 3
Output voltages: [0.23006, 0.018591, 0.36797, 0.79878, 0.018551, 0.0010852, 0.012293, 0.0022508, 0.57526, 0.028097]
Predicted label: 3
Correct prediction
Energy consumption = 150.051956 pJ
sum error= 103
Actual label: 2
Output voltages: [0.78544, 0.27421, 0.7722, 0.028609, 0.0012201, 0.014742, 0.10358, 0.0027647, 0.45485, 0.018703]
Predicted label: 0
Wrong prediction!
Energy consumption = 145.232258 pJ
sum error= 104
Actual label: 4
Output voltages: [0.0032925, 0.011217, 0.014082, 0.0040362, 0.79876, 0.0011301, 0.30585, 0.12608, 0.033898, 0.012422]
Predicted label: 4
Correct prediction
Energy consumption = 157.010607 pJ
sum error= 104
Actual label: 1
Output voltages: [0.022855, 0.79843, 0.29799, 0.054307, 0.047642, 0.0025859, 0.59602, 0.0046831, 0.066548, 0.12872]
Predicted label: 1
Correct prediction
Energy consumption = 157.010119 pJ
sum error= 104
Actual label: 0
Output voltages: [0.79879, 0.034257, 0.035267, 0.008162, 0.0068242, 0.0024142, 0.50032, 0.027652, 0.10431, 0.16368]
Predicted label: 0
Correct prediction
Energy consumption = 144.654989 pJ
sum error= 104
Actual label: 1
Output voltages: [0.042341, 0.79864, 0.51515, 0.024376, 0.076889, 0.0010719, 0.50262, 0.0010836, 0.013209, 0.058299]
Predicted label: 1
Correct prediction
Energy consumption = 161.692281 pJ
sum error= 104
Actual label: 4
Output voltages: [0.025395, 0.27539, 0.11197, 0.027368, 0.79876, 0.0011042, 0.42396, 0.012074, 0.0014723, 0.071542]
Predicted label: 4
Correct prediction
Energy consumption = 150.023719 pJ
sum error= 104
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 199 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 199 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 199 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.39248, 0.042843, 0.062003, 0.0071926, 0.40363, 0.39353, 0.79879, 0.0037846, 0.28119, 0.0023178]
Predicted label: 6
Correct prediction
Energy consumption = 166.551308 pJ
sum error= 104
Actual label: 2
Output voltages: [0.61531, 0.031647, 0.79879, 0.14123, 0.0046747, 0.0011369, 0.0745, 0.04936, 0.50049, 0.021429]
Predicted label: 2
Correct prediction
Energy consumption = 151.084034 pJ
sum error= 104
Actual label: 9
Output voltages: [0.072649, 0.0075031, 0.030809, 0.019397, 0.022225, 0.0081809, 0.0018317, 0.030751, 0.79457, 0.78609]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.869056 pJ
sum error= 105
Actual label: 1
Output voltages: [0.25966, 0.79753, 0.29296, 0.010793, 0.0080643, 0.0010875, 0.27908, 0.0023601, 0.35908, 0.018023]
Predicted label: 1
Correct prediction
Energy consumption = 143.228430 pJ
sum error= 105
Actual label: 1
Output voltages: [0.012385, 0.7985, 0.063819, 0.020723, 0.083689, 0.0085408, 0.35453, 0.0064971, 0.24285, 0.074777]
Predicted label: 1
Correct prediction
Energy consumption = 160.337172 pJ
sum error= 105
Actual label: 0
Output voltages: [0.79863, 0.31228, 0.066187, 0.17465, 0.0063493, 0.080183, 0.21672, 0.0031386, 0.33926, 0.093021]
Predicted label: 0
Correct prediction
Energy consumption = 155.173101 pJ
sum error= 105
Actual label: 6
Output voltages: [0.10233, 0.013798, 0.02226, 0.011654, 0.35283, 0.57884, 0.79879, 0.0011263, 0.77647, 0.010947]
Predicted label: 6
Correct prediction
Energy consumption = 145.436439 pJ
sum error= 105
Actual label: 3
Output voltages: [0.35522, 0.028579, 0.025455, 0.79865, 0.0092954, 0.0099211, 0.021556, 0.0049938, 0.45638, 0.067801]
Predicted label: 3
Correct prediction
Energy consumption = 145.771334 pJ
sum error= 105
Actual label: 9
Output voltages: [0.36761, 0.0091022, 0.022626, 0.15815, 0.31757, 0.041194, 0.018365, 0.0067091, 0.1576, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 155.912444 pJ
sum error= 105
Actual label: 5
Output voltages: [0.045534, 0.0010666, 0.025275, 0.34433, 0.0037998, 0.79673, 0.0087587, 0.025921, 0.79615, 0.060953]
Predicted label: 5
Correct prediction
Energy consumption = 144.192618 pJ
sum error= 105
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 200 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 200 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 200 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.050312, 0.0086403, 0.15784, 0.0044115, 0.37741, 0.42622, 0.79879, 0.0027642, 0.60864, 0.0082251]
Predicted label: 6
Correct prediction
Energy consumption = 164.387822 pJ
sum error= 105
Actual label: 5
Output voltages: [0.021609, 0.0026409, 0.024747, 0.074617, 0.0054943, 0.79714, 0.031576, 0.023463, 0.79847, 0.030942]
Predicted label: 8
Wrong prediction!
Energy consumption = 145.058988 pJ
sum error= 106
Actual label: 6
Output voltages: [0.28618, 0.012256, 0.10484, 0.010662, 0.37977, 0.36007, 0.79878, 0.0013408, 0.58988, 0.01161]
Predicted label: 6
Correct prediction
Energy consumption = 148.924895 pJ
sum error= 106
Actual label: 5
Output voltages: [0.016328, 0.0011046, 0.0010748, 0.17856, 0.048786, 0.79811, 0.36288, 0.015403, 0.58648, 0.040514]
Predicted label: 5
Correct prediction
Energy consumption = 149.621306 pJ
sum error= 106
Actual label: 8
Output voltages: [0.030608, 0.039636, 0.17871, 0.48719, 0.001497, 0.088359, 0.0049206, 0.046154, 0.79877, 0.049194]
Predicted label: 8
Correct prediction
Energy consumption = 149.877995 pJ
sum error= 106
Actual label: 4
Output voltages: [0.022108, 0.0069975, 0.22836, 0.0027322, 0.79864, 0.0013891, 0.40935, 0.043784, 0.021004, 0.026413]
Predicted label: 4
Correct prediction
Energy consumption = 156.345393 pJ
sum error= 106
Actual label: 6
Output voltages: [0.046346, 0.067732, 0.20887, 0.005492, 0.049996, 0.044041, 0.79879, 0.0017597, 0.58282, 0.011259]
Predicted label: 6
Correct prediction
Energy consumption = 148.853091 pJ
sum error= 106
Actual label: 4
Output voltages: [0.018854, 0.01958, 0.1328, 0.00621, 0.79855, 0.0071105, 0.10274, 0.041925, 0.047648, 0.10621]
Predicted label: 4
Correct prediction
Energy consumption = 154.982794 pJ
sum error= 106
Actual label: 3
Output voltages: [0.12982, 0.034066, 0.049914, 0.79863, 0.032076, 0.0059626, 0.012994, 0.020415, 0.47928, 0.045654]
Predicted label: 3
Correct prediction
Energy consumption = 141.901923 pJ
sum error= 106
Actual label: 9
Output voltages: [0.42614, 0.0042365, 0.028508, 0.011496, 0.042972, 0.0047538, 0.033571, 0.033515, 0.49818, 0.79381]
Predicted label: 9
Correct prediction
Energy consumption = 144.101317 pJ
sum error= 106
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 201 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 201 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 201 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.042503, 0.79865, 0.0396, 0.22143, 0.1279, 0.018012, 0.70199, 0.001116, 0.0068151, 0.090734]
Predicted label: 1
Correct prediction
Energy consumption = 177.407179 pJ
sum error= 106
Actual label: 3
Output voltages: [0.054052, 0.045505, 0.044397, 0.79859, 0.024481, 0.0033334, 0.010211, 0.027003, 0.36352, 0.20031]
Predicted label: 3
Correct prediction
Energy consumption = 155.742062 pJ
sum error= 106
Actual label: 4
Output voltages: [0.001221, 0.023651, 0.28998, 0.002374, 0.79879, 0.0016832, 0.1478, 0.27788, 0.023289, 0.12284]
Predicted label: 4
Correct prediction
Energy consumption = 158.614095 pJ
sum error= 106
Actual label: 1
Output voltages: [0.032345, 0.79856, 0.022079, 0.27142, 0.046484, 0.0091441, 0.24978, 0.0013294, 0.39379, 0.042397]
Predicted label: 1
Correct prediction
Energy consumption = 158.850355 pJ
sum error= 106
Actual label: 9
Output voltages: [0.28487, 0.018645, 0.034432, 0.24829, 0.50368, 0.021252, 0.022124, 0.0031651, 0.049116, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 154.916816 pJ
sum error= 106
Actual label: 1
Output voltages: [0.03191, 0.79864, 0.22606, 0.34418, 0.095676, 0.0037336, 0.40525, 0.0011297, 0.09658, 0.41347]
Predicted label: 1
Correct prediction
Energy consumption = 159.573335 pJ
sum error= 106
Actual label: 7
Output voltages: [0.1624, 0.001591, 0.7957, 0.22258, 0.0028676, 0.0011197, 0.0032329, 0.75018, 0.77179, 0.012817]
Predicted label: 2
Wrong prediction!
Energy consumption = 143.816029 pJ
sum error= 107
Actual label: 1
Output voltages: [0.045656, 0.79871, 0.0048983, 0.050644, 0.29178, 0.0014967, 0.017787, 0.026797, 0.4992, 0.052426]
Predicted label: 1
Correct prediction
Energy consumption = 165.329415 pJ
sum error= 107
Actual label: 1
Output voltages: [0.47768, 0.58148, 0.26344, 0.086018, 0.0024125, 0.0011255, 0.012995, 0.72421, 0.76691, 0.0015569]
Predicted label: 8
Wrong prediction!
Energy consumption = 154.868795 pJ
sum error= 108
Actual label: 9
Output voltages: [0.41409, 0.0090956, 0.030734, 0.021955, 0.31087, 0.0064782, 0.0012274, 0.019856, 0.47995, 0.79816]
Predicted label: 9
Correct prediction
Energy consumption = 149.631281 pJ
sum error= 108
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 202 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 202 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 202 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.087481, 0.0019363, 0.17522, 0.79874, 0.047544, 0.24095, 0.023732, 0.016461, 0.45037, 0.039343]
Predicted label: 3
Correct prediction
Energy consumption = 162.214565 pJ
sum error= 108
Actual label: 5
Output voltages: [0.027992, 0.0010666, 0.0025275, 0.29843, 0.10296, 0.79398, 0.09266, 0.011345, 0.77404, 0.25411]
Predicted label: 5
Correct prediction
Energy consumption = 142.234981 pJ
sum error= 108
Actual label: 4
Output voltages: [0.0023053, 0.0091913, 0.32447, 0.026543, 0.79866, 0.0026907, 0.24026, 0.041244, 0.018103, 0.040068]
Predicted label: 4
Correct prediction
Energy consumption = 160.758331 pJ
sum error= 108
Actual label: 0
Output voltages: [0.79877, 0.18878, 0.10011, 0.027129, 0.0010846, 0.04847, 0.39165, 0.0035803, 0.24102, 0.049564]
Predicted label: 0
Correct prediction
Energy consumption = 158.406741 pJ
sum error= 108
Actual label: 7
Output voltages: [0.42291, 0.42328, 0.015243, 0.0045786, 0.0060277, 0.0021114, 0.0065415, 0.79749, 0.289, 0.46485]
Predicted label: 7
Correct prediction
Energy consumption = 163.545035 pJ
sum error= 108
Actual label: 3
Output voltages: [0.40103, 0.0053886, 0.10459, 0.79872, 0.0018249, 0.020894, 0.14606, 0.0086515, 0.57942, 0.0085741]
Predicted label: 3
Correct prediction
Energy consumption = 156.316805 pJ
sum error= 108
Actual label: 6
Output voltages: [0.050405, 0.019049, 0.23972, 0.0019307, 0.23354, 0.22458, 0.79872, 0.0051461, 0.67573, 0.0045192]
Predicted label: 6
Correct prediction
Energy consumption = 142.938709 pJ
sum error= 108
Actual label: 1
Output voltages: [0.019067, 0.79863, 0.0010752, 0.10873, 0.012464, 0.3029, 0.53279, 0.0081916, 0.23801, 0.037621]
Predicted label: 1
Correct prediction
Energy consumption = 159.104922 pJ
sum error= 108
Actual label: 7
Output voltages: [0.039132, 0.46011, 0.2466, 0.042178, 0.0093295, 0.0025986, 0.0011932, 0.79851, 0.45289, 0.006233]
Predicted label: 7
Correct prediction
Energy consumption = 145.518708 pJ
sum error= 108
Actual label: 5
Output voltages: [0.11017, 0.0044137, 0.0010762, 0.074791, 0.004752, 0.79214, 0.27687, 0.30301, 0.4963, 0.043093]
Predicted label: 5
Correct prediction
Energy consumption = 160.348503 pJ
sum error= 108
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 203 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 203 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 203 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.0025851, 0.0011105, 0.0035151, 0.16148, 0.29287, 0.79677, 0.56439, 0.0088898, 0.76531, 0.087031]
Predicted label: 5
Correct prediction
Energy consumption = 160.299516 pJ
sum error= 108
Actual label: 3
Output voltages: [0.069213, 0.012539, 0.43789, 0.79877, 0.036586, 0.0057474, 0.031799, 0.035485, 0.76291, 0.15967]
Predicted label: 3
Correct prediction
Energy consumption = 140.626773 pJ
sum error= 108
Actual label: 3
Output voltages: [0.21368, 0.017456, 0.049029, 0.79862, 0.018533, 0.013823, 0.019086, 0.047686, 0.51112, 0.095203]
Predicted label: 3
Correct prediction
Energy consumption = 132.369027 pJ
sum error= 108
Actual label: 0
Output voltages: [0.79848, 0.019015, 0.36712, 0.011705, 0.027791, 0.0010735, 0.033834, 0.047157, 0.47529, 0.24734]
Predicted label: 0
Correct prediction
Energy consumption = 151.248876 pJ
sum error= 108
Actual label: 1
Output voltages: [0.012044, 0.79846, 0.0040324, 0.61753, 0.013439, 0.10886, 0.098157, 0.037777, 0.39973, 0.29181]
Predicted label: 1
Correct prediction
Energy consumption = 169.088954 pJ
sum error= 108
Actual label: 5
Output voltages: [0.02965, 0.0032945, 0.020682, 0.79818, 0.25704, 0.78934, 0.048903, 0.026818, 0.17825, 0.010632]
Predicted label: 3
Wrong prediction!
Energy consumption = 148.109869 pJ
sum error= 109
Actual label: 7
Output voltages: [0.15715, 0.031793, 0.022108, 0.026301, 0.018528, 0.0059712, 0.0010666, 0.79866, 0.042029, 0.59389]
Predicted label: 7
Correct prediction
Energy consumption = 154.853342 pJ
sum error= 109
Actual label: 5
Output voltages: [0.41131, 0.0011834, 0.010144, 0.32943, 0.0064419, 0.79701, 0.25176, 0.043414, 0.74574, 0.043226]
Predicted label: 5
Correct prediction
Energy consumption = 143.664246 pJ
sum error= 109
Actual label: 8
Output voltages: [0.015861, 0.65318, 0.051715, 0.29024, 0.0039839, 0.0085553, 0.044304, 0.0026529, 0.79877, 0.26344]
Predicted label: 8
Correct prediction
Energy consumption = 152.800741 pJ
sum error= 109
Actual label: 6
Output voltages: [0.058202, 0.26237, 0.43973, 0.0026967, 0.020859, 0.026669, 0.79879, 0.0017076, 0.68866, 0.010239]
Predicted label: 6
Correct prediction
Energy consumption = 149.328760 pJ
sum error= 109
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 204 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 204 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 204 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.39922, 0.0012878, 0.0010909, 0.28588, 0.046504, 0.79865, 0.4844, 0.001066, 0.75097, 0.0019961]
Predicted label: 5
Correct prediction
Energy consumption = 156.815660 pJ
sum error= 109
Actual label: 1
Output voltages: [0.081659, 0.79848, 0.21686, 0.040415, 0.018242, 0.0011383, 0.41591, 0.011299, 0.062102, 0.03801]
Predicted label: 1
Correct prediction
Energy consumption = 165.586676 pJ
sum error= 109
Actual label: 0
Output voltages: [0.79878, 0.12818, 0.04822, 0.025683, 0.028648, 0.004403, 0.49201, 0.013151, 0.063911, 0.59848]
Predicted label: 0
Correct prediction
Energy consumption = 161.148883 pJ
sum error= 109
Actual label: 4
Output voltages: [0.0010678, 0.12273, 0.017253, 0.0027391, 0.77541, 0.0052957, 0.29422, 0.018671, 0.66235, 0.088707]
Predicted label: 4
Correct prediction
Energy consumption = 149.963639 pJ
sum error= 109
Actual label: 2
Output voltages: [0.67262, 0.081877, 0.75271, 0.016877, 0.0012811, 0.0016662, 0.021977, 0.56648, 0.7124, 0.041471]
Predicted label: 2
Correct prediction
Energy consumption = 152.887546 pJ
sum error= 109
Actual label: 3
Output voltages: [0.48614, 0.0036667, 0.09508, 0.79869, 0.025077, 0.20923, 0.017975, 0.013886, 0.55848, 0.048311]
Predicted label: 3
Correct prediction
Energy consumption = 137.768420 pJ
sum error= 109
Actual label: 4
Output voltages: [0.011464, 0.0065072, 0.1039, 0.01553, 0.79873, 0.004287, 0.081995, 0.061198, 0.25927, 0.011261]
Predicted label: 4
Correct prediction
Energy consumption = 151.843328 pJ
sum error= 109
Actual label: 6
Output voltages: [0.35039, 0.0051418, 0.040802, 0.0013102, 0.17091, 0.30793, 0.7986, 0.0011934, 0.28567, 0.0096979]
Predicted label: 6
Correct prediction
Energy consumption = 144.674225 pJ
sum error= 109
Actual label: 7
Output voltages: [0.32381, 0.013823, 0.032863, 0.17889, 0.026344, 0.0012687, 0.0010685, 0.79866, 0.19848, 0.75787]
Predicted label: 7
Correct prediction
Energy consumption = 158.062657 pJ
sum error= 109
Actual label: 9
Output voltages: [0.39359, 0.0056164, 0.16172, 0.27606, 0.4546, 0.0014374, 0.052024, 0.0011605, 0.03303, 0.79859]
Predicted label: 9
Correct prediction
Energy consumption = 148.605626 pJ
sum error= 109
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 205 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 205 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 205 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.42161, 0.073871, 0.48282, 0.18192, 0.011689, 0.0021195, 0.026713, 0.0036107, 0.79851, 0.29169]
Predicted label: 8
Correct prediction
Energy consumption = 178.165266 pJ
sum error= 109
Actual label: 1
Output voltages: [0.03002, 0.79851, 0.19234, 0.48106, 0.30037, 0.0080776, 0.49898, 0.0046719, 0.016139, 0.025463]
Predicted label: 1
Correct prediction
Energy consumption = 161.157661 pJ
sum error= 109
Actual label: 8
Output voltages: [0.047282, 0.0071026, 0.080133, 0.0020096, 0.75694, 0.01013, 0.20161, 0.0013334, 0.78941, 0.0067183]
Predicted label: 8
Correct prediction
Energy consumption = 138.941153 pJ
sum error= 109
Actual label: 4
Output voltages: [0.021513, 0.0037398, 0.041006, 0.030219, 0.69562, 0.0028953, 0.0043958, 0.035162, 0.30571, 0.69529]
Predicted label: 4
Correct prediction
Energy consumption = 143.652954 pJ
sum error= 109
Actual label: 9
Output voltages: [0.50023, 0.013488, 0.027301, 0.056208, 0.10482, 0.024461, 0.0015839, 0.03033, 0.43821, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 142.156896 pJ
sum error= 109
Actual label: 2
Output voltages: [0.38086, 0.01708, 0.79874, 0.028806, 0.013444, 0.0011277, 0.071028, 0.041969, 0.47289, 0.020351]
Predicted label: 2
Correct prediction
Energy consumption = 147.605693 pJ
sum error= 109
Actual label: 8
Output voltages: [0.12808, 0.018585, 0.11583, 0.51141, 0.0042721, 0.0064794, 0.0108, 0.0010665, 0.79876, 0.27315]
Predicted label: 8
Correct prediction
Energy consumption = 144.610521 pJ
sum error= 109
Actual label: 6
Output voltages: [0.071716, 0.025896, 0.1738, 0.0027079, 0.39568, 0.33663, 0.79874, 0.0045408, 0.22458, 0.0059763]
Predicted label: 6
Correct prediction
Energy consumption = 152.027773 pJ
sum error= 109
Actual label: 2
Output voltages: [0.66332, 0.09227, 0.79873, 0.016787, 0.0073027, 0.0012705, 0.04331, 0.44649, 0.2127, 0.021995]
Predicted label: 2
Correct prediction
Energy consumption = 144.725698 pJ
sum error= 109
Actual label: 7
Output voltages: [0.18838, 0.63153, 0.026672, 0.37366, 0.0039767, 0.0011708, 0.0027918, 0.79825, 0.018441, 0.45877]
Predicted label: 7
Correct prediction
Energy consumption = 153.624269 pJ
sum error= 109
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 206 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 206 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 206 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79845, 0.053293, 0.0368, 0.021782, 0.02617, 0.011783, 0.77116, 0.052065, 0.1468, 0.047688]
Predicted label: 0
Correct prediction
Energy consumption = 168.489891 pJ
sum error= 109
Actual label: 0
Output voltages: [0.79878, 0.052785, 0.035345, 0.062084, 0.0075483, 0.004015, 0.69365, 0.031846, 0.33893, 0.1526]
Predicted label: 0
Correct prediction
Energy consumption = 150.903945 pJ
sum error= 109
Actual label: 6
Output voltages: [0.032975, 0.13292, 0.41033, 0.001542, 0.28009, 0.17963, 0.79863, 0.0027088, 0.30184, 0.018831]
Predicted label: 6
Correct prediction
Energy consumption = 141.413447 pJ
sum error= 109
Actual label: 7
Output voltages: [0.020663, 0.30865, 0.7929, 0.052414, 0.0063744, 0.0011341, 0.016107, 0.79243, 0.62558, 0.0018626]
Predicted label: 2
Wrong prediction!
Energy consumption = 140.385742 pJ
sum error= 110
Actual label: 5
Output voltages: [0.018145, 0.0010686, 0.0028705, 0.30616, 0.046432, 0.79878, 0.25369, 0.016258, 0.73264, 0.015641]
Predicted label: 5
Correct prediction
Energy consumption = 149.609894 pJ
sum error= 110
Actual label: 8
Output voltages: [0.025898, 0.011482, 0.050243, 0.25926, 0.011246, 0.05284, 0.019693, 0.0010739, 0.79852, 0.6699]
Predicted label: 8
Correct prediction
Energy consumption = 147.991774 pJ
sum error= 110
Actual label: 6
Output voltages: [0.3678, 0.028597, 0.030907, 0.010019, 0.44008, 0.63192, 0.79873, 0.0079336, 0.74638, 0.0013186]
Predicted label: 6
Correct prediction
Energy consumption = 150.662368 pJ
sum error= 110
Actual label: 0
Output voltages: [0.79868, 0.039715, 0.061076, 0.049023, 0.035525, 0.0061974, 0.50208, 0.032368, 0.3215, 0.033893]
Predicted label: 0
Correct prediction
Energy consumption = 150.454170 pJ
sum error= 110
Actual label: 9
Output voltages: [0.050514, 0.0011402, 0.063229, 0.010358, 0.75693, 0.36232, 0.039639, 0.014961, 0.18793, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 158.032554 pJ
sum error= 110
Actual label: 3
Output voltages: [0.47855, 0.036309, 0.18373, 0.79871, 0.032782, 0.021949, 0.11321, 0.013842, 0.32507, 0.032601]
Predicted label: 3
Correct prediction
Energy consumption = 146.933084 pJ
sum error= 110
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 207 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 207 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 207 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.19825, 0.026593, 0.019149, 0.0033284, 0.4998, 0.0010668, 0.15104, 0.023347, 0.18778, 0.7653]
Predicted label: 9
Wrong prediction!
Energy consumption = 180.567394 pJ
sum error= 111
Actual label: 1
Output voltages: [0.039944, 0.79844, 0.017444, 0.039129, 0.02789, 0.014986, 0.031148, 0.090254, 0.0032465, 0.30883]
Predicted label: 1
Correct prediction
Energy consumption = 160.793389 pJ
sum error= 111
Actual label: 3
Output voltages: [0.19829, 0.014645, 0.29942, 0.79879, 0.036204, 0.0011824, 0.012144, 0.0033426, 0.75059, 0.021331]
Predicted label: 3
Correct prediction
Energy consumption = 146.905073 pJ
sum error= 111
Actual label: 5
Output voltages: [0.77596, 0.019427, 0.0010934, 0.55079, 0.0051486, 0.79126, 0.75923, 0.011432, 0.54248, 0.0099904]
Predicted label: 5
Correct prediction
Energy consumption = 151.375300 pJ
sum error= 111
Actual label: 4
Output voltages: [0.0059284, 0.0045384, 0.011996, 0.001814, 0.79875, 0.0048367, 0.12323, 0.21121, 0.32673, 0.023932]
Predicted label: 4
Correct prediction
Energy consumption = 148.819619 pJ
sum error= 111
Actual label: 3
Output voltages: [0.14609, 0.0066188, 0.046796, 0.79873, 0.03578, 0.0018239, 0.093424, 0.010674, 0.68115, 0.027472]
Predicted label: 3
Correct prediction
Energy consumption = 148.050374 pJ
sum error= 111
Actual label: 3
Output voltages: [0.15158, 0.018098, 0.15037, 0.79875, 0.040877, 0.0042351, 0.0056031, 0.0028608, 0.47831, 0.039043]
Predicted label: 3
Correct prediction
Energy consumption = 138.059890 pJ
sum error= 111
Actual label: 5
Output voltages: [0.045342, 0.0025245, 0.011901, 0.56606, 0.022054, 0.79831, 0.036832, 0.050115, 0.7763, 0.10001]
Predicted label: 5
Correct prediction
Energy consumption = 138.512424 pJ
sum error= 111
Actual label: 5
Output voltages: [0.23315, 0.0016834, 0.0011697, 0.37166, 0.030314, 0.79879, 0.40389, 0.0044454, 0.71905, 0.057866]
Predicted label: 5
Correct prediction
Energy consumption = 142.580824 pJ
sum error= 111
Actual label: 6
Output voltages: [0.12389, 0.11085, 0.19148, 0.013656, 0.33193, 0.28016, 0.79878, 0.011997, 0.73693, 0.0028843]
Predicted label: 6
Correct prediction
Energy consumption = 151.012878 pJ
sum error= 111
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 208 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 208 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 208 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.043718, 0.023717, 0.08877, 0.79877, 0.0056556, 0.027699, 0.0014076, 0.16478, 0.78225, 0.018263]
Predicted label: 3
Correct prediction
Energy consumption = 159.400181 pJ
sum error= 111
Actual label: 0
Output voltages: [0.79878, 0.029554, 0.036269, 0.049942, 0.027404, 0.020892, 0.43453, 0.031804, 0.18877, 0.011253]
Predicted label: 0
Correct prediction
Energy consumption = 159.964941 pJ
sum error= 111
Actual label: 2
Output voltages: [0.41034, 0.5735, 0.79864, 0.021205, 0.0085432, 0.0014508, 0.29351, 0.036636, 0.31895, 0.041512]
Predicted label: 2
Correct prediction
Energy consumption = 157.863459 pJ
sum error= 111
Actual label: 3
Output voltages: [0.52579, 0.02195, 0.15648, 0.79873, 0.012911, 0.0049789, 0.022729, 0.015335, 0.59334, 0.04087]
Predicted label: 3
Correct prediction
Energy consumption = 141.540257 pJ
sum error= 111
Actual label: 4
Output voltages: [0.008966, 0.003295, 0.18529, 0.030982, 0.79879, 0.047279, 0.32012, 0.14755, 0.037681, 0.33438]
Predicted label: 4
Correct prediction
Energy consumption = 154.708010 pJ
sum error= 111
Actual label: 2
Output voltages: [0.26081, 0.046784, 0.79879, 0.060978, 0.011114, 0.001282, 0.28146, 0.015174, 0.49174, 0.022628]
Predicted label: 2
Correct prediction
Energy consumption = 152.726165 pJ
sum error= 111
Actual label: 3
Output voltages: [0.040716, 0.01845, 0.050769, 0.79878, 0.027554, 0.0014631, 0.0092247, 0.00691, 0.43077, 0.2465]
Predicted label: 3
Correct prediction
Energy consumption = 140.200377 pJ
sum error= 111
Actual label: 0
Output voltages: [0.79857, 0.059906, 0.025624, 0.028393, 0.014411, 0.0051595, 0.63642, 0.017226, 0.38256, 0.024854]
Predicted label: 0
Correct prediction
Energy consumption = 151.616137 pJ
sum error= 111
Actual label: 9
Output voltages: [0.41308, 0.011869, 0.030775, 0.037714, 0.081041, 0.048468, 0.0049291, 0.06993, 0.46311, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 152.487968 pJ
sum error= 111
Actual label: 9
Output voltages: [0.36045, 0.03233, 0.010212, 0.060105, 0.18156, 0.019276, 0.0019661, 0.024909, 0.16344, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 139.120229 pJ
sum error= 111
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 209 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 209 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 209 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.19149, 0.58528, 0.039086, 0.084266, 0.79855, 0.0011141, 0.015905, 0.014242, 0.0090821, 0.52175]
Predicted label: 4
Correct prediction
Energy consumption = 175.289504 pJ
sum error= 111
Actual label: 7
Output voltages: [0.12862, 0.097327, 0.001264, 0.42461, 0.0011225, 0.033978, 0.0011839, 0.79765, 0.38033, 0.65204]
Predicted label: 7
Correct prediction
Energy consumption = 152.891887 pJ
sum error= 111
Actual label: 2
Output voltages: [0.42278, 0.046305, 0.79874, 0.10991, 0.02634, 0.001253, 0.47907, 0.038932, 0.71892, 0.046102]
Predicted label: 2
Correct prediction
Energy consumption = 147.919984 pJ
sum error= 111
Actual label: 8
Output voltages: [0.055823, 0.7948, 0.030567, 0.11011, 0.24698, 0.0012945, 0.0062068, 0.0011387, 0.66055, 0.37741]
Predicted label: 1
Wrong prediction!
Energy consumption = 147.651919 pJ
sum error= 112
Actual label: 4
Output voltages: [0.010291, 0.0097509, 0.1086, 0.0096012, 0.79877, 0.0011283, 0.01782, 0.070964, 0.042144, 0.27946]
Predicted label: 4
Correct prediction
Energy consumption = 158.762082 pJ
sum error= 112
Actual label: 7
Output voltages: [0.03627, 0.050288, 0.4235, 0.38439, 0.016815, 0.0010842, 0.0010695, 0.79878, 0.020921, 0.41749]
Predicted label: 7
Correct prediction
Energy consumption = 150.620326 pJ
sum error= 112
Actual label: 0
Output voltages: [0.79876, 0.11767, 0.050866, 0.024591, 0.02823, 0.0038897, 0.61688, 0.014532, 0.10684, 0.27675]
Predicted label: 0
Correct prediction
Energy consumption = 153.571656 pJ
sum error= 112
Actual label: 6
Output voltages: [0.024203, 0.034333, 0.19794, 0.0015634, 0.051665, 0.18889, 0.79877, 0.010555, 0.39735, 0.0029381]
Predicted label: 6
Correct prediction
Energy consumption = 149.800633 pJ
sum error= 112
Actual label: 2
Output voltages: [0.7735, 0.023207, 0.7974, 0.070646, 0.0014766, 0.0010675, 0.049855, 0.12716, 0.25057, 0.034756]
Predicted label: 2
Correct prediction
Energy consumption = 150.600376 pJ
sum error= 112
Actual label: 8
Output voltages: [0.021147, 0.026891, 0.023561, 0.066669, 0.0055026, 0.044552, 0.013843, 0.22435, 0.79879, 0.028364]
Predicted label: 8
Correct prediction
Energy consumption = 141.834635 pJ
sum error= 112
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 210 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 210 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 210 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.053417, 0.0010785, 0.0056019, 0.2107, 0.053249, 0.79848, 0.044157, 0.041988, 0.79778, 0.04208]
Predicted label: 5
Correct prediction
Energy consumption = 164.512672 pJ
sum error= 112
Actual label: 2
Output voltages: [0.35651, 0.027428, 0.79879, 0.06941, 0.013221, 0.0012645, 0.45957, 0.036744, 0.73444, 0.041564]
Predicted label: 2
Correct prediction
Energy consumption = 148.480111 pJ
sum error= 112
Actual label: 8
Output voltages: [0.048072, 0.03655, 0.32415, 0.20669, 0.034683, 0.010087, 0.038117, 0.0030303, 0.79869, 0.070379]
Predicted label: 8
Correct prediction
Energy consumption = 141.231726 pJ
sum error= 112
Actual label: 5
Output voltages: [0.048145, 0.0069688, 0.0013967, 0.035615, 0.036575, 0.79831, 0.050958, 0.0022043, 0.79337, 0.021485]
Predicted label: 5
Correct prediction
Energy consumption = 143.756820 pJ
sum error= 112
Actual label: 7
Output voltages: [0.031014, 0.049471, 0.20878, 0.042004, 0.0094666, 0.0010663, 0.0013284, 0.79859, 0.046571, 0.025148]
Predicted label: 7
Correct prediction
Energy consumption = 160.782878 pJ
sum error= 112
Actual label: 3
Output voltages: [0.2722, 0.0030941, 0.1946, 0.79845, 0.023496, 0.034497, 0.0028995, 0.042804, 0.78456, 0.021831]
Predicted label: 3
Correct prediction
Energy consumption = 148.095726 pJ
sum error= 112
Actual label: 0
Output voltages: [0.79843, 0.16118, 0.22785, 0.0017492, 0.0066532, 0.0010839, 0.17553, 0.023624, 0.23083, 0.18083]
Predicted label: 0
Correct prediction
Energy consumption = 145.770412 pJ
sum error= 112
Actual label: 8
Output voltages: [0.75767, 0.024948, 0.2736, 0.47438, 0.027755, 0.013536, 0.35904, 0.0026564, 0.79863, 0.4816]
Predicted label: 8
Correct prediction
Energy consumption = 139.978641 pJ
sum error= 112
Actual label: 2
Output voltages: [0.32303, 0.031713, 0.79866, 0.29591, 0.052688, 0.001156, 0.098951, 0.010567, 0.73264, 0.027449]
Predicted label: 2
Correct prediction
Energy consumption = 149.614242 pJ
sum error= 112
Actual label: 3
Output voltages: [0.0025195, 0.48836, 0.4999, 0.030911, 0.047314, 0.12359, 0.0010663, 0.49337, 0.70981, 0.047759]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.493726 pJ
sum error= 113
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 211 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 211 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 211 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.21644, 0.36534, 0.79878, 0.13791, 0.0030505, 0.00122, 0.30691, 0.0055387, 0.66528, 0.17567]
Predicted label: 2
Correct prediction
Energy consumption = 163.084711 pJ
sum error= 113
Actual label: 8
Output voltages: [0.027129, 0.0026523, 0.16485, 0.032562, 0.020461, 0.29749, 0.033545, 0.0039918, 0.7987, 0.024886]
Predicted label: 8
Correct prediction
Energy consumption = 141.258106 pJ
sum error= 113
Actual label: 2
Output voltages: [0.40671, 0.041027, 0.79879, 0.12715, 0.020443, 0.0012193, 0.20151, 0.047747, 0.39511, 0.035425]
Predicted label: 2
Correct prediction
Energy consumption = 148.753310 pJ
sum error= 113
Actual label: 5
Output voltages: [0.017483, 0.0013824, 0.0020739, 0.27069, 0.043157, 0.79875, 0.29406, 0.023341, 0.77811, 0.045215]
Predicted label: 5
Correct prediction
Energy consumption = 145.448468 pJ
sum error= 113
Actual label: 5
Output voltages: [0.052203, 0.0015689, 0.0025899, 0.59411, 0.021311, 0.79879, 0.15086, 0.025178, 0.72637, 0.15303]
Predicted label: 5
Correct prediction
Energy consumption = 134.806289 pJ
sum error= 113
Actual label: 7
Output voltages: [0.76414, 0.22798, 0.015053, 0.0063766, 0.0027381, 0.091858, 0.017952, 0.79721, 0.49385, 0.065935]
Predicted label: 7
Correct prediction
Energy consumption = 161.032872 pJ
sum error= 113
Actual label: 6
Output voltages: [0.025359, 0.0054875, 0.029506, 0.0095549, 0.37771, 0.089091, 0.7978, 0.0011315, 0.76204, 0.030962]
Predicted label: 6
Correct prediction
Energy consumption = 145.075098 pJ
sum error= 113
Actual label: 4
Output voltages: [0.0036153, 0.0073785, 0.031621, 0.0080884, 0.7986, 0.0019402, 0.16192, 0.22746, 0.058211, 0.039376]
Predicted label: 4
Correct prediction
Energy consumption = 153.268919 pJ
sum error= 113
Actual label: 6
Output voltages: [0.77521, 0.54045, 0.20447, 0.011617, 0.0023469, 0.0033925, 0.74039, 0.0084096, 0.44034, 0.041427]
Predicted label: 0
Wrong prediction!
Energy consumption = 163.693170 pJ
sum error= 114
Actual label: 8
Output voltages: [0.016498, 0.036142, 0.072575, 0.049887, 0.0073601, 0.025551, 0.025704, 0.014696, 0.79871, 0.022258]
Predicted label: 8
Correct prediction
Energy consumption = 156.968377 pJ
sum error= 114
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 212 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 212 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 212 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.012155, 0.0079632, 0.30062, 0.038152, 0.7987, 0.0011192, 0.02259, 0.067325, 0.0068396, 0.037863]
Predicted label: 4
Correct prediction
Energy consumption = 172.176112 pJ
sum error= 114
Actual label: 8
Output voltages: [0.001554, 0.25883, 0.14487, 0.01372, 0.011653, 0.023159, 0.48098, 0.019139, 0.79811, 0.037799]
Predicted label: 8
Correct prediction
Energy consumption = 161.353824 pJ
sum error= 114
Actual label: 2
Output voltages: [0.12648, 0.075826, 0.79878, 0.1914, 0.011372, 0.0012611, 0.013876, 0.48504, 0.05206, 0.15019]
Predicted label: 2
Correct prediction
Energy consumption = 150.947682 pJ
sum error= 114
Actual label: 7
Output voltages: [0.11927, 0.13065, 0.72404, 0.049503, 0.11125, 0.00108, 0.0010667, 0.79872, 0.024479, 0.033625]
Predicted label: 7
Correct prediction
Energy consumption = 142.341393 pJ
sum error= 114
Actual label: 4
Output voltages: [0.0042077, 0.0031327, 0.39413, 0.018636, 0.79864, 0.0010997, 0.42513, 0.037128, 0.014712, 0.036185]
Predicted label: 4
Correct prediction
Energy consumption = 151.995692 pJ
sum error= 114
Actual label: 5
Output voltages: [0.21246, 0.020167, 0.001067, 0.69785, 0.009311, 0.74344, 0.47782, 0.0013184, 0.37795, 0.5554]
Predicted label: 5
Correct prediction
Energy consumption = 159.999317 pJ
sum error= 114
Actual label: 2
Output voltages: [0.36444, 0.12568, 0.79879, 0.4059, 0.010062, 0.0012937, 0.2567, 0.07789, 0.39287, 0.021884]
Predicted label: 2
Correct prediction
Energy consumption = 148.654850 pJ
sum error= 114
Actual label: 0
Output voltages: [0.79876, 0.0874, 0.019598, 0.014402, 0.015767, 0.015171, 0.58644, 0.017734, 0.15271, 0.015965]
Predicted label: 0
Correct prediction
Energy consumption = 148.188644 pJ
sum error= 114
Actual label: 3
Output voltages: [0.24626, 0.029907, 0.022729, 0.79869, 0.010124, 0.00513, 0.0099583, 0.0069837, 0.51137, 0.056315]
Predicted label: 3
Correct prediction
Energy consumption = 149.821096 pJ
sum error= 114
Actual label: 9
Output voltages: [0.015869, 0.0010855, 0.4136, 0.022082, 0.052763, 0.0359, 0.0070838, 0.0012673, 0.79729, 0.39822]
Predicted label: 8
Wrong prediction!
Energy consumption = 145.646077 pJ
sum error= 115
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 213 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 213 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 213 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.043826, 0.011973, 0.024164, 0.16211, 0.52348, 0.0068378, 0.001732, 0.004997, 0.32784, 0.77535]
Predicted label: 9
Wrong prediction!
Energy consumption = 166.688248 pJ
sum error= 116
Actual label: 6
Output voltages: [0.77939, 0.026286, 0.3253, 0.018626, 0.024586, 0.0014974, 0.77285, 0.014338, 0.61173, 0.018867]
Predicted label: 0
Wrong prediction!
Energy consumption = 155.520175 pJ
sum error= 117
Actual label: 7
Output voltages: [0.02052, 0.020039, 0.020268, 0.32696, 0.021898, 0.0020574, 0.0010666, 0.79874, 0.17993, 0.42667]
Predicted label: 7
Correct prediction
Energy consumption = 160.500917 pJ
sum error= 117
Actual label: 2
Output voltages: [0.39721, 0.058767, 0.79877, 0.20945, 0.022432, 0.0012796, 0.25788, 0.081664, 0.46529, 0.075677]
Predicted label: 2
Correct prediction
Energy consumption = 148.857626 pJ
sum error= 117
Actual label: 5
Output voltages: [0.09061, 0.0010687, 0.0011305, 0.040114, 0.16823, 0.79878, 0.21566, 0.0032264, 0.78686, 0.0071003]
Predicted label: 5
Correct prediction
Energy consumption = 143.615030 pJ
sum error= 117
Actual label: 6
Output voltages: [0.10975, 0.79804, 0.093822, 0.015905, 0.0291, 0.062809, 0.7647, 0.0032894, 0.31484, 0.0030488]
Predicted label: 1
Wrong prediction!
Energy consumption = 150.047631 pJ
sum error= 118
Actual label: 1
Output voltages: [0.002862, 0.79868, 0.50047, 0.51367, 0.22584, 0.014586, 0.029233, 0.36495, 0.0039222, 0.044883]
Predicted label: 1
Correct prediction
Energy consumption = 162.759647 pJ
sum error= 118
Actual label: 1
Output voltages: [0.025057, 0.79852, 0.017499, 0.012177, 0.015499, 0.0027394, 0.48204, 0.0020191, 0.5856, 0.021032]
Predicted label: 1
Correct prediction
Energy consumption = 161.401626 pJ
sum error= 118
Actual label: 2
Output voltages: [0.24289, 0.038528, 0.79876, 0.044201, 0.0033125, 0.0010681, 0.25032, 0.032066, 0.78144, 0.030655]
Predicted label: 2
Correct prediction
Energy consumption = 146.064015 pJ
sum error= 118
Actual label: 3
Output voltages: [0.29111, 0.017974, 0.20824, 0.7987, 0.029335, 0.048902, 0.018969, 0.021447, 0.72098, 0.10891]
Predicted label: 3
Correct prediction
Energy consumption = 134.299145 pJ
sum error= 118
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 214 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 214 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 214 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.39233, 0.040254, 0.39777, 0.0011876, 0.25143, 0.028486, 0.79869, 0.006838, 0.023736, 0.054973]
Predicted label: 6
Correct prediction
Energy consumption = 170.301686 pJ
sum error= 118
Actual label: 7
Output voltages: [0.039604, 0.03962, 0.048925, 0.59979, 0.0014721, 0.0058089, 0.0010855, 0.79872, 0.22213, 0.71227]
Predicted label: 7
Correct prediction
Energy consumption = 166.148979 pJ
sum error= 118
Actual label: 8
Output voltages: [0.030489, 0.047429, 0.32175, 0.11535, 0.016073, 0.0051846, 0.33198, 0.0017863, 0.79877, 0.30251]
Predicted label: 8
Correct prediction
Energy consumption = 151.565505 pJ
sum error= 118
Actual label: 7
Output voltages: [0.34863, 0.073684, 0.76245, 0.029011, 0.0016255, 0.0011856, 0.0012852, 0.79875, 0.4196, 0.074238]
Predicted label: 7
Correct prediction
Energy consumption = 154.886502 pJ
sum error= 118
Actual label: 6
Output voltages: [0.13683, 0.027914, 0.079445, 0.0077881, 0.22507, 0.12179, 0.79877, 0.0078818, 0.734, 0.0052605]
Predicted label: 6
Correct prediction
Energy consumption = 156.197450 pJ
sum error= 118
Actual label: 4
Output voltages: [0.028045, 0.019783, 0.31516, 0.0011378, 0.79879, 0.001066, 0.71953, 0.012833, 0.30598, 0.037337]
Predicted label: 4
Correct prediction
Energy consumption = 144.187974 pJ
sum error= 118
Actual label: 8
Output voltages: [0.12064, 0.031001, 0.22729, 0.028988, 0.014669, 0.032315, 0.023773, 0.0029971, 0.79874, 0.21009]
Predicted label: 8
Correct prediction
Energy consumption = 156.296113 pJ
sum error= 118
Actual label: 9
Output voltages: [0.072627, 0.0037031, 0.014553, 0.034768, 0.15594, 0.0024333, 0.0082053, 0.040448, 0.64813, 0.79784]
Predicted label: 9
Correct prediction
Energy consumption = 156.667142 pJ
sum error= 118
Actual label: 4
Output voltages: [0.17372, 0.010358, 0.30458, 0.019318, 0.79863, 0.0012308, 0.05337, 0.014384, 0.02413, 0.48052]
Predicted label: 4
Correct prediction
Energy consumption = 143.035786 pJ
sum error= 118
Actual label: 8
Output voltages: [0.12784, 0.42218, 0.78025, 0.061475, 0.015918, 0.0011963, 0.01695, 0.060684, 0.73044, 0.039196]
Predicted label: 2
Wrong prediction!
Energy consumption = 148.190067 pJ
sum error= 119
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 215 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 215 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 215 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.02496, 0.082332, 0.044928, 0.0045311, 0.082235, 0.38124, 0.79877, 0.0026477, 0.48131, 0.0015064]
Predicted label: 6
Correct prediction
Energy consumption = 165.742831 pJ
sum error= 119
Actual label: 3
Output voltages: [0.13405, 0.0012558, 0.10918, 0.79873, 0.1078, 0.017039, 0.053857, 0.0044849, 0.57596, 0.0026547]
Predicted label: 3
Correct prediction
Energy consumption = 141.846647 pJ
sum error= 119
Actual label: 8
Output voltages: [0.075096, 0.021204, 0.22162, 0.20146, 0.026865, 0.012698, 0.20221, 0.0064454, 0.79875, 0.027726]
Predicted label: 8
Correct prediction
Energy consumption = 156.154551 pJ
sum error= 119
Actual label: 3
Output voltages: [0.021785, 0.0080639, 0.23646, 0.79873, 0.10432, 0.31217, 0.025286, 0.013537, 0.42926, 0.0079758]
Predicted label: 3
Correct prediction
Energy consumption = 141.576769 pJ
sum error= 119
Actual label: 1
Output voltages: [0.04409, 0.79867, 0.59375, 0.055821, 0.057552, 0.0010679, 0.53706, 0.0050058, 0.096373, 0.039798]
Predicted label: 1
Correct prediction
Energy consumption = 166.412866 pJ
sum error= 119
Actual label: 0
Output voltages: [0.79877, 0.045986, 0.015067, 0.025502, 0.028581, 0.0137, 0.73115, 0.0112, 0.31726, 0.028636]
Predicted label: 0
Correct prediction
Energy consumption = 158.700981 pJ
sum error= 119
Actual label: 6
Output voltages: [0.19688, 0.29859, 0.062098, 0.021485, 0.099391, 0.065486, 0.79876, 0.0034494, 0.43644, 0.013737]
Predicted label: 6
Correct prediction
Energy consumption = 139.420154 pJ
sum error= 119
Actual label: 2
Output voltages: [0.36305, 0.030933, 0.79877, 0.12331, 0.0098956, 0.0013449, 0.2424, 0.092835, 0.48795, 0.030263]
Predicted label: 2
Correct prediction
Energy consumption = 150.836995 pJ
sum error= 119
Actual label: 2
Output voltages: [0.28069, 0.14636, 0.79873, 0.43546, 0.0086001, 0.0014047, 0.020579, 0.16783, 0.26752, 0.018892]
Predicted label: 2
Correct prediction
Energy consumption = 140.443481 pJ
sum error= 119
Actual label: 5
Output voltages: [0.038323, 0.0062878, 0.002783, 0.20988, 0.030142, 0.79878, 0.11253, 0.010203, 0.74144, 0.022282]
Predicted label: 5
Correct prediction
Energy consumption = 147.632188 pJ
sum error= 119
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 216 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 216 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 216 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.16148, 0.046122, 0.054893, 0.0087131, 0.24108, 0.58623, 0.79876, 0.0059933, 0.57579, 0.0033743]
Predicted label: 6
Correct prediction
Energy consumption = 166.867506 pJ
sum error= 119
Actual label: 9
Output voltages: [0.045174, 0.0021589, 0.0050151, 0.052685, 0.78126, 0.041528, 0.021667, 0.11951, 0.029814, 0.78526]
Predicted label: 9
Correct prediction
Energy consumption = 153.209295 pJ
sum error= 119
Actual label: 5
Output voltages: [0.046911, 0.001072, 0.017605, 0.0089445, 0.052717, 0.79564, 0.50226, 0.0070999, 0.7743, 0.044724]
Predicted label: 5
Correct prediction
Energy consumption = 153.493842 pJ
sum error= 119
Actual label: 8
Output voltages: [0.017262, 0.011877, 0.20375, 0.45435, 0.0019661, 0.0049723, 0.12089, 0.016458, 0.79878, 0.045712]
Predicted label: 8
Correct prediction
Energy consumption = 149.177873 pJ
sum error= 119
Actual label: 1
Output voltages: [0.01139, 0.79841, 0.035054, 0.042628, 0.028905, 0.006134, 0.61315, 0.0026417, 0.27109, 0.16594]
Predicted label: 1
Correct prediction
Energy consumption = 165.853229 pJ
sum error= 119
Actual label: 4
Output voltages: [0.0051023, 0.023598, 0.081416, 0.0054048, 0.79864, 0.0025534, 0.33206, 0.26867, 0.019154, 0.067343]
Predicted label: 4
Correct prediction
Energy consumption = 158.169461 pJ
sum error= 119
Actual label: 1
Output voltages: [0.0069317, 0.79872, 0.036632, 0.47006, 0.24894, 0.0010994, 0.02432, 0.029526, 0.1743, 0.14451]
Predicted label: 1
Correct prediction
Energy consumption = 155.693052 pJ
sum error= 119
Actual label: 7
Output voltages: [0.3259, 0.025807, 0.28851, 0.01001, 0.012852, 0.0018678, 0.0011335, 0.79869, 0.54682, 0.26795]
Predicted label: 7
Correct prediction
Energy consumption = 152.301177 pJ
sum error= 119
Actual label: 8
Output voltages: [0.24688, 0.011842, 0.25834, 0.29288, 0.013999, 0.02219, 0.22761, 0.0090305, 0.79878, 0.052493]
Predicted label: 8
Correct prediction
Energy consumption = 158.717394 pJ
sum error= 119
Actual label: 4
Output voltages: [0.044481, 0.024302, 0.043455, 0.0011689, 0.77373, 0.0011423, 0.013578, 0.013952, 0.074564, 0.78619]
Predicted label: 9
Wrong prediction!
Energy consumption = 164.142734 pJ
sum error= 120
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 217 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 217 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 217 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.082701, 0.026439, 0.38563, 0.0011187, 0.39054, 0.14271, 0.79879, 0.0010704, 0.42217, 0.0027103]
Predicted label: 6
Correct prediction
Energy consumption = 161.982829 pJ
sum error= 120
Actual label: 1
Output voltages: [0.0014362, 0.79856, 0.048538, 0.58064, 0.021988, 0.030689, 0.036654, 0.016286, 0.010839, 0.1757]
Predicted label: 1
Correct prediction
Energy consumption = 165.217955 pJ
sum error= 120
Actual label: 8
Output voltages: [0.013337, 0.020597, 0.068485, 0.1653, 0.0031513, 0.019573, 0.17037, 0.024237, 0.7987, 0.042385]
Predicted label: 8
Correct prediction
Energy consumption = 155.027661 pJ
sum error= 120
Actual label: 4
Output voltages: [0.0072654, 0.0052151, 0.057396, 0.010599, 0.79875, 0.010438, 0.060022, 0.22107, 0.52057, 0.00175]
Predicted label: 4
Correct prediction
Energy consumption = 149.452772 pJ
sum error= 120
Actual label: 3
Output voltages: [0.41873, 0.086179, 0.042571, 0.79878, 0.0031004, 0.77818, 0.035739, 0.14443, 0.041465, 0.0015401]
Predicted label: 3
Correct prediction
Energy consumption = 156.953989 pJ
sum error= 120
Actual label: 1
Output voltages: [0.0055632, 0.79855, 0.0031143, 0.04618, 0.16684, 0.0010847, 0.12583, 0.012437, 0.20379, 0.18658]
Predicted label: 1
Correct prediction
Energy consumption = 166.750067 pJ
sum error= 120
Actual label: 2
Output voltages: [0.50186, 0.031265, 0.79878, 0.27607, 0.18577, 0.0011676, 0.042391, 0.082807, 0.067655, 0.013948]
Predicted label: 2
Correct prediction
Energy consumption = 147.986313 pJ
sum error= 120
Actual label: 8
Output voltages: [0.31971, 0.015333, 0.35069, 0.046751, 0.039545, 0.022314, 0.43679, 0.0067944, 0.79878, 0.034608]
Predicted label: 8
Correct prediction
Energy consumption = 148.825902 pJ
sum error= 120
Actual label: 0
Output voltages: [0.79877, 0.14985, 0.11213, 0.028741, 0.0040659, 0.0036216, 0.37752, 0.053709, 0.19106, 0.041928]
Predicted label: 0
Correct prediction
Energy consumption = 155.683211 pJ
sum error= 120
Actual label: 8
Output voltages: [0.060376, 0.012104, 0.41575, 0.67102, 0.0051225, 0.0021608, 0.0099616, 0.0025697, 0.79869, 0.10486]
Predicted label: 8
Correct prediction
Energy consumption = 146.059276 pJ
sum error= 120
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 218 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 218 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 218 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.084343, 0.0012068, 0.0016868, 0.54634, 0.049398, 0.79876, 0.074195, 0.053957, 0.73601, 0.13334]
Predicted label: 5
Correct prediction
Energy consumption = 165.297666 pJ
sum error= 120
Actual label: 9
Output voltages: [0.56707, 0.0033497, 0.17726, 0.010621, 0.45589, 0.01152, 0.0057309, 0.0041149, 0.064523, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 151.501215 pJ
sum error= 120
Actual label: 1
Output voltages: [0.43497, 0.41067, 0.58831, 0.79521, 0.0012294, 0.01428, 0.0051529, 0.0060092, 0.46325, 0.0041789]
Predicted label: 3
Wrong prediction!
Energy consumption = 160.976039 pJ
sum error= 121
Actual label: 4
Output voltages: [0.047848, 0.024432, 0.073381, 0.0050102, 0.79879, 0.0049515, 0.7268, 0.02347, 0.020167, 0.022457]
Predicted label: 4
Correct prediction
Energy consumption = 153.887302 pJ
sum error= 121
Actual label: 2
Output voltages: [0.31045, 0.026276, 0.79879, 0.097539, 0.03442, 0.0012262, 0.18677, 0.013615, 0.5724, 0.046215]
Predicted label: 2
Correct prediction
Energy consumption = 148.612150 pJ
sum error= 121
Actual label: 0
Output voltages: [0.79857, 0.17349, 0.03099, 0.010804, 0.0036395, 0.0094922, 0.40965, 0.070919, 0.46507, 0.028394]
Predicted label: 0
Correct prediction
Energy consumption = 164.427991 pJ
sum error= 121
Actual label: 2
Output voltages: [0.49227, 0.0084585, 0.77932, 0.78059, 0.024702, 0.0011982, 0.0092086, 0.0080492, 0.61166, 0.026759]
Predicted label: 3
Wrong prediction!
Energy consumption = 147.708654 pJ
sum error= 122
Actual label: 7
Output voltages: [0.13988, 0.033136, 0.46479, 0.027104, 0.0030034, 0.0015075, 0.0011016, 0.79853, 0.59391, 0.038176]
Predicted label: 7
Correct prediction
Energy consumption = 153.146416 pJ
sum error= 122
Actual label: 0
Output voltages: [0.79872, 0.01718, 0.01607, 0.040046, 0.007079, 0.015372, 0.5578, 0.024862, 0.2352, 0.47823]
Predicted label: 0
Correct prediction
Energy consumption = 151.599461 pJ
sum error= 122
Actual label: 9
Output voltages: [0.0039588, 0.78558, 0.0028427, 0.15996, 0.034059, 0.019177, 0.001221, 0.0326, 0.78218, 0.62941]
Predicted label: 1
Wrong prediction!
Energy consumption = 150.101686 pJ
sum error= 123
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 219 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 219 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 219 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79824, 0.13429, 0.17483, 0.033815, 0.023499, 0.0035426, 0.52986, 0.010797, 0.27077, 0.024749]
Predicted label: 0
Correct prediction
Energy consumption = 179.164032 pJ
sum error= 123
Actual label: 2
Output voltages: [0.52678, 0.045136, 0.79878, 0.24817, 0.019253, 0.0012118, 0.46577, 0.019586, 0.65213, 0.094503]
Predicted label: 2
Correct prediction
Energy consumption = 147.928678 pJ
sum error= 123
Actual label: 5
Output voltages: [0.28705, 0.0014298, 0.025561, 0.56987, 0.022737, 0.79745, 0.12237, 0.0055321, 0.78926, 0.05979]
Predicted label: 5
Correct prediction
Energy consumption = 147.307109 pJ
sum error= 123
Actual label: 7
Output voltages: [0.037211, 0.072128, 0.52092, 0.15107, 0.001067, 0.0014245, 0.0011349, 0.79877, 0.68649, 0.47511]
Predicted label: 7
Correct prediction
Energy consumption = 142.829986 pJ
sum error= 123
Actual label: 6
Output voltages: [0.021486, 0.2208, 0.51395, 0.0013259, 0.070977, 0.040828, 0.79877, 0.0012767, 0.40983, 0.0035835]
Predicted label: 6
Correct prediction
Energy consumption = 144.391221 pJ
sum error= 123
Actual label: 7
Output voltages: [0.70076, 0.0074171, 0.77476, 0.0078966, 0.0011735, 0.0010762, 0.0011078, 0.79736, 0.62352, 0.038688]
Predicted label: 7
Correct prediction
Energy consumption = 144.004503 pJ
sum error= 123
Actual label: 9
Output voltages: [0.35101, 0.0068815, 0.024969, 0.010337, 0.0563, 0.013697, 0.0031816, 0.062858, 0.64745, 0.79402]
Predicted label: 9
Correct prediction
Energy consumption = 146.343762 pJ
sum error= 123
Actual label: 4
Output voltages: [0.021518, 0.019298, 0.084122, 0.0032237, 0.79701, 0.0016841, 0.48895, 0.015585, 0.3645, 0.0011442]
Predicted label: 4
Correct prediction
Energy consumption = 152.528982 pJ
sum error= 123
Actual label: 2
Output voltages: [0.36822, 0.41303, 0.79878, 0.0060874, 0.019505, 0.0014073, 0.12451, 0.23797, 0.24094, 0.011597]
Predicted label: 2
Correct prediction
Energy consumption = 152.301025 pJ
sum error= 123
Actual label: 6
Output voltages: [0.15903, 0.018567, 0.033511, 0.04555, 0.2276, 0.52418, 0.79866, 0.0078355, 0.75897, 0.0033293]
Predicted label: 6
Correct prediction
Energy consumption = 145.670476 pJ
sum error= 123
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 220 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 220 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 220 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.32914, 0.030999, 0.76944, 0.091696, 0.28017, 0.0011401, 0.78396, 0.0053, 0.206, 0.001088]
Predicted label: 6
Wrong prediction!
Energy consumption = 161.296780 pJ
sum error= 124
Actual label: 4
Output voltages: [0.0042099, 0.011606, 0.023763, 0.13836, 0.79878, 0.13705, 0.028808, 0.0082233, 0.072252, 0.72455]
Predicted label: 4
Correct prediction
Energy consumption = 157.941896 pJ
sum error= 124
Actual label: 4
Output voltages: [0.0088082, 0.0042695, 0.026284, 0.0037718, 0.79875, 0.0020103, 0.053469, 0.15186, 0.42765, 0.0011443]
Predicted label: 4
Correct prediction
Energy consumption = 147.847456 pJ
sum error= 124
Actual label: 8
Output voltages: [0.0898, 0.038065, 0.22442, 0.17027, 0.019595, 0.011256, 0.070553, 0.0065612, 0.79875, 0.44276]
Predicted label: 8
Correct prediction
Energy consumption = 153.407642 pJ
sum error= 124
Actual label: 0
Output voltages: [0.79867, 0.0087083, 0.020118, 0.14502, 0.010324, 0.041261, 0.028947, 0.080694, 0.69646, 0.28668]
Predicted label: 0
Correct prediction
Energy consumption = 158.154205 pJ
sum error= 124
Actual label: 4
Output voltages: [0.0086553, 0.040427, 0.077023, 0.0033306, 0.79879, 0.0011663, 0.4786, 0.039867, 0.029377, 0.040256]
Predicted label: 4
Correct prediction
Energy consumption = 152.459793 pJ
sum error= 124
Actual label: 4
Output voltages: [0.0039834, 0.03489, 0.18705, 0.016856, 0.79874, 0.00127, 0.062501, 0.14539, 0.014028, 0.078417]
Predicted label: 4
Correct prediction
Energy consumption = 141.687409 pJ
sum error= 124
Actual label: 5
Output voltages: [0.043364, 0.0010809, 0.004014, 0.045347, 0.019136, 0.79876, 0.11368, 0.020036, 0.7725, 0.0041461]
Predicted label: 5
Correct prediction
Energy consumption = 151.508537 pJ
sum error= 124
Actual label: 8
Output voltages: [0.045548, 0.028236, 0.16441, 0.54056, 0.0068521, 0.0014429, 0.078635, 0.019105, 0.79878, 0.20313]
Predicted label: 8
Correct prediction
Energy consumption = 153.059748 pJ
sum error= 124
Actual label: 0
Output voltages: [0.79878, 0.0065757, 0.075204, 0.0018332, 0.01976, 0.0049315, 0.04934, 0.011019, 0.26379, 0.039679]
Predicted label: 0
Correct prediction
Energy consumption = 153.123356 pJ
sum error= 124
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 221 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 221 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 221 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.042225, 0.027572, 0.22965, 0.0020863, 0.39065, 0.30318, 0.7987, 0.003924, 0.58836, 0.0061241]
Predicted label: 6
Correct prediction
Energy consumption = 163.019228 pJ
sum error= 124
Actual label: 8
Output voltages: [0.15519, 0.0016772, 0.13179, 0.072789, 0.012766, 0.074115, 0.0033487, 0.0095722, 0.79876, 0.087196]
Predicted label: 8
Correct prediction
Energy consumption = 152.544393 pJ
sum error= 124
Actual label: 9
Output voltages: [0.16814, 0.0038889, 0.030602, 0.0043169, 0.093498, 0.016874, 0.007014, 0.021261, 0.67586, 0.79779]
Predicted label: 9
Correct prediction
Energy consumption = 145.309428 pJ
sum error= 124
Actual label: 8
Output voltages: [0.024638, 0.05932, 0.035331, 0.52418, 0.0044049, 0.12721, 0.008306, 0.021322, 0.79878, 0.38325]
Predicted label: 8
Correct prediction
Energy consumption = 147.512743 pJ
sum error= 124
Actual label: 5
Output voltages: [0.14495, 0.00117, 0.0046902, 0.47187, 0.0083605, 0.79878, 0.1893, 0.035399, 0.69148, 0.023892]
Predicted label: 5
Correct prediction
Energy consumption = 143.434990 pJ
sum error= 124
Actual label: 6
Output voltages: [0.20609, 0.017883, 0.47075, 0.010975, 0.066713, 0.16498, 0.79858, 0.0010706, 0.75074, 0.045224]
Predicted label: 6
Correct prediction
Energy consumption = 141.703986 pJ
sum error= 124
Actual label: 9
Output voltages: [0.2038, 0.0056837, 0.0096402, 0.082626, 0.45481, 0.28674, 0.045771, 0.029066, 0.042024, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 156.700788 pJ
sum error= 124
Actual label: 0
Output voltages: [0.79872, 0.0148, 0.031734, 0.0046947, 0.019693, 0.03006, 0.28869, 0.017315, 0.026769, 0.022875]
Predicted label: 0
Correct prediction
Energy consumption = 151.136532 pJ
sum error= 124
Actual label: 4
Output voltages: [0.01238, 0.0019874, 0.028672, 0.035183, 0.79875, 0.0034742, 0.12535, 0.026562, 0.32253, 0.025058]
Predicted label: 4
Correct prediction
Energy consumption = 158.394434 pJ
sum error= 124
Actual label: 8
Output voltages: [0.17966, 0.0046785, 0.43853, 0.0062888, 0.016126, 0.0071708, 0.006636, 0.0014304, 0.79831, 0.64235]
Predicted label: 8
Correct prediction
Energy consumption = 143.467941 pJ
sum error= 124
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 222 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 222 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 222 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.22205, 0.032631, 0.030032, 0.12083, 0.021781, 0.0018038, 0.0010906, 0.79869, 0.4732, 0.45532]
Predicted label: 7
Correct prediction
Energy consumption = 171.436736 pJ
sum error= 124
Actual label: 1
Output voltages: [0.041516, 0.79869, 0.047644, 0.0013657, 0.24814, 0.022162, 0.22885, 0.01582, 0.67508, 0.49725]
Predicted label: 1
Correct prediction
Energy consumption = 156.967217 pJ
sum error= 124
Actual label: 3
Output voltages: [0.45578, 0.0024619, 0.012505, 0.79877, 0.0022436, 0.59277, 0.010007, 0.042162, 0.1624, 0.0011636]
Predicted label: 3
Correct prediction
Energy consumption = 152.928414 pJ
sum error= 124
Actual label: 4
Output voltages: [0.0035209, 0.01445, 0.1522, 0.0063804, 0.79866, 0.0067096, 0.2551, 0.078189, 0.034014, 0.026191]
Predicted label: 4
Correct prediction
Energy consumption = 153.745764 pJ
sum error= 124
Actual label: 5
Output voltages: [0.31654, 0.0019498, 0.0072433, 0.19744, 0.0055533, 0.77466, 0.74834, 0.0023608, 0.75194, 0.041613]
Predicted label: 5
Correct prediction
Energy consumption = 156.824969 pJ
sum error= 124
Actual label: 8
Output voltages: [0.076543, 0.039026, 0.3822, 0.41065, 0.0015756, 0.0043225, 0.021519, 0.010562, 0.79417, 0.6408]
Predicted label: 8
Correct prediction
Energy consumption = 153.818748 pJ
sum error= 124
Actual label: 0
Output voltages: [0.79797, 0.018653, 0.02476, 0.0055907, 0.032541, 0.0034056, 0.69123, 0.017984, 0.15107, 0.03672]
Predicted label: 0
Correct prediction
Energy consumption = 152.032981 pJ
sum error= 124
Actual label: 9
Output voltages: [0.51346, 0.0092029, 0.01025, 0.11665, 0.28544, 0.1592, 0.019495, 0.008353, 0.045855, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.461510 pJ
sum error= 124
Actual label: 1
Output voltages: [0.020551, 0.79854, 0.0010813, 0.031081, 0.42703, 0.030224, 0.74226, 0.005731, 0.053144, 0.037137]
Predicted label: 1
Correct prediction
Energy consumption = 162.945986 pJ
sum error= 124
Actual label: 3
Output voltages: [0.13252, 0.024565, 0.2191, 0.79878, 0.010492, 0.0027772, 0.0053736, 0.021392, 0.74082, 0.03028]
Predicted label: 3
Correct prediction
Energy consumption = 143.872693 pJ
sum error= 124
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 223 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 223 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 223 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.091331, 0.025461, 0.30356, 0.79879, 0.047557, 0.0071952, 0.035512, 0.0016588, 0.4698, 0.33607]
Predicted label: 3
Correct prediction
Energy consumption = 161.362710 pJ
sum error= 124
Actual label: 6
Output voltages: [0.044641, 0.041204, 0.2878, 0.0061272, 0.29717, 0.099142, 0.79872, 0.0015083, 0.55964, 0.024625]
Predicted label: 6
Correct prediction
Energy consumption = 145.012468 pJ
sum error= 124
Actual label: 9
Output voltages: [0.51307, 0.033574, 0.011718, 0.10593, 0.21732, 0.018556, 0.062582, 0.0073081, 0.36729, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 158.118649 pJ
sum error= 124
Actual label: 8
Output voltages: [0.010706, 0.010121, 0.30126, 0.019926, 0.037081, 0.051511, 0.035235, 0.0043162, 0.79875, 0.03959]
Predicted label: 8
Correct prediction
Energy consumption = 143.814688 pJ
sum error= 124
Actual label: 7
Output voltages: [0.30893, 0.041098, 0.44159, 0.026374, 0.0035698, 0.0012117, 0.0010813, 0.79875, 0.20137, 0.026428]
Predicted label: 7
Correct prediction
Energy consumption = 156.292070 pJ
sum error= 124
Actual label: 1
Output voltages: [0.073228, 0.79875, 0.35861, 0.0065298, 0.73446, 0.0012004, 0.3294, 0.0029712, 0.068409, 0.0038706]
Predicted label: 1
Correct prediction
Energy consumption = 151.585956 pJ
sum error= 124
Actual label: 0
Output voltages: [0.79877, 0.12515, 0.079032, 0.019862, 0.017021, 0.0093785, 0.42468, 0.026237, 0.041916, 0.020572]
Predicted label: 0
Correct prediction
Energy consumption = 151.890192 pJ
sum error= 124
Actual label: 5
Output voltages: [0.025951, 0.0014875, 0.33008, 0.03145, 0.0013594, 0.78042, 0.74074, 0.0015439, 0.78134, 0.025698]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.652112 pJ
sum error= 125
Actual label: 7
Output voltages: [0.51976, 0.020229, 0.055069, 0.68942, 0.0012875, 0.0011087, 0.0010668, 0.79827, 0.21155, 0.32789]
Predicted label: 7
Correct prediction
Energy consumption = 160.645984 pJ
sum error= 125
Actual label: 1
Output voltages: [0.011851, 0.79843, 0.0082718, 0.10809, 0.038926, 0.010565, 0.31569, 0.020315, 0.13371, 0.044331]
Predicted label: 1
Correct prediction
Energy consumption = 160.013183 pJ
sum error= 125
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 224 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 224 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 224 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30818, 0.037824, 0.015929, 0.10002, 0.012849, 0.036069, 0.001079, 0.79859, 0.21236, 0.43482]
Predicted label: 7
Correct prediction
Energy consumption = 172.049746 pJ
sum error= 125
Actual label: 5
Output voltages: [0.16915, 0.0011083, 0.0010805, 0.39669, 0.045467, 0.79874, 0.44522, 0.053256, 0.76801, 0.018209]
Predicted label: 5
Correct prediction
Energy consumption = 151.425227 pJ
sum error= 125
Actual label: 2
Output voltages: [0.17161, 0.041998, 0.79879, 0.040785, 0.0038526, 0.0013024, 0.030765, 0.18467, 0.48219, 0.010112]
Predicted label: 2
Correct prediction
Energy consumption = 159.185007 pJ
sum error= 125
Actual label: 7
Output voltages: [0.22166, 0.022281, 0.0021611, 0.32201, 0.026864, 0.014778, 0.0010866, 0.79835, 0.52003, 0.74588]
Predicted label: 7
Correct prediction
Energy consumption = 149.021415 pJ
sum error= 125
Actual label: 9
Output voltages: [0.1964, 0.03775, 0.017086, 0.26555, 0.19713, 0.017002, 0.01439, 0.014974, 0.22786, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 145.181861 pJ
sum error= 125
Actual label: 1
Output voltages: [0.059581, 0.7985, 0.0264, 0.037878, 0.03923, 0.0022068, 0.62651, 0.0052341, 0.14534, 0.022797]
Predicted label: 1
Correct prediction
Energy consumption = 167.433914 pJ
sum error= 125
Actual label: 8
Output voltages: [0.0063962, 0.22847, 0.021266, 0.35169, 0.0019143, 0.19423, 0.24372, 0.0043003, 0.79852, 0.29624]
Predicted label: 8
Correct prediction
Energy consumption = 150.979405 pJ
sum error= 125
Actual label: 5
Output voltages: [0.03853, 0.0010955, 0.0064423, 0.14836, 0.015048, 0.79423, 0.054354, 0.039267, 0.74376, 0.36595]
Predicted label: 5
Correct prediction
Energy consumption = 144.175326 pJ
sum error= 125
Actual label: 2
Output voltages: [0.65957, 0.019849, 0.79879, 0.25247, 0.0036253, 0.0012086, 0.24766, 0.27313, 0.6586, 0.10847]
Predicted label: 2
Correct prediction
Energy consumption = 150.475780 pJ
sum error= 125
Actual label: 4
Output voltages: [0.0053408, 0.0023586, 0.62039, 0.0081205, 0.79859, 0.0012101, 0.042334, 0.049325, 0.020253, 0.043972]
Predicted label: 4
Correct prediction
Energy consumption = 147.436229 pJ
sum error= 125
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 225 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 225 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 225 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.056494, 0.015848, 0.026264, 0.38548, 0.40051, 0.0068942, 0.026316, 0.0177, 0.32917, 0.7984]
Predicted label: 9
Correct prediction
Energy consumption = 170.146429 pJ
sum error= 125
Actual label: 4
Output voltages: [0.041479, 0.016424, 0.075392, 0.0068939, 0.79873, 0.0041254, 0.025876, 0.11546, 0.051791, 0.43932]
Predicted label: 4
Correct prediction
Energy consumption = 149.680363 pJ
sum error= 125
Actual label: 7
Output voltages: [0.02362, 0.02933, 0.057444, 0.45832, 0.0052874, 0.0017579, 0.0010917, 0.79877, 0.26738, 0.4626]
Predicted label: 7
Correct prediction
Energy consumption = 155.876535 pJ
sum error= 125
Actual label: 2
Output voltages: [0.21426, 0.013435, 0.79878, 0.017378, 0.023436, 0.001108, 0.05464, 0.18334, 0.72821, 0.0030935]
Predicted label: 2
Correct prediction
Energy consumption = 140.474463 pJ
sum error= 125
Actual label: 2
Output voltages: [0.48362, 0.0012095, 0.79878, 0.49004, 0.015254, 0.0012073, 0.013074, 0.044945, 0.69775, 0.024778]
Predicted label: 2
Correct prediction
Energy consumption = 130.081187 pJ
sum error= 125
Actual label: 3
Output voltages: [0.11131, 0.0064385, 0.023526, 0.79869, 0.0089763, 0.0026795, 0.037754, 0.021494, 0.45834, 0.036718]
Predicted label: 3
Correct prediction
Energy consumption = 143.229453 pJ
sum error= 125
Actual label: 4
Output voltages: [0.0027346, 0.0088224, 0.19159, 0.018179, 0.79857, 0.0062746, 0.2763, 0.051522, 0.033382, 0.037693]
Predicted label: 4
Correct prediction
Energy consumption = 153.828566 pJ
sum error= 125
Actual label: 9
Output voltages: [0.76638, 0.0022263, 0.030348, 0.027788, 0.19198, 0.037917, 0.011367, 0.37244, 0.36111, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 152.425748 pJ
sum error= 125
Actual label: 1
Output voltages: [0.0042082, 0.79758, 0.28105, 0.0091329, 0.50808, 0.0010863, 0.37878, 0.0042701, 0.23959, 0.064337]
Predicted label: 1
Correct prediction
Energy consumption = 163.194257 pJ
sum error= 125
Actual label: 9
Output voltages: [0.69809, 0.0028871, 0.020854, 0.028979, 0.23358, 0.021402, 0.0074297, 0.04886, 0.064234, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 153.639964 pJ
sum error= 125
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 226 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 226 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 226 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.26927, 0.017678, 0.79879, 0.20025, 0.0091582, 0.0010985, 0.034442, 0.044702, 0.51479, 0.011247]
Predicted label: 2
Correct prediction
Energy consumption = 166.810502 pJ
sum error= 125
Actual label: 1
Output voltages: [0.039257, 0.79866, 0.14847, 0.015211, 0.22146, 0.0011014, 0.65619, 0.0014964, 0.07846, 0.041764]
Predicted label: 1
Correct prediction
Energy consumption = 157.128149 pJ
sum error= 125
Actual label: 7
Output voltages: [0.026203, 0.22096, 0.35942, 0.087987, 0.0093869, 0.0010883, 0.0010714, 0.79871, 0.059869, 0.1527]
Predicted label: 7
Correct prediction
Energy consumption = 151.530263 pJ
sum error= 125
Actual label: 9
Output voltages: [0.72291, 0.001085, 0.082114, 0.0013407, 0.23427, 0.0034979, 0.0022941, 0.0020036, 0.47687, 0.79073]
Predicted label: 9
Correct prediction
Energy consumption = 147.949304 pJ
sum error= 125
Actual label: 4
Output voltages: [0.032234, 0.0025195, 0.45602, 0.10907, 0.79863, 0.011328, 0.17437, 0.046113, 0.010788, 0.27376]
Predicted label: 4
Correct prediction
Energy consumption = 150.436260 pJ
sum error= 125
Actual label: 4
Output voltages: [0.011601, 0.0095049, 0.086741, 0.026047, 0.79865, 0.002716, 0.076465, 0.17197, 0.020124, 0.035516]
Predicted label: 4
Correct prediction
Energy consumption = 149.919173 pJ
sum error= 125
Actual label: 1
Output voltages: [0.043038, 0.5262, 0.065937, 0.78832, 0.0069161, 0.28441, 0.76476, 0.31894, 0.0025315, 0.0010937]
Predicted label: 3
Wrong prediction!
Energy consumption = 153.116861 pJ
sum error= 126
Actual label: 6
Output voltages: [0.19308, 0.13375, 0.049929, 0.0013141, 0.056868, 0.30981, 0.79872, 0.0056614, 0.28536, 0.021651]
Predicted label: 6
Correct prediction
Energy consumption = 149.437252 pJ
sum error= 126
Actual label: 7
Output voltages: [0.36961, 0.17016, 0.0023656, 0.0040035, 0.045713, 0.0093411, 0.03909, 0.79697, 0.03209, 0.40791]
Predicted label: 7
Correct prediction
Energy consumption = 149.388213 pJ
sum error= 126
Actual label: 2
Output voltages: [0.43226, 0.3632, 0.79878, 0.048244, 0.016704, 0.0013808, 0.37326, 0.081111, 0.36938, 0.062332]
Predicted label: 2
Correct prediction
Energy consumption = 152.220296 pJ
sum error= 126
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 227 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 227 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 227 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.025339, 0.30072, 0.65187, 0.015241, 0.017577, 0.0011918, 0.001066, 0.79874, 0.15525, 0.080047]
Predicted label: 7
Correct prediction
Energy consumption = 175.214941 pJ
sum error= 126
Actual label: 8
Output voltages: [0.010332, 0.050789, 0.05365, 0.045976, 0.020447, 0.010171, 0.014324, 0.034842, 0.79871, 0.33606]
Predicted label: 8
Correct prediction
Energy consumption = 154.117994 pJ
sum error= 126
Actual label: 8
Output voltages: [0.59122, 0.014045, 0.050146, 0.16713, 0.020712, 0.0344, 0.69122, 0.0068087, 0.79835, 0.01114]
Predicted label: 8
Correct prediction
Energy consumption = 147.463197 pJ
sum error= 126
Actual label: 1
Output voltages: [0.007914, 0.79874, 0.030619, 0.037793, 0.03455, 0.0010998, 0.29702, 0.047657, 0.29713, 0.036318]
Predicted label: 1
Correct prediction
Energy consumption = 155.715323 pJ
sum error= 126
Actual label: 9
Output voltages: [0.38613, 0.047368, 0.045083, 0.093968, 0.22627, 0.023765, 0.0015137, 0.0084879, 0.37765, 0.79844]
Predicted label: 9
Correct prediction
Energy consumption = 153.027476 pJ
sum error= 126
Actual label: 7
Output voltages: [0.050612, 0.021337, 0.034138, 0.10902, 0.0079889, 0.0057991, 0.0010722, 0.79858, 0.03662, 0.30861]
Predicted label: 7
Correct prediction
Energy consumption = 151.595662 pJ
sum error= 126
Actual label: 1
Output voltages: [0.029713, 0.79874, 0.0051658, 0.75066, 0.015976, 0.036344, 0.016894, 0.0010657, 0.40063, 0.76335]
Predicted label: 1
Correct prediction
Energy consumption = 159.879728 pJ
sum error= 126
Actual label: 1
Output voltages: [0.0039787, 0.79864, 0.0018678, 0.023286, 0.30958, 0.31238, 0.40949, 0.0019015, 0.035848, 0.02843]
Predicted label: 1
Correct prediction
Energy consumption = 153.997037 pJ
sum error= 126
Actual label: 7
Output voltages: [0.43471, 0.024641, 0.04205, 0.041471, 0.0015914, 0.0019203, 0.0011386, 0.79873, 0.62055, 0.18684]
Predicted label: 7
Correct prediction
Energy consumption = 154.390971 pJ
sum error= 126
Actual label: 5
Output voltages: [0.049978, 0.0010922, 0.001306, 0.28896, 0.013364, 0.79864, 0.020399, 0.11241, 0.78201, 0.018713]
Predicted label: 5
Correct prediction
Energy consumption = 138.529784 pJ
sum error= 126
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 228 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 228 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 228 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.11971, 0.0018518, 0.0010668, 0.74442, 0.18621, 0.77771, 0.015417, 0.35304, 0.028586, 0.0010717]
Predicted label: 5
Wrong prediction!
Energy consumption = 177.454811 pJ
sum error= 127
Actual label: 3
Output voltages: [0.34848, 0.013875, 0.0357, 0.79862, 0.011982, 0.024565, 0.024917, 0.012025, 0.5503, 0.095937]
Predicted label: 3
Correct prediction
Energy consumption = 142.147855 pJ
sum error= 127
Actual label: 5
Output voltages: [0.016678, 0.001066, 0.002623, 0.22545, 0.03775, 0.79839, 0.24899, 0.016037, 0.76689, 0.06695]
Predicted label: 5
Correct prediction
Energy consumption = 145.241388 pJ
sum error= 127
Actual label: 1
Output voltages: [0.0038572, 0.79855, 0.027406, 0.16813, 0.32695, 0.0081907, 0.039221, 0.0089056, 0.50139, 0.043148]
Predicted label: 1
Correct prediction
Energy consumption = 167.438953 pJ
sum error= 127
Actual label: 3
Output voltages: [0.26162, 0.0067671, 0.11643, 0.79867, 0.026493, 0.086771, 0.016788, 0.021012, 0.54368, 0.039753]
Predicted label: 3
Correct prediction
Energy consumption = 144.456943 pJ
sum error= 127
Actual label: 7
Output voltages: [0.25393, 0.0096465, 0.13795, 0.023656, 0.030993, 0.0010662, 0.0010882, 0.79863, 0.11355, 0.071816]
Predicted label: 7
Correct prediction
Energy consumption = 146.534234 pJ
sum error= 127
Actual label: 6
Output voltages: [0.23382, 0.023816, 0.21104, 0.0010665, 0.2089, 0.015361, 0.79879, 0.0032606, 0.31252, 0.023288]
Predicted label: 6
Correct prediction
Energy consumption = 154.381834 pJ
sum error= 127
Actual label: 1
Output voltages: [0.026278, 0.79854, 0.32028, 0.031501, 0.012762, 0.0010679, 0.37838, 0.0081281, 0.058431, 0.1436]
Predicted label: 1
Correct prediction
Energy consumption = 161.624218 pJ
sum error= 127
Actual label: 3
Output voltages: [0.7503, 0.013644, 0.040452, 0.79879, 0.0012007, 0.16004, 0.0054943, 0.0069978, 0.52006, 0.0023279]
Predicted label: 3
Correct prediction
Energy consumption = 147.048667 pJ
sum error= 127
Actual label: 8
Output voltages: [0.42895, 0.0057981, 0.51222, 0.024812, 0.044015, 0.009323, 0.028991, 0.0043546, 0.79878, 0.15358]
Predicted label: 8
Correct prediction
Energy consumption = 145.009585 pJ
sum error= 127
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 229 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 229 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 229 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.040602, 0.12238, 0.25158, 0.024918, 0.02264, 0.0011072, 0.0010726, 0.79871, 0.065726, 0.074689]
Predicted label: 7
Correct prediction
Energy consumption = 172.321080 pJ
sum error= 127
Actual label: 5
Output voltages: [0.3698, 0.0024655, 0.0037641, 0.33572, 0.0011606, 0.79802, 0.037135, 0.049843, 0.78329, 0.017657]
Predicted label: 5
Correct prediction
Energy consumption = 150.804672 pJ
sum error= 127
Actual label: 9
Output voltages: [0.64426, 0.015486, 0.010536, 0.43295, 0.079673, 0.01805, 0.0043049, 0.016408, 0.36325, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 148.739239 pJ
sum error= 127
Actual label: 9
Output voltages: [0.55549, 0.0042735, 0.69862, 0.0011496, 0.21962, 0.0010875, 0.78712, 0.0033387, 0.038603, 0.48558]
Predicted label: 6
Wrong prediction!
Energy consumption = 151.773425 pJ
sum error= 128
Actual label: 0
Output voltages: [0.79875, 0.0606, 0.015384, 0.02018, 0.0017097, 0.028634, 0.22468, 0.027393, 0.35914, 0.044623]
Predicted label: 0
Correct prediction
Energy consumption = 142.634948 pJ
sum error= 128
Actual label: 0
Output voltages: [0.79872, 0.16462, 0.033942, 0.0066158, 0.014245, 0.018048, 0.25185, 0.019489, 0.048674, 0.046129]
Predicted label: 0
Correct prediction
Energy consumption = 140.360045 pJ
sum error= 128
Actual label: 2
Output voltages: [0.2078, 0.48619, 0.7984, 0.33524, 0.0046463, 0.0012297, 0.37885, 0.025763, 0.6411, 0.036567]
Predicted label: 2
Correct prediction
Energy consumption = 152.068351 pJ
sum error= 128
Actual label: 8
Output voltages: [0.032843, 0.034529, 0.14029, 0.25154, 0.0053638, 0.019101, 0.039731, 0.008342, 0.79875, 0.26996]
Predicted label: 8
Correct prediction
Energy consumption = 146.762773 pJ
sum error= 128
Actual label: 8
Output voltages: [0.060589, 0.0037347, 0.026537, 0.58319, 0.0072249, 0.33228, 0.17054, 0.0036019, 0.79877, 0.055843]
Predicted label: 8
Correct prediction
Energy consumption = 143.961823 pJ
sum error= 128
Actual label: 2
Output voltages: [0.65783, 0.12503, 0.79868, 0.039702, 0.0010679, 0.001113, 0.038194, 0.69188, 0.58789, 0.043083]
Predicted label: 2
Correct prediction
Energy consumption = 142.221822 pJ
sum error= 128
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 230 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 230 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 230 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.52854, 0.013659, 0.13171, 0.79869, 0.051602, 0.012104, 0.0048792, 0.052793, 0.40933, 0.0122]
Predicted label: 3
Correct prediction
Energy consumption = 159.288930 pJ
sum error= 128
Actual label: 7
Output voltages: [0.24171, 0.17132, 0.028359, 0.22735, 0.020242, 0.0010921, 0.0011496, 0.79875, 0.24494, 0.16249]
Predicted label: 7
Correct prediction
Energy consumption = 151.121659 pJ
sum error= 128
Actual label: 1
Output voltages: [0.0046777, 0.79877, 0.13788, 0.42899, 0.061004, 0.0010685, 0.1967, 0.015151, 0.64048, 0.092153]
Predicted label: 1
Correct prediction
Energy consumption = 160.098268 pJ
sum error= 128
Actual label: 3
Output voltages: [0.25892, 0.056082, 0.04072, 0.7986, 0.021455, 0.0089385, 0.031574, 0.012982, 0.45573, 0.20726]
Predicted label: 3
Correct prediction
Energy consumption = 139.619914 pJ
sum error= 128
Actual label: 0
Output voltages: [0.78492, 0.0022077, 0.033472, 0.001082, 0.017707, 0.039405, 0.74158, 0.0011822, 0.043007, 0.1157]
Predicted label: 0
Correct prediction
Energy consumption = 151.038630 pJ
sum error= 128
Actual label: 3
Output voltages: [0.40506, 0.016764, 0.14461, 0.79876, 0.0076223, 0.014611, 0.0013971, 0.0022555, 0.72184, 0.0069802]
Predicted label: 3
Correct prediction
Energy consumption = 147.573996 pJ
sum error= 128
Actual label: 4
Output voltages: [0.0015215, 0.019081, 0.018094, 0.014694, 0.79871, 0.0017577, 0.050247, 0.02644, 0.048312, 0.040134]
Predicted label: 4
Correct prediction
Energy consumption = 151.673180 pJ
sum error= 128
Actual label: 4
Output voltages: [0.0088453, 0.0040906, 0.054933, 0.14617, 0.79877, 0.0010762, 0.033334, 0.070997, 0.12392, 0.016257]
Predicted label: 4
Correct prediction
Energy consumption = 143.211107 pJ
sum error= 128
Actual label: 3
Output voltages: [0.27773, 0.0085398, 0.18219, 0.79325, 0.0074924, 0.41201, 0.0010702, 0.22815, 0.78879, 0.010908]
Predicted label: 3
Correct prediction
Energy consumption = 149.561511 pJ
sum error= 128
Actual label: 8
Output voltages: [0.015747, 0.012952, 0.032188, 0.38188, 0.002638, 0.29865, 0.02685, 0.0029943, 0.79877, 0.15767]
Predicted label: 8
Correct prediction
Energy consumption = 138.999419 pJ
sum error= 128
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 231 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 231 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 231 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33083, 0.006582, 0.014557, 0.016658, 0.46209, 0.020596, 0.049804, 0.02038, 0.29012, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 170.558699 pJ
sum error= 128
Actual label: 2
Output voltages: [0.5645, 0.036182, 0.79786, 0.054788, 0.025091, 0.0013232, 0.3413, 0.075632, 0.64123, 0.024479]
Predicted label: 2
Correct prediction
Energy consumption = 154.321428 pJ
sum error= 128
Actual label: 3
Output voltages: [0.04329, 0.021213, 0.13291, 0.79879, 0.026239, 0.0055032, 0.0048032, 0.0064435, 0.62318, 0.022452]
Predicted label: 3
Correct prediction
Energy consumption = 135.224141 pJ
sum error= 128
Actual label: 9
Output voltages: [0.31364, 0.034997, 0.0092194, 0.75077, 0.023493, 0.010333, 0.0031235, 0.031332, 0.24945, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 149.109115 pJ
sum error= 128
Actual label: 7
Output voltages: [0.26261, 0.052515, 0.71489, 0.12899, 0.0014099, 0.0010666, 0.0010901, 0.79878, 0.32934, 0.073288]
Predicted label: 7
Correct prediction
Energy consumption = 142.820158 pJ
sum error= 128
Actual label: 1
Output voltages: [0.082013, 0.79853, 0.10119, 0.26427, 0.015418, 0.0029612, 0.099718, 0.0017876, 0.27739, 0.036172]
Predicted label: 1
Correct prediction
Energy consumption = 162.474713 pJ
sum error= 128
Actual label: 1
Output voltages: [0.22249, 0.79869, 0.75062, 0.3193, 0.057414, 0.0012054, 0.27689, 0.0011529, 0.036183, 0.2012]
Predicted label: 1
Correct prediction
Energy consumption = 151.509908 pJ
sum error= 128
Actual label: 7
Output voltages: [0.63445, 0.66696, 0.19425, 0.43948, 0.001729, 0.0014436, 0.0011248, 0.79879, 0.01443, 0.59408]
Predicted label: 7
Correct prediction
Energy consumption = 154.837482 pJ
sum error= 128
Actual label: 0
Output voltages: [0.79315, 0.012132, 0.042479, 0.0028176, 0.013449, 0.019504, 0.77194, 0.0016815, 0.11374, 0.3472]
Predicted label: 0
Correct prediction
Energy consumption = 157.495531 pJ
sum error= 128
Actual label: 4
Output voltages: [0.014901, 0.0062159, 0.27816, 0.0088161, 0.79863, 0.0046157, 0.64036, 0.081794, 0.047159, 0.024766]
Predicted label: 4
Correct prediction
Energy consumption = 144.834538 pJ
sum error= 128
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 232 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 232 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 232 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.20791, 0.10272, 0.023302, 0.083608, 0.25986, 0.047389, 0.0070903, 0.014618, 0.12116, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 169.201424 pJ
sum error= 128
Actual label: 6
Output voltages: [0.041734, 0.042495, 0.28049, 0.0026417, 0.37145, 0.16924, 0.79868, 0.0046172, 0.52838, 0.010528]
Predicted label: 6
Correct prediction
Energy consumption = 148.916242 pJ
sum error= 128
Actual label: 5
Output voltages: [0.15341, 0.0012395, 0.010338, 0.57583, 0.021278, 0.79878, 0.029653, 0.061689, 0.77595, 0.095801]
Predicted label: 5
Correct prediction
Energy consumption = 145.140337 pJ
sum error= 128
Actual label: 9
Output voltages: [0.559, 0.0035513, 0.025183, 0.033314, 0.18909, 0.065483, 0.010756, 0.093229, 0.16707, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 154.898059 pJ
sum error= 128
Actual label: 1
Output voltages: [0.017564, 0.79844, 0.016366, 0.16756, 0.034313, 0.0076754, 0.58261, 0.010002, 0.048124, 0.11157]
Predicted label: 1
Correct prediction
Energy consumption = 168.817523 pJ
sum error= 128
Actual label: 7
Output voltages: [0.06719, 0.41722, 0.5665, 0.79876, 0.024102, 0.0010691, 0.045753, 0.14542, 0.042478, 0.22791]
Predicted label: 3
Wrong prediction!
Energy consumption = 152.148102 pJ
sum error= 129
Actual label: 0
Output voltages: [0.73087, 0.0022385, 0.038791, 0.023212, 0.0062893, 0.13953, 0.21964, 0.0011152, 0.72536, 0.12253]
Predicted label: 0
Correct prediction
Energy consumption = 149.764964 pJ
sum error= 129
Actual label: 2
Output voltages: [0.086657, 0.083405, 0.79879, 0.043108, 0.015489, 0.0012274, 0.36246, 0.019677, 0.68128, 0.045775]
Predicted label: 2
Correct prediction
Energy consumption = 149.692513 pJ
sum error= 129
Actual label: 0
Output voltages: [0.79879, 0.14593, 0.035834, 0.021281, 0.0090621, 0.04548, 0.72122, 0.045712, 0.12871, 0.034788]
Predicted label: 0
Correct prediction
Energy consumption = 145.596364 pJ
sum error= 129
Actual label: 0
Output voltages: [0.79859, 0.014716, 0.78633, 0.065853, 0.001801, 0.0010806, 0.11021, 0.74053, 0.024986, 0.0068979]
Predicted label: 0
Correct prediction
Energy consumption = 132.314006 pJ
sum error= 129
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 233 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 233 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 233 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0027876, 0.0081753, 0.15428, 0.011614, 0.79866, 0.0019182, 0.079428, 0.04235, 0.046494, 0.023291]
Predicted label: 4
Correct prediction
Energy consumption = 176.035552 pJ
sum error= 129
Actual label: 6
Output voltages: [0.041835, 0.037618, 0.46052, 0.0012568, 0.64972, 0.3144, 0.79877, 0.0012604, 0.04559, 0.0011514]
Predicted label: 6
Correct prediction
Energy consumption = 144.206659 pJ
sum error= 129
Actual label: 7
Output voltages: [0.21546, 0.021484, 0.021189, 0.37806, 0.0031331, 0.0012062, 0.0010929, 0.79867, 0.059931, 0.12566]
Predicted label: 7
Correct prediction
Energy consumption = 159.997587 pJ
sum error= 129
Actual label: 0
Output voltages: [0.79833, 0.056187, 0.27871, 0.0076295, 0.0076286, 0.0011856, 0.38424, 0.022835, 0.25195, 0.26555]
Predicted label: 0
Correct prediction
Energy consumption = 149.335174 pJ
sum error= 129
Actual label: 7
Output voltages: [0.20175, 0.016341, 0.51326, 0.030455, 0.0038792, 0.0010862, 0.0011638, 0.79879, 0.76131, 0.05781]
Predicted label: 7
Correct prediction
Energy consumption = 137.833600 pJ
sum error= 129
Actual label: 1
Output voltages: [0.0033194, 0.79849, 0.079713, 0.044134, 0.11691, 0.007294, 0.4636, 0.023108, 0.15703, 0.074474]
Predicted label: 1
Correct prediction
Energy consumption = 165.111553 pJ
sum error= 129
Actual label: 4
Output voltages: [0.0010772, 0.019357, 0.032574, 0.0050391, 0.79873, 0.0011671, 0.369, 0.31293, 0.039477, 0.012005]
Predicted label: 4
Correct prediction
Energy consumption = 149.427654 pJ
sum error= 129
Actual label: 6
Output voltages: [0.2397, 0.021416, 0.30434, 0.0011657, 0.2591, 0.46936, 0.79877, 0.0032701, 0.33744, 0.014616]
Predicted label: 6
Correct prediction
Energy consumption = 135.542404 pJ
sum error= 129
Actual label: 4
Output voltages: [0.025276, 0.073629, 0.046694, 0.15561, 0.79872, 0.001083, 0.017011, 0.0080899, 0.0085964, 0.3576]
Predicted label: 4
Correct prediction
Energy consumption = 150.489386 pJ
sum error= 129
Actual label: 5
Output voltages: [0.041532, 0.0017269, 0.001183, 0.27839, 0.0040109, 0.7983, 0.039676, 0.035367, 0.77035, 0.015998]
Predicted label: 5
Correct prediction
Energy consumption = 159.558865 pJ
sum error= 129
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 234 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 234 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 234 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0066216, 0.011314, 0.21471, 0.0041908, 0.79873, 0.0015305, 0.20639, 0.044206, 0.022955, 0.045909]
Predicted label: 4
Correct prediction
Energy consumption = 174.564512 pJ
sum error= 129
Actual label: 9
Output voltages: [0.66751, 0.0033191, 0.10678, 0.037034, 0.55291, 0.023692, 0.011604, 0.0047306, 0.029109, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 153.229417 pJ
sum error= 129
Actual label: 9
Output voltages: [0.62535, 0.001168, 0.032555, 0.011751, 0.02857, 0.007112, 0.0010707, 0.30959, 0.4406, 0.79608]
Predicted label: 9
Correct prediction
Energy consumption = 146.702194 pJ
sum error= 129
Actual label: 1
Output voltages: [0.3941, 0.79873, 0.61721, 0.07856, 0.034773, 0.0013429, 0.21712, 0.078845, 0.19028, 0.090905]
Predicted label: 1
Correct prediction
Energy consumption = 164.477501 pJ
sum error= 129
Actual label: 7
Output voltages: [0.27886, 0.091043, 0.0022284, 0.040605, 0.0032949, 0.0014752, 0.0010843, 0.79864, 0.46645, 0.4525]
Predicted label: 7
Correct prediction
Energy consumption = 150.311283 pJ
sum error= 129
Actual label: 9
Output voltages: [0.46536, 0.0010992, 0.00728, 0.032075, 0.029927, 0.009376, 0.0010665, 0.71928, 0.66944, 0.76248]
Predicted label: 9
Correct prediction
Energy consumption = 150.770230 pJ
sum error= 129
Actual label: 5
Output voltages: [0.049244, 0.0011135, 0.0012447, 0.41793, 0.37629, 0.79817, 0.14889, 0.010075, 0.78799, 0.050597]
Predicted label: 5
Correct prediction
Energy consumption = 138.960163 pJ
sum error= 129
Actual label: 3
Output voltages: [0.76046, 0.0088512, 0.32052, 0.79869, 0.077898, 0.064623, 0.010195, 0.029864, 0.60925, 0.025977]
Predicted label: 3
Correct prediction
Energy consumption = 133.019831 pJ
sum error= 129
Actual label: 3
Output voltages: [0.015447, 0.038657, 0.19657, 0.79879, 0.0088509, 0.0078739, 0.0081367, 0.046871, 0.429, 0.28934]
Predicted label: 3
Correct prediction
Energy consumption = 141.875554 pJ
sum error= 129
Actual label: 8
Output voltages: [0.028444, 0.013273, 0.039426, 0.23475, 0.0063354, 0.042206, 0.016517, 0.0054631, 0.79874, 0.23642]
Predicted label: 8
Correct prediction
Energy consumption = 143.810174 pJ
sum error= 129
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 235 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 235 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 235 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.21944, 0.029026, 0.79858, 0.057828, 0.029293, 0.0010876, 0.059683, 0.050665, 0.33535, 0.017283]
Predicted label: 2
Correct prediction
Energy consumption = 154.496200 pJ
sum error= 129
Actual label: 3
Output voltages: [0.68593, 0.063607, 0.038547, 0.7576, 0.0085359, 0.63869, 0.67955, 0.21431, 0.018203, 0.0012118]
Predicted label: 3
Correct prediction
Energy consumption = 141.013017 pJ
sum error= 129
Actual label: 6
Output voltages: [0.03694, 0.0068152, 0.68629, 0.0010822, 0.048263, 0.57884, 0.79861, 0.0012443, 0.47453, 0.021976]
Predicted label: 6
Correct prediction
Energy consumption = 139.672947 pJ
sum error= 129
Actual label: 2
Output voltages: [0.58819, 0.024995, 0.79712, 0.18255, 0.081213, 0.0011755, 0.30049, 0.018418, 0.71644, 0.02089]
Predicted label: 2
Correct prediction
Energy consumption = 144.760594 pJ
sum error= 129
Actual label: 2
Output voltages: [0.28045, 0.23305, 0.79879, 0.15407, 0.023309, 0.0012992, 0.36678, 0.004058, 0.54758, 0.33705]
Predicted label: 2
Correct prediction
Energy consumption = 140.225196 pJ
sum error= 129
Actual label: 1
Output voltages: [0.038192, 0.79869, 0.01481, 0.037194, 0.047372, 0.0015204, 0.58225, 0.0010696, 0.4186, 0.03101]
Predicted label: 1
Correct prediction
Energy consumption = 159.095301 pJ
sum error= 129
Actual label: 1
Output voltages: [0.054661, 0.79835, 0.044489, 0.29415, 0.013579, 0.0086802, 0.69534, 0.024877, 0.12569, 0.09741]
Predicted label: 1
Correct prediction
Energy consumption = 146.460363 pJ
sum error= 129
Actual label: 1
Output voltages: [0.015332, 0.79859, 0.26106, 0.018295, 0.0071787, 0.0010833, 0.34881, 0.0015402, 0.27993, 0.016532]
Predicted label: 1
Correct prediction
Energy consumption = 152.673370 pJ
sum error= 129
Actual label: 1
Output voltages: [0.15794, 0.79777, 0.16581, 0.32033, 0.41254, 0.0010976, 0.10409, 0.001378, 0.047094, 0.0014343]
Predicted label: 1
Correct prediction
Energy consumption = 144.499487 pJ
sum error= 129
Actual label: 1
Output voltages: [0.097039, 0.79864, 0.038275, 0.30595, 0.025179, 0.0011804, 0.077836, 0.0018534, 0.59754, 0.2561]
Predicted label: 1
Correct prediction
Energy consumption = 153.246364 pJ
sum error= 129
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 236 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 236 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 236 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.10133, 0.037636, 0.051232, 0.01548, 0.56206, 0.23003, 0.79873, 0.0021151, 0.61782, 0.0074829]
Predicted label: 6
Correct prediction
Energy consumption = 162.765880 pJ
sum error= 129
Actual label: 9
Output voltages: [0.13299, 0.0054484, 0.15526, 0.1802, 0.7987, 0.0011001, 0.0013381, 0.0087873, 0.03307, 0.78973]
Predicted label: 4
Wrong prediction!
Energy consumption = 153.400700 pJ
sum error= 130
Actual label: 8
Output voltages: [0.038828, 0.22049, 0.18721, 0.010378, 0.05724, 0.0011743, 0.34645, 0.001067, 0.79773, 0.29645]
Predicted label: 8
Correct prediction
Energy consumption = 162.230102 pJ
sum error= 130
Actual label: 4
Output voltages: [0.0057991, 0.012035, 0.018272, 0.0026506, 0.79838, 0.039107, 0.046808, 0.57942, 0.2811, 0.00373]
Predicted label: 4
Correct prediction
Energy consumption = 149.433379 pJ
sum error= 130
Actual label: 3
Output voltages: [0.38298, 0.012654, 0.037345, 0.79863, 0.019459, 0.01975, 0.020869, 0.017275, 0.55484, 0.041047]
Predicted label: 3
Correct prediction
Energy consumption = 151.780707 pJ
sum error= 130
Actual label: 7
Output voltages: [0.28558, 0.18064, 0.062142, 0.0033668, 0.0059207, 0.0013621, 0.001066, 0.79867, 0.57897, 0.037074]
Predicted label: 7
Correct prediction
Energy consumption = 135.586810 pJ
sum error= 130
Actual label: 1
Output voltages: [0.052169, 0.79839, 0.22285, 0.26384, 0.23004, 0.0022015, 0.41642, 0.0098731, 0.0039412, 0.19103]
Predicted label: 1
Correct prediction
Energy consumption = 163.873807 pJ
sum error= 130
Actual label: 6
Output voltages: [0.1872, 0.024861, 0.023385, 0.026943, 0.59766, 0.45623, 0.79879, 0.011865, 0.74965, 0.0029351]
Predicted label: 6
Correct prediction
Energy consumption = 155.764242 pJ
sum error= 130
Actual label: 4
Output voltages: [0.011462, 0.0089701, 0.040787, 0.0026368, 0.7986, 0.0012062, 0.033908, 0.15382, 0.040228, 0.046732]
Predicted label: 4
Correct prediction
Energy consumption = 150.322296 pJ
sum error= 130
Actual label: 5
Output voltages: [0.01132, 0.014175, 0.0011538, 0.7411, 0.27148, 0.77632, 0.0468, 0.031688, 0.7128, 0.20731]
Predicted label: 5
Correct prediction
Energy consumption = 144.441494 pJ
sum error= 130
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 237 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 237 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 237 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.78173, 0.0020871, 0.014173, 0.0024998, 0.019548, 0.376, 0.76275, 0.0013944, 0.28882, 0.14454]
Predicted label: 0
Correct prediction
Energy consumption = 171.131854 pJ
sum error= 130
Actual label: 4
Output voltages: [0.013107, 0.013413, 0.3262, 0.0035273, 0.79872, 0.0012949, 0.13572, 0.0089347, 0.027916, 0.57057]
Predicted label: 4
Correct prediction
Energy consumption = 146.026828 pJ
sum error= 130
Actual label: 7
Output voltages: [0.028142, 0.13693, 0.22334, 0.05088, 0.0035054, 0.001141, 0.0026341, 0.79861, 0.04443, 0.30796]
Predicted label: 7
Correct prediction
Energy consumption = 155.379586 pJ
sum error= 130
Actual label: 4
Output voltages: [0.0013223, 0.0036508, 0.039067, 0.037941, 0.79879, 0.0010791, 0.049237, 0.071689, 0.034944, 0.010278]
Predicted label: 4
Correct prediction
Energy consumption = 149.225402 pJ
sum error= 130
Actual label: 2
Output voltages: [0.39938, 0.1681, 0.79868, 0.053059, 0.0089133, 0.0011615, 0.16758, 0.058603, 0.70312, 0.019944]
Predicted label: 2
Correct prediction
Energy consumption = 155.496007 pJ
sum error= 130
Actual label: 4
Output voltages: [0.0092238, 0.0075459, 0.18632, 0.012128, 0.7986, 0.0079274, 0.28032, 0.024977, 0.037105, 0.28422]
Predicted label: 4
Correct prediction
Energy consumption = 155.878582 pJ
sum error= 130
Actual label: 0
Output voltages: [0.79875, 0.01045, 0.10616, 0.013865, 0.028413, 0.0069103, 0.42862, 0.011686, 0.32174, 0.033468]
Predicted label: 0
Correct prediction
Energy consumption = 153.650824 pJ
sum error= 130
Actual label: 7
Output voltages: [0.05139, 0.15863, 0.38044, 0.085394, 0.010612, 0.0011352, 0.0011993, 0.79879, 0.41198, 0.33831]
Predicted label: 7
Correct prediction
Energy consumption = 143.528793 pJ
sum error= 130
Actual label: 0
Output voltages: [0.79878, 0.0012457, 0.030791, 0.0049345, 0.0090174, 0.19078, 0.26661, 0.024282, 0.68083, 0.0081159]
Predicted label: 0
Correct prediction
Energy consumption = 155.715333 pJ
sum error= 130
Actual label: 1
Output voltages: [0.0036839, 0.79865, 0.28782, 0.24332, 0.012392, 0.0011166, 0.69662, 0.0045726, 0.035719, 0.024402]
Predicted label: 1
Correct prediction
Energy consumption = 160.105836 pJ
sum error= 130
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 238 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 238 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 238 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.57457, 0.0060343, 0.26395, 0.0099841, 0.22152, 0.0055598, 0.1571, 0.0031818, 0.27744, 0.79856]
Predicted label: 9
Correct prediction
Energy consumption = 172.455053 pJ
sum error= 130
Actual label: 8
Output voltages: [0.0098076, 0.030309, 0.12568, 0.011398, 0.0096792, 0.0021997, 0.0347, 0.035534, 0.79874, 0.42398]
Predicted label: 8
Correct prediction
Energy consumption = 142.848929 pJ
sum error= 130
Actual label: 8
Output voltages: [0.037999, 0.0012764, 0.38801, 0.52429, 0.0058996, 0.0054792, 0.010178, 0.045067, 0.79868, 0.072608]
Predicted label: 8
Correct prediction
Energy consumption = 148.046326 pJ
sum error= 130
Actual label: 6
Output voltages: [0.077024, 0.18623, 0.40971, 0.0027169, 0.18326, 0.12287, 0.79872, 0.0014597, 0.4759, 0.005302]
Predicted label: 6
Correct prediction
Energy consumption = 149.517398 pJ
sum error= 130
Actual label: 0
Output voltages: [0.79877, 0.029646, 0.048851, 0.048348, 0.0092367, 0.016963, 0.53797, 0.033269, 0.24362, 0.41344]
Predicted label: 0
Correct prediction
Energy consumption = 161.144812 pJ
sum error= 130
Actual label: 0
Output voltages: [0.79831, 0.18955, 0.025491, 0.0065522, 0.0032071, 0.0022288, 0.67451, 0.038591, 0.15822, 0.15101]
Predicted label: 0
Correct prediction
Energy consumption = 133.630120 pJ
sum error= 130
Actual label: 4
Output voltages: [0.0039059, 0.014168, 0.01527, 0.0026834, 0.79858, 0.01096, 0.030524, 0.16629, 0.282, 0.057149]
Predicted label: 4
Correct prediction
Energy consumption = 158.344091 pJ
sum error= 130
Actual label: 9
Output voltages: [0.082575, 0.79325, 0.022295, 0.019586, 0.11504, 0.0049519, 0.012985, 0.0045581, 0.067243, 0.39374]
Predicted label: 1
Wrong prediction!
Energy consumption = 159.277781 pJ
sum error= 131
Actual label: 6
Output voltages: [0.091331, 0.024712, 0.16293, 0.0028769, 0.23504, 0.067953, 0.79879, 0.0068126, 0.71344, 0.0047112]
Predicted label: 6
Correct prediction
Energy consumption = 157.346364 pJ
sum error= 131
Actual label: 8
Output voltages: [0.0062885, 0.029278, 0.040769, 0.13689, 0.017528, 0.023145, 0.060878, 0.0022422, 0.79878, 0.3754]
Predicted label: 8
Correct prediction
Energy consumption = 147.432430 pJ
sum error= 131
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 239 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 239 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 239 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.22236, 0.25417, 0.79878, 0.075315, 0.0087208, 0.0013797, 0.26085, 0.030026, 0.35401, 0.07349]
Predicted label: 2
Correct prediction
Energy consumption = 168.376302 pJ
sum error= 131
Actual label: 2
Output voltages: [0.29506, 0.067205, 0.79879, 0.049857, 0.0074867, 0.0012298, 0.30207, 0.026312, 0.61673, 0.023381]
Predicted label: 2
Correct prediction
Energy consumption = 137.028589 pJ
sum error= 131
Actual label: 3
Output voltages: [0.38495, 0.045475, 0.051907, 0.79869, 0.0030251, 0.0055091, 0.016594, 0.019953, 0.55839, 0.039242]
Predicted label: 3
Correct prediction
Energy consumption = 151.032554 pJ
sum error= 131
Actual label: 8
Output voltages: [0.013462, 0.0032549, 0.12299, 0.36068, 0.010967, 0.016459, 0.021324, 0.0011126, 0.7966, 0.43124]
Predicted label: 8
Correct prediction
Energy consumption = 144.560980 pJ
sum error= 131
Actual label: 4
Output voltages: [0.031029, 0.017879, 0.30681, 0.0092945, 0.79869, 0.0011005, 0.047738, 0.041915, 0.025415, 0.66295]
Predicted label: 4
Correct prediction
Energy consumption = 145.911347 pJ
sum error= 131
Actual label: 8
Output voltages: [0.28002, 0.016023, 0.096811, 0.33127, 0.023762, 0.020795, 0.3117, 0.0010672, 0.79602, 0.0047937]
Predicted label: 8
Correct prediction
Energy consumption = 154.054079 pJ
sum error= 131
Actual label: 2
Output voltages: [0.61731, 0.01734, 0.79879, 0.1029, 0.0037467, 0.0012564, 0.31228, 0.13372, 0.41223, 0.001101]
Predicted label: 2
Correct prediction
Energy consumption = 142.969048 pJ
sum error= 131
Actual label: 2
Output voltages: [0.15999, 0.087193, 0.7985, 0.096353, 0.0013919, 0.0013149, 0.05502, 0.028379, 0.50975, 0.019383]
Predicted label: 2
Correct prediction
Energy consumption = 144.017816 pJ
sum error= 131
Actual label: 1
Output voltages: [0.033576, 0.79877, 0.027653, 0.028326, 0.015005, 0.0028452, 0.035566, 0.0037277, 0.76442, 0.01004]
Predicted label: 1
Correct prediction
Energy consumption = 151.644840 pJ
sum error= 131
Actual label: 7
Output voltages: [0.095675, 0.059974, 0.23206, 0.047405, 0.0048234, 0.0012917, 0.0011485, 0.79855, 0.090048, 0.24408]
Predicted label: 7
Correct prediction
Energy consumption = 148.836892 pJ
sum error= 131
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 240 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 240 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 240 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.036901, 0.0010679, 0.005377, 0.60627, 0.0034344, 0.79879, 0.013102, 0.30731, 0.67339, 0.03562]
Predicted label: 5
Correct prediction
Energy consumption = 160.523079 pJ
sum error= 131
Actual label: 4
Output voltages: [0.0011603, 0.002394, 0.12164, 0.022415, 0.79861, 0.0011363, 0.22151, 0.15058, 0.030774, 0.071996]
Predicted label: 4
Correct prediction
Energy consumption = 161.249778 pJ
sum error= 131
Actual label: 4
Output voltages: [0.0032074, 0.0091573, 0.082569, 0.021415, 0.79859, 0.0027004, 0.19735, 0.12626, 0.035454, 0.021614]
Predicted label: 4
Correct prediction
Energy consumption = 146.820615 pJ
sum error= 131
Actual label: 0
Output voltages: [0.79874, 0.063434, 0.022291, 0.10036, 0.0037246, 0.16336, 0.35286, 0.010047, 0.020649, 0.080261]
Predicted label: 0
Correct prediction
Energy consumption = 164.657228 pJ
sum error= 131
Actual label: 4
Output voltages: [0.010716, 0.0037031, 0.31347, 0.013038, 0.79851, 0.0025112, 0.53985, 0.023026, 0.033339, 0.036414]
Predicted label: 4
Correct prediction
Energy consumption = 145.975625 pJ
sum error= 131
Actual label: 3
Output voltages: [0.72765, 0.0038551, 0.44453, 0.79879, 0.0045522, 0.025597, 0.0065334, 0.039571, 0.24147, 0.0044734]
Predicted label: 3
Correct prediction
Energy consumption = 152.443710 pJ
sum error= 131
Actual label: 9
Output voltages: [0.37701, 0.52206, 0.011154, 0.03419, 0.15247, 0.0011064, 0.021749, 0.011959, 0.40447, 0.75576]
Predicted label: 9
Correct prediction
Energy consumption = 156.024606 pJ
sum error= 131
Actual label: 7
Output voltages: [0.22692, 0.048105, 0.021089, 0.040515, 0.0089329, 0.012652, 0.0010758, 0.79867, 0.46069, 0.35457]
Predicted label: 7
Correct prediction
Energy consumption = 155.661667 pJ
sum error= 131
Actual label: 3
Output voltages: [0.16114, 0.036731, 0.024202, 0.79872, 0.043247, 0.036378, 0.0055146, 0.007036, 0.25543, 0.043026]
Predicted label: 3
Correct prediction
Energy consumption = 153.627126 pJ
sum error= 131
Actual label: 1
Output voltages: [0.082461, 0.79877, 0.20294, 0.060907, 0.16735, 0.0011564, 0.12845, 0.010429, 0.29943, 0.16789]
Predicted label: 1
Correct prediction
Energy consumption = 161.273240 pJ
sum error= 131
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 241 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 241 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 241 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.01315, 0.048302, 0.19994, 0.0023406, 0.0013465, 0.11965, 0.030766, 0.052144, 0.036148]
Predicted label: 0
Correct prediction
Energy consumption = 177.336746 pJ
sum error= 131
Actual label: 1
Output voltages: [0.090636, 0.79835, 0.020121, 0.091741, 0.003708, 0.0020479, 0.61217, 0.0058092, 0.1487, 0.17847]
Predicted label: 1
Correct prediction
Energy consumption = 165.333488 pJ
sum error= 131
Actual label: 2
Output voltages: [0.16946, 0.24717, 0.79874, 0.011424, 0.014523, 0.0013389, 0.1163, 0.025336, 0.2815, 0.16309]
Predicted label: 2
Correct prediction
Energy consumption = 142.789100 pJ
sum error= 131
Actual label: 5
Output voltages: [0.20919, 0.0011875, 0.0011633, 0.38021, 0.033666, 0.79868, 0.27155, 0.19743, 0.79482, 0.0067842]
Predicted label: 5
Correct prediction
Energy consumption = 152.485511 pJ
sum error= 131
Actual label: 9
Output voltages: [0.035562, 0.0023018, 0.053968, 0.022941, 0.77797, 0.0011654, 0.0015178, 0.032832, 0.54066, 0.54385]
Predicted label: 4
Wrong prediction!
Energy consumption = 155.597678 pJ
sum error= 132
Actual label: 2
Output voltages: [0.29911, 0.010787, 0.79877, 0.030702, 0.039122, 0.0013272, 0.15309, 0.036109, 0.61169, 0.07065]
Predicted label: 2
Correct prediction
Energy consumption = 148.170263 pJ
sum error= 132
Actual label: 1
Output voltages: [0.012017, 0.79871, 0.014254, 0.12459, 0.030137, 0.0016871, 0.77337, 0.0014747, 0.48664, 0.012504]
Predicted label: 1
Correct prediction
Energy consumption = 156.142545 pJ
sum error= 132
Actual label: 0
Output voltages: [0.79509, 0.044702, 0.065701, 0.02111, 0.021474, 0.0011778, 0.68926, 0.0035833, 0.26003, 0.020818]
Predicted label: 0
Correct prediction
Energy consumption = 146.362503 pJ
sum error= 132
Actual label: 1
Output voltages: [0.12865, 0.79853, 0.019237, 0.017305, 0.40958, 0.0050059, 0.3167, 0.0060214, 0.018681, 0.064515]
Predicted label: 1
Correct prediction
Energy consumption = 163.304522 pJ
sum error= 132
Actual label: 8
Output voltages: [0.13702, 0.023426, 0.038445, 0.56279, 0.0014323, 0.020575, 0.022386, 0.0014796, 0.79877, 0.36694]
Predicted label: 8
Correct prediction
Energy consumption = 149.500877 pJ
sum error= 132
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 242 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 242 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 242 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.15855, 0.011182, 0.026893, 0.1486, 0.36037, 0.015461, 0.061024, 0.008414, 0.068616, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 164.372036 pJ
sum error= 132
Actual label: 1
Output voltages: [0.02435, 0.79858, 0.051625, 0.62831, 0.007728, 0.0039876, 0.15393, 0.012026, 0.0048413, 0.29236]
Predicted label: 1
Correct prediction
Energy consumption = 171.041262 pJ
sum error= 132
Actual label: 6
Output voltages: [0.57879, 0.0024123, 0.0079167, 0.002065, 0.75294, 0.0038451, 0.76069, 0.21249, 0.047065, 0.058304]
Predicted label: 6
Correct prediction
Energy consumption = 158.402683 pJ
sum error= 132
Actual label: 8
Output voltages: [0.012876, 0.047796, 0.16788, 0.028006, 0.0095743, 0.021848, 0.013877, 0.0046935, 0.79879, 0.53474]
Predicted label: 8
Correct prediction
Energy consumption = 149.344386 pJ
sum error= 132
Actual label: 3
Output voltages: [0.26768, 0.010321, 0.047439, 0.79862, 0.038715, 0.023986, 0.012109, 0.036884, 0.39618, 0.086422]
Predicted label: 3
Correct prediction
Energy consumption = 151.469194 pJ
sum error= 132
Actual label: 8
Output voltages: [0.013015, 0.04381, 0.031624, 0.11916, 0.0068274, 0.047025, 0.0078061, 0.27603, 0.79869, 0.13266]
Predicted label: 8
Correct prediction
Energy consumption = 149.364834 pJ
sum error= 132
Actual label: 9
Output voltages: [0.33472, 0.0011288, 0.016953, 0.29364, 0.13774, 0.0032742, 0.0016869, 0.57772, 0.3218, 0.77026]
Predicted label: 9
Correct prediction
Energy consumption = 157.371149 pJ
sum error= 132
Actual label: 3
Output voltages: [0.23187, 0.02186, 0.08748, 0.79876, 0.0057845, 0.0040478, 0.0072994, 0.0036387, 0.53227, 0.050488]
Predicted label: 3
Correct prediction
Energy consumption = 139.434829 pJ
sum error= 132
Actual label: 6
Output voltages: [0.028251, 0.085283, 0.62907, 0.0010666, 0.19104, 0.04427, 0.79876, 0.0031861, 0.38674, 0.0034748]
Predicted label: 6
Correct prediction
Energy consumption = 153.880230 pJ
sum error= 132
Actual label: 2
Output voltages: [0.26211, 0.71194, 0.79854, 0.018511, 0.0030699, 0.00138, 0.047285, 0.33183, 0.25604, 0.0073267]
Predicted label: 2
Correct prediction
Energy consumption = 145.534194 pJ
sum error= 132
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 243 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 243 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 243 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.018511, 0.043261, 0.053395, 0.45861, 0.0012632, 0.037939, 0.02295, 0.0084827, 0.79879, 0.26834]
Predicted label: 8
Correct prediction
Energy consumption = 171.148816 pJ
sum error= 132
Actual label: 3
Output voltages: [0.77506, 0.0048358, 0.21252, 0.79872, 0.035751, 0.070787, 0.0019616, 0.029954, 0.5402, 0.023627]
Predicted label: 3
Correct prediction
Energy consumption = 147.040282 pJ
sum error= 132
Actual label: 2
Output voltages: [0.24895, 0.47842, 0.79875, 0.03945, 0.015713, 0.0013539, 0.2137, 0.074333, 0.14955, 0.19774]
Predicted label: 2
Correct prediction
Energy consumption = 146.855921 pJ
sum error= 132
Actual label: 2
Output voltages: [0.010717, 0.24375, 0.79698, 0.13687, 0.0044312, 0.0012536, 0.023041, 0.11041, 0.61936, 0.023548]
Predicted label: 2
Correct prediction
Energy consumption = 140.309248 pJ
sum error= 132
Actual label: 1
Output voltages: [0.032404, 0.79868, 0.50583, 0.41549, 0.0012353, 0.0011053, 0.25978, 0.0044453, 0.24551, 0.11901]
Predicted label: 1
Correct prediction
Energy consumption = 154.803216 pJ
sum error= 132
Actual label: 0
Output voltages: [0.79869, 0.082463, 0.084318, 0.0054279, 0.01339, 0.016176, 0.43134, 0.011652, 0.13437, 0.032537]
Predicted label: 0
Correct prediction
Energy consumption = 154.746900 pJ
sum error= 132
Actual label: 4
Output voltages: [0.0257, 0.0017637, 0.32095, 0.010913, 0.7986, 0.0016192, 0.13017, 0.029375, 0.027246, 0.16333]
Predicted label: 4
Correct prediction
Energy consumption = 152.802803 pJ
sum error= 132
Actual label: 2
Output voltages: [0.28551, 0.72119, 0.79536, 0.036212, 0.069549, 0.0016099, 0.023759, 0.35171, 0.13848, 0.0048372]
Predicted label: 2
Correct prediction
Energy consumption = 145.237033 pJ
sum error= 132
Actual label: 9
Output voltages: [0.44658, 0.0217, 0.0091582, 0.047238, 0.084866, 0.0067592, 0.0013105, 0.040322, 0.26438, 0.79856]
Predicted label: 9
Correct prediction
Energy consumption = 162.512303 pJ
sum error= 132
Actual label: 2
Output voltages: [0.52678, 0.027606, 0.79879, 0.15553, 0.0020465, 0.0010686, 0.37084, 0.022027, 0.76758, 0.018077]
Predicted label: 2
Correct prediction
Energy consumption = 148.844972 pJ
sum error= 132
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 244 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 244 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 244 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0038983, 0.018304, 0.25699, 0.025103, 0.79859, 0.016486, 0.2085, 0.45113, 0.036452, 0.023424]
Predicted label: 4
Correct prediction
Energy consumption = 168.305992 pJ
sum error= 132
Actual label: 3
Output voltages: [0.26439, 0.041732, 0.074441, 0.7987, 0.010586, 0.0014377, 0.019961, 0.037677, 0.2112, 0.11525]
Predicted label: 3
Correct prediction
Energy consumption = 154.478981 pJ
sum error= 132
Actual label: 7
Output voltages: [0.70436, 0.033471, 0.74763, 0.014282, 0.001078, 0.00124, 0.0014231, 0.7987, 0.6815, 0.1926]
Predicted label: 7
Correct prediction
Energy consumption = 154.781263 pJ
sum error= 132
Actual label: 9
Output voltages: [0.28535, 0.010059, 0.028179, 0.019354, 0.089098, 0.023249, 0.014451, 0.041361, 0.49059, 0.79601]
Predicted label: 9
Correct prediction
Energy consumption = 148.349872 pJ
sum error= 132
Actual label: 1
Output voltages: [0.10443, 0.79835, 0.20203, 0.1788, 0.0053749, 0.0037632, 0.69333, 0.0023602, 0.019215, 0.04357]
Predicted label: 1
Correct prediction
Energy consumption = 168.236919 pJ
sum error= 132
Actual label: 5
Output voltages: [0.01794, 0.0013724, 0.0010687, 0.1308, 0.13963, 0.79632, 0.035936, 0.063966, 0.49546, 0.12449]
Predicted label: 5
Correct prediction
Energy consumption = 155.476384 pJ
sum error= 132
Actual label: 2
Output voltages: [0.45252, 0.65218, 0.79879, 0.39137, 0.0064547, 0.0012267, 0.40555, 0.0064502, 0.19914, 0.093444]
Predicted label: 2
Correct prediction
Energy consumption = 155.465040 pJ
sum error= 132
Actual label: 4
Output voltages: [0.37374, 0.018808, 0.018869, 0.042266, 0.7984, 0.0011024, 0.0064473, 0.13884, 0.005984, 0.78543]
Predicted label: 4
Correct prediction
Energy consumption = 156.453789 pJ
sum error= 132
Actual label: 9
Output voltages: [0.14606, 0.019443, 0.011412, 0.02405, 0.082173, 0.014628, 0.010023, 0.010582, 0.46804, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 146.268735 pJ
sum error= 132
Actual label: 0
Output voltages: [0.79588, 0.13882, 0.023354, 0.023959, 0.017285, 0.0040123, 0.75631, 0.055992, 0.237, 0.20219]
Predicted label: 0
Correct prediction
Energy consumption = 159.264786 pJ
sum error= 132
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 245 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 245 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 245 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.040103, 0.0012209, 0.023372, 0.79852, 0.0095064, 0.61245, 0.049992, 0.029911, 0.2705, 0.0016732]
Predicted label: 3
Correct prediction
Energy consumption = 166.662613 pJ
sum error= 132
Actual label: 8
Output voltages: [0.0075748, 0.081441, 0.086079, 0.12458, 0.0085909, 0.029739, 0.015761, 0.061348, 0.79874, 0.13423]
Predicted label: 8
Correct prediction
Energy consumption = 153.844342 pJ
sum error= 132
Actual label: 5
Output voltages: [0.033615, 0.0014462, 0.0046527, 0.31375, 0.014831, 0.79878, 0.11159, 0.14371, 0.75248, 0.04023]
Predicted label: 5
Correct prediction
Energy consumption = 146.650462 pJ
sum error= 132
Actual label: 3
Output voltages: [0.19175, 0.045128, 0.08767, 0.79858, 0.031556, 0.017005, 0.020389, 0.056805, 0.30743, 0.24872]
Predicted label: 3
Correct prediction
Energy consumption = 145.598138 pJ
sum error= 132
Actual label: 6
Output voltages: [0.42793, 0.019077, 0.0096144, 0.28771, 0.0027331, 0.79402, 0.79719, 0.0064798, 0.59764, 0.0078746]
Predicted label: 6
Correct prediction
Energy consumption = 158.999999 pJ
sum error= 132
Actual label: 0
Output voltages: [0.79251, 0.029157, 0.24868, 0.0098107, 0.01137, 0.0022285, 0.76949, 0.022749, 0.092739, 0.086085]
Predicted label: 0
Correct prediction
Energy consumption = 144.830904 pJ
sum error= 132
Actual label: 9
Output voltages: [0.037633, 0.017251, 0.023742, 0.050245, 0.017122, 0.0066205, 0.0025693, 0.020948, 0.66417, 0.79335]
Predicted label: 9
Correct prediction
Energy consumption = 149.191819 pJ
sum error= 132
Actual label: 4
Output voltages: [0.0014798, 0.010566, 0.060106, 0.0013807, 0.78098, 0.0047658, 0.33575, 0.032376, 0.75253, 0.021391]
Predicted label: 4
Correct prediction
Energy consumption = 144.527640 pJ
sum error= 132
Actual label: 6
Output voltages: [0.12185, 0.035594, 0.079092, 0.0096648, 0.32994, 0.33864, 0.7987, 0.0017216, 0.63087, 0.012898]
Predicted label: 6
Correct prediction
Energy consumption = 148.265656 pJ
sum error= 132
Actual label: 2
Output voltages: [0.32083, 0.61965, 0.79877, 0.079447, 0.0027115, 0.0011956, 0.036367, 0.34364, 0.034295, 0.13501]
Predicted label: 2
Correct prediction
Energy consumption = 159.847468 pJ
sum error= 132
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 246 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 246 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 246 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.023775, 0.0011507, 0.0010667, 0.27487, 0.45363, 0.79877, 0.52876, 0.015509, 0.77763, 0.028797]
Predicted label: 5
Correct prediction
Energy consumption = 167.049579 pJ
sum error= 132
Actual label: 0
Output voltages: [0.79876, 0.032761, 0.17466, 0.042197, 0.041715, 0.0018307, 0.28431, 0.012254, 0.036657, 0.38611]
Predicted label: 0
Correct prediction
Energy consumption = 159.166531 pJ
sum error= 132
Actual label: 2
Output voltages: [0.77715, 0.021635, 0.56734, 0.028155, 0.0065713, 0.001128, 0.44504, 0.0056374, 0.71044, 0.15259]
Predicted label: 0
Wrong prediction!
Energy consumption = 147.936925 pJ
sum error= 133
Actual label: 7
Output voltages: [0.27997, 0.13474, 0.37894, 0.038525, 0.0043915, 0.0010674, 0.0011343, 0.79879, 0.12447, 0.47287]
Predicted label: 7
Correct prediction
Energy consumption = 152.953261 pJ
sum error= 133
Actual label: 4
Output voltages: [0.012919, 0.0017446, 0.20312, 0.014771, 0.79859, 0.012702, 0.25515, 0.0062262, 0.062233, 0.62253]
Predicted label: 4
Correct prediction
Energy consumption = 154.980632 pJ
sum error= 133
Actual label: 6
Output voltages: [0.058221, 0.019314, 0.11381, 0.0046203, 0.35817, 0.72374, 0.79876, 0.0010993, 0.38138, 0.0043003]
Predicted label: 6
Correct prediction
Energy consumption = 147.134478 pJ
sum error= 133
Actual label: 6
Output voltages: [0.059306, 0.044418, 0.049602, 0.0046323, 0.23021, 0.74361, 0.79872, 0.0019293, 0.30656, 0.073334]
Predicted label: 6
Correct prediction
Energy consumption = 126.217616 pJ
sum error= 133
Actual label: 8
Output voltages: [0.011946, 0.025757, 0.17873, 0.1057, 0.014085, 0.022271, 0.041725, 0.025557, 0.79879, 0.22575]
Predicted label: 8
Correct prediction
Energy consumption = 146.327403 pJ
sum error= 133
Actual label: 6
Output voltages: [0.053542, 0.30078, 0.11032, 0.0069122, 0.10225, 0.34033, 0.79859, 0.0071457, 0.19771, 0.020568]
Predicted label: 6
Correct prediction
Energy consumption = 150.359720 pJ
sum error= 133
Actual label: 6
Output voltages: [0.46712, 0.1004, 0.071156, 0.0021172, 0.21269, 0.21664, 0.79876, 0.016268, 0.4543, 0.0018455]
Predicted label: 6
Correct prediction
Energy consumption = 143.807564 pJ
sum error= 133
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 247 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 247 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 247 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.17556, 0.019417, 0.045256, 0.023216, 0.01753, 0.037128, 0.008249, 0.050552, 0.79876, 0.41772]
Predicted label: 8
Correct prediction
Energy consumption = 170.181906 pJ
sum error= 133
Actual label: 6
Output voltages: [0.046778, 0.023433, 0.26385, 0.0022621, 0.46602, 0.064329, 0.79874, 0.0017856, 0.61351, 0.0062257]
Predicted label: 6
Correct prediction
Energy consumption = 149.085388 pJ
sum error= 133
Actual label: 9
Output voltages: [0.36931, 0.0024318, 0.0031176, 0.048466, 0.43002, 0.0046227, 0.0061697, 0.0033685, 0.56286, 0.79737]
Predicted label: 9
Correct prediction
Energy consumption = 152.926935 pJ
sum error= 133
Actual label: 1
Output voltages: [0.045839, 0.79874, 0.0057735, 0.035597, 0.18771, 0.010416, 0.43015, 0.0030612, 0.46887, 0.028464]
Predicted label: 1
Correct prediction
Energy consumption = 163.849170 pJ
sum error= 133
Actual label: 7
Output voltages: [0.15087, 0.065111, 0.05028, 0.25074, 0.012833, 0.0010691, 0.0011141, 0.79879, 0.64917, 0.048143]
Predicted label: 7
Correct prediction
Energy consumption = 158.914176 pJ
sum error= 133
Actual label: 2
Output voltages: [0.026591, 0.14831, 0.79876, 0.029061, 0.0018421, 0.0012377, 0.054135, 0.086921, 0.5741, 0.033728]
Predicted label: 2
Correct prediction
Energy consumption = 142.599576 pJ
sum error= 133
Actual label: 5
Output voltages: [0.083342, 0.016543, 0.0013316, 0.76676, 0.0099804, 0.79657, 0.30388, 0.060535, 0.3585, 0.018606]
Predicted label: 5
Correct prediction
Energy consumption = 142.391364 pJ
sum error= 133
Actual label: 9
Output voltages: [0.106, 0.0039107, 0.034368, 0.006426, 0.38505, 0.022852, 0.023186, 0.02241, 0.34757, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 148.540334 pJ
sum error= 133
Actual label: 9
Output voltages: [0.32592, 0.0067977, 0.030754, 0.10704, 0.15812, 0.1027, 0.0018923, 0.027773, 0.094642, 0.79736]
Predicted label: 9
Correct prediction
Energy consumption = 147.977229 pJ
sum error= 133
Actual label: 0
Output voltages: [0.79866, 0.070698, 0.058627, 0.012512, 0.011676, 0.0032035, 0.31346, 0.02784, 0.050165, 0.30059]
Predicted label: 0
Correct prediction
Energy consumption = 149.245400 pJ
sum error= 133
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 248 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 248 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 248 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.5496, 0.11424, 0.76105, 0.0047533, 0.0028629, 0.0010703, 0.0019052, 0.79089, 0.059287, 0.68843]
Predicted label: 7
Correct prediction
Energy consumption = 166.279736 pJ
sum error= 133
Actual label: 2
Output voltages: [0.25848, 0.01413, 0.79878, 0.1743, 0.025429, 0.0012698, 0.31018, 0.10501, 0.72831, 0.044564]
Predicted label: 2
Correct prediction
Energy consumption = 144.171154 pJ
sum error= 133
Actual label: 7
Output voltages: [0.04648, 0.05876, 0.20344, 0.26781, 0.0010712, 0.0010873, 0.0011225, 0.79879, 0.74265, 0.14087]
Predicted label: 7
Correct prediction
Energy consumption = 155.779710 pJ
sum error= 133
Actual label: 6
Output voltages: [0.18835, 0.13864, 0.2672, 0.012035, 0.26023, 0.15458, 0.79874, 0.0011584, 0.18705, 0.018181]
Predicted label: 6
Correct prediction
Energy consumption = 149.777559 pJ
sum error= 133
Actual label: 7
Output voltages: [0.055433, 0.005329, 0.005008, 0.02062, 0.031609, 0.0086662, 0.0011224, 0.79879, 0.65346, 0.56556]
Predicted label: 7
Correct prediction
Energy consumption = 158.922536 pJ
sum error= 133
Actual label: 0
Output voltages: [0.79878, 0.18341, 0.010778, 0.033524, 0.0049824, 0.045082, 0.37712, 0.036008, 0.043543, 0.025499]
Predicted label: 0
Correct prediction
Energy consumption = 155.060331 pJ
sum error= 133
Actual label: 6
Output voltages: [0.11381, 0.01575, 0.43562, 0.0013148, 0.1683, 0.25442, 0.79878, 0.0054222, 0.4775, 0.0044016]
Predicted label: 6
Correct prediction
Energy consumption = 141.087467 pJ
sum error= 133
Actual label: 5
Output voltages: [0.012233, 0.0020714, 0.0011172, 0.07889, 0.046026, 0.79875, 0.33042, 0.012253, 0.72934, 0.051262]
Predicted label: 5
Correct prediction
Energy consumption = 151.510160 pJ
sum error= 133
Actual label: 2
Output voltages: [0.32594, 0.29483, 0.7376, 0.0031006, 0.16554, 0.0012849, 0.031841, 0.58199, 0.47469, 0.0056358]
Predicted label: 2
Correct prediction
Energy consumption = 163.327697 pJ
sum error= 133
Actual label: 4
Output voltages: [0.0040891, 0.0068106, 0.14453, 0.0084998, 0.79863, 0.0027016, 0.27884, 0.017929, 0.044835, 0.16994]
Predicted label: 4
Correct prediction
Energy consumption = 150.862173 pJ
sum error= 133
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 249 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 249 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 249 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.033533, 0.14693, 0.36337, 0.018005, 0.013072, 0.0011562, 0.0011841, 0.79879, 0.45084, 0.040432]
Predicted label: 7
Correct prediction
Energy consumption = 167.114807 pJ
sum error= 133
Actual label: 2
Output voltages: [0.39865, 0.2578, 0.79879, 0.44285, 0.023631, 0.001246, 0.04228, 0.17993, 0.089046, 0.037559]
Predicted label: 2
Correct prediction
Energy consumption = 142.636616 pJ
sum error= 133
Actual label: 0
Output voltages: [0.79878, 0.54422, 0.019792, 0.0088277, 0.015807, 0.0068727, 0.49325, 0.027189, 0.10523, 0.48761]
Predicted label: 0
Correct prediction
Energy consumption = 147.370740 pJ
sum error= 133
Actual label: 9
Output voltages: [0.51237, 0.017714, 0.031712, 0.22109, 0.31695, 0.011577, 0.0010756, 0.12032, 0.12945, 0.7985]
Predicted label: 9
Correct prediction
Energy consumption = 152.574906 pJ
sum error= 133
Actual label: 9
Output voltages: [0.34234, 0.0056062, 0.021741, 0.26817, 0.35787, 0.060841, 0.02103, 0.011951, 0.063003, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 145.418160 pJ
sum error= 133
Actual label: 2
Output voltages: [0.35211, 0.027717, 0.79877, 0.1807, 0.047944, 0.0012146, 0.033232, 0.03205, 0.33708, 0.02674]
Predicted label: 2
Correct prediction
Energy consumption = 147.149720 pJ
sum error= 133
Actual label: 2
Output voltages: [0.052128, 0.034728, 0.79839, 0.60812, 0.010873, 0.0012085, 0.020596, 0.038031, 0.22352, 0.0086728]
Predicted label: 2
Correct prediction
Energy consumption = 135.779328 pJ
sum error= 133
Actual label: 9
Output voltages: [0.237, 0.018518, 0.01065, 0.050224, 0.12171, 0.0078148, 0.0011382, 0.0031865, 0.45494, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 144.935012 pJ
sum error= 133
Actual label: 4
Output voltages: [0.0062695, 0.011729, 0.15845, 0.023859, 0.79858, 0.025869, 0.13386, 0.079136, 0.019796, 0.32369]
Predicted label: 4
Correct prediction
Energy consumption = 154.703069 pJ
sum error= 133
Actual label: 4
Output voltages: [0.0035759, 0.0053765, 0.23567, 0.0064875, 0.79855, 0.0020599, 0.14619, 0.27251, 0.036181, 0.27298]
Predicted label: 4
Correct prediction
Energy consumption = 144.309347 pJ
sum error= 133
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 250 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 250 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 250 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.24296, 0.29176, 0.79878, 0.050539, 0.031964, 0.0012928, 0.34909, 0.17261, 0.44787, 0.046351]
Predicted label: 2
Correct prediction
Energy consumption = 167.367547 pJ
sum error= 133
Actual label: 3
Output voltages: [0.7532, 0.012236, 0.029487, 0.79865, 0.013047, 0.0278, 0.010071, 0.025893, 0.29612, 0.044939]
Predicted label: 3
Correct prediction
Energy consumption = 144.673098 pJ
sum error= 133
Actual label: 3
Output voltages: [0.68505, 0.19797, 0.063693, 0.79872, 0.0089663, 0.01072, 0.027025, 0.0030775, 0.48968, 0.01499]
Predicted label: 3
Correct prediction
Energy consumption = 138.945569 pJ
sum error= 133
Actual label: 2
Output voltages: [0.48135, 0.025421, 0.79874, 0.074812, 0.03181, 0.0010976, 0.15535, 0.042325, 0.36931, 0.0040663]
Predicted label: 2
Correct prediction
Energy consumption = 143.776136 pJ
sum error= 133
Actual label: 1
Output voltages: [0.0051769, 0.79841, 0.21758, 0.36201, 0.012055, 0.0018007, 0.34683, 0.028962, 0.014536, 0.080474]
Predicted label: 1
Correct prediction
Energy consumption = 160.017198 pJ
sum error= 133
Actual label: 7
Output voltages: [0.60861, 0.032572, 0.0046127, 0.0015098, 0.028098, 0.058946, 0.001553, 0.79876, 0.27473, 0.047104]
Predicted label: 7
Correct prediction
Energy consumption = 160.405969 pJ
sum error= 133
Actual label: 0
Output voltages: [0.7987, 0.048808, 0.027156, 0.0050515, 0.04923, 0.010141, 0.76214, 0.0079095, 0.033954, 0.17506]
Predicted label: 0
Correct prediction
Energy consumption = 152.842668 pJ
sum error= 133
Actual label: 7
Output voltages: [0.18955, 0.016931, 0.1499, 0.79828, 0.019399, 0.0011121, 0.0010745, 0.74688, 0.43797, 0.036548]
Predicted label: 3
Wrong prediction!
Energy consumption = 147.397150 pJ
sum error= 134
Actual label: 6
Output voltages: [0.030928, 0.060188, 0.042524, 0.031175, 0.057237, 0.69251, 0.79878, 0.010452, 0.35611, 0.0074837]
Predicted label: 6
Correct prediction
Energy consumption = 150.342148 pJ
sum error= 134
Actual label: 4
Output voltages: [0.0022305, 0.0094452, 0.076978, 0.025574, 0.79872, 0.0057977, 0.030975, 0.028755, 0.072298, 0.043428]
Predicted label: 4
Correct prediction
Energy consumption = 152.056579 pJ
sum error= 134
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 251 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 251 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 251 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.013101, 0.79863, 0.033791, 0.022885, 0.027793, 0.0023317, 0.665, 0.0027903, 0.40953, 0.0084]
Predicted label: 1
Correct prediction
Energy consumption = 174.266662 pJ
sum error= 134
Actual label: 3
Output voltages: [0.17001, 0.008539, 0.40154, 0.79873, 0.037427, 0.0020477, 0.052578, 0.039001, 0.61213, 0.049649]
Predicted label: 3
Correct prediction
Energy consumption = 144.754843 pJ
sum error= 134
Actual label: 8
Output voltages: [0.30616, 0.017103, 0.16987, 0.096604, 0.0016222, 0.0042903, 0.0081881, 0.0010917, 0.79381, 0.73603]
Predicted label: 8
Correct prediction
Energy consumption = 156.532538 pJ
sum error= 134
Actual label: 7
Output voltages: [0.26866, 0.031757, 0.22144, 0.72803, 0.018068, 0.001115, 0.0013545, 0.78648, 0.40401, 0.048688]
Predicted label: 7
Correct prediction
Energy consumption = 150.221590 pJ
sum error= 134
Actual label: 4
Output voltages: [0.035253, 0.034788, 0.30267, 0.0029793, 0.79877, 0.0011186, 0.37021, 0.038245, 0.012175, 0.6216]
Predicted label: 4
Correct prediction
Energy consumption = 157.119139 pJ
sum error= 134
Actual label: 5
Output voltages: [0.24916, 0.0011688, 0.02571, 0.060619, 0.012594, 0.7981, 0.068915, 0.01653, 0.77448, 0.0046918]
Predicted label: 5
Correct prediction
Energy consumption = 153.342132 pJ
sum error= 134
Actual label: 9
Output voltages: [0.42484, 0.012442, 0.41565, 0.070247, 0.22513, 0.0024843, 0.15256, 0.0092527, 0.045748, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 145.590126 pJ
sum error= 134
Actual label: 2
Output voltages: [0.5535, 0.032535, 0.79868, 0.57488, 0.0016906, 0.0011825, 0.11054, 0.10459, 0.61386, 0.014026]
Predicted label: 2
Correct prediction
Energy consumption = 141.833294 pJ
sum error= 134
Actual label: 5
Output voltages: [0.05155, 0.0011468, 0.0019253, 0.22585, 0.024947, 0.79879, 0.27977, 0.052446, 0.75001, 0.042121]
Predicted label: 5
Correct prediction
Energy consumption = 147.381995 pJ
sum error= 134
Actual label: 1
Output voltages: [0.010636, 0.79837, 0.022274, 0.073366, 0.019531, 0.009794, 0.43532, 0.0051998, 0.041833, 0.1124]
Predicted label: 1
Correct prediction
Energy consumption = 165.962791 pJ
sum error= 134
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 252 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 252 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 252 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.048896, 0.12573, 0.043763, 0.34345, 0.0082745, 0.0013575, 0.18964, 0.041641, 0.79865, 0.060665]
Predicted label: 8
Correct prediction
Energy consumption = 176.098296 pJ
sum error= 134
Actual label: 7
Output voltages: [0.77429, 0.056717, 0.15415, 0.001348, 0.045732, 0.0011147, 0.0023081, 0.75596, 0.53471, 0.02833]
Predicted label: 0
Wrong prediction!
Energy consumption = 147.357214 pJ
sum error= 135
Actual label: 3
Output voltages: [0.050321, 0.0032219, 0.051338, 0.79875, 0.11989, 0.018888, 0.015647, 0.061493, 0.50867, 0.16452]
Predicted label: 3
Correct prediction
Energy consumption = 151.126659 pJ
sum error= 135
Actual label: 7
Output voltages: [0.047521, 0.010283, 0.0024948, 0.0021243, 0.37617, 0.022897, 0.0069247, 0.79869, 0.17778, 0.010346]
Predicted label: 7
Correct prediction
Energy consumption = 153.729525 pJ
sum error= 135
Actual label: 1
Output voltages: [0.0036516, 0.79857, 0.057892, 0.028622, 0.050116, 0.0080259, 0.67119, 0.0014149, 0.42679, 0.040663]
Predicted label: 1
Correct prediction
Energy consumption = 164.533034 pJ
sum error= 135
Actual label: 5
Output voltages: [0.020072, 0.0016588, 0.0019205, 0.15456, 0.0067531, 0.78146, 0.063927, 0.0010919, 0.66473, 0.074363]
Predicted label: 5
Correct prediction
Energy consumption = 154.439344 pJ
sum error= 135
Actual label: 5
Output voltages: [0.012555, 0.0029517, 0.029911, 0.70998, 0.031509, 0.77742, 0.034988, 0.0047922, 0.7932, 0.051727]
Predicted label: 8
Wrong prediction!
Energy consumption = 142.912017 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79818, 0.21531, 0.057754, 0.042365, 0.020796, 0.0013235, 0.76811, 0.0039439, 0.24538, 0.1897]
Predicted label: 0
Correct prediction
Energy consumption = 152.876871 pJ
sum error= 136
Actual label: 9
Output voltages: [0.61046, 0.0095424, 0.036177, 0.022815, 0.71727, 0.0026326, 0.035922, 0.023889, 0.031575, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 153.748210 pJ
sum error= 136
Actual label: 1
Output voltages: [0.018639, 0.79861, 0.041878, 0.04217, 0.013049, 0.0010721, 0.58215, 0.0026935, 0.34068, 0.012622]
Predicted label: 1
Correct prediction
Energy consumption = 161.059185 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 253 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 253 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 253 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.025473, 0.02175, 0.077992, 0.0061849, 0.79879, 0.0011188, 0.044412, 0.15685, 0.031606, 0.22438]
Predicted label: 4
Correct prediction
Energy consumption = 180.324137 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79878, 0.20521, 0.028144, 0.019286, 0.0044838, 0.013814, 0.59209, 0.051344, 0.13898, 0.020048]
Predicted label: 0
Correct prediction
Energy consumption = 150.904575 pJ
sum error= 136
Actual label: 6
Output voltages: [0.099535, 0.42511, 0.033073, 0.076297, 0.0028186, 0.5302, 0.79512, 0.013416, 0.76183, 0.003535]
Predicted label: 6
Correct prediction
Energy consumption = 152.371407 pJ
sum error= 136
Actual label: 3
Output voltages: [0.10493, 0.050418, 0.19617, 0.79872, 0.14271, 0.038777, 0.019798, 0.032416, 0.76463, 0.0219]
Predicted label: 3
Correct prediction
Energy consumption = 150.359080 pJ
sum error= 136
Actual label: 3
Output voltages: [0.023562, 0.0069709, 0.0019179, 0.79728, 0.026522, 0.69495, 0.022808, 0.028523, 0.60152, 0.0093173]
Predicted label: 3
Correct prediction
Energy consumption = 138.520465 pJ
sum error= 136
Actual label: 6
Output voltages: [0.090738, 0.18657, 0.27289, 0.0014141, 0.41259, 0.30595, 0.79868, 0.0014538, 0.35837, 0.023311]
Predicted label: 6
Correct prediction
Energy consumption = 161.650142 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79875, 0.048639, 0.033795, 0.024202, 0.016603, 0.0065709, 0.40732, 0.029026, 0.048243, 0.1463]
Predicted label: 0
Correct prediction
Energy consumption = 146.749420 pJ
sum error= 136
Actual label: 4
Output voltages: [0.0031679, 0.0087688, 0.070451, 0.012638, 0.79864, 0.002053, 0.035012, 0.16638, 0.32567, 0.0085967]
Predicted label: 4
Correct prediction
Energy consumption = 159.118057 pJ
sum error= 136
Actual label: 9
Output voltages: [0.039277, 0.023208, 0.101, 0.19524, 0.040486, 0.029063, 0.049016, 0.035164, 0.31443, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.947892 pJ
sum error= 136
Actual label: 7
Output voltages: [0.68915, 0.0090906, 0.046288, 0.70416, 0.086871, 0.0010728, 0.0012454, 0.785, 0.071869, 0.053229]
Predicted label: 7
Correct prediction
Energy consumption = 143.288645 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 254 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 254 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 254 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.27997, 0.0011197, 0.013592, 0.35742, 0.0094384, 0.79814, 0.032408, 0.023777, 0.77667, 0.25935]
Predicted label: 5
Correct prediction
Energy consumption = 164.638874 pJ
sum error= 136
Actual label: 1
Output voltages: [0.038797, 0.7985, 0.052682, 0.13746, 0.14159, 0.0062982, 0.49546, 0.0037375, 0.14732, 0.055688]
Predicted label: 1
Correct prediction
Energy consumption = 170.481674 pJ
sum error= 136
Actual label: 6
Output voltages: [0.43652, 0.0281, 0.062539, 0.0207, 0.02853, 0.087452, 0.79869, 0.0097761, 0.42321, 0.0086967]
Predicted label: 6
Correct prediction
Energy consumption = 142.770372 pJ
sum error= 136
Actual label: 8
Output voltages: [0.027673, 0.013584, 0.021698, 0.53389, 0.001702, 0.055411, 0.010952, 0.0067246, 0.79878, 0.018293]
Predicted label: 8
Correct prediction
Energy consumption = 145.220571 pJ
sum error= 136
Actual label: 9
Output voltages: [0.24387, 0.0041029, 0.028633, 0.14814, 0.064319, 0.003348, 0.0010941, 0.23082, 0.39156, 0.79728]
Predicted label: 9
Correct prediction
Energy consumption = 150.779123 pJ
sum error= 136
Actual label: 5
Output voltages: [0.087946, 0.00354, 0.0053768, 0.50832, 0.022296, 0.79807, 0.16017, 0.026631, 0.75948, 0.098856]
Predicted label: 5
Correct prediction
Energy consumption = 145.114385 pJ
sum error= 136
Actual label: 5
Output voltages: [0.041515, 0.039546, 0.0067918, 0.20016, 0.068509, 0.79866, 0.26798, 0.012529, 0.29345, 0.065008]
Predicted label: 5
Correct prediction
Energy consumption = 139.693147 pJ
sum error= 136
Actual label: 7
Output voltages: [0.061704, 0.014641, 0.42303, 0.06998, 0.0055253, 0.0011324, 0.0020344, 0.79878, 0.25818, 0.079399]
Predicted label: 7
Correct prediction
Energy consumption = 151.041760 pJ
sum error= 136
Actual label: 9
Output voltages: [0.39588, 0.0097159, 0.017101, 0.0301, 0.37568, 0.015163, 0.0028791, 0.0050047, 0.3942, 0.79836]
Predicted label: 9
Correct prediction
Energy consumption = 145.656617 pJ
sum error= 136
Actual label: 3
Output voltages: [0.060233, 0.050159, 0.040653, 0.79867, 0.025834, 0.0054336, 0.019507, 0.01148, 0.74222, 0.14887]
Predicted label: 3
Correct prediction
Energy consumption = 149.752720 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 255 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 255 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 255 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.2305, 0.0069397, 0.24927, 0.68577, 0.002851, 0.0014413, 0.014351, 0.0010701, 0.79685, 0.25356]
Predicted label: 8
Correct prediction
Energy consumption = 174.902266 pJ
sum error= 136
Actual label: 3
Output voltages: [0.063113, 0.019717, 0.55012, 0.79829, 0.015749, 0.0050969, 0.021348, 0.0010868, 0.6704, 0.033212]
Predicted label: 3
Correct prediction
Energy consumption = 143.418375 pJ
sum error= 136
Actual label: 8
Output voltages: [0.11451, 0.011445, 0.64783, 0.005273, 0.025612, 0.0018686, 0.037983, 0.020187, 0.79879, 0.13584]
Predicted label: 8
Correct prediction
Energy consumption = 146.868496 pJ
sum error= 136
Actual label: 1
Output voltages: [0.0012077, 0.79857, 0.032716, 0.024508, 0.24599, 0.048662, 0.4329, 0.0044769, 0.42379, 0.029634]
Predicted label: 1
Correct prediction
Energy consumption = 164.505000 pJ
sum error= 136
Actual label: 5
Output voltages: [0.029889, 0.001135, 0.001068, 0.39873, 0.1331, 0.79877, 0.26514, 0.0030904, 0.72373, 0.038989]
Predicted label: 5
Correct prediction
Energy consumption = 144.024276 pJ
sum error= 136
Actual label: 3
Output voltages: [0.56139, 0.033466, 0.025542, 0.79861, 0.01264, 0.020086, 0.023782, 0.013645, 0.51419, 0.044157]
Predicted label: 3
Correct prediction
Energy consumption = 147.891870 pJ
sum error= 136
Actual label: 5
Output voltages: [0.029314, 0.001066, 0.0036573, 0.16547, 0.021688, 0.79215, 0.5486, 0.010968, 0.78553, 0.010413]
Predicted label: 5
Correct prediction
Energy consumption = 142.054759 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79879, 0.068999, 0.29365, 0.022438, 0.03416, 0.0023324, 0.56103, 0.010802, 0.61559, 0.020593]
Predicted label: 0
Correct prediction
Energy consumption = 153.749898 pJ
sum error= 136
Actual label: 5
Output voltages: [0.010958, 0.0010674, 0.0010905, 0.43072, 0.048708, 0.79807, 0.044646, 0.0082537, 0.74869, 0.099103]
Predicted label: 5
Correct prediction
Energy consumption = 158.076808 pJ
sum error= 136
Actual label: 5
Output voltages: [0.026403, 0.0011297, 0.021475, 0.7467, 0.038646, 0.7803, 0.030515, 0.058902, 0.70354, 0.038645]
Predicted label: 5
Correct prediction
Energy consumption = 143.000889 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 256 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 256 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 256 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.38491, 0.0077939, 0.050059, 0.79611, 0.0017565, 0.48167, 0.42596, 0.010693, 0.31663, 0.0011011]
Predicted label: 3
Correct prediction
Energy consumption = 168.113687 pJ
sum error= 136
Actual label: 8
Output voltages: [0.032373, 0.026631, 0.1705, 0.059431, 0.021403, 0.037543, 0.032917, 0.015875, 0.7986, 0.18614]
Predicted label: 8
Correct prediction
Energy consumption = 149.798255 pJ
sum error= 136
Actual label: 6
Output voltages: [0.11358, 0.026359, 0.13545, 0.017686, 0.43915, 0.35941, 0.79855, 0.0029847, 0.73923, 0.013446]
Predicted label: 6
Correct prediction
Energy consumption = 153.585095 pJ
sum error= 136
Actual label: 7
Output voltages: [0.1241, 0.070255, 0.33457, 0.049944, 0.0022636, 0.001157, 0.0010682, 0.79874, 0.63283, 0.31752]
Predicted label: 7
Correct prediction
Energy consumption = 163.474625 pJ
sum error= 136
Actual label: 7
Output voltages: [0.31895, 0.4372, 0.35151, 0.080184, 0.010138, 0.0010693, 0.0010675, 0.79872, 0.36739, 0.24829]
Predicted label: 7
Correct prediction
Energy consumption = 143.725982 pJ
sum error= 136
Actual label: 7
Output voltages: [0.40407, 0.022044, 0.0069098, 0.24737, 0.019898, 0.0025195, 0.0011206, 0.79872, 0.60829, 0.40852]
Predicted label: 7
Correct prediction
Energy consumption = 145.570952 pJ
sum error= 136
Actual label: 3
Output voltages: [0.19482, 0.017835, 0.11351, 0.79873, 0.01411, 0.0012153, 0.0066342, 0.0060475, 0.63409, 0.03581]
Predicted label: 3
Correct prediction
Energy consumption = 149.072670 pJ
sum error= 136
Actual label: 7
Output voltages: [0.19519, 0.020745, 0.028888, 0.36118, 0.0043042, 0.0011386, 0.0012002, 0.79872, 0.5959, 0.1734]
Predicted label: 7
Correct prediction
Energy consumption = 148.919765 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79879, 0.17857, 0.0094495, 0.021227, 0.029376, 0.049131, 0.45504, 0.0062514, 0.013992, 0.26375]
Predicted label: 0
Correct prediction
Energy consumption = 155.554218 pJ
sum error= 136
Actual label: 5
Output voltages: [0.035957, 0.0010664, 0.0011523, 0.41999, 0.016502, 0.79879, 0.030972, 0.036464, 0.66753, 0.042117]
Predicted label: 5
Correct prediction
Energy consumption = 144.762961 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 257 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 257 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 257 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.17278, 0.0083458, 0.019555, 0.02348, 0.095971, 0.02891, 0.003801, 0.024968, 0.59553, 0.79811]
Predicted label: 9
Correct prediction
Energy consumption = 171.021186 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79854, 0.030911, 0.034284, 0.035359, 0.049187, 0.0023475, 0.67645, 0.041653, 0.45211, 0.037056]
Predicted label: 0
Correct prediction
Energy consumption = 162.453739 pJ
sum error= 136
Actual label: 2
Output voltages: [0.49868, 0.039707, 0.79874, 0.04084, 0.0097986, 0.001211, 0.025081, 0.069021, 0.55449, 0.014546]
Predicted label: 2
Correct prediction
Energy consumption = 151.269268 pJ
sum error= 136
Actual label: 5
Output voltages: [0.32609, 0.016935, 0.0017718, 0.20493, 0.0010849, 0.78894, 0.0041704, 0.0041308, 0.79875, 0.041655]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.656456 pJ
sum error= 137
Actual label: 5
Output voltages: [0.037465, 0.001285, 0.0024939, 0.56568, 0.014919, 0.7987, 0.037647, 0.39579, 0.67854, 0.2629]
Predicted label: 5
Correct prediction
Energy consumption = 146.373663 pJ
sum error= 137
Actual label: 3
Output voltages: [0.27557, 0.020079, 0.029026, 0.79866, 0.013113, 0.0089725, 0.011147, 0.016488, 0.55687, 0.12056]
Predicted label: 3
Correct prediction
Energy consumption = 140.825827 pJ
sum error= 137
Actual label: 1
Output voltages: [0.17258, 0.7986, 0.37322, 0.030983, 0.010701, 0.0010975, 0.34877, 0.0016563, 0.12287, 0.09242]
Predicted label: 1
Correct prediction
Energy consumption = 161.067442 pJ
sum error= 137
Actual label: 7
Output voltages: [0.013456, 0.46185, 0.20059, 0.005852, 0.024155, 0.0011324, 0.0010665, 0.79879, 0.29916, 0.13694]
Predicted label: 7
Correct prediction
Energy consumption = 154.119512 pJ
sum error= 137
Actual label: 7
Output voltages: [0.30802, 0.20463, 0.79845, 0.036182, 0.0048395, 0.001271, 0.0018247, 0.79247, 0.15324, 0.56416]
Predicted label: 2
Wrong prediction!
Energy consumption = 144.663740 pJ
sum error= 138
Actual label: 8
Output voltages: [0.018999, 0.053239, 0.32474, 0.062948, 0.011858, 0.01449, 0.23512, 0.028364, 0.79867, 0.17477]
Predicted label: 8
Correct prediction
Energy consumption = 151.099738 pJ
sum error= 138
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 258 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 258 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 258 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.070617, 0.018904, 0.02252, 0.040264, 0.47346, 0.27492, 0.79879, 0.0018889, 0.75282, 0.01753]
Predicted label: 6
Correct prediction
Energy consumption = 169.623817 pJ
sum error= 138
Actual label: 5
Output voltages: [0.027844, 0.0011884, 0.0011035, 0.077875, 0.03791, 0.79871, 0.040076, 0.0037568, 0.59009, 0.042346]
Predicted label: 5
Correct prediction
Energy consumption = 148.455994 pJ
sum error= 138
Actual label: 9
Output voltages: [0.62487, 0.0030181, 0.11525, 0.43245, 0.030719, 0.02821, 0.0010816, 0.74429, 0.50207, 0.76615]
Predicted label: 9
Correct prediction
Energy consumption = 148.906007 pJ
sum error= 138
Actual label: 3
Output voltages: [0.05263, 0.010107, 0.30066, 0.79879, 0.011533, 0.013044, 0.0045808, 0.0057922, 0.76078, 0.030983]
Predicted label: 3
Correct prediction
Energy consumption = 140.500969 pJ
sum error= 138
Actual label: 8
Output voltages: [0.01454, 0.068743, 0.34889, 0.24413, 0.0055863, 0.025963, 0.19837, 0.044823, 0.79871, 0.038321]
Predicted label: 8
Correct prediction
Energy consumption = 148.772725 pJ
sum error= 138
Actual label: 9
Output voltages: [0.26921, 0.030387, 0.033028, 0.32013, 0.043316, 0.0306, 0.041769, 0.10135, 0.13095, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.777665 pJ
sum error= 138
Actual label: 5
Output voltages: [0.13677, 0.0013428, 0.0011119, 0.54369, 0.13005, 0.79877, 0.14765, 0.029751, 0.72927, 0.11253]
Predicted label: 5
Correct prediction
Energy consumption = 148.396409 pJ
sum error= 138
Actual label: 3
Output voltages: [0.37377, 0.0021918, 0.016073, 0.79877, 0.0092541, 0.71506, 0.0080051, 0.022212, 0.52963, 0.017308]
Predicted label: 3
Correct prediction
Energy consumption = 139.932140 pJ
sum error= 138
Actual label: 7
Output voltages: [0.53772, 0.028505, 0.0013207, 0.039685, 0.12001, 0.11749, 0.0017, 0.79873, 0.57386, 0.74562]
Predicted label: 7
Correct prediction
Energy consumption = 153.164730 pJ
sum error= 138
Actual label: 9
Output voltages: [0.78476, 0.0074338, 0.030855, 0.014392, 0.040861, 0.02482, 0.029227, 0.0040042, 0.22421, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 147.089045 pJ
sum error= 138
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 259 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 259 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 259 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.053857, 0.79863, 0.056662, 0.054871, 0.027407, 0.0010681, 0.5605, 0.0013469, 0.14706, 0.10078]
Predicted label: 1
Correct prediction
Energy consumption = 188.143400 pJ
sum error= 138
Actual label: 7
Output voltages: [0.049161, 0.10605, 0.23797, 0.20906, 0.0086018, 0.0011017, 0.0056958, 0.79866, 0.0492, 0.18735]
Predicted label: 7
Correct prediction
Energy consumption = 156.395242 pJ
sum error= 138
Actual label: 0
Output voltages: [0.7987, 0.040426, 0.31446, 0.027635, 0.0087396, 0.0036607, 0.052854, 0.036707, 0.033103, 0.056576]
Predicted label: 0
Correct prediction
Energy consumption = 146.534115 pJ
sum error= 138
Actual label: 0
Output voltages: [0.79597, 0.039033, 0.049147, 0.024948, 0.01663, 0.0010858, 0.49222, 0.018034, 0.66663, 0.080623]
Predicted label: 0
Correct prediction
Energy consumption = 143.109047 pJ
sum error= 138
Actual label: 3
Output voltages: [0.37268, 0.0027989, 0.14207, 0.79874, 0.045157, 0.34857, 0.01227, 0.0065238, 0.52232, 0.019242]
Predicted label: 3
Correct prediction
Energy consumption = 147.010993 pJ
sum error= 138
Actual label: 7
Output voltages: [0.21309, 0.03145, 0.014441, 0.029238, 0.025439, 0.0027741, 0.0010879, 0.79868, 0.14961, 0.39115]
Predicted label: 7
Correct prediction
Energy consumption = 158.157970 pJ
sum error= 138
Actual label: 2
Output voltages: [0.075293, 0.44339, 0.7987, 0.038983, 0.012747, 0.001244, 0.21209, 0.36977, 0.36074, 0.2793]
Predicted label: 2
Correct prediction
Energy consumption = 147.113596 pJ
sum error= 138
Actual label: 5
Output voltages: [0.010674, 0.0013631, 0.048131, 0.73077, 0.01373, 0.76729, 0.01583, 0.010275, 0.78763, 0.044651]
Predicted label: 8
Wrong prediction!
Energy consumption = 138.951896 pJ
sum error= 139
Actual label: 8
Output voltages: [0.037066, 0.032071, 0.76237, 0.026506, 0.03362, 0.0028666, 0.068436, 0.04323, 0.79879, 0.12283]
Predicted label: 8
Correct prediction
Energy consumption = 147.742411 pJ
sum error= 139
Actual label: 1
Output voltages: [0.026135, 0.79847, 0.045855, 0.16154, 0.003573, 0.0011372, 0.34556, 0.0076212, 0.55077, 0.14698]
Predicted label: 1
Correct prediction
Energy consumption = 152.808120 pJ
sum error= 139
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 260 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 260 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 260 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.016603, 0.043987, 0.11112, 0.045173, 0.058153, 0.038213, 0.22275, 0.04133, 0.79868, 0.034845]
Predicted label: 8
Correct prediction
Energy consumption = 177.448671 pJ
sum error= 139
Actual label: 6
Output voltages: [0.20527, 0.1251, 0.35806, 0.0019315, 0.28407, 0.18448, 0.79874, 0.0013858, 0.47851, 0.026478]
Predicted label: 6
Correct prediction
Energy consumption = 152.694649 pJ
sum error= 139
Actual label: 2
Output voltages: [0.30006, 0.34454, 0.79788, 0.28715, 0.013894, 0.0012677, 0.024362, 0.034212, 0.1944, 0.037737]
Predicted label: 2
Correct prediction
Energy consumption = 156.501038 pJ
sum error= 139
Actual label: 9
Output voltages: [0.077664, 0.006203, 0.046108, 0.015423, 0.037437, 0.0097603, 0.0013155, 0.039205, 0.7524, 0.79261]
Predicted label: 9
Correct prediction
Energy consumption = 158.918757 pJ
sum error= 139
Actual label: 5
Output voltages: [0.035716, 0.0020368, 0.0037179, 0.78564, 0.007045, 0.76954, 0.036602, 0.016793, 0.65366, 0.092492]
Predicted label: 3
Wrong prediction!
Energy consumption = 143.031675 pJ
sum error= 140
Actual label: 7
Output voltages: [0.14814, 0.014085, 0.0059797, 0.045585, 0.012231, 0.004123, 0.0010759, 0.79873, 0.07368, 0.66336]
Predicted label: 7
Correct prediction
Energy consumption = 151.721276 pJ
sum error= 140
Actual label: 5
Output voltages: [0.14465, 0.0010741, 0.011987, 0.20014, 0.010074, 0.79877, 0.067032, 0.044767, 0.71938, 0.088865]
Predicted label: 5
Correct prediction
Energy consumption = 147.668137 pJ
sum error= 140
Actual label: 7
Output voltages: [0.072933, 0.002867, 0.77451, 0.027777, 0.30536, 0.0010688, 0.0055599, 0.5848, 0.76169, 0.045966]
Predicted label: 2
Wrong prediction!
Energy consumption = 155.627910 pJ
sum error= 141
Actual label: 8
Output voltages: [0.0044653, 0.1738, 0.049975, 0.022563, 0.0051442, 0.0023851, 0.019945, 0.0095377, 0.79878, 0.40727]
Predicted label: 8
Correct prediction
Energy consumption = 155.001514 pJ
sum error= 141
Actual label: 6
Output voltages: [0.64355, 0.031713, 0.018798, 0.034577, 0.14702, 0.70683, 0.79879, 0.0011049, 0.18346, 0.037653]
Predicted label: 6
Correct prediction
Energy consumption = 141.097756 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 261 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 261 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 261 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.070987, 0.0091597, 0.79808, 0.21536, 0.0026282, 0.0011336, 0.042358, 0.031855, 0.77089, 0.02275]
Predicted label: 2
Correct prediction
Energy consumption = 160.452075 pJ
sum error= 141
Actual label: 5
Output voltages: [0.63338, 0.031666, 0.0010868, 0.75522, 0.0044393, 0.79453, 0.27211, 0.0054409, 0.58557, 0.0016111]
Predicted label: 5
Correct prediction
Energy consumption = 149.016797 pJ
sum error= 141
Actual label: 1
Output voltages: [0.08766, 0.79875, 0.04619, 0.28093, 0.010105, 0.0017328, 0.16494, 0.0010732, 0.42796, 0.041386]
Predicted label: 1
Correct prediction
Energy consumption = 160.314586 pJ
sum error= 141
Actual label: 4
Output voltages: [0.02012, 0.0076624, 0.2072, 0.0029991, 0.7987, 0.0020995, 0.16759, 0.33997, 0.053238, 0.13174]
Predicted label: 4
Correct prediction
Energy consumption = 160.036144 pJ
sum error= 141
Actual label: 8
Output voltages: [0.018334, 0.17138, 0.41836, 0.048842, 0.021277, 0.0065233, 0.043375, 0.0079738, 0.7987, 0.30884]
Predicted label: 8
Correct prediction
Energy consumption = 156.610772 pJ
sum error= 141
Actual label: 4
Output voltages: [0.0055358, 0.0038766, 0.048455, 0.03967, 0.79864, 0.001426, 0.055045, 0.033041, 0.18883, 0.021152]
Predicted label: 4
Correct prediction
Energy consumption = 154.912700 pJ
sum error= 141
Actual label: 5
Output voltages: [0.0043796, 0.0020908, 0.026976, 0.18551, 0.051153, 0.79682, 0.2268, 0.009425, 0.79556, 0.26086]
Predicted label: 5
Correct prediction
Energy consumption = 142.299762 pJ
sum error= 141
Actual label: 8
Output voltages: [0.01064, 0.058519, 0.037156, 0.057715, 0.002543, 0.015529, 0.013985, 0.021639, 0.79874, 0.26338]
Predicted label: 8
Correct prediction
Energy consumption = 146.748536 pJ
sum error= 141
Actual label: 3
Output voltages: [0.26696, 0.0013167, 0.042913, 0.79879, 0.10474, 0.7809, 0.026472, 0.071688, 0.36611, 0.012183]
Predicted label: 3
Correct prediction
Energy consumption = 148.370306 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79877, 0.066262, 0.069755, 0.021061, 0.018922, 0.0017234, 0.50247, 0.010852, 0.32772, 0.030625]
Predicted label: 0
Correct prediction
Energy consumption = 155.983046 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 262 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 262 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 262 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.047481, 0.044993, 0.29764, 0.0015949, 0.15464, 0.094602, 0.79875, 0.0037498, 0.71875, 0.026604]
Predicted label: 6
Correct prediction
Energy consumption = 165.615209 pJ
sum error= 141
Actual label: 2
Output voltages: [0.49527, 0.0026788, 0.79877, 0.024027, 0.040347, 0.0013536, 0.12158, 0.047655, 0.64381, 0.0012904]
Predicted label: 2
Correct prediction
Energy consumption = 145.554813 pJ
sum error= 141
Actual label: 7
Output voltages: [0.040581, 0.04054, 0.035898, 0.59751, 0.14725, 0.0012414, 0.0010661, 0.79874, 0.20275, 0.054308]
Predicted label: 7
Correct prediction
Energy consumption = 151.258305 pJ
sum error= 141
Actual label: 3
Output voltages: [0.14412, 0.0071067, 0.056158, 0.79858, 0.041613, 0.034163, 0.015072, 0.017322, 0.43612, 0.10925]
Predicted label: 3
Correct prediction
Energy consumption = 140.528502 pJ
sum error= 141
Actual label: 3
Output voltages: [0.35234, 0.026935, 0.02031, 0.79864, 0.017563, 0.012662, 0.0056834, 0.012648, 0.36265, 0.039257]
Predicted label: 3
Correct prediction
Energy consumption = 139.391139 pJ
sum error= 141
Actual label: 2
Output voltages: [0.25555, 0.62735, 0.79865, 0.16422, 0.018813, 0.001386, 0.058228, 0.020688, 0.046314, 0.02015]
Predicted label: 2
Correct prediction
Energy consumption = 150.790420 pJ
sum error= 141
Actual label: 1
Output voltages: [0.001262, 0.79864, 0.020397, 0.15435, 0.051333, 0.0021618, 0.58735, 0.021247, 0.65451, 0.020884]
Predicted label: 1
Correct prediction
Energy consumption = 160.236731 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79617, 0.042534, 0.036225, 0.040991, 0.014065, 0.0061816, 0.68167, 0.042391, 0.29414, 0.023919]
Predicted label: 0
Correct prediction
Energy consumption = 151.394251 pJ
sum error= 141
Actual label: 7
Output voltages: [0.046773, 0.0067314, 0.51193, 0.48445, 0.03281, 0.0010828, 0.0012163, 0.79853, 0.097823, 0.39978]
Predicted label: 7
Correct prediction
Energy consumption = 150.066422 pJ
sum error= 141
Actual label: 3
Output voltages: [0.037719, 0.023252, 0.053507, 0.7964, 0.034681, 0.46205, 0.014134, 0.0013851, 0.66145, 0.32001]
Predicted label: 3
Correct prediction
Energy consumption = 141.506950 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 263 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 263 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 263 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.025352, 0.019507, 0.065949, 0.0040561, 0.79867, 0.0075004, 0.0343, 0.046461, 0.024999, 0.53161]
Predicted label: 4
Correct prediction
Energy consumption = 177.897791 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79861, 0.023335, 0.019191, 0.0014898, 0.22181, 0.023054, 0.79438, 0.049692, 0.043941, 0.048349]
Predicted label: 0
Correct prediction
Energy consumption = 156.024357 pJ
sum error= 141
Actual label: 3
Output voltages: [0.11858, 0.010265, 0.25123, 0.79877, 0.0033954, 0.039012, 0.0034903, 0.0013582, 0.70577, 0.021735]
Predicted label: 3
Correct prediction
Energy consumption = 150.818065 pJ
sum error= 141
Actual label: 9
Output voltages: [0.18034, 0.020746, 0.034108, 0.022462, 0.028336, 0.010549, 0.0023747, 0.014633, 0.76342, 0.79694]
Predicted label: 9
Correct prediction
Energy consumption = 143.115843 pJ
sum error= 141
Actual label: 3
Output voltages: [0.44432, 0.025071, 0.03163, 0.7987, 0.019002, 0.01918, 0.014892, 0.0042285, 0.47086, 0.065806]
Predicted label: 3
Correct prediction
Energy consumption = 146.503176 pJ
sum error= 141
Actual label: 2
Output voltages: [0.30294, 0.038432, 0.79879, 0.2334, 0.02404, 0.0011818, 0.26804, 0.64649, 0.086101, 0.023427]
Predicted label: 2
Correct prediction
Energy consumption = 140.291184 pJ
sum error= 141
Actual label: 8
Output voltages: [0.25181, 0.026695, 0.41315, 0.1955, 0.0051879, 0.038047, 0.015951, 0.015135, 0.79879, 0.38726]
Predicted label: 8
Correct prediction
Energy consumption = 152.459425 pJ
sum error= 141
Actual label: 9
Output voltages: [0.33821, 0.001066, 0.20878, 0.027189, 0.76261, 0.0077974, 0.020684, 0.01196, 0.024837, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 146.691958 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79879, 0.10645, 0.045106, 0.094029, 0.0012116, 0.026696, 0.59021, 0.010543, 0.20019, 0.049932]
Predicted label: 0
Correct prediction
Energy consumption = 146.859025 pJ
sum error= 141
Actual label: 3
Output voltages: [0.15919, 0.0064344, 0.084012, 0.7987, 0.055817, 0.028023, 0.034759, 0.025654, 0.51806, 0.050523]
Predicted label: 3
Correct prediction
Energy consumption = 137.263366 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 264 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 264 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 264 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.011564, 0.30346, 0.045317, 0.1908, 0.0045105, 0.0095724, 0.020949, 0.0073865, 0.79869, 0.47465]
Predicted label: 8
Correct prediction
Energy consumption = 166.163966 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79879, 0.0043439, 0.0077334, 0.028711, 0.0011644, 0.24612, 0.32421, 0.01934, 0.47783, 0.0011348]
Predicted label: 0
Correct prediction
Energy consumption = 149.963673 pJ
sum error= 141
Actual label: 7
Output voltages: [0.020336, 0.068293, 0.022423, 0.0077604, 0.032245, 0.0011209, 0.0010714, 0.79867, 0.057789, 0.043678]
Predicted label: 7
Correct prediction
Energy consumption = 158.054745 pJ
sum error= 141
Actual label: 6
Output voltages: [0.23882, 0.10576, 0.029822, 0.016611, 0.2748, 0.2982, 0.79871, 0.0041311, 0.63277, 0.012943]
Predicted label: 6
Correct prediction
Energy consumption = 149.776527 pJ
sum error= 141
Actual label: 5
Output voltages: [0.026951, 0.0010726, 0.0029283, 0.30141, 0.023708, 0.79865, 0.30958, 0.022853, 0.75094, 0.032097]
Predicted label: 5
Correct prediction
Energy consumption = 147.327232 pJ
sum error= 141
Actual label: 4
Output voltages: [0.01569, 0.0016046, 0.044645, 0.031274, 0.79869, 0.0010678, 0.17656, 0.3661, 0.072892, 0.018195]
Predicted label: 4
Correct prediction
Energy consumption = 159.542029 pJ
sum error= 141
Actual label: 7
Output voltages: [0.037648, 0.12781, 0.223, 0.16802, 0.0037333, 0.0010798, 0.0013165, 0.79869, 0.29105, 0.35901]
Predicted label: 7
Correct prediction
Energy consumption = 153.006653 pJ
sum error= 141
Actual label: 3
Output voltages: [0.54207, 0.06075, 0.090166, 0.79855, 0.14269, 0.014647, 0.02283, 0.02047, 0.70591, 0.073823]
Predicted label: 3
Correct prediction
Energy consumption = 147.183123 pJ
sum error= 141
Actual label: 9
Output voltages: [0.77048, 0.0011514, 0.42769, 0.17707, 0.58936, 0.0015723, 0.0014413, 0.0015154, 0.059241, 0.79512]
Predicted label: 9
Correct prediction
Energy consumption = 149.006787 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79867, 0.030637, 0.38456, 0.0079626, 0.029834, 0.0010987, 0.46187, 0.024841, 0.43959, 0.038347]
Predicted label: 0
Correct prediction
Energy consumption = 135.540589 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 265 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 265 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 265 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.029269, 0.012583, 0.16104, 0.030367, 0.0384, 0.025647, 0.020631, 0.0016815, 0.79876, 0.2631]
Predicted label: 8
Correct prediction
Energy consumption = 168.194132 pJ
sum error= 141
Actual label: 6
Output voltages: [0.40036, 0.049724, 0.030172, 0.0079197, 0.55631, 0.29013, 0.79876, 0.0030291, 0.50188, 0.013894]
Predicted label: 6
Correct prediction
Energy consumption = 152.707467 pJ
sum error= 141
Actual label: 2
Output voltages: [0.023583, 0.67594, 0.79871, 0.0075285, 0.017291, 0.0013394, 0.038308, 0.51438, 0.13038, 0.026191]
Predicted label: 2
Correct prediction
Energy consumption = 154.756597 pJ
sum error= 141
Actual label: 5
Output voltages: [0.058401, 0.0010669, 0.0018992, 0.17622, 0.021458, 0.79871, 0.058499, 0.055896, 0.79423, 0.0084496]
Predicted label: 5
Correct prediction
Energy consumption = 144.652614 pJ
sum error= 141
Actual label: 6
Output voltages: [0.3245, 0.79879, 0.34912, 0.045866, 0.020049, 0.0017952, 0.76564, 0.0015508, 0.24157, 0.0018817]
Predicted label: 1
Wrong prediction!
Energy consumption = 160.726744 pJ
sum error= 142
Actual label: 1
Output voltages: [0.021498, 0.7984, 0.13074, 0.024497, 0.066452, 0.0074674, 0.59776, 0.0088984, 0.13114, 0.033978]
Predicted label: 1
Correct prediction
Energy consumption = 147.796527 pJ
sum error= 142
Actual label: 0
Output voltages: [0.79878, 0.050889, 0.062594, 0.0022126, 0.034568, 0.0069129, 0.35467, 0.028888, 0.22031, 0.46155]
Predicted label: 0
Correct prediction
Energy consumption = 156.907600 pJ
sum error= 142
Actual label: 0
Output voltages: [0.79861, 0.19119, 0.019623, 0.019265, 0.0067841, 0.01501, 0.71617, 0.032496, 0.10494, 0.033152]
Predicted label: 0
Correct prediction
Energy consumption = 141.939489 pJ
sum error= 142
Actual label: 4
Output voltages: [0.010958, 0.084019, 0.021281, 0.0024205, 0.79876, 0.0012404, 0.46547, 0.022985, 0.046022, 0.0069491]
Predicted label: 4
Correct prediction
Energy consumption = 160.431421 pJ
sum error= 142
Actual label: 4
Output voltages: [0.0010689, 0.04012, 0.00723, 0.0075802, 0.79594, 0.0018994, 0.039849, 0.068652, 0.45222, 0.027435]
Predicted label: 4
Correct prediction
Energy consumption = 147.030734 pJ
sum error= 142
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 266 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 266 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 266 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.02851, 0.051199, 0.0031571, 0.048303, 0.0056853, 0.5114, 0.0087337, 0.38064, 0.30642]
Predicted label: 0
Correct prediction
Energy consumption = 173.676380 pJ
sum error= 142
Actual label: 1
Output voltages: [0.012102, 0.7986, 0.057058, 0.049466, 0.042761, 0.0012027, 0.75459, 0.0021628, 0.25236, 0.07117]
Predicted label: 1
Correct prediction
Energy consumption = 162.432588 pJ
sum error= 142
Actual label: 2
Output voltages: [0.47435, 0.021645, 0.79879, 0.33402, 0.030209, 0.0010789, 0.051898, 0.12552, 0.57019, 0.007319]
Predicted label: 2
Correct prediction
Energy consumption = 151.172086 pJ
sum error= 142
Actual label: 3
Output voltages: [0.25748, 0.020028, 0.053006, 0.79867, 0.01817, 0.0016464, 0.021353, 0.04814, 0.63353, 0.035806]
Predicted label: 3
Correct prediction
Energy consumption = 143.880873 pJ
sum error= 142
Actual label: 2
Output voltages: [0.67488, 0.0068637, 0.7982, 0.049171, 0.016464, 0.0010858, 0.15248, 0.026278, 0.60134, 0.029477]
Predicted label: 2
Correct prediction
Energy consumption = 142.682212 pJ
sum error= 142
Actual label: 7
Output voltages: [0.39373, 0.0059381, 0.66423, 0.69279, 0.0094129, 0.0012843, 0.0017241, 0.79397, 0.21673, 0.26168]
Predicted label: 7
Correct prediction
Energy consumption = 141.963432 pJ
sum error= 142
Actual label: 7
Output voltages: [0.060755, 0.0070616, 0.043789, 0.52107, 0.0067656, 0.011828, 0.0010791, 0.79871, 0.086582, 0.65784]
Predicted label: 7
Correct prediction
Energy consumption = 132.571009 pJ
sum error= 142
Actual label: 8
Output voltages: [0.040666, 0.003123, 0.022797, 0.055177, 0.001281, 0.48897, 0.012188, 0.010189, 0.79879, 0.020132]
Predicted label: 8
Correct prediction
Energy consumption = 146.342480 pJ
sum error= 142
Actual label: 5
Output voltages: [0.082459, 0.0011253, 0.0056953, 0.70583, 0.14249, 0.62054, 0.17784, 0.010272, 0.61154, 0.60437]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.193901 pJ
sum error= 143
Actual label: 2
Output voltages: [0.28454, 0.034443, 0.79873, 0.089755, 0.010259, 0.0012024, 0.045521, 0.035345, 0.35124, 0.01979]
Predicted label: 2
Correct prediction
Energy consumption = 148.567045 pJ
sum error= 143
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 267 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 267 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 267 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.48111, 0.0011087, 0.00458, 0.70186, 0.0026384, 0.77163, 0.016193, 0.038113, 0.77968, 0.036055]
Predicted label: 8
Wrong prediction!
Energy consumption = 169.938964 pJ
sum error= 144
Actual label: 7
Output voltages: [0.14144, 0.18421, 0.7239, 0.019115, 0.016045, 0.0010812, 0.0010767, 0.79873, 0.17641, 0.033969]
Predicted label: 7
Correct prediction
Energy consumption = 142.606426 pJ
sum error= 144
Actual label: 6
Output voltages: [0.29395, 0.033895, 0.13424, 0.002002, 0.086427, 0.27203, 0.79879, 0.001939, 0.42144, 0.0049913]
Predicted label: 6
Correct prediction
Energy consumption = 162.610480 pJ
sum error= 144
Actual label: 9
Output voltages: [0.40217, 0.044597, 0.011364, 0.025401, 0.47711, 0.0021093, 0.0048439, 0.022639, 0.059519, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 156.526268 pJ
sum error= 144
Actual label: 1
Output voltages: [0.22327, 0.79846, 0.053672, 0.1697, 0.062533, 0.0015079, 0.24831, 0.012091, 0.027369, 0.21774]
Predicted label: 1
Correct prediction
Energy consumption = 165.886987 pJ
sum error= 144
Actual label: 4
Output voltages: [0.0033472, 0.021058, 0.036586, 0.0010859, 0.79869, 0.0023888, 0.10319, 0.20096, 0.21056, 0.0371]
Predicted label: 4
Correct prediction
Energy consumption = 155.372824 pJ
sum error= 144
Actual label: 1
Output voltages: [0.019555, 0.79855, 0.0014449, 0.049582, 0.075172, 0.020206, 0.57114, 0.0079252, 0.111, 0.095022]
Predicted label: 1
Correct prediction
Energy consumption = 154.640561 pJ
sum error= 144
Actual label: 6
Output voltages: [0.081229, 0.033363, 0.11941, 0.0033191, 0.45371, 0.19664, 0.79877, 0.0030282, 0.53726, 0.0024657]
Predicted label: 6
Correct prediction
Energy consumption = 144.586755 pJ
sum error= 144
Actual label: 4
Output voltages: [0.16542, 0.0078028, 0.74646, 0.0035881, 0.79878, 0.0011558, 0.055817, 0.036172, 0.029791, 0.53249]
Predicted label: 4
Correct prediction
Energy consumption = 156.125498 pJ
sum error= 144
Actual label: 2
Output voltages: [0.44423, 0.014078, 0.79878, 0.043686, 0.028612, 0.0011143, 0.047858, 0.022251, 0.37242, 0.017724]
Predicted label: 2
Correct prediction
Energy consumption = 148.353632 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 268 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 268 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 268 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.010989, 0.020926, 0.33731, 0.0057065, 0.79873, 0.0010679, 0.4498, 0.062486, 0.025794, 0.09429]
Predicted label: 4
Correct prediction
Energy consumption = 170.026417 pJ
sum error= 144
Actual label: 3
Output voltages: [0.16437, 0.01473, 0.06507, 0.79873, 0.013462, 0.23419, 0.0031378, 0.0055739, 0.499, 0.018148]
Predicted label: 3
Correct prediction
Energy consumption = 149.716028 pJ
sum error= 144
Actual label: 5
Output voltages: [0.035885, 0.0010989, 0.0010806, 0.35474, 0.36091, 0.7987, 0.33927, 0.0067065, 0.78963, 0.037872]
Predicted label: 5
Correct prediction
Energy consumption = 136.338507 pJ
sum error= 144
Actual label: 4
Output voltages: [0.010104, 0.0014617, 0.20291, 0.016991, 0.79873, 0.0010773, 0.021342, 0.18605, 0.042181, 0.052364]
Predicted label: 4
Correct prediction
Energy consumption = 153.035519 pJ
sum error= 144
Actual label: 3
Output voltages: [0.64339, 0.054409, 0.062023, 0.79877, 0.0010794, 0.0072435, 0.096074, 0.1201, 0.5989, 0.0011503]
Predicted label: 3
Correct prediction
Energy consumption = 146.872932 pJ
sum error= 144
Actual label: 9
Output voltages: [0.50634, 0.026737, 0.014349, 0.097353, 0.050809, 0.027658, 0.0025202, 0.032663, 0.30128, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 150.751624 pJ
sum error= 144
Actual label: 5
Output voltages: [0.16911, 0.0019416, 0.0012335, 0.27976, 0.13531, 0.79877, 0.040075, 0.062939, 0.77771, 0.046287]
Predicted label: 5
Correct prediction
Energy consumption = 147.055986 pJ
sum error= 144
Actual label: 0
Output voltages: [0.79878, 0.19722, 0.025771, 0.022562, 0.0074641, 0.021409, 0.45284, 0.027647, 0.063483, 0.024936]
Predicted label: 0
Correct prediction
Energy consumption = 149.369722 pJ
sum error= 144
Actual label: 1
Output voltages: [0.040058, 0.79838, 0.033777, 0.17427, 0.0049795, 0.017457, 0.72755, 0.012264, 0.15821, 0.11593]
Predicted label: 1
Correct prediction
Energy consumption = 164.795638 pJ
sum error= 144
Actual label: 5
Output voltages: [0.050334, 0.001094, 0.0029199, 0.68147, 0.01263, 0.78629, 0.079172, 0.051205, 0.46682, 0.026748]
Predicted label: 5
Correct prediction
Energy consumption = 152.120902 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 269 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 269 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 269 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.031576, 0.025566, 0.037804, 0.79876, 0.012081, 0.0027086, 0.0056158, 0.022922, 0.75828, 0.027903]
Predicted label: 3
Correct prediction
Energy consumption = 160.552622 pJ
sum error= 144
Actual label: 8
Output voltages: [0.026617, 0.045897, 0.089016, 0.053453, 0.004373, 0.021923, 0.035992, 0.0069717, 0.79876, 0.1098]
Predicted label: 8
Correct prediction
Energy consumption = 147.657448 pJ
sum error= 144
Actual label: 9
Output voltages: [0.19647, 0.0087922, 0.034693, 0.032492, 0.031255, 0.010974, 0.0059062, 0.22424, 0.56475, 0.79599]
Predicted label: 9
Correct prediction
Energy consumption = 156.074993 pJ
sum error= 144
Actual label: 1
Output voltages: [0.0025652, 0.79862, 0.045535, 0.023757, 0.020405, 0.0019273, 0.72305, 0.0031079, 0.43666, 0.012716]
Predicted label: 1
Correct prediction
Energy consumption = 163.768481 pJ
sum error= 144
Actual label: 9
Output voltages: [0.58401, 0.029978, 0.052154, 0.028518, 0.21799, 0.01772, 0.0026352, 0.0098548, 0.2784, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 158.709242 pJ
sum error= 144
Actual label: 7
Output voltages: [0.36964, 0.013846, 0.044395, 0.16748, 0.025101, 0.026039, 0.017897, 0.79841, 0.095258, 0.02749]
Predicted label: 7
Correct prediction
Energy consumption = 144.591530 pJ
sum error= 144
Actual label: 9
Output voltages: [0.17064, 0.027297, 0.20141, 0.21404, 0.15702, 0.043027, 0.053674, 0.016467, 0.15018, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 151.563801 pJ
sum error= 144
Actual label: 5
Output voltages: [0.01817, 0.0012008, 0.0016717, 0.27796, 0.027502, 0.79764, 0.093188, 0.0037822, 0.67936, 0.26846]
Predicted label: 5
Correct prediction
Energy consumption = 138.046681 pJ
sum error= 144
Actual label: 5
Output voltages: [0.0028182, 0.0017794, 0.0011767, 0.1056, 0.047667, 0.79531, 0.035973, 0.0018478, 0.72503, 0.093041]
Predicted label: 5
Correct prediction
Energy consumption = 139.690745 pJ
sum error= 144
Actual label: 2
Output voltages: [0.060029, 0.45676, 0.79843, 0.023506, 0.045621, 0.0012577, 0.078376, 0.029757, 0.25859, 0.032961]
Predicted label: 2
Correct prediction
Energy consumption = 156.929904 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 270 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 270 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 270 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.071133, 0.037867, 0.060232, 0.45092, 0.0021618, 0.0023353, 0.0012753, 0.79876, 0.017526, 0.5002]
Predicted label: 7
Correct prediction
Energy consumption = 173.980489 pJ
sum error= 144
Actual label: 4
Output voltages: [0.017861, 0.0051642, 0.032954, 0.01292, 0.79867, 0.0033514, 0.30948, 0.23961, 0.27244, 0.0046643]
Predicted label: 4
Correct prediction
Energy consumption = 158.474932 pJ
sum error= 144
Actual label: 6
Output voltages: [0.33892, 0.043297, 0.14088, 0.0028434, 0.39716, 0.072623, 0.79879, 0.0011644, 0.45716, 0.014778]
Predicted label: 6
Correct prediction
Energy consumption = 146.434669 pJ
sum error= 144
Actual label: 0
Output voltages: [0.79875, 0.11179, 0.0092674, 0.031209, 0.0090322, 0.072134, 0.56904, 0.021706, 0.22618, 0.020109]
Predicted label: 0
Correct prediction
Energy consumption = 140.467072 pJ
sum error= 144
Actual label: 1
Output voltages: [0.024816, 0.79862, 0.00513, 0.027199, 0.020046, 0.0034251, 0.32462, 0.0025313, 0.74632, 0.020727]
Predicted label: 1
Correct prediction
Energy consumption = 161.818369 pJ
sum error= 144
Actual label: 1
Output voltages: [0.060326, 0.79861, 0.31024, 0.12665, 0.0045744, 0.0027051, 0.13564, 0.0012255, 0.75454, 0.058501]
Predicted label: 1
Correct prediction
Energy consumption = 148.603706 pJ
sum error= 144
Actual label: 1
Output voltages: [0.054321, 0.7985, 0.0066918, 0.41175, 0.073029, 0.025373, 0.259, 0.0037918, 0.35754, 0.11488]
Predicted label: 1
Correct prediction
Energy consumption = 159.830768 pJ
sum error= 144
Actual label: 0
Output voltages: [0.79875, 0.10746, 0.057563, 0.018029, 0.00937, 0.012821, 0.40503, 0.026151, 0.045035, 0.018257]
Predicted label: 0
Correct prediction
Energy consumption = 150.088177 pJ
sum error= 144
Actual label: 4
Output voltages: [0.032618, 0.011213, 0.056275, 0.077184, 0.79865, 0.013744, 0.076911, 0.032375, 0.027441, 0.20848]
Predicted label: 4
Correct prediction
Energy consumption = 156.282808 pJ
sum error= 144
Actual label: 4
Output voltages: [0.018184, 0.0064976, 0.54087, 0.032804, 0.79872, 0.0010823, 0.042885, 0.093528, 0.023215, 0.16312]
Predicted label: 4
Correct prediction
Energy consumption = 132.404474 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 271 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 271 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 271 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.33279, 0.032602, 0.085946, 0.33133, 0.0022418, 0.0010701, 0.0020187, 0.79871, 0.058603, 0.41028]
Predicted label: 7
Correct prediction
Energy consumption = 177.702011 pJ
sum error= 144
Actual label: 6
Output voltages: [0.17351, 0.029156, 0.33553, 0.0013331, 0.23243, 0.39326, 0.79873, 0.0086203, 0.47767, 0.01611]
Predicted label: 6
Correct prediction
Energy consumption = 147.974588 pJ
sum error= 144
Actual label: 3
Output voltages: [0.30752, 0.011882, 0.034577, 0.7987, 0.014242, 0.015457, 0.0087499, 0.012568, 0.50667, 0.11736]
Predicted label: 3
Correct prediction
Energy consumption = 148.983549 pJ
sum error= 144
Actual label: 0
Output voltages: [0.78949, 0.048192, 0.23697, 0.046594, 0.022094, 0.0010719, 0.55751, 0.010472, 0.73302, 0.076699]
Predicted label: 0
Correct prediction
Energy consumption = 158.387902 pJ
sum error= 144
Actual label: 0
Output voltages: [0.79879, 0.067018, 0.016364, 0.015152, 0.030299, 0.010093, 0.74288, 0.0097901, 0.069912, 0.14459]
Predicted label: 0
Correct prediction
Energy consumption = 142.234777 pJ
sum error= 144
Actual label: 4
Output voltages: [0.0010833, 0.011199, 0.046372, 0.039, 0.79879, 0.0011592, 0.009289, 0.46812, 0.15245, 0.0029113]
Predicted label: 4
Correct prediction
Energy consumption = 152.539044 pJ
sum error= 144
Actual label: 3
Output voltages: [0.40055, 0.0088086, 0.28256, 0.79877, 0.04575, 0.0028361, 0.012282, 0.0010793, 0.67384, 0.037106]
Predicted label: 3
Correct prediction
Energy consumption = 149.312215 pJ
sum error= 144
Actual label: 0
Output voltages: [0.7986, 0.085327, 0.048585, 0.015591, 0.0018414, 0.0034786, 0.45228, 0.0027289, 0.061237, 0.10203]
Predicted label: 0
Correct prediction
Energy consumption = 152.666867 pJ
sum error= 144
Actual label: 6
Output voltages: [0.048463, 0.013821, 0.050565, 0.015037, 0.28904, 0.10722, 0.79871, 0.011051, 0.56997, 0.0034189]
Predicted label: 6
Correct prediction
Energy consumption = 149.079657 pJ
sum error= 144
Actual label: 1
Output voltages: [0.028997, 0.7987, 0.0011622, 0.039011, 0.46456, 0.03823, 0.72285, 0.0038934, 0.029715, 0.030372]
Predicted label: 1
Correct prediction
Energy consumption = 154.054441 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 272 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 272 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 272 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.068984, 0.0015972, 0.045336, 0.055977, 0.53614, 0.0012566, 0.0015513, 0.0086422, 0.48984, 0.78351]
Predicted label: 9
Correct prediction
Energy consumption = 177.137878 pJ
sum error= 144
Actual label: 6
Output voltages: [0.028674, 0.0081383, 0.17959, 0.022058, 0.035342, 0.72371, 0.79847, 0.0010777, 0.75733, 0.035721]
Predicted label: 6
Correct prediction
Energy consumption = 153.351183 pJ
sum error= 144
Actual label: 1
Output voltages: [0.003602, 0.79868, 0.069053, 0.14434, 0.014601, 0.0012365, 0.038334, 0.0022248, 0.57161, 0.14733]
Predicted label: 1
Correct prediction
Energy consumption = 168.376484 pJ
sum error= 144
Actual label: 3
Output voltages: [0.28588, 0.013119, 0.46431, 0.79879, 0.026264, 0.001655, 0.002867, 0.0022873, 0.65557, 0.021378]
Predicted label: 3
Correct prediction
Energy consumption = 144.599386 pJ
sum error= 144
Actual label: 8
Output voltages: [0.0014926, 0.0083928, 0.27461, 0.018498, 0.013845, 0.22756, 0.60444, 0.0011068, 0.79531, 0.052306]
Predicted label: 8
Correct prediction
Energy consumption = 151.560562 pJ
sum error= 144
Actual label: 1
Output voltages: [0.032017, 0.7986, 0.04303, 0.0063609, 0.21598, 0.0020477, 0.54911, 0.0026605, 0.2203, 0.028806]
Predicted label: 1
Correct prediction
Energy consumption = 160.293876 pJ
sum error= 144
Actual label: 2
Output voltages: [0.50772, 0.0063551, 0.79871, 0.093855, 0.005686, 0.0012521, 0.044492, 0.067029, 0.52986, 0.01385]
Predicted label: 2
Correct prediction
Energy consumption = 148.630163 pJ
sum error= 144
Actual label: 5
Output voltages: [0.077307, 0.0010796, 0.0030851, 0.23884, 0.028358, 0.79859, 0.07218, 0.068637, 0.79301, 0.027689]
Predicted label: 5
Correct prediction
Energy consumption = 148.424009 pJ
sum error= 144
Actual label: 6
Output voltages: [0.2349, 0.080594, 0.27232, 0.0018621, 0.11024, 0.27541, 0.79873, 0.0048501, 0.55055, 0.0069648]
Predicted label: 6
Correct prediction
Energy consumption = 153.354053 pJ
sum error= 144
Actual label: 2
Output voltages: [0.41318, 0.28796, 0.79866, 0.052016, 0.021966, 0.0011915, 0.20881, 0.2696, 0.36801, 0.030497]
Predicted label: 2
Correct prediction
Energy consumption = 144.649731 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 273 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 273 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 273 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.11313, 0.0010767, 0.28967, 0.75158, 0.63423, 0.0011273, 0.013582, 0.35272, 0.29765, 0.0089261]
Predicted label: 3
Wrong prediction!
Energy consumption = 167.285641 pJ
sum error= 145
Actual label: 3
Output voltages: [0.027276, 0.0092394, 0.037502, 0.79876, 0.35709, 0.36884, 0.36364, 0.010165, 0.38567, 0.12795]
Predicted label: 3
Correct prediction
Energy consumption = 140.565437 pJ
sum error= 145
Actual label: 6
Output voltages: [0.082797, 0.005182, 0.0014793, 0.045141, 0.1802, 0.71361, 0.7977, 0.01123, 0.59827, 0.001237]
Predicted label: 6
Correct prediction
Energy consumption = 155.047225 pJ
sum error= 145
Actual label: 0
Output voltages: [0.79868, 0.05318, 0.42928, 0.017603, 0.035055, 0.0010801, 0.1395, 0.042098, 0.2731, 0.068088]
Predicted label: 0
Correct prediction
Energy consumption = 156.212405 pJ
sum error= 145
Actual label: 1
Output voltages: [0.15295, 0.79408, 0.0035068, 0.014813, 0.74887, 0.0012219, 0.46615, 0.0010851, 0.65841, 0.043824]
Predicted label: 1
Correct prediction
Energy consumption = 151.678762 pJ
sum error= 145
Actual label: 9
Output voltages: [0.78674, 0.012102, 0.10578, 0.32261, 0.079197, 0.032071, 0.14705, 0.18362, 0.001636, 0.77027]
Predicted label: 0
Wrong prediction!
Energy consumption = 156.355535 pJ
sum error= 146
Actual label: 7
Output voltages: [0.78228, 0.010822, 0.42659, 0.092934, 0.0048971, 0.0028449, 0.0010785, 0.79875, 0.41771, 0.18984]
Predicted label: 7
Correct prediction
Energy consumption = 146.524340 pJ
sum error= 146
Actual label: 6
Output voltages: [0.1222, 0.23881, 0.34758, 0.0046812, 0.078011, 0.074147, 0.79876, 0.0013055, 0.32632, 0.0070458]
Predicted label: 6
Correct prediction
Energy consumption = 153.562912 pJ
sum error= 146
Actual label: 6
Output voltages: [0.12595, 0.38151, 0.32508, 0.0015493, 0.15714, 0.23014, 0.79869, 0.001938, 0.26937, 0.011122]
Predicted label: 6
Correct prediction
Energy consumption = 142.395346 pJ
sum error= 146
Actual label: 8
Output voltages: [0.15102, 0.087203, 0.029258, 0.269, 0.013837, 0.0013328, 0.031544, 0.0022488, 0.79755, 0.62409]
Predicted label: 8
Correct prediction
Energy consumption = 154.842941 pJ
sum error= 146
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 274 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 274 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 274 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.55525, 0.016999, 0.018215, 0.16332, 0.42258, 0.0019534, 0.0010758, 0.022901, 0.28858, 0.79277]
Predicted label: 9
Correct prediction
Energy consumption = 171.020622 pJ
sum error= 146
Actual label: 2
Output voltages: [0.30163, 0.27365, 0.7986, 0.03373, 0.0074418, 0.0011492, 0.055552, 0.12761, 0.27226, 0.0085042]
Predicted label: 2
Correct prediction
Energy consumption = 150.796298 pJ
sum error= 146
Actual label: 9
Output voltages: [0.76998, 0.029105, 0.075307, 0.48418, 0.0046797, 0.0037537, 0.072889, 0.045209, 0.64181, 0.79777]
Predicted label: 9
Correct prediction
Energy consumption = 164.092445 pJ
sum error= 146
Actual label: 5
Output voltages: [0.0099934, 0.0050055, 0.010038, 0.078785, 0.013871, 0.79843, 0.58396, 0.001749, 0.63415, 0.023835]
Predicted label: 5
Correct prediction
Energy consumption = 156.011822 pJ
sum error= 146
Actual label: 8
Output voltages: [0.0049849, 0.031842, 0.079244, 0.027063, 0.035369, 0.046646, 0.028248, 0.0094214, 0.79873, 0.26337]
Predicted label: 8
Correct prediction
Energy consumption = 144.093204 pJ
sum error= 146
Actual label: 3
Output voltages: [0.20385, 0.021483, 0.41214, 0.79877, 0.023185, 0.001094, 0.011234, 0.0030771, 0.49157, 0.01314]
Predicted label: 3
Correct prediction
Energy consumption = 140.269689 pJ
sum error= 146
Actual label: 1
Output voltages: [0.013545, 0.79876, 0.0084698, 0.0068411, 0.031942, 0.0015689, 0.50596, 0.022306, 0.32272, 0.043842]
Predicted label: 1
Correct prediction
Energy consumption = 155.653028 pJ
sum error= 146
Actual label: 0
Output voltages: [0.79872, 0.073559, 0.021819, 0.0083283, 0.12315, 0.0098688, 0.64708, 0.030518, 0.038157, 0.04962]
Predicted label: 0
Correct prediction
Energy consumption = 152.745769 pJ
sum error= 146
Actual label: 0
Output voltages: [0.79878, 0.01757, 0.011476, 0.0034456, 0.029589, 0.0053923, 0.32484, 0.048155, 0.22406, 0.15262]
Predicted label: 0
Correct prediction
Energy consumption = 147.097229 pJ
sum error= 146
Actual label: 7
Output voltages: [0.4193, 0.0038034, 0.0038281, 0.052734, 0.043539, 0.34373, 0.0010734, 0.79879, 0.35861, 0.70942]
Predicted label: 7
Correct prediction
Energy consumption = 151.443093 pJ
sum error= 146
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 275 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 275 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 275 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.041448, 0.15217, 0.07484, 0.058201, 0.010007, 0.11793, 0.795, 0.011323, 0.79714, 0.0057052]
Predicted label: 8
Wrong prediction!
Energy consumption = 169.278546 pJ
sum error= 147
Actual label: 6
Output voltages: [0.64654, 0.041297, 0.010222, 0.0035235, 0.17277, 0.49392, 0.79855, 0.013542, 0.37147, 0.0010668]
Predicted label: 6
Correct prediction
Energy consumption = 139.851033 pJ
sum error= 147
Actual label: 2
Output voltages: [0.47545, 0.018419, 0.79869, 0.024752, 0.058414, 0.0010719, 0.18032, 0.041621, 0.39137, 0.02827]
Predicted label: 2
Correct prediction
Energy consumption = 145.330710 pJ
sum error= 147
Actual label: 1
Output voltages: [0.027894, 0.79878, 0.036364, 0.031715, 0.33338, 0.0053832, 0.69388, 0.002003, 0.4905, 0.022767]
Predicted label: 1
Correct prediction
Energy consumption = 145.106056 pJ
sum error= 147
Actual label: 6
Output voltages: [0.63631, 0.032591, 0.21764, 0.0012119, 0.233, 0.0036186, 0.7984, 0.0060136, 0.14225, 0.012444]
Predicted label: 6
Correct prediction
Energy consumption = 145.515826 pJ
sum error= 147
Actual label: 9
Output voltages: [0.40631, 0.0099765, 0.030718, 0.015017, 0.14498, 0.026109, 0.0044986, 0.023331, 0.47662, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 156.037166 pJ
sum error= 147
Actual label: 3
Output voltages: [0.7045, 0.076947, 0.10731, 0.7987, 0.0058555, 0.29153, 0.47275, 0.022531, 0.038846, 0.001066]
Predicted label: 3
Correct prediction
Energy consumption = 151.371743 pJ
sum error= 147
Actual label: 1
Output voltages: [0.030772, 0.79852, 0.28423, 0.037531, 0.019937, 0.0016847, 0.73589, 0.0012648, 0.052578, 0.043393]
Predicted label: 1
Correct prediction
Energy consumption = 159.333856 pJ
sum error= 147
Actual label: 8
Output voltages: [0.26452, 0.0032009, 0.026915, 0.70884, 0.0091397, 0.072972, 0.054304, 0.011925, 0.79879, 0.061591]
Predicted label: 8
Correct prediction
Energy consumption = 154.518149 pJ
sum error= 147
Actual label: 6
Output voltages: [0.043118, 0.035498, 0.13392, 0.0032945, 0.26323, 0.38897, 0.7987, 0.0040988, 0.55377, 0.0045417]
Predicted label: 6
Correct prediction
Energy consumption = 145.143393 pJ
sum error= 147
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 276 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 276 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 276 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.29974, 0.034585, 0.14798, 0.019096, 0.79608, 0.00109, 0.0051259, 0.0068058, 0.040646, 0.67373]
Predicted label: 4
Wrong prediction!
Energy consumption = 180.801511 pJ
sum error= 148
Actual label: 0
Output voltages: [0.79568, 0.028597, 0.016124, 0.004205, 0.037321, 0.0099235, 0.72566, 0.014901, 0.13345, 0.0051946]
Predicted label: 0
Correct prediction
Energy consumption = 152.441119 pJ
sum error= 148
Actual label: 6
Output voltages: [0.32866, 0.051656, 0.099901, 0.0024477, 0.46976, 0.41187, 0.79875, 0.0012226, 0.45697, 0.011059]
Predicted label: 6
Correct prediction
Energy consumption = 151.084778 pJ
sum error= 148
Actual label: 0
Output voltages: [0.79871, 0.15982, 0.023777, 0.0094664, 0.0066023, 0.0027771, 0.52375, 0.02198, 0.10647, 0.041224]
Predicted label: 0
Correct prediction
Energy consumption = 152.074460 pJ
sum error= 148
Actual label: 0
Output voltages: [0.79879, 0.035697, 0.27127, 0.10289, 0.026126, 0.0082786, 0.20566, 0.020523, 0.37023, 0.038993]
Predicted label: 0
Correct prediction
Energy consumption = 154.432741 pJ
sum error= 148
Actual label: 0
Output voltages: [0.79869, 0.028065, 0.030184, 0.022919, 0.010382, 0.0054918, 0.63765, 0.014573, 0.14599, 0.11154]
Predicted label: 0
Correct prediction
Energy consumption = 148.296360 pJ
sum error= 148
Actual label: 6
Output voltages: [0.10372, 0.2175, 0.13985, 0.001936, 0.15338, 0.30664, 0.79863, 0.0038338, 0.31009, 0.0087291]
Predicted label: 6
Correct prediction
Energy consumption = 142.088997 pJ
sum error= 148
Actual label: 3
Output voltages: [0.06381, 0.024375, 0.22589, 0.79872, 0.011331, 0.0011136, 0.0056947, 0.0010911, 0.53371, 0.12599]
Predicted label: 3
Correct prediction
Energy consumption = 148.820965 pJ
sum error= 148
Actual label: 5
Output voltages: [0.17098, 0.0016071, 0.011661, 0.35644, 0.018138, 0.79629, 0.014743, 0.020601, 0.76765, 0.27285]
Predicted label: 5
Correct prediction
Energy consumption = 141.722081 pJ
sum error= 148
Actual label: 9
Output voltages: [0.055543, 0.027963, 0.015245, 0.030976, 0.038843, 0.0014298, 0.0012122, 0.0022958, 0.68537, 0.79784]
Predicted label: 9
Correct prediction
Energy consumption = 148.850543 pJ
sum error= 148
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 277 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 277 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 277 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.025778, 0.0011003, 0.2644, 0.67437, 0.0010677, 0.40248, 0.0064356, 0.060295, 0.79607, 0.015776]
Predicted label: 8
Wrong prediction!
Energy consumption = 160.069886 pJ
sum error= 149
Actual label: 4
Output voltages: [0.01516, 0.038554, 0.026962, 0.027284, 0.78612, 0.01659, 0.023547, 0.030241, 0.24765, 0.78534]
Predicted label: 4
Correct prediction
Energy consumption = 161.342703 pJ
sum error= 149
Actual label: 5
Output voltages: [0.0095683, 0.0070419, 0.0011226, 0.15741, 0.047549, 0.79869, 0.45646, 0.021811, 0.75913, 0.032501]
Predicted label: 5
Correct prediction
Energy consumption = 144.087335 pJ
sum error= 149
Actual label: 5
Output voltages: [0.042359, 0.0010913, 0.017249, 0.088903, 0.024504, 0.78125, 0.20883, 0.01108, 0.79646, 0.18181]
Predicted label: 8
Wrong prediction!
Energy consumption = 137.974598 pJ
sum error= 150
Actual label: 8
Output voltages: [0.093047, 0.031106, 0.10446, 0.035955, 0.020984, 0.11904, 0.026967, 0.0098044, 0.79878, 0.2779]
Predicted label: 8
Correct prediction
Energy consumption = 138.552493 pJ
sum error= 150
Actual label: 5
Output voltages: [0.0083032, 0.0010748, 0.0033974, 0.13717, 0.084709, 0.79865, 0.28421, 0.028089, 0.78415, 0.046304]
Predicted label: 5
Correct prediction
Energy consumption = 136.634919 pJ
sum error= 150
Actual label: 3
Output voltages: [0.19987, 0.051432, 0.03148, 0.7987, 0.0086968, 0.005181, 0.0032462, 0.0036771, 0.63183, 0.033487]
Predicted label: 3
Correct prediction
Energy consumption = 140.931941 pJ
sum error= 150
Actual label: 0
Output voltages: [0.79855, 0.055598, 0.0095209, 0.0092791, 0.070411, 0.03668, 0.77386, 0.1369, 0.065109, 0.028485]
Predicted label: 0
Correct prediction
Energy consumption = 155.709584 pJ
sum error= 150
Actual label: 4
Output voltages: [0.23422, 0.19804, 0.14643, 0.014564, 0.79677, 0.0011354, 0.39429, 0.14138, 0.0076589, 0.65187]
Predicted label: 4
Correct prediction
Energy consumption = 153.013897 pJ
sum error= 150
Actual label: 0
Output voltages: [0.79877, 0.048861, 0.013618, 0.0099537, 0.016779, 0.039372, 0.35254, 0.037204, 0.27289, 0.037392]
Predicted label: 0
Correct prediction
Energy consumption = 153.754396 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 278 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 278 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 278 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.66889, 0.0011033, 0.79362, 0.75049, 0.028298, 0.0025445, 0.013309, 0.010088, 0.78456, 0.16272]
Predicted label: 2
Correct prediction
Energy consumption = 168.602691 pJ
sum error= 150
Actual label: 9
Output voltages: [0.50126, 0.0030608, 0.017646, 0.040722, 0.31233, 0.045602, 0.02196, 0.036026, 0.30554, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 154.150782 pJ
sum error= 150
Actual label: 6
Output voltages: [0.046139, 0.0078386, 0.42602, 0.0043641, 0.03937, 0.37102, 0.79847, 0.0011298, 0.55406, 0.041777]
Predicted label: 6
Correct prediction
Energy consumption = 148.579868 pJ
sum error= 150
Actual label: 8
Output voltages: [0.027338, 0.01644, 0.056787, 0.51167, 0.0054531, 0.009135, 0.018748, 0.0081364, 0.79879, 0.14035]
Predicted label: 8
Correct prediction
Energy consumption = 142.990517 pJ
sum error= 150
Actual label: 2
Output voltages: [0.32099, 0.47413, 0.79879, 0.012558, 0.053509, 0.001217, 0.025729, 0.50827, 0.46243, 0.0099649]
Predicted label: 2
Correct prediction
Energy consumption = 147.826652 pJ
sum error= 150
Actual label: 3
Output voltages: [0.31375, 0.015333, 0.038826, 0.79868, 0.016074, 0.019016, 0.0092347, 0.01639, 0.537, 0.12728]
Predicted label: 3
Correct prediction
Energy consumption = 143.164479 pJ
sum error= 150
Actual label: 1
Output voltages: [0.23019, 0.79835, 0.031352, 0.079806, 0.0052782, 0.0032122, 0.75925, 0.018196, 0.028747, 0.16469]
Predicted label: 1
Correct prediction
Energy consumption = 160.179887 pJ
sum error= 150
Actual label: 2
Output voltages: [0.75357, 0.0054627, 0.79876, 0.55762, 0.011435, 0.0025778, 0.052378, 0.088937, 0.63029, 0.011616]
Predicted label: 2
Correct prediction
Energy consumption = 154.151546 pJ
sum error= 150
Actual label: 1
Output voltages: [0.01946, 0.79842, 0.009647, 0.040964, 0.013392, 0.016678, 0.67055, 0.0023843, 0.38306, 0.036571]
Predicted label: 1
Correct prediction
Energy consumption = 163.034160 pJ
sum error= 150
Actual label: 1
Output voltages: [0.023291, 0.79726, 0.27374, 0.030587, 0.46517, 0.0011844, 0.089357, 0.004109, 0.027995, 0.24231]
Predicted label: 1
Correct prediction
Energy consumption = 144.887206 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 279 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 279 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 279 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25439, 0.0018034, 0.0047914, 0.47131, 0.0042219, 0.79877, 0.27464, 0.032725, 0.76263, 0.005456]
Predicted label: 5
Correct prediction
Energy consumption = 165.639112 pJ
sum error= 150
Actual label: 6
Output voltages: [0.281, 0.16178, 0.23694, 0.0096369, 0.22028, 0.044583, 0.79878, 0.0012823, 0.44964, 0.017548]
Predicted label: 6
Correct prediction
Energy consumption = 151.389437 pJ
sum error= 150
Actual label: 9
Output voltages: [0.2551, 0.031077, 0.037288, 0.048333, 0.054516, 0.039242, 0.0098929, 0.039036, 0.39131, 0.7978]
Predicted label: 9
Correct prediction
Energy consumption = 152.593197 pJ
sum error= 150
Actual label: 8
Output voltages: [0.045529, 0.030168, 0.49595, 0.0066779, 0.095142, 0.0013644, 0.052604, 0.0014966, 0.79878, 0.55328]
Predicted label: 8
Correct prediction
Energy consumption = 139.769671 pJ
sum error= 150
Actual label: 0
Output voltages: [0.79878, 0.050684, 0.026194, 0.040153, 0.011655, 0.011095, 0.52713, 0.012196, 0.33878, 0.62968]
Predicted label: 0
Correct prediction
Energy consumption = 159.681670 pJ
sum error= 150
Actual label: 6
Output voltages: [0.032943, 0.13665, 0.2506, 0.0028058, 0.31265, 0.10045, 0.79864, 0.0015572, 0.6078, 0.01851]
Predicted label: 6
Correct prediction
Energy consumption = 148.890691 pJ
sum error= 150
Actual label: 6
Output voltages: [0.032625, 0.2944, 0.19824, 0.022355, 0.053838, 0.34328, 0.7987, 0.0067781, 0.73423, 0.0061119]
Predicted label: 6
Correct prediction
Energy consumption = 141.003099 pJ
sum error= 150
Actual label: 5
Output voltages: [0.06717, 0.0056089, 0.0015363, 0.5694, 0.15856, 0.79876, 0.042713, 0.030273, 0.45039, 0.32633]
Predicted label: 5
Correct prediction
Energy consumption = 148.729534 pJ
sum error= 150
Actual label: 5
Output voltages: [0.040908, 0.0010659, 0.0050935, 0.045765, 0.025811, 0.79879, 0.37335, 0.021994, 0.77994, 0.022316]
Predicted label: 5
Correct prediction
Energy consumption = 137.372829 pJ
sum error= 150
Actual label: 3
Output voltages: [0.50654, 0.0086469, 0.2044, 0.79872, 0.030128, 0.013946, 0.01566, 0.024393, 0.45951, 0.010889]
Predicted label: 3
Correct prediction
Energy consumption = 135.975117 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 280 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 280 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 280 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.06632, 0.005748, 0.24535, 0.38887, 0.0083126, 0.020806, 0.0037062, 0.013506, 0.79874, 0.11237]
Predicted label: 8
Correct prediction
Energy consumption = 173.883896 pJ
sum error= 150
Actual label: 6
Output voltages: [0.18002, 0.02895, 0.064097, 0.0029157, 0.34519, 0.073064, 0.79879, 0.0014703, 0.43577, 0.014873]
Predicted label: 6
Correct prediction
Energy consumption = 144.853038 pJ
sum error= 150
Actual label: 2
Output voltages: [0.78838, 0.079997, 0.79878, 0.15399, 0.0033716, 0.0011306, 0.11022, 0.026502, 0.26178, 0.072123]
Predicted label: 2
Correct prediction
Energy consumption = 146.763425 pJ
sum error= 150
Actual label: 1
Output voltages: [0.011008, 0.79869, 0.0012654, 0.061431, 0.30002, 0.0045216, 0.01393, 0.0026875, 0.34761, 0.32503]
Predicted label: 1
Correct prediction
Energy consumption = 164.524610 pJ
sum error= 150
Actual label: 4
Output voltages: [0.0054458, 0.00383, 0.034163, 0.010458, 0.79864, 0.0029385, 0.20994, 0.1132, 0.33401, 0.0045887]
Predicted label: 4
Correct prediction
Energy consumption = 151.911587 pJ
sum error= 150
Actual label: 5
Output voltages: [0.017596, 0.0042803, 0.0013347, 0.27751, 0.3048, 0.79865, 0.23144, 0.0016303, 0.49492, 0.27698]
Predicted label: 5
Correct prediction
Energy consumption = 146.553712 pJ
sum error= 150
Actual label: 4
Output voltages: [0.0048129, 0.012846, 0.20097, 0.026866, 0.7986, 0.0037656, 0.087461, 0.022922, 0.029252, 0.046776]
Predicted label: 4
Correct prediction
Energy consumption = 152.550713 pJ
sum error= 150
Actual label: 3
Output voltages: [0.65561, 0.018589, 0.040826, 0.79858, 0.046253, 0.012389, 0.014831, 0.0058487, 0.556, 0.055828]
Predicted label: 3
Correct prediction
Energy consumption = 152.878467 pJ
sum error= 150
Actual label: 7
Output voltages: [0.30854, 0.042317, 0.0055663, 0.054141, 0.011878, 0.017187, 0.0010743, 0.79875, 0.35869, 0.51825]
Predicted label: 7
Correct prediction
Energy consumption = 160.750717 pJ
sum error= 150
Actual label: 8
Output voltages: [0.035559, 0.0059925, 0.016685, 0.094988, 0.085345, 0.057103, 0.22424, 0.010647, 0.79872, 0.038863]
Predicted label: 8
Correct prediction
Energy consumption = 147.862155 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 281 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 281 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 281 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.41388, 0.0010829, 0.024947, 0.76134, 0.066604, 0.52855, 0.017137, 0.0089299, 0.66476, 0.14414]
Predicted label: 3
Wrong prediction!
Energy consumption = 171.635579 pJ
sum error= 151
Actual label: 0
Output voltages: [0.79877, 0.018649, 0.054235, 0.019764, 0.010943, 0.0064159, 0.70765, 0.023433, 0.12037, 0.14612]
Predicted label: 0
Correct prediction
Energy consumption = 139.957608 pJ
sum error= 151
Actual label: 9
Output voltages: [0.56662, 0.013123, 0.025237, 0.0016537, 0.71682, 0.0010748, 0.021904, 0.0084862, 0.053119, 0.78907]
Predicted label: 9
Correct prediction
Energy consumption = 160.519571 pJ
sum error= 151
Actual label: 3
Output voltages: [0.5566, 0.041266, 0.037105, 0.79877, 0.0019824, 0.012097, 0.066849, 0.026441, 0.32476, 0.0062499]
Predicted label: 3
Correct prediction
Energy consumption = 146.189882 pJ
sum error= 151
Actual label: 5
Output voltages: [0.19515, 0.0011507, 0.024443, 0.38013, 0.002955, 0.79804, 0.038138, 0.010466, 0.79181, 0.063167]
Predicted label: 5
Correct prediction
Energy consumption = 146.024374 pJ
sum error= 151
Actual label: 1
Output voltages: [0.021196, 0.79875, 0.11031, 0.56357, 0.058732, 0.034887, 0.015997, 0.011817, 0.0050915, 0.28737]
Predicted label: 1
Correct prediction
Energy consumption = 165.351317 pJ
sum error= 151
Actual label: 1
Output voltages: [0.019245, 0.7987, 0.010167, 0.038031, 0.19159, 0.0064426, 0.59309, 0.0031652, 0.048745, 0.0092207]
Predicted label: 1
Correct prediction
Energy consumption = 153.958076 pJ
sum error= 151
Actual label: 0
Output voltages: [0.79871, 0.061412, 0.030887, 0.013177, 0.013507, 0.0031112, 0.70064, 0.025884, 0.11399, 0.046946]
Predicted label: 0
Correct prediction
Energy consumption = 150.509944 pJ
sum error= 151
Actual label: 4
Output voltages: [0.011197, 0.0069779, 0.10701, 0.020423, 0.79868, 0.034159, 0.018627, 0.0097616, 0.061758, 0.038546]
Predicted label: 4
Correct prediction
Energy consumption = 152.728191 pJ
sum error= 151
Actual label: 4
Output voltages: [0.0084658, 0.032571, 0.052333, 0.046937, 0.79863, 0.0079827, 0.18065, 0.19877, 0.029243, 0.0098011]
Predicted label: 4
Correct prediction
Energy consumption = 140.967098 pJ
sum error= 151
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 282 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 282 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 282 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.019406, 0.022791, 0.23665, 0.043309, 0.021959, 0.0012344, 0.0014726, 0.79879, 0.28655, 0.036133]
Predicted label: 7
Correct prediction
Energy consumption = 164.363733 pJ
sum error= 151
Actual label: 0
Output voltages: [0.79824, 0.28467, 0.010485, 0.0091681, 0.039104, 0.023941, 0.7666, 0.012856, 0.036793, 0.025927]
Predicted label: 0
Correct prediction
Energy consumption = 155.186199 pJ
sum error= 151
Actual label: 1
Output voltages: [0.039564, 0.79847, 0.32326, 0.18753, 0.044667, 0.0042204, 0.15323, 0.13413, 0.0073893, 0.24273]
Predicted label: 1
Correct prediction
Energy consumption = 164.238305 pJ
sum error= 151
Actual label: 7
Output voltages: [0.0014331, 0.012714, 0.039495, 0.39768, 0.019854, 0.38904, 0.0012236, 0.65001, 0.51555, 0.16823]
Predicted label: 7
Correct prediction
Energy consumption = 145.183198 pJ
sum error= 151
Actual label: 0
Output voltages: [0.79879, 0.22503, 0.040176, 0.021348, 0.023119, 0.0059278, 0.61577, 0.018107, 0.20048, 0.38651]
Predicted label: 0
Correct prediction
Energy consumption = 165.148925 pJ
sum error= 151
Actual label: 1
Output voltages: [0.091321, 0.79866, 0.035426, 0.21138, 0.0013477, 0.0043289, 0.51899, 0.002254, 0.1915, 0.049541]
Predicted label: 1
Correct prediction
Energy consumption = 159.578190 pJ
sum error= 151
Actual label: 6
Output voltages: [0.021685, 0.04486, 0.6658, 0.0030659, 0.045042, 0.049622, 0.79879, 0.0029125, 0.5623, 0.017079]
Predicted label: 6
Correct prediction
Energy consumption = 139.862221 pJ
sum error= 151
Actual label: 1
Output voltages: [0.17992, 0.79878, 0.011141, 0.010817, 0.28013, 0.0077641, 0.22847, 0.0012446, 0.37021, 0.72342]
Predicted label: 1
Correct prediction
Energy consumption = 163.440417 pJ
sum error= 151
Actual label: 4
Output voltages: [0.0027828, 0.0046964, 0.059781, 0.0065569, 0.79861, 0.018329, 0.059318, 0.21876, 0.29805, 0.0028402]
Predicted label: 4
Correct prediction
Energy consumption = 143.804399 pJ
sum error= 151
Actual label: 5
Output voltages: [0.0097355, 0.0015075, 0.01267, 0.53787, 0.044156, 0.7846, 0.036457, 0.11028, 0.7541, 0.37454]
Predicted label: 5
Correct prediction
Energy consumption = 151.411217 pJ
sum error= 151
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 283 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 283 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 283 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.47857, 0.0023446, 0.0070211, 0.001545, 0.5493, 0.76925, 0.79864, 0.0020967, 0.34455, 0.063729]
Predicted label: 6
Correct prediction
Energy consumption = 157.876770 pJ
sum error= 151
Actual label: 6
Output voltages: [0.17594, 0.036126, 0.33646, 0.0084014, 0.07694, 0.26981, 0.79878, 0.001078, 0.632, 0.063263]
Predicted label: 6
Correct prediction
Energy consumption = 143.766421 pJ
sum error= 151
Actual label: 5
Output voltages: [0.022416, 0.0011965, 0.0016683, 0.77838, 0.047974, 0.79879, 0.20027, 0.03445, 0.41806, 0.068363]
Predicted label: 5
Correct prediction
Energy consumption = 147.930654 pJ
sum error= 151
Actual label: 7
Output voltages: [0.45644, 0.17365, 0.0022817, 0.038915, 0.012025, 0.044382, 0.0010915, 0.79869, 0.46172, 0.13526]
Predicted label: 7
Correct prediction
Energy consumption = 153.785504 pJ
sum error= 151
Actual label: 8
Output voltages: [0.45019, 0.0040937, 0.21531, 0.57723, 0.017938, 0.0014699, 0.04902, 0.013688, 0.79022, 0.0052846]
Predicted label: 8
Correct prediction
Energy consumption = 158.354547 pJ
sum error= 151
Actual label: 4
Output voltages: [0.020111, 0.0034857, 0.057165, 0.045397, 0.7987, 0.0011608, 0.062872, 0.028171, 0.010263, 0.12021]
Predicted label: 4
Correct prediction
Energy consumption = 152.639665 pJ
sum error= 151
Actual label: 4
Output voltages: [0.015831, 0.0065439, 0.76888, 0.37974, 0.79522, 0.0011038, 0.0044324, 0.002778, 0.017831, 0.62367]
Predicted label: 4
Correct prediction
Energy consumption = 140.406316 pJ
sum error= 151
Actual label: 7
Output voltages: [0.078748, 0.18201, 0.6428, 0.059079, 0.0014409, 0.0011073, 0.0012847, 0.79879, 0.67165, 0.070208]
Predicted label: 7
Correct prediction
Energy consumption = 149.341376 pJ
sum error= 151
Actual label: 2
Output voltages: [0.047782, 0.1983, 0.79878, 0.14159, 0.0026466, 0.00129, 0.37561, 0.025009, 0.44419, 0.039595]
Predicted label: 2
Correct prediction
Energy consumption = 146.674819 pJ
sum error= 151
Actual label: 5
Output voltages: [0.17127, 0.0040024, 0.031398, 0.050313, 0.0039759, 0.79537, 0.088676, 0.0010939, 0.79495, 0.071714]
Predicted label: 5
Correct prediction
Energy consumption = 143.084796 pJ
sum error= 151
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 284 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 284 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 284 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.52917, 0.017197, 0.053888, 0.79863, 0.089163, 0.0057192, 0.0059361, 0.015461, 0.62426, 0.055501]
Predicted label: 3
Correct prediction
Energy consumption = 163.844990 pJ
sum error= 151
Actual label: 7
Output voltages: [0.016322, 0.13687, 0.49953, 0.030713, 0.017962, 0.0012428, 0.0060547, 0.79876, 0.024079, 0.23029]
Predicted label: 7
Correct prediction
Energy consumption = 146.393822 pJ
sum error= 151
Actual label: 0
Output voltages: [0.79876, 0.048741, 0.0064552, 0.040089, 0.0010663, 0.41581, 0.17246, 0.011629, 0.39984, 0.013731]
Predicted label: 0
Correct prediction
Energy consumption = 154.254997 pJ
sum error= 151
Actual label: 7
Output voltages: [0.26633, 0.016174, 0.77278, 0.028691, 0.0011793, 0.0011225, 0.0010685, 0.79816, 0.5162, 0.271]
Predicted label: 7
Correct prediction
Energy consumption = 139.085331 pJ
sum error= 151
Actual label: 7
Output voltages: [0.18161, 0.08702, 0.24797, 0.048865, 0.0012439, 0.0010704, 0.0011153, 0.79872, 0.55912, 0.11725]
Predicted label: 7
Correct prediction
Energy consumption = 146.443437 pJ
sum error= 151
Actual label: 9
Output voltages: [0.10811, 0.014489, 0.12095, 0.16866, 0.06238, 0.0043497, 0.011974, 0.045875, 0.33811, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 143.803784 pJ
sum error= 151
Actual label: 6
Output voltages: [0.17252, 0.032833, 0.093406, 0.0022167, 0.17952, 0.32303, 0.79879, 0.0034308, 0.48054, 0.0012179]
Predicted label: 6
Correct prediction
Energy consumption = 150.257983 pJ
sum error= 151
Actual label: 4
Output voltages: [0.042738, 0.0077241, 0.003878, 0.027938, 0.79879, 0.0013555, 0.0059712, 0.45627, 0.038244, 0.44597]
Predicted label: 4
Correct prediction
Energy consumption = 152.914071 pJ
sum error= 151
Actual label: 2
Output voltages: [0.01253, 0.25311, 0.7985, 0.21289, 0.0015094, 0.0010994, 0.24465, 0.043293, 0.69428, 0.029282]
Predicted label: 2
Correct prediction
Energy consumption = 155.895869 pJ
sum error= 151
Actual label: 8
Output voltages: [0.042218, 0.018843, 0.026954, 0.037865, 0.042257, 0.19709, 0.016721, 0.012307, 0.7987, 0.016655]
Predicted label: 8
Correct prediction
Energy consumption = 144.444214 pJ
sum error= 151
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 285 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 285 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 285 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.3381, 0.008674, 0.068961, 0.40591, 0.0010758, 0.78288, 0.66443, 0.0013551, 0.074879, 0.0017519]
Predicted label: 5
Correct prediction
Energy consumption = 165.935865 pJ
sum error= 151
Actual label: 7
Output voltages: [0.46195, 0.01361, 0.0086634, 0.068734, 0.23546, 0.017512, 0.0010951, 0.79872, 0.15496, 0.63502]
Predicted label: 7
Correct prediction
Energy consumption = 159.862840 pJ
sum error= 151
Actual label: 8
Output voltages: [0.035567, 0.13482, 0.049707, 0.20197, 0.0099499, 0.0085174, 0.026212, 0.032203, 0.79874, 0.12748]
Predicted label: 8
Correct prediction
Energy consumption = 157.663172 pJ
sum error= 151
Actual label: 3
Output voltages: [0.47952, 0.0048605, 0.33074, 0.79878, 0.00366, 0.0089337, 0.011053, 0.039452, 0.75171, 0.032425]
Predicted label: 3
Correct prediction
Energy consumption = 143.716730 pJ
sum error= 151
Actual label: 9
Output voltages: [0.03958, 0.0088945, 0.005788, 0.015596, 0.035819, 0.0069211, 0.0011102, 0.026665, 0.75431, 0.7947]
Predicted label: 9
Correct prediction
Energy consumption = 147.084041 pJ
sum error= 151
Actual label: 5
Output voltages: [0.14663, 0.039062, 0.0011154, 0.62598, 0.037653, 0.79863, 0.33066, 0.035863, 0.3584, 0.0028525]
Predicted label: 5
Correct prediction
Energy consumption = 150.625252 pJ
sum error= 151
Actual label: 8
Output voltages: [0.031421, 0.019066, 0.017303, 0.28912, 0.0072305, 0.0086584, 0.061367, 0.0044076, 0.79879, 0.090161]
Predicted label: 8
Correct prediction
Energy consumption = 151.606872 pJ
sum error= 151
Actual label: 9
Output voltages: [0.073174, 0.028064, 0.045126, 0.055115, 0.076752, 0.067162, 0.14462, 0.028421, 0.1214, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 155.406781 pJ
sum error= 151
Actual label: 9
Output voltages: [0.042143, 0.011604, 0.024719, 0.30635, 0.67307, 0.0047737, 0.0016237, 0.014723, 0.11311, 0.79643]
Predicted label: 9
Correct prediction
Energy consumption = 151.088542 pJ
sum error= 151
Actual label: 8
Output voltages: [0.019016, 0.023061, 0.16391, 0.16375, 0.0071821, 0.019498, 0.092665, 0.034415, 0.79878, 0.059052]
Predicted label: 8
Correct prediction
Energy consumption = 149.346248 pJ
sum error= 151
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 286 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 286 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 286 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.038138, 0.019744, 0.2751, 0.0010718, 0.04287, 0.29842, 0.79876, 0.003403, 0.59667, 0.0018132]
Predicted label: 6
Correct prediction
Energy consumption = 168.034008 pJ
sum error= 151
Actual label: 2
Output voltages: [0.067203, 0.19478, 0.79877, 0.21355, 0.0054173, 0.0013337, 0.1459, 0.27518, 0.34355, 0.03169]
Predicted label: 2
Correct prediction
Energy consumption = 150.620783 pJ
sum error= 151
Actual label: 8
Output voltages: [0.11885, 0.19565, 0.014593, 0.28458, 0.002494, 0.015467, 0.023065, 0.0020427, 0.79879, 0.43605]
Predicted label: 8
Correct prediction
Energy consumption = 154.022571 pJ
sum error= 151
Actual label: 9
Output voltages: [0.0031165, 0.02004, 0.057188, 0.03719, 0.79791, 0.012537, 0.035975, 0.0081746, 0.1415, 0.40749]
Predicted label: 4
Wrong prediction!
Energy consumption = 155.923650 pJ
sum error= 152
Actual label: 2
Output voltages: [0.39459, 0.023641, 0.79879, 0.1283, 0.0065989, 0.0011893, 0.22298, 0.16154, 0.5649, 0.0438]
Predicted label: 2
Correct prediction
Energy consumption = 146.010183 pJ
sum error= 152
Actual label: 3
Output voltages: [0.20921, 0.019345, 0.041356, 0.79862, 0.024929, 0.0034844, 0.025496, 0.042178, 0.59701, 0.050187]
Predicted label: 3
Correct prediction
Energy consumption = 140.596544 pJ
sum error= 152
Actual label: 6
Output voltages: [0.032461, 0.0068944, 0.03348, 0.0059847, 0.25165, 0.74177, 0.79835, 0.0049965, 0.60086, 0.0010848]
Predicted label: 6
Correct prediction
Energy consumption = 151.452224 pJ
sum error= 152
Actual label: 1
Output voltages: [0.0022632, 0.79844, 0.055484, 0.029713, 0.023036, 0.018859, 0.67012, 0.0079826, 0.42658, 0.17211]
Predicted label: 1
Correct prediction
Energy consumption = 163.252705 pJ
sum error= 152
Actual label: 1
Output voltages: [0.03252, 0.79841, 0.016969, 0.086776, 0.017885, 0.0040336, 0.68032, 0.0066794, 0.20331, 0.084493]
Predicted label: 1
Correct prediction
Energy consumption = 154.644026 pJ
sum error= 152
Actual label: 8
Output voltages: [0.023759, 0.021054, 0.23119, 0.035459, 0.022479, 0.021611, 0.031728, 0.011003, 0.79874, 0.096832]
Predicted label: 8
Correct prediction
Energy consumption = 143.246209 pJ
sum error= 152
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 287 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 287 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 287 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.2868, 0.015835, 0.27945, 0.27119, 0.037195, 0.051979, 0.020632, 0.044803, 0.14947, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 175.288688 pJ
sum error= 152
Actual label: 3
Output voltages: [0.14608, 0.014429, 0.044147, 0.79872, 0.024686, 0.019678, 0.013252, 0.0041135, 0.49408, 0.057947]
Predicted label: 3
Correct prediction
Energy consumption = 148.036353 pJ
sum error= 152
Actual label: 4
Output voltages: [0.014691, 0.0037638, 0.29152, 0.011577, 0.79874, 0.0041296, 0.012649, 0.014466, 0.079257, 0.29414]
Predicted label: 4
Correct prediction
Energy consumption = 157.260047 pJ
sum error= 152
Actual label: 0
Output voltages: [0.79878, 0.095666, 0.013029, 0.017432, 0.037009, 0.024974, 0.71009, 0.0052121, 0.050295, 0.029035]
Predicted label: 0
Correct prediction
Energy consumption = 158.341202 pJ
sum error= 152
Actual label: 7
Output voltages: [0.55173, 0.0037124, 0.2603, 0.29975, 0.0068761, 0.001066, 0.0011724, 0.79878, 0.36428, 0.02701]
Predicted label: 7
Correct prediction
Energy consumption = 157.827100 pJ
sum error= 152
Actual label: 9
Output voltages: [0.16867, 0.023644, 0.011066, 0.15624, 0.79843, 0.0012798, 0.0084924, 0.016631, 0.016774, 0.77219]
Predicted label: 4
Wrong prediction!
Energy consumption = 151.014413 pJ
sum error= 153
Actual label: 6
Output voltages: [0.17518, 0.0050864, 0.04072, 0.014955, 0.22456, 0.71229, 0.79768, 0.0010685, 0.51661, 0.11336]
Predicted label: 6
Correct prediction
Energy consumption = 150.269977 pJ
sum error= 153
Actual label: 4
Output voltages: [0.051386, 0.0010668, 0.043668, 0.044651, 0.77275, 0.0020422, 0.019484, 0.032335, 0.044945, 0.7569]
Predicted label: 4
Correct prediction
Energy consumption = 149.411234 pJ
sum error= 153
Actual label: 1
Output voltages: [0.027293, 0.79842, 0.037192, 0.15772, 0.0023157, 0.0058899, 0.60719, 0.0014019, 0.048536, 0.020461]
Predicted label: 1
Correct prediction
Energy consumption = 168.403718 pJ
sum error= 153
Actual label: 4
Output voltages: [0.11043, 0.0070794, 0.19262, 0.0048169, 0.79872, 0.0010856, 0.31985, 0.010715, 0.054818, 0.049308]
Predicted label: 4
Correct prediction
Energy consumption = 153.733266 pJ
sum error= 153
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 288 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 288 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 288 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0025726, 0.79858, 0.013179, 0.17336, 0.12468, 0.0012337, 0.65302, 0.022929, 0.3007, 0.065508]
Predicted label: 1
Correct prediction
Energy consumption = 182.862022 pJ
sum error= 153
Actual label: 3
Output voltages: [0.011713, 0.0011624, 0.041096, 0.79879, 0.039625, 0.047097, 0.055638, 0.0074807, 0.64303, 0.006746]
Predicted label: 3
Correct prediction
Energy consumption = 143.754749 pJ
sum error= 153
Actual label: 4
Output voltages: [0.02432, 0.0010871, 0.63013, 0.10665, 0.79476, 0.015246, 0.0019458, 0.033846, 0.029707, 0.67709]
Predicted label: 4
Correct prediction
Energy consumption = 152.693382 pJ
sum error= 153
Actual label: 9
Output voltages: [0.26629, 0.0089017, 0.05122, 0.008816, 0.025158, 0.017845, 0.0038202, 0.01129, 0.78664, 0.79246]
Predicted label: 9
Correct prediction
Energy consumption = 134.649495 pJ
sum error= 153
Actual label: 3
Output voltages: [0.15217, 0.0045418, 0.049031, 0.79877, 0.023273, 0.015136, 0.0077424, 0.0065159, 0.51539, 0.037512]
Predicted label: 3
Correct prediction
Energy consumption = 139.585549 pJ
sum error= 153
Actual label: 1
Output voltages: [0.0013835, 0.79866, 0.10423, 0.0113, 0.012386, 0.02783, 0.32188, 0.0043316, 0.57554, 0.026749]
Predicted label: 1
Correct prediction
Energy consumption = 155.026956 pJ
sum error= 153
Actual label: 4
Output voltages: [0.02039, 0.0049285, 0.024514, 0.0043777, 0.79871, 0.0013444, 0.037049, 0.021129, 0.46561, 0.026833]
Predicted label: 4
Correct prediction
Energy consumption = 158.950044 pJ
sum error= 153
Actual label: 7
Output voltages: [0.055441, 0.22808, 0.048303, 0.066926, 0.0010735, 0.0038666, 0.0011921, 0.79879, 0.69149, 0.52475]
Predicted label: 7
Correct prediction
Energy consumption = 154.477099 pJ
sum error= 153
Actual label: 7
Output voltages: [0.37889, 0.14512, 0.74544, 0.021276, 0.0040153, 0.0013058, 0.0042194, 0.79879, 0.2471, 0.035826]
Predicted label: 7
Correct prediction
Energy consumption = 148.296568 pJ
sum error= 153
Actual label: 4
Output voltages: [0.0038584, 0.0086384, 0.26796, 0.026875, 0.79857, 0.011661, 0.063689, 0.031196, 0.033252, 0.052117]
Predicted label: 4
Correct prediction
Energy consumption = 154.761483 pJ
sum error= 153
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 289 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 289 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 289 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.19126, 0.031757, 0.6115, 0.28557, 0.0020996, 0.0012423, 0.0011434, 0.79832, 0.047178, 0.36571]
Predicted label: 7
Correct prediction
Energy consumption = 176.322432 pJ
sum error= 153
Actual label: 2
Output voltages: [0.15074, 0.19714, 0.78966, 0.45686, 0.012292, 0.0011255, 0.33025, 0.0010689, 0.79295, 0.42876]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.057346 pJ
sum error= 154
Actual label: 9
Output voltages: [0.19133, 0.0045505, 0.011468, 0.12853, 0.1928, 0.17547, 0.046423, 0.2972, 0.2559, 0.79103]
Predicted label: 9
Correct prediction
Energy consumption = 150.301582 pJ
sum error= 154
Actual label: 3
Output voltages: [0.44974, 0.046374, 0.025949, 0.79868, 0.0037341, 0.059313, 0.019041, 0.016757, 0.45611, 0.018241]
Predicted label: 3
Correct prediction
Energy consumption = 151.586904 pJ
sum error= 154
Actual label: 0
Output voltages: [0.77359, 0.031378, 0.086718, 0.0021819, 0.17529, 0.18836, 0.78635, 0.0028224, 0.28369, 0.0014074]
Predicted label: 6
Wrong prediction!
Energy consumption = 155.748719 pJ
sum error= 155
Actual label: 8
Output voltages: [0.013774, 0.021956, 0.066077, 0.082513, 0.0025716, 0.18373, 0.03834, 0.005743, 0.79875, 0.080424]
Predicted label: 8
Correct prediction
Energy consumption = 151.921133 pJ
sum error= 155
Actual label: 8
Output voltages: [0.79594, 0.0035616, 0.011745, 0.0094371, 0.002092, 0.26816, 0.52257, 0.0082223, 0.61399, 0.024475]
Predicted label: 0
Wrong prediction!
Energy consumption = 155.740487 pJ
sum error= 156
Actual label: 8
Output voltages: [0.041513, 0.029172, 0.48037, 0.020386, 0.017277, 0.0073985, 0.041756, 0.011878, 0.79875, 0.040238]
Predicted label: 8
Correct prediction
Energy consumption = 147.866213 pJ
sum error= 156
Actual label: 4
Output voltages: [0.0062692, 0.026419, 0.019857, 0.0017372, 0.7987, 0.02111, 0.34607, 0.095441, 0.33492, 0.10083]
Predicted label: 4
Correct prediction
Energy consumption = 158.776046 pJ
sum error= 156
Actual label: 0
Output voltages: [0.79679, 0.017642, 0.10324, 0.0013265, 0.047349, 0.0023588, 0.65241, 0.031998, 0.020288, 0.16175]
Predicted label: 0
Correct prediction
Energy consumption = 154.820634 pJ
sum error= 156
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 290 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 290 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 290 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.024486, 0.0030553, 0.36984, 0.0027744, 0.79869, 0.0011286, 0.22405, 0.010663, 0.027804, 0.16473]
Predicted label: 4
Correct prediction
Energy consumption = 160.161486 pJ
sum error= 156
Actual label: 4
Output voltages: [0.0038611, 0.1702, 0.010422, 0.0035216, 0.79684, 0.0010667, 0.66896, 0.0010751, 0.2988, 0.034461]
Predicted label: 4
Correct prediction
Energy consumption = 149.283797 pJ
sum error= 156
Actual label: 1
Output voltages: [0.034565, 0.79861, 0.097163, 0.45948, 0.0025249, 0.0022717, 0.27826, 0.015891, 0.048584, 0.016146]
Predicted label: 1
Correct prediction
Energy consumption = 158.870064 pJ
sum error= 156
Actual label: 5
Output voltages: [0.020216, 0.0011511, 0.0024309, 0.43775, 0.074173, 0.79029, 0.056625, 0.021541, 0.78201, 0.045698]
Predicted label: 5
Correct prediction
Energy consumption = 145.686917 pJ
sum error= 156
Actual label: 2
Output voltages: [0.63739, 0.032859, 0.79871, 0.041318, 0.021829, 0.0011641, 0.26884, 0.05199, 0.32672, 0.048461]
Predicted label: 2
Correct prediction
Energy consumption = 148.151334 pJ
sum error= 156
Actual label: 8
Output voltages: [0.0034865, 0.53998, 0.064997, 0.02676, 0.018126, 0.0021301, 0.040527, 0.0090928, 0.79876, 0.53761]
Predicted label: 8
Correct prediction
Energy consumption = 150.518237 pJ
sum error= 156
Actual label: 3
Output voltages: [0.12204, 0.0054333, 0.037913, 0.79879, 0.032293, 0.055802, 0.013349, 0.031852, 0.74885, 0.029534]
Predicted label: 3
Correct prediction
Energy consumption = 145.167368 pJ
sum error= 156
Actual label: 4
Output voltages: [0.0024385, 0.0096024, 0.61219, 0.015822, 0.79868, 0.0026953, 0.20112, 0.048312, 0.022429, 0.22923]
Predicted label: 4
Correct prediction
Energy consumption = 147.820116 pJ
sum error= 156
Actual label: 9
Output voltages: [0.16466, 0.022113, 0.055521, 0.22948, 0.11391, 0.016819, 0.022201, 0.0046787, 0.40622, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 150.909452 pJ
sum error= 156
Actual label: 5
Output voltages: [0.058764, 0.0035372, 0.002389, 0.51865, 0.038886, 0.79862, 0.26101, 0.05772, 0.78015, 0.10991]
Predicted label: 5
Correct prediction
Energy consumption = 147.742704 pJ
sum error= 156
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 291 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 291 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 291 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.25361, 0.48744, 0.79867, 0.49066, 0.0144, 0.0012331, 0.046913, 0.088018, 0.24635, 0.12111]
Predicted label: 2
Correct prediction
Energy consumption = 169.505838 pJ
sum error= 156
Actual label: 8
Output voltages: [0.066954, 0.090023, 0.74754, 0.072117, 0.027429, 0.001708, 0.35641, 0.0010669, 0.78903, 0.35697]
Predicted label: 8
Correct prediction
Energy consumption = 149.963782 pJ
sum error= 156
Actual label: 1
Output voltages: [0.022613, 0.79858, 0.032919, 0.092149, 0.017656, 0.0015413, 0.23368, 0.0059509, 0.67327, 0.030733]
Predicted label: 1
Correct prediction
Energy consumption = 161.374194 pJ
sum error= 156
Actual label: 5
Output voltages: [0.026409, 0.0019997, 0.0045833, 0.41325, 0.025097, 0.79879, 0.13431, 0.059462, 0.73655, 0.23371]
Predicted label: 5
Correct prediction
Energy consumption = 154.776995 pJ
sum error= 156
Actual label: 3
Output voltages: [0.17426, 0.075124, 0.03199, 0.7987, 0.0050246, 0.0041636, 0.0019744, 0.27291, 0.53826, 0.11528]
Predicted label: 3
Correct prediction
Energy consumption = 147.055066 pJ
sum error= 156
Actual label: 7
Output voltages: [0.035812, 0.68251, 0.54828, 0.3871, 0.0046221, 0.0012413, 0.002812, 0.75183, 0.65208, 0.011726]
Predicted label: 7
Correct prediction
Energy consumption = 150.797991 pJ
sum error= 156
Actual label: 9
Output voltages: [0.23357, 0.017205, 0.0077927, 0.055834, 0.14098, 0.0096338, 0.0019166, 0.024202, 0.16867, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 154.717619 pJ
sum error= 156
Actual label: 4
Output voltages: [0.0090573, 0.045578, 0.082883, 0.049268, 0.79867, 0.0031129, 0.20982, 0.051077, 0.015299, 0.19071]
Predicted label: 4
Correct prediction
Energy consumption = 157.529493 pJ
sum error= 156
Actual label: 2
Output voltages: [0.5607, 0.0081403, 0.79878, 0.13365, 0.034333, 0.0010728, 0.10277, 0.2176, 0.534, 0.0039724]
Predicted label: 2
Correct prediction
Energy consumption = 149.965079 pJ
sum error= 156
Actual label: 5
Output voltages: [0.025199, 0.001095, 0.001217, 0.24161, 0.1471, 0.79773, 0.20571, 0.055127, 0.60294, 0.29437]
Predicted label: 5
Correct prediction
Energy consumption = 144.823122 pJ
sum error= 156
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 292 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 292 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 292 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.019907, 0.022675, 0.23649, 0.0029617, 0.24134, 0.50223, 0.79874, 0.013258, 0.34351, 0.0062019]
Predicted label: 6
Correct prediction
Energy consumption = 159.386895 pJ
sum error= 156
Actual label: 3
Output voltages: [0.67599, 0.012996, 0.76335, 0.75288, 0.0010662, 0.0022319, 0.027833, 0.030253, 0.78671, 0.0046494]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.055663 pJ
sum error= 157
Actual label: 5
Output voltages: [0.042744, 0.0011566, 0.0043546, 0.22623, 0.046223, 0.79768, 0.038763, 0.0045237, 0.78159, 0.09632]
Predicted label: 5
Correct prediction
Energy consumption = 146.759974 pJ
sum error= 157
Actual label: 9
Output voltages: [0.063197, 0.017182, 0.015649, 0.04269, 0.047939, 0.0021875, 0.0061891, 0.037354, 0.4075, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 150.879068 pJ
sum error= 157
Actual label: 3
Output voltages: [0.080723, 0.019749, 0.054476, 0.79874, 0.0068895, 0.016927, 0.040726, 0.023385, 0.57024, 0.023245]
Predicted label: 3
Correct prediction
Energy consumption = 146.033485 pJ
sum error= 157
Actual label: 5
Output voltages: [0.04438, 0.0040362, 0.0011334, 0.13453, 0.33165, 0.7828, 0.76185, 0.001156, 0.73932, 0.062491]
Predicted label: 5
Correct prediction
Energy consumption = 144.838843 pJ
sum error= 157
Actual label: 9
Output voltages: [0.44521, 0.036928, 0.0069696, 0.33309, 0.67967, 0.051181, 0.046146, 0.0054555, 0.058062, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 152.183385 pJ
sum error= 157
Actual label: 3
Output voltages: [0.031085, 0.023435, 0.79765, 0.54542, 0.026074, 0.0011098, 0.017777, 0.42008, 0.60124, 0.0032201]
Predicted label: 2
Wrong prediction!
Energy consumption = 152.752309 pJ
sum error= 158
Actual label: 1
Output voltages: [0.008653, 0.79877, 0.34006, 0.03631, 0.056263, 0.0011297, 0.7392, 0.0017166, 0.10239, 0.014652]
Predicted label: 1
Correct prediction
Energy consumption = 159.490336 pJ
sum error= 158
Actual label: 9
Output voltages: [0.65909, 0.001125, 0.18388, 0.0035516, 0.075506, 0.039743, 0.0010724, 0.40334, 0.36486, 0.78368]
Predicted label: 9
Correct prediction
Energy consumption = 151.931228 pJ
sum error= 158
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 293 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 293 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 293 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.78503, 0.0080157, 0.0010996, 0.46754, 0.22541, 0.79877, 0.037844, 0.0072212, 0.047845, 0.039989]
Predicted label: 5
Correct prediction
Energy consumption = 162.445924 pJ
sum error= 158
Actual label: 3
Output voltages: [0.13883, 0.062937, 0.05461, 0.79867, 0.018154, 0.0038543, 0.018493, 0.011911, 0.44132, 0.2215]
Predicted label: 3
Correct prediction
Energy consumption = 147.693527 pJ
sum error= 158
Actual label: 0
Output voltages: [0.79879, 0.041239, 0.34031, 0.013826, 0.001601, 0.01142, 0.50542, 0.021389, 0.18435, 0.04708]
Predicted label: 0
Correct prediction
Energy consumption = 153.576370 pJ
sum error= 158
Actual label: 6
Output voltages: [0.055746, 0.15514, 0.43684, 0.006965, 0.16516, 0.12797, 0.79871, 0.0014414, 0.37846, 0.030633]
Predicted label: 6
Correct prediction
Energy consumption = 144.328973 pJ
sum error= 158
Actual label: 9
Output voltages: [0.12866, 0.008077, 0.010865, 0.042843, 0.014001, 0.039075, 0.0015074, 0.40372, 0.67851, 0.76551]
Predicted label: 9
Correct prediction
Energy consumption = 156.748804 pJ
sum error= 158
Actual label: 8
Output voltages: [0.015828, 0.12, 0.2047, 0.053984, 0.0081245, 0.022238, 0.035195, 0.035611, 0.79878, 0.1903]
Predicted label: 8
Correct prediction
Energy consumption = 147.333278 pJ
sum error= 158
Actual label: 4
Output voltages: [0.012801, 0.011737, 0.11872, 0.0067844, 0.79858, 0.023447, 0.050303, 0.030222, 0.030662, 0.33832]
Predicted label: 4
Correct prediction
Energy consumption = 153.259504 pJ
sum error= 158
Actual label: 0
Output voltages: [0.79873, 0.04961, 0.019007, 0.02287, 0.047679, 0.021038, 0.040231, 0.12584, 0.30147, 0.13379]
Predicted label: 0
Correct prediction
Energy consumption = 162.285659 pJ
sum error= 158
Actual label: 4
Output voltages: [0.30237, 0.0036472, 0.0091333, 0.0043108, 0.76917, 0.0010938, 0.51319, 0.0041238, 0.20969, 0.026652]
Predicted label: 4
Correct prediction
Energy consumption = 152.315986 pJ
sum error= 158
Actual label: 9
Output voltages: [0.5616, 0.027111, 0.0011101, 0.64274, 0.66954, 0.62856, 0.0017734, 0.39886, 0.016751, 0.76678]
Predicted label: 9
Correct prediction
Energy consumption = 145.834489 pJ
sum error= 158
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 294 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 294 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 294 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.48966, 0.36589, 0.79843, 0.036996, 0.02783, 0.0013581, 0.58945, 0.035912, 0.39526, 0.043883]
Predicted label: 2
Correct prediction
Energy consumption = 162.669180 pJ
sum error= 158
Actual label: 9
Output voltages: [0.1179, 0.0011696, 0.018773, 0.0020246, 0.38072, 0.35943, 0.0083821, 0.045234, 0.67622, 0.78323]
Predicted label: 9
Correct prediction
Energy consumption = 154.323276 pJ
sum error= 158
Actual label: 0
Output voltages: [0.79874, 0.13202, 0.051593, 0.030857, 0.0047197, 0.0057728, 0.65459, 0.0074513, 0.14544, 0.10526]
Predicted label: 0
Correct prediction
Energy consumption = 160.529580 pJ
sum error= 158
Actual label: 1
Output voltages: [0.2505, 0.79857, 0.019945, 0.34516, 0.01504, 0.0055032, 0.59773, 0.0020532, 0.44503, 0.02749]
Predicted label: 1
Correct prediction
Energy consumption = 157.461041 pJ
sum error= 158
Actual label: 0
Output voltages: [0.79879, 0.072435, 0.62937, 0.0042381, 0.018581, 0.0039125, 0.14622, 0.012722, 0.4569, 0.42121]
Predicted label: 0
Correct prediction
Energy consumption = 158.143811 pJ
sum error= 158
Actual label: 3
Output voltages: [0.28124, 0.063567, 0.078972, 0.79876, 0.0019233, 0.0033498, 0.0010664, 0.7252, 0.038323, 0.67187]
Predicted label: 3
Correct prediction
Energy consumption = 148.617032 pJ
sum error= 158
Actual label: 1
Output voltages: [0.023673, 0.79232, 0.029494, 0.0044456, 0.19784, 0.039239, 0.36112, 0.0010779, 0.76304, 0.43602]
Predicted label: 1
Correct prediction
Energy consumption = 148.593203 pJ
sum error= 158
Actual label: 6
Output voltages: [0.11911, 0.044136, 0.12229, 0.0046826, 0.37522, 0.31662, 0.79868, 0.0018206, 0.54495, 0.012361]
Predicted label: 6
Correct prediction
Energy consumption = 148.027309 pJ
sum error= 158
Actual label: 5
Output voltages: [0.11858, 0.0019028, 0.047797, 0.32831, 0.0015817, 0.79229, 0.11599, 0.0017257, 0.78754, 0.022849]
Predicted label: 5
Correct prediction
Energy consumption = 144.991023 pJ
sum error= 158
Actual label: 8
Output voltages: [0.012885, 0.050245, 0.12876, 0.19632, 0.0029284, 0.032739, 0.031935, 0.015025, 0.79878, 0.056775]
Predicted label: 8
Correct prediction
Energy consumption = 143.639291 pJ
sum error= 158
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 295 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 295 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 295 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.012593, 0.79843, 0.040543, 0.020859, 0.008286, 0.0025438, 0.56386, 0.001654, 0.12296, 0.058959]
Predicted label: 1
Correct prediction
Energy consumption = 179.195340 pJ
sum error= 158
Actual label: 5
Output voltages: [0.026467, 0.0010738, 0.014367, 0.34344, 0.0018255, 0.79661, 0.35361, 0.024938, 0.77382, 0.01903]
Predicted label: 5
Correct prediction
Energy consumption = 154.637751 pJ
sum error= 158
Actual label: 3
Output voltages: [0.046638, 0.0010885, 0.037079, 0.77999, 0.4426, 0.75844, 0.018911, 0.015326, 0.65776, 0.019672]
Predicted label: 3
Correct prediction
Energy consumption = 145.447441 pJ
sum error= 158
Actual label: 3
Output voltages: [0.17409, 0.0029126, 0.015726, 0.78385, 0.01165, 0.74157, 0.0058618, 0.028604, 0.79066, 0.012235]
Predicted label: 8
Wrong prediction!
Energy consumption = 137.249259 pJ
sum error= 159
Actual label: 0
Output voltages: [0.79706, 0.025148, 0.34005, 0.0089457, 0.0091269, 0.0081839, 0.71314, 0.045542, 0.44102, 0.011536]
Predicted label: 0
Correct prediction
Energy consumption = 151.262723 pJ
sum error= 159
Actual label: 3
Output voltages: [0.053503, 0.015401, 0.049986, 0.7987, 0.01896, 0.030696, 0.018755, 0.0014697, 0.48849, 0.078726]
Predicted label: 3
Correct prediction
Energy consumption = 149.859216 pJ
sum error= 159
Actual label: 5
Output voltages: [0.0032514, 0.0016451, 0.094427, 0.40888, 0.13377, 0.78779, 0.024189, 0.001668, 0.79708, 0.16197]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.829586 pJ
sum error= 160
Actual label: 5
Output voltages: [0.26171, 0.0010751, 0.003141, 0.20329, 0.0105, 0.79879, 0.46734, 0.030974, 0.59183, 0.0012817]
Predicted label: 5
Correct prediction
Energy consumption = 138.179793 pJ
sum error= 160
Actual label: 9
Output voltages: [0.23785, 0.0078931, 0.023435, 0.027884, 0.37659, 0.0061979, 0.031391, 0.0031338, 0.47101, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 153.181048 pJ
sum error= 160
Actual label: 2
Output voltages: [0.022346, 0.014587, 0.79879, 0.3841, 0.0029876, 0.0011392, 0.012562, 0.3695, 0.38122, 0.01508]
Predicted label: 2
Correct prediction
Energy consumption = 143.127483 pJ
sum error= 160
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 296 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 296 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 296 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0063991, 0.22722, 0.11676, 0.023952, 0.020443, 0.0022124, 0.024584, 0.0095012, 0.79878, 0.60787]
Predicted label: 8
Correct prediction
Energy consumption = 171.158205 pJ
sum error= 160
Actual label: 7
Output voltages: [0.44694, 0.027369, 0.49972, 0.78452, 0.0072646, 0.0015953, 0.0022273, 0.78581, 0.019914, 0.71746]
Predicted label: 7
Correct prediction
Energy consumption = 154.061752 pJ
sum error= 160
Actual label: 0
Output voltages: [0.79856, 0.040933, 0.026121, 0.01412, 0.020393, 0.0011201, 0.75348, 0.0025016, 0.22127, 0.1305]
Predicted label: 0
Correct prediction
Energy consumption = 158.448538 pJ
sum error= 160
Actual label: 4
Output voltages: [0.011979, 0.0084911, 0.11511, 0.014738, 0.79858, 0.00322, 0.26792, 0.053404, 0.024899, 0.017341]
Predicted label: 4
Correct prediction
Energy consumption = 149.094722 pJ
sum error= 160
Actual label: 9
Output voltages: [0.11908, 0.02656, 0.040186, 0.036834, 0.79017, 0.0032786, 0.027193, 0.0076441, 0.033483, 0.79586]
Predicted label: 9
Correct prediction
Energy consumption = 148.172318 pJ
sum error= 160
Actual label: 1
Output voltages: [0.014952, 0.79846, 0.038025, 0.030304, 0.010239, 0.0056398, 0.60385, 0.0041423, 0.32394, 0.036081]
Predicted label: 1
Correct prediction
Energy consumption = 169.253487 pJ
sum error= 160
Actual label: 9
Output voltages: [0.47833, 0.020666, 0.0013301, 0.17364, 0.74843, 0.22339, 0.11104, 0.0025486, 0.044935, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 159.963504 pJ
sum error= 160
Actual label: 7
Output voltages: [0.069294, 0.038259, 0.1377, 0.15989, 0.0046938, 0.0011039, 0.0010863, 0.7986, 0.16943, 0.29786]
Predicted label: 7
Correct prediction
Energy consumption = 155.205844 pJ
sum error= 160
Actual label: 7
Output voltages: [0.19509, 0.038636, 0.02118, 0.077527, 0.02839, 0.0041662, 0.0016574, 0.79879, 0.11821, 0.50649]
Predicted label: 7
Correct prediction
Energy consumption = 143.683996 pJ
sum error= 160
Actual label: 5
Output voltages: [0.32871, 0.0010691, 0.020743, 0.1898, 0.018987, 0.79876, 0.44829, 0.076466, 0.73183, 0.003912]
Predicted label: 5
Correct prediction
Energy consumption = 137.023049 pJ
sum error= 160
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 297 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 297 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 297 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.17342, 0.0010668, 0.0011298, 0.61469, 0.0016558, 0.77338, 0.016565, 0.15002, 0.74858, 0.047114]
Predicted label: 5
Correct prediction
Energy consumption = 165.473250 pJ
sum error= 160
Actual label: 2
Output voltages: [0.48615, 0.041861, 0.79875, 0.048023, 0.011179, 0.0012868, 0.21024, 0.15264, 0.45205, 0.023233]
Predicted label: 2
Correct prediction
Energy consumption = 150.419966 pJ
sum error= 160
Actual label: 0
Output voltages: [0.79711, 0.043842, 0.093407, 0.003675, 0.052956, 0.0036748, 0.79226, 0.11805, 0.13688, 0.021039]
Predicted label: 0
Correct prediction
Energy consumption = 146.681226 pJ
sum error= 160
Actual label: 9
Output voltages: [0.38427, 0.018453, 0.027323, 0.043409, 0.22287, 0.10345, 0.048361, 0.02607, 0.24965, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.524169 pJ
sum error= 160
Actual label: 1
Output voltages: [0.028995, 0.7985, 0.45093, 0.02206, 0.024552, 0.0015396, 0.62552, 0.00146, 0.05906, 0.025427]
Predicted label: 1
Correct prediction
Energy consumption = 166.726390 pJ
sum error= 160
Actual label: 8
Output voltages: [0.35806, 0.016315, 0.68994, 0.0034942, 0.22425, 0.0012091, 0.050073, 0.005476, 0.7986, 0.21078]
Predicted label: 8
Correct prediction
Energy consumption = 147.040592 pJ
sum error= 160
Actual label: 6
Output voltages: [0.40259, 0.014594, 0.019201, 0.028277, 0.27736, 0.7096, 0.79834, 0.0029593, 0.41069, 0.024618]
Predicted label: 6
Correct prediction
Energy consumption = 148.242636 pJ
sum error= 160
Actual label: 2
Output voltages: [0.58071, 0.018639, 0.79879, 0.2906, 0.029237, 0.0011553, 0.064951, 0.053725, 0.68822, 0.019194]
Predicted label: 2
Correct prediction
Energy consumption = 146.796475 pJ
sum error= 160
Actual label: 3
Output voltages: [0.3798, 0.15572, 0.051982, 0.7986, 0.014486, 0.047936, 0.032073, 0.043018, 0.6582, 0.074375]
Predicted label: 3
Correct prediction
Energy consumption = 148.601198 pJ
sum error= 160
Actual label: 9
Output voltages: [0.79654, 0.0074168, 0.012918, 0.003712, 0.055477, 0.0011023, 0.027072, 0.3545, 0.30835, 0.73941]
Predicted label: 0
Wrong prediction!
Energy consumption = 154.230529 pJ
sum error= 161
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 298 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 298 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 298 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.48346, 0.011584, 0.033224, 0.039171, 0.045412, 0.29994, 0.79879, 0.0010974, 0.45145, 0.15823]
Predicted label: 6
Correct prediction
Energy consumption = 164.692519 pJ
sum error= 161
Actual label: 2
Output voltages: [0.30367, 0.036032, 0.79874, 0.39693, 0.0014699, 0.0010677, 0.35364, 0.032968, 0.51583, 0.017751]
Predicted label: 2
Correct prediction
Energy consumption = 146.997161 pJ
sum error= 161
Actual label: 1
Output voltages: [0.025527, 0.79856, 0.045688, 0.043718, 0.22211, 0.002507, 0.53825, 0.0071057, 0.053733, 0.055994]
Predicted label: 1
Correct prediction
Energy consumption = 170.464877 pJ
sum error= 161
Actual label: 9
Output voltages: [0.63268, 0.0073633, 0.019598, 0.020108, 0.4331, 0.021773, 0.0049579, 0.015472, 0.35527, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 160.701834 pJ
sum error= 161
Actual label: 1
Output voltages: [0.020514, 0.79852, 0.39654, 0.66216, 0.025587, 0.0012287, 0.22919, 0.0056254, 0.024681, 0.27817]
Predicted label: 1
Correct prediction
Energy consumption = 163.985478 pJ
sum error= 161
Actual label: 3
Output voltages: [0.32846, 0.024843, 0.10359, 0.7986, 0.033457, 0.028884, 0.014195, 0.036575, 0.45323, 0.061449]
Predicted label: 3
Correct prediction
Energy consumption = 148.820676 pJ
sum error= 161
Actual label: 5
Output voltages: [0.041715, 0.0011023, 0.0011796, 0.18165, 0.15204, 0.79796, 0.50417, 0.0013852, 0.77228, 0.019914]
Predicted label: 5
Correct prediction
Energy consumption = 139.526114 pJ
sum error= 161
Actual label: 5
Output voltages: [0.025266, 0.0021538, 0.0015383, 0.76297, 0.024536, 0.79756, 0.025866, 0.022733, 0.47425, 0.14071]
Predicted label: 5
Correct prediction
Energy consumption = 145.371572 pJ
sum error= 161
Actual label: 0
Output voltages: [0.79873, 0.17801, 0.1235, 0.044667, 0.047199, 0.021955, 0.35423, 0.11123, 0.41611, 0.039769]
Predicted label: 0
Correct prediction
Energy consumption = 160.182976 pJ
sum error= 161
Actual label: 3
Output voltages: [0.38634, 0.013835, 0.37178, 0.79876, 0.048009, 0.0075602, 0.0044669, 0.0023055, 0.50666, 0.002814]
Predicted label: 3
Correct prediction
Energy consumption = 146.626937 pJ
sum error= 161
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 299 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 299 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 299 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.022633, 0.03473, 0.056097, 0.022522, 0.0076978, 0.025627, 0.010001, 0.001532, 0.79875, 0.6346]
Predicted label: 8
Correct prediction
Energy consumption = 168.920619 pJ
sum error= 161
Actual label: 3
Output voltages: [0.030681, 0.0070814, 0.039201, 0.79879, 0.13771, 0.11495, 0.010065, 0.034805, 0.33882, 0.33066]
Predicted label: 3
Correct prediction
Energy consumption = 147.478263 pJ
sum error= 161
Actual label: 3
Output voltages: [0.37264, 0.015918, 0.0562, 0.7986, 0.017415, 0.04784, 0.012974, 0.016703, 0.44299, 0.029606]
Predicted label: 3
Correct prediction
Energy consumption = 141.606997 pJ
sum error= 161
Actual label: 7
Output voltages: [0.4023, 0.031076, 0.77714, 0.029025, 0.0033657, 0.0011041, 0.0010698, 0.79872, 0.11884, 0.061802]
Predicted label: 7
Correct prediction
Energy consumption = 147.690958 pJ
sum error= 161
Actual label: 6
Output voltages: [0.045083, 0.037942, 0.48731, 0.0019703, 0.52855, 0.13795, 0.79877, 0.0065247, 0.63638, 0.0017709]
Predicted label: 6
Correct prediction
Energy consumption = 156.589806 pJ
sum error= 161
Actual label: 6
Output voltages: [0.32591, 0.029954, 0.065509, 0.19161, 0.0013035, 0.56756, 0.74653, 0.0074312, 0.79727, 0.0036715]
Predicted label: 8
Wrong prediction!
Energy consumption = 151.562413 pJ
sum error= 162
Actual label: 0
Output voltages: [0.79876, 0.31879, 0.018909, 0.014916, 0.010272, 0.04154, 0.29879, 0.017889, 0.053143, 0.15208]
Predicted label: 0
Correct prediction
Energy consumption = 141.782282 pJ
sum error= 162
Actual label: 1
Output voltages: [0.11408, 0.79842, 0.084429, 0.4075, 0.10698, 0.0078808, 0.40128, 0.0087825, 0.029197, 0.31456]
Predicted label: 1
Correct prediction
Energy consumption = 163.277196 pJ
sum error= 162
Actual label: 4
Output voltages: [0.010782, 0.011513, 0.10538, 0.00787, 0.79872, 0.021673, 0.074838, 0.023592, 0.035434, 0.13611]
Predicted label: 4
Correct prediction
Energy consumption = 153.670408 pJ
sum error= 162
Actual label: 0
Output voltages: [0.79862, 0.17728, 0.015043, 0.038018, 0.0068327, 0.050545, 0.74036, 0.023446, 0.17649, 0.013935]
Predicted label: 0
Correct prediction
Energy consumption = 148.031978 pJ
sum error= 162
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 300 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 300 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 300 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.027513, 0.021289, 0.025455, 0.10061, 0.086685, 0.73419, 0.79847, 0.0072547, 0.78118, 0.001594]
Predicted label: 6
Correct prediction
Energy consumption = 171.262693 pJ
sum error= 162
Actual label: 9
Output voltages: [0.27106, 0.015436, 0.23323, 0.028626, 0.21053, 0.0017444, 0.035916, 0.0015128, 0.67339, 0.7957]
Predicted label: 9
Correct prediction
Energy consumption = 149.399649 pJ
sum error= 162
Actual label: 8
Output voltages: [0.018796, 0.13063, 0.12658, 0.076696, 0.0047271, 0.0075051, 0.022564, 0.0049718, 0.79878, 0.43712]
Predicted label: 8
Correct prediction
Energy consumption = 152.620219 pJ
sum error= 162
Actual label: 1
Output voltages: [0.1024, 0.79849, 0.024524, 0.21702, 0.039476, 0.0052757, 0.051438, 0.029454, 0.22051, 0.50218]
Predicted label: 1
Correct prediction
Energy consumption = 161.027711 pJ
sum error= 162
Actual label: 2
Output voltages: [0.049866, 0.048429, 0.79534, 0.13704, 0.023507, 0.0011346, 0.030988, 0.06207, 0.75114, 0.011045]
Predicted label: 2
Correct prediction
Energy consumption = 151.905354 pJ
sum error= 162
Actual label: 9
Output voltages: [0.028759, 0.75377, 0.011043, 0.20734, 0.0053319, 0.22911, 0.069796, 0.0011209, 0.79527, 0.72899]
Predicted label: 8
Wrong prediction!
Energy consumption = 159.734944 pJ
sum error= 163
Actual label: 9
Output voltages: [0.60392, 0.014329, 0.020272, 0.048918, 0.32465, 0.0062191, 0.0064855, 0.01186, 0.1492, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 156.821693 pJ
sum error= 163
Actual label: 5
Output voltages: [0.0063575, 0.0010938, 0.0071276, 0.058151, 0.0034851, 0.79179, 0.05708, 0.0021366, 0.79641, 0.0037349]
Predicted label: 8
Wrong prediction!
Energy consumption = 141.927431 pJ
sum error= 164
Actual label: 9
Output voltages: [0.26925, 0.029605, 0.02434, 0.046294, 0.083179, 0.042546, 0.016167, 0.026053, 0.45952, 0.79833]
Predicted label: 9
Correct prediction
Energy consumption = 149.365645 pJ
sum error= 164
Actual label: 7
Output voltages: [0.019846, 0.49343, 0.4628, 0.042229, 0.0020342, 0.001089, 0.0010896, 0.79876, 0.3625, 0.19681]
Predicted label: 7
Correct prediction
Energy consumption = 147.910740 pJ
sum error= 164
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 301 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 301 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 301 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.015956, 0.029883, 0.20996, 0.79879, 0.0072762, 0.020381, 0.0032017, 0.022331, 0.75522, 0.030463]
Predicted label: 3
Correct prediction
Energy consumption = 160.228761 pJ
sum error= 164
Actual label: 7
Output voltages: [0.33921, 0.044275, 0.007107, 0.16158, 0.017172, 0.63079, 0.0013821, 0.79871, 0.049142, 0.3759]
Predicted label: 7
Correct prediction
Energy consumption = 150.011060 pJ
sum error= 164
Actual label: 8
Output voltages: [0.0029538, 0.10509, 0.033479, 0.13557, 0.013587, 0.0017735, 0.011286, 0.0039805, 0.78929, 0.75691]
Predicted label: 8
Correct prediction
Energy consumption = 153.124530 pJ
sum error= 164
Actual label: 0
Output voltages: [0.79879, 0.14825, 0.024831, 0.034524, 0.0042825, 0.083792, 0.43109, 0.0016164, 0.24683, 0.27071]
Predicted label: 0
Correct prediction
Energy consumption = 148.610801 pJ
sum error= 164
Actual label: 1
Output voltages: [0.0042245, 0.79862, 0.0084552, 0.029447, 0.025953, 0.15778, 0.7551, 0.01792, 0.075782, 0.013322]
Predicted label: 1
Correct prediction
Energy consumption = 162.127638 pJ
sum error= 164
Actual label: 3
Output voltages: [0.084118, 0.025976, 0.20889, 0.79871, 0.025681, 0.016468, 0.0072642, 0.0098034, 0.65313, 0.3605]
Predicted label: 3
Correct prediction
Energy consumption = 148.369667 pJ
sum error= 164
Actual label: 0
Output voltages: [0.79871, 0.058767, 0.016617, 0.022824, 0.039068, 0.029761, 0.55314, 0.095203, 0.25057, 0.016573]
Predicted label: 0
Correct prediction
Energy consumption = 145.134897 pJ
sum error= 164
Actual label: 4
Output voltages: [0.0055038, 0.011316, 0.065476, 0.04755, 0.79872, 0.0011894, 0.010586, 0.031104, 0.050567, 0.057232]
Predicted label: 4
Correct prediction
Energy consumption = 151.273865 pJ
sum error= 164
Actual label: 6
Output voltages: [0.29131, 0.030455, 0.13265, 0.0061254, 0.33444, 0.054741, 0.79879, 0.0021063, 0.6479, 0.0072023]
Predicted label: 6
Correct prediction
Energy consumption = 142.272819 pJ
sum error= 164
Actual label: 1
Output voltages: [0.00149, 0.79863, 0.030248, 0.0056335, 0.03381, 0.0063866, 0.57124, 0.0048827, 0.51067, 0.015195]
Predicted label: 1
Correct prediction
Energy consumption = 154.250547 pJ
sum error= 164
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 302 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 302 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 302 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79863, 0.23086, 0.016337, 0.016612, 0.021236, 0.046407, 0.62571, 0.01435, 0.040934, 0.28865]
Predicted label: 0
Correct prediction
Energy consumption = 172.693458 pJ
sum error= 164
Actual label: 2
Output voltages: [0.70944, 0.042471, 0.79491, 0.21176, 0.0017032, 0.0012223, 0.039355, 0.60966, 0.37678, 0.0123]
Predicted label: 2
Correct prediction
Energy consumption = 148.511460 pJ
sum error= 164
Actual label: 5
Output voltages: [0.037173, 0.0011069, 0.0010785, 0.15201, 0.41655, 0.79773, 0.40347, 0.013696, 0.77199, 0.032548]
Predicted label: 5
Correct prediction
Energy consumption = 147.379864 pJ
sum error= 164
Actual label: 8
Output voltages: [0.051515, 0.0070695, 0.12336, 0.024157, 0.006738, 0.77688, 0.25652, 0.0051106, 0.78933, 0.010772]
Predicted label: 8
Correct prediction
Energy consumption = 145.576530 pJ
sum error= 164
Actual label: 4
Output voltages: [0.034586, 0.006447, 0.083537, 0.0010661, 0.79879, 0.0047913, 0.20799, 0.010198, 0.36903, 0.047999]
Predicted label: 4
Correct prediction
Energy consumption = 154.470848 pJ
sum error= 164
Actual label: 4
Output voltages: [0.021689, 0.010668, 0.40218, 0.011688, 0.79858, 0.0065576, 0.072936, 0.020584, 0.028534, 0.24736]
Predicted label: 4
Correct prediction
Energy consumption = 149.963137 pJ
sum error= 164
Actual label: 1
Output voltages: [0.03235, 0.79879, 0.046641, 0.016601, 0.5528, 0.0014796, 0.25794, 0.0012403, 0.1897, 0.10869]
Predicted label: 1
Correct prediction
Energy consumption = 153.975714 pJ
sum error= 164
Actual label: 1
Output voltages: [0.0049215, 0.79858, 0.13144, 0.01109, 0.0066397, 0.0041813, 0.48457, 0.023369, 0.42656, 0.0037425]
Predicted label: 1
Correct prediction
Energy consumption = 147.824042 pJ
sum error= 164
Actual label: 5
Output voltages: [0.20048, 0.0010762, 0.0043961, 0.05166, 0.025913, 0.7986, 0.46025, 0.014492, 0.77821, 0.0056267]
Predicted label: 5
Correct prediction
Energy consumption = 148.296164 pJ
sum error= 164
Actual label: 4
Output voltages: [0.0019284, 0.017926, 0.10815, 0.010565, 0.79867, 0.0014421, 0.022921, 0.036902, 0.085217, 0.025976]
Predicted label: 4
Correct prediction
Energy consumption = 152.383070 pJ
sum error= 164
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 303 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 303 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 303 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.7775, 0.038517, 0.04953, 0.024729, 0.047092, 0.001092, 0.52097, 0.034916, 0.70612, 0.052335]
Predicted label: 0
Wrong prediction!
Energy consumption = 174.969402 pJ
sum error= 165
Actual label: 6
Output voltages: [0.042948, 0.057526, 0.53412, 0.0010856, 0.15078, 0.033488, 0.79876, 0.0032449, 0.41927, 0.0076398]
Predicted label: 6
Correct prediction
Energy consumption = 141.234735 pJ
sum error= 165
Actual label: 0
Output voltages: [0.79879, 0.10815, 0.28754, 0.026196, 0.034237, 0.0093178, 0.20379, 0.0044933, 0.53642, 0.032467]
Predicted label: 0
Correct prediction
Energy consumption = 156.106624 pJ
sum error= 165
Actual label: 6
Output voltages: [0.52625, 0.037583, 0.11906, 0.011626, 0.16449, 0.15173, 0.79869, 0.0011342, 0.31653, 0.04611]
Predicted label: 6
Correct prediction
Energy consumption = 150.726701 pJ
sum error= 165
Actual label: 9
Output voltages: [0.15035, 0.016648, 0.09482, 0.21272, 0.054672, 0.020817, 0.091284, 0.029261, 0.13887, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.957244 pJ
sum error= 165
Actual label: 2
Output voltages: [0.098011, 0.010856, 0.79879, 0.17447, 0.12055, 0.001067, 0.026669, 0.050446, 0.22588, 0.046455]
Predicted label: 2
Correct prediction
Energy consumption = 144.553092 pJ
sum error= 165
Actual label: 6
Output voltages: [0.022925, 0.117, 0.34757, 0.001472, 0.3156, 0.12302, 0.79872, 0.0025055, 0.61062, 0.0061563]
Predicted label: 6
Correct prediction
Energy consumption = 152.339785 pJ
sum error= 165
Actual label: 2
Output voltages: [0.6382, 0.012376, 0.79879, 0.30337, 0.021682, 0.0010665, 0.28476, 0.22385, 0.31915, 0.017894]
Predicted label: 2
Correct prediction
Energy consumption = 144.148940 pJ
sum error= 165
Actual label: 7
Output voltages: [0.23461, 0.026033, 0.0013931, 0.025033, 0.27679, 0.013268, 0.0012792, 0.79872, 0.19001, 0.58411]
Predicted label: 7
Correct prediction
Energy consumption = 157.849197 pJ
sum error= 165
Actual label: 1
Output voltages: [0.0076632, 0.79869, 0.083252, 0.77581, 0.011754, 0.042439, 0.027386, 0.02462, 0.026648, 0.51832]
Predicted label: 1
Correct prediction
Energy consumption = 163.009211 pJ
sum error= 165
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 304 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 304 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 304 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.069212, 0.12128, 0.6781, 0.0044959, 0.0092319, 0.0012456, 0.0011301, 0.79863, 0.33515, 0.021253]
Predicted label: 7
Correct prediction
Energy consumption = 176.856327 pJ
sum error= 165
Actual label: 9
Output voltages: [0.1545, 0.019684, 0.047949, 0.046478, 0.03708, 0.040133, 0.015306, 0.21947, 0.51192, 0.79725]
Predicted label: 9
Correct prediction
Energy consumption = 155.381537 pJ
sum error= 165
Actual label: 4
Output voltages: [0.0012718, 0.027706, 0.045247, 0.003233, 0.79879, 0.011733, 0.50869, 0.36515, 0.04251, 0.014715]
Predicted label: 4
Correct prediction
Energy consumption = 152.825856 pJ
sum error= 165
Actual label: 0
Output voltages: [0.79879, 0.11713, 0.037378, 0.0063902, 0.0093795, 0.010449, 0.37183, 0.012458, 0.073716, 0.061395]
Predicted label: 0
Correct prediction
Energy consumption = 153.394906 pJ
sum error= 165
Actual label: 0
Output voltages: [0.79869, 0.072978, 0.021463, 0.053385, 0.024945, 0.02157, 0.1466, 0.023411, 0.15687, 0.41654]
Predicted label: 0
Correct prediction
Energy consumption = 147.585069 pJ
sum error= 165
Actual label: 3
Output voltages: [0.40148, 0.025888, 0.020496, 0.79862, 0.013216, 0.015113, 0.021987, 0.0066694, 0.53964, 0.048483]
Predicted label: 3
Correct prediction
Energy consumption = 150.290642 pJ
sum error= 165
Actual label: 8
Output voltages: [0.019515, 0.066291, 0.058837, 0.04891, 0.027021, 0.0084437, 0.02611, 0.01149, 0.79877, 0.55415]
Predicted label: 8
Correct prediction
Energy consumption = 149.458841 pJ
sum error= 165
Actual label: 2
Output voltages: [0.29529, 0.14732, 0.79738, 0.44288, 0.016224, 0.0012743, 0.043984, 0.012303, 0.32948, 0.0054853]
Predicted label: 2
Correct prediction
Energy consumption = 153.447385 pJ
sum error= 165
Actual label: 2
Output voltages: [0.40297, 0.0023723, 0.79846, 0.12626, 0.018443, 0.0012246, 0.033001, 0.061534, 0.65206, 0.022077]
Predicted label: 2
Correct prediction
Energy consumption = 135.933698 pJ
sum error= 165
Actual label: 3
Output voltages: [0.32752, 0.011165, 0.04397, 0.7987, 0.015679, 0.13265, 0.018961, 0.0095913, 0.64522, 0.049561]
Predicted label: 3
Correct prediction
Energy consumption = 139.735262 pJ
sum error= 165
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 305 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 305 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 305 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.021033, 0.79857, 0.15218, 0.080221, 0.22924, 0.0019795, 0.51561, 0.0080091, 0.22821, 0.079269]
Predicted label: 1
Correct prediction
Energy consumption = 183.176470 pJ
sum error= 165
Actual label: 6
Output voltages: [0.054892, 0.038505, 0.039565, 0.013129, 0.21611, 0.092563, 0.79879, 0.0068082, 0.76341, 0.0026953]
Predicted label: 6
Correct prediction
Energy consumption = 144.083032 pJ
sum error= 165
Actual label: 0
Output voltages: [0.79879, 0.056815, 0.017214, 0.020831, 0.018674, 0.016242, 0.53915, 0.021205, 0.042573, 0.042807]
Predicted label: 0
Correct prediction
Energy consumption = 151.370846 pJ
sum error= 165
Actual label: 5
Output voltages: [0.0065596, 0.0010685, 0.01119, 0.24131, 0.26415, 0.79873, 0.15173, 0.017774, 0.71907, 0.38838]
Predicted label: 5
Correct prediction
Energy consumption = 144.813499 pJ
sum error= 165
Actual label: 7
Output voltages: [0.22296, 0.039534, 0.16344, 0.0037562, 0.044003, 0.0014738, 0.0011415, 0.79865, 0.05237, 0.24591]
Predicted label: 7
Correct prediction
Energy consumption = 153.856162 pJ
sum error= 165
Actual label: 7
Output voltages: [0.22836, 0.30342, 0.055206, 0.35257, 0.0012659, 0.040078, 0.0010701, 0.78836, 0.79525, 0.13904]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.106034 pJ
sum error= 166
Actual label: 9
Output voltages: [0.21497, 0.014261, 0.016178, 0.19513, 0.022415, 0.030818, 0.014213, 0.16377, 0.57716, 0.79813]
Predicted label: 9
Correct prediction
Energy consumption = 146.380946 pJ
sum error= 166
Actual label: 2
Output voltages: [0.73533, 0.0018109, 0.79877, 0.24367, 0.014511, 0.0011298, 0.043868, 0.06651, 0.73887, 0.010331]
Predicted label: 2
Correct prediction
Energy consumption = 140.650780 pJ
sum error= 166
Actual label: 6
Output voltages: [0.46369, 0.075788, 0.046629, 0.0023398, 0.2625, 0.404, 0.79874, 0.029736, 0.19674, 0.016474]
Predicted label: 6
Correct prediction
Energy consumption = 144.765895 pJ
sum error= 166
Actual label: 7
Output voltages: [0.10789, 0.28966, 0.025408, 0.015106, 0.0090589, 0.0077138, 0.0010831, 0.79588, 0.10849, 0.56901]
Predicted label: 7
Correct prediction
Energy consumption = 160.689219 pJ
sum error= 166
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 306 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 306 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 306 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.2668, 0.55273, 0.15964, 0.023595, 0.017122, 0.0032065, 0.0012015, 0.50675, 0.077991, 0.79396]
Predicted label: 9
Correct prediction
Energy consumption = 173.421398 pJ
sum error= 166
Actual label: 7
Output voltages: [0.067077, 0.015635, 0.25698, 0.32213, 0.0028133, 0.0011101, 0.0016047, 0.79878, 0.062373, 0.13804]
Predicted label: 7
Correct prediction
Energy consumption = 144.592581 pJ
sum error= 166
Actual label: 8
Output voltages: [0.55756, 0.026658, 0.67033, 0.79403, 0.0010978, 0.0093256, 0.096749, 0.012982, 0.79391, 0.001418]
Predicted label: 3
Wrong prediction!
Energy consumption = 147.724604 pJ
sum error= 167
Actual label: 6
Output voltages: [0.08157, 0.042946, 0.030653, 0.0045085, 0.15739, 0.25934, 0.79879, 0.026089, 0.74777, 0.0052314]
Predicted label: 6
Correct prediction
Energy consumption = 150.840077 pJ
sum error= 167
Actual label: 8
Output voltages: [0.0248, 0.020383, 0.11114, 0.16466, 0.0020036, 0.090711, 0.092364, 0.013598, 0.7987, 0.056151]
Predicted label: 8
Correct prediction
Energy consumption = 150.598040 pJ
sum error= 167
Actual label: 8
Output voltages: [0.025859, 0.11811, 0.018845, 0.29968, 0.0081053, 0.15761, 0.044295, 0.0011183, 0.79879, 0.59672]
Predicted label: 8
Correct prediction
Energy consumption = 146.077112 pJ
sum error= 167
Actual label: 4
Output voltages: [0.002697, 0.004651, 0.039098, 0.018347, 0.79878, 0.0096343, 0.040387, 0.019204, 0.071396, 0.015178]
Predicted label: 4
Correct prediction
Energy consumption = 153.546585 pJ
sum error= 167
Actual label: 6
Output voltages: [0.1245, 0.042593, 0.2419, 0.003379, 0.1025, 0.36622, 0.79873, 0.0022044, 0.70395, 0.012384]
Predicted label: 6
Correct prediction
Energy consumption = 143.306814 pJ
sum error= 167
Actual label: 8
Output voltages: [0.064632, 0.03231, 0.18118, 0.76213, 0.0011218, 0.014326, 0.0011739, 0.28067, 0.79877, 0.033383]
Predicted label: 8
Correct prediction
Energy consumption = 151.673005 pJ
sum error= 167
Actual label: 4
Output voltages: [0.48578, 0.0012407, 0.3771, 0.0010671, 0.78255, 0.0121, 0.40992, 0.0010753, 0.047085, 0.15864]
Predicted label: 4
Correct prediction
Energy consumption = 157.621024 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 307 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 307 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 307 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.033141, 0.79863, 0.53753, 0.18155, 0.067862, 0.0010678, 0.41326, 0.0064133, 0.1299, 0.045653]
Predicted label: 1
Correct prediction
Energy consumption = 187.482811 pJ
sum error= 167
Actual label: 2
Output voltages: [0.47801, 0.0055998, 0.79876, 0.10008, 0.037787, 0.0010872, 0.044666, 0.054238, 0.66746, 0.0071075]
Predicted label: 2
Correct prediction
Energy consumption = 141.657608 pJ
sum error= 167
Actual label: 8
Output voltages: [0.023704, 0.10958, 0.1642, 0.46586, 0.0053444, 0.014855, 0.012819, 0.022391, 0.79867, 0.054748]
Predicted label: 8
Correct prediction
Energy consumption = 150.561572 pJ
sum error= 167
Actual label: 1
Output voltages: [0.020925, 0.79463, 0.76582, 0.47401, 0.060769, 0.001079, 0.043703, 0.031324, 0.21416, 0.0019438]
Predicted label: 1
Correct prediction
Energy consumption = 147.160526 pJ
sum error= 167
Actual label: 3
Output voltages: [0.12079, 0.01405, 0.075082, 0.79871, 0.017092, 0.0068992, 0.0060665, 0.018463, 0.55649, 0.11396]
Predicted label: 3
Correct prediction
Energy consumption = 133.869034 pJ
sum error= 167
Actual label: 9
Output voltages: [0.52247, 0.0030433, 0.013136, 0.020265, 0.16154, 0.046629, 0.0084101, 0.040901, 0.46964, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 152.792422 pJ
sum error= 167
Actual label: 4
Output voltages: [0.0076647, 0.017848, 0.064024, 0.0043217, 0.79871, 0.0036098, 0.11289, 0.058669, 0.13302, 0.020551]
Predicted label: 4
Correct prediction
Energy consumption = 148.240296 pJ
sum error= 167
Actual label: 0
Output voltages: [0.79875, 0.18659, 0.11533, 0.027102, 0.014925, 0.0096737, 0.74121, 0.0026276, 0.05058, 0.15009]
Predicted label: 0
Correct prediction
Energy consumption = 150.813652 pJ
sum error= 167
Actual label: 3
Output voltages: [0.16162, 0.039405, 0.12534, 0.79863, 0.018829, 0.0022415, 0.067564, 0.069715, 0.5018, 0.12619]
Predicted label: 3
Correct prediction
Energy consumption = 154.052678 pJ
sum error= 167
Actual label: 7
Output voltages: [0.085369, 0.054558, 0.040781, 0.04944, 0.001723, 0.0038605, 0.0011005, 0.79874, 0.52373, 0.3462]
Predicted label: 7
Correct prediction
Energy consumption = 151.401366 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 308 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 308 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 308 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23899, 0.03921, 0.16567, 0.79873, 0.023788, 0.0015001, 0.0083956, 0.0078819, 0.73223, 0.024556]
Predicted label: 3
Correct prediction
Energy consumption = 164.194194 pJ
sum error= 167
Actual label: 2
Output voltages: [0.30454, 0.086827, 0.79878, 0.092688, 0.0050224, 0.0012971, 0.15046, 0.045238, 0.5003, 0.015833]
Predicted label: 2
Correct prediction
Energy consumption = 139.702619 pJ
sum error= 167
Actual label: 3
Output voltages: [0.73376, 0.015783, 0.24636, 0.79866, 0.018599, 0.023725, 0.0094469, 0.034897, 0.5839, 0.020265]
Predicted label: 3
Correct prediction
Energy consumption = 146.808290 pJ
sum error= 167
Actual label: 3
Output voltages: [0.23272, 0.060958, 0.017367, 0.79868, 0.08417, 0.049552, 0.22446, 0.030123, 0.36611, 0.020652]
Predicted label: 3
Correct prediction
Energy consumption = 138.551865 pJ
sum error= 167
Actual label: 7
Output voltages: [0.11076, 0.03231, 0.028907, 0.026561, 0.024904, 0.011077, 0.0014875, 0.79866, 0.045658, 0.60947]
Predicted label: 7
Correct prediction
Energy consumption = 158.702697 pJ
sum error= 167
Actual label: 3
Output voltages: [0.14207, 0.013249, 0.50209, 0.7987, 0.029941, 0.0021469, 0.009093, 0.0010807, 0.58177, 0.052248]
Predicted label: 3
Correct prediction
Energy consumption = 152.587478 pJ
sum error= 167
Actual label: 4
Output voltages: [0.0030041, 0.0067129, 0.15487, 0.0089152, 0.79879, 0.0011657, 0.013058, 0.034264, 0.6139, 0.015813]
Predicted label: 4
Correct prediction
Energy consumption = 158.267223 pJ
sum error= 167
Actual label: 0
Output voltages: [0.79879, 0.036958, 0.038445, 0.03412, 0.023462, 0.0048549, 0.68947, 0.011026, 0.051498, 0.20848]
Predicted label: 0
Correct prediction
Energy consumption = 159.468907 pJ
sum error= 167
Actual label: 6
Output voltages: [0.03618, 0.032379, 0.13588, 0.0037955, 0.049027, 0.18905, 0.79876, 0.01595, 0.56378, 0.0051255]
Predicted label: 6
Correct prediction
Energy consumption = 149.846604 pJ
sum error= 167
Actual label: 2
Output voltages: [0.34816, 0.10495, 0.79879, 0.039457, 0.0059251, 0.0013202, 0.21651, 0.020779, 0.62325, 0.030853]
Predicted label: 2
Correct prediction
Energy consumption = 148.782043 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 309 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 309 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 309 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.026297, 0.036226, 0.0098415, 0.06656, 0.0028951, 0.56153, 0.012997, 0.062457, 0.065863]
Predicted label: 0
Correct prediction
Energy consumption = 179.368508 pJ
sum error= 167
Actual label: 8
Output voltages: [0.70022, 0.021765, 0.18935, 0.55685, 0.0065322, 0.017867, 0.020666, 0.0011018, 0.79743, 0.47552]
Predicted label: 8
Correct prediction
Energy consumption = 152.929392 pJ
sum error= 167
Actual label: 1
Output voltages: [0.09016, 0.79876, 0.44318, 0.080657, 0.38242, 0.0017025, 0.23005, 0.01163, 0.036463, 0.035656]
Predicted label: 1
Correct prediction
Energy consumption = 168.345626 pJ
sum error= 167
Actual label: 5
Output voltages: [0.019879, 0.0010669, 0.001536, 0.34687, 0.011519, 0.7814, 0.15083, 0.016933, 0.73203, 0.083971]
Predicted label: 5
Correct prediction
Energy consumption = 151.128505 pJ
sum error= 167
Actual label: 3
Output voltages: [0.31313, 0.036947, 0.036444, 0.79868, 0.0090694, 0.010382, 0.013126, 0.009989, 0.47259, 0.10108]
Predicted label: 3
Correct prediction
Energy consumption = 144.371967 pJ
sum error= 167
Actual label: 5
Output voltages: [0.17857, 0.0018454, 0.0067604, 0.2365, 0.022124, 0.79879, 0.37585, 0.031301, 0.56483, 0.010065]
Predicted label: 5
Correct prediction
Energy consumption = 144.700534 pJ
sum error= 167
Actual label: 4
Output voltages: [0.019779, 0.0024495, 0.1735, 0.0039135, 0.79862, 0.0070308, 0.29928, 0.1476, 0.056411, 0.0049708]
Predicted label: 4
Correct prediction
Energy consumption = 151.598108 pJ
sum error= 167
Actual label: 1
Output voltages: [0.29858, 0.79875, 0.0018532, 0.015249, 0.74029, 0.0048095, 0.11814, 0.0012299, 0.44562, 0.19881]
Predicted label: 1
Correct prediction
Energy consumption = 155.099354 pJ
sum error= 167
Actual label: 7
Output voltages: [0.13484, 0.13621, 0.012281, 0.012246, 0.014748, 0.0052038, 0.0015962, 0.79869, 0.138, 0.34916]
Predicted label: 7
Correct prediction
Energy consumption = 156.972309 pJ
sum error= 167
Actual label: 1
Output voltages: [0.016673, 0.79872, 0.45188, 0.044846, 0.04214, 0.0017921, 0.77232, 0.0030838, 0.22591, 0.013783]
Predicted label: 1
Correct prediction
Energy consumption = 151.600702 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 310 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 310 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 310 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.034155, 0.0020489, 0.0046732, 0.78839, 0.0046054, 0.79155, 0.042349, 0.037118, 0.69913, 0.0084271]
Predicted label: 5
Correct prediction
Energy consumption = 161.491147 pJ
sum error= 167
Actual label: 7
Output voltages: [0.43259, 0.01196, 0.034398, 0.036549, 0.03298, 0.015575, 0.001091, 0.79849, 0.30488, 0.24547]
Predicted label: 7
Correct prediction
Energy consumption = 151.014985 pJ
sum error= 167
Actual label: 5
Output voltages: [0.002836, 0.023854, 0.0033082, 0.48515, 0.01451, 0.79873, 0.060711, 0.22013, 0.4189, 0.29357]
Predicted label: 5
Correct prediction
Energy consumption = 144.657018 pJ
sum error= 167
Actual label: 7
Output voltages: [0.033014, 0.4083, 0.28166, 0.12925, 0.075205, 0.0011189, 0.0010723, 0.79823, 0.021487, 0.33668]
Predicted label: 7
Correct prediction
Energy consumption = 153.039138 pJ
sum error= 167
Actual label: 3
Output voltages: [0.48479, 0.055699, 0.071112, 0.79863, 0.052292, 0.0028163, 0.024084, 0.025705, 0.56992, 0.040617]
Predicted label: 3
Correct prediction
Energy consumption = 151.340597 pJ
sum error= 167
Actual label: 2
Output voltages: [0.77796, 0.0031703, 0.79814, 0.43105, 0.013478, 0.0011531, 0.023876, 0.031506, 0.75204, 0.013176]
Predicted label: 2
Correct prediction
Energy consumption = 142.169935 pJ
sum error= 167
Actual label: 2
Output voltages: [0.74664, 0.03862, 0.78613, 0.26396, 0.0072181, 0.0011194, 0.51945, 0.0060191, 0.55303, 0.007665]
Predicted label: 2
Correct prediction
Energy consumption = 139.019411 pJ
sum error= 167
Actual label: 7
Output voltages: [0.22125, 0.014172, 0.0021021, 0.038554, 0.1077, 0.16284, 0.0014927, 0.79873, 0.54642, 0.55392]
Predicted label: 7
Correct prediction
Energy consumption = 158.938082 pJ
sum error= 167
Actual label: 3
Output voltages: [0.37193, 0.032572, 0.06126, 0.79878, 0.0071561, 0.055215, 0.015474, 0.014371, 0.40045, 0.04812]
Predicted label: 3
Correct prediction
Energy consumption = 150.025591 pJ
sum error= 167
Actual label: 7
Output voltages: [0.20988, 0.74376, 0.28081, 0.34507, 0.0018867, 0.0013952, 0.0067439, 0.78165, 0.072521, 0.11209]
Predicted label: 7
Correct prediction
Energy consumption = 153.820563 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 311 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 311 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 311 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.71988, 0.0015578, 0.11855, 0.79878, 0.0012653, 0.039143, 0.062696, 0.1375, 0.38474, 0.0012106]
Predicted label: 3
Correct prediction
Energy consumption = 163.233467 pJ
sum error= 167
Actual label: 7
Output voltages: [0.04886, 0.40392, 0.18686, 0.0049692, 0.04735, 0.0010844, 0.0019833, 0.79877, 0.016626, 0.41723]
Predicted label: 7
Correct prediction
Energy consumption = 147.858200 pJ
sum error= 167
Actual label: 8
Output voltages: [0.22975, 0.0013636, 0.63502, 0.37815, 0.01699, 0.030584, 0.032039, 0.0075008, 0.79879, 0.1629]
Predicted label: 8
Correct prediction
Energy consumption = 156.765966 pJ
sum error= 167
Actual label: 5
Output voltages: [0.035671, 0.0011352, 0.0018122, 0.044822, 0.053636, 0.79854, 0.048481, 0.036804, 0.78347, 0.036546]
Predicted label: 5
Correct prediction
Energy consumption = 139.355858 pJ
sum error= 167
Actual label: 4
Output voltages: [0.020622, 0.044949, 0.52234, 0.062117, 0.79877, 0.0017657, 0.76646, 0.036033, 0.0010825, 0.030381]
Predicted label: 4
Correct prediction
Energy consumption = 157.906633 pJ
sum error= 167
Actual label: 5
Output voltages: [0.11116, 0.0011322, 0.0010661, 0.016721, 0.11205, 0.79874, 0.0071018, 0.24282, 0.63875, 0.11109]
Predicted label: 5
Correct prediction
Energy consumption = 142.655427 pJ
sum error= 167
Actual label: 2
Output voltages: [0.46348, 0.061927, 0.79867, 0.043906, 0.034227, 0.0012428, 0.34069, 0.027015, 0.39759, 0.045396]
Predicted label: 2
Correct prediction
Energy consumption = 145.244564 pJ
sum error= 167
Actual label: 5
Output voltages: [0.046738, 0.0035146, 0.0011699, 0.34122, 0.66217, 0.6683, 0.052688, 0.0038286, 0.037822, 0.56561]
Predicted label: 5
Correct prediction
Energy consumption = 145.617558 pJ
sum error= 167
Actual label: 6
Output voltages: [0.3467, 0.14307, 0.038416, 0.0047244, 0.25677, 0.67222, 0.79874, 0.0092718, 0.23322, 0.013809]
Predicted label: 6
Correct prediction
Energy consumption = 149.154052 pJ
sum error= 167
Actual label: 5
Output voltages: [0.024746, 0.0042253, 0.018673, 0.30459, 0.042418, 0.79662, 0.039933, 0.0044281, 0.777, 0.23633]
Predicted label: 5
Correct prediction
Energy consumption = 139.673852 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 312 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 312 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 312 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.4036, 0.020457, 0.20567, 0.79876, 0.0078799, 0.0045933, 0.038736, 0.0022415, 0.60912, 0.034736]
Predicted label: 3
Correct prediction
Energy consumption = 163.069762 pJ
sum error= 167
Actual label: 6
Output voltages: [0.069753, 0.046782, 0.39942, 0.0010795, 0.27531, 0.023286, 0.79879, 0.017383, 0.18478, 0.0010957]
Predicted label: 6
Correct prediction
Energy consumption = 151.297050 pJ
sum error= 167
Actual label: 7
Output voltages: [0.038684, 0.020785, 0.67296, 0.059653, 0.040887, 0.0012496, 0.020609, 0.79871, 0.031969, 0.042256]
Predicted label: 7
Correct prediction
Energy consumption = 140.304213 pJ
sum error= 167
Actual label: 4
Output voltages: [0.013274, 0.024559, 0.071456, 0.0035266, 0.7986, 0.0017909, 0.069567, 0.012095, 0.036581, 0.12888]
Predicted label: 4
Correct prediction
Energy consumption = 160.001576 pJ
sum error= 167
Actual label: 1
Output voltages: [0.043901, 0.79858, 0.012808, 0.045413, 0.057912, 0.0012542, 0.63477, 0.012254, 0.052327, 0.1311]
Predicted label: 1
Correct prediction
Energy consumption = 161.791166 pJ
sum error= 167
Actual label: 7
Output voltages: [0.071812, 0.049454, 0.5531, 0.20185, 0.013875, 0.0011048, 0.001066, 0.79865, 0.24723, 0.29032]
Predicted label: 7
Correct prediction
Energy consumption = 152.424558 pJ
sum error= 167
Actual label: 1
Output voltages: [0.049578, 0.79849, 0.079329, 0.049189, 0.05471, 0.0021845, 0.69159, 0.0086616, 0.10668, 0.07058]
Predicted label: 1
Correct prediction
Energy consumption = 165.128919 pJ
sum error= 167
Actual label: 5
Output voltages: [0.091571, 0.0010837, 0.0037017, 0.32834, 0.018648, 0.79879, 0.067973, 0.21077, 0.78442, 0.073853]
Predicted label: 5
Correct prediction
Energy consumption = 154.887032 pJ
sum error= 167
Actual label: 2
Output voltages: [0.31381, 0.26021, 0.79879, 0.3624, 0.0060925, 0.001321, 0.29543, 0.0069844, 0.25662, 0.023368]
Predicted label: 2
Correct prediction
Energy consumption = 151.668175 pJ
sum error= 167
Actual label: 3
Output voltages: [0.33663, 0.0027618, 0.58682, 0.79834, 0.003366, 0.0010921, 0.018293, 0.0089864, 0.6246, 0.020462]
Predicted label: 3
Correct prediction
Energy consumption = 137.848362 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 313 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 313 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 313 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.75072, 0.14615, 0.0039267, 0.044674, 0.0032262, 0.73672, 0.76954, 0.015869, 0.338, 0.001365]
Predicted label: 6
Correct prediction
Energy consumption = 170.961577 pJ
sum error= 167
Actual label: 3
Output voltages: [0.034126, 0.00343, 0.032443, 0.79868, 0.1119, 0.20344, 0.30273, 0.021551, 0.56487, 0.080207]
Predicted label: 3
Correct prediction
Energy consumption = 148.841937 pJ
sum error= 167
Actual label: 1
Output voltages: [0.064645, 0.77072, 0.75859, 0.39871, 0.0010975, 0.0010962, 0.31779, 0.012736, 0.36933, 0.0011701]
Predicted label: 1
Correct prediction
Energy consumption = 148.632123 pJ
sum error= 167
Actual label: 4
Output voltages: [0.0011768, 0.02452, 0.0056879, 0.0020677, 0.79537, 0.028897, 0.21964, 0.12292, 0.55076, 0.03935]
Predicted label: 4
Correct prediction
Energy consumption = 148.011373 pJ
sum error= 167
Actual label: 2
Output voltages: [0.53457, 0.0025192, 0.79879, 0.044182, 0.027921, 0.0010732, 0.05017, 0.037503, 0.50892, 0.006532]
Predicted label: 2
Correct prediction
Energy consumption = 147.210376 pJ
sum error= 167
Actual label: 6
Output voltages: [0.073285, 0.17761, 0.039401, 0.010713, 0.20623, 0.51898, 0.79874, 0.003485, 0.44136, 0.0030702]
Predicted label: 6
Correct prediction
Energy consumption = 148.836307 pJ
sum error= 167
Actual label: 7
Output voltages: [0.029112, 0.001066, 0.0077595, 0.061383, 0.69154, 0.018788, 0.0010923, 0.68534, 0.72297, 0.043473]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.095238 pJ
sum error= 168
Actual label: 4
Output voltages: [0.0048903, 0.010659, 0.040965, 0.0012878, 0.79868, 0.0011726, 0.30214, 0.20419, 0.036384, 0.033865]
Predicted label: 4
Correct prediction
Energy consumption = 145.491393 pJ
sum error= 168
Actual label: 3
Output voltages: [0.71554, 0.16367, 0.065691, 0.7968, 0.0054942, 0.44445, 0.040528, 0.11642, 0.1078, 0.0011005]
Predicted label: 3
Correct prediction
Energy consumption = 153.946566 pJ
sum error= 168
Actual label: 8
Output voltages: [0.040965, 0.014909, 0.26132, 0.33426, 0.012665, 0.011992, 0.15493, 0.005093, 0.79878, 0.047016]
Predicted label: 8
Correct prediction
Energy consumption = 153.725859 pJ
sum error= 168
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 314 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 314 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 314 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79316, 0.13195, 0.17189, 0.039511, 0.0055404, 0.001605, 0.52451, 0.02158, 0.52433, 0.019339]
Predicted label: 0
Correct prediction
Energy consumption = 175.898481 pJ
sum error= 168
Actual label: 6
Output voltages: [0.30231, 0.072224, 0.072503, 0.025658, 0.096517, 0.6442, 0.79876, 0.0030251, 0.4757, 0.071183]
Predicted label: 6
Correct prediction
Energy consumption = 152.079672 pJ
sum error= 168
Actual label: 2
Output voltages: [0.64926, 0.066178, 0.79873, 0.14712, 0.0060668, 0.0011368, 0.35315, 0.069745, 0.76453, 0.032393]
Predicted label: 2
Correct prediction
Energy consumption = 145.163388 pJ
sum error= 168
Actual label: 1
Output voltages: [0.0098547, 0.79845, 0.092011, 0.59018, 0.0019151, 0.0013454, 0.027211, 0.040158, 0.066004, 0.18814]
Predicted label: 1
Correct prediction
Energy consumption = 159.321069 pJ
sum error= 168
Actual label: 6
Output voltages: [0.045851, 0.038544, 0.32136, 0.0011725, 0.19838, 0.061407, 0.79879, 0.0014004, 0.70742, 0.013933]
Predicted label: 6
Correct prediction
Energy consumption = 145.039153 pJ
sum error= 168
Actual label: 5
Output voltages: [0.012749, 0.0011131, 0.019857, 0.12843, 0.19883, 0.79744, 0.043093, 0.020926, 0.78487, 0.23932]
Predicted label: 5
Correct prediction
Energy consumption = 151.824585 pJ
sum error= 168
Actual label: 3
Output voltages: [0.072759, 0.031123, 0.06029, 0.79874, 0.012698, 0.0091956, 0.013091, 0.05291, 0.75044, 0.052629]
Predicted label: 3
Correct prediction
Energy consumption = 140.106081 pJ
sum error= 168
Actual label: 9
Output voltages: [0.3302, 0.022427, 0.0083769, 0.33321, 0.38446, 0.10463, 0.034334, 0.0022853, 0.16249, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 141.848995 pJ
sum error= 168
Actual label: 1
Output voltages: [0.056745, 0.79835, 0.076582, 0.04453, 0.041748, 0.0061178, 0.48647, 0.003984, 0.045314, 0.13341]
Predicted label: 1
Correct prediction
Energy consumption = 165.990105 pJ
sum error= 168
Actual label: 9
Output voltages: [0.49197, 0.0084439, 0.0093315, 0.052497, 0.26583, 0.02289, 0.0020423, 0.0087771, 0.30523, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.988838 pJ
sum error= 168
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 315 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 315 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 315 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.027958, 0.020429, 0.056792, 0.79872, 0.02389, 0.018128, 0.0082417, 0.029778, 0.67849, 0.023063]
Predicted label: 3
Correct prediction
Energy consumption = 161.723391 pJ
sum error= 168
Actual label: 2
Output voltages: [0.091131, 0.26391, 0.7985, 0.083952, 0.0045894, 0.0013988, 0.33762, 0.01903, 0.50034, 0.01952]
Predicted label: 2
Correct prediction
Energy consumption = 143.902337 pJ
sum error= 168
Actual label: 1
Output voltages: [0.0022268, 0.79858, 0.10065, 0.055958, 0.053102, 0.0010787, 0.37978, 0.006822, 0.29006, 0.026875]
Predicted label: 1
Correct prediction
Energy consumption = 160.762763 pJ
sum error= 168
Actual label: 8
Output voltages: [0.19785, 0.0031897, 0.53165, 0.58122, 0.0025425, 0.0078088, 0.0050006, 0.011177, 0.79687, 0.27129]
Predicted label: 8
Correct prediction
Energy consumption = 155.463124 pJ
sum error= 168
Actual label: 4
Output voltages: [0.070064, 0.0069159, 0.20057, 0.0013148, 0.79874, 0.0037291, 0.28531, 0.29027, 0.0086156, 0.069603]
Predicted label: 4
Correct prediction
Energy consumption = 157.328096 pJ
sum error= 168
Actual label: 4
Output voltages: [0.0031786, 0.012496, 0.030351, 0.023562, 0.79879, 0.0011241, 0.038077, 0.034705, 0.041336, 0.036461]
Predicted label: 4
Correct prediction
Energy consumption = 156.070924 pJ
sum error= 168
Actual label: 6
Output voltages: [0.051831, 0.031977, 0.40062, 0.0010694, 0.14682, 0.064632, 0.79879, 0.0035852, 0.56847, 0.0090888]
Predicted label: 6
Correct prediction
Energy consumption = 149.986908 pJ
sum error= 168
Actual label: 5
Output voltages: [0.41549, 0.014242, 0.0010686, 0.58769, 0.021887, 0.79879, 0.011032, 0.11256, 0.46501, 0.0067039]
Predicted label: 5
Correct prediction
Energy consumption = 150.681430 pJ
sum error= 168
Actual label: 8
Output voltages: [0.30052, 0.0087526, 0.34819, 0.2728, 0.013415, 0.0045612, 0.036487, 0.00108, 0.79837, 0.46996]
Predicted label: 8
Correct prediction
Energy consumption = 151.531319 pJ
sum error= 168
Actual label: 6
Output voltages: [0.042496, 0.039062, 0.048681, 0.004997, 0.24949, 0.099505, 0.79877, 0.0032927, 0.75886, 0.0063504]
Predicted label: 6
Correct prediction
Energy consumption = 146.699358 pJ
sum error= 168
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 316 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 316 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 316 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.063481, 0.0287, 0.0022236, 0.13649, 0.65748, 0.21931, 0.0598, 0.0061381, 0.056156, 0.77569]
Predicted label: 9
Correct prediction
Energy consumption = 175.562531 pJ
sum error= 168
Actual label: 7
Output voltages: [0.29791, 0.3925, 0.55439, 0.014614, 0.0025059, 0.0011101, 0.0012502, 0.79878, 0.11837, 0.068785]
Predicted label: 7
Correct prediction
Energy consumption = 157.681252 pJ
sum error= 168
Actual label: 7
Output voltages: [0.17001, 0.14389, 0.17386, 0.01504, 0.0015038, 0.001072, 0.001089, 0.79875, 0.69655, 0.14327]
Predicted label: 7
Correct prediction
Energy consumption = 145.533566 pJ
sum error= 168
Actual label: 8
Output voltages: [0.0034384, 0.027639, 0.037493, 0.27961, 0.011045, 0.014372, 0.034293, 0.0071938, 0.79875, 0.24283]
Predicted label: 8
Correct prediction
Energy consumption = 147.340186 pJ
sum error= 168
Actual label: 6
Output voltages: [0.22983, 0.0095409, 0.32318, 0.00134, 0.19103, 0.20055, 0.79867, 0.0031367, 0.37386, 0.0033217]
Predicted label: 6
Correct prediction
Energy consumption = 145.946972 pJ
sum error= 168
Actual label: 9
Output voltages: [0.28449, 0.050463, 0.046982, 0.11181, 0.048579, 0.10736, 0.0075394, 0.033096, 0.41266, 0.79828]
Predicted label: 9
Correct prediction
Energy consumption = 157.545156 pJ
sum error= 168
Actual label: 7
Output voltages: [0.021979, 0.18432, 0.78604, 0.4402, 0.022456, 0.0011842, 0.0078238, 0.75079, 0.74434, 0.012966]
Predicted label: 2
Wrong prediction!
Energy consumption = 146.436590 pJ
sum error= 169
Actual label: 3
Output voltages: [0.33033, 0.40243, 0.051487, 0.79857, 0.012313, 0.18269, 0.0049517, 0.034671, 0.3556, 0.02741]
Predicted label: 3
Correct prediction
Energy consumption = 151.692429 pJ
sum error= 169
Actual label: 9
Output voltages: [0.20578, 0.011256, 0.042246, 0.03021, 0.062728, 0.013388, 0.017998, 0.028848, 0.56707, 0.79829]
Predicted label: 9
Correct prediction
Energy consumption = 159.971134 pJ
sum error= 169
Actual label: 4
Output voltages: [0.0083569, 0.0051917, 0.35478, 0.0031356, 0.7987, 0.0013177, 0.28458, 0.032552, 0.032435, 0.027708]
Predicted label: 4
Correct prediction
Energy consumption = 150.685473 pJ
sum error= 169
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 317 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 317 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 317 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.095774, 0.045687, 0.0012845, 0.005486, 0.027341, 0.30328, 0.020911, 0.28736, 0.055723]
Predicted label: 0
Correct prediction
Energy consumption = 173.448157 pJ
sum error= 169
Actual label: 5
Output voltages: [0.065452, 0.0011192, 0.021413, 0.75207, 0.0090379, 0.39094, 0.007596, 0.013578, 0.78765, 0.030163]
Predicted label: 8
Wrong prediction!
Energy consumption = 155.746665 pJ
sum error= 170
Actual label: 4
Output voltages: [0.011829, 0.0070498, 0.37146, 0.047617, 0.7987, 0.013561, 0.029145, 0.0053338, 0.084368, 0.20939]
Predicted label: 4
Correct prediction
Energy consumption = 156.036562 pJ
sum error= 170
Actual label: 6
Output voltages: [0.12911, 0.22858, 0.41106, 0.0071692, 0.65909, 0.44968, 0.79868, 0.0010661, 0.036115, 0.0012567]
Predicted label: 6
Correct prediction
Energy consumption = 149.458538 pJ
sum error= 170
Actual label: 4
Output voltages: [0.0038173, 0.013004, 0.20714, 0.015362, 0.79856, 0.0071613, 0.25087, 0.046696, 0.034895, 0.03169]
Predicted label: 4
Correct prediction
Energy consumption = 156.008972 pJ
sum error= 170
Actual label: 1
Output voltages: [0.044134, 0.79844, 0.038222, 0.27353, 0.01129, 0.0028314, 0.36503, 0.032102, 0.15548, 0.18929]
Predicted label: 1
Correct prediction
Energy consumption = 169.964492 pJ
sum error= 170
Actual label: 2
Output voltages: [0.52323, 0.062124, 0.79602, 0.10524, 0.027953, 0.0013099, 0.1014, 0.59473, 0.24489, 0.021543]
Predicted label: 2
Correct prediction
Energy consumption = 150.608083 pJ
sum error= 170
Actual label: 3
Output voltages: [0.36879, 0.1842, 0.095395, 0.79858, 0.045182, 0.0063262, 0.032291, 0.18619, 0.4524, 0.027401]
Predicted label: 3
Correct prediction
Energy consumption = 140.715345 pJ
sum error= 170
Actual label: 0
Output voltages: [0.75689, 0.0010671, 0.34991, 0.027065, 0.0088698, 0.25237, 0.56005, 0.0010661, 0.3119, 0.088577]
Predicted label: 0
Correct prediction
Energy consumption = 162.469669 pJ
sum error= 170
Actual label: 0
Output voltages: [0.79879, 0.029339, 0.015025, 0.0046307, 0.0093124, 0.020058, 0.48105, 0.0023079, 0.04889, 0.028151]
Predicted label: 0
Correct prediction
Energy consumption = 144.222114 pJ
sum error= 170
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 318 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 318 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 318 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.44186, 0.19447, 0.79878, 0.25785, 0.013084, 0.0013215, 0.28985, 0.0073275, 0.28603, 0.022308]
Predicted label: 2
Correct prediction
Energy consumption = 167.418233 pJ
sum error= 170
Actual label: 6
Output voltages: [0.45069, 0.034002, 0.035309, 0.0031075, 0.18657, 0.32593, 0.79879, 0.0030907, 0.37914, 0.0090509]
Predicted label: 6
Correct prediction
Energy consumption = 144.474282 pJ
sum error= 170
Actual label: 6
Output voltages: [0.38958, 0.0063216, 0.43206, 0.0010772, 0.47566, 0.043175, 0.79879, 0.0033702, 0.31429, 0.0082148]
Predicted label: 6
Correct prediction
Energy consumption = 134.400667 pJ
sum error= 170
Actual label: 5
Output voltages: [0.039718, 0.0012526, 0.00107, 0.51881, 0.038403, 0.79869, 0.66557, 0.015389, 0.77489, 0.013235]
Predicted label: 5
Correct prediction
Energy consumption = 147.883799 pJ
sum error= 170
Actual label: 7
Output voltages: [0.04549, 0.013142, 0.10181, 0.039261, 0.01961, 0.0010691, 0.0014116, 0.79854, 0.22825, 0.054341]
Predicted label: 7
Correct prediction
Energy consumption = 151.625559 pJ
sum error= 170
Actual label: 0
Output voltages: [0.79855, 0.093694, 0.030145, 0.027744, 0.046335, 0.0043875, 0.7596, 0.0092892, 0.19961, 0.043936]
Predicted label: 0
Correct prediction
Energy consumption = 160.156234 pJ
sum error= 170
Actual label: 8
Output voltages: [0.36037, 0.0094334, 0.49189, 0.42011, 0.015454, 0.0010734, 0.031312, 0.0017599, 0.79476, 0.46506]
Predicted label: 8
Correct prediction
Energy consumption = 157.662002 pJ
sum error= 170
Actual label: 6
Output voltages: [0.11478, 0.14884, 0.032033, 0.022376, 0.27986, 0.46429, 0.79869, 0.0030393, 0.39628, 0.031046]
Predicted label: 6
Correct prediction
Energy consumption = 152.484952 pJ
sum error= 170
Actual label: 4
Output voltages: [0.0011869, 0.013699, 0.52271, 0.036508, 0.79875, 0.0011176, 0.4233, 0.5288, 0.0034331, 0.085486]
Predicted label: 4
Correct prediction
Energy consumption = 151.128922 pJ
sum error= 170
Actual label: 7
Output voltages: [0.1123, 0.0015444, 0.053323, 0.040242, 0.017007, 0.0079295, 0.022149, 0.79866, 0.12208, 0.0028866]
Predicted label: 7
Correct prediction
Energy consumption = 133.379201 pJ
sum error= 170
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 319 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 319 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 319 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.43938, 0.025703, 0.022767, 0.31114, 0.21913, 0.015312, 0.011099, 0.01428, 0.16399, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 171.176311 pJ
sum error= 170
Actual label: 0
Output voltages: [0.79877, 0.060269, 0.027423, 0.15347, 0.039454, 0.018857, 0.45069, 0.036452, 0.16548, 0.012855]
Predicted label: 0
Correct prediction
Energy consumption = 162.864617 pJ
sum error= 170
Actual label: 7
Output voltages: [0.33422, 0.18883, 0.55483, 0.45218, 0.0010929, 0.0011348, 0.0012285, 0.79817, 0.35109, 0.53206]
Predicted label: 7
Correct prediction
Energy consumption = 162.281130 pJ
sum error= 170
Actual label: 3
Output voltages: [0.38106, 0.014725, 0.56861, 0.79879, 0.013549, 0.0022792, 0.002162, 0.0075082, 0.58982, 0.014918]
Predicted label: 3
Correct prediction
Energy consumption = 141.456719 pJ
sum error= 170
Actual label: 4
Output voltages: [0.0025018, 0.033328, 0.0138, 0.0088606, 0.79877, 0.0014075, 0.033396, 0.69828, 0.06787, 0.0013681]
Predicted label: 4
Correct prediction
Energy consumption = 150.567090 pJ
sum error= 170
Actual label: 2
Output voltages: [0.67654, 0.031334, 0.79876, 0.20344, 0.024039, 0.0011682, 0.30315, 0.042444, 0.66062, 0.032228]
Predicted label: 2
Correct prediction
Energy consumption = 152.353349 pJ
sum error= 170
Actual label: 1
Output voltages: [0.01002, 0.79879, 0.011693, 0.011789, 0.11068, 0.011317, 0.3977, 0.0061298, 0.66289, 0.14834]
Predicted label: 1
Correct prediction
Energy consumption = 156.130716 pJ
sum error= 170
Actual label: 8
Output voltages: [0.030039, 0.037515, 0.25622, 0.015371, 0.070498, 0.0084206, 0.012823, 0.0083525, 0.79872, 0.10374]
Predicted label: 8
Correct prediction
Energy consumption = 144.654947 pJ
sum error= 170
Actual label: 8
Output voltages: [0.023852, 0.0065443, 0.1893, 0.1032, 0.0051301, 0.28343, 0.09736, 0.0221, 0.79875, 0.14947]
Predicted label: 8
Correct prediction
Energy consumption = 147.678295 pJ
sum error= 170
Actual label: 5
Output voltages: [0.021834, 0.0011118, 0.0048405, 0.031178, 0.24563, 0.79867, 0.35233, 0.031009, 0.79696, 0.026993]
Predicted label: 5
Correct prediction
Energy consumption = 133.323228 pJ
sum error= 170
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 320 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 320 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 320 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.018668, 0.019186, 0.034935, 0.40494, 0.040789, 0.029323, 0.31425, 0.024902, 0.31883, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 168.480096 pJ
sum error= 170
Actual label: 2
Output voltages: [0.20591, 0.020555, 0.79878, 0.20619, 0.005736, 0.0010724, 0.16928, 0.028901, 0.5184, 0.0088473]
Predicted label: 2
Correct prediction
Energy consumption = 152.063665 pJ
sum error= 170
Actual label: 7
Output voltages: [0.012351, 0.013292, 0.10055, 0.10209, 0.045647, 0.0018226, 0.0010764, 0.79874, 0.77295, 0.0090585]
Predicted label: 7
Correct prediction
Energy consumption = 143.662659 pJ
sum error= 170
Actual label: 1
Output voltages: [0.022438, 0.79848, 0.24907, 0.070553, 0.014176, 0.001145, 0.30979, 0.0039666, 0.31931, 0.034892]
Predicted label: 1
Correct prediction
Energy consumption = 162.611495 pJ
sum error= 170
Actual label: 8
Output voltages: [0.039566, 0.03943, 0.13528, 0.095576, 0.0032692, 0.023295, 0.014473, 0.010864, 0.79869, 0.62631]
Predicted label: 8
Correct prediction
Energy consumption = 153.298380 pJ
sum error= 170
Actual label: 8
Output voltages: [0.31967, 0.014151, 0.01004, 0.35999, 0.0013441, 0.59597, 0.24531, 0.0026948, 0.79878, 0.017667]
Predicted label: 8
Correct prediction
Energy consumption = 151.215607 pJ
sum error= 170
Actual label: 8
Output voltages: [0.27567, 0.017033, 0.35842, 0.79831, 0.019465, 0.0014541, 0.0095851, 0.0054862, 0.79547, 0.0064851]
Predicted label: 3
Wrong prediction!
Energy consumption = 144.778905 pJ
sum error= 171
Actual label: 2
Output voltages: [0.56674, 0.0062776, 0.7973, 0.21687, 0.009154, 0.0011754, 0.012064, 0.053211, 0.76335, 0.032521]
Predicted label: 2
Correct prediction
Energy consumption = 137.087261 pJ
sum error= 171
Actual label: 7
Output voltages: [0.069243, 0.0084709, 0.024748, 0.774, 0.0064895, 0.0089504, 0.0011202, 0.79636, 0.064748, 0.67479]
Predicted label: 7
Correct prediction
Energy consumption = 150.670839 pJ
sum error= 171
Actual label: 6
Output voltages: [0.056188, 0.04652, 0.034817, 0.017322, 0.15816, 0.33937, 0.79879, 0.0077915, 0.74777, 0.026076]
Predicted label: 6
Correct prediction
Energy consumption = 154.660975 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 321 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 321 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 321 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79806, 0.024308, 0.31778, 0.025521, 0.017133, 0.0015083, 0.44422, 0.04463, 0.21281, 0.032304]
Predicted label: 0
Correct prediction
Energy consumption = 174.047270 pJ
sum error= 171
Actual label: 1
Output voltages: [0.0456, 0.79834, 0.17965, 0.054727, 0.34752, 0.001066, 0.5598, 0.001105, 0.060177, 0.033246]
Predicted label: 1
Correct prediction
Energy consumption = 154.094452 pJ
sum error= 171
Actual label: 2
Output voltages: [0.13351, 0.011304, 0.79874, 0.091927, 0.0052333, 0.0011867, 0.048091, 0.38253, 0.57763, 0.0075955]
Predicted label: 2
Correct prediction
Energy consumption = 143.640463 pJ
sum error= 171
Actual label: 7
Output voltages: [0.11081, 0.23718, 0.46937, 0.028421, 0.03379, 0.0012566, 0.0010665, 0.79864, 0.040402, 0.06815]
Predicted label: 7
Correct prediction
Energy consumption = 147.673012 pJ
sum error= 171
Actual label: 1
Output voltages: [0.010434, 0.79879, 0.5414, 0.0069252, 0.22333, 0.0010884, 0.42318, 0.0063216, 0.25196, 0.014204]
Predicted label: 1
Correct prediction
Energy consumption = 148.509711 pJ
sum error= 171
Actual label: 0
Output voltages: [0.79875, 0.042868, 0.054782, 0.0087183, 0.012411, 0.0043142, 0.62785, 0.0079761, 0.047569, 0.04938]
Predicted label: 0
Correct prediction
Energy consumption = 153.455678 pJ
sum error= 171
Actual label: 8
Output voltages: [0.010894, 0.028934, 0.043474, 0.75899, 0.0013298, 0.076078, 0.0049281, 0.021732, 0.79879, 0.071967]
Predicted label: 8
Correct prediction
Energy consumption = 151.763945 pJ
sum error= 171
Actual label: 3
Output voltages: [0.66156, 0.010061, 0.27922, 0.7987, 0.022926, 0.0019507, 0.019586, 0.011665, 0.41225, 0.015919]
Predicted label: 3
Correct prediction
Energy consumption = 134.806402 pJ
sum error= 171
Actual label: 6
Output voltages: [0.26471, 0.0011254, 0.0015494, 0.011342, 0.03714, 0.79141, 0.76526, 0.0019629, 0.78378, 0.016941]
Predicted label: 5
Wrong prediction!
Energy consumption = 143.914124 pJ
sum error= 172
Actual label: 0
Output voltages: [0.79836, 0.028913, 0.016129, 0.015421, 0.18165, 0.0060191, 0.66912, 0.0048347, 0.1884, 0.026149]
Predicted label: 0
Correct prediction
Energy consumption = 148.144810 pJ
sum error= 172
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 322 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 322 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 322 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.14172, 0.016459, 0.0019142, 0.73877, 0.02282, 0.79879, 0.0080187, 0.0023407, 0.76998, 0.052953]
Predicted label: 5
Correct prediction
Energy consumption = 164.802161 pJ
sum error= 172
Actual label: 3
Output voltages: [0.16562, 0.04186, 0.036068, 0.79865, 0.033448, 0.0041541, 0.011452, 0.035502, 0.62046, 0.033057]
Predicted label: 3
Correct prediction
Energy consumption = 144.051957 pJ
sum error= 172
Actual label: 6
Output voltages: [0.049198, 0.0052444, 0.25528, 0.061212, 0.014653, 0.19795, 0.79864, 0.0011575, 0.69677, 0.25881]
Predicted label: 6
Correct prediction
Energy consumption = 134.120179 pJ
sum error= 172
Actual label: 2
Output voltages: [0.36291, 0.043175, 0.79872, 0.10095, 0.020474, 0.0011878, 0.16342, 0.04014, 0.61161, 0.028798]
Predicted label: 2
Correct prediction
Energy consumption = 147.803876 pJ
sum error= 172
Actual label: 8
Output voltages: [0.005031, 0.06277, 0.077454, 0.3597, 0.0011242, 0.031335, 0.020456, 0.0028046, 0.79879, 0.096261]
Predicted label: 8
Correct prediction
Energy consumption = 151.103033 pJ
sum error= 172
Actual label: 7
Output voltages: [0.057724, 0.26271, 0.15948, 0.65338, 0.0029751, 0.0012076, 0.0010941, 0.79869, 0.50375, 0.72047]
Predicted label: 7
Correct prediction
Energy consumption = 148.839141 pJ
sum error= 172
Actual label: 0
Output voltages: [0.79878, 0.16008, 0.0087925, 0.018727, 0.021384, 0.0463, 0.63234, 0.012029, 0.028991, 0.13564]
Predicted label: 0
Correct prediction
Energy consumption = 159.867760 pJ
sum error= 172
Actual label: 1
Output voltages: [0.020247, 0.79866, 0.0011998, 0.018606, 0.041439, 0.31922, 0.56112, 0.15786, 0.33728, 0.0053566]
Predicted label: 1
Correct prediction
Energy consumption = 163.536922 pJ
sum error= 172
Actual label: 4
Output voltages: [0.009892, 0.046307, 0.063138, 0.011335, 0.79872, 0.0017423, 0.44879, 0.031961, 0.026528, 0.38696]
Predicted label: 4
Correct prediction
Energy consumption = 162.605493 pJ
sum error= 172
Actual label: 2
Output voltages: [0.38169, 0.025611, 0.7974, 0.46646, 0.0071274, 0.0011289, 0.046936, 0.010352, 0.60427, 0.015367]
Predicted label: 2
Correct prediction
Energy consumption = 155.850553 pJ
sum error= 172
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 323 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 323 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 323 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.017161, 0.79848, 0.3843, 0.051757, 0.010591, 0.0011253, 0.44758, 0.0059772, 0.04574, 0.18307]
Predicted label: 1
Correct prediction
Energy consumption = 179.018061 pJ
sum error= 172
Actual label: 1
Output voltages: [0.027948, 0.79854, 0.038389, 0.3058, 0.010488, 0.0016176, 0.74591, 0.0019219, 0.05454, 0.028995]
Predicted label: 1
Correct prediction
Energy consumption = 151.587901 pJ
sum error= 172
Actual label: 4
Output voltages: [0.015724, 0.0083405, 0.35686, 0.016484, 0.79864, 0.001202, 0.088749, 0.036908, 0.01941, 0.41631]
Predicted label: 4
Correct prediction
Energy consumption = 158.786944 pJ
sum error= 172
Actual label: 4
Output voltages: [0.0031712, 0.02375, 0.13879, 0.0056685, 0.79879, 0.0072749, 0.044296, 0.026627, 0.3681, 0.062558]
Predicted label: 4
Correct prediction
Energy consumption = 151.791725 pJ
sum error= 172
Actual label: 4
Output voltages: [0.0068791, 0.0035816, 0.17069, 0.0011276, 0.79855, 0.0055113, 0.28039, 0.017429, 0.16504, 0.094362]
Predicted label: 4
Correct prediction
Energy consumption = 143.764670 pJ
sum error= 172
Actual label: 4
Output voltages: [0.021288, 0.029228, 0.040977, 0.012318, 0.79834, 0.048244, 0.2646, 0.023366, 0.055935, 0.77125]
Predicted label: 4
Correct prediction
Energy consumption = 148.573907 pJ
sum error= 172
Actual label: 7
Output voltages: [0.45858, 0.73235, 0.23424, 0.60064, 0.037818, 0.0012496, 0.0013644, 0.37827, 0.001422, 0.36168]
Predicted label: 1
Wrong prediction!
Energy consumption = 160.821848 pJ
sum error= 173
Actual label: 1
Output voltages: [0.01701, 0.79846, 0.028711, 0.016215, 0.039138, 0.002835, 0.35092, 0.019026, 0.011674, 0.19945]
Predicted label: 1
Correct prediction
Energy consumption = 149.780125 pJ
sum error= 173
Actual label: 6
Output voltages: [0.3636, 0.16629, 0.052403, 0.011207, 0.28236, 0.32352, 0.79879, 0.0016603, 0.31623, 0.024561]
Predicted label: 6
Correct prediction
Energy consumption = 151.500608 pJ
sum error= 173
Actual label: 2
Output voltages: [0.49858, 0.31716, 0.78693, 0.18006, 0.22124, 0.0012345, 0.18815, 0.053146, 0.23416, 0.027246]
Predicted label: 2
Correct prediction
Energy consumption = 152.683008 pJ
sum error= 173
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 324 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 324 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 324 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.2498, 0.001215, 0.027874, 0.13055, 0.033981, 0.02504, 0.0038035, 0.0047991, 0.68797, 0.78902]
Predicted label: 9
Correct prediction
Energy consumption = 174.791761 pJ
sum error= 173
Actual label: 9
Output voltages: [0.31364, 0.012346, 0.019497, 0.026159, 0.40456, 0.029128, 0.042764, 0.13612, 0.21144, 0.79856]
Predicted label: 9
Correct prediction
Energy consumption = 153.422496 pJ
sum error= 173
Actual label: 0
Output voltages: [0.79805, 0.013343, 0.45394, 0.0037909, 0.0016563, 0.018648, 0.44227, 0.0091315, 0.29783, 0.0061457]
Predicted label: 0
Correct prediction
Energy consumption = 150.087160 pJ
sum error= 173
Actual label: 0
Output voltages: [0.79879, 0.043781, 0.037141, 0.046723, 0.019152, 0.0075608, 0.46163, 0.023917, 0.51072, 0.022405]
Predicted label: 0
Correct prediction
Energy consumption = 151.820007 pJ
sum error= 173
Actual label: 1
Output voltages: [0.0025882, 0.79853, 0.019876, 0.013079, 0.024507, 0.011721, 0.55023, 0.0094114, 0.35911, 0.018309]
Predicted label: 1
Correct prediction
Energy consumption = 156.278902 pJ
sum error= 173
Actual label: 8
Output voltages: [0.02259, 0.14183, 0.18786, 0.3377, 0.051083, 0.032303, 0.027067, 0.0054304, 0.79879, 0.089426]
Predicted label: 8
Correct prediction
Energy consumption = 150.405238 pJ
sum error= 173
Actual label: 8
Output voltages: [0.33299, 0.029572, 0.054372, 0.73899, 0.0035833, 0.090474, 0.033693, 0.0010913, 0.79868, 0.36668]
Predicted label: 8
Correct prediction
Energy consumption = 147.389587 pJ
sum error= 173
Actual label: 4
Output voltages: [0.056245, 0.001081, 0.23965, 0.015473, 0.79879, 0.0011183, 0.02094, 0.055806, 0.026282, 0.51472]
Predicted label: 4
Correct prediction
Energy consumption = 160.152411 pJ
sum error= 173
Actual label: 3
Output voltages: [0.20762, 0.018327, 0.0436, 0.79861, 0.029326, 0.016984, 0.014638, 0.037576, 0.38749, 0.18199]
Predicted label: 3
Correct prediction
Energy consumption = 147.734085 pJ
sum error= 173
Actual label: 4
Output voltages: [0.0022294, 0.013579, 0.083542, 0.0043661, 0.79867, 0.011312, 0.091106, 0.26247, 0.21539, 0.0030693]
Predicted label: 4
Correct prediction
Energy consumption = 154.842793 pJ
sum error= 173
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 325 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 325 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 325 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.1556, 0.30094, 0.672, 0.048462, 0.34236, 0.0073089, 0.74831, 0.0045368, 0.14397, 0.0016888]
Predicted label: 6
Wrong prediction!
Energy consumption = 166.172065 pJ
sum error= 174
Actual label: 0
Output voltages: [0.79473, 0.0091283, 0.16994, 0.052129, 0.034179, 0.026949, 0.69807, 0.0089413, 0.011414, 0.61175]
Predicted label: 0
Correct prediction
Energy consumption = 147.750933 pJ
sum error= 174
Actual label: 6
Output voltages: [0.029162, 0.20238, 0.42299, 0.01759, 0.079001, 0.1457, 0.79879, 0.0013181, 0.76012, 0.011239]
Predicted label: 6
Correct prediction
Energy consumption = 147.030548 pJ
sum error= 174
Actual label: 1
Output voltages: [0.10196, 0.79852, 0.031181, 0.023179, 0.27305, 0.0075059, 0.42846, 0.0020986, 0.054654, 0.038449]
Predicted label: 1
Correct prediction
Energy consumption = 159.902812 pJ
sum error= 174
Actual label: 6
Output voltages: [0.19866, 0.10353, 0.05819, 0.016322, 0.027435, 0.29443, 0.79788, 0.035836, 0.78313, 0.0092241]
Predicted label: 6
Correct prediction
Energy consumption = 150.987843 pJ
sum error= 174
Actual label: 1
Output voltages: [0.0092906, 0.79846, 0.13718, 0.023931, 0.0431, 0.014822, 0.4847, 0.0019058, 0.15509, 0.050376]
Predicted label: 1
Correct prediction
Energy consumption = 159.554339 pJ
sum error= 174
Actual label: 2
Output voltages: [0.52679, 0.052976, 0.79878, 0.20723, 0.021463, 0.0012334, 0.13457, 0.078545, 0.46327, 0.083558]
Predicted label: 2
Correct prediction
Energy consumption = 147.491359 pJ
sum error= 174
Actual label: 2
Output voltages: [0.13643, 0.19418, 0.79879, 0.044448, 0.024864, 0.0012766, 0.28298, 0.03207, 0.30187, 0.2053]
Predicted label: 2
Correct prediction
Energy consumption = 139.785439 pJ
sum error= 174
Actual label: 2
Output voltages: [0.44733, 0.038347, 0.79878, 0.25808, 0.025194, 0.0012784, 0.24431, 0.029312, 0.62173, 0.017506]
Predicted label: 2
Correct prediction
Energy consumption = 142.417764 pJ
sum error= 174
Actual label: 1
Output voltages: [0.0045895, 0.79873, 0.030507, 0.53414, 0.43105, 0.001524, 0.016949, 0.058352, 0.053239, 0.057208]
Predicted label: 1
Correct prediction
Energy consumption = 158.291791 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 326 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 326 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 326 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.41583, 0.0671, 0.79879, 0.22151, 0.0041708, 0.0012515, 0.03215, 0.36047, 0.51521, 0.091719]
Predicted label: 2
Correct prediction
Energy consumption = 170.310702 pJ
sum error= 174
Actual label: 3
Output voltages: [0.60615, 0.011174, 0.037885, 0.79876, 0.015608, 0.017438, 0.0028981, 0.017179, 0.391, 0.015674]
Predicted label: 3
Correct prediction
Energy consumption = 142.495074 pJ
sum error= 174
Actual label: 7
Output voltages: [0.04023, 0.019975, 0.46221, 0.14908, 0.014735, 0.0010686, 0.0010701, 0.79879, 0.32574, 0.16563]
Predicted label: 7
Correct prediction
Energy consumption = 138.624367 pJ
sum error= 174
Actual label: 8
Output voltages: [0.11219, 0.0015703, 0.11687, 0.014688, 0.036704, 0.0042596, 0.0046076, 0.12227, 0.79878, 0.052578]
Predicted label: 8
Correct prediction
Energy consumption = 149.538477 pJ
sum error= 174
Actual label: 1
Output voltages: [0.0078025, 0.79853, 0.025881, 0.10741, 0.0061891, 0.0011857, 0.75538, 0.0050034, 0.15398, 0.033373]
Predicted label: 1
Correct prediction
Energy consumption = 163.309263 pJ
sum error= 174
Actual label: 0
Output voltages: [0.79879, 0.10017, 0.10083, 0.015826, 0.017788, 0.010296, 0.40936, 0.017877, 0.1258, 0.0274]
Predicted label: 0
Correct prediction
Energy consumption = 155.147547 pJ
sum error= 174
Actual label: 0
Output voltages: [0.79867, 0.026881, 0.0059375, 0.10306, 0.027381, 0.032802, 0.63148, 0.035912, 0.16479, 0.037299]
Predicted label: 0
Correct prediction
Energy consumption = 141.272219 pJ
sum error= 174
Actual label: 2
Output voltages: [0.048132, 0.44755, 0.79879, 0.12451, 0.016402, 0.0014007, 0.055103, 0.17673, 0.036189, 0.083702]
Predicted label: 2
Correct prediction
Energy consumption = 151.258854 pJ
sum error= 174
Actual label: 1
Output voltages: [0.16771, 0.79844, 0.089372, 0.066611, 0.007002, 0.0017598, 0.39781, 0.001623, 0.15319, 0.062106]
Predicted label: 1
Correct prediction
Energy consumption = 155.202819 pJ
sum error= 174
Actual label: 6
Output voltages: [0.73491, 0.15742, 0.056371, 0.01562, 0.031972, 0.36372, 0.79758, 0.0018265, 0.070403, 0.004846]
Predicted label: 6
Correct prediction
Energy consumption = 151.554816 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 327 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 327 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 327 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.36515, 0.056877, 0.10591, 0.012852, 0.10497, 0.13002, 0.79878, 0.0013728, 0.55462, 0.012822]
Predicted label: 6
Correct prediction
Energy consumption = 169.747614 pJ
sum error= 174
Actual label: 0
Output voltages: [0.79853, 0.03807, 0.014497, 0.0033746, 0.042485, 0.0047607, 0.60006, 0.0091987, 0.018826, 0.17046]
Predicted label: 0
Correct prediction
Energy consumption = 153.145935 pJ
sum error= 174
Actual label: 1
Output voltages: [0.0081832, 0.79851, 0.00231, 0.035523, 0.038269, 0.004715, 0.59502, 0.0032021, 0.26789, 0.11624]
Predicted label: 1
Correct prediction
Energy consumption = 156.911008 pJ
sum error= 174
Actual label: 6
Output voltages: [0.20916, 0.0064991, 0.044803, 0.011687, 0.036644, 0.72172, 0.79819, 0.0010672, 0.50979, 0.043259]
Predicted label: 6
Correct prediction
Energy consumption = 147.763153 pJ
sum error= 174
Actual label: 2
Output voltages: [0.61525, 0.19132, 0.79778, 0.045726, 0.01792, 0.0012964, 0.34508, 0.33411, 0.22645, 0.0062571]
Predicted label: 2
Correct prediction
Energy consumption = 152.275906 pJ
sum error= 174
Actual label: 5
Output voltages: [0.079942, 0.0012855, 0.001077, 0.74385, 0.029087, 0.79855, 0.017342, 0.052166, 0.73646, 0.014204]
Predicted label: 5
Correct prediction
Energy consumption = 153.360847 pJ
sum error= 174
Actual label: 1
Output voltages: [0.026246, 0.79836, 0.031004, 0.02981, 0.0068374, 0.0095753, 0.58698, 0.008375, 0.070502, 0.064931]
Predicted label: 1
Correct prediction
Energy consumption = 168.200561 pJ
sum error= 174
Actual label: 7
Output voltages: [0.037219, 0.18654, 0.72136, 0.008622, 0.015961, 0.0010751, 0.0010668, 0.79876, 0.68583, 0.018572]
Predicted label: 7
Correct prediction
Energy consumption = 140.728768 pJ
sum error= 174
Actual label: 4
Output voltages: [0.018233, 0.0066989, 0.22882, 0.0055485, 0.79865, 0.0021383, 0.15739, 0.027234, 0.037739, 0.51691]
Predicted label: 4
Correct prediction
Energy consumption = 161.818384 pJ
sum error= 174
Actual label: 8
Output voltages: [0.027537, 0.03079, 0.046432, 0.30432, 0.0013809, 0.010651, 0.010166, 0.0039133, 0.79879, 0.21967]
Predicted label: 8
Correct prediction
Energy consumption = 148.704111 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 328 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 328 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 328 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.23114, 0.57236, 0.79879, 0.021002, 0.0068287, 0.0013624, 0.046587, 0.39176, 0.15244, 0.012214]
Predicted label: 2
Correct prediction
Energy consumption = 165.018691 pJ
sum error= 174
Actual label: 1
Output voltages: [0.0042497, 0.79857, 0.034928, 0.037217, 0.026057, 0.0031326, 0.69006, 0.035862, 0.38764, 0.01545]
Predicted label: 1
Correct prediction
Energy consumption = 161.889720 pJ
sum error= 174
Actual label: 4
Output voltages: [0.025221, 0.013499, 0.11765, 0.0081772, 0.79864, 0.001066, 0.04933, 0.11812, 0.025953, 0.18257]
Predicted label: 4
Correct prediction
Energy consumption = 154.664560 pJ
sum error= 174
Actual label: 3
Output voltages: [0.49234, 0.01635, 0.045569, 0.79861, 0.011556, 0.056086, 0.015856, 0.034498, 0.61073, 0.036521]
Predicted label: 3
Correct prediction
Energy consumption = 151.307741 pJ
sum error= 174
Actual label: 8
Output voltages: [0.16225, 0.0029389, 0.39579, 0.0081928, 0.015827, 0.0043366, 0.017601, 0.0092087, 0.79874, 0.30703]
Predicted label: 8
Correct prediction
Energy consumption = 151.716004 pJ
sum error= 174
Actual label: 3
Output voltages: [0.64914, 0.017327, 0.14348, 0.7987, 0.0036295, 0.0076249, 0.011454, 0.034179, 0.5763, 0.0035131]
Predicted label: 3
Correct prediction
Energy consumption = 146.505153 pJ
sum error= 174
Actual label: 9
Output voltages: [0.27943, 0.03331, 0.035017, 0.35113, 0.18577, 0.016764, 0.020599, 0.047812, 0.11193, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 154.886796 pJ
sum error= 174
Actual label: 9
Output voltages: [0.73317, 0.0013719, 0.13467, 0.007948, 0.36743, 0.005011, 0.014504, 0.0027978, 0.15423, 0.79862]
Predicted label: 9
Correct prediction
Energy consumption = 141.356983 pJ
sum error= 174
Actual label: 4
Output voltages: [0.48303, 0.0096613, 0.21082, 0.0036213, 0.79827, 0.0010801, 0.38204, 0.0016983, 0.022321, 0.60205]
Predicted label: 4
Correct prediction
Energy consumption = 143.154007 pJ
sum error= 174
Actual label: 8
Output voltages: [0.050393, 0.028132, 0.027058, 0.061417, 0.0070542, 0.022375, 0.0018089, 0.032844, 0.79704, 0.66023]
Predicted label: 8
Correct prediction
Energy consumption = 150.800858 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 329 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 329 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 329 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.017642, 0.0074998, 0.031683, 0.78389, 0.0055308, 0.1064, 0.0040944, 0.10018, 0.79845, 0.50402]
Predicted label: 8
Wrong prediction!
Energy consumption = 158.709198 pJ
sum error= 175
Actual label: 4
Output voltages: [0.0077998, 0.040619, 0.22828, 0.0021866, 0.79867, 0.0094037, 0.18254, 0.026852, 0.045373, 0.38736]
Predicted label: 4
Correct prediction
Energy consumption = 152.961026 pJ
sum error= 175
Actual label: 7
Output voltages: [0.26257, 0.026995, 0.014483, 0.018326, 0.01528, 0.010623, 0.0011077, 0.79874, 0.39857, 0.48909]
Predicted label: 7
Correct prediction
Energy consumption = 157.890175 pJ
sum error= 175
Actual label: 2
Output voltages: [0.26026, 0.039573, 0.79872, 0.056645, 0.021798, 0.0012486, 0.3578, 0.021089, 0.49668, 0.036158]
Predicted label: 2
Correct prediction
Energy consumption = 147.712512 pJ
sum error= 175
Actual label: 7
Output voltages: [0.25748, 0.01829, 0.72772, 0.031567, 0.033675, 0.0013224, 0.016601, 0.7984, 0.045447, 0.031792]
Predicted label: 7
Correct prediction
Energy consumption = 140.990031 pJ
sum error= 175
Actual label: 5
Output voltages: [0.032999, 0.0010675, 0.0079369, 0.30521, 0.014268, 0.79839, 0.040077, 0.048911, 0.75361, 0.29777]
Predicted label: 5
Correct prediction
Energy consumption = 144.044196 pJ
sum error= 175
Actual label: 7
Output voltages: [0.75741, 0.0042457, 0.55584, 0.12226, 0.0051407, 0.0010859, 0.053185, 0.79732, 0.13422, 0.48761]
Predicted label: 7
Correct prediction
Energy consumption = 152.363011 pJ
sum error= 175
Actual label: 0
Output voltages: [0.79861, 0.034775, 0.037769, 0.013156, 0.025697, 0.004682, 0.76347, 0.013321, 0.21872, 0.080318]
Predicted label: 0
Correct prediction
Energy consumption = 145.318794 pJ
sum error= 175
Actual label: 4
Output voltages: [0.013399, 0.0092164, 0.031951, 0.0096487, 0.79858, 0.0029151, 0.12299, 0.010645, 0.15135, 0.025786]
Predicted label: 4
Correct prediction
Energy consumption = 149.998943 pJ
sum error= 175
Actual label: 3
Output voltages: [0.028289, 0.0073141, 0.060403, 0.79874, 0.04995, 0.016124, 0.033325, 0.021042, 0.46706, 0.2032]
Predicted label: 3
Correct prediction
Energy consumption = 150.186635 pJ
sum error= 175
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 330 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 330 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 330 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.060033, 0.012488, 0.21952, 0.79879, 0.064195, 0.035306, 0.28306, 0.010646, 0.34146, 0.011671]
Predicted label: 3
Correct prediction
Energy consumption = 168.974986 pJ
sum error= 175
Actual label: 2
Output voltages: [0.44018, 0.74668, 0.79456, 0.0652, 0.0050457, 0.0012519, 0.18009, 0.019414, 0.21395, 0.01845]
Predicted label: 2
Correct prediction
Energy consumption = 153.931997 pJ
sum error= 175
Actual label: 6
Output voltages: [0.15248, 0.031516, 0.44686, 0.0029933, 0.17863, 0.046906, 0.79878, 0.00875, 0.27926, 0.0036358]
Predicted label: 6
Correct prediction
Energy consumption = 143.863655 pJ
sum error= 175
Actual label: 7
Output voltages: [0.30207, 0.0080313, 0.0084165, 0.01391, 0.024777, 0.0069012, 0.0010683, 0.79877, 0.24605, 0.4175]
Predicted label: 7
Correct prediction
Energy consumption = 160.618894 pJ
sum error= 175
Actual label: 6
Output voltages: [0.069245, 0.14093, 0.20491, 0.018084, 0.1908, 0.29066, 0.79879, 0.0033163, 0.38, 0.0049595]
Predicted label: 6
Correct prediction
Energy consumption = 153.873907 pJ
sum error= 175
Actual label: 0
Output voltages: [0.79867, 0.013389, 0.028692, 0.274, 0.022879, 0.011229, 0.37898, 0.13722, 0.46379, 0.26632]
Predicted label: 0
Correct prediction
Energy consumption = 158.593577 pJ
sum error= 175
Actual label: 0
Output voltages: [0.79866, 0.066063, 0.20578, 0.0068116, 0.022319, 0.0013502, 0.51772, 0.0039744, 0.13978, 0.09552]
Predicted label: 0
Correct prediction
Energy consumption = 144.624170 pJ
sum error= 175
Actual label: 6
Output voltages: [0.041338, 0.02386, 0.16274, 0.010997, 0.081166, 0.076888, 0.79879, 0.0074841, 0.51814, 0.018395]
Predicted label: 6
Correct prediction
Energy consumption = 140.168701 pJ
sum error= 175
Actual label: 7
Output voltages: [0.55345, 0.042192, 0.64656, 0.02419, 0.010875, 0.0010743, 0.0011706, 0.79866, 0.082799, 0.028923]
Predicted label: 7
Correct prediction
Energy consumption = 148.562871 pJ
sum error= 175
Actual label: 7
Output voltages: [0.032193, 0.45162, 0.37784, 0.035184, 0.0027249, 0.0010809, 0.0011027, 0.79867, 0.24572, 0.047689]
Predicted label: 7
Correct prediction
Energy consumption = 140.243029 pJ
sum error= 175
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 331 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 331 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 331 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.19849, 0.03094, 0.01486, 0.0098472, 0.0097249, 0.55057, 0.0048543, 0.075818, 0.045154]
Predicted label: 0
Correct prediction
Energy consumption = 172.482246 pJ
sum error= 175
Actual label: 5
Output voltages: [0.023299, 0.0011686, 0.0010691, 0.34219, 0.35275, 0.79872, 0.035492, 0.0016799, 0.13757, 0.2066]
Predicted label: 5
Correct prediction
Energy consumption = 144.148581 pJ
sum error= 175
Actual label: 5
Output voltages: [0.015416, 0.0010987, 0.015663, 0.48462, 0.023814, 0.79866, 0.14327, 0.11792, 0.70297, 0.30027]
Predicted label: 5
Correct prediction
Energy consumption = 143.587743 pJ
sum error= 175
Actual label: 8
Output voltages: [0.025431, 0.025941, 0.32015, 0.038373, 0.021073, 0.040132, 0.02961, 0.014423, 0.79874, 0.53628]
Predicted label: 8
Correct prediction
Energy consumption = 147.523755 pJ
sum error= 175
Actual label: 1
Output voltages: [0.020027, 0.79868, 0.17856, 0.021596, 0.04413, 0.001174, 0.6087, 0.009992, 0.38265, 0.0076571]
Predicted label: 1
Correct prediction
Energy consumption = 167.783630 pJ
sum error= 175
Actual label: 0
Output voltages: [0.79769, 0.063189, 0.0055683, 0.016471, 0.020217, 0.06223, 0.66554, 0.0089335, 0.41393, 0.013344]
Predicted label: 0
Correct prediction
Energy consumption = 152.534659 pJ
sum error= 175
Actual label: 7
Output voltages: [0.0010984, 0.029211, 0.1105, 0.0065308, 0.43983, 0.0012713, 0.015808, 0.79874, 0.23387, 0.018192]
Predicted label: 7
Correct prediction
Energy consumption = 154.307422 pJ
sum error= 175
Actual label: 0
Output voltages: [0.79879, 0.02058, 0.02239, 0.0070193, 0.16072, 0.014853, 0.77514, 0.033283, 0.10955, 0.024452]
Predicted label: 0
Correct prediction
Energy consumption = 158.874638 pJ
sum error= 175
Actual label: 2
Output voltages: [0.033476, 0.054233, 0.79759, 0.51867, 0.0035312, 0.0012511, 0.23558, 0.036506, 0.70199, 0.016111]
Predicted label: 2
Correct prediction
Energy consumption = 144.974238 pJ
sum error= 175
Actual label: 8
Output voltages: [0.039271, 0.011077, 0.047565, 0.13527, 0.0040473, 0.0085361, 0.021091, 0.015911, 0.79872, 0.38367]
Predicted label: 8
Correct prediction
Energy consumption = 154.698623 pJ
sum error= 175
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 332 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 332 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 332 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0012123, 0.79866, 0.0042978, 0.016862, 0.34125, 0.014289, 0.33564, 0.0053716, 0.50911, 0.13585]
Predicted label: 1
Correct prediction
Energy consumption = 177.053745 pJ
sum error= 175
Actual label: 5
Output voltages: [0.031664, 0.0020796, 0.049583, 0.42647, 0.0075395, 0.72799, 0.013794, 0.0072127, 0.79843, 0.03166]
Predicted label: 8
Wrong prediction!
Energy consumption = 145.945208 pJ
sum error= 176
Actual label: 0
Output voltages: [0.79871, 0.20461, 0.02861, 0.029931, 0.038059, 0.024681, 0.22815, 0.020407, 0.17762, 0.34732]
Predicted label: 0
Correct prediction
Energy consumption = 157.647590 pJ
sum error= 176
Actual label: 8
Output voltages: [0.20477, 0.022315, 0.16887, 0.63036, 0.0063454, 0.048092, 0.029912, 0.0058639, 0.79874, 0.019659]
Predicted label: 8
Correct prediction
Energy consumption = 150.093866 pJ
sum error= 176
Actual label: 8
Output voltages: [0.02681, 0.023977, 0.045581, 0.25521, 0.0010725, 0.062972, 0.0046779, 0.0053642, 0.79878, 0.058453]
Predicted label: 8
Correct prediction
Energy consumption = 146.466601 pJ
sum error= 176
Actual label: 0
Output voltages: [0.79847, 0.040525, 0.021346, 0.0076588, 0.0076123, 0.007408, 0.75171, 0.011997, 0.15139, 0.086201]
Predicted label: 0
Correct prediction
Energy consumption = 159.608498 pJ
sum error= 176
Actual label: 3
Output voltages: [0.72623, 0.020747, 0.026114, 0.79869, 0.0019521, 0.045578, 0.0081675, 0.019526, 0.3606, 0.0089475]
Predicted label: 3
Correct prediction
Energy consumption = 140.683794 pJ
sum error= 176
Actual label: 2
Output voltages: [0.32328, 0.10048, 0.79879, 0.16213, 0.018178, 0.0013009, 0.45437, 0.020049, 0.48585, 0.026547]
Predicted label: 2
Correct prediction
Energy consumption = 146.252629 pJ
sum error= 176
Actual label: 7
Output voltages: [0.32818, 0.034082, 0.7665, 0.0019423, 0.017191, 0.001132, 0.0012043, 0.79879, 0.60389, 0.0028975]
Predicted label: 7
Correct prediction
Energy consumption = 147.463308 pJ
sum error= 176
Actual label: 7
Output voltages: [0.21261, 0.0061051, 0.7291, 0.24731, 0.08797, 0.0013591, 0.0027747, 0.78596, 0.2079, 0.1344]
Predicted label: 7
Correct prediction
Energy consumption = 142.989276 pJ
sum error= 176
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 333 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 333 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 333 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.74422, 0.037491, 0.74221, 0.79378, 0.0010692, 0.015484, 0.020601, 0.0011706, 0.74205, 0.043468]
Predicted label: 3
Wrong prediction!
Energy consumption = 162.972776 pJ
sum error= 177
Actual label: 6
Output voltages: [0.04658, 0.03293, 0.2345, 0.0039186, 0.20455, 0.12292, 0.79876, 0.0013102, 0.63387, 0.045268]
Predicted label: 6
Correct prediction
Energy consumption = 148.250614 pJ
sum error= 177
Actual label: 4
Output voltages: [0.0020053, 0.0058366, 0.13307, 0.018981, 0.79868, 0.0015768, 0.21736, 0.065602, 0.16797, 0.03016]
Predicted label: 4
Correct prediction
Energy consumption = 155.686370 pJ
sum error= 177
Actual label: 7
Output voltages: [0.23887, 0.0038827, 0.09795, 0.6575, 0.71777, 0.0010683, 0.0010778, 0.42291, 0.0059111, 0.71241]
Predicted label: 4
Wrong prediction!
Energy consumption = 144.119377 pJ
sum error= 178
Actual label: 5
Output voltages: [0.030593, 0.0014079, 0.001514, 0.43926, 0.034463, 0.79847, 0.042579, 0.028761, 0.66853, 0.50046]
Predicted label: 5
Correct prediction
Energy consumption = 147.543469 pJ
sum error= 178
Actual label: 5
Output voltages: [0.053845, 0.0030707, 0.0010763, 0.27212, 0.13772, 0.79871, 0.46675, 0.007197, 0.74138, 0.0054789]
Predicted label: 5
Correct prediction
Energy consumption = 132.662938 pJ
sum error= 178
Actual label: 5
Output voltages: [0.062574, 0.0022705, 0.0011014, 0.032129, 0.29532, 0.78406, 0.0042824, 0.75948, 0.4241, 0.44148]
Predicted label: 5
Correct prediction
Energy consumption = 145.902248 pJ
sum error= 178
Actual label: 2
Output voltages: [0.047139, 0.04024, 0.79879, 0.031612, 0.012394, 0.0010783, 0.12701, 0.45107, 0.59145, 0.26418]
Predicted label: 2
Correct prediction
Energy consumption = 149.841018 pJ
sum error= 178
Actual label: 9
Output voltages: [0.067243, 0.013206, 0.018439, 0.10973, 0.1493, 0.077642, 0.038411, 0.023146, 0.42258, 0.79661]
Predicted label: 9
Correct prediction
Energy consumption = 159.959784 pJ
sum error= 178
Actual label: 2
Output voltages: [0.13464, 0.38745, 0.79879, 0.029445, 0.02348, 0.0013721, 0.15479, 0.045335, 0.2671, 0.043358]
Predicted label: 2
Correct prediction
Energy consumption = 151.237116 pJ
sum error= 178
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 334 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 334 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 334 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.096862, 0.086395, 0.016398, 0.33845, 0.0011759, 0.32624, 0.0089411, 0.0033381, 0.79874, 0.35511]
Predicted label: 8
Correct prediction
Energy consumption = 169.983355 pJ
sum error= 178
Actual label: 4
Output voltages: [0.019139, 0.020261, 0.16703, 0.0079732, 0.79868, 0.0032471, 0.036734, 0.022421, 0.037921, 0.0091991]
Predicted label: 4
Correct prediction
Energy consumption = 144.002877 pJ
sum error= 178
Actual label: 6
Output voltages: [0.044698, 0.0050587, 0.35989, 0.01543, 0.036459, 0.10484, 0.79875, 0.0011272, 0.60651, 0.20273]
Predicted label: 6
Correct prediction
Energy consumption = 148.734688 pJ
sum error= 178
Actual label: 8
Output voltages: [0.053803, 0.03112, 0.77486, 0.026652, 0.011875, 0.0012662, 0.039317, 0.005527, 0.79874, 0.26144]
Predicted label: 8
Correct prediction
Energy consumption = 144.714276 pJ
sum error= 178
Actual label: 6
Output voltages: [0.76959, 0.025024, 0.0014294, 0.044569, 0.12486, 0.42926, 0.79326, 0.019664, 0.56294, 0.020867]
Predicted label: 6
Correct prediction
Energy consumption = 153.683570 pJ
sum error= 178
Actual label: 5
Output voltages: [0.061872, 0.0010659, 0.0029434, 0.038039, 0.011565, 0.79873, 0.28161, 0.21131, 0.77653, 0.0065671]
Predicted label: 5
Correct prediction
Energy consumption = 138.298675 pJ
sum error= 178
Actual label: 0
Output voltages: [0.79848, 0.056656, 0.33315, 0.0060705, 0.0073096, 0.0022152, 0.22042, 0.025124, 0.43959, 0.070123]
Predicted label: 0
Correct prediction
Energy consumption = 155.491502 pJ
sum error= 178
Actual label: 0
Output voltages: [0.78596, 0.010298, 0.39471, 0.0018589, 0.014449, 0.018868, 0.73593, 0.014154, 0.74366, 0.011697]
Predicted label: 0
Correct prediction
Energy consumption = 146.604052 pJ
sum error= 178
Actual label: 8
Output voltages: [0.037767, 0.022731, 0.40524, 0.2502, 0.0068809, 0.023617, 0.006857, 0.013558, 0.79861, 0.38418]
Predicted label: 8
Correct prediction
Energy consumption = 146.732172 pJ
sum error= 178
Actual label: 7
Output voltages: [0.020242, 0.0042294, 0.15855, 0.4268, 0.0020802, 0.0017772, 0.0010664, 0.79879, 0.35823, 0.50373]
Predicted label: 7
Correct prediction
Energy consumption = 144.630835 pJ
sum error= 178
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 335 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 335 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 335 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.21419, 0.052425, 0.13757, 0.0039359, 0.40149, 0.43722, 0.79864, 0.0025038, 0.45397, 0.010917]
Predicted label: 6
Correct prediction
Energy consumption = 165.048120 pJ
sum error= 178
Actual label: 1
Output voltages: [0.13812, 0.79878, 0.57763, 0.0079636, 0.39528, 0.0011083, 0.31576, 0.0019063, 0.037036, 0.023007]
Predicted label: 1
Correct prediction
Energy consumption = 153.099231 pJ
sum error= 178
Actual label: 7
Output voltages: [0.2268, 0.0022862, 0.06334, 0.70818, 0.20962, 0.0010661, 0.0010851, 0.76831, 0.67593, 0.13001]
Predicted label: 7
Correct prediction
Energy consumption = 150.284646 pJ
sum error= 178
Actual label: 1
Output voltages: [0.0078073, 0.79861, 0.13034, 0.035902, 0.26014, 0.025461, 0.025558, 0.010845, 0.018986, 0.19477]
Predicted label: 1
Correct prediction
Energy consumption = 162.613008 pJ
sum error= 178
Actual label: 1
Output voltages: [0.0049978, 0.79857, 0.060385, 0.085899, 0.051374, 0.0031784, 0.56925, 0.0041201, 0.26139, 0.033871]
Predicted label: 1
Correct prediction
Energy consumption = 157.032204 pJ
sum error= 178
Actual label: 2
Output voltages: [0.36536, 0.035801, 0.79867, 0.057366, 0.010125, 0.001066, 0.04001, 0.34564, 0.50921, 0.013377]
Predicted label: 2
Correct prediction
Energy consumption = 140.225035 pJ
sum error= 178
Actual label: 7
Output voltages: [0.36322, 0.042679, 0.0011307, 0.40471, 0.023869, 0.019895, 0.001082, 0.79878, 0.29056, 0.62588]
Predicted label: 7
Correct prediction
Energy consumption = 156.988838 pJ
sum error= 178
Actual label: 4
Output voltages: [0.034666, 0.0027182, 0.029456, 0.011991, 0.7985, 0.006421, 0.1013, 0.035066, 0.042916, 0.12819]
Predicted label: 4
Correct prediction
Energy consumption = 151.035935 pJ
sum error= 178
Actual label: 0
Output voltages: [0.79154, 0.063656, 0.019282, 0.012511, 0.0012047, 0.016278, 0.15806, 0.061181, 0.77835, 0.0033599]
Predicted label: 0
Correct prediction
Energy consumption = 160.658829 pJ
sum error= 178
Actual label: 0
Output voltages: [0.79879, 0.013042, 0.021876, 0.0018823, 0.027156, 0.010663, 0.66009, 0.0067578, 0.071658, 0.035129]
Predicted label: 0
Correct prediction
Energy consumption = 147.809679 pJ
sum error= 178
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 336 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 336 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 336 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.041847, 0.039203, 0.059984, 0.045311, 0.013293, 0.0076363, 0.0010688, 0.79854, 0.043634, 0.31032]
Predicted label: 7
Correct prediction
Energy consumption = 169.716853 pJ
sum error= 178
Actual label: 7
Output voltages: [0.75734, 0.010909, 0.55518, 0.042507, 0.0069027, 0.0011067, 0.0010886, 0.79847, 0.23521, 0.013741]
Predicted label: 7
Correct prediction
Energy consumption = 137.075191 pJ
sum error= 178
Actual label: 6
Output voltages: [0.25637, 0.028551, 0.053901, 0.034347, 0.3067, 0.39725, 0.79877, 0.0011396, 0.69213, 0.019381]
Predicted label: 6
Correct prediction
Energy consumption = 151.377953 pJ
sum error= 178
Actual label: 3
Output voltages: [0.28916, 0.01784, 0.036894, 0.79866, 0.010568, 0.017865, 0.024374, 0.017032, 0.34191, 0.03757]
Predicted label: 3
Correct prediction
Energy consumption = 154.618316 pJ
sum error= 178
Actual label: 8
Output voltages: [0.049973, 0.036288, 0.33628, 0.27324, 0.012183, 0.036777, 0.01377, 0.030362, 0.79861, 0.12859]
Predicted label: 8
Correct prediction
Energy consumption = 140.318785 pJ
sum error= 178
Actual label: 6
Output voltages: [0.62633, 0.63558, 0.010728, 0.15939, 0.016691, 0.61636, 0.79876, 0.0039234, 0.18851, 0.0064065]
Predicted label: 6
Correct prediction
Energy consumption = 147.934196 pJ
sum error= 178
Actual label: 4
Output voltages: [0.027023, 0.015148, 0.26594, 0.037661, 0.79872, 0.0011465, 0.29176, 0.011612, 0.013074, 0.0078784]
Predicted label: 4
Correct prediction
Energy consumption = 155.912176 pJ
sum error= 178
Actual label: 2
Output voltages: [0.57099, 0.015623, 0.79879, 0.11511, 0.006738, 0.0011169, 0.061041, 0.029182, 0.72978, 0.018643]
Predicted label: 2
Correct prediction
Energy consumption = 147.713223 pJ
sum error= 178
Actual label: 0
Output voltages: [0.79823, 0.021595, 0.031739, 0.030993, 0.024331, 0.091213, 0.75596, 0.033498, 0.091244, 0.042493]
Predicted label: 0
Correct prediction
Energy consumption = 156.845644 pJ
sum error= 178
Actual label: 9
Output voltages: [0.038647, 0.45227, 0.0011573, 0.040823, 0.023343, 0.0014534, 0.0010709, 0.32918, 0.64982, 0.79181]
Predicted label: 9
Correct prediction
Energy consumption = 156.935613 pJ
sum error= 178
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 337 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 337 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 337 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0052559, 0.015269, 0.2979, 0.011797, 0.79859, 0.0031081, 0.056734, 0.082704, 0.019296, 0.11392]
Predicted label: 4
Correct prediction
Energy consumption = 167.921580 pJ
sum error= 178
Actual label: 0
Output voltages: [0.79876, 0.056601, 0.024379, 0.010289, 0.024826, 0.01897, 0.58046, 0.0081012, 0.059292, 0.03207]
Predicted label: 0
Correct prediction
Energy consumption = 155.723348 pJ
sum error= 178
Actual label: 5
Output voltages: [0.070264, 0.0010986, 0.0010664, 0.25417, 0.19187, 0.79879, 0.18818, 0.040985, 0.73134, 0.054709]
Predicted label: 5
Correct prediction
Energy consumption = 149.429313 pJ
sum error= 178
Actual label: 7
Output voltages: [0.28776, 0.014059, 0.012691, 0.19857, 0.01515, 0.0055541, 0.0010659, 0.79866, 0.19429, 0.72822]
Predicted label: 7
Correct prediction
Energy consumption = 146.097628 pJ
sum error= 178
Actual label: 8
Output voltages: [0.039625, 0.031602, 0.23841, 0.087867, 0.012507, 0.0075863, 0.021059, 0.0019736, 0.79878, 0.33931]
Predicted label: 8
Correct prediction
Energy consumption = 146.873377 pJ
sum error= 178
Actual label: 2
Output voltages: [0.029934, 0.23857, 0.79799, 0.26324, 0.0064601, 0.0011414, 0.12714, 0.001305, 0.46983, 0.1111]
Predicted label: 2
Correct prediction
Energy consumption = 140.974008 pJ
sum error= 178
Actual label: 7
Output voltages: [0.025728, 0.63, 0.038629, 0.0017477, 0.013471, 0.001204, 0.0050551, 0.79877, 0.2158, 0.27088]
Predicted label: 7
Correct prediction
Energy consumption = 162.779045 pJ
sum error= 178
Actual label: 4
Output voltages: [0.0041481, 0.0081453, 0.0072955, 0.026081, 0.79879, 0.021191, 0.28997, 0.026643, 0.038469, 0.027031]
Predicted label: 4
Correct prediction
Energy consumption = 149.027183 pJ
sum error= 178
Actual label: 7
Output voltages: [0.084265, 0.010401, 0.024238, 0.26106, 0.04352, 0.019605, 0.0010664, 0.79864, 0.36545, 0.4962]
Predicted label: 7
Correct prediction
Energy consumption = 149.104649 pJ
sum error= 178
Actual label: 1
Output voltages: [0.017609, 0.79843, 0.02807, 0.36135, 0.0065774, 0.020581, 0.64392, 0.019473, 0.014152, 0.34813]
Predicted label: 1
Correct prediction
Energy consumption = 159.234629 pJ
sum error= 178
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 338 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 338 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 338 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.015791, 0.79861, 0.12653, 0.086026, 0.0089191, 0.0012181, 0.7606, 0.0062752, 0.2796, 0.020354]
Predicted label: 1
Correct prediction
Energy consumption = 181.166155 pJ
sum error= 178
Actual label: 3
Output voltages: [0.042734, 0.15857, 0.30073, 0.79871, 0.019542, 0.0012749, 0.0017276, 0.0089547, 0.53823, 0.066682]
Predicted label: 3
Correct prediction
Energy consumption = 147.540252 pJ
sum error= 178
Actual label: 6
Output voltages: [0.048271, 0.038469, 0.053645, 0.009595, 0.22114, 0.25572, 0.79865, 0.0051588, 0.75552, 0.027573]
Predicted label: 6
Correct prediction
Energy consumption = 153.404074 pJ
sum error= 178
Actual label: 6
Output voltages: [0.051964, 0.038209, 0.034774, 0.037075, 0.042404, 0.44153, 0.79879, 0.011856, 0.7247, 0.017266]
Predicted label: 6
Correct prediction
Energy consumption = 143.966402 pJ
sum error= 178
Actual label: 2
Output voltages: [0.64152, 0.049068, 0.69562, 0.40356, 0.020767, 0.0013229, 0.77538, 0.35181, 0.50892, 0.0010673]
Predicted label: 6
Wrong prediction!
Energy consumption = 147.877368 pJ
sum error= 179
Actual label: 9
Output voltages: [0.37011, 0.0018802, 0.095852, 0.043847, 0.081395, 0.0064094, 0.02227, 0.030382, 0.035917, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 148.768874 pJ
sum error= 179
Actual label: 1
Output voltages: [0.0061301, 0.79856, 0.043204, 0.012747, 0.015511, 0.0041084, 0.63724, 0.0067745, 0.35836, 0.0061189]
Predicted label: 1
Correct prediction
Energy consumption = 160.387798 pJ
sum error= 179
Actual label: 9
Output voltages: [0.26491, 0.032965, 0.037292, 0.11463, 0.094672, 0.019119, 0.0061219, 0.040636, 0.38317, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 154.828926 pJ
sum error= 179
Actual label: 4
Output voltages: [0.027853, 0.0292, 0.031331, 0.038328, 0.79876, 0.0085913, 0.045629, 0.005656, 0.11262, 0.43494]
Predicted label: 4
Correct prediction
Energy consumption = 147.171454 pJ
sum error= 179
Actual label: 8
Output voltages: [0.40429, 0.012224, 0.17677, 0.14176, 0.0074089, 0.040083, 0.0034781, 0.0020806, 0.79876, 0.17231]
Predicted label: 8
Correct prediction
Energy consumption = 145.558110 pJ
sum error= 179
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 339 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 339 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 339 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.43349, 0.02506, 0.048943, 0.79863, 0.0131, 0.02564, 0.02026, 0.01846, 0.5324, 0.23116]
Predicted label: 3
Correct prediction
Energy consumption = 166.576656 pJ
sum error= 179
Actual label: 6
Output voltages: [0.16595, 0.027933, 0.27706, 0.0010684, 0.18262, 0.17952, 0.79877, 0.0039602, 0.72792, 0.0042197]
Predicted label: 6
Correct prediction
Energy consumption = 149.999280 pJ
sum error= 179
Actual label: 9
Output voltages: [0.30912, 0.0080449, 0.019589, 0.0091124, 0.42393, 0.14179, 0.022668, 0.02775, 0.067494, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 148.039279 pJ
sum error= 179
Actual label: 5
Output voltages: [0.040973, 0.0015178, 0.00151, 0.10343, 0.030214, 0.79878, 0.41833, 0.024088, 0.74621, 0.028758]
Predicted label: 5
Correct prediction
Energy consumption = 148.657819 pJ
sum error= 179
Actual label: 9
Output voltages: [0.39317, 0.0010844, 0.43989, 0.023825, 0.46512, 0.031865, 0.0049715, 0.043969, 0.039286, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 152.758719 pJ
sum error= 179
Actual label: 6
Output voltages: [0.12338, 0.042846, 0.16857, 0.0027318, 0.29707, 0.43039, 0.79868, 0.0021713, 0.37974, 0.017663]
Predicted label: 6
Correct prediction
Energy consumption = 151.979102 pJ
sum error= 179
Actual label: 2
Output voltages: [0.46239, 0.30187, 0.79876, 0.028555, 0.027561, 0.0013569, 0.079439, 0.03588, 0.20514, 0.034293]
Predicted label: 2
Correct prediction
Energy consumption = 144.674009 pJ
sum error= 179
Actual label: 4
Output voltages: [0.008188, 0.019302, 0.04365, 0.0027113, 0.79868, 0.0039546, 0.19045, 0.34138, 0.030532, 0.028368]
Predicted label: 4
Correct prediction
Energy consumption = 153.806876 pJ
sum error= 179
Actual label: 6
Output voltages: [0.30401, 0.23262, 0.025232, 0.028647, 0.026552, 0.081129, 0.79878, 0.0034204, 0.63791, 0.01563]
Predicted label: 6
Correct prediction
Energy consumption = 158.070973 pJ
sum error= 179
Actual label: 7
Output voltages: [0.4935, 0.049038, 0.02394, 0.015693, 0.027197, 0.020553, 0.014482, 0.79857, 0.13038, 0.22022]
Predicted label: 7
Correct prediction
Energy consumption = 152.675410 pJ
sum error= 179
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 340 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 340 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 340 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.038535, 0.015273, 0.10439, 0.065438, 0.0090419, 0.0071018, 0.001069, 0.79859, 0.38331, 0.48368]
Predicted label: 7
Correct prediction
Energy consumption = 176.199063 pJ
sum error= 179
Actual label: 0
Output voltages: [0.79879, 0.05043, 0.35628, 0.007085, 0.0056905, 0.0022604, 0.30222, 0.010228, 0.16574, 0.064088]
Predicted label: 0
Correct prediction
Energy consumption = 144.746810 pJ
sum error= 179
Actual label: 6
Output voltages: [0.058349, 0.34252, 0.16225, 0.0031607, 0.039557, 0.20187, 0.79868, 0.0020748, 0.6323, 0.0070773]
Predicted label: 6
Correct prediction
Energy consumption = 142.294467 pJ
sum error= 179
Actual label: 6
Output voltages: [0.19421, 0.018499, 0.30102, 0.0070085, 0.51353, 0.091569, 0.79875, 0.0032749, 0.57771, 0.0072621]
Predicted label: 6
Correct prediction
Energy consumption = 140.046359 pJ
sum error= 179
Actual label: 9
Output voltages: [0.17103, 0.019799, 0.032267, 0.054957, 0.18963, 0.0028633, 0.2822, 0.019418, 0.044003, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.797897 pJ
sum error= 179
Actual label: 4
Output voltages: [0.053179, 0.0011177, 0.045021, 0.0023801, 0.79878, 0.0010989, 0.0023623, 0.12914, 0.027973, 0.42915]
Predicted label: 4
Correct prediction
Energy consumption = 145.057750 pJ
sum error= 179
Actual label: 8
Output voltages: [0.0060267, 0.19964, 0.05218, 0.23052, 0.0021385, 0.019624, 0.0028017, 0.1102, 0.79876, 0.065065]
Predicted label: 8
Correct prediction
Energy consumption = 146.543723 pJ
sum error= 179
Actual label: 3
Output voltages: [0.33413, 0.036312, 0.041691, 0.79864, 0.047064, 0.015124, 0.028766, 0.012389, 0.54095, 0.30711]
Predicted label: 3
Correct prediction
Energy consumption = 149.242808 pJ
sum error= 179
Actual label: 5
Output voltages: [0.045266, 0.0010663, 0.0049977, 0.35798, 0.20817, 0.79871, 0.21416, 0.045334, 0.7725, 0.017901]
Predicted label: 5
Correct prediction
Energy consumption = 144.621877 pJ
sum error= 179
Actual label: 3
Output voltages: [0.48938, 0.0053212, 0.049017, 0.79872, 0.019752, 0.0040337, 0.0078506, 0.0071826, 0.58574, 0.024427]
Predicted label: 3
Correct prediction
Energy consumption = 143.120836 pJ
sum error= 179
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 341 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 341 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 341 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.18234, 0.0065526, 0.24149, 0.0083944, 0.79864, 0.0071748, 0.050851, 0.053914, 0.031409, 0.53771]
Predicted label: 4
Correct prediction
Energy consumption = 176.663430 pJ
sum error= 179
Actual label: 9
Output voltages: [0.26607, 0.0031982, 0.014431, 0.036683, 0.028969, 0.02308, 0.0019596, 0.39396, 0.7337, 0.79085]
Predicted label: 9
Correct prediction
Energy consumption = 151.661448 pJ
sum error= 179
Actual label: 0
Output voltages: [0.78545, 0.17237, 0.15992, 0.0034445, 0.002335, 0.0011526, 0.53108, 0.325, 0.12846, 0.46688]
Predicted label: 0
Correct prediction
Energy consumption = 151.070480 pJ
sum error= 179
Actual label: 0
Output voltages: [0.7987, 0.04511, 0.026609, 0.017648, 0.011497, 0.041605, 0.045071, 0.013731, 0.15542, 0.034039]
Predicted label: 0
Correct prediction
Energy consumption = 147.289800 pJ
sum error= 179
Actual label: 5
Output voltages: [0.044123, 0.0016577, 0.046461, 0.45467, 0.0071024, 0.79167, 0.10213, 0.0083462, 0.79717, 0.052593]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.093352 pJ
sum error= 180
Actual label: 2
Output voltages: [0.33801, 0.041562, 0.79874, 0.46935, 0.010006, 0.0011517, 0.010849, 0.49253, 0.53718, 0.021784]
Predicted label: 2
Correct prediction
Energy consumption = 151.035098 pJ
sum error= 180
Actual label: 5
Output voltages: [0.016577, 0.017832, 0.0035674, 0.50473, 0.03567, 0.79726, 0.18598, 0.018566, 0.42285, 0.42718]
Predicted label: 5
Correct prediction
Energy consumption = 142.967130 pJ
sum error= 180
Actual label: 0
Output voltages: [0.79877, 0.1223, 0.050168, 0.016495, 0.029024, 0.0080457, 0.28499, 0.0041242, 0.11277, 0.42132]
Predicted label: 0
Correct prediction
Energy consumption = 158.187350 pJ
sum error= 180
Actual label: 7
Output voltages: [0.26315, 0.63951, 0.034923, 0.60395, 0.003299, 0.0017997, 0.0010919, 0.79817, 0.090626, 0.47789]
Predicted label: 7
Correct prediction
Energy consumption = 162.407454 pJ
sum error= 180
Actual label: 1
Output voltages: [0.0044597, 0.79855, 0.067733, 0.035249, 0.021583, 0.0034846, 0.62684, 0.0088221, 0.25581, 0.029591]
Predicted label: 1
Correct prediction
Energy consumption = 154.596261 pJ
sum error= 180
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 342 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 342 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 342 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.033816, 0.79856, 0.048026, 0.020747, 0.13528, 0.0026621, 0.57292, 0.0087676, 0.19181, 0.045143]
Predicted label: 1
Correct prediction
Energy consumption = 179.684036 pJ
sum error= 180
Actual label: 1
Output voltages: [0.042172, 0.79852, 0.048198, 0.049781, 0.24975, 0.0063502, 0.36633, 0.0033971, 0.20407, 0.056015]
Predicted label: 1
Correct prediction
Energy consumption = 152.811613 pJ
sum error= 180
Actual label: 6
Output voltages: [0.60803, 0.19536, 0.27479, 0.0038359, 0.032044, 0.026971, 0.79215, 0.0012273, 0.54063, 0.0017512]
Predicted label: 6
Correct prediction
Energy consumption = 151.198597 pJ
sum error= 180
Actual label: 7
Output voltages: [0.10901, 0.037243, 0.036792, 0.10225, 0.019058, 0.013779, 0.0011301, 0.79878, 0.099862, 0.511]
Predicted label: 7
Correct prediction
Energy consumption = 148.388177 pJ
sum error= 180
Actual label: 6
Output voltages: [0.01875, 0.032992, 0.27013, 0.013029, 0.12166, 0.24496, 0.79879, 0.0032976, 0.75133, 0.030259]
Predicted label: 6
Correct prediction
Energy consumption = 155.249337 pJ
sum error= 180
Actual label: 7
Output voltages: [0.62882, 0.0014908, 0.76752, 0.47327, 0.0017692, 0.0010811, 0.0011536, 0.79754, 0.60694, 0.035921]
Predicted label: 7
Correct prediction
Energy consumption = 154.808562 pJ
sum error= 180
Actual label: 9
Output voltages: [0.12369, 0.010244, 0.024197, 0.029361, 0.21277, 0.028245, 0.0026825, 0.019279, 0.57231, 0.7978]
Predicted label: 9
Correct prediction
Energy consumption = 144.763297 pJ
sum error= 180
Actual label: 6
Output voltages: [0.077762, 0.036543, 0.3617, 0.0025875, 0.25896, 0.10443, 0.79878, 0.0019927, 0.50832, 0.0038321]
Predicted label: 6
Correct prediction
Energy consumption = 150.461254 pJ
sum error= 180
Actual label: 6
Output voltages: [0.38227, 0.023458, 0.072787, 0.0021559, 0.36627, 0.23753, 0.79877, 0.011346, 0.72362, 0.0043625]
Predicted label: 6
Correct prediction
Energy consumption = 141.743143 pJ
sum error= 180
Actual label: 4
Output voltages: [0.0028668, 0.0018839, 0.06929, 0.027631, 0.79875, 0.0024885, 0.017144, 0.026533, 0.49534, 0.004817]
Predicted label: 4
Correct prediction
Energy consumption = 146.968251 pJ
sum error= 180
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 343 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 343 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 343 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.072258, 0.79872, 0.028595, 0.016567, 0.013752, 0.001066, 0.024366, 0.14964, 0.41511, 0.10982]
Predicted label: 1
Correct prediction
Energy consumption = 181.160040 pJ
sum error= 180
Actual label: 4
Output voltages: [0.012034, 0.010286, 0.054661, 0.0018757, 0.79868, 0.017542, 0.049957, 0.29062, 0.23418, 0.0035819]
Predicted label: 4
Correct prediction
Energy consumption = 153.379188 pJ
sum error= 180
Actual label: 3
Output voltages: [0.41913, 0.032755, 0.12375, 0.79878, 0.0026349, 0.43766, 0.0034915, 0.052165, 0.67558, 0.0037948]
Predicted label: 3
Correct prediction
Energy consumption = 156.756288 pJ
sum error= 180
Actual label: 1
Output voltages: [0.026535, 0.79858, 0.063593, 0.042496, 0.044433, 0.0030489, 0.74524, 0.0011212, 0.065652, 0.081531]
Predicted label: 1
Correct prediction
Energy consumption = 156.897425 pJ
sum error= 180
Actual label: 1
Output voltages: [0.042208, 0.79846, 0.0018558, 0.089265, 0.035501, 0.0053909, 0.65856, 0.013074, 0.17509, 0.083959]
Predicted label: 1
Correct prediction
Energy consumption = 151.041794 pJ
sum error= 180
Actual label: 2
Output voltages: [0.53428, 0.016518, 0.79869, 0.090727, 0.02279, 0.001115, 0.025619, 0.033483, 0.33184, 0.006011]
Predicted label: 2
Correct prediction
Energy consumption = 149.626300 pJ
sum error= 180
Actual label: 2
Output voltages: [0.40838, 0.55516, 0.79739, 0.042137, 0.0022678, 0.0012979, 0.10243, 0.55352, 0.27176, 0.039259]
Predicted label: 2
Correct prediction
Energy consumption = 138.265864 pJ
sum error= 180
Actual label: 4
Output voltages: [0.015278, 0.0029609, 0.18037, 0.031377, 0.79875, 0.001111, 0.0031971, 0.032981, 0.41948, 0.043748]
Predicted label: 4
Correct prediction
Energy consumption = 161.025366 pJ
sum error= 180
Actual label: 1
Output voltages: [0.014807, 0.79855, 0.32883, 0.017612, 0.014152, 0.0014746, 0.52817, 0.0095032, 0.33507, 0.015538]
Predicted label: 1
Correct prediction
Energy consumption = 161.729161 pJ
sum error= 180
Actual label: 0
Output voltages: [0.79866, 0.057424, 0.11141, 0.038399, 0.082649, 0.0070537, 0.67288, 0.011051, 0.46349, 0.021996]
Predicted label: 0
Correct prediction
Energy consumption = 160.341081 pJ
sum error= 180
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 344 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 344 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 344 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.030741, 0.032277, 0.19998, 0.35817, 0.016761, 0.0065039, 0.022656, 0.0025273, 0.79875, 0.25045]
Predicted label: 8
Correct prediction
Energy consumption = 165.198529 pJ
sum error= 180
Actual label: 7
Output voltages: [0.26143, 0.0071779, 0.72115, 0.0026713, 0.0010692, 0.0021623, 0.001319, 0.79829, 0.75082, 0.043014]
Predicted label: 7
Correct prediction
Energy consumption = 142.021150 pJ
sum error= 180
Actual label: 6
Output voltages: [0.08979, 0.030946, 0.0385, 0.0030881, 0.1673, 0.42458, 0.79878, 0.00331, 0.72076, 0.019481]
Predicted label: 6
Correct prediction
Energy consumption = 154.901941 pJ
sum error= 180
Actual label: 3
Output voltages: [0.5304, 0.038172, 0.17049, 0.79866, 0.01627, 0.013225, 0.035964, 0.036322, 0.44117, 0.026647]
Predicted label: 3
Correct prediction
Energy consumption = 143.765899 pJ
sum error= 180
Actual label: 4
Output voltages: [0.012246, 0.035878, 0.045922, 0.0037448, 0.79879, 0.0012485, 0.27932, 0.071982, 0.03534, 0.017531]
Predicted label: 4
Correct prediction
Energy consumption = 150.576629 pJ
sum error= 180
Actual label: 0
Output voltages: [0.79876, 0.11457, 0.025252, 0.011486, 0.0088337, 0.019692, 0.38539, 0.00801, 0.044142, 0.050616]
Predicted label: 0
Correct prediction
Energy consumption = 159.743729 pJ
sum error= 180
Actual label: 0
Output voltages: [0.79826, 0.024034, 0.37598, 0.032707, 0.045695, 0.00337, 0.28828, 0.0023464, 0.52969, 0.51396]
Predicted label: 0
Correct prediction
Energy consumption = 144.804076 pJ
sum error= 180
Actual label: 6
Output voltages: [0.35903, 0.035957, 0.33492, 0.0010721, 0.73912, 0.019693, 0.79734, 0.0012585, 0.34844, 0.0015827]
Predicted label: 6
Correct prediction
Energy consumption = 142.025955 pJ
sum error= 180
Actual label: 3
Output voltages: [0.77722, 0.001383, 0.35555, 0.79879, 0.024292, 0.0062237, 0.020156, 0.013564, 0.32257, 0.012231]
Predicted label: 3
Correct prediction
Energy consumption = 142.341941 pJ
sum error= 180
Actual label: 3
Output voltages: [0.24851, 0.038051, 0.043912, 0.79869, 0.0085829, 0.012755, 0.019716, 0.016055, 0.3902, 0.063632]
Predicted label: 3
Correct prediction
Energy consumption = 134.294096 pJ
sum error= 180
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 345 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 345 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 345 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79841, 0.049258, 0.028242, 0.058378, 0.0042545, 0.011464, 0.58481, 0.15681, 0.48637, 0.11974]
Predicted label: 0
Correct prediction
Energy consumption = 171.599790 pJ
sum error= 180
Actual label: 7
Output voltages: [0.27801, 0.0016886, 0.029464, 0.48446, 0.010895, 0.23889, 0.0011975, 0.68659, 0.23544, 0.75503]
Predicted label: 9
Wrong prediction!
Energy consumption = 158.108070 pJ
sum error= 181
Actual label: 1
Output voltages: [0.35244, 0.79879, 0.70977, 0.051769, 0.23142, 0.0012438, 0.085063, 0.035359, 0.0044482, 0.047626]
Predicted label: 1
Correct prediction
Energy consumption = 167.739603 pJ
sum error= 181
Actual label: 7
Output voltages: [0.2824, 0.23738, 0.50685, 0.44926, 0.0010743, 0.0011174, 0.0048969, 0.79594, 0.75526, 0.43964]
Predicted label: 7
Correct prediction
Energy consumption = 157.680484 pJ
sum error= 181
Actual label: 1
Output voltages: [0.038273, 0.79849, 0.11563, 0.16484, 0.051278, 0.0017755, 0.46575, 0.0025971, 0.14497, 0.069416]
Predicted label: 1
Correct prediction
Energy consumption = 162.426107 pJ
sum error= 181
Actual label: 1
Output voltages: [0.11436, 0.79839, 0.030418, 0.14519, 0.00303, 0.0031738, 0.49569, 0.0061438, 0.31089, 0.053394]
Predicted label: 1
Correct prediction
Energy consumption = 149.487549 pJ
sum error= 181
Actual label: 3
Output voltages: [0.042973, 0.0027806, 0.014328, 0.7978, 0.13467, 0.5349, 0.021567, 0.031482, 0.79352, 0.10314]
Predicted label: 3
Correct prediction
Energy consumption = 144.340534 pJ
sum error= 181
Actual label: 1
Output voltages: [0.081586, 0.79869, 0.024087, 0.27821, 0.002003, 0.0034352, 0.76305, 0.0013522, 0.2264, 0.0097667]
Predicted label: 1
Correct prediction
Energy consumption = 159.617987 pJ
sum error= 181
Actual label: 0
Output voltages: [0.79864, 0.12668, 0.054419, 0.023748, 0.001602, 0.0093859, 0.70473, 0.01715, 0.064328, 0.047699]
Predicted label: 0
Correct prediction
Energy consumption = 151.588155 pJ
sum error= 181
Actual label: 9
Output voltages: [0.61774, 0.0010964, 0.078708, 0.0022766, 0.34449, 0.0056782, 0.0021244, 0.070177, 0.031558, 0.79583]
Predicted label: 9
Correct prediction
Energy consumption = 149.718390 pJ
sum error= 181
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 346 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 346 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 346 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.19705, 0.0071396, 0.04499, 0.03257, 0.28741, 0.001315, 0.4001, 0.0016559, 0.13764, 0.78588]
Predicted label: 9
Correct prediction
Energy consumption = 169.784481 pJ
sum error= 181
Actual label: 7
Output voltages: [0.29362, 0.030207, 0.57747, 0.14065, 0.0024394, 0.00118, 0.0011468, 0.79876, 0.73291, 0.24524]
Predicted label: 7
Correct prediction
Energy consumption = 148.305894 pJ
sum error= 181
Actual label: 5
Output voltages: [0.034253, 0.0038084, 0.0098396, 0.21815, 0.013869, 0.79859, 0.15599, 0.013894, 0.76446, 0.029056]
Predicted label: 5
Correct prediction
Energy consumption = 142.743434 pJ
sum error= 181
Actual label: 4
Output voltages: [0.0048538, 0.0035183, 0.074892, 0.018933, 0.79861, 0.0011285, 0.01527, 0.037792, 0.080275, 0.022496]
Predicted label: 4
Correct prediction
Energy consumption = 153.644094 pJ
sum error= 181
Actual label: 1
Output voltages: [0.43414, 0.79597, 0.69903, 0.20835, 0.25789, 0.0011593, 0.02515, 0.0011978, 0.057408, 0.054646]
Predicted label: 1
Correct prediction
Energy consumption = 159.726556 pJ
sum error= 181
Actual label: 4
Output voltages: [0.040778, 0.024596, 0.18322, 0.048887, 0.79872, 0.012283, 0.047368, 0.036201, 0.016875, 0.33585]
Predicted label: 4
Correct prediction
Energy consumption = 152.225257 pJ
sum error= 181
Actual label: 8
Output voltages: [0.012672, 0.0070195, 0.015943, 0.20295, 0.004048, 0.030407, 0.056733, 0.0018108, 0.79879, 0.31473]
Predicted label: 8
Correct prediction
Energy consumption = 149.912300 pJ
sum error= 181
Actual label: 9
Output voltages: [0.043779, 0.033605, 0.020274, 0.022609, 0.015645, 0.0012547, 0.001261, 0.02071, 0.67002, 0.79848]
Predicted label: 9
Correct prediction
Energy consumption = 147.314885 pJ
sum error= 181
Actual label: 5
Output voltages: [0.021281, 0.0010861, 0.0036345, 0.21101, 0.036142, 0.78722, 0.37432, 0.0059649, 0.77246, 0.18114]
Predicted label: 5
Correct prediction
Energy consumption = 146.926528 pJ
sum error= 181
Actual label: 3
Output voltages: [0.091714, 0.025613, 0.064187, 0.79869, 0.023075, 0.0033776, 0.0099985, 0.018632, 0.43176, 0.12703]
Predicted label: 3
Correct prediction
Energy consumption = 142.023399 pJ
sum error= 181
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 347 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 347 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 347 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.053676, 0.0010959, 0.012494, 0.19276, 0.026273, 0.79879, 0.29939, 0.018503, 0.75896, 0.030572]
Predicted label: 5
Correct prediction
Energy consumption = 169.869433 pJ
sum error= 181
Actual label: 1
Output voltages: [0.17515, 0.79878, 0.0021695, 0.073631, 0.74627, 0.0018097, 0.024316, 0.0014123, 0.20701, 0.33899]
Predicted label: 1
Correct prediction
Energy consumption = 171.405259 pJ
sum error= 181
Actual label: 9
Output voltages: [0.37127, 0.0022827, 0.021305, 0.0062141, 0.36646, 0.083626, 0.023085, 0.034961, 0.28119, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.072858 pJ
sum error= 181
Actual label: 8
Output voltages: [0.44197, 0.019277, 0.42594, 0.2718, 0.0021781, 0.0097118, 0.0040697, 0.0043244, 0.79879, 0.6366]
Predicted label: 8
Correct prediction
Energy consumption = 147.227055 pJ
sum error= 181
Actual label: 2
Output voltages: [0.37487, 0.74796, 0.79868, 0.077911, 0.05986, 0.0014643, 0.13225, 0.023846, 0.024678, 0.016224]
Predicted label: 2
Correct prediction
Energy consumption = 151.313537 pJ
sum error= 181
Actual label: 3
Output voltages: [0.33406, 0.030009, 0.12247, 0.79875, 0.0010688, 0.014463, 0.0010752, 0.65488, 0.44093, 0.34441]
Predicted label: 3
Correct prediction
Energy consumption = 142.361882 pJ
sum error= 181
Actual label: 3
Output voltages: [0.054687, 0.062539, 0.11543, 0.79878, 0.002844, 0.0043814, 0.0051286, 0.0073355, 0.48242, 0.035947]
Predicted label: 3
Correct prediction
Energy consumption = 136.962416 pJ
sum error= 181
Actual label: 9
Output voltages: [0.33046, 0.02489, 0.026812, 0.038568, 0.21539, 0.032958, 0.0033412, 0.015191, 0.50424, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 140.544675 pJ
sum error= 181
Actual label: 9
Output voltages: [0.049807, 0.011716, 0.046249, 0.043091, 0.017626, 0.027653, 0.015425, 0.046517, 0.54267, 0.79761]
Predicted label: 9
Correct prediction
Energy consumption = 146.002504 pJ
sum error= 181
Actual label: 0
Output voltages: [0.79876, 0.34889, 0.068834, 0.0080885, 0.010378, 0.0050316, 0.28342, 0.0054748, 0.047527, 0.21257]
Predicted label: 0
Correct prediction
Energy consumption = 145.688416 pJ
sum error= 181
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 348 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 348 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 348 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0052451, 0.79868, 0.22343, 0.23315, 0.20262, 0.0012118, 0.66422, 0.00381, 0.16847, 0.024067]
Predicted label: 1
Correct prediction
Energy consumption = 182.844710 pJ
sum error= 181
Actual label: 0
Output voltages: [0.79878, 0.051436, 0.024404, 0.013547, 0.074784, 0.0060271, 0.76742, 0.0097907, 0.14062, 0.1333]
Predicted label: 0
Correct prediction
Energy consumption = 157.004293 pJ
sum error= 181
Actual label: 2
Output voltages: [0.38324, 0.57294, 0.79877, 0.057939, 0.014736, 0.0012704, 0.076316, 0.038014, 0.056813, 0.023658]
Predicted label: 2
Correct prediction
Energy consumption = 150.151375 pJ
sum error= 181
Actual label: 9
Output voltages: [0.44916, 0.0020334, 0.078063, 0.16261, 0.24167, 0.0071395, 0.016787, 0.11022, 0.086752, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 147.829488 pJ
sum error= 181
Actual label: 3
Output voltages: [0.13807, 0.0079058, 0.10097, 0.79876, 0.027708, 0.0021137, 0.0039671, 0.008573, 0.75613, 0.015582]
Predicted label: 3
Correct prediction
Energy consumption = 140.865378 pJ
sum error= 181
Actual label: 9
Output voltages: [0.36013, 0.0011153, 0.034205, 0.013934, 0.45857, 0.012572, 0.0056097, 0.050025, 0.45023, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 152.707599 pJ
sum error= 181
Actual label: 3
Output voltages: [0.59196, 0.014306, 0.011503, 0.79861, 0.020017, 0.046916, 0.022546, 0.024794, 0.6187, 0.060965]
Predicted label: 3
Correct prediction
Energy consumption = 145.472097 pJ
sum error= 181
Actual label: 3
Output voltages: [0.51147, 0.046327, 0.0503, 0.79867, 0.016093, 0.005917, 0.02054, 0.010603, 0.55524, 0.10177]
Predicted label: 3
Correct prediction
Energy consumption = 135.508714 pJ
sum error= 181
Actual label: 6
Output voltages: [0.048902, 0.0021299, 0.17032, 0.0010662, 0.35322, 0.17712, 0.79849, 0.0010662, 0.73727, 0.0062231]
Predicted label: 6
Correct prediction
Energy consumption = 145.915254 pJ
sum error= 181
Actual label: 2
Output voltages: [0.13321, 0.11607, 0.79878, 0.025387, 0.01035, 0.0012725, 0.15039, 0.011522, 0.57267, 0.031349]
Predicted label: 2
Correct prediction
Energy consumption = 143.232247 pJ
sum error= 181
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 349 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 349 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 349 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0018837, 0.047107, 0.13044, 0.0078382, 0.79879, 0.042863, 0.1222, 0.2914, 0.10913, 0.19474]
Predicted label: 4
Correct prediction
Energy consumption = 177.471271 pJ
sum error= 181
Actual label: 9
Output voltages: [0.56562, 0.018852, 0.021121, 0.070959, 0.22346, 0.074497, 0.016531, 0.028697, 0.020195, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 152.926562 pJ
sum error= 181
Actual label: 8
Output voltages: [0.62698, 0.020907, 0.086537, 0.45554, 0.0035349, 0.015303, 0.076124, 0.001067, 0.79507, 0.53583]
Predicted label: 8
Correct prediction
Energy consumption = 161.532448 pJ
sum error= 181
Actual label: 3
Output voltages: [0.27486, 0.016299, 0.03761, 0.79872, 0.022217, 0.0036294, 0.019304, 0.011778, 0.60444, 0.036898]
Predicted label: 3
Correct prediction
Energy consumption = 139.813017 pJ
sum error= 181
Actual label: 7
Output voltages: [0.06636, 0.094955, 0.77642, 0.2229, 0.0016222, 0.0010721, 0.0050072, 0.79867, 0.30746, 0.42291]
Predicted label: 7
Correct prediction
Energy consumption = 152.543331 pJ
sum error= 181
Actual label: 4
Output voltages: [0.0048886, 0.01116, 0.25157, 0.012226, 0.79857, 0.0024518, 0.046308, 0.020899, 0.039189, 0.049138]
Predicted label: 4
Correct prediction
Energy consumption = 160.631674 pJ
sum error= 181
Actual label: 0
Output voltages: [0.79877, 0.040472, 0.020856, 0.026442, 0.02233, 0.0098274, 0.71879, 0.014023, 0.11449, 0.34555]
Predicted label: 0
Correct prediction
Energy consumption = 158.450732 pJ
sum error= 181
Actual label: 4
Output voltages: [0.017922, 0.0070467, 0.039607, 0.010644, 0.79853, 0.0017454, 0.14002, 0.03569, 0.056762, 0.038629]
Predicted label: 4
Correct prediction
Energy consumption = 157.502329 pJ
sum error= 181
Actual label: 7
Output voltages: [0.41925, 0.037116, 0.073305, 0.0046098, 0.0023111, 0.0091106, 0.0058266, 0.79877, 0.065183, 0.68636]
Predicted label: 7
Correct prediction
Energy consumption = 162.757983 pJ
sum error= 181
Actual label: 8
Output voltages: [0.041773, 0.2114, 0.11568, 0.026204, 0.0418, 0.0065749, 0.10231, 0.018981, 0.79869, 0.29985]
Predicted label: 8
Correct prediction
Energy consumption = 150.497131 pJ
sum error= 181
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 350 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 350 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 350 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.016747, 0.0048215, 0.16152, 0.0054521, 0.79868, 0.011125, 0.041242, 0.022375, 0.13954, 0.051825]
Predicted label: 4
Correct prediction
Energy consumption = 174.120419 pJ
sum error= 181
Actual label: 9
Output voltages: [0.60642, 0.0040308, 0.013647, 0.0077385, 0.29668, 0.027081, 0.0057451, 0.26607, 0.15645, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.498744 pJ
sum error= 181
Actual label: 8
Output voltages: [0.0026368, 0.043085, 0.031731, 0.17552, 0.012578, 0.028412, 0.024967, 0.0040046, 0.79879, 0.406]
Predicted label: 8
Correct prediction
Energy consumption = 150.858049 pJ
sum error= 181
Actual label: 9
Output voltages: [0.0017519, 0.64586, 0.049819, 0.0011463, 0.59543, 0.0018535, 0.030922, 0.0032005, 0.33524, 0.48377]
Predicted label: 1
Wrong prediction!
Energy consumption = 153.887247 pJ
sum error= 182
Actual label: 9
Output voltages: [0.13917, 0.031884, 0.0033993, 0.39777, 0.24816, 0.0012033, 0.0020351, 0.0011751, 0.30878, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 145.700768 pJ
sum error= 182
Actual label: 7
Output voltages: [0.12246, 0.2928, 0.3496, 0.51941, 0.0010697, 0.0021131, 0.0010663, 0.79878, 0.44126, 0.76937]
Predicted label: 7
Correct prediction
Energy consumption = 154.396017 pJ
sum error= 182
Actual label: 5
Output voltages: [0.054648, 0.0010675, 0.0010948, 0.20429, 0.22532, 0.79879, 0.56653, 0.015485, 0.72561, 0.037914]
Predicted label: 5
Correct prediction
Energy consumption = 146.994025 pJ
sum error= 182
Actual label: 9
Output voltages: [0.30824, 0.017295, 0.011686, 0.030968, 0.027778, 0.038916, 0.02859, 0.04211, 0.29942, 0.79692]
Predicted label: 9
Correct prediction
Energy consumption = 146.339511 pJ
sum error= 182
Actual label: 2
Output voltages: [0.48482, 0.16528, 0.79873, 0.13197, 0.019406, 0.0012551, 0.3616, 0.03598, 0.51229, 0.034648]
Predicted label: 2
Correct prediction
Energy consumption = 153.793618 pJ
sum error= 182
Actual label: 8
Output voltages: [0.032639, 0.023353, 0.22281, 0.10578, 0.0013055, 0.047212, 0.040942, 0.017792, 0.79879, 0.23321]
Predicted label: 8
Correct prediction
Energy consumption = 147.019170 pJ
sum error= 182
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 351 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 351 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 351 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.32375, 0.18374, 0.79879, 0.13064, 0.014035, 0.0013469, 0.34044, 0.015895, 0.39096, 0.03819]
Predicted label: 2
Correct prediction
Energy consumption = 169.468575 pJ
sum error= 182
Actual label: 2
Output voltages: [0.69974, 0.038119, 0.79773, 0.41403, 0.0013021, 0.0011576, 0.0099383, 0.33313, 0.45142, 0.027891]
Predicted label: 2
Correct prediction
Energy consumption = 140.669415 pJ
sum error= 182
Actual label: 0
Output voltages: [0.79857, 0.067146, 0.014024, 0.018069, 0.033487, 0.0033653, 0.4265, 0.028015, 0.42524, 0.42369]
Predicted label: 0
Correct prediction
Energy consumption = 157.286892 pJ
sum error= 182
Actual label: 2
Output voltages: [0.27352, 0.030637, 0.79875, 0.092513, 0.0063197, 0.0011604, 0.044651, 0.29174, 0.56701, 0.035911]
Predicted label: 2
Correct prediction
Energy consumption = 146.893458 pJ
sum error= 182
Actual label: 2
Output voltages: [0.28591, 0.12546, 0.79876, 0.16259, 0.011632, 0.0012015, 0.28814, 0.023349, 0.7239, 0.026834]
Predicted label: 2
Correct prediction
Energy consumption = 138.948974 pJ
sum error= 182
Actual label: 3
Output voltages: [0.25306, 0.0043069, 0.052975, 0.79871, 0.028702, 0.023634, 0.020062, 0.0063531, 0.43519, 0.058414]
Predicted label: 3
Correct prediction
Energy consumption = 149.970260 pJ
sum error= 182
Actual label: 8
Output voltages: [0.047005, 0.019784, 0.021112, 0.7426, 0.0012741, 0.016947, 0.05015, 0.001767, 0.79837, 0.23688]
Predicted label: 8
Correct prediction
Energy consumption = 145.807308 pJ
sum error= 182
Actual label: 4
Output voltages: [0.014589, 0.13364, 0.10295, 0.0028265, 0.79872, 0.27957, 0.2368, 0.033079, 0.049323, 0.25402]
Predicted label: 4
Correct prediction
Energy consumption = 155.408966 pJ
sum error= 182
Actual label: 6
Output voltages: [0.14436, 0.12899, 0.16482, 0.0062015, 0.17701, 0.39442, 0.79869, 0.0021964, 0.39331, 0.043025]
Predicted label: 6
Correct prediction
Energy consumption = 151.132001 pJ
sum error= 182
Actual label: 8
Output voltages: [0.05192, 0.020257, 0.03489, 0.55345, 0.0036409, 0.058791, 0.19214, 0.0062164, 0.79878, 0.16942]
Predicted label: 8
Correct prediction
Energy consumption = 148.975864 pJ
sum error= 182
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 352 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 352 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 352 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.010552, 0.012398, 0.031255, 0.0017614, 0.78305, 0.063397, 0.73806, 0.048087, 0.53598, 0.20882]
Predicted label: 4
Wrong prediction!
Energy consumption = 153.383214 pJ
sum error= 183
Actual label: 8
Output voltages: [0.18091, 0.010878, 0.093732, 0.18524, 0.0057915, 0.40044, 0.01193, 0.0014807, 0.79876, 0.36681]
Predicted label: 8
Correct prediction
Energy consumption = 148.451892 pJ
sum error= 183
Actual label: 2
Output voltages: [0.30154, 0.5217, 0.79879, 0.060747, 0.016738, 0.0012118, 0.21098, 0.0043474, 0.42785, 0.12924]
Predicted label: 2
Correct prediction
Energy consumption = 154.119517 pJ
sum error= 183
Actual label: 4
Output voltages: [0.061639, 0.030313, 0.05654, 0.010721, 0.79875, 0.0010682, 0.066252, 0.13149, 0.010852, 0.073607]
Predicted label: 4
Correct prediction
Energy consumption = 164.014169 pJ
sum error= 183
Actual label: 6
Output voltages: [0.027706, 0.017873, 0.12722, 0.012413, 0.18135, 0.074506, 0.79879, 0.004075, 0.60608, 0.013907]
Predicted label: 6
Correct prediction
Energy consumption = 144.180897 pJ
sum error= 183
Actual label: 7
Output voltages: [0.17693, 0.0025159, 0.76927, 0.028992, 0.0047182, 0.0010927, 0.001067, 0.79879, 0.76808, 0.061325]
Predicted label: 7
Correct prediction
Energy consumption = 141.418325 pJ
sum error= 183
Actual label: 9
Output voltages: [0.28184, 0.012086, 0.022728, 0.05968, 0.49492, 0.018864, 0.037425, 0.0023511, 0.19497, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 152.298629 pJ
sum error= 183
Actual label: 3
Output voltages: [0.19777, 0.013332, 0.068717, 0.79875, 0.024904, 0.0092436, 0.26451, 0.013063, 0.31548, 0.016582]
Predicted label: 3
Correct prediction
Energy consumption = 148.678151 pJ
sum error= 183
Actual label: 3
Output voltages: [0.28511, 0.0064501, 0.05096, 0.79866, 0.043331, 0.027331, 0.034196, 0.013238, 0.50101, 0.11472]
Predicted label: 3
Correct prediction
Energy consumption = 137.747291 pJ
sum error= 183
Actual label: 9
Output voltages: [0.23084, 0.0010668, 0.015598, 0.020094, 0.24567, 0.028326, 0.0048625, 0.702, 0.41529, 0.7953]
Predicted label: 9
Correct prediction
Energy consumption = 154.880581 pJ
sum error= 183
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 353 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 353 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 353 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.04517, 0.037673, 0.046647, 0.0034809, 0.79879, 0.0049505, 0.48137, 0.0062685, 0.0069658, 0.27023]
Predicted label: 4
Correct prediction
Energy consumption = 180.300665 pJ
sum error= 183
Actual label: 3
Output voltages: [0.20383, 0.040831, 0.018185, 0.79871, 0.0076065, 0.02715, 0.017259, 0.0036595, 0.66421, 0.042103]
Predicted label: 3
Correct prediction
Energy consumption = 147.487080 pJ
sum error= 183
Actual label: 1
Output voltages: [0.024085, 0.79868, 0.076972, 0.77946, 0.0011203, 0.13244, 0.17196, 0.17593, 0.025359, 0.013547]
Predicted label: 1
Correct prediction
Energy consumption = 163.071464 pJ
sum error= 183
Actual label: 4
Output voltages: [0.15731, 0.0013569, 0.41677, 0.15016, 0.79837, 0.0095041, 0.011751, 0.099732, 0.013401, 0.31422]
Predicted label: 4
Correct prediction
Energy consumption = 149.694387 pJ
sum error= 183
Actual label: 4
Output voltages: [0.035423, 0.032421, 0.050953, 0.0011554, 0.79879, 0.024699, 0.55497, 0.03715, 0.5348, 0.0063741]
Predicted label: 4
Correct prediction
Energy consumption = 146.102174 pJ
sum error= 183
Actual label: 7
Output voltages: [0.42634, 0.035356, 0.0014097, 0.0050187, 0.044606, 0.20686, 0.0010707, 0.7987, 0.14639, 0.13986]
Predicted label: 7
Correct prediction
Energy consumption = 154.500908 pJ
sum error= 183
Actual label: 0
Output voltages: [0.79877, 0.25559, 0.023579, 0.065697, 0.010633, 0.0021696, 0.76136, 0.0063422, 0.15048, 0.25276]
Predicted label: 0
Correct prediction
Energy consumption = 155.480514 pJ
sum error= 183
Actual label: 5
Output voltages: [0.030031, 0.0015256, 0.01077, 0.45055, 0.0056373, 0.78996, 0.013289, 0.0025653, 0.79155, 0.013174]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.781322 pJ
sum error= 184
Actual label: 9
Output voltages: [0.5528, 0.0065841, 0.092968, 0.013582, 0.061055, 0.0083914, 0.0019002, 0.034495, 0.49909, 0.79703]
Predicted label: 9
Correct prediction
Energy consumption = 155.454001 pJ
sum error= 184
Actual label: 6
Output voltages: [0.337, 0.040808, 0.30375, 0.0039489, 0.30521, 0.054064, 0.79873, 0.0010909, 0.49336, 0.060003]
Predicted label: 6
Correct prediction
Energy consumption = 148.849154 pJ
sum error= 184
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 354 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 354 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 354 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79849, 0.0067793, 0.045825, 0.010164, 0.0064663, 0.006201, 0.37111, 0.0098444, 0.11531, 0.27964]
Predicted label: 0
Correct prediction
Energy consumption = 156.929985 pJ
sum error= 184
Actual label: 4
Output voltages: [0.0087367, 0.0019681, 0.27823, 0.0084894, 0.79864, 0.012152, 0.053398, 0.07269, 0.047915, 0.041089]
Predicted label: 4
Correct prediction
Energy consumption = 153.226151 pJ
sum error= 184
Actual label: 4
Output voltages: [0.0071582, 0.025789, 0.50704, 0.0016388, 0.79868, 0.0055988, 0.23299, 0.0055696, 0.056027, 0.24483]
Predicted label: 4
Correct prediction
Energy consumption = 142.685268 pJ
sum error= 184
Actual label: 4
Output voltages: [0.0087162, 0.010845, 0.081107, 0.0062172, 0.79871, 0.20353, 0.41387, 0.04411, 0.049482, 0.01504]
Predicted label: 4
Correct prediction
Energy consumption = 136.437673 pJ
sum error= 184
Actual label: 4
Output voltages: [0.0042573, 0.023417, 0.14599, 0.0076574, 0.79879, 0.0013484, 0.10274, 0.14237, 0.036442, 0.018375]
Predicted label: 4
Correct prediction
Energy consumption = 141.639053 pJ
sum error= 184
Actual label: 6
Output voltages: [0.053917, 0.14718, 0.33806, 0.0032883, 0.1822, 0.27147, 0.79869, 0.0021723, 0.25323, 0.032712]
Predicted label: 6
Correct prediction
Energy consumption = 150.630079 pJ
sum error= 184
Actual label: 1
Output voltages: [0.023955, 0.79835, 0.1613, 0.06175, 0.019864, 0.0053068, 0.46773, 0.003277, 0.16081, 0.17925]
Predicted label: 1
Correct prediction
Energy consumption = 162.675410 pJ
sum error= 184
Actual label: 2
Output voltages: [0.57418, 0.0030478, 0.79878, 0.50311, 0.0014748, 0.0010664, 0.051983, 0.13511, 0.61927, 0.0068582]
Predicted label: 2
Correct prediction
Energy consumption = 145.028689 pJ
sum error= 184
Actual label: 3
Output voltages: [0.45601, 0.011313, 0.098075, 0.79864, 0.020035, 0.019415, 0.0095233, 0.012806, 0.58939, 0.027548]
Predicted label: 3
Correct prediction
Energy consumption = 141.601436 pJ
sum error= 184
Actual label: 3
Output voltages: [0.51189, 0.0012833, 0.70754, 0.68945, 0.0028455, 0.001099, 0.017257, 0.046033, 0.78746, 0.0027969]
Predicted label: 8
Wrong prediction!
Energy consumption = 135.651689 pJ
sum error= 185
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 355 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 355 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 355 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.23166, 0.052837, 0.0088341, 0.32304, 0.02794, 0.77713, 0.79879, 0.0021839, 0.49379, 0.030952]
Predicted label: 6
Correct prediction
Energy consumption = 167.958610 pJ
sum error= 185
Actual label: 4
Output voltages: [0.0033093, 0.0045737, 0.12759, 0.076495, 0.79872, 0.001066, 0.033429, 0.031908, 0.03303, 0.022853]
Predicted label: 4
Correct prediction
Energy consumption = 154.521980 pJ
sum error= 185
Actual label: 5
Output voltages: [0.33153, 0.0011648, 0.0011647, 0.5641, 0.05179, 0.79879, 0.082481, 0.030739, 0.68106, 0.039721]
Predicted label: 5
Correct prediction
Energy consumption = 148.838583 pJ
sum error= 185
Actual label: 9
Output voltages: [0.34459, 0.019311, 0.011306, 0.122, 0.070649, 0.007334, 0.017885, 0.02268, 0.25317, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.238235 pJ
sum error= 185
Actual label: 6
Output voltages: [0.060684, 0.028904, 0.064601, 0.0078626, 0.51803, 0.25944, 0.79877, 0.0023908, 0.6566, 0.0036692]
Predicted label: 6
Correct prediction
Energy consumption = 155.202974 pJ
sum error= 185
Actual label: 8
Output voltages: [0.1866, 0.049945, 0.35305, 0.61974, 0.0017986, 0.050696, 0.027327, 0.0035796, 0.79875, 0.06368]
Predicted label: 8
Correct prediction
Energy consumption = 153.076228 pJ
sum error= 185
Actual label: 5
Output voltages: [0.1951, 0.0011728, 0.0010677, 0.038752, 0.022057, 0.79867, 0.35957, 0.052255, 0.77867, 0.0068526]
Predicted label: 5
Correct prediction
Energy consumption = 139.430720 pJ
sum error= 185
Actual label: 6
Output voltages: [0.22965, 0.20083, 0.034353, 0.0061736, 0.018181, 0.033349, 0.7958, 0.0046803, 0.68781, 0.0012077]
Predicted label: 6
Correct prediction
Energy consumption = 150.810045 pJ
sum error= 185
Actual label: 5
Output voltages: [0.79878, 0.0014841, 0.012278, 0.14552, 0.020057, 0.026773, 0.32962, 0.055703, 0.0087756, 0.038764]
Predicted label: 0
Wrong prediction!
Energy consumption = 154.634104 pJ
sum error= 186
Actual label: 8
Output voltages: [0.69043, 0.29624, 0.0032096, 0.72655, 0.001067, 0.63904, 0.46708, 0.012673, 0.74374, 0.0010727]
Predicted label: 8
Correct prediction
Energy consumption = 141.196756 pJ
sum error= 186
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 356 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 356 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 356 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.0243, 0.015221, 0.25023, 0.0025087, 0.16136, 0.27682, 0.79877, 0.0084342, 0.64404, 0.0021007]
Predicted label: 6
Correct prediction
Energy consumption = 163.940229 pJ
sum error= 186
Actual label: 4
Output voltages: [0.01498, 0.0013581, 0.078299, 0.030209, 0.79871, 0.0010827, 0.0079821, 0.018306, 0.55207, 0.041739]
Predicted label: 4
Correct prediction
Energy consumption = 165.600658 pJ
sum error= 186
Actual label: 1
Output voltages: [0.0019635, 0.79868, 0.043685, 0.0062644, 0.030153, 0.008361, 0.72201, 0.017196, 0.72734, 0.0048552]
Predicted label: 1
Correct prediction
Energy consumption = 155.936088 pJ
sum error= 186
Actual label: 8
Output voltages: [0.061201, 0.0051306, 0.011104, 0.49407, 0.0035651, 0.13016, 0.0023057, 0.0072206, 0.79878, 0.053234]
Predicted label: 8
Correct prediction
Energy consumption = 144.890202 pJ
sum error= 186
Actual label: 6
Output voltages: [0.39254, 0.030502, 0.0057852, 0.015483, 0.28557, 0.15842, 0.79832, 0.0042395, 0.70134, 0.0032792]
Predicted label: 6
Correct prediction
Energy consumption = 149.535342 pJ
sum error= 186
Actual label: 5
Output voltages: [0.10208, 0.0010819, 0.013911, 0.47727, 0.0086091, 0.79862, 0.12972, 0.020586, 0.7873, 0.014418]
Predicted label: 5
Correct prediction
Energy consumption = 148.345277 pJ
sum error= 186
Actual label: 2
Output voltages: [0.50928, 0.29173, 0.79879, 0.033197, 0.027073, 0.0013575, 0.42462, 0.045986, 0.29135, 0.040079]
Predicted label: 2
Correct prediction
Energy consumption = 153.011480 pJ
sum error= 186
Actual label: 8
Output voltages: [0.093791, 0.012948, 0.027705, 0.0069018, 0.059559, 0.70803, 0.046604, 0.035698, 0.79677, 0.0076799]
Predicted label: 8
Correct prediction
Energy consumption = 146.985424 pJ
sum error= 186
Actual label: 4
Output voltages: [0.013537, 0.050223, 0.47239, 0.017093, 0.79877, 0.0010742, 0.45319, 0.02329, 0.0097988, 0.13085]
Predicted label: 4
Correct prediction
Energy consumption = 157.370069 pJ
sum error= 186
Actual label: 5
Output voltages: [0.077896, 0.001281, 0.0052445, 0.36988, 0.020679, 0.79869, 0.072948, 0.21842, 0.77268, 0.015709]
Predicted label: 5
Correct prediction
Energy consumption = 145.716125 pJ
sum error= 186
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 357 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 357 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 357 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.1387, 0.0048202, 0.015031, 0.57621, 0.0078544, 0.79776, 0.14733, 0.003113, 0.79025, 0.029592]
Predicted label: 5
Correct prediction
Energy consumption = 164.364843 pJ
sum error= 186
Actual label: 4
Output voltages: [0.010817, 0.051172, 0.028496, 0.062932, 0.79811, 0.043274, 0.2026, 0.010633, 0.0099471, 0.38865]
Predicted label: 4
Correct prediction
Energy consumption = 151.382950 pJ
sum error= 186
Actual label: 7
Output voltages: [0.03923, 0.021904, 0.44949, 0.085386, 0.0016359, 0.0011203, 0.0010946, 0.79878, 0.59504, 0.095134]
Predicted label: 7
Correct prediction
Energy consumption = 153.392164 pJ
sum error= 186
Actual label: 7
Output voltages: [0.043171, 0.0016697, 0.7347, 0.25864, 0.059469, 0.0012934, 0.0010871, 0.76573, 0.37753, 0.01437]
Predicted label: 7
Correct prediction
Energy consumption = 139.568846 pJ
sum error= 186
Actual label: 0
Output voltages: [0.79879, 0.041998, 0.04323, 0.017642, 0.0057935, 0.0047909, 0.57929, 0.0067806, 0.14426, 0.62143]
Predicted label: 0
Correct prediction
Energy consumption = 156.829224 pJ
sum error= 186
Actual label: 7
Output voltages: [0.039204, 0.0099188, 0.22818, 0.032276, 0.0050351, 0.0018218, 0.0010723, 0.79869, 0.69339, 0.21984]
Predicted label: 7
Correct prediction
Energy consumption = 134.341404 pJ
sum error= 186
Actual label: 8
Output voltages: [0.0071159, 0.032131, 0.018167, 0.12118, 0.003653, 0.023653, 0.006432, 0.012154, 0.79879, 0.41078]
Predicted label: 8
Correct prediction
Energy consumption = 146.566816 pJ
sum error= 186
Actual label: 2
Output voltages: [0.3143, 0.050382, 0.79879, 0.16023, 0.014447, 0.0012308, 0.21943, 0.012397, 0.56931, 0.022306]
Predicted label: 2
Correct prediction
Energy consumption = 144.704399 pJ
sum error= 186
Actual label: 2
Output voltages: [0.75095, 0.65616, 0.79742, 0.023615, 0.0022276, 0.0013821, 0.31659, 0.37646, 0.071864, 0.030733]
Predicted label: 2
Correct prediction
Energy consumption = 138.630008 pJ
sum error= 186
Actual label: 3
Output voltages: [0.69718, 0.024437, 0.086068, 0.7987, 0.0061037, 0.0072536, 0.025823, 0.0097073, 0.44262, 0.029851]
Predicted label: 3
Correct prediction
Energy consumption = 140.185889 pJ
sum error= 186
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 358 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 358 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 358 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.26701, 0.34503, 0.58444, 0.3238, 0.0010716, 0.0010885, 0.0010666, 0.79879, 0.63907, 0.061833]
Predicted label: 7
Correct prediction
Energy consumption = 170.596640 pJ
sum error= 186
Actual label: 0
Output voltages: [0.79808, 0.17536, 0.042902, 0.046179, 0.014471, 0.0020567, 0.69299, 0.026577, 0.072363, 0.40762]
Predicted label: 0
Correct prediction
Energy consumption = 157.063239 pJ
sum error= 186
Actual label: 1
Output voltages: [0.046188, 0.79869, 0.015439, 0.18324, 0.08253, 0.0064188, 0.072297, 0.0030091, 0.020849, 0.20182]
Predicted label: 1
Correct prediction
Energy consumption = 163.091989 pJ
sum error= 186
Actual label: 8
Output voltages: [0.020703, 0.35791, 0.017318, 0.5134, 0.0014741, 0.043338, 0.0020688, 0.031081, 0.79876, 0.26323]
Predicted label: 8
Correct prediction
Energy consumption = 147.709385 pJ
sum error= 186
Actual label: 0
Output voltages: [0.79877, 0.042081, 0.00975, 0.0082339, 0.031312, 0.022691, 0.27852, 0.02051, 0.028787, 0.035639]
Predicted label: 0
Correct prediction
Energy consumption = 153.424090 pJ
sum error= 186
Actual label: 7
Output voltages: [0.1848, 0.025959, 0.10185, 0.27174, 0.0058034, 0.0011833, 0.0010764, 0.79879, 0.051102, 0.54762]
Predicted label: 7
Correct prediction
Energy consumption = 160.046868 pJ
sum error= 186
Actual label: 1
Output voltages: [0.022545, 0.79867, 0.14625, 0.11896, 0.018347, 0.0013007, 0.35017, 0.0010708, 0.39407, 0.089845]
Predicted label: 1
Correct prediction
Energy consumption = 158.429320 pJ
sum error= 186
Actual label: 9
Output voltages: [0.065783, 0.0059178, 0.021205, 0.070525, 0.023707, 0.014115, 0.0011465, 0.44039, 0.63989, 0.78393]
Predicted label: 9
Correct prediction
Energy consumption = 152.432604 pJ
sum error= 186
Actual label: 8
Output voltages: [0.039096, 0.02308, 0.087346, 0.62453, 0.0010718, 0.34187, 0.025427, 0.0018239, 0.79876, 0.1349]
Predicted label: 8
Correct prediction
Energy consumption = 150.644806 pJ
sum error= 186
Actual label: 7
Output voltages: [0.12288, 0.037923, 0.030701, 0.17013, 0.0087301, 0.0031297, 0.0010675, 0.79855, 0.042805, 0.39949]
Predicted label: 7
Correct prediction
Energy consumption = 157.309290 pJ
sum error= 186
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 359 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 359 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 359 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.22111, 0.002813, 0.001132, 0.69127, 0.037308, 0.7987, 0.14605, 0.037215, 0.77183, 0.14696]
Predicted label: 5
Correct prediction
Energy consumption = 167.757983 pJ
sum error= 186
Actual label: 5
Output voltages: [0.22652, 0.0011483, 0.033852, 0.079838, 0.0056447, 0.70895, 0.0042987, 0.029483, 0.79359, 0.52519]
Predicted label: 8
Wrong prediction!
Energy consumption = 136.989273 pJ
sum error= 187
Actual label: 9
Output voltages: [0.27587, 0.010258, 0.33015, 0.085801, 0.0075532, 0.036917, 0.0017738, 0.76515, 0.30232, 0.77933]
Predicted label: 9
Correct prediction
Energy consumption = 151.038027 pJ
sum error= 187
Actual label: 1
Output voltages: [0.051353, 0.79876, 0.038422, 0.0042507, 0.3473, 0.0018676, 0.41294, 0.0011007, 0.067444, 0.16401]
Predicted label: 1
Correct prediction
Energy consumption = 153.933029 pJ
sum error= 187
Actual label: 7
Output voltages: [0.28128, 0.17252, 0.0085229, 0.032288, 0.0026064, 0.0014057, 0.0011836, 0.79879, 0.15823, 0.28636]
Predicted label: 7
Correct prediction
Energy consumption = 155.541456 pJ
sum error= 187
Actual label: 5
Output voltages: [0.038185, 0.0010679, 0.0010659, 0.061179, 0.149, 0.79879, 0.16405, 0.005133, 0.76887, 0.0084191]
Predicted label: 5
Correct prediction
Energy consumption = 140.368626 pJ
sum error= 187
Actual label: 4
Output voltages: [0.0035047, 0.004354, 0.19084, 0.0014575, 0.79864, 0.0044077, 0.057298, 0.10329, 0.14039, 0.048465]
Predicted label: 4
Correct prediction
Energy consumption = 151.032234 pJ
sum error= 187
Actual label: 9
Output voltages: [0.38341, 0.044429, 0.31383, 0.79702, 0.022491, 0.20458, 0.019675, 0.0028075, 0.44093, 0.032656]
Predicted label: 3
Wrong prediction!
Energy consumption = 162.373559 pJ
sum error= 188
Actual label: 1
Output voltages: [0.020961, 0.78486, 0.076566, 0.034161, 0.55077, 0.0017484, 0.0085442, 0.0028219, 0.036688, 0.04197]
Predicted label: 1
Correct prediction
Energy consumption = 153.925818 pJ
sum error= 188
Actual label: 2
Output voltages: [0.67183, 0.47251, 0.79509, 0.15629, 0.011402, 0.0011946, 0.018415, 0.32258, 0.049564, 0.025764]
Predicted label: 2
Correct prediction
Energy consumption = 147.350119 pJ
sum error= 188
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 360 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 360 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 360 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.62056, 0.16367, 0.79867, 0.06747, 0.012234, 0.0012503, 0.32032, 0.037772, 0.46541, 0.01893]
Predicted label: 2
Correct prediction
Energy consumption = 166.837397 pJ
sum error= 188
Actual label: 1
Output voltages: [0.15657, 0.46141, 0.030292, 0.003007, 0.42466, 0.27355, 0.79314, 0.0010891, 0.21934, 0.0023878]
Predicted label: 6
Wrong prediction!
Energy consumption = 160.161255 pJ
sum error= 189
Actual label: 6
Output voltages: [0.057681, 0.16657, 0.096465, 0.0073395, 0.26966, 0.2529, 0.79865, 0.0020111, 0.44976, 0.012014]
Predicted label: 6
Correct prediction
Energy consumption = 144.047444 pJ
sum error= 189
Actual label: 6
Output voltages: [0.074869, 0.18343, 0.52628, 0.0012649, 0.081325, 0.077779, 0.79872, 0.0037573, 0.61606, 0.0042181]
Predicted label: 6
Correct prediction
Energy consumption = 134.418085 pJ
sum error= 189
Actual label: 7
Output voltages: [0.7984, 0.0013581, 0.24882, 0.018979, 0.0051092, 0.045044, 0.15863, 0.79864, 0.30599, 0.001093]
Predicted label: 7
Correct prediction
Energy consumption = 142.533354 pJ
sum error= 189
Actual label: 1
Output voltages: [0.032738, 0.79872, 0.055666, 0.0036012, 0.042598, 0.0010936, 0.34034, 0.0010702, 0.22709, 0.018028]
Predicted label: 1
Correct prediction
Energy consumption = 163.593550 pJ
sum error= 189
Actual label: 1
Output voltages: [0.0080057, 0.79868, 0.013849, 0.010865, 0.032565, 0.0054026, 0.73515, 0.0028689, 0.74158, 0.019276]
Predicted label: 1
Correct prediction
Energy consumption = 150.517848 pJ
sum error= 189
Actual label: 4
Output voltages: [0.026116, 0.003003, 0.1709, 0.013924, 0.79815, 0.0013723, 0.0079466, 0.001497, 0.035011, 0.73738]
Predicted label: 4
Correct prediction
Energy consumption = 162.125746 pJ
sum error= 189
Actual label: 0
Output voltages: [0.79878, 0.084201, 0.039002, 0.01993, 0.0065463, 0.0083194, 0.28412, 0.014325, 0.034008, 0.1184]
Predicted label: 0
Correct prediction
Energy consumption = 156.092476 pJ
sum error= 189
Actual label: 7
Output voltages: [0.036479, 0.045224, 0.2771, 0.13224, 0.0012859, 0.0010818, 0.001136, 0.79879, 0.17354, 0.23392]
Predicted label: 7
Correct prediction
Energy consumption = 146.998482 pJ
sum error= 189
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 361 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 361 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 361 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0018886, 0.015215, 0.31807, 0.015538, 0.79855, 0.0029125, 0.17216, 0.041217, 0.033739, 0.11316]
Predicted label: 4
Correct prediction
Energy consumption = 166.286890 pJ
sum error= 189
Actual label: 2
Output voltages: [0.40229, 0.051541, 0.79874, 0.04217, 0.0056384, 0.0012875, 0.13148, 0.20652, 0.49911, 0.026101]
Predicted label: 2
Correct prediction
Energy consumption = 155.071483 pJ
sum error= 189
Actual label: 4
Output voltages: [0.012535, 0.048932, 0.062664, 0.0069328, 0.79878, 0.015012, 0.34278, 0.24282, 0.14708, 0.04765]
Predicted label: 4
Correct prediction
Energy consumption = 157.732703 pJ
sum error= 189
Actual label: 0
Output voltages: [0.79878, 0.022947, 0.11028, 0.026715, 0.021006, 0.0089394, 0.083005, 0.047363, 0.30702, 0.033457]
Predicted label: 0
Correct prediction
Energy consumption = 159.460245 pJ
sum error= 189
Actual label: 6
Output voltages: [0.3855, 0.015017, 0.11085, 0.0017834, 0.024111, 0.019546, 0.79734, 0.004972, 0.34829, 0.12399]
Predicted label: 6
Correct prediction
Energy consumption = 141.316411 pJ
sum error= 189
Actual label: 4
Output voltages: [0.033251, 0.034878, 0.037392, 0.0077604, 0.79879, 0.0010814, 0.49626, 0.087949, 0.048277, 0.03068]
Predicted label: 4
Correct prediction
Energy consumption = 151.253486 pJ
sum error= 189
Actual label: 7
Output voltages: [0.034634, 0.27955, 0.16973, 0.054772, 0.0078021, 0.0011113, 0.0011006, 0.79862, 0.31901, 0.053433]
Predicted label: 7
Correct prediction
Energy consumption = 152.149064 pJ
sum error= 189
Actual label: 6
Output voltages: [0.23048, 0.36454, 0.30108, 0.046542, 0.057038, 0.3056, 0.79879, 0.013107, 0.70013, 0.001986]
Predicted label: 6
Correct prediction
Energy consumption = 150.290509 pJ
sum error= 189
Actual label: 9
Output voltages: [0.081042, 0.0098513, 0.035416, 0.019413, 0.018986, 0.014708, 0.0015828, 0.35646, 0.69825, 0.79453]
Predicted label: 9
Correct prediction
Energy consumption = 154.035063 pJ
sum error= 189
Actual label: 5
Output voltages: [0.21314, 0.0024943, 0.0010957, 0.74237, 0.023372, 0.79802, 0.040452, 0.0046091, 0.72613, 0.019936]
Predicted label: 5
Correct prediction
Energy consumption = 140.886474 pJ
sum error= 189
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 362 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 362 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 362 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.35547, 0.0036712, 0.025369, 0.79876, 0.017715, 0.077203, 0.0055623, 0.025921, 0.55632, 0.029363]
Predicted label: 3
Correct prediction
Energy consumption = 164.244127 pJ
sum error= 189
Actual label: 4
Output voltages: [0.014615, 0.012188, 0.2867, 0.0166, 0.79868, 0.0053954, 0.1997, 0.13882, 0.065518, 0.024761]
Predicted label: 4
Correct prediction
Energy consumption = 154.722023 pJ
sum error= 189
Actual label: 6
Output voltages: [0.057036, 0.053184, 0.41724, 0.0012067, 0.34265, 0.031205, 0.79873, 0.0014281, 0.32929, 0.0073651]
Predicted label: 6
Correct prediction
Energy consumption = 147.964956 pJ
sum error= 189
Actual label: 5
Output voltages: [0.36987, 0.030697, 0.0011241, 0.57488, 0.047908, 0.79874, 0.34159, 0.0060384, 0.27346, 0.033285]
Predicted label: 5
Correct prediction
Energy consumption = 149.948166 pJ
sum error= 189
Actual label: 0
Output voltages: [0.79846, 0.034058, 0.038438, 0.014184, 0.0035781, 0.001906, 0.72401, 0.028787, 0.30794, 0.034614]
Predicted label: 0
Correct prediction
Energy consumption = 147.453415 pJ
sum error= 189
Actual label: 1
Output voltages: [0.025249, 0.79849, 0.010318, 0.060168, 0.0018469, 0.0041947, 0.77166, 0.010385, 0.45048, 0.027981]
Predicted label: 1
Correct prediction
Energy consumption = 158.465943 pJ
sum error= 189
Actual label: 8
Output voltages: [0.097623, 0.057742, 0.10123, 0.79875, 0.0034356, 0.008054, 0.012251, 0.0028406, 0.79418, 0.12562]
Predicted label: 3
Wrong prediction!
Energy consumption = 156.158781 pJ
sum error= 190
Actual label: 8
Output voltages: [0.030285, 0.038326, 0.37336, 0.017683, 0.09419, 0.0038742, 0.060129, 0.010726, 0.79879, 0.38502]
Predicted label: 8
Correct prediction
Energy consumption = 145.074791 pJ
sum error= 190
Actual label: 2
Output voltages: [0.43477, 0.0048955, 0.79873, 0.14471, 0.040621, 0.0012073, 0.21126, 0.15881, 0.57442, 0.029789]
Predicted label: 2
Correct prediction
Energy consumption = 145.201093 pJ
sum error= 190
Actual label: 8
Output voltages: [0.53961, 0.007559, 0.2194, 0.40833, 0.003739, 0.016549, 0.024292, 0.0010805, 0.79874, 0.15393]
Predicted label: 8
Correct prediction
Energy consumption = 146.501652 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 363 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 363 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 363 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.57325, 0.014831, 0.43258, 0.79872, 0.037573, 0.030546, 0.0046972, 0.036195, 0.71041, 0.043065]
Predicted label: 3
Correct prediction
Energy consumption = 163.221316 pJ
sum error= 190
Actual label: 5
Output voltages: [0.041179, 0.0011757, 0.015056, 0.4052, 0.0074687, 0.79872, 0.11238, 0.041764, 0.7656, 0.052411]
Predicted label: 5
Correct prediction
Energy consumption = 141.754478 pJ
sum error= 190
Actual label: 7
Output voltages: [0.089506, 0.097543, 0.0032791, 0.10557, 0.0011721, 0.0035234, 0.0011586, 0.79639, 0.66409, 0.7492]
Predicted label: 7
Correct prediction
Energy consumption = 154.664675 pJ
sum error= 190
Actual label: 8
Output voltages: [0.008251, 0.037913, 0.17646, 0.19672, 0.0013021, 0.048675, 0.022813, 0.0077499, 0.79875, 0.043691]
Predicted label: 8
Correct prediction
Energy consumption = 150.407231 pJ
sum error= 190
Actual label: 0
Output voltages: [0.78614, 0.056628, 0.24112, 0.026913, 0.012603, 0.001066, 0.5297, 0.044534, 0.15776, 0.43206]
Predicted label: 0
Correct prediction
Energy consumption = 159.314197 pJ
sum error= 190
Actual label: 8
Output voltages: [0.42615, 0.021712, 0.32077, 0.10612, 0.045222, 0.0012829, 0.21776, 0.0010911, 0.79812, 0.1187]
Predicted label: 8
Correct prediction
Energy consumption = 152.561788 pJ
sum error= 190
Actual label: 5
Output voltages: [0.0023684, 0.002407, 0.014035, 0.26143, 0.062374, 0.79423, 0.26017, 0.019961, 0.72159, 0.32045]
Predicted label: 5
Correct prediction
Energy consumption = 139.664321 pJ
sum error= 190
Actual label: 7
Output voltages: [0.036261, 0.27994, 0.25184, 0.018709, 0.013881, 0.0010753, 0.0011568, 0.7987, 0.084264, 0.024667]
Predicted label: 7
Correct prediction
Energy consumption = 155.974248 pJ
sum error= 190
Actual label: 1
Output voltages: [0.0082746, 0.79879, 0.58809, 0.085069, 0.14461, 0.0010802, 0.72256, 0.0013245, 0.038603, 0.0091802]
Predicted label: 1
Correct prediction
Energy consumption = 157.716858 pJ
sum error= 190
Actual label: 1
Output voltages: [0.0025022, 0.79857, 0.10186, 0.48917, 0.032883, 0.0025954, 0.48888, 0.088178, 0.085306, 0.01426]
Predicted label: 1
Correct prediction
Energy consumption = 153.629831 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 364 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 364 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 364 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.25863, 0.26693, 0.012826, 0.011371, 0.0017768, 0.45127, 0.010364, 0.14336, 0.46486]
Predicted label: 0
Correct prediction
Energy consumption = 172.356574 pJ
sum error= 190
Actual label: 1
Output voltages: [0.07405, 0.79846, 0.60536, 0.48085, 0.0083053, 0.0016597, 0.16902, 0.015066, 0.016335, 0.31165]
Predicted label: 1
Correct prediction
Energy consumption = 165.004400 pJ
sum error= 190
Actual label: 3
Output voltages: [0.12223, 0.020115, 0.024872, 0.79865, 0.017454, 0.0046049, 0.011007, 0.020923, 0.56686, 0.044198]
Predicted label: 3
Correct prediction
Energy consumption = 147.541905 pJ
sum error= 190
Actual label: 7
Output voltages: [0.55067, 0.17517, 0.40833, 0.44456, 0.0011136, 0.0010734, 0.00112, 0.79876, 0.56099, 0.0087951]
Predicted label: 7
Correct prediction
Energy consumption = 153.564697 pJ
sum error= 190
Actual label: 8
Output voltages: [0.14279, 0.077862, 0.36178, 0.11097, 0.023097, 0.10149, 0.013308, 0.0066469, 0.79869, 0.12468]
Predicted label: 8
Correct prediction
Energy consumption = 146.833272 pJ
sum error= 190
Actual label: 5
Output voltages: [0.022972, 0.0035048, 0.0084487, 0.23211, 0.033384, 0.79879, 0.35162, 0.037037, 0.6167, 0.029633]
Predicted label: 5
Correct prediction
Energy consumption = 151.999634 pJ
sum error= 190
Actual label: 0
Output voltages: [0.79534, 0.11746, 0.010702, 0.035672, 0.13245, 0.001066, 0.74721, 0.0019641, 0.33098, 0.068202]
Predicted label: 0
Correct prediction
Energy consumption = 154.643959 pJ
sum error= 190
Actual label: 7
Output voltages: [0.016788, 0.017677, 0.088862, 0.76552, 0.02116, 0.012879, 0.0010867, 0.79844, 0.33754, 0.34363]
Predicted label: 7
Correct prediction
Energy consumption = 158.390344 pJ
sum error= 190
Actual label: 1
Output voltages: [0.024833, 0.79845, 0.04638, 0.036971, 0.021965, 0.0039401, 0.50501, 0.0032395, 0.22703, 0.036317]
Predicted label: 1
Correct prediction
Energy consumption = 163.672302 pJ
sum error= 190
Actual label: 1
Output voltages: [0.029825, 0.79846, 0.077343, 0.026351, 0.0021204, 0.0014941, 0.71384, 0.005267, 0.30613, 0.10172]
Predicted label: 1
Correct prediction
Energy consumption = 148.274499 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 365 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 365 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 365 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79855, 0.085079, 0.32247, 0.025113, 0.0077063, 0.0011432, 0.56452, 0.010096, 0.12938, 0.16246]
Predicted label: 0
Correct prediction
Energy consumption = 174.005665 pJ
sum error= 190
Actual label: 1
Output voltages: [0.055405, 0.79845, 0.065291, 0.32794, 0.075226, 0.003627, 0.44601, 0.007856, 0.022825, 0.21142]
Predicted label: 1
Correct prediction
Energy consumption = 165.400912 pJ
sum error= 190
Actual label: 1
Output voltages: [0.013511, 0.79856, 0.022344, 0.041521, 0.021194, 0.0012079, 0.72466, 0.012214, 0.33804, 0.02042]
Predicted label: 1
Correct prediction
Energy consumption = 154.166125 pJ
sum error= 190
Actual label: 4
Output voltages: [0.026594, 0.024338, 0.3462, 0.0059137, 0.79877, 0.0010697, 0.19668, 0.16366, 0.013927, 0.50618]
Predicted label: 4
Correct prediction
Energy consumption = 158.859114 pJ
sum error= 190
Actual label: 5
Output voltages: [0.2559, 0.042608, 0.0060749, 0.17559, 0.018616, 0.78977, 0.75791, 0.0013861, 0.74561, 0.024184]
Predicted label: 5
Correct prediction
Energy consumption = 162.655945 pJ
sum error= 190
Actual label: 2
Output voltages: [0.41949, 0.47173, 0.79879, 0.068745, 0.023394, 0.0013485, 0.37525, 0.029888, 0.27943, 0.18561]
Predicted label: 2
Correct prediction
Energy consumption = 157.448274 pJ
sum error= 190
Actual label: 7
Output voltages: [0.057098, 0.012074, 0.028016, 0.75556, 0.022874, 0.02313, 0.0011628, 0.79872, 0.27494, 0.47627]
Predicted label: 7
Correct prediction
Energy consumption = 146.384265 pJ
sum error= 190
Actual label: 6
Output voltages: [0.097138, 0.18161, 0.35496, 0.0012661, 0.4981, 0.088046, 0.79872, 0.0011854, 0.025509, 0.027376]
Predicted label: 6
Correct prediction
Energy consumption = 152.273719 pJ
sum error= 190
Actual label: 2
Output voltages: [0.14802, 0.55328, 0.79879, 0.077529, 0.009825, 0.0012698, 0.089513, 0.06604, 0.22135, 0.029221]
Predicted label: 2
Correct prediction
Energy consumption = 154.436191 pJ
sum error= 190
Actual label: 3
Output voltages: [0.22234, 0.012916, 0.045736, 0.79863, 0.025954, 0.016495, 0.013041, 0.044153, 0.48561, 0.21459]
Predicted label: 3
Correct prediction
Energy consumption = 138.013137 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 366 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 366 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 366 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79866, 0.041403, 0.023838, 0.0064968, 0.0020676, 0.0025287, 0.63776, 0.017221, 0.22123, 0.036106]
Predicted label: 0
Correct prediction
Energy consumption = 170.844128 pJ
sum error= 190
Actual label: 2
Output voltages: [0.42765, 0.098767, 0.79861, 0.46196, 0.020046, 0.0011079, 0.079066, 0.037251, 0.41405, 0.0099256]
Predicted label: 2
Correct prediction
Energy consumption = 147.630047 pJ
sum error= 190
Actual label: 8
Output voltages: [0.31792, 0.0088349, 0.097599, 0.055304, 0.030627, 0.020504, 0.38821, 0.0011042, 0.79863, 0.0027858]
Predicted label: 8
Correct prediction
Energy consumption = 143.819180 pJ
sum error= 190
Actual label: 5
Output voltages: [0.0097393, 0.00361, 0.0013747, 0.25336, 0.010299, 0.79547, 0.050677, 0.055944, 0.50328, 0.39768]
Predicted label: 5
Correct prediction
Energy consumption = 150.098356 pJ
sum error= 190
Actual label: 9
Output voltages: [0.05181, 0.02464, 0.068043, 0.17994, 0.064104, 0.0097948, 0.037658, 0.017556, 0.53074, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 145.378374 pJ
sum error= 190
Actual label: 6
Output voltages: [0.32167, 0.0084982, 0.27699, 0.0013014, 0.22047, 0.098224, 0.79874, 0.004484, 0.43503, 0.026353]
Predicted label: 6
Correct prediction
Energy consumption = 145.142567 pJ
sum error= 190
Actual label: 9
Output voltages: [0.062077, 0.014583, 0.023828, 0.037633, 0.040821, 0.037126, 0.01229, 0.24199, 0.52851, 0.7934]
Predicted label: 9
Correct prediction
Energy consumption = 154.137545 pJ
sum error= 190
Actual label: 7
Output voltages: [0.58268, 0.032232, 0.15541, 0.021857, 0.011447, 0.0010936, 0.003006, 0.79871, 0.30092, 0.027995]
Predicted label: 7
Correct prediction
Energy consumption = 153.650582 pJ
sum error= 190
Actual label: 2
Output voltages: [0.55331, 0.0054235, 0.79879, 0.21661, 0.045638, 0.0010825, 0.035196, 0.17663, 0.46766, 0.011528]
Predicted label: 2
Correct prediction
Energy consumption = 144.271240 pJ
sum error= 190
Actual label: 1
Output voltages: [0.023111, 0.79851, 0.0092376, 0.068944, 0.041947, 0.017545, 0.21794, 0.007628, 0.064883, 0.35659]
Predicted label: 1
Correct prediction
Energy consumption = 162.402961 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 367 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 367 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 367 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.44673, 0.010138, 0.37432, 0.79869, 0.036243, 0.0093358, 0.0094703, 0.025482, 0.71046, 0.036163]
Predicted label: 3
Correct prediction
Energy consumption = 158.329519 pJ
sum error= 190
Actual label: 6
Output voltages: [0.45136, 0.028712, 0.060467, 0.029232, 0.30902, 0.73877, 0.79879, 0.0019711, 0.56912, 0.010776]
Predicted label: 6
Correct prediction
Energy consumption = 151.857564 pJ
sum error= 190
Actual label: 4
Output voltages: [0.0011837, 0.0079048, 0.043139, 0.004207, 0.79872, 0.0013339, 0.42415, 0.17471, 0.036725, 0.025092]
Predicted label: 4
Correct prediction
Energy consumption = 148.058225 pJ
sum error= 190
Actual label: 1
Output voltages: [0.012561, 0.79861, 0.029638, 0.35517, 0.44547, 0.0020384, 0.24438, 0.021366, 0.07956, 0.15997]
Predicted label: 1
Correct prediction
Energy consumption = 168.325719 pJ
sum error= 190
Actual label: 8
Output voltages: [0.024115, 0.0016676, 0.015682, 0.21651, 0.0022912, 0.70464, 0.018225, 0.0027651, 0.79856, 0.057848]
Predicted label: 8
Correct prediction
Energy consumption = 149.219630 pJ
sum error= 190
Actual label: 2
Output voltages: [0.7009, 0.010387, 0.79875, 0.066937, 0.034482, 0.0010694, 0.040517, 0.11022, 0.58726, 0.013602]
Predicted label: 2
Correct prediction
Energy consumption = 147.209610 pJ
sum error= 190
Actual label: 4
Output voltages: [0.010888, 0.010444, 0.28334, 0.019306, 0.79866, 0.0024522, 0.090812, 0.031496, 0.17449, 0.040618]
Predicted label: 4
Correct prediction
Energy consumption = 152.496899 pJ
sum error= 190
Actual label: 0
Output voltages: [0.79879, 0.057646, 0.019991, 0.11659, 0.013258, 0.16011, 0.73824, 0.069121, 0.28404, 0.023404]
Predicted label: 0
Correct prediction
Energy consumption = 151.173663 pJ
sum error= 190
Actual label: 5
Output voltages: [0.070737, 0.0010872, 0.037033, 0.10232, 0.0029978, 0.79843, 0.13537, 0.018663, 0.79246, 0.011883]
Predicted label: 5
Correct prediction
Energy consumption = 143.443393 pJ
sum error= 190
Actual label: 1
Output voltages: [0.019216, 0.79858, 0.0018, 0.039114, 0.33795, 0.0057976, 0.30882, 0.002863, 0.30373, 0.25446]
Predicted label: 1
Correct prediction
Energy consumption = 165.404127 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 368 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 368 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 368 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79858, 0.037816, 0.032537, 0.19926, 0.0031743, 0.29123, 0.034259, 0.026934, 0.13424, 0.017676]
Predicted label: 0
Correct prediction
Energy consumption = 168.335172 pJ
sum error= 190
Actual label: 2
Output voltages: [0.10358, 0.0028318, 0.75842, 0.78146, 0.0020736, 0.0072223, 0.012159, 0.0014415, 0.77782, 0.0019088]
Predicted label: 3
Wrong prediction!
Energy consumption = 138.804791 pJ
sum error= 191
Actual label: 2
Output voltages: [0.75326, 0.0017715, 0.79839, 0.17833, 0.0069897, 0.0010744, 0.028762, 0.10042, 0.52696, 0.008514]
Predicted label: 2
Correct prediction
Energy consumption = 140.948437 pJ
sum error= 191
Actual label: 6
Output voltages: [0.051913, 0.30838, 0.42578, 0.0019551, 0.33134, 0.16932, 0.79866, 0.0044832, 0.16361, 0.0082227]
Predicted label: 6
Correct prediction
Energy consumption = 155.184803 pJ
sum error= 191
Actual label: 4
Output voltages: [0.021306, 0.0048716, 0.1564, 0.021991, 0.79866, 0.0028598, 0.17516, 0.062029, 0.02025, 0.098912]
Predicted label: 4
Correct prediction
Energy consumption = 151.284613 pJ
sum error= 191
Actual label: 4
Output voltages: [0.0356, 0.0133, 0.54017, 0.009741, 0.79875, 0.0011542, 0.25734, 0.090312, 0.023309, 0.023883]
Predicted label: 4
Correct prediction
Energy consumption = 146.683298 pJ
sum error= 191
Actual label: 3
Output voltages: [0.16027, 0.038218, 0.0305, 0.79878, 0.0028096, 0.0029049, 0.010067, 0.016218, 0.78451, 0.02783]
Predicted label: 3
Correct prediction
Energy consumption = 152.798878 pJ
sum error= 191
Actual label: 9
Output voltages: [0.15346, 0.023253, 0.032891, 0.20887, 0.27251, 0.024132, 0.046171, 0.0020332, 0.30425, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 143.488909 pJ
sum error= 191
Actual label: 6
Output voltages: [0.34651, 0.51544, 0.012523, 0.040222, 0.015169, 0.41902, 0.79879, 0.018117, 0.69855, 0.0012051]
Predicted label: 6
Correct prediction
Energy consumption = 161.871856 pJ
sum error= 191
Actual label: 1
Output voltages: [0.0095195, 0.79842, 0.022797, 0.089661, 0.038358, 0.0049619, 0.4792, 0.077037, 0.13814, 0.029483]
Predicted label: 1
Correct prediction
Energy consumption = 161.141358 pJ
sum error= 191
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 369 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 369 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 369 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.35147, 0.076522, 0.044893, 0.010888, 0.55274, 0.43502, 0.79879, 0.0026512, 0.50192, 0.0034175]
Predicted label: 6
Correct prediction
Energy consumption = 167.947370 pJ
sum error= 191
Actual label: 5
Output voltages: [0.019647, 0.0011011, 0.0025873, 0.10655, 0.043648, 0.79695, 0.094361, 0.028075, 0.79669, 0.038765]
Predicted label: 5
Correct prediction
Energy consumption = 138.275520 pJ
sum error= 191
Actual label: 7
Output voltages: [0.20784, 0.018866, 0.056002, 0.11001, 0.028845, 0.039854, 0.0011082, 0.79845, 0.16103, 0.44813]
Predicted label: 7
Correct prediction
Energy consumption = 151.701341 pJ
sum error= 191
Actual label: 9
Output voltages: [0.057758, 0.0028408, 0.018455, 0.016564, 0.45854, 0.0011227, 0.0029733, 0.036031, 0.28927, 0.7975]
Predicted label: 9
Correct prediction
Energy consumption = 152.388706 pJ
sum error= 191
Actual label: 2
Output voltages: [0.21684, 0.50065, 0.79879, 0.037648, 0.014562, 0.0012401, 0.066445, 0.0074633, 0.18061, 0.076624]
Predicted label: 2
Correct prediction
Energy consumption = 148.778497 pJ
sum error= 191
Actual label: 0
Output voltages: [0.79871, 0.027634, 0.044157, 0.0033252, 0.012992, 0.0013059, 0.55395, 0.12524, 0.16388, 0.079969]
Predicted label: 0
Correct prediction
Energy consumption = 146.631312 pJ
sum error= 191
Actual label: 2
Output voltages: [0.21978, 0.093453, 0.79879, 0.041765, 0.0085294, 0.0013787, 0.23048, 0.019984, 0.44256, 0.029935]
Predicted label: 2
Correct prediction
Energy consumption = 142.814266 pJ
sum error= 191
Actual label: 6
Output voltages: [0.36847, 0.042642, 0.037572, 0.018273, 0.25516, 0.51206, 0.79871, 0.0011511, 0.44725, 0.028015]
Predicted label: 6
Correct prediction
Energy consumption = 148.445037 pJ
sum error= 191
Actual label: 0
Output voltages: [0.79878, 0.19236, 0.074586, 0.024864, 0.020354, 0.0077543, 0.44126, 0.0236, 0.080299, 0.33229]
Predicted label: 0
Correct prediction
Energy consumption = 153.991966 pJ
sum error= 191
Actual label: 1
Output voltages: [0.04782, 0.79855, 0.27773, 0.042537, 0.02791, 0.0016906, 0.4788, 0.001578, 0.24184, 0.027891]
Predicted label: 1
Correct prediction
Energy consumption = 163.605644 pJ
sum error= 191
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 370 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 370 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 370 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0073994, 0.0051355, 0.041734, 0.057752, 0.79872, 0.0010751, 0.0216, 0.016849, 0.0472, 0.015257]
Predicted label: 4
Correct prediction
Energy consumption = 174.178414 pJ
sum error= 191
Actual label: 3
Output voltages: [0.70743, 0.013463, 0.13796, 0.79872, 0.0064517, 0.010877, 0.012518, 0.013356, 0.45176, 0.048232]
Predicted label: 3
Correct prediction
Energy consumption = 151.088073 pJ
sum error= 191
Actual label: 5
Output voltages: [0.0019219, 0.0011533, 0.0029307, 0.78846, 0.66747, 0.77282, 0.11218, 0.032212, 0.064409, 0.061054]
Predicted label: 3
Wrong prediction!
Energy consumption = 151.115764 pJ
sum error= 192
Actual label: 2
Output voltages: [0.13701, 0.7469, 0.7925, 0.2071, 0.034151, 0.0013285, 0.037601, 0.021283, 0.032557, 0.026385]
Predicted label: 2
Correct prediction
Energy consumption = 153.139615 pJ
sum error= 192
Actual label: 8
Output voltages: [0.01749, 0.21664, 0.03585, 0.12292, 0.0026046, 0.023194, 0.012981, 0.021467, 0.79879, 0.30035]
Predicted label: 8
Correct prediction
Energy consumption = 151.024198 pJ
sum error= 192
Actual label: 8
Output voltages: [0.21689, 0.038734, 0.6507, 0.053099, 0.0013587, 0.032068, 0.051724, 0.032166, 0.79874, 0.022675]
Predicted label: 8
Correct prediction
Energy consumption = 144.196515 pJ
sum error= 192
Actual label: 0
Output voltages: [0.79853, 0.017487, 0.071808, 0.0034861, 0.0040659, 0.0026014, 0.27471, 0.025314, 0.42929, 0.044393]
Predicted label: 0
Correct prediction
Energy consumption = 151.815145 pJ
sum error= 192
Actual label: 8
Output voltages: [0.0032687, 0.037295, 0.13411, 0.020171, 0.013017, 0.0067068, 0.054114, 0.042642, 0.79878, 0.29865]
Predicted label: 8
Correct prediction
Energy consumption = 149.064279 pJ
sum error= 192
Actual label: 8
Output voltages: [0.17631, 0.002399, 0.20599, 0.034929, 0.0087171, 0.13396, 0.031845, 0.015483, 0.79878, 0.25186]
Predicted label: 8
Correct prediction
Energy consumption = 143.782906 pJ
sum error= 192
Actual label: 9
Output voltages: [0.46936, 0.024344, 0.010342, 0.013939, 0.029185, 0.026387, 0.0017735, 0.61568, 0.16961, 0.79415]
Predicted label: 9
Correct prediction
Energy consumption = 150.961404 pJ
sum error= 192
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 371 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 371 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 371 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79162, 0.050986, 0.44276, 0.0012407, 0.0012231, 0.0010743, 0.24019, 0.01256, 0.51423, 0.15609]
Predicted label: 0
Correct prediction
Energy consumption = 169.793343 pJ
sum error= 192
Actual label: 9
Output voltages: [0.091139, 0.029345, 0.037324, 0.051515, 0.26329, 0.015419, 0.0035413, 0.018811, 0.397, 0.79865]
Predicted label: 9
Correct prediction
Energy consumption = 156.226347 pJ
sum error= 192
Actual label: 6
Output voltages: [0.14127, 0.023836, 0.16992, 0.0019744, 0.27844, 0.13645, 0.79868, 0.0068368, 0.4059, 0.024252]
Predicted label: 6
Correct prediction
Energy consumption = 144.532421 pJ
sum error= 192
Actual label: 7
Output voltages: [0.1618, 0.0095277, 0.64128, 0.19248, 0.0012694, 0.001081, 0.0070014, 0.79868, 0.31251, 0.054953]
Predicted label: 7
Correct prediction
Energy consumption = 146.018447 pJ
sum error= 192
Actual label: 6
Output voltages: [0.067904, 0.053435, 0.032823, 0.012587, 0.064078, 0.76273, 0.79879, 0.018607, 0.47228, 0.005591]
Predicted label: 6
Correct prediction
Energy consumption = 150.736090 pJ
sum error= 192
Actual label: 3
Output voltages: [0.13958, 0.0065625, 0.6458, 0.79823, 0.0048127, 0.0010714, 0.0050319, 0.011247, 0.337, 0.24928]
Predicted label: 3
Correct prediction
Energy consumption = 149.098898 pJ
sum error= 192
Actual label: 9
Output voltages: [0.21474, 0.0015119, 0.013892, 0.11052, 0.040593, 0.019284, 0.0026263, 0.0034837, 0.7048, 0.7767]
Predicted label: 9
Correct prediction
Energy consumption = 146.908696 pJ
sum error= 192
Actual label: 3
Output voltages: [0.37961, 0.034482, 0.039631, 0.79859, 0.017748, 0.018524, 0.017607, 0.02679, 0.43773, 0.10075]
Predicted label: 3
Correct prediction
Energy consumption = 142.190740 pJ
sum error= 192
Actual label: 4
Output voltages: [0.0057801, 0.0013835, 0.043348, 0.013772, 0.79251, 0.0016505, 0.001066, 0.0041147, 0.42912, 0.32394]
Predicted label: 4
Correct prediction
Energy consumption = 150.104394 pJ
sum error= 192
Actual label: 7
Output voltages: [0.069015, 0.062961, 0.30888, 0.054757, 0.0038317, 0.0010662, 0.002214, 0.79859, 0.038916, 0.32457]
Predicted label: 7
Correct prediction
Energy consumption = 156.940462 pJ
sum error= 192
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 372 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 372 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 372 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.12907, 0.0038006, 0.023125, 0.77334, 0.0057296, 0.047954, 0.0010861, 0.79819, 0.23346, 0.7397]
Predicted label: 7
Correct prediction
Energy consumption = 171.908551 pJ
sum error= 192
Actual label: 7
Output voltages: [0.35479, 0.65457, 0.071836, 0.75251, 0.0026163, 0.0010682, 0.0021111, 0.78767, 0.017271, 0.39161]
Predicted label: 7
Correct prediction
Energy consumption = 154.400043 pJ
sum error= 192
Actual label: 4
Output voltages: [0.12044, 0.0019059, 0.29671, 0.0022972, 0.79879, 0.0034546, 0.014272, 0.33686, 0.031467, 0.59457]
Predicted label: 4
Correct prediction
Energy consumption = 157.344921 pJ
sum error= 192
Actual label: 9
Output voltages: [0.75957, 0.010598, 0.026325, 0.032726, 0.0038529, 0.0094378, 0.42386, 0.003982, 0.12719, 0.77097]
Predicted label: 9
Correct prediction
Energy consumption = 149.704249 pJ
sum error= 192
Actual label: 0
Output voltages: [0.79874, 0.02988, 0.015171, 0.018414, 0.015848, 0.02233, 0.41708, 0.019175, 0.36823, 0.034971]
Predicted label: 0
Correct prediction
Energy consumption = 143.985940 pJ
sum error= 192
Actual label: 6
Output voltages: [0.031856, 0.081003, 0.056319, 0.037415, 0.26189, 0.47054, 0.79867, 0.032922, 0.47124, 0.012114]
Predicted label: 6
Correct prediction
Energy consumption = 150.205380 pJ
sum error= 192
Actual label: 4
Output voltages: [0.016825, 0.031099, 0.031059, 0.059947, 0.79878, 0.0011013, 0.0010792, 0.0316, 0.0046385, 0.68975]
Predicted label: 4
Correct prediction
Energy consumption = 154.712613 pJ
sum error= 192
Actual label: 8
Output voltages: [0.22738, 0.0011755, 0.0098169, 0.60768, 0.19546, 0.21419, 0.017246, 0.0011153, 0.78442, 0.21788]
Predicted label: 8
Correct prediction
Energy consumption = 146.727923 pJ
sum error= 192
Actual label: 4
Output voltages: [0.0085962, 0.0024105, 0.06655, 0.029194, 0.79879, 0.0044392, 0.015936, 0.03211, 0.035539, 0.56767]
Predicted label: 4
Correct prediction
Energy consumption = 156.316285 pJ
sum error= 192
Actual label: 2
Output voltages: [0.72257, 0.0034437, 0.79834, 0.39366, 0.016982, 0.0010856, 0.11229, 0.20037, 0.72257, 0.03937]
Predicted label: 2
Correct prediction
Energy consumption = 151.429585 pJ
sum error= 192
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 373 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 373 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 373 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.40401, 0.0014429, 0.021733, 0.15899, 0.020933, 0.15786, 0.0010884, 0.79878, 0.51453, 0.68933]
Predicted label: 7
Correct prediction
Energy consumption = 174.887478 pJ
sum error= 192
Actual label: 2
Output voltages: [0.63519, 0.0157, 0.7983, 0.38879, 0.0067056, 0.0012028, 0.013215, 0.067825, 0.38308, 0.0055848]
Predicted label: 2
Correct prediction
Energy consumption = 147.540052 pJ
sum error= 192
Actual label: 8
Output voltages: [0.031897, 0.43513, 0.047211, 0.61518, 0.0012921, 0.021422, 0.037658, 0.013064, 0.79879, 0.04351]
Predicted label: 8
Correct prediction
Energy consumption = 153.377921 pJ
sum error= 192
Actual label: 1
Output voltages: [0.075157, 0.7987, 0.19523, 0.02378, 0.66952, 0.0024085, 0.15341, 0.013212, 0.036717, 0.005233]
Predicted label: 1
Correct prediction
Energy consumption = 152.841197 pJ
sum error= 192
Actual label: 0
Output voltages: [0.79758, 0.020354, 0.0088224, 0.032418, 0.0041038, 0.21765, 0.55261, 0.0034048, 0.16699, 0.11262]
Predicted label: 0
Correct prediction
Energy consumption = 159.510380 pJ
sum error= 192
Actual label: 0
Output voltages: [0.79878, 0.06049, 0.017409, 0.023306, 0.0049823, 0.083239, 0.34487, 0.012006, 0.28612, 0.28271]
Predicted label: 0
Correct prediction
Energy consumption = 147.628336 pJ
sum error= 192
Actual label: 7
Output voltages: [0.03818, 0.78679, 0.17178, 0.38398, 0.00107, 0.0011423, 0.0011848, 0.78108, 0.037572, 0.024957]
Predicted label: 1
Wrong prediction!
Energy consumption = 159.084908 pJ
sum error= 193
Actual label: 8
Output voltages: [0.0076262, 0.0038881, 0.018971, 0.062907, 0.02831, 0.062159, 0.044642, 0.0091637, 0.79879, 0.0054161]
Predicted label: 8
Correct prediction
Energy consumption = 141.376124 pJ
sum error= 193
Actual label: 3
Output voltages: [0.58871, 0.1956, 0.14866, 0.79879, 0.0012106, 0.038172, 0.29868, 0.060619, 0.045015, 0.0019315]
Predicted label: 3
Correct prediction
Energy consumption = 146.070684 pJ
sum error= 193
Actual label: 3
Output voltages: [0.53893, 0.023173, 0.030628, 0.7986, 0.0039934, 0.04078, 0.030961, 0.0466, 0.63758, 0.079389]
Predicted label: 3
Correct prediction
Energy consumption = 137.253460 pJ
sum error= 193
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 374 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 374 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 374 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.59863, 0.056392, 0.0035282, 0.79879, 0.0014341, 0.036293, 0.0093013, 0.057452, 0.51472, 0.0022358]
Predicted label: 3
Correct prediction
Energy consumption = 166.398431 pJ
sum error= 193
Actual label: 1
Output voltages: [0.01551, 0.79856, 0.023917, 0.13829, 0.060758, 0.005505, 0.64738, 0.0027251, 0.049116, 0.17081]
Predicted label: 1
Correct prediction
Energy consumption = 161.501774 pJ
sum error= 193
Actual label: 3
Output voltages: [0.0026615, 0.038706, 0.092547, 0.79388, 0.0058833, 0.0010693, 0.0066577, 0.027525, 0.68745, 0.47174]
Predicted label: 3
Correct prediction
Energy consumption = 154.610679 pJ
sum error= 193
Actual label: 7
Output voltages: [0.043857, 0.024776, 0.080413, 0.029449, 0.0015025, 0.0022829, 0.0011914, 0.79878, 0.74871, 0.42939]
Predicted label: 7
Correct prediction
Energy consumption = 144.062348 pJ
sum error= 193
Actual label: 6
Output voltages: [0.2974, 0.026351, 0.016155, 0.0025518, 0.14241, 0.33313, 0.79768, 0.017649, 0.7692, 0.0034829]
Predicted label: 6
Correct prediction
Energy consumption = 143.859868 pJ
sum error= 193
Actual label: 1
Output voltages: [0.12543, 0.79866, 0.033056, 0.42249, 0.023802, 0.0046998, 0.1558, 0.0010977, 0.38209, 0.23527]
Predicted label: 1
Correct prediction
Energy consumption = 165.422863 pJ
sum error= 193
Actual label: 3
Output voltages: [0.049822, 0.022415, 0.060529, 0.79864, 0.017463, 0.010066, 0.017821, 0.24076, 0.44768, 0.21172]
Predicted label: 3
Correct prediction
Energy consumption = 147.766018 pJ
sum error= 193
Actual label: 1
Output voltages: [0.0035281, 0.79869, 0.025203, 0.081116, 0.02177, 0.048651, 0.031224, 0.034303, 0.42059, 0.083431]
Predicted label: 1
Correct prediction
Energy consumption = 160.373150 pJ
sum error= 193
Actual label: 6
Output voltages: [0.16035, 0.080423, 0.02799, 0.08483, 0.02575, 0.14174, 0.79866, 0.010539, 0.63578, 0.0052924]
Predicted label: 6
Correct prediction
Energy consumption = 151.419074 pJ
sum error= 193
Actual label: 6
Output voltages: [0.77194, 0.016357, 0.034731, 0.0027285, 0.026584, 0.004184, 0.78871, 0.0038552, 0.13468, 0.057847]
Predicted label: 6
Correct prediction
Energy consumption = 154.725795 pJ
sum error= 193
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 375 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 375 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 375 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.042302, 0.0011318, 0.011068, 0.13832, 0.025365, 0.79628, 0.036783, 0.0034437, 0.78742, 0.042654]
Predicted label: 5
Correct prediction
Energy consumption = 155.287538 pJ
sum error= 193
Actual label: 7
Output voltages: [0.0079499, 0.25785, 0.3045, 0.064066, 0.0022026, 0.0010839, 0.0039922, 0.79599, 0.73512, 0.025965]
Predicted label: 7
Correct prediction
Energy consumption = 146.493532 pJ
sum error= 193
Actual label: 4
Output voltages: [0.018013, 0.001471, 0.21323, 0.0070937, 0.79858, 0.0010878, 0.55832, 0.033741, 0.03158, 0.047275]
Predicted label: 4
Correct prediction
Energy consumption = 155.133962 pJ
sum error= 193
Actual label: 7
Output voltages: [0.041171, 0.11102, 0.62579, 0.23507, 0.0024033, 0.0010886, 0.0011155, 0.79879, 0.38685, 0.28341]
Predicted label: 7
Correct prediction
Energy consumption = 152.097367 pJ
sum error= 193
Actual label: 5
Output voltages: [0.0068873, 0.0011117, 0.0048103, 0.31662, 0.17423, 0.79852, 0.14733, 0.038958, 0.77157, 0.15192]
Predicted label: 5
Correct prediction
Energy consumption = 146.149319 pJ
sum error= 193
Actual label: 9
Output voltages: [0.33016, 0.055182, 0.4226, 0.017956, 0.57413, 0.0016204, 0.013451, 0.014921, 0.22199, 0.77653]
Predicted label: 9
Correct prediction
Energy consumption = 159.162304 pJ
sum error= 193
Actual label: 5
Output voltages: [0.21882, 0.0011134, 0.0020153, 0.43453, 0.0085352, 0.79879, 0.014044, 0.35285, 0.78122, 0.10419]
Predicted label: 5
Correct prediction
Energy consumption = 145.455754 pJ
sum error= 193
Actual label: 8
Output voltages: [0.2392, 0.019252, 0.041383, 0.59647, 0.0024693, 0.054061, 0.30339, 0.0015325, 0.79685, 0.015012]
Predicted label: 8
Correct prediction
Energy consumption = 135.843594 pJ
sum error= 193
Actual label: 4
Output voltages: [0.011561, 0.011806, 0.093592, 0.024528, 0.79878, 0.0038519, 0.070092, 0.045044, 0.26521, 0.010825]
Predicted label: 4
Correct prediction
Energy consumption = 154.931875 pJ
sum error= 193
Actual label: 9
Output voltages: [0.25425, 0.040838, 0.050405, 0.29647, 0.35533, 0.15707, 0.13351, 0.026411, 0.11728, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 150.288080 pJ
sum error= 193
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 376 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 376 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 376 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.30569, 0.010934, 0.01496, 0.026885, 0.33921, 0.013031, 0.0012696, 0.0097014, 0.41957, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 169.658179 pJ
sum error= 193
Actual label: 1
Output voltages: [0.05385, 0.79852, 0.0079186, 0.066679, 0.0044375, 0.0014001, 0.69289, 0.010129, 0.081127, 0.054761]
Predicted label: 1
Correct prediction
Energy consumption = 165.236704 pJ
sum error= 193
Actual label: 6
Output voltages: [0.12012, 0.088457, 0.031042, 0.33288, 0.013585, 0.26051, 0.79346, 0.0021413, 0.79875, 0.0010694]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.095253 pJ
sum error= 194
Actual label: 5
Output voltages: [0.03873, 0.0068374, 0.036304, 0.30967, 0.017834, 0.79876, 0.11998, 0.0040617, 0.77333, 0.015637]
Predicted label: 5
Correct prediction
Energy consumption = 135.893986 pJ
sum error= 194
Actual label: 0
Output voltages: [0.79868, 0.15281, 0.027421, 0.010218, 0.0011256, 0.03662, 0.37863, 0.043566, 0.32557, 0.02137]
Predicted label: 0
Correct prediction
Energy consumption = 150.130392 pJ
sum error= 194
Actual label: 1
Output voltages: [0.019311, 0.79843, 0.037595, 0.29096, 0.033379, 0.0040901, 0.43953, 0.0056869, 0.021882, 0.44417]
Predicted label: 1
Correct prediction
Energy consumption = 162.744328 pJ
sum error= 194
Actual label: 3
Output voltages: [0.48841, 0.0030113, 0.226, 0.79877, 0.0293, 0.142, 0.017954, 0.0037172, 0.4286, 0.019678]
Predicted label: 3
Correct prediction
Energy consumption = 145.678993 pJ
sum error= 194
Actual label: 7
Output voltages: [0.062296, 0.061821, 0.79723, 0.22191, 0.0012278, 0.0013327, 0.0017467, 0.66014, 0.75873, 0.048385]
Predicted label: 2
Wrong prediction!
Energy consumption = 138.688858 pJ
sum error= 195
Actual label: 0
Output voltages: [0.79874, 0.0089605, 0.26454, 0.008772, 0.048794, 0.008926, 0.17031, 0.024707, 0.66983, 0.053193]
Predicted label: 0
Correct prediction
Energy consumption = 144.496372 pJ
sum error= 195
Actual label: 3
Output voltages: [0.046764, 0.24472, 0.033294, 0.79865, 0.0018921, 0.0019123, 0.00266, 0.023106, 0.25033, 0.33328]
Predicted label: 3
Correct prediction
Energy consumption = 139.434496 pJ
sum error= 195
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 377 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 377 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 377 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0083922, 0.021758, 0.13628, 0.023845, 0.7987, 0.0014411, 0.27256, 0.32277, 0.030334, 0.05686]
Predicted label: 4
Correct prediction
Energy consumption = 172.058410 pJ
sum error= 195
Actual label: 8
Output voltages: [0.046901, 0.0049608, 0.29376, 0.03579, 0.010155, 0.1101, 0.02987, 0.013506, 0.79875, 0.45436]
Predicted label: 8
Correct prediction
Energy consumption = 151.459495 pJ
sum error= 195
Actual label: 2
Output voltages: [0.24222, 0.012576, 0.79862, 0.31024, 0.001501, 0.0012764, 0.030358, 0.65118, 0.75399, 0.04649]
Predicted label: 2
Correct prediction
Energy consumption = 146.124275 pJ
sum error= 195
Actual label: 2
Output voltages: [0.25194, 0.11877, 0.79873, 0.038141, 0.010229, 0.0012995, 0.18824, 0.0028744, 0.21582, 0.027492]
Predicted label: 2
Correct prediction
Energy consumption = 131.690653 pJ
sum error= 195
Actual label: 0
Output voltages: [0.79879, 0.0325, 0.010828, 0.019814, 0.012663, 0.019452, 0.58732, 0.039706, 0.13149, 0.19056]
Predicted label: 0
Correct prediction
Energy consumption = 155.505603 pJ
sum error= 195
Actual label: 2
Output voltages: [0.62983, 0.029203, 0.79868, 0.084241, 0.050613, 0.0011451, 0.20077, 0.15071, 0.4094, 0.027845]
Predicted label: 2
Correct prediction
Energy consumption = 139.312473 pJ
sum error= 195
Actual label: 5
Output voltages: [0.0096737, 0.0020421, 0.0064229, 0.12806, 0.0061403, 0.79473, 0.035678, 0.008814, 0.77073, 0.022844]
Predicted label: 5
Correct prediction
Energy consumption = 148.793083 pJ
sum error= 195
Actual label: 1
Output voltages: [0.028946, 0.7987, 0.0012911, 0.37444, 0.0050323, 0.06111, 0.24296, 0.0027789, 0.24764, 0.16745]
Predicted label: 1
Correct prediction
Energy consumption = 161.882623 pJ
sum error= 195
Actual label: 5
Output voltages: [0.7809, 0.0090241, 0.40449, 0.52759, 0.0011353, 0.44207, 0.18965, 0.050402, 0.73867, 0.0067275]
Predicted label: 0
Wrong prediction!
Energy consumption = 152.122002 pJ
sum error= 196
Actual label: 1
Output voltages: [0.038928, 0.79839, 0.097212, 0.21157, 0.12138, 0.0089008, 0.35344, 0.027791, 0.0060618, 0.40085]
Predicted label: 1
Correct prediction
Energy consumption = 165.078602 pJ
sum error= 196
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 378 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 378 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 378 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.03855, 0.0064671, 0.1641, 0.011325, 0.69906, 0.34739, 0.78355, 0.0014385, 0.59519, 0.0016471]
Predicted label: 6
Wrong prediction!
Energy consumption = 171.546553 pJ
sum error= 197
Actual label: 8
Output voltages: [0.045627, 0.079631, 0.19212, 0.74023, 0.012978, 0.0035832, 0.11017, 0.0048373, 0.79738, 0.17]
Predicted label: 8
Correct prediction
Energy consumption = 163.799280 pJ
sum error= 197
Actual label: 8
Output voltages: [0.23351, 0.0010769, 0.78794, 0.3872, 0.0064004, 0.0020653, 0.0041107, 0.12172, 0.79689, 0.0056628]
Predicted label: 8
Correct prediction
Energy consumption = 150.894313 pJ
sum error= 197
Actual label: 9
Output voltages: [0.44096, 0.0094568, 0.014705, 0.070621, 0.28437, 0.2025, 0.046017, 0.045164, 0.028161, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.818982 pJ
sum error= 197
Actual label: 1
Output voltages: [0.011715, 0.79845, 0.062063, 0.055835, 0.025081, 0.0016837, 0.70083, 0.0023142, 0.061835, 0.1896]
Predicted label: 1
Correct prediction
Energy consumption = 160.673476 pJ
sum error= 197
Actual label: 2
Output voltages: [0.26304, 0.55274, 0.79877, 0.014692, 0.0026301, 0.0013275, 0.04009, 0.39592, 0.2976, 0.031872]
Predicted label: 2
Correct prediction
Energy consumption = 150.890437 pJ
sum error= 197
Actual label: 1
Output voltages: [0.1675, 0.79863, 0.15503, 0.174, 0.0076495, 0.0024031, 0.039728, 0.0094512, 0.054811, 0.038613]
Predicted label: 1
Correct prediction
Energy consumption = 154.519428 pJ
sum error= 197
Actual label: 3
Output voltages: [0.34421, 0.0084719, 0.56891, 0.79689, 0.0074089, 0.0015703, 0.0074712, 0.0073981, 0.76862, 0.026593]
Predicted label: 3
Correct prediction
Energy consumption = 149.384452 pJ
sum error= 197
Actual label: 5
Output voltages: [0.16331, 0.001353, 0.0042415, 0.22984, 0.026028, 0.79877, 0.037584, 0.028095, 0.77785, 0.062749]
Predicted label: 5
Correct prediction
Energy consumption = 142.337268 pJ
sum error= 197
Actual label: 1
Output voltages: [0.0074068, 0.79852, 0.048061, 0.099992, 0.048299, 0.0058885, 0.41901, 0.010315, 0.2994, 0.080624]
Predicted label: 1
Correct prediction
Energy consumption = 163.200844 pJ
sum error= 197
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 379 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 379 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 379 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7985, 0.17761, 0.021868, 0.014781, 0.011637, 0.03223, 0.69321, 0.0098783, 0.38803, 0.063039]
Predicted label: 0
Correct prediction
Energy consumption = 165.227461 pJ
sum error= 197
Actual label: 9
Output voltages: [0.58988, 0.0046614, 0.018034, 0.015387, 0.21395, 0.027267, 0.027435, 0.023117, 0.022451, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 148.583531 pJ
sum error= 197
Actual label: 4
Output voltages: [0.054703, 0.0085962, 0.2228, 0.01456, 0.79871, 0.020642, 0.11359, 0.112, 0.027392, 0.16404]
Predicted label: 4
Correct prediction
Energy consumption = 151.997817 pJ
sum error= 197
Actual label: 4
Output voltages: [0.0045487, 0.011308, 0.60579, 0.034549, 0.79867, 0.0012251, 0.24901, 0.11632, 0.013658, 0.20427]
Predicted label: 4
Correct prediction
Energy consumption = 146.748254 pJ
sum error= 197
Actual label: 8
Output voltages: [0.012558, 0.24728, 0.014059, 0.045775, 0.0031867, 0.018041, 0.0047878, 0.042585, 0.79879, 0.51494]
Predicted label: 8
Correct prediction
Energy consumption = 151.727643 pJ
sum error= 197
Actual label: 3
Output voltages: [0.021691, 0.078525, 0.098147, 0.79876, 0.03526, 0.0035074, 0.0042058, 0.31879, 0.47761, 0.090098]
Predicted label: 3
Correct prediction
Energy consumption = 143.381690 pJ
sum error= 197
Actual label: 2
Output voltages: [0.022191, 0.74818, 0.7802, 0.19866, 0.0047361, 0.0013436, 0.45509, 0.001487, 0.40795, 0.062077]
Predicted label: 2
Correct prediction
Energy consumption = 148.394242 pJ
sum error= 197
Actual label: 5
Output voltages: [0.033566, 0.0012483, 0.0017667, 0.3606, 0.020163, 0.79875, 0.071906, 0.022515, 0.71413, 0.092434]
Predicted label: 5
Correct prediction
Energy consumption = 150.791016 pJ
sum error= 197
Actual label: 9
Output voltages: [0.35699, 0.0093645, 0.02723, 0.011212, 0.070653, 0.0028516, 0.0015744, 0.015077, 0.69925, 0.7964]
Predicted label: 9
Correct prediction
Energy consumption = 148.756436 pJ
sum error= 197
Actual label: 7
Output voltages: [0.50053, 0.049735, 0.76964, 0.46044, 0.0010905, 0.0012222, 0.0017229, 0.78607, 0.53838, 0.035475]
Predicted label: 7
Correct prediction
Energy consumption = 141.618716 pJ
sum error= 197
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 380 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 380 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 380 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.054901, 0.035166, 0.027144, 0.19197, 0.037598, 0.39113, 0.79296, 0.024025, 0.79335, 0.0012803]
Predicted label: 8
Wrong prediction!
Energy consumption = 164.570485 pJ
sum error= 198
Actual label: 6
Output voltages: [0.19193, 0.20884, 0.22435, 0.0079946, 0.36666, 0.16249, 0.79878, 0.0010659, 0.12174, 0.0086463]
Predicted label: 6
Correct prediction
Energy consumption = 153.186474 pJ
sum error= 198
Actual label: 2
Output voltages: [0.37674, 0.016948, 0.79873, 0.084913, 0.0059587, 0.0011831, 0.044452, 0.12696, 0.67371, 0.0090778]
Predicted label: 2
Correct prediction
Energy consumption = 148.435480 pJ
sum error= 198
Actual label: 0
Output voltages: [0.79812, 0.021667, 0.076511, 0.012495, 0.030119, 0.0013353, 0.57445, 0.015457, 0.033831, 0.52648]
Predicted label: 0
Correct prediction
Energy consumption = 158.316409 pJ
sum error= 198
Actual label: 0
Output voltages: [0.79877, 0.35212, 0.027811, 0.039165, 0.0012072, 0.030388, 0.53415, 0.018269, 0.31936, 0.18765]
Predicted label: 0
Correct prediction
Energy consumption = 146.476978 pJ
sum error= 198
Actual label: 0
Output voltages: [0.79878, 0.033061, 0.023441, 0.0090606, 0.035295, 0.012229, 0.73692, 0.031584, 0.037115, 0.30203]
Predicted label: 0
Correct prediction
Energy consumption = 151.161101 pJ
sum error= 198
Actual label: 5
Output voltages: [0.011492, 0.024912, 0.001272, 0.14821, 0.46441, 0.77129, 0.047356, 0.4049, 0.66582, 0.12326]
Predicted label: 5
Correct prediction
Energy consumption = 148.479502 pJ
sum error= 198
Actual label: 8
Output voltages: [0.030162, 0.020009, 0.36943, 0.0341, 0.0093594, 0.014877, 0.011473, 0.023826, 0.79862, 0.025431]
Predicted label: 8
Correct prediction
Energy consumption = 140.305411 pJ
sum error= 198
Actual label: 7
Output voltages: [0.13529, 0.29773, 0.50301, 0.74968, 0.0010759, 0.002864, 0.0012889, 0.007665, 0.77634, 0.42167]
Predicted label: 8
Wrong prediction!
Energy consumption = 139.751912 pJ
sum error= 199
Actual label: 1
Output voltages: [0.042685, 0.79859, 0.001466, 0.031686, 0.3553, 0.0074649, 0.34301, 0.0054142, 0.027954, 0.05836]
Predicted label: 1
Correct prediction
Energy consumption = 153.087403 pJ
sum error= 199
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 381 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 381 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 381 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.042807, 0.0010672, 0.0018818, 0.42768, 0.021681, 0.7987, 0.12277, 0.019528, 0.72645, 0.22825]
Predicted label: 5
Correct prediction
Energy consumption = 161.907809 pJ
sum error= 199
Actual label: 2
Output voltages: [0.54575, 0.0030108, 0.70728, 0.78778, 0.022828, 0.0011264, 0.01684, 0.032028, 0.52641, 0.0042807]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.120140 pJ
sum error= 200
Actual label: 3
Output voltages: [0.71445, 0.019036, 0.14943, 0.79873, 0.04146, 0.018757, 0.0036566, 0.012612, 0.39381, 0.012134]
Predicted label: 3
Correct prediction
Energy consumption = 140.667194 pJ
sum error= 200
Actual label: 8
Output voltages: [0.22884, 0.013494, 0.33502, 0.068469, 0.0059877, 0.62159, 0.02994, 0.03252, 0.79875, 0.012252]
Predicted label: 8
Correct prediction
Energy consumption = 147.830731 pJ
sum error= 200
Actual label: 5
Output voltages: [0.039926, 0.0010761, 0.0031786, 0.22654, 0.0076589, 0.7972, 0.15687, 0.0090321, 0.78736, 0.049745]
Predicted label: 5
Correct prediction
Energy consumption = 141.060065 pJ
sum error= 200
Actual label: 1
Output voltages: [0.0021448, 0.79856, 0.089559, 0.074179, 0.027656, 0.0013155, 0.29423, 0.0028834, 0.39635, 0.044084]
Predicted label: 1
Correct prediction
Energy consumption = 167.648641 pJ
sum error= 200
Actual label: 8
Output voltages: [0.034021, 0.026391, 0.034938, 0.36654, 0.023602, 0.39453, 0.10738, 0.055403, 0.79875, 0.014797]
Predicted label: 8
Correct prediction
Energy consumption = 152.443252 pJ
sum error= 200
Actual label: 2
Output voltages: [0.24906, 0.016608, 0.79874, 0.036092, 0.45459, 0.0010755, 0.080639, 0.18772, 0.48938, 0.0037957]
Predicted label: 2
Correct prediction
Energy consumption = 140.530432 pJ
sum error= 200
Actual label: 0
Output voltages: [0.74316, 0.025343, 0.72034, 0.005259, 0.014136, 0.001499, 0.79164, 0.0011489, 0.59822, 0.2101]
Predicted label: 6
Wrong prediction!
Energy consumption = 144.259291 pJ
sum error= 201
Actual label: 4
Output voltages: [0.017711, 0.0022695, 0.024227, 0.0048444, 0.79875, 0.019077, 0.40693, 0.027469, 0.050837, 0.023677]
Predicted label: 4
Correct prediction
Energy consumption = 152.196231 pJ
sum error= 201
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 382 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 382 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 382 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.7577, 0.0018885, 0.22458, 0.01547, 0.052688, 0.0064898, 0.04603, 0.0010722, 0.20681, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 162.499852 pJ
sum error= 201
Actual label: 9
Output voltages: [0.0031122, 0.0042773, 0.058328, 0.064431, 0.79804, 0.037587, 0.23063, 0.012942, 0.028067, 0.74354]
Predicted label: 4
Wrong prediction!
Energy consumption = 145.374887 pJ
sum error= 202
Actual label: 6
Output voltages: [0.056081, 0.14491, 0.24632, 0.0069884, 0.077824, 0.27097, 0.7987, 0.0053861, 0.42167, 0.010827]
Predicted label: 6
Correct prediction
Energy consumption = 144.145643 pJ
sum error= 202
Actual label: 2
Output voltages: [0.50749, 0.1025, 0.79869, 0.045151, 0.023964, 0.0011229, 0.22913, 0.031284, 0.2758, 0.017968]
Predicted label: 2
Correct prediction
Energy consumption = 145.684059 pJ
sum error= 202
Actual label: 3
Output voltages: [0.055093, 0.034654, 0.041653, 0.79876, 0.0030519, 0.0018134, 0.0097749, 0.064643, 0.44881, 0.069357]
Predicted label: 3
Correct prediction
Energy consumption = 140.131681 pJ
sum error= 202
Actual label: 3
Output voltages: [0.1377, 0.0047249, 0.014946, 0.79866, 0.31257, 0.45788, 0.34396, 0.019617, 0.48567, 0.054494]
Predicted label: 3
Correct prediction
Energy consumption = 140.736395 pJ
sum error= 202
Actual label: 5
Output voltages: [0.018247, 0.001081, 0.0013395, 0.031727, 0.17054, 0.79877, 0.4364, 0.01987, 0.78436, 0.024282]
Predicted label: 5
Correct prediction
Energy consumption = 143.067057 pJ
sum error= 202
Actual label: 6
Output voltages: [0.42251, 0.038512, 0.28662, 0.0011086, 0.033569, 0.02405, 0.79874, 0.0012809, 0.32576, 0.023975]
Predicted label: 6
Correct prediction
Energy consumption = 144.040512 pJ
sum error= 202
Actual label: 4
Output voltages: [0.0036241, 0.0084826, 0.33197, 0.028547, 0.79864, 0.015154, 0.16746, 0.042971, 0.087733, 0.040023]
Predicted label: 4
Correct prediction
Energy consumption = 156.348862 pJ
sum error= 202
Actual label: 8
Output voltages: [0.036413, 0.0092882, 0.047625, 0.16975, 0.0014217, 0.040469, 0.0090788, 0.0042704, 0.79878, 0.26638]
Predicted label: 8
Correct prediction
Energy consumption = 147.162773 pJ
sum error= 202
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 383 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 383 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 383 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79874, 0.023732, 0.013471, 0.030668, 0.020858, 0.043519, 0.28826, 0.010476, 0.17367, 0.042209]
Predicted label: 0
Correct prediction
Energy consumption = 176.513634 pJ
sum error= 202
Actual label: 9
Output voltages: [0.029475, 0.0039463, 0.17505, 0.056247, 0.079564, 0.0027023, 0.0021249, 0.010108, 0.78603, 0.69958]
Predicted label: 8
Wrong prediction!
Energy consumption = 161.163602 pJ
sum error= 203
Actual label: 2
Output voltages: [0.65198, 0.060125, 0.79878, 0.076077, 0.0074801, 0.0012994, 0.3838, 0.2865, 0.47691, 0.14447]
Predicted label: 2
Correct prediction
Energy consumption = 148.572849 pJ
sum error= 203
Actual label: 8
Output voltages: [0.013353, 0.14817, 0.17842, 0.74624, 0.0025822, 0.0010663, 0.016397, 0.31649, 0.79867, 0.018276]
Predicted label: 8
Correct prediction
Energy consumption = 152.722653 pJ
sum error= 203
Actual label: 3
Output voltages: [0.34881, 0.011825, 0.58217, 0.79833, 0.015744, 0.0011251, 0.0059363, 0.0014895, 0.63279, 0.021654]
Predicted label: 3
Correct prediction
Energy consumption = 144.059053 pJ
sum error= 203
Actual label: 6
Output voltages: [0.33407, 0.045927, 0.32524, 0.013485, 0.39971, 0.30579, 0.79874, 0.0045009, 0.18933, 0.045589]
Predicted label: 6
Correct prediction
Energy consumption = 149.021385 pJ
sum error= 203
Actual label: 7
Output voltages: [0.038303, 0.009331, 0.0011661, 0.13038, 0.53721, 0.76461, 0.002811, 0.79378, 0.53202, 0.39829]
Predicted label: 7
Correct prediction
Energy consumption = 157.167902 pJ
sum error= 203
Actual label: 5
Output voltages: [0.058284, 0.0017962, 0.0010676, 0.5552, 0.027398, 0.79867, 0.050625, 0.13428, 0.77341, 0.01946]
Predicted label: 5
Correct prediction
Energy consumption = 142.461906 pJ
sum error= 203
Actual label: 7
Output voltages: [0.0030226, 0.0066404, 0.015417, 0.31441, 0.25976, 0.0038887, 0.0021248, 0.16996, 0.67939, 0.41319]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.901757 pJ
sum error= 204
Actual label: 2
Output voltages: [0.037517, 0.042439, 0.79839, 0.26541, 0.023083, 0.0011986, 0.092136, 0.0036397, 0.74979, 0.086999]
Predicted label: 2
Correct prediction
Energy consumption = 143.163665 pJ
sum error= 204
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 384 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 384 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 384 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.63712, 0.0028078, 0.32651, 0.0093877, 0.43959, 0.015697, 0.047417, 0.010699, 0.02674, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 171.073428 pJ
sum error= 204
Actual label: 4
Output voltages: [0.0035673, 0.082955, 0.12247, 0.0062895, 0.79861, 0.041448, 0.28131, 0.032684, 0.03131, 0.1041]
Predicted label: 4
Correct prediction
Energy consumption = 151.960433 pJ
sum error= 204
Actual label: 9
Output voltages: [0.17918, 0.015247, 0.018856, 0.0063063, 0.40414, 0.025859, 0.012992, 0.01592, 0.46335, 0.79817]
Predicted label: 9
Correct prediction
Energy consumption = 148.201568 pJ
sum error= 204
Actual label: 1
Output voltages: [0.044046, 0.79853, 0.17179, 0.22889, 0.012398, 0.0010892, 0.30035, 0.011386, 0.19231, 0.032847]
Predicted label: 1
Correct prediction
Energy consumption = 167.334301 pJ
sum error= 204
Actual label: 2
Output voltages: [0.47622, 0.050043, 0.79876, 0.39016, 0.023368, 0.0011759, 0.03878, 0.39296, 0.16771, 0.029532]
Predicted label: 2
Correct prediction
Energy consumption = 146.361142 pJ
sum error= 204
Actual label: 8
Output voltages: [0.038714, 0.043014, 0.49896, 0.068339, 0.022853, 0.024488, 0.034255, 0.0055034, 0.79873, 0.14987]
Predicted label: 8
Correct prediction
Energy consumption = 149.860496 pJ
sum error= 204
Actual label: 6
Output voltages: [0.33747, 0.39567, 0.31053, 0.0011159, 0.23083, 0.13945, 0.79854, 0.0088383, 0.020643, 0.19769]
Predicted label: 6
Correct prediction
Energy consumption = 162.238455 pJ
sum error= 204
Actual label: 0
Output voltages: [0.79818, 0.20378, 0.35928, 0.05715, 0.0012937, 0.0088337, 0.22996, 0.070098, 0.3154, 0.017879]
Predicted label: 0
Correct prediction
Energy consumption = 148.835020 pJ
sum error= 204
Actual label: 7
Output voltages: [0.25063, 0.0046568, 0.64491, 0.73963, 0.24806, 0.0011919, 0.0029665, 0.72497, 0.52432, 0.058005]
Predicted label: 3
Wrong prediction!
Energy consumption = 151.444940 pJ
sum error= 205
Actual label: 0
Output voltages: [0.79853, 0.068792, 0.0121, 0.0023564, 0.0040007, 0.15135, 0.36788, 0.0026326, 0.34599, 0.28168]
Predicted label: 0
Correct prediction
Energy consumption = 150.576114 pJ
sum error= 205
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 385 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 385 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 385 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.0024911, 0.042873, 0.15933, 0.0038158, 0.79843, 0.0113, 0.17823, 0.0045742, 0.052502, 0.75699]
Predicted label: 4
Wrong prediction!
Energy consumption = 172.377392 pJ
sum error= 206
Actual label: 1
Output voltages: [0.067768, 0.79841, 0.010962, 0.024397, 0.040935, 0.066562, 0.60079, 0.017688, 0.15398, 0.045121]
Predicted label: 1
Correct prediction
Energy consumption = 166.808248 pJ
sum error= 206
Actual label: 1
Output voltages: [0.2516, 0.79872, 0.036063, 0.087876, 0.23369, 0.028072, 0.39532, 0.0016955, 0.032976, 0.024249]
Predicted label: 1
Correct prediction
Energy consumption = 149.576988 pJ
sum error= 206
Actual label: 6
Output voltages: [0.27174, 0.073183, 0.2147, 0.058771, 0.019622, 0.64441, 0.7792, 0.0011343, 0.75694, 0.0031366]
Predicted label: 6
Correct prediction
Energy consumption = 145.885440 pJ
sum error= 206
Actual label: 7
Output voltages: [0.060513, 0.018475, 0.042047, 0.36332, 0.003545, 0.012092, 0.0012443, 0.79879, 0.30596, 0.73359]
Predicted label: 7
Correct prediction
Energy consumption = 156.565537 pJ
sum error= 206
Actual label: 5
Output voltages: [0.040048, 0.017667, 0.0012752, 0.037896, 0.02986, 0.79864, 0.13343, 0.0047643, 0.79163, 0.0014455]
Predicted label: 5
Correct prediction
Energy consumption = 151.706278 pJ
sum error= 206
Actual label: 9
Output voltages: [0.13734, 0.0015323, 0.0046362, 0.447, 0.079599, 0.088151, 0.0011832, 0.64624, 0.18119, 0.66541]
Predicted label: 9
Correct prediction
Energy consumption = 157.587501 pJ
sum error= 206
Actual label: 9
Output voltages: [0.058, 0.012527, 0.038227, 0.03623, 0.015014, 0.0024173, 0.0063528, 0.07491, 0.73978, 0.7963]
Predicted label: 9
Correct prediction
Energy consumption = 147.575487 pJ
sum error= 206
Actual label: 1
Output voltages: [0.027589, 0.79855, 0.03876, 0.0067107, 0.25753, 0.017179, 0.5209, 0.0037215, 0.46627, 0.049014]
Predicted label: 1
Correct prediction
Energy consumption = 159.121705 pJ
sum error= 206
Actual label: 9
Output voltages: [0.1967, 0.0013824, 0.60932, 0.33394, 0.61403, 0.0017789, 0.0050987, 0.012985, 0.036469, 0.79299]
Predicted label: 9
Correct prediction
Energy consumption = 150.762259 pJ
sum error= 206
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 386 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 386 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 386 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.020762, 0.0010943, 0.012867, 0.061234, 0.033026, 0.79823, 0.41086, 0.02246, 0.79295, 0.023771]
Predicted label: 5
Correct prediction
Energy consumption = 157.846718 pJ
sum error= 206
Actual label: 9
Output voltages: [0.30848, 0.012676, 0.044832, 0.089755, 0.054811, 0.019427, 0.0018034, 0.071957, 0.11689, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 158.488942 pJ
sum error= 206
Actual label: 2
Output voltages: [0.531, 0.44, 0.79818, 0.17234, 0.0067849, 0.0013081, 0.028236, 0.26074, 0.02013, 0.02567]
Predicted label: 2
Correct prediction
Energy consumption = 150.722300 pJ
sum error= 206
Actual label: 5
Output voltages: [0.008559, 0.001066, 0.0061148, 0.06814, 0.019198, 0.79693, 0.50416, 0.0013649, 0.79307, 0.030783]
Predicted label: 5
Correct prediction
Energy consumption = 154.904092 pJ
sum error= 206
Actual label: 0
Output voltages: [0.79871, 0.031803, 0.028406, 0.031283, 0.048053, 0.015996, 0.6981, 0.041576, 0.33833, 0.024771]
Predicted label: 0
Correct prediction
Energy consumption = 151.098850 pJ
sum error= 206
Actual label: 4
Output voltages: [0.0084876, 0.0028293, 0.18776, 0.033263, 0.79863, 0.0063655, 0.11743, 0.043757, 0.050206, 0.051131]
Predicted label: 4
Correct prediction
Energy consumption = 160.088476 pJ
sum error= 206
Actual label: 1
Output voltages: [0.021782, 0.7986, 0.0013944, 0.061044, 0.016667, 0.019838, 0.20436, 0.019882, 0.052821, 0.21289]
Predicted label: 1
Correct prediction
Energy consumption = 167.811044 pJ
sum error= 206
Actual label: 0
Output voltages: [0.79878, 0.033609, 0.098891, 0.012008, 0.0064757, 0.027321, 0.65633, 0.021739, 0.27, 0.0094014]
Predicted label: 0
Correct prediction
Energy consumption = 149.772756 pJ
sum error= 206
Actual label: 8
Output voltages: [0.0076063, 0.138, 0.1259, 0.24704, 0.0039596, 0.0080736, 0.020774, 0.01273, 0.79873, 0.16508]
Predicted label: 8
Correct prediction
Energy consumption = 153.545283 pJ
sum error= 206
Actual label: 9
Output voltages: [0.014523, 0.0058076, 0.054546, 0.14197, 0.79878, 0.0051539, 0.0047746, 0.015218, 0.039238, 0.41953]
Predicted label: 4
Wrong prediction!
Energy consumption = 147.492658 pJ
sum error= 207
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 387 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 387 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 387 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79861, 0.053922, 0.037177, 0.019029, 0.0087547, 0.001648, 0.51452, 0.019531, 0.10771, 0.10188]
Predicted label: 0
Correct prediction
Energy consumption = 164.162850 pJ
sum error= 207
Actual label: 8
Output voltages: [0.037479, 0.016344, 0.31831, 0.058599, 0.0017079, 0.019761, 0.012299, 0.060968, 0.79877, 0.041955]
Predicted label: 8
Correct prediction
Energy consumption = 149.799341 pJ
sum error= 207
Actual label: 9
Output voltages: [0.29061, 0.012702, 0.031262, 0.17323, 0.24933, 0.010721, 0.0074744, 0.010943, 0.16516, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 154.380183 pJ
sum error= 207
Actual label: 8
Output voltages: [0.080948, 0.029362, 0.71244, 0.042894, 0.011556, 0.017659, 0.18266, 0.0070642, 0.79879, 0.11671]
Predicted label: 8
Correct prediction
Energy consumption = 140.729095 pJ
sum error= 207
Actual label: 9
Output voltages: [0.27696, 0.060663, 0.032718, 0.14867, 0.10322, 0.0098498, 0.0035605, 0.014674, 0.34071, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 148.261096 pJ
sum error= 207
Actual label: 4
Output voltages: [0.0014945, 0.0066011, 0.31149, 0.0098483, 0.79865, 0.020127, 0.18326, 0.015742, 0.060081, 0.14566]
Predicted label: 4
Correct prediction
Energy consumption = 144.409871 pJ
sum error= 207
Actual label: 2
Output voltages: [0.60787, 0.48585, 0.7958, 0.19194, 0.0052246, 0.0011514, 0.49926, 0.027574, 0.62379, 0.0045245]
Predicted label: 2
Correct prediction
Energy consumption = 154.140130 pJ
sum error= 207
Actual label: 5
Output voltages: [0.30342, 0.0010911, 0.0011413, 0.58668, 0.020829, 0.79872, 0.039368, 0.053152, 0.65666, 0.026026]
Predicted label: 5
Correct prediction
Energy consumption = 140.910567 pJ
sum error= 207
Actual label: 7
Output voltages: [0.12259, 0.3044, 0.031205, 0.047421, 0.0013088, 0.0026967, 0.0011126, 0.79879, 0.40953, 0.65618]
Predicted label: 7
Correct prediction
Energy consumption = 162.534240 pJ
sum error= 207
Actual label: 9
Output voltages: [0.77408, 0.0015953, 0.044418, 0.31977, 0.5782, 0.03818, 0.0083883, 0.0091104, 0.022284, 0.77214]
Predicted label: 0
Wrong prediction!
Energy consumption = 146.412370 pJ
sum error= 208
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 388 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 388 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 388 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.013424, 0.030655, 0.20353, 0.023892, 0.012862, 0.022602, 0.029446, 0.0014682, 0.79875, 0.415]
Predicted label: 8
Correct prediction
Energy consumption = 165.927743 pJ
sum error= 208
Actual label: 9
Output voltages: [0.16053, 0.0023964, 0.023678, 0.016353, 0.013369, 0.067601, 0.0089403, 0.075832, 0.66619, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 154.776430 pJ
sum error= 208
Actual label: 8
Output voltages: [0.019463, 0.018499, 0.031772, 0.21295, 0.0069257, 0.095906, 0.013707, 0.0036864, 0.79875, 0.31636]
Predicted label: 8
Correct prediction
Energy consumption = 150.392222 pJ
sum error= 208
Actual label: 0
Output voltages: [0.79879, 0.017586, 0.10481, 0.004715, 0.018331, 0.032588, 0.32289, 0.021878, 0.020575, 0.012566]
Predicted label: 0
Correct prediction
Energy consumption = 149.314245 pJ
sum error= 208
Actual label: 9
Output voltages: [0.63272, 0.0067676, 0.30762, 0.018437, 0.022345, 0.0058799, 0.03807, 0.0044786, 0.23834, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 146.241150 pJ
sum error= 208
Actual label: 9
Output voltages: [0.52495, 0.002314, 0.26606, 0.036301, 0.42923, 0.023517, 0.017462, 0.0080938, 0.21507, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 143.229437 pJ
sum error= 208
Actual label: 6
Output voltages: [0.050014, 0.32367, 0.16608, 0.016734, 0.09513, 0.27472, 0.79862, 0.0014817, 0.15859, 0.042084]
Predicted label: 6
Correct prediction
Energy consumption = 144.887336 pJ
sum error= 208
Actual label: 8
Output voltages: [0.021555, 0.023288, 0.13173, 0.44057, 0.005013, 0.024929, 0.30003, 0.0036772, 0.79877, 0.11068]
Predicted label: 8
Correct prediction
Energy consumption = 150.783858 pJ
sum error= 208
Actual label: 9
Output voltages: [0.41698, 0.015116, 0.16985, 0.027747, 0.47527, 0.026194, 0.054296, 0.0026661, 0.050329, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 157.771868 pJ
sum error= 208
Actual label: 9
Output voltages: [0.29805, 0.0258, 0.0075128, 0.032437, 0.13723, 0.015426, 0.024608, 0.013842, 0.59246, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 134.737689 pJ
sum error= 208
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 389 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 389 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 389 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.37358, 0.0010883, 0.0010676, 0.64998, 0.026701, 0.7977, 0.056156, 0.0015279, 0.78175, 0.0042639]
Predicted label: 5
Correct prediction
Energy consumption = 160.780440 pJ
sum error= 208
Actual label: 9
Output voltages: [0.21935, 0.01835, 0.01347, 0.026233, 0.039392, 0.010258, 0.001088, 0.00866, 0.63113, 0.79815]
Predicted label: 9
Correct prediction
Energy consumption = 152.488363 pJ
sum error= 208
Actual label: 8
Output voltages: [0.0068236, 0.025846, 0.17587, 0.20394, 0.010408, 0.033019, 0.12756, 0.020284, 0.79874, 0.03224]
Predicted label: 8
Correct prediction
Energy consumption = 146.969912 pJ
sum error= 208
Actual label: 5
Output voltages: [0.56532, 0.0021579, 0.014684, 0.37332, 0.039583, 0.62185, 0.79365, 0.0051143, 0.020208, 0.028956]
Predicted label: 6
Wrong prediction!
Energy consumption = 149.339049 pJ
sum error= 209
Actual label: 1
Output voltages: [0.025334, 0.79869, 0.020772, 0.45188, 0.011912, 0.0010857, 0.25814, 0.0034836, 0.54798, 0.28942]
Predicted label: 1
Correct prediction
Energy consumption = 163.948771 pJ
sum error= 209
Actual label: 0
Output voltages: [0.79757, 0.15443, 0.031947, 0.19741, 0.022376, 0.017808, 0.71827, 0.030566, 0.5918, 0.032241]
Predicted label: 0
Correct prediction
Energy consumption = 158.557253 pJ
sum error= 209
Actual label: 3
Output voltages: [0.20547, 0.033812, 0.064294, 0.79865, 0.0078587, 0.0085197, 0.0045551, 0.13393, 0.44142, 0.19593]
Predicted label: 3
Correct prediction
Energy consumption = 143.121508 pJ
sum error= 209
Actual label: 3
Output voltages: [0.033278, 0.41831, 0.29947, 0.79879, 0.0057354, 0.0012246, 0.0063006, 0.091484, 0.20935, 0.025915]
Predicted label: 3
Correct prediction
Energy consumption = 146.532051 pJ
sum error= 209
Actual label: 5
Output voltages: [0.015759, 0.0010742, 0.01074, 0.42349, 0.020516, 0.79677, 0.0055899, 0.067761, 0.77171, 0.22663]
Predicted label: 5
Correct prediction
Energy consumption = 144.930519 pJ
sum error= 209
Actual label: 2
Output voltages: [0.27766, 0.002284, 0.78028, 0.74577, 0.008916, 0.0012113, 0.04062, 0.042476, 0.70163, 0.023208]
Predicted label: 2
Correct prediction
Energy consumption = 150.194906 pJ
sum error= 209
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 390 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 390 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 390 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.025319, 0.79862, 0.016551, 0.16731, 0.10754, 0.0025103, 0.56116, 0.0010663, 0.33694, 0.12359]
Predicted label: 1
Correct prediction
Energy consumption = 184.559993 pJ
sum error= 209
Actual label: 6
Output voltages: [0.2606, 0.10281, 0.27521, 0.0013009, 0.14487, 0.2275, 0.79874, 0.0064159, 0.30105, 0.012031]
Predicted label: 6
Correct prediction
Energy consumption = 146.707721 pJ
sum error= 209
Actual label: 5
Output voltages: [0.024041, 0.0011018, 0.030275, 0.55667, 0.063755, 0.79563, 0.05197, 0.01611, 0.79293, 0.048084]
Predicted label: 5
Correct prediction
Energy consumption = 144.848240 pJ
sum error= 209
Actual label: 0
Output voltages: [0.79876, 0.041, 0.027879, 0.018581, 0.076917, 0.00871, 0.636, 0.016061, 0.048079, 0.14711]
Predicted label: 0
Correct prediction
Energy consumption = 155.017437 pJ
sum error= 209
Actual label: 2
Output voltages: [0.19903, 0.022701, 0.79879, 0.13445, 0.016339, 0.0013276, 0.16034, 0.24452, 0.61016, 0.053309]
Predicted label: 2
Correct prediction
Energy consumption = 150.221748 pJ
sum error= 209
Actual label: 8
Output voltages: [0.0065143, 0.014662, 0.037952, 0.75313, 0.003662, 0.0033309, 0.02441, 0.017078, 0.79772, 0.058725]
Predicted label: 8
Correct prediction
Energy consumption = 150.781087 pJ
sum error= 209
Actual label: 1
Output voltages: [0.02114, 0.76362, 0.50256, 0.79765, 0.001883, 0.0046212, 0.022781, 0.01063, 0.059286, 0.015377]
Predicted label: 3
Wrong prediction!
Energy consumption = 144.510580 pJ
sum error= 210
Actual label: 5
Output voltages: [0.050799, 0.0020887, 0.0013883, 0.32608, 0.021736, 0.79869, 0.36046, 0.081405, 0.67577, 0.015923]
Predicted label: 5
Correct prediction
Energy consumption = 140.319345 pJ
sum error= 210
Actual label: 6
Output voltages: [0.073159, 0.029592, 0.22602, 0.0049472, 0.29524, 0.15193, 0.79876, 0.0039619, 0.64476, 0.018218]
Predicted label: 6
Correct prediction
Energy consumption = 146.025412 pJ
sum error= 210
Actual label: 2
Output voltages: [0.23735, 0.5486, 0.79741, 0.016034, 0.0022043, 0.0012509, 0.012729, 0.78087, 0.2913, 0.029202]
Predicted label: 2
Correct prediction
Energy consumption = 151.694327 pJ
sum error= 210
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 391 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 391 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 391 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.72846, 0.023119, 0.036742, 0.79861, 0.027187, 0.018833, 0.015238, 0.011645, 0.44754, 0.12065]
Predicted label: 3
Correct prediction
Energy consumption = 165.554990 pJ
sum error= 210
Actual label: 0
Output voltages: [0.79871, 0.02847, 0.049826, 0.019246, 0.040305, 0.017694, 0.44743, 0.035282, 0.023018, 0.16295]
Predicted label: 0
Correct prediction
Energy consumption = 142.154403 pJ
sum error= 210
Actual label: 2
Output voltages: [0.19396, 0.0060615, 0.79867, 0.041578, 0.066771, 0.0012015, 0.068011, 0.055807, 0.36778, 0.0061681]
Predicted label: 2
Correct prediction
Energy consumption = 141.748224 pJ
sum error= 210
Actual label: 2
Output voltages: [0.71432, 0.0022036, 0.79859, 0.056229, 0.022087, 0.0010774, 0.014466, 0.028994, 0.51647, 0.023884]
Predicted label: 2
Correct prediction
Energy consumption = 135.253137 pJ
sum error= 210
Actual label: 6
Output voltages: [0.019544, 0.035983, 0.21243, 0.0020324, 0.2035, 0.17948, 0.7987, 0.011694, 0.37304, 0.0048613]
Predicted label: 6
Correct prediction
Energy consumption = 139.340361 pJ
sum error= 210
Actual label: 4
Output voltages: [0.02197, 0.020498, 0.16387, 0.015727, 0.79875, 0.001091, 0.043841, 0.034514, 0.017253, 0.027533]
Predicted label: 4
Correct prediction
Energy consumption = 152.867753 pJ
sum error= 210
Actual label: 3
Output voltages: [0.037986, 0.022502, 0.024323, 0.79875, 0.040915, 0.001936, 0.0057757, 0.008665, 0.71648, 0.26788]
Predicted label: 3
Correct prediction
Energy consumption = 144.142238 pJ
sum error= 210
Actual label: 5
Output voltages: [0.17335, 0.0011246, 0.0076857, 0.52414, 0.010642, 0.79066, 0.28335, 0.036071, 0.77393, 0.01165]
Predicted label: 5
Correct prediction
Energy consumption = 142.993771 pJ
sum error= 210
Actual label: 5
Output voltages: [0.46076, 0.001066, 0.0030684, 0.33717, 0.024566, 0.79424, 0.0054102, 0.0014636, 0.74747, 0.11101]
Predicted label: 5
Correct prediction
Energy consumption = 138.034640 pJ
sum error= 210
Actual label: 1
Output voltages: [0.012961, 0.79848, 0.15406, 0.27162, 0.04176, 0.022761, 0.5165, 0.0096312, 0.26045, 0.039204]
Predicted label: 1
Correct prediction
Energy consumption = 171.919381 pJ
sum error= 210
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 392 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 392 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 392 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.036281, 0.019816, 0.12438, 0.0066951, 0.019949, 0.0014344, 0.004218, 0.79858, 0.25372, 0.31252]
Predicted label: 7
Correct prediction
Energy consumption = 169.344436 pJ
sum error= 210
Actual label: 2
Output voltages: [0.25821, 0.052298, 0.79851, 0.53062, 0.034302, 0.0011937, 0.014592, 0.015066, 0.69353, 0.020132]
Predicted label: 2
Correct prediction
Energy consumption = 153.581698 pJ
sum error= 210
Actual label: 1
Output voltages: [0.027061, 0.79855, 0.039312, 0.019865, 0.40156, 0.0024223, 0.76756, 0.001071, 0.22366, 0.01173]
Predicted label: 1
Correct prediction
Energy consumption = 158.156888 pJ
sum error= 210
Actual label: 6
Output voltages: [0.071013, 0.051668, 0.044063, 0.0022171, 0.20284, 0.38837, 0.79878, 0.011135, 0.44384, 0.0013855]
Predicted label: 6
Correct prediction
Energy consumption = 148.777988 pJ
sum error= 210
Actual label: 9
Output voltages: [0.71785, 0.021454, 0.044929, 0.2732, 0.089368, 0.041899, 0.0041098, 0.52114, 0.15575, 0.78657]
Predicted label: 9
Correct prediction
Energy consumption = 161.629728 pJ
sum error= 210
Actual label: 1
Output voltages: [0.025353, 0.79875, 0.28086, 0.015607, 0.41382, 0.0019696, 0.23643, 0.031565, 0.30793, 0.014324]
Predicted label: 1
Correct prediction
Energy consumption = 146.137390 pJ
sum error= 210
Actual label: 9
Output voltages: [0.011407, 0.0074313, 0.0014348, 0.55403, 0.32971, 0.39072, 0.0071873, 0.0011771, 0.59783, 0.72758]
Predicted label: 9
Correct prediction
Energy consumption = 161.637342 pJ
sum error= 210
Actual label: 9
Output voltages: [0.58954, 0.0071438, 0.006344, 0.11592, 0.59193, 0.021959, 0.0094005, 0.016977, 0.29724, 0.79789]
Predicted label: 9
Correct prediction
Energy consumption = 146.195553 pJ
sum error= 210
Actual label: 5
Output voltages: [0.45782, 0.0074681, 0.014955, 0.42068, 0.001726, 0.79693, 0.12034, 0.0011686, 0.57876, 0.06541]
Predicted label: 5
Correct prediction
Energy consumption = 154.211554 pJ
sum error= 210
Actual label: 5
Output voltages: [0.26269, 0.0014644, 0.015256, 0.40468, 0.003339, 0.79879, 0.22173, 0.039476, 0.766, 0.058638]
Predicted label: 5
Correct prediction
Energy consumption = 136.462609 pJ
sum error= 210
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 393 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 393 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 393 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.027069, 0.79854, 0.015342, 0.21139, 0.038576, 0.0013025, 0.52331, 0.0021576, 0.15367, 0.1738]
Predicted label: 1
Correct prediction
Energy consumption = 180.162168 pJ
sum error= 210
Actual label: 6
Output voltages: [0.031254, 0.041868, 0.28973, 0.011274, 0.067304, 0.18484, 0.79877, 0.0058432, 0.65082, 0.0029741]
Predicted label: 6
Correct prediction
Energy consumption = 151.708997 pJ
sum error= 210
Actual label: 2
Output voltages: [0.66501, 0.0074486, 0.79878, 0.27385, 0.014819, 0.0010725, 0.02961, 0.030739, 0.60747, 0.004327]
Predicted label: 2
Correct prediction
Energy consumption = 152.267214 pJ
sum error= 210
Actual label: 2
Output voltages: [0.51554, 0.16094, 0.79878, 0.32869, 0.013031, 0.0012041, 0.27007, 0.054089, 0.25234, 0.029837]
Predicted label: 2
Correct prediction
Energy consumption = 138.914861 pJ
sum error= 210
Actual label: 8
Output voltages: [0.012482, 0.015021, 0.033787, 0.11088, 0.0080351, 0.096102, 0.018505, 0.001792, 0.79875, 0.30337]
Predicted label: 8
Correct prediction
Energy consumption = 151.098521 pJ
sum error= 210
Actual label: 6
Output voltages: [0.03671, 0.017733, 0.25661, 0.0013964, 0.3495, 0.52695, 0.79876, 0.0012724, 0.34874, 0.0015333]
Predicted label: 6
Correct prediction
Energy consumption = 152.882419 pJ
sum error= 210
Actual label: 7
Output voltages: [0.023609, 0.0032263, 0.72971, 0.31899, 0.012614, 0.0010785, 0.0042596, 0.79872, 0.47556, 0.012154]
Predicted label: 7
Correct prediction
Energy consumption = 145.762295 pJ
sum error= 210
Actual label: 1
Output voltages: [0.0048323, 0.79878, 0.0030259, 0.062122, 0.074388, 0.45319, 0.46899, 0.068156, 0.054928, 0.013914]
Predicted label: 1
Correct prediction
Energy consumption = 166.485406 pJ
sum error= 210
Actual label: 4
Output voltages: [0.020417, 0.020284, 0.18278, 0.025123, 0.79865, 0.0031118, 0.035878, 0.0069951, 0.020722, 0.31012]
Predicted label: 4
Correct prediction
Energy consumption = 163.523078 pJ
sum error= 210
Actual label: 6
Output voltages: [0.43384, 0.014987, 0.059501, 0.0010746, 0.39585, 0.0063468, 0.79877, 0.0058574, 0.043603, 0.3918]
Predicted label: 6
Correct prediction
Energy consumption = 143.434658 pJ
sum error= 210
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 394 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 394 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 394 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.034895, 0.17406, 0.031438, 0.0022257, 0.014088, 0.64705, 0.034337, 0.45175, 0.018605]
Predicted label: 0
Correct prediction
Energy consumption = 159.911345 pJ
sum error= 210
Actual label: 4
Output voltages: [0.24725, 0.38668, 0.49275, 0.0022248, 0.64878, 0.010991, 0.79378, 0.0032384, 0.2248, 0.0011626]
Predicted label: 6
Wrong prediction!
Energy consumption = 143.159578 pJ
sum error= 211
Actual label: 0
Output voltages: [0.78723, 0.034168, 0.014593, 0.001104, 0.025722, 0.005985, 0.7613, 0.019828, 0.19312, 0.1469]
Predicted label: 0
Correct prediction
Energy consumption = 151.325761 pJ
sum error= 211
Actual label: 3
Output voltages: [0.0036447, 0.0014071, 0.0084994, 0.79339, 0.61975, 0.552, 0.3327, 0.01525, 0.514, 0.0010706]
Predicted label: 3
Correct prediction
Energy consumption = 149.273948 pJ
sum error= 211
Actual label: 3
Output voltages: [0.14487, 0.012085, 0.023936, 0.79871, 0.010308, 0.011542, 0.014888, 0.005427, 0.52206, 0.053384]
Predicted label: 3
Correct prediction
Energy consumption = 137.167311 pJ
sum error= 211
Actual label: 2
Output voltages: [0.36343, 0.025199, 0.79873, 0.066785, 0.015097, 0.0010776, 0.043955, 0.015209, 0.34708, 0.018338]
Predicted label: 2
Correct prediction
Energy consumption = 149.551465 pJ
sum error= 211
Actual label: 2
Output voltages: [0.21323, 0.23668, 0.79722, 0.047617, 0.0091796, 0.0012187, 0.34662, 0.012231, 0.65972, 0.037213]
Predicted label: 2
Correct prediction
Energy consumption = 143.924026 pJ
sum error= 211
Actual label: 3
Output voltages: [0.47464, 0.025863, 0.10448, 0.79861, 0.026012, 0.02013, 0.012973, 0.030567, 0.60192, 0.035202]
Predicted label: 3
Correct prediction
Energy consumption = 142.049967 pJ
sum error= 211
Actual label: 6
Output voltages: [0.3456, 0.065662, 0.32865, 0.001068, 0.097256, 0.19211, 0.79878, 0.0014241, 0.44505, 0.0049206]
Predicted label: 6
Correct prediction
Energy consumption = 151.617960 pJ
sum error= 211
Actual label: 8
Output voltages: [0.18045, 0.045215, 0.15575, 0.23076, 0.10906, 0.016809, 0.21413, 0.021603, 0.79867, 0.035256]
Predicted label: 8
Correct prediction
Energy consumption = 151.460147 pJ
sum error= 211
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 395 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 395 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 395 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.09291, 0.0015975, 0.0080733, 0.27741, 0.053451, 0.0010673, 0.0011064, 0.44095, 0.55685, 0.78244]
Predicted label: 9
Correct prediction
Energy consumption = 179.207014 pJ
sum error= 211
Actual label: 8
Output voltages: [0.67699, 0.0029857, 0.15348, 0.37806, 0.028925, 0.0011595, 0.0010998, 0.036896, 0.78388, 0.29372]
Predicted label: 8
Correct prediction
Energy consumption = 149.900433 pJ
sum error= 211
Actual label: 5
Output voltages: [0.24212, 0.0052105, 0.0010689, 0.54174, 0.024971, 0.79867, 0.48529, 0.0023509, 0.30989, 0.044674]
Predicted label: 5
Correct prediction
Energy consumption = 156.203231 pJ
sum error= 211
Actual label: 3
Output voltages: [0.33266, 0.013466, 0.45194, 0.79867, 0.036588, 0.010495, 0.01263, 0.039137, 0.19237, 0.044071]
Predicted label: 3
Correct prediction
Energy consumption = 139.210327 pJ
sum error= 211
Actual label: 8
Output voltages: [0.054022, 0.022423, 0.23063, 0.01752, 0.011835, 0.013921, 0.0074602, 0.035613, 0.79504, 0.77245]
Predicted label: 8
Correct prediction
Energy consumption = 152.703530 pJ
sum error= 211
Actual label: 5
Output voltages: [0.108, 0.004498, 0.0027069, 0.12048, 0.017189, 0.79878, 0.38883, 0.018776, 0.64665, 0.0074438]
Predicted label: 5
Correct prediction
Energy consumption = 148.005757 pJ
sum error= 211
Actual label: 4
Output voltages: [0.0022969, 0.013375, 0.29364, 0.0077256, 0.79861, 0.0023009, 0.091084, 0.021818, 0.032344, 0.057986]
Predicted label: 4
Correct prediction
Energy consumption = 151.023193 pJ
sum error= 211
Actual label: 5
Output voltages: [0.099311, 0.0014523, 0.0066226, 0.50278, 0.027633, 0.79879, 0.30448, 0.085303, 0.70805, 0.26464]
Predicted label: 5
Correct prediction
Energy consumption = 149.253098 pJ
sum error= 211
Actual label: 2
Output voltages: [0.26339, 0.009631, 0.79786, 0.2935, 0.035847, 0.001218, 0.043782, 0.028093, 0.66236, 0.062431]
Predicted label: 2
Correct prediction
Energy consumption = 153.710870 pJ
sum error= 211
Actual label: 0
Output voltages: [0.79878, 0.061909, 0.03047, 0.023939, 0.080484, 0.002824, 0.66952, 0.012458, 0.031094, 0.25049]
Predicted label: 0
Correct prediction
Energy consumption = 151.869725 pJ
sum error= 211
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 396 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 396 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 396 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.033794, 0.0017124, 0.0012092, 0.39173, 0.012458, 0.79718, 0.24527, 0.0015302, 0.76488, 0.005598]
Predicted label: 5
Correct prediction
Energy consumption = 162.878067 pJ
sum error= 211
Actual label: 6
Output voltages: [0.22815, 0.0010668, 0.0062877, 0.0052632, 0.087651, 0.63447, 0.77662, 0.0018571, 0.78781, 0.0092621]
Predicted label: 8
Wrong prediction!
Energy consumption = 139.339862 pJ
sum error= 212
Actual label: 3
Output voltages: [0.29575, 0.0033497, 0.33698, 0.7987, 0.027884, 0.011024, 0.057819, 0.015045, 0.75742, 0.01779]
Predicted label: 3
Correct prediction
Energy consumption = 140.962435 pJ
sum error= 212
Actual label: 2
Output voltages: [0.52841, 0.021929, 0.79874, 0.1829, 0.018571, 0.0011125, 0.036594, 0.070495, 0.54491, 0.0072732]
Predicted label: 2
Correct prediction
Energy consumption = 144.763093 pJ
sum error= 212
Actual label: 8
Output voltages: [0.0089002, 0.055627, 0.079547, 0.026068, 0.0063245, 0.0057044, 0.015091, 0.017463, 0.79879, 0.4523]
Predicted label: 8
Correct prediction
Energy consumption = 148.349419 pJ
sum error= 212
Actual label: 3
Output voltages: [0.46244, 0.022383, 0.070636, 0.79869, 0.067691, 0.0027694, 0.032332, 0.017225, 0.59523, 0.018731]
Predicted label: 3
Correct prediction
Energy consumption = 147.315348 pJ
sum error= 212
Actual label: 9
Output voltages: [0.12309, 0.001309, 0.041633, 0.088218, 0.03541, 0.038105, 0.002189, 0.11066, 0.22759, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 147.923497 pJ
sum error= 212
Actual label: 9
Output voltages: [0.31887, 0.029906, 0.03663, 0.109, 0.12717, 0.023306, 0.14741, 0.0030615, 0.23151, 0.79864]
Predicted label: 9
Correct prediction
Energy consumption = 143.977075 pJ
sum error= 212
Actual label: 5
Output voltages: [0.0036053, 0.0012272, 0.040604, 0.37646, 0.15678, 0.78001, 0.043759, 0.0034066, 0.77417, 0.040439]
Predicted label: 5
Correct prediction
Energy consumption = 149.747025 pJ
sum error= 212
Actual label: 7
Output voltages: [0.29214, 0.74058, 0.028726, 0.47022, 0.0012004, 0.0010812, 0.0012065, 0.78278, 0.17669, 0.1771]
Predicted label: 7
Correct prediction
Energy consumption = 159.383158 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 397 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 397 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 397 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.36048, 0.025235, 0.0072943, 0.033236, 0.044833, 0.0028155, 0.0012053, 0.008376, 0.49807, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 175.947039 pJ
sum error= 212
Actual label: 4
Output voltages: [0.012861, 0.0057445, 0.24192, 0.0016508, 0.79878, 0.0032601, 0.46961, 0.14188, 0.067359, 0.011899]
Predicted label: 4
Correct prediction
Energy consumption = 147.362587 pJ
sum error= 212
Actual label: 6
Output voltages: [0.2806, 0.011335, 0.14864, 0.0013971, 0.26285, 0.20837, 0.79879, 0.002625, 0.73721, 0.010777]
Predicted label: 6
Correct prediction
Energy consumption = 148.049664 pJ
sum error= 212
Actual label: 7
Output voltages: [0.16705, 0.31417, 0.18481, 0.07832, 0.0022624, 0.0010966, 0.0022641, 0.79871, 0.029336, 0.62932]
Predicted label: 7
Correct prediction
Energy consumption = 161.308532 pJ
sum error= 212
Actual label: 1
Output voltages: [0.09927, 0.79834, 0.054621, 0.38545, 0.050942, 0.0024895, 0.075258, 0.31166, 0.022223, 0.17637]
Predicted label: 1
Correct prediction
Energy consumption = 162.450797 pJ
sum error= 212
Actual label: 3
Output voltages: [0.72298, 0.0025359, 0.39, 0.79856, 0.01431, 0.0018542, 0.042827, 0.013156, 0.40547, 0.0056536]
Predicted label: 3
Correct prediction
Energy consumption = 147.902122 pJ
sum error= 212
Actual label: 7
Output voltages: [0.05011, 0.71514, 0.060589, 0.38459, 0.0021851, 0.0012258, 0.0012033, 0.7984, 0.093797, 0.057832]
Predicted label: 7
Correct prediction
Energy consumption = 156.617695 pJ
sum error= 212
Actual label: 3
Output voltages: [0.40505, 0.025424, 0.1412, 0.79864, 0.027574, 0.0042168, 0.018951, 0.050031, 0.32068, 0.042771]
Predicted label: 3
Correct prediction
Energy consumption = 145.823728 pJ
sum error= 212
Actual label: 6
Output voltages: [0.379, 0.05225, 0.024508, 0.0061653, 0.15872, 0.6187, 0.79878, 0.0052029, 0.33696, 0.024452]
Predicted label: 6
Correct prediction
Energy consumption = 157.586362 pJ
sum error= 212
Actual label: 6
Output voltages: [0.033657, 0.16121, 0.076319, 0.011549, 0.14715, 0.35348, 0.79875, 0.015502, 0.69481, 0.0095754]
Predicted label: 6
Correct prediction
Energy consumption = 135.102328 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 398 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 398 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 398 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.1154, 0.33162, 0.035899, 0.001375, 0.0095035, 0.36169, 0.062193, 0.066422, 0.029781]
Predicted label: 0
Correct prediction
Energy consumption = 167.642655 pJ
sum error= 212
Actual label: 9
Output voltages: [0.26417, 0.020545, 0.051252, 0.14982, 0.18329, 0.0036057, 0.056099, 0.024659, 0.064604, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 153.495447 pJ
sum error= 212
Actual label: 0
Output voltages: [0.79871, 0.029587, 0.002991, 0.014962, 0.03147, 0.47469, 0.18776, 0.02721, 0.13315, 0.38051]
Predicted label: 0
Correct prediction
Energy consumption = 158.457835 pJ
sum error= 212
Actual label: 1
Output voltages: [0.18729, 0.79879, 0.022583, 0.0694, 0.43601, 0.0011918, 0.4757, 0.010757, 0.031696, 0.013655]
Predicted label: 1
Correct prediction
Energy consumption = 159.706768 pJ
sum error= 212
Actual label: 9
Output voltages: [0.027971, 0.012562, 0.010243, 0.028475, 0.037674, 0.0071466, 0.001254, 0.017244, 0.76463, 0.79762]
Predicted label: 9
Correct prediction
Energy consumption = 153.526547 pJ
sum error= 212
Actual label: 9
Output voltages: [0.02834, 0.0031356, 0.14282, 0.35523, 0.78815, 0.0010659, 0.0019638, 0.022799, 0.021858, 0.75873]
Predicted label: 4
Wrong prediction!
Energy consumption = 151.170576 pJ
sum error= 213
Actual label: 2
Output voltages: [0.43384, 0.34496, 0.79597, 0.050051, 0.021889, 0.0012672, 0.31637, 0.0055428, 0.63395, 0.038844]
Predicted label: 2
Correct prediction
Energy consumption = 149.780394 pJ
sum error= 213
Actual label: 8
Output voltages: [0.062133, 0.15903, 0.21507, 0.52079, 0.010942, 0.010418, 0.063737, 0.0032947, 0.79877, 0.40358]
Predicted label: 8
Correct prediction
Energy consumption = 152.537713 pJ
sum error= 213
Actual label: 8
Output voltages: [0.17954, 0.017534, 0.0026056, 0.50512, 0.013444, 0.28483, 0.031095, 0.0010751, 0.79872, 0.4145]
Predicted label: 8
Correct prediction
Energy consumption = 146.965300 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79869, 0.040802, 0.15831, 0.015814, 0.021095, 0.0011703, 0.44645, 0.034124, 0.20192, 0.055261]
Predicted label: 0
Correct prediction
Energy consumption = 147.729299 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 399 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 399 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 399 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.21102, 0.7987, 0.25047, 0.021564, 0.046837, 0.0010757, 0.072597, 0.013984, 0.33342, 0.03248]
Predicted label: 1
Correct prediction
Energy consumption = 182.177821 pJ
sum error= 213
Actual label: 6
Output voltages: [0.050259, 0.079541, 0.33992, 0.0011389, 0.30102, 0.12404, 0.79872, 0.001398, 0.52416, 0.010145]
Predicted label: 6
Correct prediction
Energy consumption = 155.229775 pJ
sum error= 213
Actual label: 9
Output voltages: [0.28975, 0.007044, 0.022047, 0.33167, 0.021823, 0.056692, 0.0081918, 0.23535, 0.28569, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 160.292013 pJ
sum error= 213
Actual label: 7
Output voltages: [0.22371, 0.096399, 0.097881, 0.034336, 0.024092, 0.0011162, 0.0013668, 0.79862, 0.04344, 0.12434]
Predicted label: 7
Correct prediction
Energy consumption = 152.752638 pJ
sum error= 213
Actual label: 5
Output voltages: [0.032935, 0.0016029, 0.011726, 0.069984, 0.0071975, 0.79879, 0.404, 0.24573, 0.79263, 0.003244]
Predicted label: 5
Correct prediction
Energy consumption = 149.501415 pJ
sum error= 213
Actual label: 3
Output voltages: [0.18061, 0.0024643, 0.048747, 0.79877, 0.027399, 0.40684, 0.018573, 0.012203, 0.46889, 0.032164]
Predicted label: 3
Correct prediction
Energy consumption = 139.607783 pJ
sum error= 213
Actual label: 4
Output voltages: [0.028786, 0.0011813, 0.50196, 0.001878, 0.79861, 0.002538, 0.032919, 0.14284, 0.028566, 0.22174]
Predicted label: 4
Correct prediction
Energy consumption = 151.166734 pJ
sum error= 213
Actual label: 7
Output voltages: [0.02886, 0.0049929, 0.0041037, 0.58609, 0.0079832, 0.043897, 0.0011012, 0.79878, 0.26842, 0.12518]
Predicted label: 7
Correct prediction
Energy consumption = 147.585402 pJ
sum error= 213
Actual label: 4
Output voltages: [0.012862, 0.0096653, 0.29601, 0.0024476, 0.79879, 0.0018903, 0.65323, 0.022702, 0.15593, 0.0036327]
Predicted label: 4
Correct prediction
Energy consumption = 150.703293 pJ
sum error= 213
Actual label: 9
Output voltages: [0.3585, 0.012882, 0.040484, 0.54661, 0.077292, 0.063011, 0.0081797, 0.039693, 0.087169, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 152.555473 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 400 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 400 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 400 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.24302, 0.0015511, 0.25316, 0.01854, 0.23892, 0.18355, 0.026961, 0.0014374, 0.55736, 0.79866]
Predicted label: 9
Correct prediction
Energy consumption = 170.166247 pJ
sum error= 213
Actual label: 4
Output voltages: [0.011068, 0.0036827, 0.04434, 0.037568, 0.79877, 0.0050973, 0.037057, 0.46769, 0.059744, 0.094559]
Predicted label: 4
Correct prediction
Energy consumption = 144.534886 pJ
sum error= 213
Actual label: 3
Output voltages: [0.024725, 0.050923, 0.075884, 0.79683, 0.0032876, 0.12766, 0.01475, 0.0010865, 0.75201, 0.032303]
Predicted label: 3
Correct prediction
Energy consumption = 147.743937 pJ
sum error= 213
Actual label: 6
Output voltages: [0.089329, 0.034324, 0.12416, 0.0025315, 0.15305, 0.063019, 0.79879, 0.0062927, 0.75142, 0.013283]
Predicted label: 6
Correct prediction
Energy consumption = 143.584887 pJ
sum error= 213
Actual label: 3
Output voltages: [0.46926, 0.018, 0.067097, 0.79871, 0.0063938, 0.014319, 0.07241, 0.03258, 0.45986, 0.037363]
Predicted label: 3
Correct prediction
Energy consumption = 147.895993 pJ
sum error= 213
Actual label: 1
Output voltages: [0.0020021, 0.79867, 0.044625, 0.28109, 0.020372, 0.0010754, 0.032244, 0.047029, 0.48009, 0.078334]
Predicted label: 1
Correct prediction
Energy consumption = 165.324181 pJ
sum error= 213
Actual label: 1
Output voltages: [0.0077585, 0.79843, 0.029048, 0.2547, 0.054221, 0.0014401, 0.17717, 0.14604, 0.06596, 0.093843]
Predicted label: 1
Correct prediction
Energy consumption = 156.867939 pJ
sum error= 213
Actual label: 7
Output voltages: [0.2339, 0.081634, 0.0012494, 0.54655, 0.061821, 0.022345, 0.0012157, 0.78911, 0.24937, 0.17187]
Predicted label: 7
Correct prediction
Energy consumption = 155.598906 pJ
sum error= 213
Actual label: 6
Output voltages: [0.04409, 0.16247, 0.36732, 0.0030502, 0.44281, 0.071038, 0.79865, 0.0015627, 0.57228, 0.018358]
Predicted label: 6
Correct prediction
Energy consumption = 148.994010 pJ
sum error= 213
Actual label: 9
Output voltages: [0.45115, 0.05902, 0.021832, 0.19303, 0.28458, 0.014204, 0.0067413, 0.11472, 0.049572, 0.79746]
Predicted label: 9
Correct prediction
Energy consumption = 162.326043 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 401 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 401 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 401 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.027458, 0.79856, 0.24516, 0.033319, 0.051786, 0.0013028, 0.26227, 0.0012397, 0.071801, 0.067592]
Predicted label: 1
Correct prediction
Energy consumption = 179.660707 pJ
sum error= 213
Actual label: 8
Output voltages: [0.13848, 0.012462, 0.02781, 0.39346, 0.0086804, 0.039164, 0.0055462, 0.00146, 0.79875, 0.42315]
Predicted label: 8
Correct prediction
Energy consumption = 151.409935 pJ
sum error= 213
Actual label: 4
Output voltages: [0.0081978, 0.017221, 0.32579, 0.025733, 0.7986, 0.047372, 0.031715, 0.38788, 0.032168, 0.25122]
Predicted label: 4
Correct prediction
Energy consumption = 151.265135 pJ
sum error= 213
Actual label: 1
Output voltages: [0.023744, 0.79876, 0.52104, 0.34934, 0.68537, 0.0056884, 0.0351, 0.014961, 0.37568, 0.021482]
Predicted label: 1
Correct prediction
Energy consumption = 152.694892 pJ
sum error= 213
Actual label: 1
Output voltages: [0.0034036, 0.79862, 0.18019, 0.15101, 0.013878, 0.0010808, 0.056007, 0.012667, 0.19919, 0.050331]
Predicted label: 1
Correct prediction
Energy consumption = 160.244631 pJ
sum error= 213
Actual label: 9
Output voltages: [0.68624, 0.014471, 0.017077, 0.047099, 0.5609, 0.011453, 0.0021668, 0.001098, 0.10577, 0.796]
Predicted label: 9
Correct prediction
Energy consumption = 151.197168 pJ
sum error= 213
Actual label: 9
Output voltages: [0.27545, 0.033793, 0.023591, 0.031106, 0.11838, 0.02333, 0.0028924, 0.013599, 0.47058, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 137.905061 pJ
sum error= 213
Actual label: 4
Output voltages: [0.0014607, 0.037515, 0.0017445, 0.11184, 0.71187, 0.10404, 0.36398, 0.0045048, 0.2901, 0.60615]
Predicted label: 4
Correct prediction
Energy consumption = 140.196647 pJ
sum error= 213
Actual label: 3
Output voltages: [0.49795, 0.099569, 0.31118, 0.79879, 0.001202, 0.037586, 0.0037028, 0.14657, 0.48451, 0.0052501]
Predicted label: 3
Correct prediction
Energy consumption = 148.225266 pJ
sum error= 213
Actual label: 6
Output voltages: [0.26094, 0.045917, 0.049463, 0.0076084, 0.20328, 0.3276, 0.79879, 0.0034352, 0.63172, 0.0048153]
Predicted label: 6
Correct prediction
Energy consumption = 147.882064 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 402 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 402 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 402 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.037598, 0.01877, 0.03768, 0.023146, 0.016968, 0.063748, 0.018268, 0.017089, 0.79867, 0.030065]
Predicted label: 8
Correct prediction
Energy consumption = 168.572598 pJ
sum error= 213
Actual label: 1
Output voltages: [0.013334, 0.79857, 0.28874, 0.052651, 0.0032167, 0.0012314, 0.57787, 0.0021295, 0.15651, 0.030586]
Predicted label: 1
Correct prediction
Energy consumption = 162.877272 pJ
sum error= 213
Actual label: 6
Output voltages: [0.037847, 0.010731, 0.23777, 0.0021536, 0.21387, 0.32604, 0.79879, 0.0010935, 0.55179, 0.03276]
Predicted label: 6
Correct prediction
Energy consumption = 149.776816 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79877, 0.10282, 0.0045902, 0.015577, 0.010843, 0.07946, 0.18829, 0.01487, 0.046827, 0.14603]
Predicted label: 0
Correct prediction
Energy consumption = 150.961108 pJ
sum error= 213
Actual label: 4
Output voltages: [0.002856, 0.02679, 0.03069, 0.021841, 0.79867, 0.0014039, 0.028668, 0.15784, 0.026207, 0.022253]
Predicted label: 4
Correct prediction
Energy consumption = 155.309693 pJ
sum error= 213
Actual label: 1
Output voltages: [0.021367, 0.79856, 0.13976, 0.15992, 0.10748, 0.014194, 0.59097, 0.0026847, 0.026764, 0.20365]
Predicted label: 1
Correct prediction
Energy consumption = 160.165604 pJ
sum error= 213
Actual label: 3
Output voltages: [0.18186, 0.025945, 0.042267, 0.7987, 0.015601, 0.013833, 0.0094352, 0.0091935, 0.54686, 0.039087]
Predicted label: 3
Correct prediction
Energy consumption = 147.685297 pJ
sum error= 213
Actual label: 7
Output voltages: [0.021633, 0.42119, 0.0096808, 0.01291, 0.33922, 0.0010787, 0.0016388, 0.79777, 0.019786, 0.66129]
Predicted label: 7
Correct prediction
Energy consumption = 155.827133 pJ
sum error= 213
Actual label: 7
Output voltages: [0.23088, 0.032354, 0.010295, 0.02568, 0.0039416, 0.012214, 0.001103, 0.79873, 0.18743, 0.26141]
Predicted label: 7
Correct prediction
Energy consumption = 150.361155 pJ
sum error= 213
Actual label: 4
Output voltages: [0.011733, 0.0068837, 0.17928, 0.02099, 0.79343, 0.0011386, 0.0012152, 0.017384, 0.20164, 0.60844]
Predicted label: 4
Correct prediction
Energy consumption = 146.086416 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 403 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 403 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 403 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.30768, 0.034982, 0.019559, 0.035629, 0.028191, 0.0084942, 0.0091439, 0.035795, 0.27563, 0.79848]
Predicted label: 9
Correct prediction
Energy consumption = 168.057469 pJ
sum error= 213
Actual label: 5
Output voltages: [0.060106, 0.0013021, 0.0019188, 0.60732, 0.022916, 0.79824, 0.28693, 0.0249, 0.77405, 0.2855]
Predicted label: 5
Correct prediction
Energy consumption = 148.753113 pJ
sum error= 213
Actual label: 1
Output voltages: [0.0015514, 0.79876, 0.0038211, 0.019277, 0.046195, 0.0066098, 0.75547, 0.011344, 0.67104, 0.016248]
Predicted label: 1
Correct prediction
Energy consumption = 162.024045 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79873, 0.15176, 0.22737, 0.012538, 0.0021414, 0.0016844, 0.49422, 0.010033, 0.068708, 0.17842]
Predicted label: 0
Correct prediction
Energy consumption = 149.991939 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79861, 0.026739, 0.31254, 0.043303, 0.027219, 0.010095, 0.049927, 0.14499, 0.060813, 0.026519]
Predicted label: 0
Correct prediction
Energy consumption = 146.346761 pJ
sum error= 213
Actual label: 1
Output voltages: [0.029772, 0.79868, 0.44942, 0.071437, 0.0027107, 0.0011336, 0.26473, 0.0092849, 0.26036, 0.054399]
Predicted label: 1
Correct prediction
Energy consumption = 166.516678 pJ
sum error= 213
Actual label: 1
Output voltages: [0.010595, 0.79855, 0.15915, 0.036867, 0.017097, 0.0011269, 0.65634, 0.0016743, 0.084283, 0.039173]
Predicted label: 1
Correct prediction
Energy consumption = 150.197486 pJ
sum error= 213
Actual label: 6
Output voltages: [0.44904, 0.31291, 0.0055265, 0.23043, 0.002716, 0.24323, 0.79708, 0.038486, 0.78506, 0.0015772]
Predicted label: 6
Correct prediction
Energy consumption = 150.821396 pJ
sum error= 213
Actual label: 2
Output voltages: [0.29918, 0.30039, 0.79879, 0.12662, 0.0096677, 0.0013604, 0.30346, 0.022871, 0.30087, 0.032877]
Predicted label: 2
Correct prediction
Energy consumption = 150.941836 pJ
sum error= 213
Actual label: 1
Output voltages: [0.013633, 0.7985, 0.061561, 0.046715, 0.03865, 0.0015151, 0.59907, 0.0037676, 0.31447, 0.034442]
Predicted label: 1
Correct prediction
Energy consumption = 157.105606 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 404 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 404 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 404 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.55637, 0.0050151, 0.031804, 0.011728, 0.37812, 0.022187, 0.0095703, 0.043775, 0.29812, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 173.614759 pJ
sum error= 213
Actual label: 8
Output voltages: [0.33938, 0.0076785, 0.046967, 0.16372, 0.017972, 0.27198, 0.011078, 0.022365, 0.79864, 0.022559]
Predicted label: 8
Correct prediction
Energy consumption = 150.483233 pJ
sum error= 213
Actual label: 4
Output voltages: [0.024918, 0.0099509, 0.27046, 0.0015723, 0.79876, 0.0013701, 0.47231, 0.16905, 0.043878, 0.17557]
Predicted label: 4
Correct prediction
Energy consumption = 157.442887 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79879, 0.022917, 0.019734, 0.006096, 0.0049856, 0.09286, 0.3566, 0.019177, 0.10885, 0.0944]
Predicted label: 0
Correct prediction
Energy consumption = 157.185141 pJ
sum error= 213
Actual label: 3
Output voltages: [0.43593, 0.019559, 0.0016783, 0.79844, 0.007003, 0.66361, 0.061597, 0.56406, 0.36034, 0.0011567]
Predicted label: 3
Correct prediction
Energy consumption = 152.672099 pJ
sum error= 213
Actual label: 6
Output voltages: [0.1246, 0.033593, 0.29871, 0.0031918, 0.0243, 0.55476, 0.79871, 0.0011482, 0.58917, 0.010864]
Predicted label: 6
Correct prediction
Energy consumption = 139.907891 pJ
sum error= 213
Actual label: 4
Output voltages: [0.0072649, 0.032233, 0.075906, 0.01049, 0.79866, 0.0010827, 0.23558, 0.024983, 0.02074, 0.1457]
Predicted label: 4
Correct prediction
Energy consumption = 153.500573 pJ
sum error= 213
Actual label: 9
Output voltages: [0.35559, 0.047549, 0.042725, 0.26235, 0.032978, 0.032867, 0.0082462, 0.045961, 0.24355, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 152.354231 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79871, 0.37035, 0.33783, 0.042729, 0.0036143, 0.013146, 0.1841, 0.0073869, 0.131, 0.31062]
Predicted label: 0
Correct prediction
Energy consumption = 151.796039 pJ
sum error= 213
Actual label: 7
Output voltages: [0.22149, 0.042145, 0.14436, 0.044338, 0.0013037, 0.0119, 0.0011563, 0.79867, 0.35754, 0.43476]
Predicted label: 7
Correct prediction
Energy consumption = 152.799726 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 405 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 405 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 405 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0081585, 0.79839, 0.027091, 0.13952, 0.014916, 0.0086144, 0.7766, 0.0048618, 0.038227, 0.23928]
Predicted label: 1
Correct prediction
Energy consumption = 184.609268 pJ
sum error= 213
Actual label: 6
Output voltages: [0.65457, 0.039951, 0.04017, 0.0015674, 0.057701, 0.045019, 0.79878, 0.0046445, 0.10456, 0.054127]
Predicted label: 6
Correct prediction
Energy consumption = 156.840716 pJ
sum error= 213
Actual label: 5
Output voltages: [0.041975, 0.0010949, 0.0010673, 0.3755, 0.068583, 0.79826, 0.28941, 0.0068601, 0.74124, 0.053839]
Predicted label: 5
Correct prediction
Energy consumption = 150.989113 pJ
sum error= 213
Actual label: 7
Output voltages: [0.218, 0.0095736, 0.0041805, 0.019122, 0.026074, 0.0055945, 0.001135, 0.79873, 0.53558, 0.20112]
Predicted label: 7
Correct prediction
Energy consumption = 157.289286 pJ
sum error= 213
Actual label: 5
Output voltages: [0.026143, 0.0010832, 0.0012085, 0.69579, 0.015394, 0.79561, 0.20802, 0.057374, 0.48106, 0.043965]
Predicted label: 5
Correct prediction
Energy consumption = 148.366961 pJ
sum error= 213
Actual label: 2
Output voltages: [0.5956, 0.015024, 0.79768, 0.35853, 0.0035846, 0.001139, 0.16169, 0.024593, 0.76536, 0.0050098]
Predicted label: 2
Correct prediction
Energy consumption = 145.579505 pJ
sum error= 213
Actual label: 5
Output voltages: [0.0061909, 0.0096157, 0.0018878, 0.23033, 0.042651, 0.79842, 0.02961, 0.018292, 0.75324, 0.26946]
Predicted label: 5
Correct prediction
Energy consumption = 149.691524 pJ
sum error= 213
Actual label: 1
Output voltages: [0.16173, 0.79843, 0.063769, 0.28264, 0.0031607, 0.0050485, 0.15719, 0.0043357, 0.58827, 0.029958]
Predicted label: 1
Correct prediction
Energy consumption = 159.122301 pJ
sum error= 213
Actual label: 8
Output voltages: [0.098866, 0.017614, 0.027814, 0.31256, 0.0018778, 0.27216, 0.0017292, 0.001462, 0.79872, 0.26243]
Predicted label: 8
Correct prediction
Energy consumption = 152.557853 pJ
sum error= 213
Actual label: 5
Output voltages: [0.031397, 0.0010705, 0.034882, 0.11157, 0.030458, 0.79476, 0.020861, 0.11597, 0.76655, 0.23746]
Predicted label: 5
Correct prediction
Energy consumption = 142.243521 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 406 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 406 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 406 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0060032, 0.010113, 0.30122, 0.035773, 0.79867, 0.0017124, 0.22929, 0.1951, 0.030381, 0.35165]
Predicted label: 4
Correct prediction
Energy consumption = 171.248542 pJ
sum error= 213
Actual label: 7
Output voltages: [0.087018, 0.045438, 0.036067, 0.0070516, 0.020069, 0.0014108, 0.0011125, 0.79879, 0.31318, 0.41534]
Predicted label: 7
Correct prediction
Energy consumption = 150.431970 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79877, 0.0502, 0.054128, 0.029414, 0.010285, 0.0046871, 0.36835, 0.007557, 0.1952, 0.082043]
Predicted label: 0
Correct prediction
Energy consumption = 152.566766 pJ
sum error= 213
Actual label: 6
Output voltages: [0.53036, 0.002506, 0.0031698, 0.049181, 0.018127, 0.79075, 0.7968, 0.0040216, 0.63385, 0.010051]
Predicted label: 6
Correct prediction
Energy consumption = 143.773006 pJ
sum error= 213
Actual label: 7
Output voltages: [0.095878, 0.059068, 0.23656, 0.0095742, 0.010308, 0.0011208, 0.0010789, 0.79866, 0.42101, 0.095983]
Predicted label: 7
Correct prediction
Energy consumption = 156.765298 pJ
sum error= 213
Actual label: 0
Output voltages: [0.76177, 0.037742, 0.66037, 0.754, 0.0011742, 0.015669, 0.76803, 0.091003, 0.25621, 0.02554]
Predicted label: 6
Wrong prediction!
Energy consumption = 149.741341 pJ
sum error= 214
Actual label: 2
Output voltages: [0.37103, 0.055694, 0.79874, 0.11792, 0.019149, 0.001246, 0.31689, 0.059518, 0.66298, 0.043852]
Predicted label: 2
Correct prediction
Energy consumption = 142.098471 pJ
sum error= 214
Actual label: 5
Output voltages: [0.027667, 0.013161, 0.002965, 0.70156, 0.018824, 0.79879, 0.050806, 0.032948, 0.75859, 0.063778]
Predicted label: 5
Correct prediction
Energy consumption = 142.291357 pJ
sum error= 214
Actual label: 8
Output voltages: [0.65599, 0.002339, 0.17812, 0.37012, 0.0053455, 0.052613, 0.28886, 0.0099166, 0.7987, 0.053765]
Predicted label: 8
Correct prediction
Energy consumption = 151.781152 pJ
sum error= 214
Actual label: 1
Output voltages: [0.033215, 0.79843, 0.027139, 0.18579, 0.34987, 0.010256, 0.31459, 0.02242, 0.022084, 0.15125]
Predicted label: 1
Correct prediction
Energy consumption = 167.144742 pJ
sum error= 214
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 407 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 407 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 407 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.35302, 0.033886, 0.029329, 0.025283, 0.04272, 0.23348, 0.004545, 0.019423, 0.45037]
Predicted label: 0
Correct prediction
Energy consumption = 174.016116 pJ
sum error= 214
Actual label: 4
Output voltages: [0.1456, 0.030621, 0.044706, 0.024306, 0.79873, 0.0021895, 0.25325, 0.11304, 0.015522, 0.01667]
Predicted label: 4
Correct prediction
Energy consumption = 155.351022 pJ
sum error= 214
Actual label: 5
Output voltages: [0.13635, 0.0022196, 0.001066, 0.5346, 0.01735, 0.79876, 0.086147, 0.028221, 0.7682, 0.043618]
Predicted label: 5
Correct prediction
Energy consumption = 155.829838 pJ
sum error= 214
Actual label: 7
Output voltages: [0.23678, 0.0071434, 0.023651, 0.20282, 0.014338, 0.0070839, 0.0011413, 0.7987, 0.52907, 0.53438]
Predicted label: 7
Correct prediction
Energy consumption = 154.000271 pJ
sum error= 214
Actual label: 1
Output voltages: [0.03461, 0.79841, 0.0092679, 0.086407, 0.20411, 0.0099163, 0.092108, 0.019193, 0.047747, 0.36044]
Predicted label: 1
Correct prediction
Energy consumption = 161.760306 pJ
sum error= 214
Actual label: 8
Output voltages: [0.79052, 0.0095442, 0.044756, 0.55862, 0.0019012, 0.028625, 0.25715, 0.017791, 0.79367, 0.027009]
Predicted label: 8
Correct prediction
Energy consumption = 159.546369 pJ
sum error= 214
Actual label: 5
Output voltages: [0.31264, 0.0026047, 0.029663, 0.090317, 0.018192, 0.77871, 0.5208, 0.0019344, 0.43917, 0.045478]
Predicted label: 5
Correct prediction
Energy consumption = 149.753483 pJ
sum error= 214
Actual label: 1
Output voltages: [0.0013691, 0.79876, 0.32968, 0.64839, 0.073577, 0.011651, 0.018865, 0.16291, 0.0031396, 0.0091672]
Predicted label: 1
Correct prediction
Energy consumption = 164.949417 pJ
sum error= 214
Actual label: 9
Output voltages: [0.3255, 0.0026843, 0.78512, 0.51516, 0.020125, 0.0011105, 0.0031309, 0.27028, 0.77113, 0.016036]
Predicted label: 2
Wrong prediction!
Energy consumption = 147.075509 pJ
sum error= 215
Actual label: 0
Output voltages: [0.79879, 0.13169, 0.0033374, 0.022794, 0.013785, 0.050278, 0.59632, 0.015612, 0.077552, 0.39912]
Predicted label: 0
Correct prediction
Energy consumption = 154.856010 pJ
sum error= 215
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 408 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 408 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 408 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7986, 0.31275, 0.15101, 0.0022502, 0.014751, 0.0017219, 0.41105, 0.016125, 0.52546, 0.14239]
Predicted label: 0
Correct prediction
Energy consumption = 177.671238 pJ
sum error= 215
Actual label: 6
Output voltages: [0.08751, 0.0072931, 0.013317, 0.026915, 0.14544, 0.42503, 0.7897, 0.02512, 0.79682, 0.023288]
Predicted label: 8
Wrong prediction!
Energy consumption = 141.926164 pJ
sum error= 216
Actual label: 0
Output voltages: [0.79871, 0.018035, 0.044371, 0.016467, 0.023653, 0.43535, 0.20945, 0.0018589, 0.22934, 0.059665]
Predicted label: 0
Correct prediction
Energy consumption = 150.867448 pJ
sum error= 216
Actual label: 7
Output voltages: [0.066156, 0.048717, 0.17079, 0.025917, 0.0015316, 0.0012712, 0.0010733, 0.79861, 0.33579, 0.18489]
Predicted label: 7
Correct prediction
Energy consumption = 150.994067 pJ
sum error= 216
Actual label: 3
Output voltages: [0.19944, 0.052076, 0.017971, 0.79869, 0.0053342, 0.002795, 0.010695, 0.027249, 0.35298, 0.24952]
Predicted label: 3
Correct prediction
Energy consumption = 148.677982 pJ
sum error= 216
Actual label: 1
Output voltages: [0.049153, 0.79836, 0.1356, 0.19374, 0.0066199, 0.0073461, 0.37357, 0.025015, 0.42472, 0.047419]
Predicted label: 1
Correct prediction
Energy consumption = 159.434544 pJ
sum error= 216
Actual label: 8
Output voltages: [0.032298, 0.0054104, 0.13857, 0.01655, 0.023831, 0.33861, 0.080289, 0.047597, 0.79878, 0.0050259]
Predicted label: 8
Correct prediction
Energy consumption = 151.895531 pJ
sum error= 216
Actual label: 3
Output voltages: [0.21864, 0.003043, 0.24881, 0.79869, 0.039204, 0.0023573, 0.0022812, 0.004889, 0.7274, 0.021195]
Predicted label: 3
Correct prediction
Energy consumption = 146.165840 pJ
sum error= 216
Actual label: 9
Output voltages: [0.10266, 0.044576, 0.05071, 0.038183, 0.06254, 0.011218, 0.0065375, 0.0092216, 0.51813, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 152.055297 pJ
sum error= 216
Actual label: 7
Output voltages: [0.04517, 0.034831, 0.60108, 0.011274, 0.0010802, 0.0039993, 0.0011371, 0.79877, 0.77696, 0.035066]
Predicted label: 7
Correct prediction
Energy consumption = 145.346983 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 409 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 409 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 409 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79868, 0.13394, 0.025808, 0.045684, 0.027588, 0.012105, 0.70694, 0.012357, 0.043068, 0.054691]
Predicted label: 0
Correct prediction
Energy consumption = 176.797820 pJ
sum error= 216
Actual label: 0
Output voltages: [0.79864, 0.058452, 0.065926, 0.014153, 0.0011733, 0.0036086, 0.58219, 0.046782, 0.2986, 0.033905]
Predicted label: 0
Correct prediction
Energy consumption = 147.895797 pJ
sum error= 216
Actual label: 8
Output voltages: [0.025087, 0.12363, 0.044442, 0.047548, 0.0020484, 0.087858, 0.38853, 0.046256, 0.79878, 0.009207]
Predicted label: 8
Correct prediction
Energy consumption = 154.982650 pJ
sum error= 216
Actual label: 9
Output voltages: [0.26372, 0.01193, 0.052085, 0.021178, 0.78637, 0.040039, 0.19659, 0.048545, 0.012309, 0.77512]
Predicted label: 4
Wrong prediction!
Energy consumption = 148.353520 pJ
sum error= 217
Actual label: 5
Output voltages: [0.20424, 0.0010843, 0.016095, 0.5278, 0.0013694, 0.79749, 0.032352, 0.055966, 0.76657, 0.054992]
Predicted label: 5
Correct prediction
Energy consumption = 145.919947 pJ
sum error= 217
Actual label: 9
Output voltages: [0.52847, 0.0016437, 0.0074288, 0.01814, 0.065266, 0.077684, 0.0052584, 0.12497, 0.57071, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 151.344921 pJ
sum error= 217
Actual label: 8
Output voltages: [0.0021337, 0.14758, 0.20912, 0.077372, 0.015654, 0.068313, 0.019199, 0.092331, 0.79866, 0.051598]
Predicted label: 8
Correct prediction
Energy consumption = 138.372809 pJ
sum error= 217
Actual label: 3
Output voltages: [0.59502, 0.020831, 0.26181, 0.79868, 0.12547, 0.0013908, 0.010765, 0.040402, 0.45624, 0.019508]
Predicted label: 3
Correct prediction
Energy consumption = 145.015876 pJ
sum error= 217
Actual label: 2
Output voltages: [0.43858, 0.049158, 0.79879, 0.045517, 0.029241, 0.001129, 0.055175, 0.090198, 0.42258, 0.036875]
Predicted label: 2
Correct prediction
Energy consumption = 140.479155 pJ
sum error= 217
Actual label: 7
Output voltages: [0.26767, 0.025774, 0.78004, 0.028629, 0.0018775, 0.0011524, 0.0011296, 0.79876, 0.56422, 0.20272]
Predicted label: 7
Correct prediction
Energy consumption = 135.796703 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 410 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 410 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 410 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.23338, 0.021039, 0.79874, 0.44582, 0.0065594, 0.0012812, 0.16466, 0.024754, 0.54446, 0.007977]
Predicted label: 2
Correct prediction
Energy consumption = 159.247840 pJ
sum error= 217
Actual label: 9
Output voltages: [0.27273, 0.0060146, 0.065023, 0.012515, 0.12733, 0.019452, 0.0026333, 0.11222, 0.62568, 0.7951]
Predicted label: 9
Correct prediction
Energy consumption = 155.060869 pJ
sum error= 217
Actual label: 7
Output voltages: [0.31816, 0.015852, 0.0010708, 0.62776, 0.32867, 0.039747, 0.0027882, 0.75416, 0.014127, 0.73013]
Predicted label: 7
Correct prediction
Energy consumption = 149.275080 pJ
sum error= 217
Actual label: 2
Output voltages: [0.24045, 0.22363, 0.79879, 0.39866, 0.022498, 0.0012986, 0.14743, 0.056414, 0.17913, 0.041787]
Predicted label: 2
Correct prediction
Energy consumption = 146.323991 pJ
sum error= 217
Actual label: 1
Output voltages: [0.023987, 0.79867, 0.044123, 0.10303, 0.036623, 0.0012116, 0.4491, 0.0018606, 0.42252, 0.1569]
Predicted label: 1
Correct prediction
Energy consumption = 158.859108 pJ
sum error= 217
Actual label: 1
Output voltages: [0.01538, 0.79856, 0.022141, 0.044802, 0.065954, 0.0065947, 0.55431, 0.0020473, 0.45426, 0.1206]
Predicted label: 1
Correct prediction
Energy consumption = 148.390523 pJ
sum error= 217
Actual label: 3
Output voltages: [0.095464, 0.055378, 0.16502, 0.79871, 0.017769, 0.0024073, 0.0081042, 0.0038827, 0.75243, 0.053862]
Predicted label: 3
Correct prediction
Energy consumption = 143.260837 pJ
sum error= 217
Actual label: 7
Output voltages: [0.010904, 0.02915, 0.73964, 0.2874, 0.015683, 0.0010904, 0.01658, 0.79875, 0.20074, 0.044068]
Predicted label: 7
Correct prediction
Energy consumption = 141.559364 pJ
sum error= 217
Actual label: 5
Output voltages: [0.0521, 0.0016596, 0.002285, 0.46294, 0.028838, 0.79873, 0.039969, 0.010032, 0.54971, 0.026205]
Predicted label: 5
Correct prediction
Energy consumption = 149.689367 pJ
sum error= 217
Actual label: 3
Output voltages: [0.4975, 0.016628, 0.072815, 0.79876, 0.0013333, 0.015445, 0.029257, 0.020792, 0.3335, 0.024853]
Predicted label: 3
Correct prediction
Energy consumption = 144.424754 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 411 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 411 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 411 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.023402, 0.79876, 0.001073, 0.016388, 0.51223, 0.0085018, 0.29382, 0.0071441, 0.29721, 0.14733]
Predicted label: 1
Correct prediction
Energy consumption = 178.007013 pJ
sum error= 217
Actual label: 9
Output voltages: [0.052037, 0.001498, 0.53481, 0.018686, 0.096859, 0.017869, 0.35556, 0.0015599, 0.57483, 0.77321]
Predicted label: 9
Correct prediction
Energy consumption = 153.231608 pJ
sum error= 217
Actual label: 8
Output voltages: [0.18876, 0.0034044, 0.5047, 0.054359, 0.0068983, 0.028319, 0.025296, 0.018292, 0.79878, 0.041684]
Predicted label: 8
Correct prediction
Energy consumption = 144.808565 pJ
sum error= 217
Actual label: 2
Output voltages: [0.54969, 0.55771, 0.79874, 0.32418, 0.018348, 0.0013662, 0.2629, 0.036181, 0.065967, 0.018997]
Predicted label: 2
Correct prediction
Energy consumption = 152.721625 pJ
sum error= 217
Actual label: 2
Output voltages: [0.052104, 0.50276, 0.79856, 0.064879, 0.0014705, 0.0011313, 0.018354, 0.50678, 0.26871, 0.057213]
Predicted label: 2
Correct prediction
Energy consumption = 143.526765 pJ
sum error= 217
Actual label: 2
Output voltages: [0.47923, 0.007401, 0.79879, 0.25868, 0.010219, 0.0011927, 0.015256, 0.18527, 0.67906, 0.0076293]
Predicted label: 2
Correct prediction
Energy consumption = 146.390690 pJ
sum error= 217
Actual label: 8
Output voltages: [0.40607, 0.0084737, 0.33556, 0.1963, 0.012922, 0.04712, 0.45364, 0.0011637, 0.78415, 0.50887]
Predicted label: 8
Correct prediction
Energy consumption = 151.074067 pJ
sum error= 217
Actual label: 8
Output voltages: [0.022649, 0.011724, 0.37635, 0.041383, 0.036997, 0.0068873, 0.020454, 0.0011308, 0.7982, 0.64444]
Predicted label: 8
Correct prediction
Energy consumption = 139.004660 pJ
sum error= 217
Actual label: 5
Output voltages: [0.012848, 0.0010913, 0.0072564, 0.35812, 0.025342, 0.79195, 0.27352, 0.0031912, 0.75516, 0.046331]
Predicted label: 5
Correct prediction
Energy consumption = 135.025651 pJ
sum error= 217
Actual label: 7
Output voltages: [0.039256, 0.52609, 0.41492, 0.056234, 0.0045603, 0.0011758, 0.0011598, 0.79873, 0.036991, 0.19555]
Predicted label: 7
Correct prediction
Energy consumption = 152.320511 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 412 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 412 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 412 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.77999, 0.030588, 0.048331, 0.79876, 0.0010739, 0.33058, 0.0012536, 0.1563, 0.14211, 0.0029539]
Predicted label: 3
Correct prediction
Energy consumption = 166.085566 pJ
sum error= 217
Actual label: 8
Output voltages: [0.23236, 0.037346, 0.22143, 0.28829, 0.019229, 0.0044708, 0.038571, 0.0021203, 0.79879, 0.23092]
Predicted label: 8
Correct prediction
Energy consumption = 152.870429 pJ
sum error= 217
Actual label: 9
Output voltages: [0.31845, 0.0017278, 0.0071968, 0.017338, 0.22303, 0.36346, 0.0049504, 0.24574, 0.2065, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 154.030923 pJ
sum error= 217
Actual label: 8
Output voltages: [0.051792, 0.0072465, 0.17756, 0.74399, 0.0010664, 0.023128, 0.0075971, 0.019472, 0.79757, 0.35926]
Predicted label: 8
Correct prediction
Energy consumption = 150.406791 pJ
sum error= 217
Actual label: 8
Output voltages: [0.18399, 0.0065683, 0.28534, 0.74855, 0.003096, 0.0047243, 0.0049364, 0.0011515, 0.7863, 0.18968]
Predicted label: 8
Correct prediction
Energy consumption = 155.375519 pJ
sum error= 217
Actual label: 6
Output voltages: [0.051066, 0.037203, 0.15952, 0.0031898, 0.25765, 0.25897, 0.79874, 0.0017614, 0.55218, 0.0046695]
Predicted label: 6
Correct prediction
Energy consumption = 141.086369 pJ
sum error= 217
Actual label: 8
Output voltages: [0.043758, 0.02511, 0.48708, 0.44219, 0.004509, 0.0010692, 0.0046038, 0.029301, 0.79679, 0.059824]
Predicted label: 8
Correct prediction
Energy consumption = 158.636214 pJ
sum error= 217
Actual label: 2
Output voltages: [0.46528, 0.055692, 0.79878, 0.13375, 0.016199, 0.0013023, 0.26309, 0.036857, 0.52203, 0.051222]
Predicted label: 2
Correct prediction
Energy consumption = 146.206026 pJ
sum error= 217
Actual label: 3
Output voltages: [0.16496, 0.0066689, 0.091458, 0.7987, 0.33792, 0.03892, 0.027562, 0.057315, 0.38546, 0.10303]
Predicted label: 3
Correct prediction
Energy consumption = 140.631882 pJ
sum error= 217
Actual label: 9
Output voltages: [0.40801, 0.046496, 0.0041438, 0.37842, 0.26109, 0.016748, 0.017912, 0.0035587, 0.028317, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 148.736939 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 413 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 413 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 413 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.047778, 0.014125, 0.36345, 0.040181, 0.0014682, 0.0015866, 0.0012134, 0.79879, 0.78588, 0.063573]
Predicted label: 7
Correct prediction
Energy consumption = 174.999792 pJ
sum error= 217
Actual label: 5
Output voltages: [0.045064, 0.0046458, 0.0018286, 0.46268, 0.0015291, 0.79878, 0.049526, 0.018056, 0.79392, 0.0024621]
Predicted label: 5
Correct prediction
Energy consumption = 151.073902 pJ
sum error= 217
Actual label: 6
Output voltages: [0.09408, 0.056197, 0.23282, 0.0016959, 0.25098, 0.11783, 0.79874, 0.0049773, 0.62145, 0.0076721]
Predicted label: 6
Correct prediction
Energy consumption = 145.873172 pJ
sum error= 217
Actual label: 2
Output voltages: [0.23194, 0.030186, 0.79864, 0.02978, 0.027212, 0.0010661, 0.051396, 0.0083602, 0.49899, 0.021798]
Predicted label: 2
Correct prediction
Energy consumption = 139.333747 pJ
sum error= 217
Actual label: 9
Output voltages: [0.25762, 0.014483, 0.022001, 0.044748, 0.44466, 0.0012478, 0.032725, 0.0013729, 0.40161, 0.79726]
Predicted label: 9
Correct prediction
Energy consumption = 157.376228 pJ
sum error= 217
Actual label: 2
Output voltages: [0.45448, 0.04496, 0.79721, 0.12793, 0.012019, 0.0012621, 0.097256, 0.53294, 0.26479, 0.019656]
Predicted label: 2
Correct prediction
Energy consumption = 153.822817 pJ
sum error= 217
Actual label: 8
Output voltages: [0.058056, 0.027996, 0.74448, 0.038659, 0.017025, 0.0014248, 0.10371, 0.0021494, 0.79879, 0.25151]
Predicted label: 8
Correct prediction
Energy consumption = 145.978941 pJ
sum error= 217
Actual label: 8
Output voltages: [0.0076531, 0.041697, 0.023874, 0.042344, 0.01565, 0.048555, 0.4839, 0.015336, 0.79875, 0.035498]
Predicted label: 8
Correct prediction
Energy consumption = 151.284404 pJ
sum error= 217
Actual label: 1
Output voltages: [0.029274, 0.7986, 0.036083, 0.025775, 0.039669, 0.0016556, 0.57635, 0.0044145, 0.24473, 0.053777]
Predicted label: 1
Correct prediction
Energy consumption = 158.382894 pJ
sum error= 217
Actual label: 6
Output voltages: [0.19497, 0.023977, 0.24857, 0.0035659, 0.3279, 0.29992, 0.79879, 0.0013525, 0.56132, 0.02913]
Predicted label: 6
Correct prediction
Energy consumption = 137.718965 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 414 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 414 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 414 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.28589, 0.013529, 0.4355, 0.050881, 0.017347, 0.0040968, 0.028687, 0.0023584, 0.79879, 0.37702]
Predicted label: 8
Correct prediction
Energy consumption = 170.041786 pJ
sum error= 217
Actual label: 8
Output voltages: [0.013695, 0.036342, 0.26531, 0.024016, 0.012825, 0.019951, 0.012029, 0.02509, 0.79874, 0.27044]
Predicted label: 8
Correct prediction
Energy consumption = 149.571598 pJ
sum error= 217
Actual label: 7
Output voltages: [0.37363, 0.023355, 0.27264, 0.1354, 0.0017415, 0.0053765, 0.0011639, 0.79875, 0.35957, 0.48252]
Predicted label: 7
Correct prediction
Energy consumption = 138.705879 pJ
sum error= 217
Actual label: 9
Output voltages: [0.32653, 0.029967, 0.014882, 0.03838, 0.37075, 0.0022171, 0.0012646, 0.02278, 0.15673, 0.79843]
Predicted label: 9
Correct prediction
Energy consumption = 156.102976 pJ
sum error= 217
Actual label: 1
Output voltages: [0.0088345, 0.7984, 0.10109, 0.089524, 0.015601, 0.0017086, 0.50394, 0.0043698, 0.14261, 0.13267]
Predicted label: 1
Correct prediction
Energy consumption = 160.848031 pJ
sum error= 217
Actual label: 8
Output voltages: [0.2989, 0.032589, 0.25489, 0.67416, 0.0011345, 0.24, 0.036401, 0.0012628, 0.79879, 0.25919]
Predicted label: 8
Correct prediction
Energy consumption = 158.130282 pJ
sum error= 217
Actual label: 0
Output voltages: [0.79856, 0.018695, 0.0043239, 0.1777, 0.0091238, 0.29322, 0.65873, 0.020491, 0.23611, 0.027112]
Predicted label: 0
Correct prediction
Energy consumption = 149.883630 pJ
sum error= 217
Actual label: 1
Output voltages: [0.2024, 0.79855, 0.64007, 0.031697, 0.32749, 0.0010728, 0.29729, 0.014846, 0.016554, 0.22428]
Predicted label: 1
Correct prediction
Energy consumption = 161.236518 pJ
sum error= 217
Actual label: 7
Output voltages: [0.048422, 0.21839, 0.78786, 0.28123, 0.015838, 0.001275, 0.0026619, 0.79711, 0.089729, 0.17861]
Predicted label: 7
Correct prediction
Energy consumption = 146.094084 pJ
sum error= 217
Actual label: 2
Output voltages: [0.67391, 0.0091242, 0.79872, 0.5197, 0.013898, 0.0010735, 0.034853, 0.15219, 0.66032, 0.017625]
Predicted label: 2
Correct prediction
Energy consumption = 143.672405 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 415 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 415 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 415 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.1165, 0.040753, 0.011947, 0.016231, 0.010365, 0.59587, 0.015704, 0.044074, 0.034373]
Predicted label: 0
Correct prediction
Energy consumption = 164.611711 pJ
sum error= 217
Actual label: 7
Output voltages: [0.74705, 0.02586, 0.0038721, 0.019846, 0.026711, 0.060275, 0.0014969, 0.79878, 0.11196, 0.20136]
Predicted label: 7
Correct prediction
Energy consumption = 152.431564 pJ
sum error= 217
Actual label: 5
Output voltages: [0.042289, 0.33226, 0.0010684, 0.0092024, 0.006906, 0.79867, 0.201, 0.05429, 0.52463, 0.081039]
Predicted label: 5
Correct prediction
Energy consumption = 147.450240 pJ
sum error= 217
Actual label: 1
Output voltages: [0.036497, 0.79854, 0.048688, 0.033904, 0.036736, 0.0013224, 0.49719, 0.0014521, 0.2195, 0.049454]
Predicted label: 1
Correct prediction
Energy consumption = 164.531200 pJ
sum error= 217
Actual label: 9
Output voltages: [0.76383, 0.0011234, 0.064855, 0.014937, 0.42317, 0.012498, 0.0091695, 0.0073326, 0.15202, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 144.801819 pJ
sum error= 217
Actual label: 0
Output voltages: [0.79876, 0.32997, 0.010859, 0.0081963, 0.012038, 0.029416, 0.48798, 0.0069784, 0.21953, 0.24724]
Predicted label: 0
Correct prediction
Energy consumption = 150.581276 pJ
sum error= 217
Actual label: 2
Output voltages: [0.041004, 0.31787, 0.78842, 0.75214, 0.016817, 0.0011956, 0.031022, 0.028617, 0.60086, 0.15329]
Predicted label: 2
Correct prediction
Energy consumption = 155.123107 pJ
sum error= 217
Actual label: 0
Output voltages: [0.79821, 0.051591, 0.043164, 0.018266, 0.038158, 0.0011304, 0.69332, 0.014294, 0.44363, 0.049145]
Predicted label: 0
Correct prediction
Energy consumption = 144.725897 pJ
sum error= 217
Actual label: 9
Output voltages: [0.29166, 0.0036502, 0.0056612, 0.04395, 0.31366, 0.58475, 0.027612, 0.33536, 0.35196, 0.78692]
Predicted label: 9
Correct prediction
Energy consumption = 145.687784 pJ
sum error= 217
Actual label: 8
Output voltages: [0.23792, 0.0020694, 0.40114, 0.39887, 0.021075, 0.016159, 0.0024757, 0.043995, 0.79854, 0.27093]
Predicted label: 8
Correct prediction
Energy consumption = 154.947195 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 416 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 416 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 416 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.25059, 0.089232, 0.14098, 0.0012856, 0.048926, 0.058382, 0.79879, 0.0026735, 0.50003, 0.0086811]
Predicted label: 6
Correct prediction
Energy consumption = 166.231919 pJ
sum error= 217
Actual label: 2
Output voltages: [0.27458, 0.05476, 0.79866, 0.084079, 0.024728, 0.0010668, 0.050374, 0.035864, 0.43746, 0.01656]
Predicted label: 2
Correct prediction
Energy consumption = 146.327852 pJ
sum error= 217
Actual label: 3
Output voltages: [0.12719, 0.023271, 0.069876, 0.79867, 0.021245, 0.0032963, 0.010114, 0.024549, 0.56674, 0.058469]
Predicted label: 3
Correct prediction
Energy consumption = 141.664018 pJ
sum error= 217
Actual label: 9
Output voltages: [0.78812, 0.016666, 0.0019033, 0.46827, 0.043815, 0.041372, 0.014136, 0.034015, 0.49753, 0.77491]
Predicted label: 0
Wrong prediction!
Energy consumption = 145.238165 pJ
sum error= 218
Actual label: 3
Output voltages: [0.073004, 0.0027387, 0.0782, 0.79878, 0.2009, 0.016942, 0.01562, 0.020946, 0.73919, 0.03704]
Predicted label: 3
Correct prediction
Energy consumption = 139.913366 pJ
sum error= 218
Actual label: 8
Output voltages: [0.48116, 0.58563, 0.097625, 0.017209, 0.0010724, 0.014416, 0.67181, 0.0062138, 0.77705, 0.029221]
Predicted label: 8
Correct prediction
Energy consumption = 157.895883 pJ
sum error= 218
Actual label: 0
Output voltages: [0.7829, 0.34048, 0.26491, 0.010258, 0.001181, 0.0032422, 0.61506, 0.077843, 0.68214, 0.052885]
Predicted label: 0
Correct prediction
Energy consumption = 154.821106 pJ
sum error= 218
Actual label: 2
Output voltages: [0.33535, 0.0011593, 0.79879, 0.25007, 0.0079279, 0.0010994, 0.033665, 0.42886, 0.79309, 0.016718]
Predicted label: 2
Correct prediction
Energy consumption = 144.407802 pJ
sum error= 218
Actual label: 1
Output voltages: [0.2671, 0.79872, 0.013371, 0.3533, 0.0026304, 0.01117, 0.75223, 0.0052977, 0.29206, 0.0082695]
Predicted label: 1
Correct prediction
Energy consumption = 156.904803 pJ
sum error= 218
Actual label: 1
Output voltages: [0.0012091, 0.7986, 0.047845, 0.086691, 0.011143, 0.0014753, 0.77311, 0.038488, 0.12881, 0.015002]
Predicted label: 1
Correct prediction
Energy consumption = 145.242889 pJ
sum error= 218
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 417 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 417 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 417 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0052926, 0.79878, 0.22123, 0.1945, 0.031142, 0.045019, 0.28008, 0.012644, 0.47873, 0.018141]
Predicted label: 1
Correct prediction
Energy consumption = 180.412844 pJ
sum error= 218
Actual label: 1
Output voltages: [0.023363, 0.79877, 0.20138, 0.2361, 0.017859, 0.0010734, 0.23719, 0.0011759, 0.33742, 0.073657]
Predicted label: 1
Correct prediction
Energy consumption = 148.639452 pJ
sum error= 218
Actual label: 4
Output voltages: [0.0025629, 0.021678, 0.074052, 0.014695, 0.79873, 0.0011233, 0.061759, 0.049114, 0.04473, 0.14096]
Predicted label: 4
Correct prediction
Energy consumption = 156.720802 pJ
sum error= 218
Actual label: 2
Output voltages: [0.057007, 0.018388, 0.7987, 0.51627, 0.45759, 0.0011342, 0.026413, 0.044294, 0.25493, 0.11109]
Predicted label: 2
Correct prediction
Energy consumption = 143.939675 pJ
sum error= 218
Actual label: 9
Output voltages: [0.13868, 0.020533, 0.033097, 0.020019, 0.20087, 0.020082, 0.0024652, 0.010789, 0.47058, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 155.734059 pJ
sum error= 218
Actual label: 7
Output voltages: [0.085785, 0.23821, 0.42853, 0.20497, 0.0050567, 0.0011793, 0.0010666, 0.79869, 0.30483, 0.30808]
Predicted label: 7
Correct prediction
Energy consumption = 152.928576 pJ
sum error= 218
Actual label: 2
Output voltages: [0.015679, 0.026778, 0.09386, 0.0020782, 0.0010749, 0.024901, 0.058997, 0.55572, 0.79848, 0.080371]
Predicted label: 8
Wrong prediction!
Energy consumption = 140.292656 pJ
sum error= 219
Actual label: 5
Output voltages: [0.014631, 0.0011029, 0.0026021, 0.1375, 0.60584, 0.79879, 0.19915, 0.0038158, 0.45658, 0.040833]
Predicted label: 5
Correct prediction
Energy consumption = 148.929069 pJ
sum error= 219
Actual label: 1
Output voltages: [0.059628, 0.79879, 0.028825, 0.023992, 0.2164, 0.018257, 0.7894, 0.0024534, 0.27172, 0.014641]
Predicted label: 1
Correct prediction
Energy consumption = 154.402850 pJ
sum error= 219
Actual label: 1
Output voltages: [0.025631, 0.79845, 0.31706, 0.24674, 0.040121, 0.0011815, 0.60813, 0.0028989, 0.070565, 0.33002]
Predicted label: 1
Correct prediction
Energy consumption = 157.230037 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 418 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 418 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 418 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.61927, 0.11946, 0.79542, 0.073365, 0.0092709, 0.0011379, 0.5007, 0.0041399, 0.46749, 0.0041275]
Predicted label: 2
Correct prediction
Energy consumption = 167.251378 pJ
sum error= 219
Actual label: 1
Output voltages: [0.013952, 0.79873, 0.30855, 0.028448, 0.025281, 0.0012583, 0.7706, 0.0082921, 0.27334, 0.056942]
Predicted label: 1
Correct prediction
Energy consumption = 162.058544 pJ
sum error= 219
Actual label: 9
Output voltages: [0.3409, 0.013441, 0.02642, 0.030167, 0.14556, 0.033034, 0.018311, 0.043079, 0.40467, 0.79758]
Predicted label: 9
Correct prediction
Energy consumption = 157.538533 pJ
sum error= 219
Actual label: 9
Output voltages: [0.15418, 0.0034638, 0.014205, 0.16195, 0.40994, 0.24686, 0.018793, 0.017783, 0.068431, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 144.975500 pJ
sum error= 219
Actual label: 9
Output voltages: [0.48394, 0.014571, 0.030877, 0.15775, 0.38185, 0.011022, 0.0067136, 0.066033, 0.25583, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.942195 pJ
sum error= 219
Actual label: 1
Output voltages: [0.02558, 0.79833, 0.013884, 0.010476, 0.33693, 0.0040928, 0.25442, 0.0069988, 0.40638, 0.035475]
Predicted label: 1
Correct prediction
Energy consumption = 149.522024 pJ
sum error= 219
Actual label: 0
Output voltages: [0.79806, 0.14259, 0.30692, 0.019898, 0.013973, 0.0011924, 0.36446, 0.0049945, 0.39757, 0.024515]
Predicted label: 0
Correct prediction
Energy consumption = 154.409595 pJ
sum error= 219
Actual label: 2
Output voltages: [0.016043, 0.0022928, 0.79631, 0.3179, 0.0016492, 0.0012071, 0.028979, 0.53659, 0.39442, 0.037932]
Predicted label: 2
Correct prediction
Energy consumption = 138.849994 pJ
sum error= 219
Actual label: 0
Output voltages: [0.79827, 0.18494, 0.055977, 0.0076435, 0.0018084, 0.0011158, 0.30896, 0.019686, 0.15191, 0.11262]
Predicted label: 0
Correct prediction
Energy consumption = 147.078895 pJ
sum error= 219
Actual label: 2
Output voltages: [0.67337, 0.01813, 0.79879, 0.24531, 0.00182, 0.0011622, 0.031483, 0.30808, 0.68466, 0.0080413]
Predicted label: 2
Correct prediction
Energy consumption = 141.229983 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 419 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 419 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 419 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.045695, 0.79852, 0.16599, 0.58141, 0.028389, 0.0011474, 0.19394, 0.040185, 0.031715, 0.14532]
Predicted label: 1
Correct prediction
Energy consumption = 183.809922 pJ
sum error= 219
Actual label: 1
Output voltages: [0.017947, 0.79845, 0.016886, 0.086685, 0.17809, 0.01342, 0.33102, 0.026955, 0.066492, 0.15315]
Predicted label: 1
Correct prediction
Energy consumption = 160.667885 pJ
sum error= 219
Actual label: 4
Output voltages: [0.011387, 0.011958, 0.19275, 0.0085253, 0.7986, 0.0064688, 0.23005, 0.080084, 0.034096, 0.019348]
Predicted label: 4
Correct prediction
Energy consumption = 158.947808 pJ
sum error= 219
Actual label: 6
Output voltages: [0.32164, 0.2192, 0.39222, 0.0010911, 0.047843, 0.10555, 0.79878, 0.0025746, 0.36255, 0.0044748]
Predicted label: 6
Correct prediction
Energy consumption = 150.875942 pJ
sum error= 219
Actual label: 4
Output voltages: [0.22959, 0.0036727, 0.11735, 0.023558, 0.79854, 0.0013764, 0.001837, 0.14026, 0.0080536, 0.76317]
Predicted label: 4
Correct prediction
Energy consumption = 157.585226 pJ
sum error= 219
Actual label: 1
Output voltages: [0.20086, 0.79855, 0.039163, 0.35679, 0.037826, 0.0014066, 0.15561, 0.0051818, 0.02094, 0.66138]
Predicted label: 1
Correct prediction
Energy consumption = 161.672283 pJ
sum error= 219
Actual label: 5
Output voltages: [0.31704, 0.0010689, 0.01062, 0.7754, 0.0086891, 0.77523, 0.017523, 0.098367, 0.42135, 0.1606]
Predicted label: 3
Wrong prediction!
Energy consumption = 152.476743 pJ
sum error= 220
Actual label: 4
Output voltages: [0.0085914, 0.019923, 0.11051, 0.0067617, 0.79875, 0.0035893, 0.66138, 0.037786, 0.038367, 0.40793]
Predicted label: 4
Correct prediction
Energy consumption = 156.146792 pJ
sum error= 220
Actual label: 9
Output voltages: [0.4156, 0.027006, 0.012276, 0.06749, 0.25552, 0.012737, 0.0015863, 0.019871, 0.27383, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 147.381034 pJ
sum error= 220
Actual label: 7
Output voltages: [0.034532, 0.18933, 0.0071149, 0.020911, 0.40435, 0.0024481, 0.0010712, 0.7775, 0.0011555, 0.7671]
Predicted label: 7
Correct prediction
Energy consumption = 146.591221 pJ
sum error= 220
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 420 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 420 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 420 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37495, 0.36225, 0.0039959, 0.041162, 0.011914, 0.017589, 0.0018621, 0.79871, 0.094535, 0.35892]
Predicted label: 7
Correct prediction
Energy consumption = 174.063605 pJ
sum error= 220
Actual label: 1
Output voltages: [0.19098, 0.78191, 0.0010882, 0.0010909, 0.22392, 0.0041528, 0.019562, 0.79341, 0.077106, 0.41899]
Predicted label: 7
Wrong prediction!
Energy consumption = 152.569329 pJ
sum error= 221
Actual label: 5
Output voltages: [0.026181, 0.0011124, 0.0050284, 0.16994, 0.010821, 0.79728, 0.3557, 0.0065343, 0.73436, 0.040911]
Predicted label: 5
Correct prediction
Energy consumption = 146.789076 pJ
sum error= 221
Actual label: 6
Output voltages: [0.20488, 0.020984, 0.15657, 0.0013762, 0.32921, 0.042682, 0.79879, 0.0065851, 0.66598, 0.0091984]
Predicted label: 6
Correct prediction
Energy consumption = 150.918952 pJ
sum error= 221
Actual label: 2
Output voltages: [0.33143, 0.028558, 0.79877, 0.26552, 0.011043, 0.0011074, 0.36323, 0.026805, 0.54097, 0.020039]
Predicted label: 2
Correct prediction
Energy consumption = 151.985708 pJ
sum error= 221
Actual label: 2
Output voltages: [0.76119, 0.56782, 0.79247, 0.001079, 0.0134, 0.0011793, 0.48049, 0.028747, 0.48977, 0.054239]
Predicted label: 2
Correct prediction
Energy consumption = 155.027123 pJ
sum error= 221
Actual label: 2
Output voltages: [0.69366, 0.021875, 0.79878, 0.23556, 0.01244, 0.0010831, 0.087235, 0.043882, 0.59334, 0.028263]
Predicted label: 2
Correct prediction
Energy consumption = 146.905389 pJ
sum error= 221
Actual label: 8
Output voltages: [0.073054, 0.065827, 0.78316, 0.14476, 0.019917, 0.0010671, 0.28648, 0.0018518, 0.78908, 0.026065]
Predicted label: 8
Correct prediction
Energy consumption = 135.260051 pJ
sum error= 221
Actual label: 0
Output voltages: [0.79736, 0.031131, 0.22398, 0.0060334, 0.0012211, 0.00143, 0.64713, 0.0094844, 0.13293, 0.030637]
Predicted label: 0
Correct prediction
Energy consumption = 145.671921 pJ
sum error= 221
Actual label: 6
Output voltages: [0.05758, 0.0028337, 0.037023, 0.0083876, 0.3695, 0.15786, 0.7987, 0.0012754, 0.77658, 0.023629]
Predicted label: 6
Correct prediction
Energy consumption = 143.046743 pJ
sum error= 221
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 421 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 421 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 421 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.62378, 0.015455, 0.017398, 0.077373, 0.18038, 0.026971, 0.014702, 0.016989, 0.098576, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 172.044359 pJ
sum error= 221
Actual label: 6
Output voltages: [0.26387, 0.0011606, 0.0044924, 0.063077, 0.029456, 0.68268, 0.72324, 0.03558, 0.77205, 0.0059835]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.399615 pJ
sum error= 222
Actual label: 1
Output voltages: [0.023889, 0.79855, 0.70959, 0.50517, 0.03602, 0.001154, 0.020935, 0.061629, 0.0025241, 0.051672]
Predicted label: 1
Correct prediction
Energy consumption = 151.357677 pJ
sum error= 222
Actual label: 9
Output voltages: [0.37037, 0.0026578, 0.015258, 0.037941, 0.34329, 0.0073579, 0.0066942, 0.042825, 0.61887, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 158.867956 pJ
sum error= 222
Actual label: 7
Output voltages: [0.32792, 0.022737, 0.01462, 0.021032, 0.099259, 0.014815, 0.0011035, 0.79856, 0.18841, 0.16161]
Predicted label: 7
Correct prediction
Energy consumption = 153.502145 pJ
sum error= 222
Actual label: 7
Output voltages: [0.016099, 0.0018413, 0.2615, 0.63181, 0.043528, 0.0018571, 0.0011472, 0.79877, 0.74057, 0.075497]
Predicted label: 7
Correct prediction
Energy consumption = 140.827653 pJ
sum error= 222
Actual label: 1
Output voltages: [0.0043035, 0.79867, 0.0097966, 0.0086483, 0.010154, 0.0047709, 0.61975, 0.0056597, 0.65321, 0.023933]
Predicted label: 1
Correct prediction
Energy consumption = 157.313453 pJ
sum error= 222
Actual label: 4
Output voltages: [0.018105, 0.0047378, 0.10647, 0.025192, 0.79856, 0.051986, 0.044701, 0.032021, 0.091866, 0.20808]
Predicted label: 4
Correct prediction
Energy consumption = 157.940423 pJ
sum error= 222
Actual label: 8
Output voltages: [0.027082, 0.071647, 0.31109, 0.094163, 0.010729, 0.028507, 0.33803, 0.016292, 0.79879, 0.051362]
Predicted label: 8
Correct prediction
Energy consumption = 149.733004 pJ
sum error= 222
Actual label: 5
Output voltages: [0.019439, 0.0038779, 0.0045945, 0.45479, 0.031733, 0.79843, 0.11524, 0.019242, 0.65712, 0.2184]
Predicted label: 5
Correct prediction
Energy consumption = 141.269857 pJ
sum error= 222
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 422 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 422 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 422 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.32344, 0.0089205, 0.068026, 0.79872, 0.022868, 0.082137, 0.029505, 0.010577, 0.54781, 0.16251]
Predicted label: 3
Correct prediction
Energy consumption = 169.608733 pJ
sum error= 222
Actual label: 4
Output voltages: [0.034195, 0.035043, 0.034482, 0.18291, 0.79873, 0.011774, 0.035354, 0.0030325, 0.011609, 0.36788]
Predicted label: 4
Correct prediction
Energy consumption = 149.644159 pJ
sum error= 222
Actual label: 3
Output voltages: [0.44416, 0.0067485, 0.39022, 0.79879, 0.0043354, 0.0019637, 0.011493, 0.0017655, 0.41762, 0.016617]
Predicted label: 3
Correct prediction
Energy consumption = 149.037424 pJ
sum error= 222
Actual label: 4
Output voltages: [0.0052963, 0.0012612, 0.43377, 0.0013175, 0.79855, 0.013534, 0.21802, 0.01188, 0.33173, 0.062218]
Predicted label: 4
Correct prediction
Energy consumption = 145.107986 pJ
sum error= 222
Actual label: 9
Output voltages: [0.19748, 0.10445, 0.0056788, 0.021673, 0.02197, 0.0015551, 0.0010712, 0.79841, 0.016531, 0.75273]
Predicted label: 7
Wrong prediction!
Energy consumption = 159.040446 pJ
sum error= 223
Actual label: 7
Output voltages: [0.053369, 0.0085986, 0.36836, 0.39219, 0.028459, 0.0058381, 0.0010872, 0.79879, 0.4039, 0.23438]
Predicted label: 7
Correct prediction
Energy consumption = 143.221126 pJ
sum error= 223
Actual label: 5
Output voltages: [0.02887, 0.0015385, 0.016769, 0.6741, 0.017986, 0.79879, 0.041896, 0.35818, 0.75874, 0.11332]
Predicted label: 5
Correct prediction
Energy consumption = 138.866398 pJ
sum error= 223
Actual label: 0
Output voltages: [0.79877, 0.032957, 0.029626, 0.018808, 0.039861, 0.0014413, 0.76134, 0.0042022, 0.075634, 0.42571]
Predicted label: 0
Correct prediction
Energy consumption = 159.381143 pJ
sum error= 223
Actual label: 7
Output voltages: [0.012847, 0.018325, 0.65955, 0.045191, 0.024763, 0.0010833, 0.0012973, 0.79879, 0.2328, 0.14096]
Predicted label: 7
Correct prediction
Energy consumption = 147.337275 pJ
sum error= 223
Actual label: 4
Output voltages: [0.0025652, 0.010455, 0.26245, 0.036528, 0.79866, 0.0046885, 0.036463, 0.023905, 0.042415, 0.043799]
Predicted label: 4
Correct prediction
Energy consumption = 150.820895 pJ
sum error= 223
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 423 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 423 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 423 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.14568, 0.021479, 0.68564, 0.01429, 0.021805, 0.001066, 0.52807, 0.0021481, 0.79812, 0.17149]
Predicted label: 8
Correct prediction
Energy consumption = 162.566868 pJ
sum error= 223
Actual label: 8
Output voltages: [0.0066757, 0.046016, 0.21184, 0.042454, 0.007498, 0.0097996, 0.035954, 0.027828, 0.79872, 0.2097]
Predicted label: 8
Correct prediction
Energy consumption = 140.414540 pJ
sum error= 223
Actual label: 1
Output voltages: [0.021689, 0.79838, 0.0055978, 0.22404, 0.0068586, 0.018148, 0.51847, 0.029051, 0.31865, 0.072862]
Predicted label: 1
Correct prediction
Energy consumption = 163.683125 pJ
sum error= 223
Actual label: 5
Output voltages: [0.058071, 0.0011786, 0.0012237, 0.10777, 0.031193, 0.79879, 0.13715, 0.03174, 0.78495, 0.025195]
Predicted label: 5
Correct prediction
Energy consumption = 152.419037 pJ
sum error= 223
Actual label: 3
Output voltages: [0.22328, 0.020268, 0.03804, 0.79864, 0.029438, 0.0052583, 0.016868, 0.029761, 0.70817, 0.059783]
Predicted label: 3
Correct prediction
Energy consumption = 145.008171 pJ
sum error= 223
Actual label: 9
Output voltages: [0.63876, 0.0060243, 0.02495, 0.055737, 0.14551, 0.10191, 0.0080693, 0.03632, 0.10732, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.027948 pJ
sum error= 223
Actual label: 5
Output voltages: [0.011885, 0.0010662, 0.0017376, 0.26668, 0.16798, 0.79877, 0.22912, 0.019318, 0.77709, 0.01115]
Predicted label: 5
Correct prediction
Energy consumption = 137.208034 pJ
sum error= 223
Actual label: 9
Output voltages: [0.71008, 0.021326, 0.021871, 0.19121, 0.54548, 0.0072543, 0.017909, 0.0069858, 0.029288, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 147.915598 pJ
sum error= 223
Actual label: 7
Output voltages: [0.27879, 0.0025168, 0.071738, 0.72717, 0.010185, 0.0010767, 0.0010824, 0.76712, 0.71235, 0.35396]
Predicted label: 7
Correct prediction
Energy consumption = 144.432323 pJ
sum error= 223
Actual label: 6
Output voltages: [0.033847, 0.0064393, 0.017791, 0.035111, 0.28611, 0.37289, 0.79817, 0.0010772, 0.76911, 0.052608]
Predicted label: 6
Correct prediction
Energy consumption = 147.718514 pJ
sum error= 223
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 424 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 424 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 424 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.21903, 0.0023031, 0.022096, 0.50037, 0.18431, 0.0051542, 0.0030615, 0.035041, 0.1417, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 173.366701 pJ
sum error= 223
Actual label: 0
Output voltages: [0.79878, 0.03201, 0.033156, 0.010131, 0.014701, 0.030118, 0.76108, 0.0067371, 0.088668, 0.043996]
Predicted label: 0
Correct prediction
Energy consumption = 156.614070 pJ
sum error= 223
Actual label: 3
Output voltages: [0.24233, 0.018971, 0.021424, 0.79871, 0.013631, 0.030423, 0.024251, 0.0035163, 0.57972, 0.055501]
Predicted label: 3
Correct prediction
Energy consumption = 146.568763 pJ
sum error= 223
Actual label: 6
Output voltages: [0.20823, 0.054141, 0.032588, 0.010179, 0.033112, 0.33423, 0.79878, 0.014847, 0.66354, 0.033938]
Predicted label: 6
Correct prediction
Energy consumption = 150.567970 pJ
sum error= 223
Actual label: 3
Output voltages: [0.24504, 0.073653, 0.21761, 0.7987, 0.032785, 0.0032663, 0.021746, 0.036291, 0.20037, 0.059052]
Predicted label: 3
Correct prediction
Energy consumption = 149.174568 pJ
sum error= 223
Actual label: 9
Output voltages: [0.091462, 0.0046107, 0.058415, 0.021846, 0.31869, 0.033322, 0.09322, 0.069046, 0.17162, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 151.794253 pJ
sum error= 223
Actual label: 8
Output voltages: [0.030995, 0.030521, 0.11978, 0.067664, 0.009944, 0.041506, 0.0061159, 0.0043768, 0.79879, 0.52845]
Predicted label: 8
Correct prediction
Energy consumption = 149.659281 pJ
sum error= 223
Actual label: 2
Output voltages: [0.31105, 0.035746, 0.79876, 0.082711, 0.013631, 0.0012239, 0.1522, 0.040081, 0.46844, 0.022393]
Predicted label: 2
Correct prediction
Energy consumption = 150.981357 pJ
sum error= 223
Actual label: 2
Output voltages: [0.26131, 0.78182, 0.31388, 0.0010677, 0.33482, 0.0011017, 0.23617, 0.033383, 0.44028, 0.067617]
Predicted label: 1
Wrong prediction!
Energy consumption = 164.163120 pJ
sum error= 224
Actual label: 1
Output voltages: [0.0099298, 0.79836, 0.1017, 0.04449, 0.019848, 0.0091948, 0.56703, 0.0090034, 0.15753, 0.13022]
Predicted label: 1
Correct prediction
Energy consumption = 156.307436 pJ
sum error= 224
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 425 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 425 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 425 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.42096, 0.043487, 0.79874, 0.10893, 0.014514, 0.0011715, 0.046266, 0.062356, 0.39396, 0.048324]
Predicted label: 2
Correct prediction
Energy consumption = 166.675761 pJ
sum error= 224
Actual label: 8
Output voltages: [0.010029, 0.51161, 0.10596, 0.20248, 0.002511, 0.0096767, 0.013646, 0.2829, 0.79867, 0.04551]
Predicted label: 8
Correct prediction
Energy consumption = 153.795624 pJ
sum error= 224
Actual label: 6
Output voltages: [0.10456, 0.03027, 0.10889, 0.0069726, 0.30135, 0.28541, 0.79873, 0.0039191, 0.69925, 0.016184]
Predicted label: 6
Correct prediction
Energy consumption = 154.889462 pJ
sum error= 224
Actual label: 8
Output voltages: [0.020044, 0.010583, 0.44871, 0.015835, 0.029771, 0.029726, 0.088807, 0.0021425, 0.79879, 0.077326]
Predicted label: 8
Correct prediction
Energy consumption = 145.924705 pJ
sum error= 224
Actual label: 5
Output voltages: [0.012583, 0.0023784, 0.0012791, 0.57665, 0.012756, 0.79877, 0.02757, 0.066463, 0.68039, 0.038667]
Predicted label: 5
Correct prediction
Energy consumption = 152.411014 pJ
sum error= 224
Actual label: 5
Output voltages: [0.4943, 0.0020945, 0.04011, 0.13541, 0.0011006, 0.78527, 0.72952, 0.039907, 0.36416, 0.0033784]
Predicted label: 5
Correct prediction
Energy consumption = 144.260440 pJ
sum error= 224
Actual label: 3
Output voltages: [0.7782, 0.01141, 0.45757, 0.79763, 0.0011846, 0.022972, 0.27516, 0.037786, 0.020812, 0.020322]
Predicted label: 3
Correct prediction
Energy consumption = 142.231227 pJ
sum error= 224
Actual label: 9
Output voltages: [0.26618, 0.0096076, 0.043094, 0.049989, 0.10495, 0.070628, 0.040891, 0.031097, 0.1143, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 154.660688 pJ
sum error= 224
Actual label: 4
Output voltages: [0.0036847, 0.02529, 0.13673, 0.011993, 0.79869, 0.0010805, 0.18852, 0.040983, 0.033296, 0.33424]
Predicted label: 4
Correct prediction
Energy consumption = 158.591693 pJ
sum error= 224
Actual label: 9
Output voltages: [0.67727, 0.16625, 0.0016954, 0.26271, 0.76159, 0.2685, 0.044586, 0.014886, 0.035971, 0.7985]
Predicted label: 9
Correct prediction
Energy consumption = 149.631075 pJ
sum error= 224
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 426 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 426 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 426 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.5928, 0.69362, 0.79877, 0.025343, 0.0047516, 0.001315, 0.037865, 0.27261, 0.15712, 0.037517]
Predicted label: 2
Correct prediction
Energy consumption = 167.524980 pJ
sum error= 224
Actual label: 5
Output voltages: [0.0013559, 0.0010698, 0.0061872, 0.50002, 0.125, 0.78871, 0.27024, 0.011004, 0.74211, 0.072862]
Predicted label: 5
Correct prediction
Energy consumption = 146.309892 pJ
sum error= 224
Actual label: 1
Output voltages: [0.02419, 0.79879, 0.16004, 0.046667, 0.33933, 0.0010878, 0.40779, 0.0043706, 0.039245, 0.065408]
Predicted label: 1
Correct prediction
Energy consumption = 158.204723 pJ
sum error= 224
Actual label: 5
Output voltages: [0.042622, 0.0028839, 0.0025164, 0.54665, 0.016507, 0.79872, 0.026801, 0.030125, 0.76954, 0.046119]
Predicted label: 5
Correct prediction
Energy consumption = 148.645576 pJ
sum error= 224
Actual label: 1
Output voltages: [0.10207, 0.79853, 0.35927, 0.24496, 0.087168, 0.0051535, 0.46176, 0.0068613, 0.020367, 0.11309]
Predicted label: 1
Correct prediction
Energy consumption = 170.880620 pJ
sum error= 224
Actual label: 4
Output voltages: [0.44325, 0.72908, 0.0010663, 0.31857, 0.73717, 0.0011558, 0.02959, 0.039132, 0.027515, 0.36648]
Predicted label: 4
Correct prediction
Energy consumption = 161.860082 pJ
sum error= 224
Actual label: 4
Output voltages: [0.0048778, 0.0049672, 0.068957, 0.022172, 0.79871, 0.0024559, 0.041075, 0.19892, 0.27919, 0.0051204]
Predicted label: 4
Correct prediction
Energy consumption = 149.555518 pJ
sum error= 224
Actual label: 1
Output voltages: [0.0057225, 0.79852, 0.01554, 0.040241, 0.032328, 0.0059596, 0.67449, 0.013498, 0.38183, 0.026308]
Predicted label: 1
Correct prediction
Energy consumption = 157.512839 pJ
sum error= 224
Actual label: 4
Output voltages: [0.0038247, 0.0042142, 0.021397, 0.15148, 0.78863, 0.53694, 0.21871, 0.0034673, 0.065605, 0.43339]
Predicted label: 4
Correct prediction
Energy consumption = 152.620979 pJ
sum error= 224
Actual label: 4
Output voltages: [0.50255, 0.001804, 0.046801, 0.0010716, 0.79834, 0.0044555, 0.65715, 0.016822, 0.19187, 0.015459]
Predicted label: 4
Correct prediction
Energy consumption = 145.357296 pJ
sum error= 224
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 427 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 427 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 427 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.25428, 0.0069633, 0.1945, 0.79874, 0.033151, 0.17585, 0.0019825, 0.0072763, 0.65181, 0.017062]
Predicted label: 3
Correct prediction
Energy consumption = 164.060327 pJ
sum error= 224
Actual label: 5
Output voltages: [0.25391, 0.0084894, 0.0039976, 0.79869, 0.010443, 0.7299, 0.040294, 0.028781, 0.68091, 0.36615]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.030888 pJ
sum error= 225
Actual label: 9
Output voltages: [0.53157, 0.0022501, 0.14536, 0.61252, 0.098299, 0.031533, 0.0016798, 0.49283, 0.27073, 0.79588]
Predicted label: 9
Correct prediction
Energy consumption = 149.655956 pJ
sum error= 225
Actual label: 1
Output voltages: [0.033643, 0.79852, 0.059543, 0.23793, 0.033528, 0.001227, 0.047443, 0.0055258, 0.21211, 0.076743]
Predicted label: 1
Correct prediction
Energy consumption = 166.063882 pJ
sum error= 225
Actual label: 2
Output voltages: [0.30027, 0.042921, 0.79876, 0.15675, 0.019605, 0.0012885, 0.31287, 0.031701, 0.49121, 0.02249]
Predicted label: 2
Correct prediction
Energy consumption = 153.494215 pJ
sum error= 225
Actual label: 2
Output voltages: [0.43049, 0.022303, 0.79877, 0.047999, 0.0069531, 0.0011566, 0.023113, 0.19882, 0.46396, 0.010074]
Predicted label: 2
Correct prediction
Energy consumption = 134.819637 pJ
sum error= 225
Actual label: 3
Output voltages: [0.060953, 0.0053307, 0.27929, 0.79876, 0.16407, 0.090778, 0.042061, 0.01022, 0.2965, 0.23967]
Predicted label: 3
Correct prediction
Energy consumption = 144.620519 pJ
sum error= 225
Actual label: 3
Output voltages: [0.43816, 0.008934, 0.02799, 0.79877, 0.0083473, 0.018511, 0.037003, 0.018696, 0.26122, 0.015103]
Predicted label: 3
Correct prediction
Energy consumption = 137.229343 pJ
sum error= 225
Actual label: 0
Output voltages: [0.79879, 0.35538, 0.030794, 0.014947, 0.014981, 0.014641, 0.47179, 0.011007, 0.040213, 0.15797]
Predicted label: 0
Correct prediction
Energy consumption = 155.468880 pJ
sum error= 225
Actual label: 2
Output voltages: [0.41521, 0.013147, 0.7986, 0.6442, 0.020918, 0.0011044, 0.022506, 0.026364, 0.48093, 0.08632]
Predicted label: 2
Correct prediction
Energy consumption = 141.937483 pJ
sum error= 225
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 428 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 428 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 428 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.087903, 0.057349, 0.32003, 0.014231, 0.71629, 0.0041767, 0.0014598, 0.002463, 0.054226, 0.79748]
Predicted label: 9
Correct prediction
Energy consumption = 168.265231 pJ
sum error= 225
Actual label: 0
Output voltages: [0.79869, 0.055881, 0.20548, 0.03275, 0.015749, 0.0012554, 0.5198, 0.0099384, 0.1367, 0.14259]
Predicted label: 0
Correct prediction
Energy consumption = 157.577004 pJ
sum error= 225
Actual label: 0
Output voltages: [0.79825, 0.25209, 0.015802, 0.0093731, 0.0039573, 0.0024747, 0.63973, 0.075181, 0.12198, 0.067539]
Predicted label: 0
Correct prediction
Energy consumption = 135.938538 pJ
sum error= 225
Actual label: 9
Output voltages: [0.22687, 0.023246, 0.023954, 0.24392, 0.23324, 0.12837, 0.051972, 0.033151, 0.051663, 0.79839]
Predicted label: 9
Correct prediction
Energy consumption = 146.904388 pJ
sum error= 225
Actual label: 9
Output voltages: [0.014047, 0.0010669, 0.0058796, 0.43189, 0.74398, 0.25027, 0.020981, 0.0093132, 0.2349, 0.36115]
Predicted label: 4
Wrong prediction!
Energy consumption = 156.562670 pJ
sum error= 226
Actual label: 6
Output voltages: [0.25822, 0.011459, 0.036594, 0.0094623, 0.055985, 0.49649, 0.79871, 0.0011954, 0.5574, 0.067571]
Predicted label: 6
Correct prediction
Energy consumption = 150.936538 pJ
sum error= 226
Actual label: 0
Output voltages: [0.79872, 0.057918, 0.085191, 0.038305, 0.0037822, 0.020855, 0.056428, 0.018598, 0.26517, 0.031659]
Predicted label: 0
Correct prediction
Energy consumption = 150.888260 pJ
sum error= 226
Actual label: 9
Output voltages: [0.64695, 0.0010712, 0.20719, 0.0094777, 0.22427, 0.0054816, 0.033309, 0.016661, 0.57087, 0.79544]
Predicted label: 9
Correct prediction
Energy consumption = 150.929672 pJ
sum error= 226
Actual label: 3
Output voltages: [0.23578, 0.025013, 0.025132, 0.79863, 0.015128, 0.0098288, 0.01102, 0.015452, 0.5331, 0.060739]
Predicted label: 3
Correct prediction
Energy consumption = 152.786497 pJ
sum error= 226
Actual label: 2
Output voltages: [0.17693, 0.039978, 0.79875, 0.0059865, 0.0039072, 0.0013084, 0.067242, 0.74445, 0.52071, 0.014547]
Predicted label: 2
Correct prediction
Energy consumption = 137.059655 pJ
sum error= 226
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 429 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 429 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 429 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0054769, 0.0027823, 0.035328, 0.041245, 0.016227, 0.21694, 0.075684, 0.0096014, 0.79876, 0.064678]
Predicted label: 8
Correct prediction
Energy consumption = 169.296192 pJ
sum error= 226
Actual label: 4
Output voltages: [0.020443, 0.022114, 0.027601, 0.0030038, 0.79874, 0.0023621, 0.40416, 0.031542, 0.14196, 0.17049]
Predicted label: 4
Correct prediction
Energy consumption = 156.183221 pJ
sum error= 226
Actual label: 1
Output voltages: [0.0571, 0.79847, 0.037991, 0.030902, 0.019617, 0.0015336, 0.56143, 0.0014884, 0.3747, 0.073014]
Predicted label: 1
Correct prediction
Energy consumption = 168.170515 pJ
sum error= 226
Actual label: 9
Output voltages: [0.11211, 0.016089, 0.031496, 0.060734, 0.40739, 0.031699, 0.38782, 0.0074237, 0.083465, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 156.629564 pJ
sum error= 226
Actual label: 9
Output voltages: [0.5685, 0.011821, 0.0011156, 0.60996, 0.27638, 0.77801, 0.0046612, 0.20581, 0.039263, 0.79209]
Predicted label: 9
Correct prediction
Energy consumption = 143.503231 pJ
sum error= 226
Actual label: 7
Output voltages: [0.023614, 0.078763, 0.092437, 0.12902, 0.0050348, 0.0011123, 0.0016314, 0.79878, 0.17575, 0.5172]
Predicted label: 7
Correct prediction
Energy consumption = 157.311305 pJ
sum error= 226
Actual label: 2
Output voltages: [0.022732, 0.23917, 0.79879, 0.19961, 0.026921, 0.001087, 0.48662, 0.0084116, 0.48464, 0.057941]
Predicted label: 2
Correct prediction
Energy consumption = 151.917957 pJ
sum error= 226
Actual label: 7
Output voltages: [0.13385, 0.74607, 0.16444, 0.45236, 0.0010704, 0.0010662, 0.0011516, 0.79878, 0.5345, 0.11289]
Predicted label: 7
Correct prediction
Energy consumption = 152.421429 pJ
sum error= 226
Actual label: 9
Output voltages: [0.27773, 0.0089296, 0.052423, 0.61871, 0.015035, 0.23166, 0.0059836, 0.13107, 0.16774, 0.79863]
Predicted label: 9
Correct prediction
Energy consumption = 146.460480 pJ
sum error= 226
Actual label: 9
Output voltages: [0.10766, 0.016901, 0.020629, 0.039147, 0.50459, 0.001167, 0.0020011, 0.0038626, 0.4777, 0.78845]
Predicted label: 9
Correct prediction
Energy consumption = 149.430992 pJ
sum error= 226
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 430 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 430 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 430 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.37591, 0.067111, 0.0010979, 0.76269, 0.0010829, 0.77891, 0.68932, 0.0010834, 0.7661, 0.011383]
Predicted label: 5
Correct prediction
Energy consumption = 168.342953 pJ
sum error= 226
Actual label: 9
Output voltages: [0.26402, 0.0070724, 0.052612, 0.01785, 0.23556, 0.17839, 0.02633, 0.04496, 0.15743, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 152.070559 pJ
sum error= 226
Actual label: 5
Output voltages: [0.14925, 0.0010691, 0.0011243, 0.10098, 0.13813, 0.79834, 0.31076, 0.0018894, 0.51881, 0.023585]
Predicted label: 5
Correct prediction
Energy consumption = 134.244255 pJ
sum error= 226
Actual label: 1
Output voltages: [0.038938, 0.79872, 0.0023456, 0.014777, 0.14952, 0.0072798, 0.34902, 0.02027, 0.028434, 0.03081]
Predicted label: 1
Correct prediction
Energy consumption = 153.835998 pJ
sum error= 226
Actual label: 1
Output voltages: [0.0022813, 0.79845, 0.079847, 0.018888, 0.0051247, 0.013454, 0.53526, 0.028132, 0.46317, 0.0072084]
Predicted label: 1
Correct prediction
Energy consumption = 149.890181 pJ
sum error= 226
Actual label: 8
Output voltages: [0.19663, 0.035772, 0.74642, 0.018574, 0.011294, 0.0012419, 0.033941, 0.0012535, 0.79868, 0.26593]
Predicted label: 8
Correct prediction
Energy consumption = 142.156120 pJ
sum error= 226
Actual label: 3
Output voltages: [0.042822, 0.33752, 0.0074923, 0.79832, 0.0010674, 0.039021, 0.0010771, 0.52352, 0.7817, 0.13761]
Predicted label: 3
Correct prediction
Energy consumption = 140.107920 pJ
sum error= 226
Actual label: 5
Output voltages: [0.21138, 0.0018391, 0.0013484, 0.63686, 0.023708, 0.79878, 0.46439, 0.011931, 0.72969, 0.022193]
Predicted label: 5
Correct prediction
Energy consumption = 147.088186 pJ
sum error= 226
Actual label: 1
Output voltages: [0.034943, 0.79869, 0.014651, 0.015666, 0.014974, 0.0090553, 0.70818, 0.004542, 0.45226, 0.0070079]
Predicted label: 1
Correct prediction
Energy consumption = 158.649918 pJ
sum error= 226
Actual label: 9
Output voltages: [0.3495, 0.011713, 0.051559, 0.015731, 0.18236, 0.0076219, 0.0034497, 0.0083716, 0.43559, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 153.345388 pJ
sum error= 226
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 431 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 431 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 431 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.24501, 0.0080012, 0.0010755, 0.21883, 0.008341, 0.79873, 0.18637, 0.098447, 0.7748, 0.0010672]
Predicted label: 5
Correct prediction
Energy consumption = 170.613920 pJ
sum error= 226
Actual label: 3
Output voltages: [0.3587, 0.0078207, 0.13733, 0.79876, 0.19472, 0.21289, 0.033056, 0.0030309, 0.62104, 0.043326]
Predicted label: 3
Correct prediction
Energy consumption = 149.033253 pJ
sum error= 226
Actual label: 5
Output voltages: [0.059211, 0.0036823, 0.0010711, 0.33142, 0.0044763, 0.79877, 0.17461, 0.030492, 0.69382, 0.0011024]
Predicted label: 5
Correct prediction
Energy consumption = 148.640362 pJ
sum error= 226
Actual label: 4
Output voltages: [0.001382, 0.039949, 0.0057358, 0.0011075, 0.79835, 0.0014552, 0.073648, 0.039544, 0.39817, 0.22748]
Predicted label: 4
Correct prediction
Energy consumption = 146.845453 pJ
sum error= 226
Actual label: 9
Output voltages: [0.097472, 0.042348, 0.035614, 0.35685, 0.03061, 0.0010955, 0.0020611, 0.040569, 0.50002, 0.7975]
Predicted label: 9
Correct prediction
Energy consumption = 157.732043 pJ
sum error= 226
Actual label: 5
Output voltages: [0.035791, 0.0010684, 0.0021243, 0.75056, 0.043044, 0.79756, 0.25225, 0.024572, 0.54967, 0.087017]
Predicted label: 5
Correct prediction
Energy consumption = 144.641372 pJ
sum error= 226
Actual label: 9
Output voltages: [0.21779, 0.030023, 0.025392, 0.34823, 0.29899, 0.0018887, 0.001124, 0.026332, 0.13863, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 150.222769 pJ
sum error= 226
Actual label: 3
Output voltages: [0.48914, 0.043665, 0.001787, 0.79707, 0.0016155, 0.30035, 0.001168, 0.074318, 0.59287, 0.061731]
Predicted label: 3
Correct prediction
Energy consumption = 143.198359 pJ
sum error= 226
Actual label: 1
Output voltages: [0.010065, 0.79867, 0.0091929, 0.032505, 0.010093, 0.0064906, 0.52106, 0.0049702, 0.35249, 0.047007]
Predicted label: 1
Correct prediction
Energy consumption = 153.184481 pJ
sum error= 226
Actual label: 9
Output voltages: [0.71734, 0.0014672, 0.028534, 0.025112, 0.42616, 0.024733, 0.003481, 0.036849, 0.046649, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 160.374824 pJ
sum error= 226
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 432 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 432 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 432 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79781, 0.052687, 0.11037, 0.013611, 0.0085181, 0.0011725, 0.62349, 0.013813, 0.33427, 0.3035]
Predicted label: 0
Correct prediction
Energy consumption = 163.858769 pJ
sum error= 226
Actual label: 9
Output voltages: [0.36126, 0.036807, 0.031938, 0.48436, 0.011055, 0.027156, 0.012412, 0.016653, 0.21136, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 154.398199 pJ
sum error= 226
Actual label: 7
Output voltages: [0.11009, 0.060828, 0.028839, 0.022134, 0.02829, 0.0023449, 0.0019415, 0.79853, 0.16663, 0.066726]
Predicted label: 7
Correct prediction
Energy consumption = 160.277259 pJ
sum error= 226
Actual label: 5
Output voltages: [0.038976, 0.025279, 0.0027426, 0.61719, 0.0040194, 0.79876, 0.033295, 0.0014987, 0.62361, 0.0097477]
Predicted label: 5
Correct prediction
Energy consumption = 145.337119 pJ
sum error= 226
Actual label: 4
Output voltages: [0.0039465, 0.0026792, 0.1781, 0.020469, 0.7986, 0.0028118, 0.039294, 0.042317, 0.049288, 0.14276]
Predicted label: 4
Correct prediction
Energy consumption = 159.030861 pJ
sum error= 226
Actual label: 9
Output voltages: [0.16388, 0.0042597, 0.017446, 0.0058581, 0.042867, 0.0036153, 0.0010928, 0.024577, 0.67428, 0.79778]
Predicted label: 9
Correct prediction
Energy consumption = 149.764430 pJ
sum error= 226
Actual label: 2
Output voltages: [0.54131, 0.037843, 0.79864, 0.30472, 0.026473, 0.0011883, 0.046513, 0.27422, 0.096056, 0.014895]
Predicted label: 2
Correct prediction
Energy consumption = 153.470370 pJ
sum error= 226
Actual label: 0
Output voltages: [0.79865, 0.046037, 0.020399, 0.69762, 0.0010826, 0.59302, 0.029584, 0.001278, 0.099189, 0.13548]
Predicted label: 0
Correct prediction
Energy consumption = 148.978492 pJ
sum error= 226
Actual label: 1
Output voltages: [0.0034733, 0.79852, 0.089191, 0.12461, 0.020309, 0.0026042, 0.64265, 0.0064642, 0.045459, 0.058656]
Predicted label: 1
Correct prediction
Energy consumption = 168.601486 pJ
sum error= 226
Actual label: 0
Output voltages: [0.79864, 0.0094903, 0.21314, 0.0013481, 0.0013177, 0.0080303, 0.21661, 0.0077442, 0.39769, 0.005508]
Predicted label: 0
Correct prediction
Energy consumption = 155.277505 pJ
sum error= 226
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 433 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 433 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 433 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.013369, 0.0010704, 0.018795, 0.061817, 0.0022414, 0.47507, 0.033355, 0.0011186, 0.79584, 0.12844]
Predicted label: 8
Wrong prediction!
Energy consumption = 164.058132 pJ
sum error= 227
Actual label: 1
Output voltages: [0.043121, 0.79845, 0.098159, 0.016695, 0.25887, 0.0086901, 0.25141, 0.015614, 0.0076013, 0.34531]
Predicted label: 1
Correct prediction
Energy consumption = 167.123922 pJ
sum error= 227
Actual label: 4
Output voltages: [0.012157, 0.0068082, 0.18287, 0.004172, 0.79871, 0.0010867, 0.037384, 0.040395, 0.027602, 0.13706]
Predicted label: 4
Correct prediction
Energy consumption = 158.761091 pJ
sum error= 227
Actual label: 9
Output voltages: [0.048616, 0.017051, 0.0038074, 0.60184, 0.70088, 0.025319, 0.0052268, 0.35693, 0.0084896, 0.7899]
Predicted label: 9
Correct prediction
Energy consumption = 154.398097 pJ
sum error= 227
Actual label: 3
Output voltages: [0.46546, 0.01858, 0.016365, 0.79875, 0.051693, 0.2959, 0.025595, 0.045554, 0.36901, 0.019813]
Predicted label: 3
Correct prediction
Energy consumption = 148.461935 pJ
sum error= 227
Actual label: 3
Output voltages: [0.014531, 0.18516, 0.19827, 0.79863, 0.040166, 0.014488, 0.0021659, 0.08966, 0.49205, 0.44449]
Predicted label: 3
Correct prediction
Energy consumption = 142.096812 pJ
sum error= 227
Actual label: 6
Output voltages: [0.16086, 0.047652, 0.2839, 0.0083403, 0.49811, 0.23998, 0.79868, 0.002277, 0.41129, 0.0205]
Predicted label: 6
Correct prediction
Energy consumption = 152.714351 pJ
sum error= 227
Actual label: 1
Output voltages: [0.018035, 0.79853, 0.046334, 0.157, 0.04288, 0.0054722, 0.25192, 0.0018497, 0.46597, 0.090265]
Predicted label: 1
Correct prediction
Energy consumption = 160.277028 pJ
sum error= 227
Actual label: 5
Output voltages: [0.49568, 0.0010671, 0.0027278, 0.57166, 0.010913, 0.79879, 0.044961, 0.10754, 0.7812, 0.15421]
Predicted label: 5
Correct prediction
Energy consumption = 152.781914 pJ
sum error= 227
Actual label: 2
Output voltages: [0.54159, 0.38478, 0.79874, 0.031252, 0.018028, 0.001301, 0.31264, 0.1018, 0.32266, 0.064157]
Predicted label: 2
Correct prediction
Energy consumption = 154.954498 pJ
sum error= 227
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 434 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 434 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 434 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.12993, 0.0012684, 0.0050058, 0.50611, 0.011435, 0.79875, 0.025597, 0.29528, 0.76979, 0.039192]
Predicted label: 5
Correct prediction
Energy consumption = 166.793392 pJ
sum error= 227
Actual label: 2
Output voltages: [0.48395, 0.0021415, 0.78758, 0.64088, 0.016164, 0.0012442, 0.015865, 0.041884, 0.70227, 0.03337]
Predicted label: 2
Correct prediction
Energy consumption = 148.859993 pJ
sum error= 227
Actual label: 2
Output voltages: [0.42271, 0.038981, 0.79876, 0.0638, 0.024359, 0.0012865, 0.33989, 0.05393, 0.57387, 0.039409]
Predicted label: 2
Correct prediction
Energy consumption = 140.104964 pJ
sum error= 227
Actual label: 0
Output voltages: [0.78813, 0.023352, 0.11264, 0.17067, 0.0051763, 0.0020431, 0.037245, 0.0026121, 0.78758, 0.041223]
Predicted label: 0
Correct prediction
Energy consumption = 152.494687 pJ
sum error= 227
Actual label: 9
Output voltages: [0.075829, 0.0010927, 0.042488, 0.39414, 0.050745, 0.010918, 0.03002, 0.38025, 0.038752, 0.79711]
Predicted label: 9
Correct prediction
Energy consumption = 146.785528 pJ
sum error= 227
Actual label: 2
Output voltages: [0.41914, 0.033311, 0.79867, 0.033799, 0.027604, 0.001066, 0.036853, 0.02488, 0.44917, 0.0040365]
Predicted label: 2
Correct prediction
Energy consumption = 146.323491 pJ
sum error= 227
Actual label: 6
Output voltages: [0.045539, 0.026018, 0.44218, 0.0010868, 0.36499, 0.57354, 0.79876, 0.0032394, 0.19304, 0.0025793]
Predicted label: 6
Correct prediction
Energy consumption = 145.105577 pJ
sum error= 227
Actual label: 6
Output voltages: [0.062608, 0.029439, 0.041611, 0.0022711, 0.26919, 0.19688, 0.79876, 0.001561, 0.73741, 0.0021758]
Predicted label: 6
Correct prediction
Energy consumption = 140.962759 pJ
sum error= 227
Actual label: 0
Output voltages: [0.79871, 0.087307, 0.046757, 0.027974, 0.012217, 0.0018828, 0.69556, 0.011914, 0.30542, 0.034344]
Predicted label: 0
Correct prediction
Energy consumption = 142.948525 pJ
sum error= 227
Actual label: 1
Output voltages: [0.017807, 0.79866, 0.0043649, 0.23615, 0.22601, 0.002219, 0.68409, 0.0011216, 0.65497, 0.14806]
Predicted label: 1
Correct prediction
Energy consumption = 159.404182 pJ
sum error= 227
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 435 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 435 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 435 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.065075, 0.023946, 0.72755, 0.76786, 0.0016109, 0.018755, 0.010272, 0.0045166, 0.79879, 0.010131]
Predicted label: 8
Wrong prediction!
Energy consumption = 160.198200 pJ
sum error= 228
Actual label: 0
Output voltages: [0.7987, 0.045437, 0.021822, 0.11884, 0.0063035, 0.049116, 0.20844, 0.014245, 0.030096, 0.034321]
Predicted label: 0
Correct prediction
Energy consumption = 152.051759 pJ
sum error= 228
Actual label: 3
Output voltages: [0.041681, 0.02262, 0.02021, 0.79863, 0.025687, 0.0082305, 0.009981, 0.020801, 0.54214, 0.15855]
Predicted label: 3
Correct prediction
Energy consumption = 145.032081 pJ
sum error= 228
Actual label: 0
Output voltages: [0.79879, 0.026173, 0.034509, 0.017717, 0.04596, 0.014732, 0.30373, 0.0059613, 0.12154, 0.036697]
Predicted label: 0
Correct prediction
Energy consumption = 162.161114 pJ
sum error= 228
Actual label: 2
Output voltages: [0.49726, 0.38515, 0.79878, 0.023734, 0.012813, 0.0013982, 0.25441, 0.089431, 0.18762, 0.035866]
Predicted label: 2
Correct prediction
Energy consumption = 150.901014 pJ
sum error= 228
Actual label: 5
Output voltages: [0.0082785, 0.0013364, 0.0065504, 0.58072, 0.065087, 0.7962, 0.15614, 0.029266, 0.73641, 0.40761]
Predicted label: 5
Correct prediction
Energy consumption = 146.690414 pJ
sum error= 228
Actual label: 5
Output voltages: [0.1279, 0.0011262, 0.019058, 0.51635, 0.012596, 0.78612, 0.23007, 0.010107, 0.78793, 0.034468]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.980836 pJ
sum error= 229
Actual label: 7
Output voltages: [0.67684, 0.12695, 0.022648, 0.48591, 0.016209, 0.036863, 0.0011129, 0.79871, 0.023004, 0.20902]
Predicted label: 7
Correct prediction
Energy consumption = 157.935873 pJ
sum error= 229
Actual label: 9
Output voltages: [0.22094, 0.010952, 0.0034953, 0.19682, 0.075511, 0.0023324, 0.0011583, 0.0084395, 0.50424, 0.79724]
Predicted label: 9
Correct prediction
Energy consumption = 154.305679 pJ
sum error= 229
Actual label: 5
Output voltages: [0.11089, 0.0069386, 0.0019116, 0.21758, 0.015014, 0.79813, 0.042525, 0.26042, 0.29962, 0.37291]
Predicted label: 5
Correct prediction
Energy consumption = 150.256692 pJ
sum error= 229
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 436 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 436 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 436 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25377, 0.00131, 0.001077, 0.78842, 0.14066, 0.78408, 0.045007, 0.0022782, 0.4646, 0.22461]
Predicted label: 3
Wrong prediction!
Energy consumption = 173.172742 pJ
sum error= 230
Actual label: 0
Output voltages: [0.79867, 0.020146, 0.033146, 0.016085, 0.037001, 0.015142, 0.48121, 0.091399, 0.10209, 0.071613]
Predicted label: 0
Correct prediction
Energy consumption = 160.535466 pJ
sum error= 230
Actual label: 8
Output voltages: [0.041885, 0.018305, 0.41122, 0.36106, 0.0034861, 0.033583, 0.10142, 0.028159, 0.79877, 0.053651]
Predicted label: 8
Correct prediction
Energy consumption = 153.680855 pJ
sum error= 230
Actual label: 9
Output voltages: [0.030597, 0.0015824, 0.0095153, 0.049454, 0.043081, 0.68082, 0.012543, 0.087522, 0.38664, 0.79002]
Predicted label: 9
Correct prediction
Energy consumption = 143.861408 pJ
sum error= 230
Actual label: 5
Output voltages: [0.17058, 0.0029441, 0.0011578, 0.47288, 0.012224, 0.7967, 0.048419, 0.0013693, 0.7724, 0.0037469]
Predicted label: 5
Correct prediction
Energy consumption = 138.121452 pJ
sum error= 230
Actual label: 0
Output voltages: [0.79868, 0.11731, 0.19389, 0.012257, 0.0078809, 0.0013197, 0.67144, 0.018671, 0.048128, 0.52242]
Predicted label: 0
Correct prediction
Energy consumption = 157.426214 pJ
sum error= 230
Actual label: 3
Output voltages: [0.17372, 0.017065, 0.19596, 0.79868, 0.029328, 0.020581, 0.0080283, 0.01493, 0.58917, 0.064338]
Predicted label: 3
Correct prediction
Energy consumption = 144.020896 pJ
sum error= 230
Actual label: 2
Output voltages: [0.60648, 0.14105, 0.79869, 0.23472, 0.040275, 0.0012913, 0.034595, 0.11949, 0.13257, 0.022422]
Predicted label: 2
Correct prediction
Energy consumption = 138.902501 pJ
sum error= 230
Actual label: 5
Output voltages: [0.11539, 0.0010808, 0.016613, 0.48474, 0.0012908, 0.79866, 0.12894, 0.2202, 0.77744, 0.0034937]
Predicted label: 5
Correct prediction
Energy consumption = 150.934743 pJ
sum error= 230
Actual label: 9
Output voltages: [0.49616, 0.010177, 0.027716, 0.029355, 0.78486, 0.0010849, 0.0011271, 0.0020949, 0.13327, 0.79817]
Predicted label: 9
Correct prediction
Energy consumption = 141.331130 pJ
sum error= 230
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 437 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 437 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 437 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7987, 0.23229, 0.058962, 0.0467, 0.12073, 0.022228, 0.44871, 0.032067, 0.18237, 0.017131]
Predicted label: 0
Correct prediction
Energy consumption = 176.658862 pJ
sum error= 230
Actual label: 8
Output voltages: [0.019839, 0.25978, 0.039974, 0.3681, 0.0011241, 0.043719, 0.0025836, 0.011078, 0.79876, 0.053953]
Predicted label: 8
Correct prediction
Energy consumption = 157.842319 pJ
sum error= 230
Actual label: 8
Output voltages: [0.03079, 0.040417, 0.36936, 0.043229, 0.017775, 0.013581, 0.053716, 0.017363, 0.7987, 0.063946]
Predicted label: 8
Correct prediction
Energy consumption = 140.699710 pJ
sum error= 230
Actual label: 4
Output voltages: [0.0024164, 0.0060562, 0.30725, 0.0027344, 0.79872, 0.0013617, 0.5524, 0.12033, 0.052755, 0.2162]
Predicted label: 4
Correct prediction
Energy consumption = 153.137708 pJ
sum error= 230
Actual label: 5
Output voltages: [0.051905, 0.0010661, 0.0061799, 0.24628, 0.0095118, 0.79875, 0.10732, 0.20991, 0.75165, 0.21585]
Predicted label: 5
Correct prediction
Energy consumption = 148.045169 pJ
sum error= 230
Actual label: 8
Output voltages: [0.026714, 0.044899, 0.38457, 0.29956, 0.0014633, 0.034685, 0.15463, 0.021868, 0.79871, 0.010827]
Predicted label: 8
Correct prediction
Energy consumption = 150.841734 pJ
sum error= 230
Actual label: 8
Output voltages: [0.018314, 0.095498, 0.0069049, 0.40956, 0.010366, 0.039687, 0.0015141, 0.004264, 0.79879, 0.30857]
Predicted label: 8
Correct prediction
Energy consumption = 143.646271 pJ
sum error= 230
Actual label: 4
Output voltages: [0.0049885, 0.012329, 0.053396, 0.017016, 0.79868, 0.0011338, 0.061159, 0.074015, 0.024508, 0.02527]
Predicted label: 4
Correct prediction
Energy consumption = 151.804829 pJ
sum error= 230
Actual label: 5
Output voltages: [0.07481, 0.0010983, 0.007157, 0.28446, 0.010908, 0.79852, 0.16604, 0.015487, 0.75847, 0.040302]
Predicted label: 5
Correct prediction
Energy consumption = 144.909000 pJ
sum error= 230
Actual label: 4
Output voltages: [0.010475, 0.010982, 0.27491, 0.027828, 0.79866, 0.0038685, 0.12964, 0.1821, 0.022544, 0.047007]
Predicted label: 4
Correct prediction
Energy consumption = 154.487534 pJ
sum error= 230
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 438 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 438 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 438 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0061183, 0.0044866, 0.044043, 0.38714, 0.0030832, 0.13609, 0.58115, 0.0010699, 0.79425, 0.020892]
Predicted label: 8
Correct prediction
Energy consumption = 167.897498 pJ
sum error= 230
Actual label: 5
Output voltages: [0.021265, 0.001066, 0.0055948, 0.31215, 0.033437, 0.79681, 0.045055, 0.031244, 0.77541, 0.047291]
Predicted label: 5
Correct prediction
Energy consumption = 142.145143 pJ
sum error= 230
Actual label: 4
Output voltages: [0.098391, 0.0096152, 0.030055, 0.019828, 0.79879, 0.0011484, 0.0064917, 0.057487, 0.0083683, 0.65461]
Predicted label: 4
Correct prediction
Energy consumption = 152.365899 pJ
sum error= 230
Actual label: 9
Output voltages: [0.57648, 0.0010992, 0.018955, 0.23133, 0.41198, 0.0019586, 0.0013743, 0.054533, 0.11101, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 147.152377 pJ
sum error= 230
Actual label: 2
Output voltages: [0.047922, 0.79626, 0.77259, 0.33764, 0.12895, 0.0010769, 0.64482, 0.00196, 0.069485, 0.022711]
Predicted label: 1
Wrong prediction!
Energy consumption = 157.500515 pJ
sum error= 231
Actual label: 2
Output voltages: [0.43616, 0.33963, 0.79878, 0.24951, 0.01225, 0.0013165, 0.29383, 0.035185, 0.48833, 0.13151]
Predicted label: 2
Correct prediction
Energy consumption = 140.282642 pJ
sum error= 231
Actual label: 1
Output voltages: [0.01246, 0.7987, 0.004762, 0.020162, 0.055586, 0.0016353, 0.46788, 0.0012746, 0.60485, 0.017644]
Predicted label: 1
Correct prediction
Energy consumption = 158.981966 pJ
sum error= 231
Actual label: 2
Output voltages: [0.032989, 0.45484, 0.79868, 0.038956, 0.054597, 0.00112, 0.017172, 0.040319, 0.23718, 0.0054159]
Predicted label: 2
Correct prediction
Energy consumption = 142.640569 pJ
sum error= 231
Actual label: 6
Output voltages: [0.19967, 0.19579, 0.26956, 0.022506, 0.14194, 0.29621, 0.79868, 0.002273, 0.25246, 0.070266]
Predicted label: 6
Correct prediction
Energy consumption = 146.188657 pJ
sum error= 231
Actual label: 8
Output voltages: [0.0046046, 0.31249, 0.048774, 0.3516, 0.0035665, 0.0054586, 0.15074, 0.022111, 0.79874, 0.064371]
Predicted label: 8
Correct prediction
Energy consumption = 155.332489 pJ
sum error= 231
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 439 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 439 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 439 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.030242, 0.019402, 0.71751, 0.034557, 0.015475, 0.0030572, 0.041669, 0.017012, 0.79874, 0.159]
Predicted label: 8
Correct prediction
Energy consumption = 170.285913 pJ
sum error= 231
Actual label: 7
Output voltages: [0.28005, 0.035728, 0.0095585, 0.0010815, 0.098311, 0.014081, 0.00481, 0.7986, 0.081931, 0.20477]
Predicted label: 7
Correct prediction
Energy consumption = 153.476711 pJ
sum error= 231
Actual label: 0
Output voltages: [0.79874, 0.091318, 0.039817, 0.0018058, 0.01487, 0.004015, 0.5797, 0.002008, 0.03727, 0.13241]
Predicted label: 0
Correct prediction
Energy consumption = 148.888672 pJ
sum error= 231
Actual label: 3
Output voltages: [0.71121, 0.016713, 0.29624, 0.79878, 0.0012498, 0.083428, 0.0053608, 0.01914, 0.37902, 0.0013106]
Predicted label: 3
Correct prediction
Energy consumption = 152.984051 pJ
sum error= 231
Actual label: 6
Output voltages: [0.14219, 0.023731, 0.39543, 0.00135, 0.42823, 0.13459, 0.79879, 0.0012026, 0.29924, 0.0028748]
Predicted label: 6
Correct prediction
Energy consumption = 148.365773 pJ
sum error= 231
Actual label: 6
Output voltages: [0.048701, 0.08995, 0.23667, 0.0010833, 0.54365, 0.16463, 0.79879, 0.0011279, 0.26285, 0.0065275]
Predicted label: 6
Correct prediction
Energy consumption = 143.741704 pJ
sum error= 231
Actual label: 4
Output voltages: [0.024854, 0.073477, 0.03436, 0.050057, 0.79879, 0.0045836, 0.086773, 0.0036372, 0.036225, 0.02254]
Predicted label: 4
Correct prediction
Energy consumption = 152.850428 pJ
sum error= 231
Actual label: 3
Output voltages: [0.13461, 0.0174, 0.038281, 0.79867, 0.15958, 0.077189, 0.051254, 0.022438, 0.61244, 0.027697]
Predicted label: 3
Correct prediction
Energy consumption = 145.904850 pJ
sum error= 231
Actual label: 8
Output voltages: [0.019701, 0.01147, 0.03331, 0.39903, 0.0092838, 0.024079, 0.0097677, 0.0385, 0.79878, 0.10986]
Predicted label: 8
Correct prediction
Energy consumption = 143.625936 pJ
sum error= 231
Actual label: 8
Output voltages: [0.33093, 0.020213, 0.15812, 0.4566, 0.021015, 0.020012, 0.3847, 0.0014134, 0.79779, 0.053124]
Predicted label: 8
Correct prediction
Energy consumption = 149.640078 pJ
sum error= 231
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 440 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 440 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 440 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.018663, 0.67692, 0.64534, 0.035012, 0.13736, 0.0012192, 0.0027711, 0.71677, 0.018916, 0.28523]
Predicted label: 7
Correct prediction
Energy consumption = 169.918419 pJ
sum error= 231
Actual label: 2
Output voltages: [0.5682, 0.029885, 0.78148, 0.78897, 0.0051416, 0.0011139, 0.023589, 0.22809, 0.75137, 0.017193]
Predicted label: 3
Wrong prediction!
Energy consumption = 152.343428 pJ
sum error= 232
Actual label: 2
Output voltages: [0.19358, 0.24306, 0.79879, 0.044316, 0.017285, 0.0013963, 0.05001, 0.044456, 0.1543, 0.036076]
Predicted label: 2
Correct prediction
Energy consumption = 142.149500 pJ
sum error= 232
Actual label: 0
Output voltages: [0.798, 0.0033205, 0.26042, 0.017668, 0.012219, 0.011308, 0.45376, 0.0068037, 0.64137, 0.35881]
Predicted label: 0
Correct prediction
Energy consumption = 147.263711 pJ
sum error= 232
Actual label: 0
Output voltages: [0.79879, 0.026859, 0.011949, 0.0063573, 0.039404, 0.01278, 0.70921, 0.0058659, 0.042552, 0.1387]
Predicted label: 0
Correct prediction
Energy consumption = 150.667437 pJ
sum error= 232
Actual label: 9
Output voltages: [0.098199, 0.0014611, 0.032459, 0.014897, 0.77251, 0.0022409, 0.022672, 0.021565, 0.058538, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 158.464593 pJ
sum error= 232
Actual label: 3
Output voltages: [0.30131, 0.052192, 0.055225, 0.79866, 0.0058121, 0.0047309, 0.0055837, 0.0066063, 0.64225, 0.042407]
Predicted label: 3
Correct prediction
Energy consumption = 139.749748 pJ
sum error= 232
Actual label: 9
Output voltages: [0.11552, 0.0055028, 0.01103, 0.093706, 0.12199, 0.007676, 0.0038024, 0.025216, 0.697, 0.7984]
Predicted label: 9
Correct prediction
Energy consumption = 143.587830 pJ
sum error= 232
Actual label: 9
Output voltages: [0.053698, 0.0095219, 0.10844, 0.1373, 0.054204, 0.0096258, 0.17305, 0.012182, 0.11208, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 145.193079 pJ
sum error= 232
Actual label: 1
Output voltages: [0.013141, 0.79855, 0.040584, 0.14093, 0.025389, 0.0014169, 0.62459, 0.013338, 0.19838, 0.020591]
Predicted label: 1
Correct prediction
Energy consumption = 159.776307 pJ
sum error= 232
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 441 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 441 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 441 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.24139, 0.020386, 0.026947, 0.02603, 0.14564, 0.020318, 0.002444, 0.023838, 0.5896, 0.79836]
Predicted label: 9
Correct prediction
Energy consumption = 165.994020 pJ
sum error= 232
Actual label: 8
Output voltages: [0.01472, 0.022215, 0.065429, 0.10073, 0.0028555, 0.030506, 0.023776, 0.011173, 0.7987, 0.082268]
Predicted label: 8
Correct prediction
Energy consumption = 144.736931 pJ
sum error= 232
Actual label: 6
Output voltages: [0.02907, 0.048962, 0.30272, 0.0016209, 0.20624, 0.067739, 0.79877, 0.0042425, 0.66817, 0.0027707]
Predicted label: 6
Correct prediction
Energy consumption = 148.774677 pJ
sum error= 232
Actual label: 6
Output voltages: [0.065841, 0.40309, 0.03347, 0.050079, 0.020601, 0.11303, 0.79878, 0.0049508, 0.68205, 0.0030981]
Predicted label: 6
Correct prediction
Energy consumption = 145.372575 pJ
sum error= 232
Actual label: 4
Output voltages: [0.0021135, 0.0047897, 0.22548, 0.01052, 0.79868, 0.0020298, 0.23439, 0.037129, 0.068764, 0.025759]
Predicted label: 4
Correct prediction
Energy consumption = 154.055999 pJ
sum error= 232
Actual label: 2
Output voltages: [0.75269, 0.031371, 0.79878, 0.20454, 0.0041105, 0.0010764, 0.066982, 0.053063, 0.32215, 0.073044]
Predicted label: 2
Correct prediction
Energy consumption = 150.526409 pJ
sum error= 232
Actual label: 6
Output voltages: [0.051233, 0.17605, 0.29343, 0.0011034, 0.34056, 0.218, 0.79869, 0.0012778, 0.46262, 0.0059978]
Predicted label: 6
Correct prediction
Energy consumption = 148.213267 pJ
sum error= 232
Actual label: 9
Output voltages: [0.19653, 0.033552, 0.0272, 0.32299, 0.022926, 0.011151, 0.022292, 0.12279, 0.17151, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 156.949106 pJ
sum error= 232
Actual label: 2
Output voltages: [0.44903, 0.0063081, 0.79826, 0.33914, 0.014384, 0.0011828, 0.16913, 0.13669, 0.59848, 0.029985]
Predicted label: 2
Correct prediction
Energy consumption = 146.026166 pJ
sum error= 232
Actual label: 8
Output voltages: [0.04226, 0.020833, 0.018236, 0.1817, 0.01573, 0.69553, 0.17179, 0.074965, 0.79877, 0.019883]
Predicted label: 8
Correct prediction
Energy consumption = 150.665761 pJ
sum error= 232
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 442 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 442 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 442 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.19644, 0.0018059, 0.0066561, 0.39189, 0.0015448, 0.79879, 0.031807, 0.18318, 0.74584, 0.035242]
Predicted label: 5
Correct prediction
Energy consumption = 166.897531 pJ
sum error= 232
Actual label: 4
Output voltages: [0.029133, 0.0052384, 0.14472, 0.015609, 0.79857, 0.0013704, 0.25665, 0.023206, 0.034973, 0.067789]
Predicted label: 4
Correct prediction
Energy consumption = 155.383902 pJ
sum error= 232
Actual label: 5
Output voltages: [0.033647, 0.0015267, 0.0070709, 0.45418, 0.015832, 0.7987, 0.191, 0.15532, 0.76109, 0.33128]
Predicted label: 5
Correct prediction
Energy consumption = 152.568538 pJ
sum error= 232
Actual label: 7
Output voltages: [0.01318, 0.0025268, 0.032294, 0.38284, 0.015484, 0.0041131, 0.0011144, 0.79879, 0.35445, 0.27306]
Predicted label: 7
Correct prediction
Energy consumption = 146.480301 pJ
sum error= 232
Actual label: 9
Output voltages: [0.41735, 0.037391, 0.016886, 0.30862, 0.34038, 0.011177, 0.045256, 0.018093, 0.040408, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 156.513930 pJ
sum error= 232
Actual label: 9
Output voltages: [0.1834, 0.028434, 0.01657, 0.01807, 0.79207, 0.0013877, 0.064134, 0.0044844, 0.017593, 0.79101]
Predicted label: 4
Wrong prediction!
Energy consumption = 145.621115 pJ
sum error= 233
Actual label: 9
Output voltages: [0.22227, 0.0045211, 0.016873, 0.0055651, 0.26849, 0.0027415, 0.0035467, 0.0090943, 0.56085, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 143.721930 pJ
sum error= 233
Actual label: 2
Output voltages: [0.22287, 0.22084, 0.79868, 0.058574, 0.0021252, 0.0013474, 0.10572, 0.01329, 0.40609, 0.031941]
Predicted label: 2
Correct prediction
Energy consumption = 157.133687 pJ
sum error= 233
Actual label: 1
Output voltages: [0.011152, 0.79847, 0.0089055, 0.04779, 0.010585, 0.0080654, 0.7548, 0.01663, 0.28604, 0.020242]
Predicted label: 1
Correct prediction
Energy consumption = 160.801854 pJ
sum error= 233
Actual label: 8
Output voltages: [0.33177, 0.0017022, 0.17282, 0.04577, 0.0087279, 0.13855, 0.24241, 0.0011632, 0.7619, 0.067471]
Predicted label: 8
Correct prediction
Energy consumption = 152.105162 pJ
sum error= 233
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 443 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 443 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 443 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.49054, 0.015505, 0.14162, 0.79875, 0.026761, 0.0019297, 0.030923, 0.0088038, 0.51976, 0.018871]
Predicted label: 3
Correct prediction
Energy consumption = 162.324497 pJ
sum error= 233
Actual label: 4
Output voltages: [0.0025244, 0.018037, 0.027456, 0.022474, 0.79856, 0.0022884, 0.14722, 0.16388, 0.078414, 0.053613]
Predicted label: 4
Correct prediction
Energy consumption = 159.547399 pJ
sum error= 233
Actual label: 0
Output voltages: [0.79879, 0.040472, 0.018483, 0.052534, 0.029344, 0.015918, 0.66602, 0.027938, 0.26189, 0.042454]
Predicted label: 0
Correct prediction
Energy consumption = 158.263414 pJ
sum error= 233
Actual label: 7
Output voltages: [0.16463, 0.0066936, 0.037441, 0.62077, 0.67661, 0.0014641, 0.0011176, 0.78829, 0.27876, 0.0018338]
Predicted label: 7
Correct prediction
Energy consumption = 157.596710 pJ
sum error= 233
Actual label: 8
Output voltages: [0.0088525, 0.29243, 0.036447, 0.13758, 0.0021382, 0.016042, 0.007926, 0.032535, 0.79871, 0.45276]
Predicted label: 8
Correct prediction
Energy consumption = 150.756952 pJ
sum error= 233
Actual label: 3
Output voltages: [0.032579, 0.030193, 0.27307, 0.79856, 0.0010909, 0.0011622, 0.0069461, 0.4452, 0.32857, 0.62008]
Predicted label: 3
Correct prediction
Energy consumption = 148.198479 pJ
sum error= 233
Actual label: 9
Output voltages: [0.048989, 0.029882, 0.073832, 0.051734, 0.044126, 0.020182, 0.020495, 0.036974, 0.62335, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 146.858643 pJ
sum error= 233
Actual label: 3
Output voltages: [0.75776, 0.0099078, 0.27952, 0.79874, 0.0069268, 0.0044705, 0.049301, 0.01012, 0.37888, 0.021268]
Predicted label: 3
Correct prediction
Energy consumption = 159.710616 pJ
sum error= 233
Actual label: 4
Output voltages: [0.030298, 0.0059376, 0.2937, 0.056402, 0.79864, 0.001066, 0.0052587, 0.0010665, 0.04705, 0.48813]
Predicted label: 4
Correct prediction
Energy consumption = 143.858960 pJ
sum error= 233
Actual label: 6
Output voltages: [0.4757, 0.011988, 0.066393, 0.0011083, 0.40629, 0.012838, 0.79811, 0.0012083, 0.2213, 0.034857]
Predicted label: 6
Correct prediction
Energy consumption = 153.562637 pJ
sum error= 233
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 444 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 444 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 444 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.13594, 0.0011194, 0.0099284, 0.53379, 0.0014827, 0.79796, 0.041065, 0.11648, 0.76173, 0.047142]
Predicted label: 5
Correct prediction
Energy consumption = 163.918161 pJ
sum error= 233
Actual label: 6
Output voltages: [0.27334, 0.046956, 0.19244, 0.0011008, 0.17755, 0.036519, 0.79879, 0.0010684, 0.29751, 0.0081059]
Predicted label: 6
Correct prediction
Energy consumption = 150.409190 pJ
sum error= 233
Actual label: 2
Output voltages: [0.20498, 0.57382, 0.79877, 0.26367, 0.015013, 0.0012051, 0.38453, 0.009142, 0.16898, 0.080958]
Predicted label: 2
Correct prediction
Energy consumption = 147.537796 pJ
sum error= 233
Actual label: 3
Output voltages: [0.1771, 0.78917, 0.5129, 0.70173, 0.003492, 0.0010828, 0.0095358, 0.016869, 0.31751, 0.0046821]
Predicted label: 1
Wrong prediction!
Energy consumption = 149.471932 pJ
sum error= 234
Actual label: 9
Output voltages: [0.44131, 0.013092, 0.13286, 0.029962, 0.28254, 0.021242, 0.012582, 0.0056312, 0.21252, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 158.379487 pJ
sum error= 234
Actual label: 2
Output voltages: [0.26675, 0.11109, 0.79876, 0.34214, 0.028943, 0.0011108, 0.024205, 0.048022, 0.22799, 0.11339]
Predicted label: 2
Correct prediction
Energy consumption = 147.696801 pJ
sum error= 234
Actual label: 6
Output voltages: [0.12034, 0.10442, 0.057667, 0.0011214, 0.1461, 0.1807, 0.79875, 0.0010664, 0.21392, 0.017545]
Predicted label: 6
Correct prediction
Energy consumption = 146.299664 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79875, 0.052087, 0.027984, 0.016456, 0.017754, 0.0024408, 0.60114, 0.027814, 0.43137, 0.27053]
Predicted label: 0
Correct prediction
Energy consumption = 151.718993 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79876, 0.041694, 0.15723, 0.036612, 0.0016679, 0.004143, 0.42747, 0.014279, 0.044751, 0.047859]
Predicted label: 0
Correct prediction
Energy consumption = 146.039243 pJ
sum error= 234
Actual label: 6
Output voltages: [0.64293, 0.02673, 0.024395, 0.008776, 0.16004, 0.26423, 0.79804, 0.0087594, 0.48894, 0.0050154]
Predicted label: 6
Correct prediction
Energy consumption = 139.523420 pJ
sum error= 234
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 445 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 445 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 445 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.033292, 0.79845, 0.010997, 0.25879, 0.035416, 0.0058271, 0.28604, 0.14859, 0.063969, 0.060301]
Predicted label: 1
Correct prediction
Energy consumption = 184.740914 pJ
sum error= 234
Actual label: 2
Output voltages: [0.16002, 0.23641, 0.79853, 0.040592, 0.015664, 0.0012073, 0.071955, 0.38447, 0.4096, 0.029196]
Predicted label: 2
Correct prediction
Energy consumption = 150.728355 pJ
sum error= 234
Actual label: 8
Output voltages: [0.054311, 0.044686, 0.49463, 0.10075, 0.0080819, 0.0019541, 0.041137, 0.0050766, 0.79879, 0.023356]
Predicted label: 8
Correct prediction
Energy consumption = 149.328565 pJ
sum error= 234
Actual label: 7
Output voltages: [0.037899, 0.11152, 0.3928, 0.058966, 0.0037354, 0.0011732, 0.0012169, 0.79878, 0.71919, 0.038718]
Predicted label: 7
Correct prediction
Energy consumption = 148.994183 pJ
sum error= 234
Actual label: 9
Output voltages: [0.64254, 0.0012304, 0.045255, 0.0062899, 0.10379, 0.0052781, 0.0011598, 0.002739, 0.74618, 0.77829]
Predicted label: 9
Correct prediction
Energy consumption = 147.662451 pJ
sum error= 234
Actual label: 8
Output voltages: [0.3763, 0.029953, 0.40843, 0.0091409, 0.28921, 0.0011649, 0.19484, 0.0012402, 0.79857, 0.26622]
Predicted label: 8
Correct prediction
Energy consumption = 140.021292 pJ
sum error= 234
Actual label: 2
Output voltages: [0.39509, 0.080577, 0.7987, 0.096077, 0.015059, 0.0012657, 0.34578, 0.011302, 0.71482, 0.030671]
Predicted label: 2
Correct prediction
Energy consumption = 150.751880 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79876, 0.022105, 0.024092, 0.0071302, 0.039738, 0.01463, 0.73327, 0.0047937, 0.19351, 0.12776]
Predicted label: 0
Correct prediction
Energy consumption = 153.799610 pJ
sum error= 234
Actual label: 4
Output voltages: [0.010206, 0.017434, 0.25129, 0.0092314, 0.79864, 0.0011587, 0.017083, 0.021782, 0.035536, 0.23528]
Predicted label: 4
Correct prediction
Energy consumption = 159.149844 pJ
sum error= 234
Actual label: 7
Output voltages: [0.094234, 0.028548, 0.15304, 0.27001, 0.0045894, 0.001133, 0.0010665, 0.79863, 0.20061, 0.27539]
Predicted label: 7
Correct prediction
Energy consumption = 154.132372 pJ
sum error= 234
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 446 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 446 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 446 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.062542, 0.23211, 0.34409, 0.75429, 0.010606, 0.0013757, 0.0010773, 0.79534, 0.014008, 0.4334]
Predicted label: 7
Correct prediction
Energy consumption = 180.959230 pJ
sum error= 234
Actual label: 5
Output voltages: [0.010564, 0.015275, 0.0014492, 0.52668, 0.015795, 0.79822, 0.062209, 0.029509, 0.60772, 0.24139]
Predicted label: 5
Correct prediction
Energy consumption = 149.593964 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79063, 0.097212, 0.016186, 0.0091653, 0.025397, 0.021853, 0.76854, 0.018558, 0.034482, 0.27269]
Predicted label: 0
Correct prediction
Energy consumption = 157.398931 pJ
sum error= 234
Actual label: 5
Output voltages: [0.020144, 0.0011241, 0.026096, 0.48173, 0.36803, 0.79211, 0.22204, 0.016415, 0.67389, 0.032872]
Predicted label: 5
Correct prediction
Energy consumption = 144.010903 pJ
sum error= 234
Actual label: 6
Output voltages: [0.34878, 0.21613, 0.29306, 0.0043913, 0.085542, 0.093149, 0.79879, 0.0011003, 0.44443, 0.013951]
Predicted label: 6
Correct prediction
Energy consumption = 146.411039 pJ
sum error= 234
Actual label: 4
Output voltages: [0.22796, 0.060846, 0.51861, 0.10849, 0.79848, 0.00122, 0.059679, 0.56067, 0.0028046, 0.37625]
Predicted label: 4
Correct prediction
Energy consumption = 146.235873 pJ
sum error= 234
Actual label: 6
Output voltages: [0.19152, 0.024763, 0.26115, 0.0040967, 0.50016, 0.20608, 0.79878, 0.0062392, 0.69094, 0.005869]
Predicted label: 6
Correct prediction
Energy consumption = 147.045591 pJ
sum error= 234
Actual label: 7
Output voltages: [0.026847, 0.0097563, 0.031079, 0.0040399, 0.060989, 0.0016764, 0.0012403, 0.79877, 0.69199, 0.044414]
Predicted label: 7
Correct prediction
Energy consumption = 160.495794 pJ
sum error= 234
Actual label: 4
Output voltages: [0.0019209, 0.027836, 0.037445, 0.024196, 0.79876, 0.0015811, 0.041502, 0.1372, 0.12406, 0.0027105]
Predicted label: 4
Correct prediction
Energy consumption = 148.489700 pJ
sum error= 234
Actual label: 3
Output voltages: [0.33211, 0.12451, 0.054964, 0.79866, 0.0016924, 0.048585, 0.026269, 0.014986, 0.41238, 0.046425]
Predicted label: 3
Correct prediction
Energy consumption = 150.745293 pJ
sum error= 234
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 447 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 447 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 447 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.038337, 0.038864, 0.014707, 0.019644, 0.0053551, 0.33844, 0.16257, 0.35137, 0.064038]
Predicted label: 0
Correct prediction
Energy consumption = 176.302432 pJ
sum error= 234
Actual label: 7
Output voltages: [0.54589, 0.0091027, 0.22331, 0.0087277, 0.012216, 0.0010802, 0.0011623, 0.79878, 0.62277, 0.20701]
Predicted label: 7
Correct prediction
Energy consumption = 155.021788 pJ
sum error= 234
Actual label: 5
Output voltages: [0.028693, 0.0011462, 0.0041138, 0.015035, 0.039716, 0.79814, 0.51792, 0.0050615, 0.78898, 0.014867]
Predicted label: 5
Correct prediction
Energy consumption = 153.023344 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79878, 0.037679, 0.038918, 0.034293, 0.036402, 0.0089557, 0.55306, 0.017061, 0.34887, 0.050709]
Predicted label: 0
Correct prediction
Energy consumption = 154.673252 pJ
sum error= 234
Actual label: 7
Output voltages: [0.39169, 0.027417, 0.16899, 0.15047, 0.015532, 0.001066, 0.0013523, 0.79869, 0.4381, 0.21549]
Predicted label: 7
Correct prediction
Energy consumption = 157.455092 pJ
sum error= 234
Actual label: 4
Output voltages: [0.0075616, 0.0070385, 0.32778, 0.023363, 0.79856, 0.0026163, 0.29316, 0.19888, 0.038311, 0.16394]
Predicted label: 4
Correct prediction
Energy consumption = 148.349430 pJ
sum error= 234
Actual label: 2
Output voltages: [0.10993, 0.32907, 0.79876, 0.028359, 0.018319, 0.0014576, 0.32054, 0.028945, 0.30426, 0.052868]
Predicted label: 2
Correct prediction
Energy consumption = 150.082282 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79845, 0.33544, 0.01255, 0.01673, 0.018213, 0.043749, 0.76632, 0.032249, 0.074764, 0.022144]
Predicted label: 0
Correct prediction
Energy consumption = 160.681219 pJ
sum error= 234
Actual label: 8
Output voltages: [0.040743, 0.025352, 0.086714, 0.054508, 0.022344, 0.0063483, 0.094531, 0.0082603, 0.79876, 0.18565]
Predicted label: 8
Correct prediction
Energy consumption = 151.837174 pJ
sum error= 234
Actual label: 9
Output voltages: [0.3879, 0.054877, 0.015318, 0.41982, 0.1392, 0.0023972, 0.0013026, 0.32749, 0.015606, 0.79831]
Predicted label: 9
Correct prediction
Energy consumption = 153.706659 pJ
sum error= 234
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 448 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 448 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 448 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.38794, 0.0049241, 0.0041266, 0.042514, 0.034116, 0.035289, 0.0011131, 0.26417, 0.67275, 0.78424]
Predicted label: 9
Correct prediction
Energy consumption = 170.481377 pJ
sum error= 234
Actual label: 4
Output voltages: [0.0030416, 0.030233, 0.043309, 0.17122, 0.79877, 0.0010763, 0.0057424, 0.041358, 0.014129, 0.19979]
Predicted label: 4
Correct prediction
Energy consumption = 141.266657 pJ
sum error= 234
Actual label: 2
Output voltages: [0.7218, 0.0011285, 0.79633, 0.62845, 0.0042017, 0.0010712, 0.0028299, 0.036467, 0.62901, 0.02183]
Predicted label: 2
Correct prediction
Energy consumption = 150.267110 pJ
sum error= 234
Actual label: 4
Output voltages: [0.15907, 0.0025856, 0.74242, 0.0012387, 0.74774, 0.0011796, 0.0022709, 0.046812, 0.27763, 0.73445]
Predicted label: 4
Correct prediction
Energy consumption = 155.091986 pJ
sum error= 234
Actual label: 6
Output voltages: [0.19085, 0.02838, 0.035203, 0.0085076, 0.29017, 0.53058, 0.79879, 0.0069184, 0.60056, 0.0037797]
Predicted label: 6
Correct prediction
Energy consumption = 149.133316 pJ
sum error= 234
Actual label: 7
Output voltages: [0.412, 0.032525, 0.030884, 0.035114, 0.012842, 0.0012845, 0.0012269, 0.79871, 0.6436, 0.056484]
Predicted label: 7
Correct prediction
Energy consumption = 157.231328 pJ
sum error= 234
Actual label: 8
Output voltages: [0.032824, 0.0131, 0.047978, 0.079912, 0.011865, 0.18228, 0.038224, 0.0031079, 0.79877, 0.037294]
Predicted label: 8
Correct prediction
Energy consumption = 149.769007 pJ
sum error= 234
Actual label: 7
Output voltages: [0.062066, 0.073234, 0.59117, 0.13511, 0.0013359, 0.0012149, 0.0018941, 0.77751, 0.79109, 0.12356]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.594155 pJ
sum error= 235
Actual label: 6
Output voltages: [0.23656, 0.026516, 0.16534, 0.0022104, 0.43698, 0.14342, 0.79876, 0.0011349, 0.45355, 0.0040255]
Predicted label: 6
Correct prediction
Energy consumption = 150.347854 pJ
sum error= 235
Actual label: 9
Output voltages: [0.050723, 0.013127, 0.034835, 0.41151, 0.0091637, 0.0048222, 0.0014772, 0.02206, 0.53453, 0.79778]
Predicted label: 9
Correct prediction
Energy consumption = 152.339305 pJ
sum error= 235
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 449 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 449 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 449 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.022603, 0.018199, 0.029329, 0.0072137, 0.79873, 0.004175, 0.35415, 0.028833, 0.052465, 0.024363]
Predicted label: 4
Correct prediction
Energy consumption = 174.898925 pJ
sum error= 235
Actual label: 1
Output voltages: [0.0090642, 0.79877, 0.15697, 0.17153, 0.045865, 0.0037376, 0.22738, 0.0014225, 0.00778, 0.054004]
Predicted label: 1
Correct prediction
Energy consumption = 154.622517 pJ
sum error= 235
Actual label: 3
Output voltages: [0.037525, 0.025896, 0.037633, 0.79864, 0.022253, 0.010168, 0.0086934, 0.2007, 0.71208, 0.031496]
Predicted label: 3
Correct prediction
Energy consumption = 149.339319 pJ
sum error= 235
Actual label: 7
Output voltages: [0.17424, 0.30071, 0.62767, 0.016405, 0.0052364, 0.0013097, 0.0029723, 0.79879, 0.048113, 0.040546]
Predicted label: 7
Correct prediction
Energy consumption = 148.931420 pJ
sum error= 235
Actual label: 3
Output voltages: [0.22524, 0.011811, 0.022952, 0.79871, 0.074538, 0.72575, 0.013808, 0.0068881, 0.26966, 0.001856]
Predicted label: 3
Correct prediction
Energy consumption = 153.049074 pJ
sum error= 235
Actual label: 0
Output voltages: [0.79874, 0.045818, 0.032229, 0.011395, 0.014159, 0.013386, 0.14468, 0.013419, 0.22918, 0.053662]
Predicted label: 0
Correct prediction
Energy consumption = 158.637622 pJ
sum error= 235
Actual label: 8
Output voltages: [0.045691, 0.025492, 0.2536, 0.025023, 0.01926, 0.013148, 0.012108, 0.0017599, 0.79871, 0.2698]
Predicted label: 8
Correct prediction
Energy consumption = 148.810771 pJ
sum error= 235
Actual label: 8
Output voltages: [0.0075664, 0.062216, 0.26146, 0.01964, 0.046429, 0.0013067, 0.0025769, 0.74974, 0.79878, 0.02425]
Predicted label: 8
Correct prediction
Energy consumption = 140.544496 pJ
sum error= 235
Actual label: 7
Output voltages: [0.052252, 0.042074, 0.29551, 0.14081, 0.0491, 0.0011025, 0.01564, 0.50593, 0.7986, 0.0046865]
Predicted label: 8
Wrong prediction!
Energy consumption = 140.502948 pJ
sum error= 236
Actual label: 6
Output voltages: [0.12404, 0.15185, 0.24115, 0.0010679, 0.03394, 0.32124, 0.79873, 0.018778, 0.50491, 0.0084678]
Predicted label: 6
Correct prediction
Energy consumption = 152.297865 pJ
sum error= 236
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 450 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 450 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 450 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.43397, 0.42912, 0.0078872, 0.021952, 0.33876, 0.0011182, 0.0010701, 0.00165, 0.087355, 0.795]
Predicted label: 9
Correct prediction
Energy consumption = 180.952472 pJ
sum error= 236
Actual label: 3
Output voltages: [0.7694, 0.016541, 0.060366, 0.79872, 0.01638, 0.12938, 0.003236, 0.033477, 0.45764, 0.074776]
Predicted label: 3
Correct prediction
Energy consumption = 145.401773 pJ
sum error= 236
Actual label: 9
Output voltages: [0.53363, 0.0033038, 0.069811, 0.015271, 0.21849, 0.0017322, 0.0010914, 0.061065, 0.39461, 0.79618]
Predicted label: 9
Correct prediction
Energy consumption = 147.991505 pJ
sum error= 236
Actual label: 2
Output voltages: [0.45656, 0.69576, 0.79589, 0.21868, 0.010392, 0.0013272, 0.26966, 0.017197, 0.10896, 0.038139]
Predicted label: 2
Correct prediction
Energy consumption = 158.328163 pJ
sum error= 236
Actual label: 2
Output voltages: [0.048502, 0.066305, 0.79879, 0.099264, 0.023416, 0.001141, 0.025391, 0.49405, 0.477, 0.0068877]
Predicted label: 2
Correct prediction
Energy consumption = 137.276088 pJ
sum error= 236
Actual label: 9
Output voltages: [0.091226, 0.0017985, 0.0099454, 0.44469, 0.42213, 0.22053, 0.0010683, 0.40151, 0.068506, 0.79221]
Predicted label: 9
Correct prediction
Energy consumption = 157.167485 pJ
sum error= 236
Actual label: 2
Output voltages: [0.48416, 0.002086, 0.79027, 0.62965, 0.0015138, 0.001066, 0.012999, 0.030243, 0.49905, 0.0096155]
Predicted label: 2
Correct prediction
Energy consumption = 147.066309 pJ
sum error= 236
Actual label: 1
Output voltages: [0.029285, 0.79788, 0.72051, 0.0090624, 0.0035493, 0.0010717, 0.021173, 0.34649, 0.45226, 0.039172]
Predicted label: 1
Correct prediction
Energy consumption = 150.050257 pJ
sum error= 236
Actual label: 8
Output voltages: [0.10095, 0.0080369, 0.28935, 0.27285, 0.006742, 0.035515, 0.0078544, 0.018933, 0.79864, 0.025433]
Predicted label: 8
Correct prediction
Energy consumption = 153.838351 pJ
sum error= 236
Actual label: 3
Output voltages: [0.085914, 0.1714, 0.49708, 0.79875, 0.025783, 0.001087, 0.0031803, 0.0051579, 0.39957, 0.29839]
Predicted label: 3
Correct prediction
Energy consumption = 147.717960 pJ
sum error= 236
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 451 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 451 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 451 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.34729, 0.013421, 0.79877, 0.016718, 0.014599, 0.0011821, 0.053051, 0.056061, 0.4848, 0.026443]
Predicted label: 2
Correct prediction
Energy consumption = 168.033808 pJ
sum error= 236
Actual label: 9
Output voltages: [0.052373, 0.0016274, 0.31736, 0.074995, 0.7918, 0.0011169, 0.0011685, 0.02129, 0.014697, 0.76584]
Predicted label: 4
Wrong prediction!
Energy consumption = 150.975209 pJ
sum error= 237
Actual label: 6
Output voltages: [0.020453, 0.034708, 0.056778, 0.014373, 0.28952, 0.15955, 0.79878, 0.0043453, 0.7356, 0.0044868]
Predicted label: 6
Correct prediction
Energy consumption = 145.378989 pJ
sum error= 237
Actual label: 8
Output voltages: [0.056085, 0.0010681, 0.13481, 0.44077, 0.0010793, 0.62969, 0.014799, 0.0026137, 0.79838, 0.032161]
Predicted label: 8
Correct prediction
Energy consumption = 145.384112 pJ
sum error= 237
Actual label: 4
Output voltages: [0.011722, 0.0028167, 0.20921, 0.030693, 0.79874, 0.0011601, 0.008909, 0.005898, 0.37039, 0.04384]
Predicted label: 4
Correct prediction
Energy consumption = 151.107307 pJ
sum error= 237
Actual label: 0
Output voltages: [0.79879, 0.0057662, 0.097729, 0.0029215, 0.040475, 0.0020511, 0.034579, 0.19504, 0.55955, 0.043979]
Predicted label: 0
Correct prediction
Energy consumption = 152.568207 pJ
sum error= 237
Actual label: 1
Output voltages: [0.0049711, 0.79861, 0.0073059, 0.049057, 0.0021843, 0.015906, 0.40606, 0.018474, 0.36725, 0.011301]
Predicted label: 1
Correct prediction
Energy consumption = 160.697657 pJ
sum error= 237
Actual label: 2
Output voltages: [0.59494, 0.014313, 0.79877, 0.22351, 0.03431, 0.0010924, 0.030751, 0.032855, 0.62911, 0.019229]
Predicted label: 2
Correct prediction
Energy consumption = 149.721986 pJ
sum error= 237
Actual label: 8
Output voltages: [0.013939, 0.051192, 0.033946, 0.23507, 0.0013548, 0.0097897, 0.0063702, 0.019956, 0.79874, 0.14214]
Predicted label: 8
Correct prediction
Energy consumption = 145.260975 pJ
sum error= 237
Actual label: 4
Output voltages: [0.0043004, 0.01538, 0.040501, 0.026746, 0.79876, 0.0011338, 0.030949, 0.02795, 0.014224, 0.079904]
Predicted label: 4
Correct prediction
Energy consumption = 158.208193 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 452 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 452 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 452 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.076586, 0.0010661, 0.0011121, 0.027315, 0.074371, 0.79335, 0.014504, 0.0066691, 0.76339, 0.07988]
Predicted label: 5
Correct prediction
Energy consumption = 172.264463 pJ
sum error= 237
Actual label: 2
Output voltages: [0.48909, 0.38468, 0.79875, 0.23329, 0.0016044, 0.0012537, 0.036747, 0.49738, 0.048015, 0.17244]
Predicted label: 2
Correct prediction
Energy consumption = 143.162601 pJ
sum error= 237
Actual label: 7
Output voltages: [0.20759, 0.044508, 0.010057, 0.15733, 0.002778, 0.0041351, 0.0010799, 0.79879, 0.54672, 0.66509]
Predicted label: 7
Correct prediction
Energy consumption = 152.638513 pJ
sum error= 237
Actual label: 8
Output voltages: [0.045147, 0.048297, 0.022048, 0.28891, 0.0079564, 0.10039, 0.022081, 0.034659, 0.79879, 0.031152]
Predicted label: 8
Correct prediction
Energy consumption = 151.371363 pJ
sum error= 237
Actual label: 1
Output voltages: [0.037989, 0.79862, 0.039171, 0.080139, 0.025179, 0.001376, 0.74937, 0.0038875, 0.11874, 0.038116]
Predicted label: 1
Correct prediction
Energy consumption = 163.206400 pJ
sum error= 237
Actual label: 1
Output voltages: [0.025487, 0.79843, 0.062248, 0.079135, 0.0034723, 0.001269, 0.47267, 0.00433, 0.43099, 0.044948]
Predicted label: 1
Correct prediction
Energy consumption = 153.798192 pJ
sum error= 237
Actual label: 3
Output voltages: [0.30878, 0.045952, 0.30162, 0.79877, 0.020707, 0.001067, 0.0015891, 0.0074624, 0.54871, 0.0061918]
Predicted label: 3
Correct prediction
Energy consumption = 150.248290 pJ
sum error= 237
Actual label: 0
Output voltages: [0.79879, 0.062572, 0.046027, 0.0078322, 0.011827, 0.0053067, 0.36606, 0.13005, 0.03905, 0.058783]
Predicted label: 0
Correct prediction
Energy consumption = 154.411064 pJ
sum error= 237
Actual label: 3
Output voltages: [0.029079, 0.0037209, 0.32897, 0.79879, 0.054839, 0.14028, 0.079574, 0.0016943, 0.19409, 0.15704]
Predicted label: 3
Correct prediction
Energy consumption = 149.195449 pJ
sum error= 237
Actual label: 5
Output voltages: [0.039891, 0.0015477, 0.0011263, 0.40706, 0.0075685, 0.79876, 0.11064, 0.021454, 0.58615, 0.014223]
Predicted label: 5
Correct prediction
Energy consumption = 136.412321 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 453 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 453 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 453 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.44999, 0.23212, 0.0017405, 0.35607, 0.0020781, 0.0084894, 0.0011641, 0.79852, 0.24685, 0.75843]
Predicted label: 7
Correct prediction
Energy consumption = 169.628589 pJ
sum error= 237
Actual label: 0
Output voltages: [0.79826, 0.02233, 0.069616, 0.0039128, 0.021445, 0.0093073, 0.57697, 0.021237, 0.10341, 0.063585]
Predicted label: 0
Correct prediction
Energy consumption = 153.785408 pJ
sum error= 237
Actual label: 3
Output voltages: [0.16474, 0.0094953, 0.042963, 0.79869, 0.019555, 0.030078, 0.0090448, 0.045399, 0.55525, 0.0446]
Predicted label: 3
Correct prediction
Energy consumption = 151.253216 pJ
sum error= 237
Actual label: 1
Output voltages: [0.01453, 0.79849, 0.028245, 0.027675, 0.013517, 0.0021285, 0.74864, 0.0012872, 0.23663, 0.055935]
Predicted label: 1
Correct prediction
Energy consumption = 167.119819 pJ
sum error= 237
Actual label: 9
Output voltages: [0.033116, 0.0118, 0.0022955, 0.1282, 0.016791, 0.014419, 0.0019996, 0.52547, 0.52529, 0.78695]
Predicted label: 9
Correct prediction
Energy consumption = 157.126185 pJ
sum error= 237
Actual label: 3
Output voltages: [0.19549, 0.064734, 0.055281, 0.79856, 0.0052424, 0.017066, 0.0052288, 0.090739, 0.41801, 0.048667]
Predicted label: 3
Correct prediction
Energy consumption = 142.176378 pJ
sum error= 237
Actual label: 6
Output voltages: [0.42637, 0.0010972, 0.011633, 0.013857, 0.027752, 0.79375, 0.79465, 0.0016307, 0.67652, 0.024725]
Predicted label: 6
Correct prediction
Energy consumption = 153.426528 pJ
sum error= 237
Actual label: 3
Output voltages: [0.32831, 0.03672, 0.34116, 0.79865, 0.055178, 0.0017485, 0.032557, 0.01737, 0.45315, 0.069428]
Predicted label: 3
Correct prediction
Energy consumption = 147.280297 pJ
sum error= 237
Actual label: 1
Output voltages: [0.0089688, 0.7986, 0.18613, 0.69266, 0.02073, 0.002552, 0.59988, 0.19376, 0.0079173, 0.12929]
Predicted label: 1
Correct prediction
Energy consumption = 158.014887 pJ
sum error= 237
Actual label: 7
Output voltages: [0.19923, 0.14343, 0.33808, 0.021484, 0.0019719, 0.001088, 0.0010925, 0.79861, 0.58703, 0.018352]
Predicted label: 7
Correct prediction
Energy consumption = 151.689780 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 454 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 454 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 454 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.51951, 0.0077864, 0.62913, 0.46835, 0.0022338, 0.0010673, 0.0010909, 0.7878, 0.7733, 0.19563]
Predicted label: 7
Correct prediction
Energy consumption = 167.213087 pJ
sum error= 237
Actual label: 3
Output voltages: [0.091595, 0.044962, 0.042411, 0.79875, 0.0056542, 0.0029019, 0.012031, 0.017449, 0.50929, 0.049093]
Predicted label: 3
Correct prediction
Energy consumption = 133.675418 pJ
sum error= 237
Actual label: 0
Output voltages: [0.79879, 0.054516, 0.027577, 0.015453, 0.013731, 0.014593, 0.45754, 0.0092648, 0.03664, 0.021839]
Predicted label: 0
Correct prediction
Energy consumption = 153.098185 pJ
sum error= 237
Actual label: 8
Output voltages: [0.026768, 0.030256, 0.03472, 0.016412, 0.014788, 0.0048681, 0.0075412, 0.0016446, 0.79876, 0.37902]
Predicted label: 8
Correct prediction
Energy consumption = 148.973193 pJ
sum error= 237
Actual label: 4
Output voltages: [0.0012114, 0.11448, 0.050849, 0.0057201, 0.79878, 0.0023083, 0.446, 0.39365, 0.028363, 0.047443]
Predicted label: 4
Correct prediction
Energy consumption = 150.701323 pJ
sum error= 237
Actual label: 8
Output voltages: [0.035174, 0.080922, 0.1374, 0.14987, 0.012185, 0.011032, 0.044403, 0.010967, 0.79863, 0.19782]
Predicted label: 8
Correct prediction
Energy consumption = 153.113567 pJ
sum error= 237
Actual label: 2
Output voltages: [0.52829, 0.19217, 0.79879, 0.020911, 0.0065124, 0.0013738, 0.23003, 0.097538, 0.32052, 0.013173]
Predicted label: 2
Correct prediction
Energy consumption = 140.945756 pJ
sum error= 237
Actual label: 6
Output voltages: [0.05123, 0.0052575, 0.26672, 0.0010784, 0.61109, 0.01127, 0.79654, 0.0010884, 0.35209, 0.022659]
Predicted label: 6
Correct prediction
Energy consumption = 136.295789 pJ
sum error= 237
Actual label: 5
Output voltages: [0.46577, 0.0069689, 0.0021635, 0.30321, 0.011606, 0.79879, 0.75886, 0.0098198, 0.52324, 0.010385]
Predicted label: 5
Correct prediction
Energy consumption = 141.451052 pJ
sum error= 237
Actual label: 2
Output voltages: [0.51215, 0.33454, 0.79875, 0.047155, 0.016949, 0.0012645, 0.19925, 0.054626, 0.31793, 0.043526]
Predicted label: 2
Correct prediction
Energy consumption = 153.333273 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 455 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 455 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 455 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33391, 0.0026077, 0.016604, 0.37694, 0.13941, 0.12626, 0.018089, 0.067525, 0.26068, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 178.713422 pJ
sum error= 237
Actual label: 7
Output voltages: [0.28736, 0.004541, 0.052139, 0.0010836, 0.059413, 0.036234, 0.0010834, 0.79863, 0.37866, 0.013457]
Predicted label: 7
Correct prediction
Energy consumption = 150.897944 pJ
sum error= 237
Actual label: 3
Output voltages: [0.54215, 0.0087512, 0.029806, 0.79875, 0.0033127, 0.048129, 0.0050679, 0.18884, 0.63435, 0.031747]
Predicted label: 3
Correct prediction
Energy consumption = 150.525946 pJ
sum error= 237
Actual label: 9
Output voltages: [0.55151, 0.016468, 0.011035, 0.044258, 0.31007, 0.031312, 0.011248, 0.010277, 0.46992, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 149.052678 pJ
sum error= 237
Actual label: 0
Output voltages: [0.79226, 0.0030585, 0.040993, 0.0013339, 0.0033482, 0.045506, 0.57309, 0.0098505, 0.24891, 0.051727]
Predicted label: 0
Correct prediction
Energy consumption = 149.474193 pJ
sum error= 237
Actual label: 9
Output voltages: [0.17304, 0.0019542, 0.011546, 0.16498, 0.33862, 0.0073339, 0.0011003, 0.015056, 0.13804, 0.79511]
Predicted label: 9
Correct prediction
Energy consumption = 155.481983 pJ
sum error= 237
Actual label: 9
Output voltages: [0.021692, 0.026389, 0.15649, 0.0060059, 0.30594, 0.0061866, 0.014357, 0.0049573, 0.24278, 0.79804]
Predicted label: 9
Correct prediction
Energy consumption = 140.941871 pJ
sum error= 237
Actual label: 6
Output voltages: [0.178, 0.23871, 0.13113, 0.0087216, 0.11131, 0.45276, 0.79868, 0.01838, 0.26632, 0.014421]
Predicted label: 6
Correct prediction
Energy consumption = 149.886850 pJ
sum error= 237
Actual label: 4
Output voltages: [0.053309, 0.016804, 0.14602, 0.0011183, 0.79872, 0.0044908, 0.78491, 0.017857, 0.18189, 0.024575]
Predicted label: 4
Correct prediction
Energy consumption = 143.089530 pJ
sum error= 237
Actual label: 2
Output voltages: [0.66906, 0.017023, 0.79877, 0.21742, 0.032372, 0.0011253, 0.042731, 0.037116, 0.55947, 0.03184]
Predicted label: 2
Correct prediction
Energy consumption = 151.208152 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 456 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 456 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 456 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.11732, 0.016403, 0.13414, 0.04565, 0.06666, 0.023974, 0.040799, 0.095704, 0.32142, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 169.054488 pJ
sum error= 237
Actual label: 7
Output voltages: [0.23358, 0.11512, 0.014611, 0.31308, 0.029356, 0.072941, 0.0010734, 0.79864, 0.044473, 0.37486]
Predicted label: 7
Correct prediction
Energy consumption = 154.438737 pJ
sum error= 237
Actual label: 2
Output voltages: [0.34626, 0.0010978, 0.79405, 0.29478, 0.027487, 0.0011295, 0.019224, 0.036005, 0.75531, 0.021438]
Predicted label: 2
Correct prediction
Energy consumption = 150.932609 pJ
sum error= 237
Actual label: 1
Output voltages: [0.16024, 0.79876, 0.62993, 0.0047659, 0.10739, 0.001122, 0.1998, 0.016257, 0.039029, 0.03374]
Predicted label: 1
Correct prediction
Energy consumption = 157.583711 pJ
sum error= 237
Actual label: 1
Output voltages: [0.012147, 0.79878, 0.078467, 0.019012, 0.40798, 0.0089189, 0.73151, 0.0010667, 0.17635, 0.063322]
Predicted label: 1
Correct prediction
Energy consumption = 151.095342 pJ
sum error= 237
Actual label: 6
Output voltages: [0.12203, 0.060632, 0.0065138, 0.047784, 0.27187, 0.7167, 0.79872, 0.033366, 0.74651, 0.0010865]
Predicted label: 6
Correct prediction
Energy consumption = 155.722025 pJ
sum error= 237
Actual label: 7
Output voltages: [0.057702, 0.01146, 0.78308, 0.084637, 0.0082126, 0.0012729, 0.0010878, 0.79867, 0.72803, 0.036533]
Predicted label: 7
Correct prediction
Energy consumption = 149.961852 pJ
sum error= 237
Actual label: 4
Output voltages: [0.052879, 0.0028212, 0.014948, 0.098541, 0.76475, 0.0011675, 0.0010841, 0.012839, 0.16103, 0.70066]
Predicted label: 4
Correct prediction
Energy consumption = 157.790471 pJ
sum error= 237
Actual label: 7
Output voltages: [0.038459, 0.17253, 0.6386, 0.016614, 0.014679, 0.001195, 0.001077, 0.7985, 0.06903, 0.40066]
Predicted label: 7
Correct prediction
Energy consumption = 152.263364 pJ
sum error= 237
Actual label: 5
Output voltages: [0.036957, 0.001107, 0.0013182, 0.23114, 0.069949, 0.79727, 0.22645, 0.066392, 0.79392, 0.024914]
Predicted label: 5
Correct prediction
Energy consumption = 144.953344 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 457 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 457 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 457 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.54926, 0.018205, 0.016085, 0.04333, 0.55363, 0.013669, 0.0023881, 0.001153, 0.25678, 0.79751]
Predicted label: 9
Correct prediction
Energy consumption = 158.194117 pJ
sum error= 237
Actual label: 6
Output voltages: [0.63015, 0.018693, 0.52403, 0.30294, 0.024691, 0.0023184, 0.49936, 0.0012173, 0.79809, 0.049226]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.827409 pJ
sum error= 238
Actual label: 8
Output voltages: [0.053595, 0.026553, 0.12356, 0.070065, 0.015267, 0.012147, 0.037755, 0.0098075, 0.79876, 0.087501]
Predicted label: 8
Correct prediction
Energy consumption = 147.523956 pJ
sum error= 238
Actual label: 2
Output voltages: [0.66534, 0.39652, 0.79878, 0.017351, 0.0017741, 0.0012287, 0.096295, 0.43668, 0.44686, 0.042831]
Predicted label: 2
Correct prediction
Energy consumption = 142.832803 pJ
sum error= 238
Actual label: 1
Output voltages: [0.016903, 0.79866, 0.15578, 0.19862, 0.024363, 0.0044462, 0.72443, 0.001683, 0.60976, 0.20475]
Predicted label: 1
Correct prediction
Energy consumption = 160.976984 pJ
sum error= 238
Actual label: 4
Output voltages: [0.75271, 0.0020593, 0.76439, 0.026577, 0.47796, 0.0011175, 0.32365, 0.0079943, 0.011705, 0.47376]
Predicted label: 2
Wrong prediction!
Energy consumption = 157.322952 pJ
sum error= 239
Actual label: 4
Output voltages: [0.0090501, 0.0091784, 0.31389, 0.0044524, 0.79862, 0.0011255, 0.036468, 0.02251, 0.021336, 0.32087]
Predicted label: 4
Correct prediction
Energy consumption = 152.603665 pJ
sum error= 239
Actual label: 5
Output voltages: [0.19558, 0.0082913, 0.0015647, 0.034975, 0.023001, 0.79868, 0.069209, 0.23972, 0.7897, 0.0014748]
Predicted label: 5
Correct prediction
Energy consumption = 149.977329 pJ
sum error= 239
Actual label: 7
Output voltages: [0.21538, 0.44972, 0.016501, 0.16059, 0.18246, 0.0033055, 0.0010779, 0.73078, 0.0014808, 0.76736]
Predicted label: 9
Wrong prediction!
Energy consumption = 161.401974 pJ
sum error= 240
Actual label: 6
Output voltages: [0.010657, 0.022705, 0.029049, 0.023369, 0.059414, 0.17737, 0.79861, 0.0035671, 0.75633, 0.011382]
Predicted label: 6
Correct prediction
Energy consumption = 154.329246 pJ
sum error= 240
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 458 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 458 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 458 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.050392, 0.79863, 0.029079, 0.016767, 0.10791, 0.0013101, 0.40989, 0.0023979, 0.058037, 0.049051]
Predicted label: 1
Correct prediction
Energy consumption = 179.159975 pJ
sum error= 240
Actual label: 3
Output voltages: [0.43208, 0.025538, 0.21054, 0.79866, 0.018844, 0.031201, 0.0098188, 0.01758, 0.6255, 0.039044]
Predicted label: 3
Correct prediction
Energy consumption = 151.510750 pJ
sum error= 240
Actual label: 2
Output voltages: [0.052449, 0.1925, 0.79831, 0.1727, 0.045331, 0.0012141, 0.18016, 0.027618, 0.44345, 0.014735]
Predicted label: 2
Correct prediction
Energy consumption = 155.380552 pJ
sum error= 240
Actual label: 5
Output voltages: [0.33899, 0.0011695, 0.0069617, 0.05214, 0.034638, 0.79861, 0.3194, 0.11485, 0.7139, 0.01935]
Predicted label: 5
Correct prediction
Energy consumption = 142.851900 pJ
sum error= 240
Actual label: 9
Output voltages: [0.29142, 0.028094, 0.027328, 0.026985, 0.060731, 0.014123, 0.24963, 0.013891, 0.23972, 0.79865]
Predicted label: 9
Correct prediction
Energy consumption = 146.334783 pJ
sum error= 240
Actual label: 9
Output voltages: [0.18495, 0.025417, 0.00207, 0.35911, 0.43225, 0.03847, 0.12682, 0.029614, 0.022863, 0.79746]
Predicted label: 9
Correct prediction
Energy consumption = 140.380454 pJ
sum error= 240
Actual label: 3
Output voltages: [0.40512, 0.031262, 0.088276, 0.79874, 0.023301, 0.020423, 0.01684, 0.0054049, 0.68878, 0.12696]
Predicted label: 3
Correct prediction
Energy consumption = 147.442795 pJ
sum error= 240
Actual label: 6
Output voltages: [0.032606, 0.028432, 0.083967, 0.0021237, 0.48215, 0.27086, 0.79875, 0.0011341, 0.55289, 0.011617]
Predicted label: 6
Correct prediction
Energy consumption = 149.177694 pJ
sum error= 240
Actual label: 1
Output voltages: [0.0030376, 0.79851, 0.34559, 0.65482, 0.0042199, 0.0013027, 0.42895, 0.071445, 0.048694, 0.020662]
Predicted label: 1
Correct prediction
Energy consumption = 167.745690 pJ
sum error= 240
Actual label: 1
Output voltages: [0.037357, 0.79861, 0.0073525, 0.026094, 0.39442, 0.0044224, 0.54151, 0.0075461, 0.21773, 0.062909]
Predicted label: 1
Correct prediction
Energy consumption = 146.427925 pJ
sum error= 240
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 459 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 459 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 459 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0040409, 0.0089746, 0.057085, 0.025579, 0.79868, 0.0010828, 0.083894, 0.056702, 0.006772, 0.040959]
Predicted label: 4
Correct prediction
Energy consumption = 176.222011 pJ
sum error= 240
Actual label: 6
Output voltages: [0.082286, 0.0025669, 0.20718, 0.001069, 0.60657, 0.051487, 0.79879, 0.0010702, 0.56653, 0.004695]
Predicted label: 6
Correct prediction
Energy consumption = 143.656911 pJ
sum error= 240
Actual label: 9
Output voltages: [0.62294, 0.0038245, 0.010683, 0.28404, 0.68077, 0.028323, 0.0087765, 0.022633, 0.036779, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 145.208972 pJ
sum error= 240
Actual label: 7
Output voltages: [0.24758, 0.11077, 0.034724, 0.50938, 0.001555, 0.0035892, 0.0011466, 0.79878, 0.019192, 0.60495]
Predicted label: 7
Correct prediction
Energy consumption = 150.871124 pJ
sum error= 240
Actual label: 2
Output voltages: [0.74116, 0.46629, 0.79869, 0.05185, 0.0028311, 0.0013763, 0.077867, 0.14209, 0.20031, 0.10033]
Predicted label: 2
Correct prediction
Energy consumption = 143.646200 pJ
sum error= 240
Actual label: 1
Output voltages: [0.010093, 0.79854, 0.03989, 0.080673, 0.027327, 0.0023061, 0.27508, 0.0031088, 0.30714, 0.046922]
Predicted label: 1
Correct prediction
Energy consumption = 153.572639 pJ
sum error= 240
Actual label: 5
Output voltages: [0.20326, 0.0011182, 0.0074703, 0.15329, 0.048174, 0.79879, 0.019238, 0.033914, 0.77622, 0.10588]
Predicted label: 5
Correct prediction
Energy consumption = 146.531946 pJ
sum error= 240
Actual label: 1
Output voltages: [0.035671, 0.79848, 0.28908, 0.033306, 0.14716, 0.0051211, 0.40756, 0.0084967, 0.053114, 0.029381]
Predicted label: 1
Correct prediction
Energy consumption = 166.994383 pJ
sum error= 240
Actual label: 4
Output voltages: [0.034243, 0.0053, 0.35254, 0.024131, 0.79876, 0.0015287, 0.087251, 0.091054, 0.0052497, 0.52514]
Predicted label: 4
Correct prediction
Energy consumption = 158.831947 pJ
sum error= 240
Actual label: 6
Output voltages: [0.63394, 0.037853, 0.030483, 0.0096867, 0.50194, 0.7065, 0.79879, 0.0043474, 0.52913, 0.0011499]
Predicted label: 6
Correct prediction
Energy consumption = 151.205280 pJ
sum error= 240
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 460 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 460 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 460 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.26946, 0.031638, 0.044978, 0.79853, 0.016806, 0.023512, 0.014208, 0.032379, 0.56661, 0.036113]
Predicted label: 3
Correct prediction
Energy consumption = 164.202392 pJ
sum error= 240
Actual label: 8
Output voltages: [0.0031728, 0.038253, 0.054812, 0.61506, 0.43136, 0.0034332, 0.028962, 0.20072, 0.79599, 0.022485]
Predicted label: 8
Correct prediction
Energy consumption = 142.767504 pJ
sum error= 240
Actual label: 1
Output voltages: [0.022044, 0.79871, 0.39556, 0.031706, 0.11554, 0.0010717, 0.62156, 0.013277, 0.15047, 0.01241]
Predicted label: 1
Correct prediction
Energy consumption = 159.851107 pJ
sum error= 240
Actual label: 1
Output voltages: [0.039201, 0.79843, 0.095304, 0.41242, 0.057393, 0.033657, 0.18649, 0.34908, 0.014596, 0.029418]
Predicted label: 1
Correct prediction
Energy consumption = 160.019891 pJ
sum error= 240
Actual label: 0
Output voltages: [0.79667, 0.026403, 0.035708, 0.0080912, 0.0082865, 0.009216, 0.76694, 0.043363, 0.089736, 0.035312]
Predicted label: 0
Correct prediction
Energy consumption = 150.785138 pJ
sum error= 240
Actual label: 3
Output voltages: [0.32804, 0.036384, 0.030974, 0.79865, 0.011094, 0.012225, 0.0080575, 0.014769, 0.47013, 0.18737]
Predicted label: 3
Correct prediction
Energy consumption = 148.191388 pJ
sum error= 240
Actual label: 1
Output voltages: [0.060093, 0.79877, 0.042958, 0.033418, 0.045795, 0.0010783, 0.65546, 0.0043817, 0.18742, 0.035059]
Predicted label: 1
Correct prediction
Energy consumption = 156.850999 pJ
sum error= 240
Actual label: 6
Output voltages: [0.16439, 0.042101, 0.024299, 0.017676, 0.33479, 0.13316, 0.79879, 0.015706, 0.76156, 0.0016651]
Predicted label: 6
Correct prediction
Energy consumption = 150.286033 pJ
sum error= 240
Actual label: 8
Output voltages: [0.3948, 0.0074864, 0.24875, 0.3623, 0.017062, 0.0017707, 0.042707, 0.0010911, 0.79818, 0.0352]
Predicted label: 8
Correct prediction
Energy consumption = 146.584830 pJ
sum error= 240
Actual label: 4
Output voltages: [0.0018005, 0.010226, 0.079992, 0.0072512, 0.79874, 0.0011134, 0.052913, 0.044026, 0.024868, 0.028117]
Predicted label: 4
Correct prediction
Energy consumption = 146.893442 pJ
sum error= 240
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 461 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 461 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 461 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.066128, 0.0033623, 0.017092, 0.03584, 0.33429, 0.0073127, 0.0050363, 0.11526, 0.21731, 0.79781]
Predicted label: 9
Correct prediction
Energy consumption = 171.840561 pJ
sum error= 240
Actual label: 0
Output voltages: [0.79877, 0.13304, 0.028577, 0.013751, 0.019339, 0.01349, 0.58173, 0.010771, 0.088361, 0.053527]
Predicted label: 0
Correct prediction
Energy consumption = 149.087649 pJ
sum error= 240
Actual label: 7
Output voltages: [0.14362, 0.035144, 0.014682, 0.07462, 0.0085208, 0.0011039, 0.001066, 0.79879, 0.42399, 0.5323]
Predicted label: 7
Correct prediction
Energy consumption = 152.468831 pJ
sum error= 240
Actual label: 3
Output voltages: [0.38296, 0.0075948, 0.066107, 0.79871, 0.014315, 0.19953, 0.0034019, 0.026293, 0.70474, 0.060766]
Predicted label: 3
Correct prediction
Energy consumption = 143.988233 pJ
sum error= 240
Actual label: 0
Output voltages: [0.79879, 0.0087298, 0.047701, 0.05822, 0.0014084, 0.049225, 0.33799, 0.042446, 0.039335, 0.036211]
Predicted label: 0
Correct prediction
Energy consumption = 140.639441 pJ
sum error= 240
Actual label: 2
Output voltages: [0.69589, 0.034442, 0.74513, 0.09562, 0.77049, 0.0011245, 0.16684, 0.024815, 0.21562, 0.057114]
Predicted label: 4
Wrong prediction!
Energy consumption = 141.673997 pJ
sum error= 241
Actual label: 9
Output voltages: [0.18373, 0.02666, 0.02257, 0.54155, 0.073907, 0.42679, 0.097178, 0.12246, 0.48959, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 156.660481 pJ
sum error= 241
Actual label: 0
Output voltages: [0.79868, 0.029214, 0.028486, 0.14495, 0.0023633, 0.13663, 0.55293, 0.054413, 0.36144, 0.025929]
Predicted label: 0
Correct prediction
Energy consumption = 140.616525 pJ
sum error= 241
Actual label: 6
Output voltages: [0.036736, 0.11878, 0.32165, 0.001083, 0.28597, 0.041842, 0.79876, 0.0011628, 0.39232, 0.004141]
Predicted label: 6
Correct prediction
Energy consumption = 139.775197 pJ
sum error= 241
Actual label: 6
Output voltages: [0.12309, 0.029628, 0.013717, 0.18433, 0.087204, 0.31712, 0.78858, 0.0026964, 0.79464, 0.016478]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.720213 pJ
sum error= 242
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 462 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 462 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 462 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.17288, 0.0088358, 0.19122, 0.0011201, 0.31694, 0.029782, 0.79855, 0.0031885, 0.69875, 0.0011601]
Predicted label: 6
Correct prediction
Energy consumption = 155.998500 pJ
sum error= 242
Actual label: 3
Output voltages: [0.14208, 0.0068423, 0.31463, 0.79876, 0.081897, 0.25732, 0.023149, 0.0061506, 0.40011, 0.012396]
Predicted label: 3
Correct prediction
Energy consumption = 147.031774 pJ
sum error= 242
Actual label: 6
Output voltages: [0.36424, 0.012687, 0.0048679, 0.02308, 0.19883, 0.50447, 0.79879, 0.0010679, 0.25815, 0.037773]
Predicted label: 6
Correct prediction
Energy consumption = 146.720667 pJ
sum error= 242
Actual label: 7
Output voltages: [0.27866, 0.025011, 0.014665, 0.078009, 0.0087679, 0.025631, 0.001111, 0.79861, 0.12431, 0.37458]
Predicted label: 7
Correct prediction
Energy consumption = 155.503712 pJ
sum error= 242
Actual label: 7
Output voltages: [0.050131, 0.063288, 0.26829, 0.070474, 0.005033, 0.0010932, 0.0016551, 0.79868, 0.032354, 0.47574]
Predicted label: 7
Correct prediction
Energy consumption = 146.624775 pJ
sum error= 242
Actual label: 2
Output voltages: [0.027597, 0.047148, 0.79864, 0.34424, 0.0087444, 0.0013463, 0.09498, 0.11967, 0.53978, 0.01241]
Predicted label: 2
Correct prediction
Energy consumption = 142.473379 pJ
sum error= 242
Actual label: 8
Output voltages: [0.017186, 0.029688, 0.36903, 0.031124, 0.055884, 0.0138, 0.015265, 0.0075285, 0.79879, 0.027147]
Predicted label: 8
Correct prediction
Energy consumption = 144.721654 pJ
sum error= 242
Actual label: 6
Output voltages: [0.025701, 0.04302, 0.52032, 0.0010906, 0.61849, 0.034705, 0.79878, 0.0011119, 0.19539, 0.0059287]
Predicted label: 6
Correct prediction
Energy consumption = 144.091531 pJ
sum error= 242
Actual label: 0
Output voltages: [0.79879, 0.2274, 0.017817, 0.0025554, 0.025727, 0.034441, 0.54303, 0.0090519, 0.11121, 0.050834]
Predicted label: 0
Correct prediction
Energy consumption = 148.653952 pJ
sum error= 242
Actual label: 8
Output voltages: [0.0085254, 0.023815, 0.26569, 0.016595, 0.014494, 0.0040281, 0.027186, 0.014026, 0.79875, 0.40455]
Predicted label: 8
Correct prediction
Energy consumption = 145.557864 pJ
sum error= 242
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 463 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 463 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 463 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.30796, 0.021896, 0.03364, 0.79868, 0.0094121, 0.019857, 0.03216, 0.0030088, 0.48858, 0.13209]
Predicted label: 3
Correct prediction
Energy consumption = 166.701267 pJ
sum error= 242
Actual label: 0
Output voltages: [0.79876, 0.026244, 0.016256, 0.012617, 0.029026, 0.0041576, 0.59996, 0.0080275, 0.048228, 0.054882]
Predicted label: 0
Correct prediction
Energy consumption = 159.120323 pJ
sum error= 242
Actual label: 2
Output voltages: [0.42788, 0.0034001, 0.7987, 0.056229, 0.040708, 0.0010677, 0.035749, 0.16241, 0.59505, 0.0031982]
Predicted label: 2
Correct prediction
Energy consumption = 148.361868 pJ
sum error= 242
Actual label: 9
Output voltages: [0.51312, 0.0037643, 0.035966, 0.063736, 0.07523, 0.0071451, 0.0054928, 0.52625, 0.20976, 0.79536]
Predicted label: 9
Correct prediction
Energy consumption = 156.924693 pJ
sum error= 242
Actual label: 8
Output voltages: [0.0090709, 0.01717, 0.043922, 0.32027, 0.0090577, 0.22183, 0.006739, 0.0026828, 0.79879, 0.25248]
Predicted label: 8
Correct prediction
Energy consumption = 153.852748 pJ
sum error= 242
Actual label: 3
Output voltages: [0.54765, 0.012339, 0.019746, 0.79859, 0.0048446, 0.25625, 0.045753, 0.061481, 0.34741, 0.0037038]
Predicted label: 3
Correct prediction
Energy consumption = 148.768153 pJ
sum error= 242
Actual label: 2
Output voltages: [0.082054, 0.30204, 0.79865, 0.057764, 0.024652, 0.0011784, 0.18644, 0.034791, 0.15329, 0.30706]
Predicted label: 2
Correct prediction
Energy consumption = 141.313906 pJ
sum error= 242
Actual label: 5
Output voltages: [0.12642, 0.0010661, 0.016746, 0.053164, 0.0070352, 0.79634, 0.095428, 0.020593, 0.77331, 0.044342]
Predicted label: 5
Correct prediction
Energy consumption = 147.029003 pJ
sum error= 242
Actual label: 3
Output voltages: [0.2724, 0.0031117, 0.020219, 0.79827, 0.020068, 0.60595, 0.016924, 0.086736, 0.56653, 0.0018018]
Predicted label: 3
Correct prediction
Energy consumption = 140.110104 pJ
sum error= 242
Actual label: 8
Output voltages: [0.16974, 0.0014155, 0.0065434, 0.0089649, 0.23452, 0.028963, 0.0044252, 0.059923, 0.69865, 0.78696]
Predicted label: 9
Wrong prediction!
Energy consumption = 155.112666 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 464 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 464 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 464 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.019494, 0.044823, 0.050029, 0.54761, 0.0020684, 0.0079825, 0.031654, 0.016829, 0.79878, 0.079806]
Predicted label: 8
Correct prediction
Energy consumption = 169.640778 pJ
sum error= 243
Actual label: 0
Output voltages: [0.79863, 0.13596, 0.0057433, 0.019857, 0.020197, 0.032618, 0.215, 0.0090789, 0.25529, 0.036997]
Predicted label: 0
Correct prediction
Energy consumption = 157.430098 pJ
sum error= 243
Actual label: 0
Output voltages: [0.79876, 0.038655, 0.014817, 0.012576, 0.046736, 0.015637, 0.73767, 0.0245, 0.13427, 0.17166]
Predicted label: 0
Correct prediction
Energy consumption = 149.909162 pJ
sum error= 243
Actual label: 1
Output voltages: [0.017181, 0.79879, 0.0048456, 0.29847, 0.16667, 0.0011516, 0.0087737, 0.017249, 0.52455, 0.33505]
Predicted label: 1
Correct prediction
Energy consumption = 159.342653 pJ
sum error= 243
Actual label: 9
Output voltages: [0.061125, 0.018827, 0.01987, 0.029184, 0.16579, 0.017501, 0.0025905, 0.0049867, 0.54289, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.300760 pJ
sum error= 243
Actual label: 5
Output voltages: [0.030684, 0.0011642, 0.004343, 0.018804, 0.028189, 0.79469, 0.24996, 0.0047732, 0.7893, 0.026149]
Predicted label: 5
Correct prediction
Energy consumption = 146.276570 pJ
sum error= 243
Actual label: 1
Output voltages: [0.022848, 0.7984, 0.0014099, 0.23879, 0.026651, 0.0029703, 0.20846, 0.014677, 0.18983, 0.28018]
Predicted label: 1
Correct prediction
Energy consumption = 164.394543 pJ
sum error= 243
Actual label: 3
Output voltages: [0.14244, 0.038603, 0.14832, 0.79857, 0.056701, 0.023329, 0.013495, 0.36446, 0.42753, 0.053538]
Predicted label: 3
Correct prediction
Energy consumption = 152.389421 pJ
sum error= 243
Actual label: 9
Output voltages: [0.25886, 0.017416, 0.032829, 0.043799, 0.053771, 0.019709, 0.0028908, 0.1855, 0.48183, 0.79597]
Predicted label: 9
Correct prediction
Energy consumption = 151.038346 pJ
sum error= 243
Actual label: 6
Output voltages: [0.024899, 0.29229, 0.075193, 0.0083379, 0.090129, 0.18083, 0.79867, 0.0095085, 0.69407, 0.0085911]
Predicted label: 6
Correct prediction
Energy consumption = 150.794122 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 465 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 465 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 465 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79875, 0.046546, 0.090019, 0.017332, 0.0016501, 0.020534, 0.66373, 0.015466, 0.41124, 0.016615]
Predicted label: 0
Correct prediction
Energy consumption = 160.436465 pJ
sum error= 243
Actual label: 1
Output voltages: [0.016338, 0.79836, 0.20266, 0.053374, 0.028649, 0.014722, 0.65627, 0.021656, 0.1882, 0.07309]
Predicted label: 1
Correct prediction
Energy consumption = 164.879975 pJ
sum error= 243
Actual label: 4
Output voltages: [0.010908, 0.0056241, 0.21467, 0.001831, 0.79843, 0.011802, 0.081306, 0.18313, 0.047071, 0.23516]
Predicted label: 4
Correct prediction
Energy consumption = 151.241347 pJ
sum error= 243
Actual label: 1
Output voltages: [0.010658, 0.79866, 0.035537, 0.0043425, 0.021555, 0.025796, 0.59995, 0.067093, 0.67214, 0.004349]
Predicted label: 1
Correct prediction
Energy consumption = 165.861662 pJ
sum error= 243
Actual label: 7
Output voltages: [0.039023, 0.0086376, 0.28196, 0.043407, 0.40863, 0.0010861, 0.0035025, 0.79872, 0.032988, 0.063055]
Predicted label: 7
Correct prediction
Energy consumption = 142.036476 pJ
sum error= 243
Actual label: 1
Output voltages: [0.035798, 0.79862, 0.0024747, 0.40439, 0.38709, 0.10023, 0.31364, 0.0031084, 0.031557, 0.43765]
Predicted label: 1
Correct prediction
Energy consumption = 165.189167 pJ
sum error= 243
Actual label: 2
Output voltages: [0.080157, 0.0045089, 0.79877, 0.1198, 0.020627, 0.0011433, 0.014807, 0.54297, 0.33629, 0.012915]
Predicted label: 2
Correct prediction
Energy consumption = 140.407290 pJ
sum error= 243
Actual label: 3
Output voltages: [0.023958, 0.21618, 0.15833, 0.79868, 0.0026089, 0.001093, 0.0032786, 0.012967, 0.39083, 0.02805]
Predicted label: 3
Correct prediction
Energy consumption = 141.735817 pJ
sum error= 243
Actual label: 7
Output voltages: [0.014749, 0.012723, 0.76816, 0.046258, 0.015264, 0.0011223, 0.0017447, 0.79837, 0.45841, 0.23501]
Predicted label: 7
Correct prediction
Energy consumption = 145.507475 pJ
sum error= 243
Actual label: 9
Output voltages: [0.23953, 0.0025251, 0.11395, 0.12401, 0.20066, 0.0066381, 0.011348, 0.029073, 0.046879, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 148.179442 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 466 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 466 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 466 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.066044, 0.012257, 0.36025, 0.35811, 0.18337, 0.0010684, 0.0010777, 0.79876, 0.20209, 0.24312]
Predicted label: 7
Correct prediction
Energy consumption = 170.889173 pJ
sum error= 243
Actual label: 4
Output voltages: [0.010662, 0.010973, 0.55182, 0.014779, 0.79867, 0.0012452, 0.14405, 0.21717, 0.016436, 0.16935]
Predicted label: 4
Correct prediction
Energy consumption = 153.516710 pJ
sum error= 243
Actual label: 9
Output voltages: [0.29243, 0.0029169, 0.014538, 0.22987, 0.020272, 0.022537, 0.0010679, 0.75171, 0.6827, 0.78002]
Predicted label: 9
Correct prediction
Energy consumption = 145.852897 pJ
sum error= 243
Actual label: 9
Output voltages: [0.55696, 0.012188, 0.0035704, 0.38936, 0.59679, 0.053089, 0.018437, 0.0068267, 0.17961, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 151.732391 pJ
sum error= 243
Actual label: 3
Output voltages: [0.35303, 0.0081409, 0.051029, 0.79873, 0.057475, 0.52739, 0.056256, 0.020982, 0.4231, 0.032085]
Predicted label: 3
Correct prediction
Energy consumption = 151.915780 pJ
sum error= 243
Actual label: 9
Output voltages: [0.015407, 0.052568, 0.40786, 0.25268, 0.26184, 0.0060933, 0.0012877, 0.00253, 0.073377, 0.78987]
Predicted label: 9
Correct prediction
Energy consumption = 151.798103 pJ
sum error= 243
Actual label: 2
Output voltages: [0.27824, 0.1343, 0.79877, 0.054031, 0.0068577, 0.0013123, 0.14323, 0.0056865, 0.48171, 0.037301]
Predicted label: 2
Correct prediction
Energy consumption = 144.239824 pJ
sum error= 243
Actual label: 8
Output voltages: [0.038178, 0.03038, 0.14118, 0.23108, 0.0064491, 0.015671, 0.012013, 0.0018207, 0.79867, 0.14816]
Predicted label: 8
Correct prediction
Energy consumption = 140.704065 pJ
sum error= 243
Actual label: 2
Output voltages: [0.069296, 0.033101, 0.77912, 0.51282, 0.078916, 0.0011433, 0.026064, 0.039412, 0.52056, 0.0065765]
Predicted label: 2
Correct prediction
Energy consumption = 148.248688 pJ
sum error= 243
Actual label: 7
Output voltages: [0.081956, 0.033642, 0.059329, 0.081097, 0.015604, 0.015452, 0.001066, 0.79862, 0.32884, 0.60318]
Predicted label: 7
Correct prediction
Energy consumption = 153.656520 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 467 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 467 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 467 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.080063, 0.79871, 0.45519, 0.11106, 0.28761, 0.0010661, 0.53273, 0.0069075, 0.11307, 0.029722]
Predicted label: 1
Correct prediction
Energy consumption = 180.313986 pJ
sum error= 243
Actual label: 8
Output voltages: [0.4043, 0.0068005, 0.036233, 0.73877, 0.0040744, 0.29477, 0.038133, 0.003073, 0.79879, 0.29884]
Predicted label: 8
Correct prediction
Energy consumption = 154.383889 pJ
sum error= 243
Actual label: 0
Output voltages: [0.79876, 0.049981, 0.0093477, 0.026692, 0.021463, 0.025653, 0.5206, 0.025693, 0.20371, 0.10691]
Predicted label: 0
Correct prediction
Energy consumption = 155.788128 pJ
sum error= 243
Actual label: 9
Output voltages: [0.28617, 0.035572, 0.0054357, 0.035722, 0.36419, 0.15541, 0.041366, 0.0025808, 0.2254, 0.79805]
Predicted label: 9
Correct prediction
Energy consumption = 146.513247 pJ
sum error= 243
Actual label: 1
Output voltages: [0.018487, 0.79879, 0.10082, 0.011678, 0.045236, 0.0054108, 0.78449, 0.0028358, 0.47925, 0.021133]
Predicted label: 1
Correct prediction
Energy consumption = 154.961878 pJ
sum error= 243
Actual label: 0
Output voltages: [0.79879, 0.26656, 0.015654, 0.048247, 0.011112, 0.032009, 0.64286, 0.12375, 0.1678, 0.20897]
Predicted label: 0
Correct prediction
Energy consumption = 161.458339 pJ
sum error= 243
Actual label: 1
Output voltages: [0.01442, 0.79845, 0.038094, 0.071196, 0.0044988, 0.0034978, 0.75928, 0.012377, 0.45186, 0.034151]
Predicted label: 1
Correct prediction
Energy consumption = 163.172106 pJ
sum error= 243
Actual label: 7
Output voltages: [0.026259, 0.40513, 0.55359, 0.018849, 0.014425, 0.0011214, 0.0010929, 0.79874, 0.20074, 0.035071]
Predicted label: 7
Correct prediction
Energy consumption = 156.514011 pJ
sum error= 243
Actual label: 7
Output voltages: [0.2231, 0.032252, 0.022831, 0.65376, 0.0033112, 0.0024778, 0.0011276, 0.79871, 0.25594, 0.64489]
Predicted label: 7
Correct prediction
Energy consumption = 150.311662 pJ
sum error= 243
Actual label: 9
Output voltages: [0.39894, 0.0089942, 0.0020906, 0.35316, 0.11412, 0.38182, 0.0087271, 0.20924, 0.36974, 0.79552]
Predicted label: 9
Correct prediction
Energy consumption = 135.558580 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 468 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 468 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 468 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.036574, 0.10869, 0.21183, 0.0059692, 0.38996, 0.39576, 0.79867, 0.0060559, 0.32838, 0.018078]
Predicted label: 6
Correct prediction
Energy consumption = 156.759555 pJ
sum error= 243
Actual label: 9
Output voltages: [0.50971, 0.0011687, 0.40105, 0.010054, 0.18441, 0.0035798, 0.044607, 0.013568, 0.058566, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 153.442744 pJ
sum error= 243
Actual label: 9
Output voltages: [0.33856, 0.010394, 0.016663, 0.034687, 0.13029, 0.014671, 0.0030121, 0.11757, 0.38314, 0.79821]
Predicted label: 9
Correct prediction
Energy consumption = 150.540503 pJ
sum error= 243
Actual label: 9
Output voltages: [0.19963, 0.0038984, 0.057034, 0.011422, 0.1463, 0.0016443, 0.0052304, 0.049635, 0.53941, 0.79847]
Predicted label: 9
Correct prediction
Energy consumption = 143.466409 pJ
sum error= 243
Actual label: 2
Output voltages: [0.095823, 0.027857, 0.79869, 0.049478, 0.0020219, 0.001066, 0.040391, 0.4305, 0.67975, 0.0077286]
Predicted label: 2
Correct prediction
Energy consumption = 149.655818 pJ
sum error= 243
Actual label: 1
Output voltages: [0.0011082, 0.7987, 0.51311, 0.54809, 0.30482, 0.0031648, 0.042598, 0.043309, 0.058109, 0.25594]
Predicted label: 1
Correct prediction
Energy consumption = 165.028441 pJ
sum error= 243
Actual label: 6
Output voltages: [0.44101, 0.30998, 0.20975, 0.0012497, 0.011495, 0.014075, 0.79736, 0.0010689, 0.2052, 0.03275]
Predicted label: 6
Correct prediction
Energy consumption = 153.931026 pJ
sum error= 243
Actual label: 1
Output voltages: [0.033249, 0.79876, 0.38077, 0.37631, 0.039501, 0.001073, 0.69853, 0.015254, 0.027498, 0.037357]
Predicted label: 1
Correct prediction
Energy consumption = 164.774579 pJ
sum error= 243
Actual label: 3
Output voltages: [0.075528, 0.0062642, 0.042609, 0.79873, 0.046368, 0.013869, 0.032263, 0.021158, 0.76869, 0.058941]
Predicted label: 3
Correct prediction
Energy consumption = 145.144267 pJ
sum error= 243
Actual label: 5
Output voltages: [0.022438, 0.001338, 0.0064085, 0.22944, 0.17222, 0.79878, 0.51472, 0.007297, 0.75419, 0.016869]
Predicted label: 5
Correct prediction
Energy consumption = 138.424571 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 469 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 469 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 469 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.56303, 0.001624, 0.73431, 0.61696, 0.016277, 0.0015468, 0.0050515, 0.73299, 0.070688, 0.30972]
Predicted label: 2
Wrong prediction!
Energy consumption = 171.273228 pJ
sum error= 244
Actual label: 1
Output voltages: [0.047915, 0.79871, 0.30877, 0.031661, 0.012284, 0.0011021, 0.65639, 0.001067, 0.10618, 0.027207]
Predicted label: 1
Correct prediction
Energy consumption = 166.356063 pJ
sum error= 244
Actual label: 9
Output voltages: [0.77475, 0.01878, 0.009655, 0.22886, 0.32962, 0.12347, 0.01021, 0.0036533, 0.098842, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 159.109104 pJ
sum error= 244
Actual label: 7
Output voltages: [0.3359, 0.014335, 0.014384, 0.05225, 0.086765, 0.2878, 0.0010718, 0.79877, 0.032953, 0.75216]
Predicted label: 7
Correct prediction
Energy consumption = 148.903342 pJ
sum error= 244
Actual label: 6
Output voltages: [0.026891, 0.1333, 0.37474, 0.0010789, 0.2431, 0.13487, 0.79872, 0.0013832, 0.27501, 0.0028919]
Predicted label: 6
Correct prediction
Energy consumption = 153.318640 pJ
sum error= 244
Actual label: 4
Output voltages: [0.0022063, 0.015597, 0.14484, 0.018669, 0.79879, 0.001724, 0.016254, 0.023225, 0.28483, 0.0094017]
Predicted label: 4
Correct prediction
Energy consumption = 155.598400 pJ
sum error= 244
Actual label: 5
Output voltages: [0.024988, 0.008279, 0.0044331, 0.64433, 0.0082287, 0.79866, 0.029866, 0.048938, 0.74797, 0.038275]
Predicted label: 5
Correct prediction
Energy consumption = 145.667441 pJ
sum error= 244
Actual label: 7
Output voltages: [0.61084, 0.0083269, 0.28828, 0.03844, 0.024872, 0.0011531, 0.0011224, 0.79874, 0.23445, 0.038009]
Predicted label: 7
Correct prediction
Energy consumption = 154.898443 pJ
sum error= 244
Actual label: 6
Output voltages: [0.2691, 0.039231, 0.3448, 0.0020367, 0.16152, 0.31276, 0.79876, 0.0043681, 0.31511, 0.0092931]
Predicted label: 6
Correct prediction
Energy consumption = 149.008144 pJ
sum error= 244
Actual label: 6
Output voltages: [0.10427, 0.50238, 0.049287, 0.021962, 0.011976, 0.2779, 0.79879, 0.020957, 0.65188, 0.0025576]
Predicted label: 6
Correct prediction
Energy consumption = 145.536012 pJ
sum error= 244
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 470 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 470 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 470 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.22818, 0.040962, 0.022301, 0.04702, 0.21494, 0.019243, 0.004071, 0.020087, 0.086863, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 173.951203 pJ
sum error= 244
Actual label: 9
Output voltages: [0.27772, 0.0019338, 0.0049621, 0.043101, 0.041374, 0.027672, 0.0011472, 0.050617, 0.63551, 0.79804]
Predicted label: 9
Correct prediction
Energy consumption = 148.769143 pJ
sum error= 244
Actual label: 6
Output voltages: [0.028463, 0.010868, 0.13375, 0.024898, 0.020762, 0.705, 0.79428, 0.001073, 0.6077, 0.0066596]
Predicted label: 6
Correct prediction
Energy consumption = 151.898009 pJ
sum error= 244
Actual label: 3
Output voltages: [0.30582, 0.019932, 0.018406, 0.79878, 0.0064776, 0.050739, 0.048032, 0.049614, 0.46496, 0.001167]
Predicted label: 3
Correct prediction
Energy consumption = 144.929522 pJ
sum error= 244
Actual label: 6
Output voltages: [0.030674, 0.044853, 0.015311, 0.020501, 0.19618, 0.422, 0.79879, 0.0099379, 0.62731, 0.0054601]
Predicted label: 6
Correct prediction
Energy consumption = 144.718715 pJ
sum error= 244
Actual label: 2
Output voltages: [0.43567, 0.19048, 0.79872, 0.10011, 0.041726, 0.0012187, 0.39611, 0.0091719, 0.403, 0.14027]
Predicted label: 2
Correct prediction
Energy consumption = 150.962789 pJ
sum error= 244
Actual label: 9
Output voltages: [0.040507, 0.0058602, 0.051687, 0.023025, 0.757, 0.0026026, 0.006157, 0.025479, 0.048111, 0.79702]
Predicted label: 9
Correct prediction
Energy consumption = 147.322936 pJ
sum error= 244
Actual label: 8
Output voltages: [0.010923, 0.031637, 0.28965, 0.044631, 0.016665, 0.025221, 0.022459, 0.014922, 0.79877, 0.34768]
Predicted label: 8
Correct prediction
Energy consumption = 150.795179 pJ
sum error= 244
Actual label: 1
Output voltages: [0.0058721, 0.79848, 0.043683, 0.20049, 0.032283, 0.0017598, 0.75726, 0.015707, 0.085504, 0.051229]
Predicted label: 1
Correct prediction
Energy consumption = 166.757896 pJ
sum error= 244
Actual label: 2
Output voltages: [0.47276, 0.006116, 0.79879, 0.024545, 0.02974, 0.001077, 0.22918, 0.077556, 0.77078, 0.0056991]
Predicted label: 2
Correct prediction
Energy consumption = 146.365362 pJ
sum error= 244
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 471 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 471 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 471 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.18342, 0.32326, 0.79877, 0.36174, 0.0013465, 0.0012655, 0.21983, 0.01262, 0.63016, 0.018963]
Predicted label: 2
Correct prediction
Energy consumption = 166.058528 pJ
sum error= 244
Actual label: 5
Output voltages: [0.055957, 0.0015318, 0.046392, 0.033602, 0.0012765, 0.75935, 0.016179, 0.0010659, 0.7951, 0.133]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.841279 pJ
sum error= 245
Actual label: 5
Output voltages: [0.030443, 0.0011652, 0.0021514, 0.0397, 0.059028, 0.79303, 0.031377, 0.14693, 0.72668, 0.2179]
Predicted label: 5
Correct prediction
Energy consumption = 143.390851 pJ
sum error= 245
Actual label: 2
Output voltages: [0.11474, 0.0012482, 0.79513, 0.49062, 0.0027749, 0.0027175, 0.41239, 0.026506, 0.74439, 0.0011312]
Predicted label: 2
Correct prediction
Energy consumption = 138.943248 pJ
sum error= 245
Actual label: 3
Output voltages: [0.69892, 0.020686, 0.031161, 0.79864, 0.0025693, 0.04665, 0.0099303, 0.044131, 0.41954, 0.018748]
Predicted label: 3
Correct prediction
Energy consumption = 144.363715 pJ
sum error= 245
Actual label: 7
Output voltages: [0.12466, 0.02411, 0.022679, 0.32203, 0.011913, 0.010379, 0.0010668, 0.79859, 0.099838, 0.41978]
Predicted label: 7
Correct prediction
Energy consumption = 151.956356 pJ
sum error= 245
Actual label: 2
Output voltages: [0.043107, 0.041903, 0.79872, 0.22524, 0.029113, 0.0011739, 0.17664, 0.0276, 0.59698, 0.02753]
Predicted label: 2
Correct prediction
Energy consumption = 151.718348 pJ
sum error= 245
Actual label: 1
Output voltages: [0.0106, 0.79855, 0.033669, 0.014209, 0.040224, 0.00523, 0.71641, 0.013497, 0.23225, 0.016938]
Predicted label: 1
Correct prediction
Energy consumption = 157.901731 pJ
sum error= 245
Actual label: 0
Output voltages: [0.79878, 0.061812, 0.039936, 0.0095723, 0.007686, 0.0082485, 0.39493, 0.016627, 0.2426, 0.018683]
Predicted label: 0
Correct prediction
Energy consumption = 154.894380 pJ
sum error= 245
Actual label: 1
Output voltages: [0.016667, 0.7984, 0.0055709, 0.15343, 0.035925, 0.0022778, 0.46953, 0.030316, 0.16422, 0.27323]
Predicted label: 1
Correct prediction
Energy consumption = 161.275646 pJ
sum error= 245
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 472 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 472 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 472 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.034621, 0.41522, 0.033041, 0.022691, 0.0012608, 0.33702, 0.042518, 0.19715, 0.30891]
Predicted label: 0
Correct prediction
Energy consumption = 178.010833 pJ
sum error= 245
Actual label: 4
Output voltages: [0.0043063, 0.0095934, 0.16035, 0.021226, 0.79875, 0.012444, 0.21546, 0.011382, 0.013487, 0.51124]
Predicted label: 4
Correct prediction
Energy consumption = 149.674310 pJ
sum error= 245
Actual label: 5
Output voltages: [0.41559, 0.0011241, 0.0030314, 0.31444, 0.0055728, 0.79874, 0.41817, 0.36364, 0.69936, 0.0095374]
Predicted label: 5
Correct prediction
Energy consumption = 138.081599 pJ
sum error= 245
Actual label: 2
Output voltages: [0.047625, 0.012417, 0.77828, 0.34883, 0.0042316, 0.0011807, 0.010683, 0.50578, 0.76447, 0.0078052]
Predicted label: 2
Correct prediction
Energy consumption = 145.426337 pJ
sum error= 245
Actual label: 8
Output voltages: [0.37834, 0.0035754, 0.049047, 0.22651, 0.017457, 0.032901, 0.29856, 0.0010896, 0.79853, 0.0031901]
Predicted label: 8
Correct prediction
Energy consumption = 153.406303 pJ
sum error= 245
Actual label: 2
Output voltages: [0.26702, 0.16294, 0.79878, 0.082413, 0.015842, 0.0012573, 0.045006, 0.40719, 0.38622, 0.055134]
Predicted label: 2
Correct prediction
Energy consumption = 152.532803 pJ
sum error= 245
Actual label: 8
Output voltages: [0.0029678, 0.34303, 0.17557, 0.18561, 0.015977, 0.010512, 0.079144, 0.064258, 0.79868, 0.30051]
Predicted label: 8
Correct prediction
Energy consumption = 154.469184 pJ
sum error= 245
Actual label: 3
Output voltages: [0.15048, 0.028358, 0.10421, 0.79867, 0.053293, 0.0013835, 0.0091391, 0.043741, 0.54823, 0.044755]
Predicted label: 3
Correct prediction
Energy consumption = 145.290899 pJ
sum error= 245
Actual label: 5
Output voltages: [0.22156, 0.0012288, 0.0011965, 0.63553, 0.13578, 0.79879, 0.27517, 0.0031713, 0.65792, 0.015229]
Predicted label: 5
Correct prediction
Energy consumption = 138.334924 pJ
sum error= 245
Actual label: 1
Output voltages: [0.033141, 0.79878, 0.03235, 0.22222, 0.031163, 0.0012397, 0.040444, 0.0010672, 0.32066, 0.04938]
Predicted label: 1
Correct prediction
Energy consumption = 159.549079 pJ
sum error= 245
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 473 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 473 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 473 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.52083, 0.27093, 0.0079617, 0.11449, 0.0078015, 0.0089963, 0.0010891, 0.79868, 0.12212, 0.19464]
Predicted label: 7
Correct prediction
Energy consumption = 173.921059 pJ
sum error= 245
Actual label: 8
Output voltages: [0.09649, 0.34881, 0.67332, 0.06039, 0.0097381, 0.0011181, 0.017317, 0.17316, 0.79775, 0.020799]
Predicted label: 8
Correct prediction
Energy consumption = 151.008366 pJ
sum error= 245
Actual label: 1
Output voltages: [0.0027399, 0.79855, 0.0069906, 0.0522, 0.015137, 0.0056564, 0.5169, 0.01821, 0.16389, 0.020938]
Predicted label: 1
Correct prediction
Energy consumption = 156.835966 pJ
sum error= 245
Actual label: 1
Output voltages: [0.0070761, 0.79877, 0.0010712, 0.0065191, 0.44901, 0.02563, 0.61273, 0.012965, 0.030535, 0.011042]
Predicted label: 1
Correct prediction
Energy consumption = 146.232441 pJ
sum error= 245
Actual label: 2
Output voltages: [0.34901, 0.030201, 0.79875, 0.055242, 0.017904, 0.0012812, 0.36892, 0.035932, 0.64828, 0.029655]
Predicted label: 2
Correct prediction
Energy consumption = 148.999275 pJ
sum error= 245
Actual label: 9
Output voltages: [0.29892, 0.0033511, 0.035627, 0.077452, 0.10389, 0.010921, 0.0046629, 0.69773, 0.31899, 0.79765]
Predicted label: 9
Correct prediction
Energy consumption = 150.392655 pJ
sum error= 245
Actual label: 7
Output voltages: [0.032968, 0.043637, 0.74055, 0.023881, 0.028334, 0.0013767, 0.0024396, 0.79624, 0.42239, 0.018389]
Predicted label: 7
Correct prediction
Energy consumption = 145.856245 pJ
sum error= 245
Actual label: 8
Output voltages: [0.13966, 0.035885, 0.16398, 0.016616, 0.0046744, 0.064816, 0.74778, 0.0030261, 0.79601, 0.0082569]
Predicted label: 8
Correct prediction
Energy consumption = 146.311429 pJ
sum error= 245
Actual label: 4
Output voltages: [0.0060755, 0.12026, 0.010015, 0.043716, 0.79851, 0.0016978, 0.40088, 0.061989, 0.0083849, 0.020478]
Predicted label: 4
Correct prediction
Energy consumption = 153.015417 pJ
sum error= 245
Actual label: 0
Output voltages: [0.78752, 0.0010962, 0.25013, 0.0010687, 0.23368, 0.003041, 0.53958, 0.016639, 0.0067132, 0.27714]
Predicted label: 0
Correct prediction
Energy consumption = 140.108357 pJ
sum error= 245
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 474 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 474 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 474 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.051701, 0.013014, 0.0035307, 0.79687, 0.062554, 0.74007, 0.01922, 0.15934, 0.052945, 0.16731]
Predicted label: 3
Correct prediction
Energy consumption = 175.212901 pJ
sum error= 245
Actual label: 0
Output voltages: [0.79576, 0.037559, 0.01755, 0.0043236, 0.13892, 0.0087536, 0.77596, 0.012157, 0.16114, 0.022627]
Predicted label: 0
Correct prediction
Energy consumption = 156.905900 pJ
sum error= 245
Actual label: 7
Output voltages: [0.018006, 0.020075, 0.43836, 0.031589, 0.056809, 0.001162, 0.0012317, 0.79876, 0.038239, 0.056523]
Predicted label: 7
Correct prediction
Energy consumption = 152.672588 pJ
sum error= 245
Actual label: 8
Output voltages: [0.29651, 0.0042391, 0.17103, 0.66163, 0.0010677, 0.30549, 0.59852, 0.0011061, 0.78407, 0.079983]
Predicted label: 8
Correct prediction
Energy consumption = 148.537283 pJ
sum error= 245
Actual label: 8
Output voltages: [0.13292, 0.096564, 0.17852, 0.7573, 0.0072812, 0.01168, 0.062305, 0.0051732, 0.79879, 0.11409]
Predicted label: 8
Correct prediction
Energy consumption = 157.554101 pJ
sum error= 245
Actual label: 4
Output voltages: [0.0054919, 0.010622, 0.56269, 0.16345, 0.79876, 0.0018181, 0.14948, 0.16595, 0.021223, 0.372]
Predicted label: 4
Correct prediction
Energy consumption = 156.528092 pJ
sum error= 245
Actual label: 7
Output voltages: [0.413, 0.0063776, 0.0010795, 0.02641, 0.2592, 0.10139, 0.0010682, 0.79878, 0.32309, 0.54515]
Predicted label: 7
Correct prediction
Energy consumption = 154.764505 pJ
sum error= 245
Actual label: 7
Output voltages: [0.4612, 0.019769, 0.034962, 0.25034, 0.016369, 0.0048855, 0.0011099, 0.79874, 0.72506, 0.59085]
Predicted label: 7
Correct prediction
Energy consumption = 142.892100 pJ
sum error= 245
Actual label: 8
Output voltages: [0.025818, 0.008072, 0.041701, 0.12277, 0.014439, 0.027594, 0.017833, 0.01816, 0.79879, 0.3109]
Predicted label: 8
Correct prediction
Energy consumption = 141.441016 pJ
sum error= 245
Actual label: 5
Output voltages: [0.070689, 0.0010685, 0.0013778, 0.38412, 0.030961, 0.79865, 0.063194, 0.015566, 0.77197, 0.14459]
Predicted label: 5
Correct prediction
Energy consumption = 144.435188 pJ
sum error= 245
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 475 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 475 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 475 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.25501, 0.0018609, 0.57504, 0.2472, 0.023958, 0.010253, 0.03212, 0.01405, 0.79878, 0.23521]
Predicted label: 8
Correct prediction
Energy consumption = 170.321817 pJ
sum error= 245
Actual label: 4
Output voltages: [0.043603, 0.021498, 0.094134, 0.0056273, 0.79877, 0.0034523, 0.74419, 0.06683, 0.0065499, 0.029021]
Predicted label: 4
Correct prediction
Energy consumption = 158.322234 pJ
sum error= 245
Actual label: 9
Output voltages: [0.3875, 0.015138, 0.040535, 0.016761, 0.73139, 0.045546, 0.017891, 0.015436, 0.1731, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 156.156034 pJ
sum error= 245
Actual label: 8
Output voltages: [0.010496, 0.16038, 0.040575, 0.23029, 0.0018481, 0.007933, 0.0070274, 0.03529, 0.79876, 0.13404]
Predicted label: 8
Correct prediction
Energy consumption = 152.485182 pJ
sum error= 245
Actual label: 1
Output voltages: [0.03917, 0.79861, 0.10032, 0.026625, 0.039027, 0.0011091, 0.45581, 0.0017021, 0.039675, 0.038018]
Predicted label: 1
Correct prediction
Energy consumption = 165.265128 pJ
sum error= 245
Actual label: 3
Output voltages: [0.59381, 0.28563, 0.27658, 0.79875, 0.041425, 0.033518, 0.0078633, 0.13893, 0.2683, 0.0089313]
Predicted label: 3
Correct prediction
Energy consumption = 155.050755 pJ
sum error= 245
Actual label: 8
Output voltages: [0.021767, 0.046715, 0.45042, 0.068882, 0.0087527, 0.026575, 0.021604, 0.029024, 0.79875, 0.080898]
Predicted label: 8
Correct prediction
Energy consumption = 150.181719 pJ
sum error= 245
Actual label: 0
Output voltages: [0.79861, 0.05814, 0.10648, 0.0085491, 0.012435, 0.0013882, 0.68446, 0.015705, 0.075209, 0.38701]
Predicted label: 0
Correct prediction
Energy consumption = 152.782474 pJ
sum error= 245
Actual label: 3
Output voltages: [0.17927, 0.028804, 0.14273, 0.79866, 0.015448, 0.012182, 0.0033936, 0.031917, 0.78279, 0.013311]
Predicted label: 3
Correct prediction
Energy consumption = 148.113073 pJ
sum error= 245
Actual label: 1
Output voltages: [0.025097, 0.79871, 0.0042905, 0.051915, 0.72544, 0.0010786, 0.039354, 0.029137, 0.028625, 0.048963]
Predicted label: 1
Correct prediction
Energy consumption = 155.367132 pJ
sum error= 245
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 476 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 476 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 476 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.10723, 0.27398, 0.019984, 0.37972, 0.0094464, 0.0010939, 0.0011046, 0.79867, 0.043316, 0.76686]
Predicted label: 7
Correct prediction
Energy consumption = 178.211371 pJ
sum error= 245
Actual label: 9
Output voltages: [0.30389, 0.12307, 0.11399, 0.013411, 0.044373, 0.0011903, 0.0041413, 0.014646, 0.7931, 0.77013]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.381600 pJ
sum error= 246
Actual label: 5
Output voltages: [0.01203, 0.0010697, 0.03575, 0.44958, 0.033809, 0.79749, 0.033126, 0.013107, 0.77666, 0.093284]
Predicted label: 5
Correct prediction
Energy consumption = 147.804809 pJ
sum error= 246
Actual label: 5
Output voltages: [0.066813, 0.010735, 0.0012702, 0.055605, 0.0039555, 0.79735, 0.78006, 0.0019741, 0.60368, 0.0010858]
Predicted label: 5
Correct prediction
Energy consumption = 139.704798 pJ
sum error= 246
Actual label: 1
Output voltages: [0.047607, 0.79838, 0.012436, 0.068644, 0.053492, 0.0098764, 0.47016, 0.0051633, 0.20981, 0.064246]
Predicted label: 1
Correct prediction
Energy consumption = 168.289643 pJ
sum error= 246
Actual label: 6
Output voltages: [0.35535, 0.47995, 0.34307, 0.012679, 0.053926, 0.15322, 0.7987, 0.0016317, 0.1953, 0.028298]
Predicted label: 6
Correct prediction
Energy consumption = 145.657621 pJ
sum error= 246
Actual label: 5
Output voltages: [0.1508, 0.0010792, 0.0097218, 0.42235, 0.0064933, 0.79878, 0.14104, 0.047467, 0.77321, 0.046915]
Predicted label: 5
Correct prediction
Energy consumption = 140.303762 pJ
sum error= 246
Actual label: 7
Output voltages: [0.29308, 0.0053337, 0.033162, 0.43191, 0.0027492, 0.0080689, 0.0012059, 0.79877, 0.6263, 0.45119]
Predicted label: 7
Correct prediction
Energy consumption = 146.710185 pJ
sum error= 246
Actual label: 4
Output voltages: [0.0096354, 0.012048, 0.062644, 0.0015802, 0.79876, 0.014374, 0.57433, 0.053403, 0.2676, 0.018512]
Predicted label: 4
Correct prediction
Energy consumption = 151.610008 pJ
sum error= 246
Actual label: 9
Output voltages: [0.48618, 0.0034908, 0.010326, 0.065458, 0.14565, 0.0018437, 0.0015842, 0.12087, 0.33011, 0.79718]
Predicted label: 9
Correct prediction
Energy consumption = 146.543006 pJ
sum error= 246
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 477 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 477 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 477 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.16401, 0.03179, 0.054464, 0.79867, 0.01341, 0.015519, 0.015383, 0.010533, 0.51511, 0.11132]
Predicted label: 3
Correct prediction
Energy consumption = 159.595624 pJ
sum error= 246
Actual label: 5
Output voltages: [0.043118, 0.0031963, 0.026494, 0.055357, 0.010345, 0.79608, 0.036583, 0.001091, 0.7693, 0.021579]
Predicted label: 5
Correct prediction
Energy consumption = 152.960076 pJ
sum error= 246
Actual label: 4
Output voltages: [0.010742, 0.012071, 0.040307, 0.0064987, 0.79878, 0.011629, 0.13115, 0.099348, 0.34384, 0.036877]
Predicted label: 4
Correct prediction
Energy consumption = 154.673020 pJ
sum error= 246
Actual label: 7
Output voltages: [0.30238, 0.17338, 0.057163, 0.64843, 0.0013802, 0.0014794, 0.0010879, 0.79875, 0.2489, 0.33897]
Predicted label: 7
Correct prediction
Energy consumption = 162.265761 pJ
sum error= 246
Actual label: 1
Output voltages: [0.0073123, 0.79859, 0.023955, 0.052515, 0.030994, 0.0011288, 0.54421, 0.0027821, 0.43217, 0.19677]
Predicted label: 1
Correct prediction
Energy consumption = 161.259572 pJ
sum error= 246
Actual label: 2
Output voltages: [0.53118, 0.22172, 0.79592, 0.16142, 0.030519, 0.0013275, 0.53679, 0.10903, 0.37938, 0.011845]
Predicted label: 2
Correct prediction
Energy consumption = 145.638725 pJ
sum error= 246
Actual label: 0
Output voltages: [0.79873, 0.028275, 0.035659, 0.0068785, 0.0081802, 0.0015967, 0.7405, 0.020631, 0.27667, 0.086281]
Predicted label: 0
Correct prediction
Energy consumption = 139.719124 pJ
sum error= 246
Actual label: 8
Output voltages: [0.044189, 0.071808, 0.016883, 0.75842, 0.0012813, 0.07112, 0.41562, 0.011279, 0.79879, 0.0099481]
Predicted label: 8
Correct prediction
Energy consumption = 153.521142 pJ
sum error= 246
Actual label: 1
Output voltages: [0.0029646, 0.7985, 0.028257, 0.10516, 0.019894, 0.0088015, 0.056561, 0.013839, 0.020167, 0.2222]
Predicted label: 1
Correct prediction
Energy consumption = 159.843270 pJ
sum error= 246
Actual label: 6
Output voltages: [0.091683, 0.015232, 0.38284, 0.001439, 0.26744, 0.20236, 0.79878, 0.0061606, 0.59477, 0.0090539]
Predicted label: 6
Correct prediction
Energy consumption = 147.049471 pJ
sum error= 246
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 478 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 478 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 478 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79705, 0.11245, 0.093104, 0.021328, 0.035545, 0.0048101, 0.77205, 0.010658, 0.33885, 0.016872]
Predicted label: 0
Correct prediction
Energy consumption = 176.023218 pJ
sum error= 246
Actual label: 7
Output voltages: [0.064071, 0.15821, 0.37876, 0.17352, 0.0020779, 0.0010827, 0.0011687, 0.79877, 0.73412, 0.19717]
Predicted label: 7
Correct prediction
Energy consumption = 152.754258 pJ
sum error= 246
Actual label: 3
Output voltages: [0.12668, 0.019804, 0.019865, 0.79875, 0.0083129, 0.0081365, 0.01029, 0.051923, 0.50648, 0.052524]
Predicted label: 3
Correct prediction
Energy consumption = 145.152803 pJ
sum error= 246
Actual label: 4
Output voltages: [0.0015276, 0.030371, 0.058516, 0.041205, 0.79879, 0.0018664, 0.29124, 0.027683, 0.025091, 0.34105]
Predicted label: 4
Correct prediction
Energy consumption = 145.372138 pJ
sum error= 246
Actual label: 7
Output voltages: [0.18281, 0.017041, 0.037902, 0.10135, 0.0041788, 0.0099139, 0.0011386, 0.79872, 0.30796, 0.53557]
Predicted label: 7
Correct prediction
Energy consumption = 153.733585 pJ
sum error= 246
Actual label: 3
Output voltages: [0.016147, 0.013848, 0.14736, 0.79492, 0.0018491, 0.0045174, 0.0014158, 0.15402, 0.79113, 0.052756]
Predicted label: 3
Correct prediction
Energy consumption = 143.930815 pJ
sum error= 246
Actual label: 9
Output voltages: [0.52833, 0.025466, 0.0085429, 0.24372, 0.44704, 0.021745, 0.020218, 0.0062152, 0.28227, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 141.087997 pJ
sum error= 246
Actual label: 6
Output voltages: [0.10654, 0.093756, 0.055188, 0.0076526, 0.19665, 0.21013, 0.79879, 0.0022467, 0.48696, 0.0035287]
Predicted label: 6
Correct prediction
Energy consumption = 153.676770 pJ
sum error= 246
Actual label: 0
Output voltages: [0.79812, 0.052015, 0.0030176, 0.029468, 0.053793, 0.25516, 0.74455, 0.044829, 0.022976, 0.2649]
Predicted label: 0
Correct prediction
Energy consumption = 152.146958 pJ
sum error= 246
Actual label: 8
Output voltages: [0.067503, 0.018473, 0.13632, 0.16767, 0.0015326, 0.72832, 0.0934, 0.0068578, 0.79879, 0.016803]
Predicted label: 8
Correct prediction
Energy consumption = 148.153620 pJ
sum error= 246
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 479 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 479 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 479 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.11014, 0.040423, 0.10431, 0.0011013, 0.18051, 0.33205, 0.79877, 0.010607, 0.54082, 0.01047]
Predicted label: 6
Correct prediction
Energy consumption = 166.753177 pJ
sum error= 246
Actual label: 4
Output voltages: [0.038738, 0.10878, 0.0023519, 0.37517, 0.79876, 0.0094473, 0.029985, 0.027547, 0.016397, 0.1474]
Predicted label: 4
Correct prediction
Energy consumption = 153.279110 pJ
sum error= 246
Actual label: 8
Output voltages: [0.010664, 0.038776, 0.32849, 0.026684, 0.008031, 0.019466, 0.017955, 0.024447, 0.79878, 0.53096]
Predicted label: 8
Correct prediction
Energy consumption = 154.971998 pJ
sum error= 246
Actual label: 7
Output voltages: [0.19216, 0.040982, 0.39202, 0.016846, 0.0016623, 0.008287, 0.0011782, 0.79869, 0.64874, 0.35523]
Predicted label: 7
Correct prediction
Energy consumption = 144.977680 pJ
sum error= 246
Actual label: 7
Output voltages: [0.12205, 0.0049133, 0.0012217, 0.0096677, 0.28465, 0.017135, 0.0010719, 0.79866, 0.24694, 0.20442]
Predicted label: 7
Correct prediction
Energy consumption = 155.397419 pJ
sum error= 246
Actual label: 9
Output voltages: [0.18538, 0.038796, 0.023993, 0.068206, 0.075926, 0.027467, 0.034957, 0.027132, 0.66902, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 139.425714 pJ
sum error= 246
Actual label: 3
Output voltages: [0.1364, 0.27919, 0.24503, 0.79865, 0.0081927, 0.018178, 0.0063453, 0.17592, 0.57452, 0.062129]
Predicted label: 3
Correct prediction
Energy consumption = 152.172204 pJ
sum error= 246
Actual label: 8
Output voltages: [0.0085264, 0.24922, 0.20454, 0.029543, 0.019261, 0.0043025, 0.01952, 0.037759, 0.7987, 0.29526]
Predicted label: 8
Correct prediction
Energy consumption = 144.225797 pJ
sum error= 246
Actual label: 6
Output voltages: [0.12487, 0.031603, 0.015088, 0.043633, 0.070303, 0.54659, 0.79621, 0.015925, 0.79727, 0.0021092]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.504603 pJ
sum error= 247
Actual label: 9
Output voltages: [0.34835, 0.034318, 0.010751, 0.46538, 0.17924, 0.012972, 0.009896, 0.041344, 0.15305, 0.79474]
Predicted label: 9
Correct prediction
Energy consumption = 150.517781 pJ
sum error= 247
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 480 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 480 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 480 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37219, 0.0021971, 0.0054974, 0.3943, 0.0048969, 0.036521, 0.0012049, 0.79875, 0.61008, 0.62863]
Predicted label: 7
Correct prediction
Energy consumption = 169.665342 pJ
sum error= 247
Actual label: 2
Output voltages: [0.035615, 0.36402, 0.7972, 0.1714, 0.31629, 0.0010687, 0.2611, 0.025479, 0.38921, 0.13246]
Predicted label: 2
Correct prediction
Energy consumption = 151.182697 pJ
sum error= 247
Actual label: 3
Output voltages: [0.11553, 0.0057785, 0.013292, 0.79861, 0.020798, 0.29622, 0.0088477, 0.0025762, 0.42722, 0.027635]
Predicted label: 3
Correct prediction
Energy consumption = 150.294211 pJ
sum error= 247
Actual label: 4
Output voltages: [0.0083253, 0.007515, 0.039446, 0.0058291, 0.79854, 0.0017618, 0.035092, 0.10486, 0.044238, 0.0050122]
Predicted label: 4
Correct prediction
Energy consumption = 151.292805 pJ
sum error= 247
Actual label: 0
Output voltages: [0.79877, 0.081938, 0.044004, 0.014629, 0.005623, 0.0098057, 0.55375, 0.0072288, 0.42125, 0.01567]
Predicted label: 0
Correct prediction
Energy consumption = 152.819110 pJ
sum error= 247
Actual label: 2
Output voltages: [0.52901, 0.37411, 0.79879, 0.025921, 0.025962, 0.0013571, 0.41359, 0.26637, 0.27331, 0.038571]
Predicted label: 2
Correct prediction
Energy consumption = 149.275993 pJ
sum error= 247
Actual label: 1
Output voltages: [0.052739, 0.79853, 0.23845, 0.040518, 0.027109, 0.0012988, 0.61703, 0.0010683, 0.028811, 0.072112]
Predicted label: 1
Correct prediction
Energy consumption = 157.798043 pJ
sum error= 247
Actual label: 8
Output voltages: [0.77802, 0.011819, 0.035042, 0.65251, 0.0044531, 0.0014533, 0.19769, 0.0010784, 0.75379, 0.47603]
Predicted label: 0
Wrong prediction!
Energy consumption = 153.570216 pJ
sum error= 248
Actual label: 3
Output voltages: [0.01485, 0.012201, 0.0060455, 0.79343, 0.012253, 0.71253, 0.037322, 0.2115, 0.59662, 0.030645]
Predicted label: 3
Correct prediction
Energy consumption = 148.320111 pJ
sum error= 248
Actual label: 5
Output voltages: [0.0091043, 0.0011185, 0.001086, 0.047356, 0.28087, 0.79853, 0.22886, 0.0099513, 0.6893, 0.034846]
Predicted label: 5
Correct prediction
Energy consumption = 138.083076 pJ
sum error= 248
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 481 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 481 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 481 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.0043379, 0.011381, 0.0014255, 0.32157, 0.013436, 0.79876, 0.10976, 0.031045, 0.65194, 0.077794]
Predicted label: 5
Correct prediction
Energy consumption = 168.149844 pJ
sum error= 248
Actual label: 7
Output voltages: [0.16821, 0.047243, 0.035375, 0.35926, 0.0078013, 0.0089569, 0.0010671, 0.79856, 0.19385, 0.41026]
Predicted label: 7
Correct prediction
Energy consumption = 153.512328 pJ
sum error= 248
Actual label: 2
Output voltages: [0.43527, 0.15729, 0.79873, 0.13813, 0.017853, 0.0013084, 0.26404, 0.029154, 0.30888, 0.035412]
Predicted label: 2
Correct prediction
Energy consumption = 154.758928 pJ
sum error= 248
Actual label: 4
Output voltages: [0.014943, 0.0079414, 0.34246, 0.0011192, 0.79878, 0.0021313, 0.15009, 0.0045306, 0.12954, 0.018326]
Predicted label: 4
Correct prediction
Energy consumption = 145.552449 pJ
sum error= 248
Actual label: 6
Output voltages: [0.79104, 0.0015076, 0.059173, 0.0040202, 0.072488, 0.0039127, 0.68056, 0.0066237, 0.41725, 0.024164]
Predicted label: 0
Wrong prediction!
Energy consumption = 159.688203 pJ
sum error= 249
Actual label: 7
Output voltages: [0.3099, 0.047324, 0.016853, 0.19407, 0.0069839, 0.0058927, 0.0011544, 0.79875, 0.26495, 0.51607]
Predicted label: 7
Correct prediction
Energy consumption = 153.259438 pJ
sum error= 249
Actual label: 2
Output voltages: [0.42426, 0.0025581, 0.52603, 0.78641, 0.027081, 0.028147, 0.46744, 0.006786, 0.11498, 0.0028416]
Predicted label: 3
Wrong prediction!
Energy consumption = 146.554194 pJ
sum error= 250
Actual label: 8
Output voltages: [0.042666, 0.030119, 0.34125, 0.19797, 0.0047212, 0.12257, 0.040018, 0.027374, 0.79877, 0.41681]
Predicted label: 8
Correct prediction
Energy consumption = 158.363001 pJ
sum error= 250
Actual label: 3
Output voltages: [0.14963, 0.031005, 0.046452, 0.79867, 0.028234, 0.0035821, 0.0092904, 0.011639, 0.54549, 0.12164]
Predicted label: 3
Correct prediction
Energy consumption = 141.020986 pJ
sum error= 250
Actual label: 0
Output voltages: [0.79874, 0.045455, 0.15858, 0.011142, 0.027786, 0.0055406, 0.14131, 0.018424, 0.38983, 0.15413]
Predicted label: 0
Correct prediction
Energy consumption = 151.093308 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 482 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 482 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 482 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.01041, 0.026734, 0.017197, 0.096898, 0.0031548, 0.11654, 0.001727, 0.019119, 0.79878, 0.46504]
Predicted label: 8
Correct prediction
Energy consumption = 168.624334 pJ
sum error= 250
Actual label: 7
Output voltages: [0.31005, 0.014377, 0.0076049, 0.022909, 0.047406, 0.06083, 0.0010837, 0.79852, 0.3653, 0.36071]
Predicted label: 7
Correct prediction
Energy consumption = 153.263441 pJ
sum error= 250
Actual label: 8
Output voltages: [0.036405, 0.032947, 0.080111, 0.43422, 0.0028319, 0.0082337, 0.042743, 0.0014653, 0.79879, 0.2346]
Predicted label: 8
Correct prediction
Energy consumption = 154.173117 pJ
sum error= 250
Actual label: 9
Output voltages: [0.035441, 0.0014812, 0.056007, 0.0064564, 0.79075, 0.012769, 0.76863, 0.0012836, 0.2138, 0.12758]
Predicted label: 4
Wrong prediction!
Energy consumption = 147.094162 pJ
sum error= 251
Actual label: 0
Output voltages: [0.7923, 0.053092, 0.039185, 0.14381, 0.038413, 0.0048583, 0.7101, 0.019686, 0.54051, 0.014287]
Predicted label: 0
Correct prediction
Energy consumption = 159.377557 pJ
sum error= 251
Actual label: 8
Output voltages: [0.047806, 0.015724, 0.076008, 0.37472, 0.0034676, 0.0012396, 0.0052113, 0.0025113, 0.78194, 0.53984]
Predicted label: 8
Correct prediction
Energy consumption = 155.965454 pJ
sum error= 251
Actual label: 4
Output voltages: [0.0034071, 0.14038, 0.051068, 0.010972, 0.79867, 0.0010666, 0.013858, 0.053203, 0.017017, 0.67921]
Predicted label: 4
Correct prediction
Energy consumption = 153.449466 pJ
sum error= 251
Actual label: 4
Output voltages: [0.0027433, 0.011569, 0.023971, 0.001161, 0.79878, 0.0032836, 0.021491, 0.04576, 0.51841, 0.0204]
Predicted label: 4
Correct prediction
Energy consumption = 142.303574 pJ
sum error= 251
Actual label: 5
Output voltages: [0.049336, 0.0010894, 0.006222, 0.21368, 0.11171, 0.79785, 0.099896, 0.14928, 0.69649, 0.53696]
Predicted label: 5
Correct prediction
Energy consumption = 151.637913 pJ
sum error= 251
Actual label: 8
Output voltages: [0.04877, 0.042025, 0.033433, 0.0086366, 0.030992, 0.045851, 0.025706, 0.33424, 0.79876, 0.050902]
Predicted label: 8
Correct prediction
Energy consumption = 147.485502 pJ
sum error= 251
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 483 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 483 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 483 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.044254, 0.0010683, 0.0017881, 0.30523, 0.13763, 0.79852, 0.078821, 0.018094, 0.77625, 0.20642]
Predicted label: 5
Correct prediction
Energy consumption = 159.083722 pJ
sum error= 251
Actual label: 6
Output voltages: [0.34389, 0.021873, 0.17248, 0.0054155, 0.21508, 0.21484, 0.79856, 0.0019782, 0.6713, 0.0086651]
Predicted label: 6
Correct prediction
Energy consumption = 146.502902 pJ
sum error= 251
Actual label: 6
Output voltages: [0.15251, 0.038343, 0.25789, 0.0016262, 0.3553, 0.14131, 0.79869, 0.0014645, 0.54232, 0.017017]
Predicted label: 6
Correct prediction
Energy consumption = 145.071288 pJ
sum error= 251
Actual label: 3
Output voltages: [0.12904, 0.0016501, 0.61343, 0.79867, 0.0079836, 0.0018255, 0.0090917, 0.015331, 0.76585, 0.0047545]
Predicted label: 3
Correct prediction
Energy consumption = 141.319777 pJ
sum error= 251
Actual label: 0
Output voltages: [0.79879, 0.0011816, 0.12235, 0.021843, 0.0023585, 0.17216, 0.41304, 0.0059947, 0.19549, 0.30484]
Predicted label: 0
Correct prediction
Energy consumption = 143.269906 pJ
sum error= 251
Actual label: 9
Output voltages: [0.26113, 0.0082562, 0.018182, 0.020482, 0.017693, 0.025313, 0.0055746, 0.084904, 0.71005, 0.79391]
Predicted label: 9
Correct prediction
Energy consumption = 149.942381 pJ
sum error= 251
Actual label: 3
Output voltages: [0.34645, 0.010838, 0.20011, 0.79872, 0.032962, 0.030856, 0.01198, 0.028239, 0.5382, 0.20737]
Predicted label: 3
Correct prediction
Energy consumption = 143.200439 pJ
sum error= 251
Actual label: 7
Output voltages: [0.1119, 0.011747, 0.76551, 0.16366, 0.018313, 0.0011745, 0.0010681, 0.79822, 0.78429, 0.29294]
Predicted label: 7
Correct prediction
Energy consumption = 149.440670 pJ
sum error= 251
Actual label: 6
Output voltages: [0.5442, 0.047517, 0.001499, 0.50883, 0.0018117, 0.7808, 0.77996, 0.053681, 0.7448, 0.0024806]
Predicted label: 5
Wrong prediction!
Energy consumption = 145.167303 pJ
sum error= 252
Actual label: 8
Output voltages: [0.12266, 0.03525, 0.34816, 0.6819, 0.0015342, 0.014202, 0.04378, 0.014944, 0.79877, 0.080816]
Predicted label: 8
Correct prediction
Energy consumption = 144.749523 pJ
sum error= 252
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 484 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 484 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 484 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.63153, 0.005486, 0.0315, 0.011684, 0.057768, 0.0028178, 0.0037855, 0.098231, 0.39444, 0.79839]
Predicted label: 9
Correct prediction
Energy consumption = 165.327203 pJ
sum error= 252
Actual label: 3
Output voltages: [0.44736, 0.024077, 0.32837, 0.79876, 0.00599, 0.0018257, 0.008261, 0.0049887, 0.74457, 0.094845]
Predicted label: 3
Correct prediction
Energy consumption = 150.524164 pJ
sum error= 252
Actual label: 4
Output voltages: [0.043961, 0.0065094, 0.3502, 0.031718, 0.79873, 0.026549, 0.024794, 0.016139, 0.028389, 0.57132]
Predicted label: 4
Correct prediction
Energy consumption = 155.039985 pJ
sum error= 252
Actual label: 9
Output voltages: [0.33078, 0.023844, 0.044769, 0.037937, 0.059978, 0.032423, 0.0031101, 0.04817, 0.40434, 0.79821]
Predicted label: 9
Correct prediction
Energy consumption = 146.871467 pJ
sum error= 252
Actual label: 5
Output voltages: [0.30933, 0.0016584, 0.0010756, 0.10264, 0.021023, 0.79861, 0.034531, 0.035954, 0.71305, 0.0086174]
Predicted label: 5
Correct prediction
Energy consumption = 148.921984 pJ
sum error= 252
Actual label: 8
Output voltages: [0.0035123, 0.12184, 0.044212, 0.12418, 0.0013289, 0.0050503, 0.014964, 0.016338, 0.79879, 0.26564]
Predicted label: 8
Correct prediction
Energy consumption = 149.770702 pJ
sum error= 252
Actual label: 9
Output voltages: [0.31326, 0.0016229, 0.26432, 0.020414, 0.25532, 0.015719, 0.0019845, 0.27177, 0.30642, 0.79709]
Predicted label: 9
Correct prediction
Energy consumption = 157.865715 pJ
sum error= 252
Actual label: 1
Output voltages: [0.038887, 0.79858, 0.11655, 0.12498, 0.023811, 0.0078511, 0.60458, 0.0012148, 0.033583, 0.049723]
Predicted label: 1
Correct prediction
Energy consumption = 163.235392 pJ
sum error= 252
Actual label: 2
Output voltages: [0.2667, 0.194, 0.79872, 0.050412, 0.027631, 0.0012505, 0.23593, 0.029365, 0.58318, 0.1352]
Predicted label: 2
Correct prediction
Energy consumption = 147.891724 pJ
sum error= 252
Actual label: 8
Output voltages: [0.033138, 0.044778, 0.023374, 0.3156, 0.013119, 0.0035056, 0.089731, 0.011048, 0.79879, 0.27323]
Predicted label: 8
Correct prediction
Energy consumption = 148.732179 pJ
sum error= 252
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 485 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 485 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 485 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.011344, 0.046634, 0.11723, 0.070145, 0.0096278, 0.0025923, 0.029804, 0.042723, 0.79875, 0.26882]
Predicted label: 8
Correct prediction
Energy consumption = 168.474491 pJ
sum error= 252
Actual label: 6
Output voltages: [0.4303, 0.075775, 0.02091, 0.031055, 0.54371, 0.040353, 0.79879, 0.0021706, 0.52573, 0.018761]
Predicted label: 6
Correct prediction
Energy consumption = 154.918536 pJ
sum error= 252
Actual label: 8
Output voltages: [0.032206, 0.0017021, 0.29022, 0.054487, 0.0044028, 0.45225, 0.4363, 0.0014092, 0.79865, 0.016327]
Predicted label: 8
Correct prediction
Energy consumption = 146.121015 pJ
sum error= 252
Actual label: 1
Output voltages: [0.0044977, 0.79865, 0.0037211, 0.039521, 0.02294, 0.0011214, 0.53124, 0.0064498, 0.66877, 0.029776]
Predicted label: 1
Correct prediction
Energy consumption = 158.837497 pJ
sum error= 252
Actual label: 3
Output voltages: [0.38714, 0.0015385, 0.0095396, 0.79877, 0.0033858, 0.52203, 0.0011384, 0.18128, 0.43479, 0.0044024]
Predicted label: 3
Correct prediction
Energy consumption = 153.095977 pJ
sum error= 252
Actual label: 7
Output voltages: [0.38949, 0.0031513, 0.023328, 0.55097, 0.014662, 0.012579, 0.0012719, 0.7987, 0.47127, 0.55186]
Predicted label: 7
Correct prediction
Energy consumption = 142.647768 pJ
sum error= 252
Actual label: 9
Output voltages: [0.43197, 0.0064176, 0.012416, 0.050741, 0.0479, 0.012734, 0.0040428, 0.19206, 0.41772, 0.79688]
Predicted label: 9
Correct prediction
Energy consumption = 142.589034 pJ
sum error= 252
Actual label: 0
Output voltages: [0.79879, 0.03177, 0.16497, 0.028765, 0.0038376, 0.023162, 0.14069, 0.013682, 0.53436, 0.2746]
Predicted label: 0
Correct prediction
Energy consumption = 154.598883 pJ
sum error= 252
Actual label: 1
Output voltages: [0.0091415, 0.79842, 0.21795, 0.19831, 0.032221, 0.0015575, 0.20831, 0.016636, 0.29231, 0.033462]
Predicted label: 1
Correct prediction
Energy consumption = 166.822864 pJ
sum error= 252
Actual label: 1
Output voltages: [0.012893, 0.79852, 0.0079815, 0.019254, 0.046523, 0.0059919, 0.30832, 0.0051564, 0.57913, 0.044514]
Predicted label: 1
Correct prediction
Energy consumption = 146.611797 pJ
sum error= 252
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 486 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 486 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 486 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.25422, 0.0022709, 0.036317, 0.19448, 0.73446, 0.0014977, 0.0015199, 0.0055654, 0.45925, 0.74739]
Predicted label: 9
Wrong prediction!
Energy consumption = 165.565243 pJ
sum error= 253
Actual label: 7
Output voltages: [0.62471, 0.086526, 0.19135, 0.76718, 0.0011091, 0.0010876, 0.0015369, 0.78908, 0.75342, 0.046553]
Predicted label: 7
Correct prediction
Energy consumption = 159.096931 pJ
sum error= 253
Actual label: 0
Output voltages: [0.79875, 0.03705, 0.2313, 0.011559, 0.020746, 0.003649, 0.15913, 0.022261, 0.044429, 0.19549]
Predicted label: 0
Correct prediction
Energy consumption = 150.013413 pJ
sum error= 253
Actual label: 8
Output voltages: [0.016837, 0.093508, 0.081425, 0.097337, 0.0095976, 0.012085, 0.01775, 0.0017241, 0.79879, 0.51722]
Predicted label: 8
Correct prediction
Energy consumption = 150.784398 pJ
sum error= 253
Actual label: 1
Output voltages: [0.038471, 0.79835, 0.020426, 0.064951, 0.021562, 0.0047459, 0.31034, 0.07838, 0.12811, 0.044266]
Predicted label: 1
Correct prediction
Energy consumption = 163.920193 pJ
sum error= 253
Actual label: 7
Output voltages: [0.19491, 0.047016, 0.40049, 0.032533, 0.0012621, 0.0010747, 0.001085, 0.79878, 0.76225, 0.061027]
Predicted label: 7
Correct prediction
Energy consumption = 148.753268 pJ
sum error= 253
Actual label: 4
Output voltages: [0.020001, 0.016619, 0.067905, 0.046447, 0.79871, 0.017259, 0.049, 0.036435, 0.033966, 0.43617]
Predicted label: 4
Correct prediction
Energy consumption = 157.458488 pJ
sum error= 253
Actual label: 5
Output voltages: [0.034617, 0.0021974, 0.0083531, 0.52122, 0.03569, 0.79879, 0.54484, 0.017531, 0.61245, 0.14983]
Predicted label: 5
Correct prediction
Energy consumption = 146.895715 pJ
sum error= 253
Actual label: 7
Output voltages: [0.052226, 0.029732, 0.60468, 0.12808, 0.0059322, 0.0010674, 0.0011191, 0.79878, 0.52144, 0.46254]
Predicted label: 7
Correct prediction
Energy consumption = 150.378137 pJ
sum error= 253
Actual label: 1
Output voltages: [0.0060136, 0.79851, 0.063286, 0.041279, 0.02364, 0.0015278, 0.74592, 0.004218, 0.10625, 0.084394]
Predicted label: 1
Correct prediction
Energy consumption = 157.988645 pJ
sum error= 253
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 487 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 487 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 487 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.50054, 0.070527, 0.79869, 0.030801, 0.049315, 0.001142, 0.4249, 0.031326, 0.55927, 0.032798]
Predicted label: 2
Correct prediction
Energy consumption = 168.434790 pJ
sum error= 253
Actual label: 1
Output voltages: [0.025589, 0.79852, 0.010355, 0.14016, 0.0011829, 0.0013584, 0.26411, 0.0049329, 0.50245, 0.047641]
Predicted label: 1
Correct prediction
Energy consumption = 167.584702 pJ
sum error= 253
Actual label: 1
Output voltages: [0.021498, 0.79864, 0.0012237, 0.027526, 0.32532, 0.025917, 0.67151, 0.010818, 0.034926, 0.034715]
Predicted label: 1
Correct prediction
Energy consumption = 153.422646 pJ
sum error= 253
Actual label: 3
Output voltages: [0.048586, 0.01736, 0.091791, 0.79873, 0.0078796, 0.011818, 0.0064587, 0.061758, 0.58144, 0.094666]
Predicted label: 3
Correct prediction
Energy consumption = 154.498259 pJ
sum error= 253
Actual label: 9
Output voltages: [0.76523, 0.0045303, 0.15171, 0.020021, 0.0025458, 0.026041, 0.74869, 0.0030376, 0.015718, 0.75966]
Predicted label: 0
Wrong prediction!
Energy consumption = 153.824393 pJ
sum error= 254
Actual label: 6
Output voltages: [0.24385, 0.072143, 0.22826, 0.0085036, 0.41935, 0.21352, 0.79868, 0.0016303, 0.36628, 0.02063]
Predicted label: 6
Correct prediction
Energy consumption = 148.486132 pJ
sum error= 254
Actual label: 2
Output voltages: [0.37649, 0.034583, 0.79425, 0.061137, 0.64997, 0.001634, 0.6529, 0.51496, 0.0061733, 0.0014434]
Predicted label: 2
Correct prediction
Energy consumption = 145.009762 pJ
sum error= 254
Actual label: 1
Output voltages: [0.056558, 0.7985, 0.051444, 0.041992, 0.03354, 0.0056439, 0.73701, 0.0021368, 0.057077, 0.094527]
Predicted label: 1
Correct prediction
Energy consumption = 166.086686 pJ
sum error= 254
Actual label: 2
Output voltages: [0.38109, 0.0011459, 0.79597, 0.51567, 0.0010693, 0.010816, 0.017223, 0.090847, 0.77446, 0.0026837]
Predicted label: 2
Correct prediction
Energy consumption = 148.242610 pJ
sum error= 254
Actual label: 8
Output voltages: [0.0022581, 0.022175, 0.018953, 0.027344, 0.3756, 0.038071, 0.73975, 0.0023393, 0.79711, 0.045315]
Predicted label: 8
Correct prediction
Energy consumption = 147.854878 pJ
sum error= 254
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 488 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 488 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 488 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.76632, 0.016734, 0.040459, 0.025958, 0.0051806, 0.0014922, 0.329, 0.0042973, 0.63074, 0.033235]
Predicted label: 0
Correct prediction
Energy consumption = 176.953005 pJ
sum error= 254
Actual label: 7
Output voltages: [0.43881, 0.010367, 0.25742, 0.095975, 0.010331, 0.0015442, 0.001123, 0.79874, 0.76179, 0.45116]
Predicted label: 7
Correct prediction
Energy consumption = 136.015797 pJ
sum error= 254
Actual label: 6
Output voltages: [0.0070013, 0.061587, 0.50252, 0.022944, 0.039951, 0.23981, 0.79878, 0.0015576, 0.76569, 0.027723]
Predicted label: 6
Correct prediction
Energy consumption = 148.981197 pJ
sum error= 254
Actual label: 6
Output voltages: [0.20618, 0.039787, 0.19113, 0.0013486, 0.43568, 0.30498, 0.79874, 0.0018075, 0.32372, 0.012225]
Predicted label: 6
Correct prediction
Energy consumption = 138.545938 pJ
sum error= 254
Actual label: 9
Output voltages: [0.2504, 0.014719, 0.050902, 0.015843, 0.18126, 0.017624, 0.0043397, 0.017551, 0.59988, 0.79665]
Predicted label: 9
Correct prediction
Energy consumption = 155.360393 pJ
sum error= 254
Actual label: 3
Output voltages: [0.043746, 0.052921, 0.028759, 0.79879, 0.0019344, 0.048795, 0.0074822, 0.0014599, 0.70363, 0.045151]
Predicted label: 3
Correct prediction
Energy consumption = 146.048937 pJ
sum error= 254
Actual label: 7
Output voltages: [0.25648, 0.6563, 0.38622, 0.43089, 0.0010698, 0.0010825, 0.0029849, 0.79823, 0.74565, 0.082758]
Predicted label: 7
Correct prediction
Energy consumption = 154.624286 pJ
sum error= 254
Actual label: 0
Output voltages: [0.79879, 0.041335, 0.24625, 0.007136, 0.016763, 0.023882, 0.1025, 0.043378, 0.68521, 0.156]
Predicted label: 0
Correct prediction
Energy consumption = 157.211437 pJ
sum error= 254
Actual label: 5
Output voltages: [0.45374, 0.0010699, 0.0056856, 0.041782, 0.010542, 0.79879, 0.24548, 0.083609, 0.69923, 0.0019074]
Predicted label: 5
Correct prediction
Energy consumption = 149.366750 pJ
sum error= 254
Actual label: 2
Output voltages: [0.36471, 0.26144, 0.79848, 0.42451, 0.011309, 0.0013151, 0.062412, 0.0034184, 0.33049, 0.013796]
Predicted label: 2
Correct prediction
Energy consumption = 141.778288 pJ
sum error= 254
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 489 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 489 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 489 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.237, 0.0023847, 0.37233, 0.47156, 0.010523, 0.012299, 0.17075, 0.010109, 0.79869, 0.0035606]
Predicted label: 8
Correct prediction
Energy consumption = 164.948720 pJ
sum error= 254
Actual label: 0
Output voltages: [0.79878, 0.049897, 0.038823, 0.0086114, 0.0079081, 0.0018847, 0.38401, 0.023803, 0.048873, 0.048111]
Predicted label: 0
Correct prediction
Energy consumption = 147.871527 pJ
sum error= 254
Actual label: 5
Output voltages: [0.022437, 0.0010661, 0.0015945, 0.13174, 0.14641, 0.79842, 0.060701, 0.0070406, 0.78174, 0.034829]
Predicted label: 5
Correct prediction
Energy consumption = 143.834454 pJ
sum error= 254
Actual label: 4
Output voltages: [0.081204, 0.017824, 0.32463, 0.021264, 0.79879, 0.0019271, 0.014514, 0.21458, 0.016286, 0.71302]
Predicted label: 4
Correct prediction
Energy consumption = 158.601624 pJ
sum error= 254
Actual label: 3
Output voltages: [0.089228, 0.02108, 0.041038, 0.79866, 0.024321, 0.034121, 0.011578, 0.064314, 0.6977, 0.075078]
Predicted label: 3
Correct prediction
Energy consumption = 146.976963 pJ
sum error= 254
Actual label: 8
Output voltages: [0.038396, 0.03438, 0.32644, 0.024855, 0.032584, 0.0098499, 0.026878, 0.0028225, 0.79875, 0.20838]
Predicted label: 8
Correct prediction
Energy consumption = 146.383092 pJ
sum error= 254
Actual label: 4
Output voltages: [0.017398, 0.036169, 0.038932, 0.0056758, 0.7986, 0.002128, 0.38495, 0.18173, 0.058648, 0.16263]
Predicted label: 4
Correct prediction
Energy consumption = 144.334720 pJ
sum error= 254
Actual label: 6
Output voltages: [0.18064, 0.14974, 0.19671, 0.025608, 0.036055, 0.39632, 0.79876, 0.0021134, 0.4758, 0.11141]
Predicted label: 6
Correct prediction
Energy consumption = 152.885335 pJ
sum error= 254
Actual label: 6
Output voltages: [0.21647, 0.062187, 0.06434, 0.0089919, 0.075696, 0.31746, 0.79872, 0.0049051, 0.40338, 0.0079133]
Predicted label: 6
Correct prediction
Energy consumption = 145.882262 pJ
sum error= 254
Actual label: 2
Output voltages: [0.13021, 0.073372, 0.79873, 0.03496, 0.003508, 0.0011169, 0.072992, 0.063601, 0.57947, 0.019625]
Predicted label: 2
Correct prediction
Energy consumption = 150.179500 pJ
sum error= 254
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 490 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 490 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 490 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.1104, 0.44479, 0.39932, 0.039771, 0.0023584, 0.0011077, 0.0049598, 0.79846, 0.18266, 0.2063]
Predicted label: 7
Correct prediction
Energy consumption = 167.271131 pJ
sum error= 254
Actual label: 9
Output voltages: [0.18456, 0.017932, 0.021517, 0.015735, 0.06569, 0.025088, 0.0061989, 0.01848, 0.4432, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 143.633388 pJ
sum error= 254
Actual label: 5
Output voltages: [0.029141, 0.0017892, 0.0011198, 0.48968, 0.012827, 0.79662, 0.017627, 0.0019076, 0.64116, 0.092461]
Predicted label: 5
Correct prediction
Energy consumption = 144.749178 pJ
sum error= 254
Actual label: 1
Output voltages: [0.044694, 0.79838, 0.26206, 0.18597, 0.018188, 0.0011792, 0.73465, 0.0016074, 0.039254, 0.2768]
Predicted label: 1
Correct prediction
Energy consumption = 162.535307 pJ
sum error= 254
Actual label: 3
Output voltages: [0.25195, 0.016803, 0.14751, 0.79877, 0.015481, 0.0016402, 0.0040075, 0.002926, 0.53701, 0.045845]
Predicted label: 3
Correct prediction
Energy consumption = 151.878014 pJ
sum error= 254
Actual label: 2
Output voltages: [0.4063, 0.15294, 0.79874, 0.10073, 0.017696, 0.0013154, 0.21793, 0.026417, 0.40946, 0.057739]
Predicted label: 2
Correct prediction
Energy consumption = 139.006222 pJ
sum error= 254
Actual label: 4
Output voltages: [0.0052759, 0.026857, 0.098454, 0.013482, 0.79876, 0.0013898, 0.3102, 0.155, 0.034609, 0.034303]
Predicted label: 4
Correct prediction
Energy consumption = 158.344280 pJ
sum error= 254
Actual label: 3
Output voltages: [0.20964, 0.18253, 0.047695, 0.79873, 0.0011772, 0.0081235, 0.0021973, 0.27314, 0.088999, 0.24835]
Predicted label: 3
Correct prediction
Energy consumption = 151.858193 pJ
sum error= 254
Actual label: 6
Output voltages: [0.17477, 0.17691, 0.041399, 0.015703, 0.29528, 0.44604, 0.79877, 0.0030107, 0.57719, 0.0085763]
Predicted label: 6
Correct prediction
Energy consumption = 153.383821 pJ
sum error= 254
Actual label: 1
Output voltages: [0.019149, 0.79862, 0.016962, 0.048182, 0.42257, 0.011594, 0.71406, 0.001104, 0.0050475, 0.15609]
Predicted label: 1
Correct prediction
Energy consumption = 157.542399 pJ
sum error= 254
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 491 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 491 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 491 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.21803, 0.013805, 0.058711, 0.029379, 0.17531, 0.037456, 0.050344, 0.084457, 0.46542, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 167.408924 pJ
sum error= 254
Actual label: 4
Output voltages: [0.27482, 0.034047, 0.14838, 0.017606, 0.77034, 0.0012362, 0.034553, 0.0012011, 0.18591, 0.79598]
Predicted label: 9
Wrong prediction!
Energy consumption = 148.195228 pJ
sum error= 255
Actual label: 4
Output voltages: [0.0058341, 0.0081103, 0.064493, 0.0034881, 0.79862, 0.0015606, 0.11433, 0.082599, 0.081939, 0.024328]
Predicted label: 4
Correct prediction
Energy consumption = 155.621424 pJ
sum error= 255
Actual label: 7
Output voltages: [0.12626, 0.026873, 0.030785, 0.042526, 0.012095, 0.0019312, 0.0018216, 0.79875, 0.055011, 0.32403]
Predicted label: 7
Correct prediction
Energy consumption = 155.478436 pJ
sum error= 255
Actual label: 6
Output voltages: [0.028747, 0.034135, 0.30155, 0.0026976, 0.040585, 0.070494, 0.79877, 0.0016637, 0.64728, 0.010541]
Predicted label: 6
Correct prediction
Energy consumption = 149.684831 pJ
sum error= 255
Actual label: 5
Output voltages: [0.033031, 0.0011378, 0.004483, 0.17087, 0.018427, 0.7884, 0.056141, 0.01932, 0.78087, 0.077941]
Predicted label: 5
Correct prediction
Energy consumption = 144.934957 pJ
sum error= 255
Actual label: 4
Output voltages: [0.0022407, 0.01849, 0.24233, 0.0096616, 0.79868, 0.0056062, 0.20982, 0.088273, 0.043782, 0.033868]
Predicted label: 4
Correct prediction
Energy consumption = 155.941980 pJ
sum error= 255
Actual label: 1
Output voltages: [0.014529, 0.79855, 0.20975, 0.0076136, 0.0022817, 0.0032716, 0.45685, 0.0019054, 0.43487, 0.017137]
Predicted label: 1
Correct prediction
Energy consumption = 161.162732 pJ
sum error= 255
Actual label: 9
Output voltages: [0.55661, 0.0024268, 0.038206, 0.016474, 0.13654, 0.0031056, 0.022632, 0.044038, 0.3872, 0.79086]
Predicted label: 9
Correct prediction
Energy consumption = 158.039712 pJ
sum error= 255
Actual label: 9
Output voltages: [0.2893, 0.0067986, 0.051699, 0.029448, 0.10955, 0.0074136, 0.014585, 0.040165, 0.30535, 0.79844]
Predicted label: 9
Correct prediction
Energy consumption = 146.466187 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 492 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 492 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 492 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.47703, 0.0068103, 0.79851, 0.21556, 0.02132, 0.0011988, 0.039821, 0.14821, 0.48054, 0.014566]
Predicted label: 2
Correct prediction
Energy consumption = 165.814565 pJ
sum error= 255
Actual label: 7
Output voltages: [0.38699, 0.36239, 0.40919, 0.19748, 0.023457, 0.0010811, 0.0010693, 0.79879, 0.024112, 0.27571]
Predicted label: 7
Correct prediction
Energy consumption = 148.326423 pJ
sum error= 255
Actual label: 8
Output voltages: [0.052197, 0.028005, 0.17917, 0.46783, 0.0011967, 0.054532, 0.01933, 0.0079351, 0.79876, 0.43659]
Predicted label: 8
Correct prediction
Energy consumption = 156.563068 pJ
sum error= 255
Actual label: 0
Output voltages: [0.79864, 0.010771, 0.051373, 0.016813, 0.010352, 0.010424, 0.64469, 0.0079954, 0.17485, 0.035827]
Predicted label: 0
Correct prediction
Energy consumption = 143.112420 pJ
sum error= 255
Actual label: 1
Output voltages: [0.13371, 0.79861, 0.74941, 0.028125, 0.012302, 0.0011163, 0.28958, 0.0039809, 0.019005, 0.057746]
Predicted label: 1
Correct prediction
Energy consumption = 160.623027 pJ
sum error= 255
Actual label: 3
Output voltages: [0.54399, 0.01536, 0.036468, 0.79873, 0.031673, 0.019157, 0.024629, 0.043557, 0.1635, 0.004804]
Predicted label: 3
Correct prediction
Energy consumption = 152.497085 pJ
sum error= 255
Actual label: 6
Output voltages: [0.27462, 0.035645, 0.045611, 0.010539, 0.48549, 0.11704, 0.79875, 0.0012833, 0.52623, 0.018762]
Predicted label: 6
Correct prediction
Energy consumption = 144.629626 pJ
sum error= 255
Actual label: 1
Output voltages: [0.07121, 0.79865, 0.34786, 0.14218, 0.056043, 0.0010782, 0.3464, 0.0010676, 0.19081, 0.15508]
Predicted label: 1
Correct prediction
Energy consumption = 161.896916 pJ
sum error= 255
Actual label: 3
Output voltages: [0.32848, 0.092569, 0.023392, 0.79863, 0.0018911, 0.003742, 0.0027146, 0.44301, 0.53899, 0.034064]
Predicted label: 3
Correct prediction
Energy consumption = 151.370531 pJ
sum error= 255
Actual label: 4
Output voltages: [0.023252, 0.0077725, 0.30648, 0.0048999, 0.79868, 0.001078, 0.13469, 0.014691, 0.014053, 0.025394]
Predicted label: 4
Correct prediction
Energy consumption = 152.029224 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 493 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 493 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 493 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.025802, 0.79859, 0.068415, 0.065885, 0.018125, 0.0099428, 0.42148, 0.0010887, 0.019466, 0.030392]
Predicted label: 1
Correct prediction
Energy consumption = 175.734028 pJ
sum error= 255
Actual label: 1
Output voltages: [0.035377, 0.79858, 0.3439, 0.059003, 0.34727, 0.0033464, 0.60501, 0.0011257, 0.063401, 0.26685]
Predicted label: 1
Correct prediction
Energy consumption = 156.596018 pJ
sum error= 255
Actual label: 1
Output voltages: [0.25387, 0.79868, 0.0050813, 0.03836, 0.17209, 0.016827, 0.68062, 0.0099034, 0.020631, 0.02343]
Predicted label: 1
Correct prediction
Energy consumption = 151.972960 pJ
sum error= 255
Actual label: 5
Output voltages: [0.023333, 0.0036232, 0.013679, 0.48609, 0.015236, 0.79871, 0.53345, 0.041767, 0.54468, 0.028328]
Predicted label: 5
Correct prediction
Energy consumption = 151.402686 pJ
sum error= 255
Actual label: 6
Output voltages: [0.59303, 0.019096, 0.036674, 0.0060277, 0.28799, 0.74793, 0.79872, 0.0010663, 0.21144, 0.043962]
Predicted label: 6
Correct prediction
Energy consumption = 148.235937 pJ
sum error= 255
Actual label: 0
Output voltages: [0.79877, 0.091317, 0.031979, 0.027195, 0.039034, 0.010631, 0.76724, 0.01706, 0.26164, 0.045323]
Predicted label: 0
Correct prediction
Energy consumption = 153.616039 pJ
sum error= 255
Actual label: 7
Output voltages: [0.0848, 0.20904, 0.58491, 0.013741, 0.0073386, 0.0011979, 0.0010674, 0.79869, 0.36323, 0.4805]
Predicted label: 7
Correct prediction
Energy consumption = 149.915493 pJ
sum error= 255
Actual label: 0
Output voltages: [0.79879, 0.11175, 0.59194, 0.019777, 0.0010683, 0.0029557, 0.14623, 0.028316, 0.1919, 0.020753]
Predicted label: 0
Correct prediction
Energy consumption = 150.580876 pJ
sum error= 255
Actual label: 7
Output voltages: [0.24053, 0.22915, 0.027215, 0.65258, 0.0011305, 0.0010665, 0.0010713, 0.79876, 0.044875, 0.06083]
Predicted label: 7
Correct prediction
Energy consumption = 158.613401 pJ
sum error= 255
Actual label: 2
Output voltages: [0.26205, 0.2808, 0.79707, 0.25995, 0.0013007, 0.0013854, 0.015728, 0.36911, 0.52943, 0.002172]
Predicted label: 2
Correct prediction
Energy consumption = 149.790887 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 494 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 494 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 494 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23531, 0.011962, 0.11958, 0.79878, 0.012367, 0.014277, 0.045927, 0.023498, 0.55891, 0.015132]
Predicted label: 3
Correct prediction
Energy consumption = 164.482099 pJ
sum error= 255
Actual label: 2
Output voltages: [0.75049, 0.0021446, 0.79729, 0.46879, 0.0039502, 0.0010872, 0.12585, 0.12219, 0.66613, 0.0026765]
Predicted label: 2
Correct prediction
Energy consumption = 140.840251 pJ
sum error= 255
Actual label: 5
Output voltages: [0.020766, 0.0013504, 0.001711, 0.75154, 0.054987, 0.79668, 0.038597, 0.052836, 0.51674, 0.26933]
Predicted label: 5
Correct prediction
Energy consumption = 146.617753 pJ
sum error= 255
Actual label: 2
Output voltages: [0.27327, 0.00358, 0.79522, 0.3854, 0.01066, 0.0010988, 0.021191, 0.70972, 0.7982, 0.006788]
Predicted label: 8
Wrong prediction!
Energy consumption = 142.015604 pJ
sum error= 256
Actual label: 2
Output voltages: [0.54172, 0.014183, 0.79861, 0.45703, 0.011443, 0.0010717, 0.40773, 0.1232, 0.59816, 0.0087612]
Predicted label: 2
Correct prediction
Energy consumption = 139.620324 pJ
sum error= 256
Actual label: 9
Output voltages: [0.41522, 0.01523, 0.035317, 0.037087, 0.044717, 0.030914, 0.0084997, 0.14284, 0.25597, 0.79817]
Predicted label: 9
Correct prediction
Energy consumption = 160.665923 pJ
sum error= 256
Actual label: 4
Output voltages: [0.00724, 0.003985, 0.12473, 0.066289, 0.79873, 0.0010714, 0.01107, 0.011199, 0.14944, 0.038051]
Predicted label: 4
Correct prediction
Energy consumption = 143.859818 pJ
sum error= 256
Actual label: 9
Output voltages: [0.11985, 0.021412, 0.015521, 0.0398, 0.11352, 0.0054384, 0.02221, 0.018743, 0.34971, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 150.244450 pJ
sum error= 256
Actual label: 8
Output voltages: [0.0079299, 0.037136, 0.047552, 0.22824, 0.013216, 0.0037531, 0.030148, 0.012773, 0.79876, 0.048137]
Predicted label: 8
Correct prediction
Energy consumption = 156.373546 pJ
sum error= 256
Actual label: 1
Output voltages: [0.016851, 0.79853, 0.022165, 0.29282, 0.04973, 0.026395, 0.61018, 0.0016813, 0.027525, 0.20919]
Predicted label: 1
Correct prediction
Energy consumption = 164.935348 pJ
sum error= 256
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 495 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 495 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 495 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.61506, 0.018176, 0.79852, 0.45758, 0.0085166, 0.0011309, 0.19323, 0.042333, 0.74657, 0.03251]
Predicted label: 2
Correct prediction
Energy consumption = 175.064660 pJ
sum error= 256
Actual label: 1
Output voltages: [0.0249, 0.79532, 0.36753, 0.039173, 0.59748, 0.001158, 0.023141, 0.19107, 0.031032, 0.012249]
Predicted label: 1
Correct prediction
Energy consumption = 152.278854 pJ
sum error= 256
Actual label: 6
Output voltages: [0.16693, 0.0022359, 0.0075107, 0.015234, 0.088203, 0.7747, 0.79048, 0.0011664, 0.73086, 0.0062076]
Predicted label: 6
Correct prediction
Energy consumption = 154.711271 pJ
sum error= 256
Actual label: 1
Output voltages: [0.018824, 0.79837, 0.049657, 0.19374, 0.0098914, 0.0066038, 0.63971, 0.016757, 0.36357, 0.25634]
Predicted label: 1
Correct prediction
Energy consumption = 161.270185 pJ
sum error= 256
Actual label: 2
Output voltages: [0.3376, 0.098504, 0.79879, 0.13534, 0.0096187, 0.0012614, 0.22503, 0.0087557, 0.59658, 0.034417]
Predicted label: 2
Correct prediction
Energy consumption = 151.176601 pJ
sum error= 256
Actual label: 7
Output voltages: [0.42227, 0.18623, 0.012646, 0.094312, 0.025517, 0.013287, 0.0011763, 0.79868, 0.32503, 0.61614]
Predicted label: 7
Correct prediction
Energy consumption = 157.933403 pJ
sum error= 256
Actual label: 8
Output voltages: [0.039412, 0.0045688, 0.042808, 0.044626, 0.78224, 0.02783, 0.082291, 0.006905, 0.7634, 0.066456]
Predicted label: 4
Wrong prediction!
Energy consumption = 152.548256 pJ
sum error= 257
Actual label: 0
Output voltages: [0.79878, 0.062757, 0.012111, 0.014216, 0.0059311, 0.0064161, 0.59262, 0.017242, 0.14106, 0.052503]
Predicted label: 0
Correct prediction
Energy consumption = 146.724678 pJ
sum error= 257
Actual label: 0
Output voltages: [0.79859, 0.060854, 0.065389, 0.012863, 0.0080688, 0.0014273, 0.74534, 0.022337, 0.15724, 0.13328]
Predicted label: 0
Correct prediction
Energy consumption = 143.290971 pJ
sum error= 257
Actual label: 0
Output voltages: [0.79875, 0.045162, 0.08857, 0.02768, 0.034242, 0.060218, 0.20782, 0.044919, 0.3102, 0.32084]
Predicted label: 0
Correct prediction
Energy consumption = 152.281162 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 496 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 496 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 496 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.10672, 0.0011818, 0.015689, 0.04994, 0.02955, 0.20898, 0.05286, 0.0060562, 0.79876, 0.0013926]
Predicted label: 8
Correct prediction
Energy consumption = 169.163492 pJ
sum error= 257
Actual label: 2
Output voltages: [0.56232, 0.25283, 0.79874, 0.083246, 0.012936, 0.0012231, 0.38594, 0.035288, 0.67871, 0.1011]
Predicted label: 2
Correct prediction
Energy consumption = 147.960891 pJ
sum error= 257
Actual label: 2
Output voltages: [0.52868, 0.21127, 0.78594, 0.27665, 0.026665, 0.001374, 0.52129, 0.031392, 0.40925, 0.010798]
Predicted label: 2
Correct prediction
Energy consumption = 136.800918 pJ
sum error= 257
Actual label: 9
Output voltages: [0.27712, 0.0031441, 0.017129, 0.22178, 0.10528, 0.019987, 0.0011469, 0.028986, 0.51076, 0.79608]
Predicted label: 9
Correct prediction
Energy consumption = 150.612039 pJ
sum error= 257
Actual label: 2
Output voltages: [0.44615, 0.21412, 0.79791, 0.62301, 0.023835, 0.0011046, 0.050285, 0.00371, 0.60086, 0.12422]
Predicted label: 2
Correct prediction
Energy consumption = 155.614414 pJ
sum error= 257
Actual label: 2
Output voltages: [0.37636, 0.081283, 0.79877, 0.26375, 0.02031, 0.0012219, 0.49172, 0.023426, 0.54648, 0.05281]
Predicted label: 2
Correct prediction
Energy consumption = 143.596940 pJ
sum error= 257
Actual label: 7
Output voltages: [0.0096492, 0.062965, 0.013688, 0.53981, 0.0034055, 0.0017588, 0.0010665, 0.78499, 0.77543, 0.43189]
Predicted label: 7
Correct prediction
Energy consumption = 140.036833 pJ
sum error= 257
Actual label: 9
Output voltages: [0.23719, 0.034457, 0.038405, 0.092523, 0.042737, 0.0094, 0.16457, 0.022109, 0.12525, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 143.967169 pJ
sum error= 257
Actual label: 9
Output voltages: [0.47029, 0.0016416, 0.31185, 0.026866, 0.22531, 0.01266, 0.153, 0.0051732, 0.20977, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 137.374561 pJ
sum error= 257
Actual label: 2
Output voltages: [0.46982, 0.094893, 0.79875, 0.054041, 0.0068739, 0.00132, 0.10901, 0.14443, 0.44097, 0.24192]
Predicted label: 2
Correct prediction
Energy consumption = 152.972479 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 497 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 497 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 497 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.04083, 0.15717, 0.16045, 0.056878, 0.0042816, 0.001116, 0.0015254, 0.79878, 0.050129, 0.44083]
Predicted label: 7
Correct prediction
Energy consumption = 174.316277 pJ
sum error= 257
Actual label: 5
Output voltages: [0.0028631, 0.0010689, 0.0058027, 0.78525, 0.086749, 0.76628, 0.027683, 0.13063, 0.40075, 0.044107]
Predicted label: 3
Wrong prediction!
Energy consumption = 152.075375 pJ
sum error= 258
Actual label: 1
Output voltages: [0.019547, 0.7986, 0.0034634, 0.0091168, 0.34706, 0.030194, 0.49244, 0.0074329, 0.052259, 0.10692]
Predicted label: 1
Correct prediction
Energy consumption = 166.096468 pJ
sum error= 258
Actual label: 3
Output voltages: [0.34352, 0.035838, 0.093023, 0.79869, 0.0076117, 0.0091217, 0.0069886, 0.014318, 0.67701, 0.021816]
Predicted label: 3
Correct prediction
Energy consumption = 150.156843 pJ
sum error= 258
Actual label: 4
Output voltages: [0.020465, 0.0023401, 0.5523, 0.022642, 0.79869, 0.0010742, 0.19878, 0.070433, 0.010935, 0.026304]
Predicted label: 4
Correct prediction
Energy consumption = 149.090545 pJ
sum error= 258
Actual label: 9
Output voltages: [0.37886, 0.014585, 0.014529, 0.25443, 0.37389, 0.017554, 0.050007, 0.03665, 0.1244, 0.79714]
Predicted label: 9
Correct prediction
Energy consumption = 147.024783 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0097603, 0.011992, 0.13724, 0.022499, 0.79867, 0.0014412, 0.066487, 0.18322, 0.017572, 0.056443]
Predicted label: 4
Correct prediction
Energy consumption = 152.446305 pJ
sum error= 258
Actual label: 1
Output voltages: [0.11846, 0.79843, 0.11013, 0.20983, 0.0091568, 0.0015549, 0.64202, 0.0011061, 0.045868, 0.12186]
Predicted label: 1
Correct prediction
Energy consumption = 166.352754 pJ
sum error= 258
Actual label: 8
Output voltages: [0.018072, 0.38342, 0.18218, 0.03573, 0.013839, 0.0010714, 0.0026229, 0.016007, 0.79866, 0.48488]
Predicted label: 8
Correct prediction
Energy consumption = 152.796186 pJ
sum error= 258
Actual label: 5
Output voltages: [0.049934, 0.0013782, 0.0021055, 0.57613, 0.034219, 0.79873, 0.060696, 0.04269, 0.75951, 0.19773]
Predicted label: 5
Correct prediction
Energy consumption = 137.664147 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 498 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 498 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 498 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.27803, 0.040769, 0.26055, 0.0023148, 0.23195, 0.22588, 0.79876, 0.0053178, 0.44889, 0.0046384]
Predicted label: 6
Correct prediction
Energy consumption = 170.658980 pJ
sum error= 258
Actual label: 2
Output voltages: [0.32378, 0.031105, 0.79879, 0.12209, 0.031946, 0.0011967, 0.2313, 0.011699, 0.67735, 0.025967]
Predicted label: 2
Correct prediction
Energy consumption = 148.913935 pJ
sum error= 258
Actual label: 8
Output voltages: [0.43504, 0.0092815, 0.74541, 0.035727, 0.0089703, 0.0028238, 0.013786, 0.0025436, 0.79828, 0.51441]
Predicted label: 8
Correct prediction
Energy consumption = 147.059957 pJ
sum error= 258
Actual label: 3
Output voltages: [0.54968, 0.0059483, 0.24887, 0.79877, 0.025165, 0.025856, 0.0019498, 0.029509, 0.6868, 0.038691]
Predicted label: 3
Correct prediction
Energy consumption = 144.911172 pJ
sum error= 258
Actual label: 1
Output voltages: [0.04338, 0.79852, 0.0231, 0.037568, 0.17834, 0.021687, 0.37297, 0.0020647, 0.0073249, 0.47397]
Predicted label: 1
Correct prediction
Energy consumption = 162.376610 pJ
sum error= 258
Actual label: 2
Output voltages: [0.12786, 0.073266, 0.79875, 0.55946, 0.1292, 0.001154, 0.052203, 0.094813, 0.015663, 0.010772]
Predicted label: 2
Correct prediction
Energy consumption = 141.718765 pJ
sum error= 258
Actual label: 8
Output voltages: [0.021762, 0.014228, 0.1208, 0.069964, 0.018412, 0.026008, 0.15344, 0.0016228, 0.79879, 0.2286]
Predicted label: 8
Correct prediction
Energy consumption = 149.679255 pJ
sum error= 258
Actual label: 4
Output voltages: [0.011929, 0.015685, 0.017164, 0.0068478, 0.79875, 0.0010795, 0.39239, 0.094567, 0.0088086, 0.0055562]
Predicted label: 4
Correct prediction
Energy consumption = 148.929880 pJ
sum error= 258
Actual label: 9
Output voltages: [0.2852, 0.0077969, 0.032535, 0.016448, 0.077016, 0.01294, 0.0045821, 0.028592, 0.71728, 0.79688]
Predicted label: 9
Correct prediction
Energy consumption = 155.904366 pJ
sum error= 258
Actual label: 9
Output voltages: [0.38789, 0.0011899, 0.026734, 0.0046853, 0.10692, 0.016145, 0.0020178, 0.36983, 0.65797, 0.79447]
Predicted label: 9
Correct prediction
Energy consumption = 142.243855 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 499 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 499 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 499 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.097735, 0.040846, 0.42599, 0.79875, 0.011229, 0.0013114, 0.021832, 0.0013917, 0.74901, 0.1329]
Predicted label: 3
Correct prediction
Energy consumption = 167.062410 pJ
sum error= 258
Actual label: 7
Output voltages: [0.21833, 0.043945, 0.041051, 0.19277, 0.0027548, 0.0092172, 0.0012707, 0.79879, 0.31459, 0.49932]
Predicted label: 7
Correct prediction
Energy consumption = 156.442815 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79793, 0.029617, 0.042198, 0.0014899, 0.0076636, 0.025605, 0.62137, 0.0068663, 0.033525, 0.21862]
Predicted label: 0
Correct prediction
Energy consumption = 155.063175 pJ
sum error= 258
Actual label: 7
Output voltages: [0.02185, 0.051298, 0.016951, 0.052081, 0.0086393, 0.0051404, 0.0011073, 0.79879, 0.12714, 0.34282]
Predicted label: 7
Correct prediction
Energy consumption = 151.695381 pJ
sum error= 258
Actual label: 7
Output voltages: [0.023288, 0.14549, 0.051521, 0.0038295, 0.016643, 0.0012373, 0.0011458, 0.79878, 0.11608, 0.3953]
Predicted label: 7
Correct prediction
Energy consumption = 145.433188 pJ
sum error= 258
Actual label: 2
Output voltages: [0.46164, 0.65002, 0.78214, 0.19249, 0.0013369, 0.00124, 0.34957, 0.0064798, 0.17847, 0.0049502]
Predicted label: 2
Correct prediction
Energy consumption = 154.732121 pJ
sum error= 258
Actual label: 3
Output voltages: [0.41363, 0.0018291, 0.025115, 0.79878, 0.026199, 0.16096, 0.031012, 0.010519, 0.69998, 0.018232]
Predicted label: 3
Correct prediction
Energy consumption = 145.797664 pJ
sum error= 258
Actual label: 2
Output voltages: [0.72928, 0.0019066, 0.79606, 0.37698, 0.036466, 0.0010817, 0.074995, 0.031701, 0.75604, 0.021271]
Predicted label: 2
Correct prediction
Energy consumption = 142.523521 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0042504, 0.012736, 0.017511, 0.0086072, 0.79872, 0.001066, 0.032927, 0.056752, 0.055204, 0.03914]
Predicted label: 4
Correct prediction
Energy consumption = 158.243844 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79869, 0.18289, 0.07753, 0.017547, 0.0075327, 0.042184, 0.34424, 0.021082, 0.029304, 0.042155]
Predicted label: 0
Correct prediction
Energy consumption = 155.304626 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 500 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 500 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 500 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.28185, 0.012751, 0.53232, 0.79879, 0.058151, 0.022724, 0.016424, 0.0020737, 0.72066, 0.0071998]
Predicted label: 3
Correct prediction
Energy consumption = 161.805499 pJ
sum error= 258
Actual label: 9
Output voltages: [0.035948, 0.0068892, 0.068584, 0.050008, 0.071843, 0.034426, 0.0092635, 0.038966, 0.62003, 0.79206]
Predicted label: 9
Correct prediction
Energy consumption = 154.011869 pJ
sum error= 258
Actual label: 9
Output voltages: [0.26902, 0.02674, 0.0096952, 0.10479, 0.34233, 0.0047865, 0.0022631, 0.0031575, 0.18928, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 139.052811 pJ
sum error= 258
Actual label: 8
Output voltages: [0.011569, 0.023794, 0.07565, 0.021989, 0.014486, 0.017449, 0.028349, 0.022387, 0.79875, 0.13034]
Predicted label: 8
Correct prediction
Energy consumption = 139.416404 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0013284, 0.0034397, 0.099674, 0.0030028, 0.79866, 0.0014453, 0.26557, 0.076918, 0.097938, 0.017772]
Predicted label: 4
Correct prediction
Energy consumption = 153.625576 pJ
sum error= 258
Actual label: 1
Output voltages: [0.024441, 0.79852, 0.13884, 0.0064768, 0.19897, 0.0052194, 0.32333, 0.032458, 0.039792, 0.025765]
Predicted label: 1
Correct prediction
Energy consumption = 158.820597 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79628, 0.16471, 0.038495, 0.035462, 0.027108, 0.0057323, 0.78903, 0.0084765, 0.15972, 0.048502]
Predicted label: 0
Correct prediction
Energy consumption = 144.801428 pJ
sum error= 258
Actual label: 6
Output voltages: [0.093024, 0.026219, 0.29176, 0.0010703, 0.38494, 0.047606, 0.79879, 0.003224, 0.25167, 0.0029241]
Predicted label: 6
Correct prediction
Energy consumption = 135.078872 pJ
sum error= 258
Actual label: 0
Output voltages: [0.7987, 0.039, 0.041772, 0.014562, 0.0047804, 0.019794, 0.5438, 0.10771, 0.13699, 0.03045]
Predicted label: 0
Correct prediction
Energy consumption = 137.754738 pJ
sum error= 258
Actual label: 9
Output voltages: [0.23644, 0.012436, 0.014898, 0.029091, 0.42841, 0.028307, 0.019882, 0.012308, 0.089635, 0.79443]
Predicted label: 9
Correct prediction
Energy consumption = 142.832434 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 501 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 501 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 501 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.09912, 0.037974, 0.2963, 0.0028127, 0.32915, 0.043036, 0.79879, 0.0015699, 0.31941, 0.0023274]
Predicted label: 6
Correct prediction
Energy consumption = 165.614724 pJ
sum error= 258
Actual label: 8
Output voltages: [0.017851, 0.028469, 0.032642, 0.29303, 0.0020836, 0.30171, 0.0026735, 0.017752, 0.79874, 0.02244]
Predicted label: 8
Correct prediction
Energy consumption = 147.574652 pJ
sum error= 258
Actual label: 6
Output voltages: [0.048379, 0.13591, 0.42854, 0.0012893, 0.1921, 0.14461, 0.79875, 0.0037243, 0.27888, 0.002218]
Predicted label: 6
Correct prediction
Energy consumption = 152.153458 pJ
sum error= 258
Actual label: 1
Output voltages: [0.0058215, 0.79876, 0.0972, 0.043187, 0.019385, 0.0011579, 0.59782, 0.0029301, 0.14309, 0.0080769]
Predicted label: 1
Correct prediction
Energy consumption = 156.308441 pJ
sum error= 258
Actual label: 1
Output voltages: [0.0010668, 0.79866, 0.0085422, 0.022022, 0.17707, 0.003778, 0.47167, 0.0032221, 0.57028, 0.057648]
Predicted label: 1
Correct prediction
Energy consumption = 153.878769 pJ
sum error= 258
Actual label: 9
Output voltages: [0.10141, 0.0063172, 0.034755, 0.40354, 0.19066, 0.02453, 0.011856, 0.022888, 0.58167, 0.77069]
Predicted label: 9
Correct prediction
Energy consumption = 154.485988 pJ
sum error= 258
Actual label: 8
Output voltages: [0.018897, 0.031436, 0.21075, 0.17176, 0.010013, 0.1279, 0.026812, 0.0024939, 0.79879, 0.29498]
Predicted label: 8
Correct prediction
Energy consumption = 141.599515 pJ
sum error= 258
Actual label: 9
Output voltages: [0.092575, 0.032353, 0.019434, 0.38832, 0.070222, 0.037603, 0.086963, 0.070577, 0.058108, 0.79834]
Predicted label: 9
Correct prediction
Energy consumption = 148.656660 pJ
sum error= 258
Actual label: 2
Output voltages: [0.4888, 0.0054552, 0.79874, 0.050199, 0.02807, 0.0010659, 0.032986, 0.068835, 0.44134, 0.0036323]
Predicted label: 2
Correct prediction
Energy consumption = 146.787124 pJ
sum error= 258
Actual label: 3
Output voltages: [0.26906, 0.036789, 0.35929, 0.79876, 0.016976, 0.022353, 0.0041575, 0.026291, 0.7541, 0.020675]
Predicted label: 3
Correct prediction
Energy consumption = 143.415392 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 502 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 502 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 502 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.031954, 0.001205, 0.001108, 0.51529, 0.041314, 0.79875, 0.25431, 0.025115, 0.70283, 0.17289]
Predicted label: 5
Correct prediction
Energy consumption = 170.475265 pJ
sum error= 258
Actual label: 5
Output voltages: [0.20628, 0.0010973, 0.0010778, 0.41752, 0.027922, 0.79866, 0.090556, 0.027663, 0.60197, 0.042722]
Predicted label: 5
Correct prediction
Energy consumption = 134.885658 pJ
sum error= 258
Actual label: 9
Output voltages: [0.087963, 0.017808, 0.025564, 0.029762, 0.059686, 0.049164, 0.021613, 0.034758, 0.53197, 0.79841]
Predicted label: 9
Correct prediction
Energy consumption = 148.487207 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0059687, 0.0087105, 0.020395, 0.017355, 0.7987, 0.0012851, 0.28952, 0.1303, 0.071862, 0.0069464]
Predicted label: 4
Correct prediction
Energy consumption = 146.562673 pJ
sum error= 258
Actual label: 2
Output voltages: [0.58397, 0.083586, 0.79872, 0.3747, 0.017784, 0.0012049, 0.12926, 0.042576, 0.43749, 0.034596]
Predicted label: 2
Correct prediction
Energy consumption = 151.114048 pJ
sum error= 258
Actual label: 1
Output voltages: [0.038706, 0.79877, 0.24511, 0.010741, 0.63166, 0.0018464, 0.17003, 0.0024776, 0.033289, 0.02944]
Predicted label: 1
Correct prediction
Energy consumption = 154.309511 pJ
sum error= 258
Actual label: 9
Output voltages: [0.31932, 0.011369, 0.013271, 0.15738, 0.338, 0.0085013, 0.0012153, 0.0098981, 0.40093, 0.79745]
Predicted label: 9
Correct prediction
Energy consumption = 154.961462 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0031646, 0.0018265, 0.028044, 0.029409, 0.79878, 0.0010861, 0.038208, 0.051993, 0.15955, 0.008406]
Predicted label: 4
Correct prediction
Energy consumption = 147.693758 pJ
sum error= 258
Actual label: 3
Output voltages: [0.21486, 0.028251, 0.041175, 0.79856, 0.02145, 0.022495, 0.012688, 0.028973, 0.58864, 0.073955]
Predicted label: 3
Correct prediction
Energy consumption = 143.230150 pJ
sum error= 258
Actual label: 9
Output voltages: [0.36735, 0.015533, 0.010932, 0.12723, 0.12138, 0.018308, 0.0061047, 0.079833, 0.35647, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 146.172647 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 503 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 503 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 503 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.097079, 0.015996, 0.22139, 0.0010735, 0.59881, 0.057776, 0.79872, 0.0014499, 0.5971, 0.013384]
Predicted label: 6
Correct prediction
Energy consumption = 161.465929 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79862, 0.027829, 0.37205, 0.015027, 0.028464, 0.0010757, 0.38917, 0.034879, 0.24551, 0.041624]
Predicted label: 0
Correct prediction
Energy consumption = 142.076658 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0039122, 0.0091815, 0.11333, 0.010833, 0.79854, 0.0033909, 0.054835, 0.046369, 0.056919, 0.024785]
Predicted label: 4
Correct prediction
Energy consumption = 153.047756 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79873, 0.057751, 0.075105, 0.017715, 0.029518, 0.0049395, 0.14735, 0.012827, 0.23539, 0.02573]
Predicted label: 0
Correct prediction
Energy consumption = 148.934589 pJ
sum error= 258
Actual label: 6
Output voltages: [0.050747, 0.064493, 0.056057, 0.0051496, 0.1882, 0.353, 0.79869, 0.0021339, 0.60258, 0.0061269]
Predicted label: 6
Correct prediction
Energy consumption = 147.101440 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79407, 0.035116, 0.03295, 0.0092486, 0.012144, 0.0018098, 0.77674, 0.0075477, 0.31525, 0.036301]
Predicted label: 0
Correct prediction
Energy consumption = 137.801592 pJ
sum error= 258
Actual label: 1
Output voltages: [0.028899, 0.79861, 0.32472, 0.0035186, 0.040207, 0.0032609, 0.60288, 0.0087019, 0.061478, 0.011937]
Predicted label: 1
Correct prediction
Energy consumption = 153.589509 pJ
sum error= 258
Actual label: 2
Output voltages: [0.27909, 0.024646, 0.79879, 0.054476, 0.011508, 0.0011272, 0.037166, 0.26728, 0.72862, 0.0010976]
Predicted label: 2
Correct prediction
Energy consumption = 147.460309 pJ
sum error= 258
Actual label: 3
Output voltages: [0.40309, 0.0012066, 0.27151, 0.7976, 0.013151, 0.30972, 0.0096247, 0.0021713, 0.77757, 0.0073685]
Predicted label: 3
Correct prediction
Energy consumption = 142.313657 pJ
sum error= 258
Actual label: 4
Output voltages: [0.015966, 0.0060902, 0.093811, 0.040688, 0.79868, 0.012595, 0.022163, 0.018965, 0.052454, 0.021749]
Predicted label: 4
Correct prediction
Energy consumption = 147.735391 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 504 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 504 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 504 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.076407, 0.1156, 0.37915, 0.010054, 0.036597, 0.0010659, 0.0011383, 0.79877, 0.052379, 0.50962]
Predicted label: 7
Correct prediction
Energy consumption = 164.272274 pJ
sum error= 258
Actual label: 8
Output voltages: [0.037017, 0.026776, 0.041174, 0.37556, 0.0029307, 0.033457, 0.0057254, 0.0019929, 0.79872, 0.22988]
Predicted label: 8
Correct prediction
Energy consumption = 145.254763 pJ
sum error= 258
Actual label: 9
Output voltages: [0.02979, 0.0055426, 0.013156, 0.34094, 0.016564, 0.0032266, 0.0014062, 0.40559, 0.6915, 0.78646]
Predicted label: 9
Correct prediction
Energy consumption = 146.324328 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79877, 0.097068, 0.025269, 0.013015, 0.0019188, 0.01163, 0.55354, 0.036622, 0.44289, 0.027602]
Predicted label: 0
Correct prediction
Energy consumption = 141.599773 pJ
sum error= 258
Actual label: 1
Output voltages: [0.0287, 0.79865, 0.54947, 0.019407, 0.069438, 0.0012182, 0.72108, 0.0040085, 0.22103, 0.030604]
Predicted label: 1
Correct prediction
Energy consumption = 163.021467 pJ
sum error= 258
Actual label: 2
Output voltages: [0.46072, 0.033761, 0.79878, 0.14225, 0.015542, 0.0013024, 0.13979, 0.086024, 0.39181, 0.034162]
Predicted label: 2
Correct prediction
Energy consumption = 146.124098 pJ
sum error= 258
Actual label: 3
Output voltages: [0.31547, 0.001202, 0.081296, 0.79879, 0.053176, 0.20704, 0.036013, 0.008224, 0.51636, 0.0040866]
Predicted label: 3
Correct prediction
Energy consumption = 143.023369 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0037282, 0.0027771, 0.21149, 0.024953, 0.79876, 0.0042515, 0.018854, 0.041707, 0.36173, 0.016873]
Predicted label: 4
Correct prediction
Energy consumption = 144.655940 pJ
sum error= 258
Actual label: 7
Output voltages: [0.017031, 0.2361, 0.57358, 0.032059, 0.0080018, 0.0010786, 0.0010957, 0.79878, 0.33789, 0.17472]
Predicted label: 7
Correct prediction
Energy consumption = 143.685939 pJ
sum error= 258
Actual label: 8
Output voltages: [0.019483, 0.0035465, 0.026401, 0.25185, 0.0017459, 0.25171, 0.025242, 0.0047273, 0.79879, 0.039579]
Predicted label: 8
Correct prediction
Energy consumption = 141.999690 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 505 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 505 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 505 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33065, 0.014054, 0.020419, 0.06072, 0.048985, 0.043395, 0.0032499, 0.045765, 0.5247, 0.79822]
Predicted label: 9
Correct prediction
Energy consumption = 168.670582 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79879, 0.023553, 0.014919, 0.0056592, 0.0060302, 0.011014, 0.68339, 0.014672, 0.25595, 0.019997]
Predicted label: 0
Correct prediction
Energy consumption = 142.883145 pJ
sum error= 258
Actual label: 1
Output voltages: [0.0064098, 0.79879, 0.019767, 0.052092, 0.21429, 0.0012286, 0.15251, 0.024129, 0.35164, 0.074417]
Predicted label: 1
Correct prediction
Energy consumption = 163.352788 pJ
sum error= 258
Actual label: 2
Output voltages: [0.16615, 0.030364, 0.79877, 0.019584, 0.0053449, 0.001066, 0.098435, 0.01557, 0.76179, 0.022315]
Predicted label: 2
Correct prediction
Energy consumption = 136.496824 pJ
sum error= 258
Actual label: 3
Output voltages: [0.31441, 0.0017072, 0.21484, 0.79879, 0.17683, 0.036406, 0.0034811, 0.0011593, 0.52755, 0.022615]
Predicted label: 3
Correct prediction
Energy consumption = 140.190540 pJ
sum error= 258
Actual label: 4
Output voltages: [0.020811, 0.0019927, 0.10869, 0.020457, 0.79864, 0.0014663, 0.13238, 0.073053, 0.034253, 0.010933]
Predicted label: 4
Correct prediction
Energy consumption = 137.145405 pJ
sum error= 258
Actual label: 5
Output voltages: [0.31015, 0.0012386, 0.0011256, 0.19629, 0.045084, 0.79867, 0.64326, 0.023046, 0.77585, 0.0033077]
Predicted label: 5
Correct prediction
Energy consumption = 138.974329 pJ
sum error= 258
Actual label: 6
Output voltages: [0.11036, 0.31878, 0.22467, 0.003055, 0.059704, 0.20195, 0.79868, 0.0014113, 0.36381, 0.0098968]
Predicted label: 6
Correct prediction
Energy consumption = 145.252312 pJ
sum error= 258
Actual label: 7
Output voltages: [0.033109, 0.204, 0.61268, 0.039003, 0.0094919, 0.0010861, 0.00107, 0.79879, 0.27026, 0.25871]
Predicted label: 7
Correct prediction
Energy consumption = 150.886403 pJ
sum error= 258
Actual label: 8
Output voltages: [0.0033567, 0.034671, 0.11919, 0.082517, 0.0036573, 0.048939, 0.020299, 0.021177, 0.79869, 0.20307]
Predicted label: 8
Correct prediction
Energy consumption = 143.915954 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 506 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 506 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 506 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.27332, 0.014058, 0.019343, 0.029763, 0.041764, 0.12046, 0.01112, 0.077087, 0.63777, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 159.283578 pJ
sum error= 258
Actual label: 8
Output voltages: [0.020019, 0.036626, 0.10741, 0.036817, 0.014816, 0.16707, 0.03449, 0.21798, 0.79855, 0.021894]
Predicted label: 8
Correct prediction
Energy consumption = 150.557093 pJ
sum error= 258
Actual label: 3
Output voltages: [0.044374, 0.039579, 0.060094, 0.79829, 0.0034595, 0.03313, 0.01143, 0.0011818, 0.76736, 0.2706]
Predicted label: 3
Correct prediction
Energy consumption = 144.756595 pJ
sum error= 258
Actual label: 4
Output voltages: [0.015572, 0.042066, 0.034484, 0.0040384, 0.79875, 0.0025729, 0.044045, 0.18741, 0.043894, 0.0060241]
Predicted label: 4
Correct prediction
Energy consumption = 150.374920 pJ
sum error= 258
Actual label: 7
Output voltages: [0.081797, 0.13087, 0.67831, 0.021767, 0.0043483, 0.0011941, 0.0012418, 0.79878, 0.26846, 0.053151]
Predicted label: 7
Correct prediction
Energy consumption = 148.225721 pJ
sum error= 258
Actual label: 8
Output voltages: [0.066346, 0.0026465, 0.036712, 0.052963, 0.013415, 0.068569, 0.24983, 0.0010663, 0.79875, 0.15495]
Predicted label: 8
Correct prediction
Energy consumption = 155.996155 pJ
sum error= 258
Actual label: 6
Output voltages: [0.28109, 0.010529, 0.022495, 0.018847, 0.17514, 0.2936, 0.79877, 0.0011495, 0.37215, 0.0093351]
Predicted label: 6
Correct prediction
Energy consumption = 144.717333 pJ
sum error= 258
Actual label: 3
Output voltages: [0.30399, 0.0010696, 0.64354, 0.78724, 0.010242, 0.0011426, 0.016996, 0.017552, 0.77043, 0.024329]
Predicted label: 3
Correct prediction
Energy consumption = 144.637365 pJ
sum error= 258
Actual label: 4
Output voltages: [0.035407, 0.29468, 0.0060244, 0.28023, 0.79831, 0.0010991, 0.075928, 0.032845, 0.084606, 0.21885]
Predicted label: 4
Correct prediction
Energy consumption = 152.440076 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79872, 0.1682, 0.046741, 0.024813, 0.0039904, 0.0021107, 0.62554, 0.0323, 0.2348, 0.020838]
Predicted label: 0
Correct prediction
Energy consumption = 143.271893 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 507 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 507 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 507 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.43529, 0.028949, 0.011279, 0.14961, 0.58352, 0.044829, 0.035569, 0.0057846, 0.038967, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 168.202424 pJ
sum error= 258
Actual label: 7
Output voltages: [0.11765, 0.016559, 0.0275, 0.042571, 0.018264, 0.0032512, 0.0010722, 0.79856, 0.053346, 0.23575]
Predicted label: 7
Correct prediction
Energy consumption = 148.229986 pJ
sum error= 258
Actual label: 1
Output voltages: [0.037434, 0.79877, 0.28618, 0.029222, 0.41061, 0.0010932, 0.037335, 0.0087008, 0.015295, 0.038457]
Predicted label: 1
Correct prediction
Energy consumption = 157.020415 pJ
sum error= 258
Actual label: 9
Output voltages: [0.10317, 0.014319, 0.026712, 0.34507, 0.1605, 0.010172, 0.0010765, 0.029278, 0.51361, 0.79765]
Predicted label: 9
Correct prediction
Energy consumption = 149.650617 pJ
sum error= 258
Actual label: 3
Output voltages: [0.0568, 0.0039684, 0.027336, 0.79879, 0.17212, 0.45564, 0.020877, 0.0092024, 0.77245, 0.048331]
Predicted label: 3
Correct prediction
Energy consumption = 144.773301 pJ
sum error= 258
Actual label: 8
Output voltages: [0.012209, 0.034519, 0.25036, 0.082661, 0.0072702, 0.068146, 0.012607, 0.028937, 0.79873, 0.07241]
Predicted label: 8
Correct prediction
Energy consumption = 141.762129 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0022556, 0.010572, 0.039248, 0.020225, 0.79864, 0.0025337, 0.28293, 0.37278, 0.03581, 0.0041115]
Predicted label: 4
Correct prediction
Energy consumption = 149.070741 pJ
sum error= 258
Actual label: 7
Output voltages: [0.15075, 0.25771, 0.75001, 0.015814, 0.011292, 0.0011106, 0.0010664, 0.79868, 0.4497, 0.051265]
Predicted label: 7
Correct prediction
Energy consumption = 146.269979 pJ
sum error= 258
Actual label: 3
Output voltages: [0.23974, 0.0018645, 0.26564, 0.79876, 0.04518, 0.15084, 0.0027853, 0.0031545, 0.76055, 0.0066644]
Predicted label: 3
Correct prediction
Energy consumption = 143.639679 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79879, 0.023249, 0.041245, 0.018327, 0.014863, 0.0068009, 0.48921, 0.016748, 0.082258, 0.045461]
Predicted label: 0
Correct prediction
Energy consumption = 146.529286 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 508 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 508 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 508 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.44201, 0.036504, 0.030396, 0.20427, 0.18063, 0.063571, 0.021928, 0.056396, 0.67498, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 167.325200 pJ
sum error= 258
Actual label: 1
Output voltages: [0.003152, 0.79866, 0.034834, 0.038807, 0.063125, 0.0010778, 0.35181, 0.006786, 0.20127, 0.12453]
Predicted label: 1
Correct prediction
Energy consumption = 164.710146 pJ
sum error= 258
Actual label: 4
Output voltages: [0.002528, 0.0066182, 0.090329, 0.072484, 0.79873, 0.0011354, 0.019359, 0.027994, 0.12052, 0.039798]
Predicted label: 4
Correct prediction
Energy consumption = 145.058297 pJ
sum error= 258
Actual label: 5
Output voltages: [0.12769, 0.0031702, 0.0026194, 0.21724, 0.041163, 0.79865, 0.46668, 0.020018, 0.78268, 0.0016418]
Predicted label: 5
Correct prediction
Energy consumption = 141.491428 pJ
sum error= 258
Actual label: 4
Output voltages: [0.00326, 0.015504, 0.20351, 0.031127, 0.79871, 0.0015253, 0.020297, 0.032886, 0.14683, 0.029142]
Predicted label: 4
Correct prediction
Energy consumption = 149.096948 pJ
sum error= 258
Actual label: 6
Output voltages: [0.18777, 0.030328, 0.24915, 0.0021215, 0.46284, 0.12535, 0.79875, 0.0014931, 0.44094, 0.0121]
Predicted label: 6
Correct prediction
Energy consumption = 149.643199 pJ
sum error= 258
Actual label: 2
Output voltages: [0.23154, 0.0068125, 0.79845, 0.080774, 0.14337, 0.0012163, 0.03017, 0.0077564, 0.72343, 0.047948]
Predicted label: 2
Correct prediction
Energy consumption = 143.202217 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79872, 0.052717, 0.012593, 0.022811, 0.0079011, 0.014029, 0.34059, 0.030122, 0.18294, 0.028441]
Predicted label: 0
Correct prediction
Energy consumption = 142.614271 pJ
sum error= 258
Actual label: 6
Output voltages: [0.4462, 0.022008, 0.31742, 0.001583, 0.26937, 0.025756, 0.79844, 0.001159, 0.57045, 0.010276]
Predicted label: 6
Correct prediction
Energy consumption = 139.251199 pJ
sum error= 258
Actual label: 2
Output voltages: [0.036042, 0.15937, 0.79877, 0.20834, 0.023618, 0.0011305, 0.061206, 0.033913, 0.62789, 0.045013]
Predicted label: 2
Correct prediction
Energy consumption = 140.357968 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 509 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 509 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 509 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.011892, 0.79721, 0.0025527, 0.0047221, 0.78737, 0.0011186, 0.22892, 0.0011018, 0.062447, 0.49877]
Predicted label: 1
Correct prediction
Energy consumption = 172.931269 pJ
sum error= 258
Actual label: 1
Output voltages: [0.044491, 0.79878, 0.026476, 0.012048, 0.77013, 0.0016821, 0.3194, 0.001066, 0.02912, 0.3734]
Predicted label: 1
Correct prediction
Energy consumption = 141.121794 pJ
sum error= 258
Actual label: 1
Output voltages: [0.0401, 0.79879, 0.090666, 0.030552, 0.22691, 0.001135, 0.2728, 0.0010735, 0.056877, 0.21762]
Predicted label: 1
Correct prediction
Energy consumption = 149.597281 pJ
sum error= 258
Actual label: 1
Output voltages: [0.029002, 0.79872, 0.22362, 0.021104, 0.28523, 0.001152, 0.27921, 0.023887, 0.017504, 0.19774]
Predicted label: 1
Correct prediction
Energy consumption = 147.490252 pJ
sum error= 258
Actual label: 7
Output voltages: [0.053677, 0.041504, 0.038188, 0.017723, 0.010042, 0.001317, 0.0010757, 0.79856, 0.21585, 0.07312]
Predicted label: 7
Correct prediction
Energy consumption = 148.847837 pJ
sum error= 258
Actual label: 2
Output voltages: [0.49098, 0.022507, 0.79861, 0.021375, 0.0057116, 0.0011513, 0.043416, 0.066571, 0.41448, 0.013296]
Predicted label: 2
Correct prediction
Energy consumption = 139.466412 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0057737, 0.017551, 0.04053, 0.034101, 0.79869, 0.0063911, 0.032773, 0.038457, 0.048711, 0.0036243]
Predicted label: 4
Correct prediction
Energy consumption = 147.489225 pJ
sum error= 258
Actual label: 7
Output voltages: [0.65233, 0.031315, 0.013434, 0.035126, 0.14922, 0.039429, 0.0010994, 0.79845, 0.22807, 0.12108]
Predicted label: 7
Correct prediction
Energy consumption = 149.578849 pJ
sum error= 258
Actual label: 5
Output voltages: [0.035446, 0.054321, 0.0010672, 0.48045, 0.028439, 0.79858, 0.14818, 0.005265, 0.4106, 0.0065553]
Predicted label: 5
Correct prediction
Energy consumption = 147.431596 pJ
sum error= 258
Actual label: 2
Output voltages: [0.14703, 0.07737, 0.79861, 0.034389, 0.031556, 0.0011042, 0.053122, 0.016916, 0.42719, 0.026914]
Predicted label: 2
Correct prediction
Energy consumption = 150.783350 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 510 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 510 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 510 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.24363, 0.015495, 0.0035602, 0.21099, 0.38692, 0.0030137, 0.0051793, 0.0012262, 0.31539, 0.79521]
Predicted label: 9
Correct prediction
Energy consumption = 170.158472 pJ
sum error= 258
Actual label: 4
Output voltages: [0.027701, 0.0079782, 0.056396, 0.057831, 0.79879, 0.0011146, 0.0102, 0.01889, 0.044597, 0.036638]
Predicted label: 4
Correct prediction
Energy consumption = 147.761301 pJ
sum error= 258
Actual label: 5
Output voltages: [0.19924, 0.0011411, 0.0010661, 0.47726, 0.024767, 0.79878, 0.48652, 0.017706, 0.75889, 0.0027589]
Predicted label: 5
Correct prediction
Energy consumption = 147.009913 pJ
sum error= 258
Actual label: 8
Output voltages: [0.0019775, 0.16346, 0.052457, 0.040755, 0.0061336, 0.052695, 0.011806, 0.066188, 0.79858, 0.033845]
Predicted label: 8
Correct prediction
Energy consumption = 134.656838 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0066379, 0.016101, 0.070654, 0.016867, 0.79864, 0.0072797, 0.17712, 0.26343, 0.022056, 0.013544]
Predicted label: 4
Correct prediction
Energy consumption = 152.174133 pJ
sum error= 258
Actual label: 2
Output voltages: [0.1481, 0.027159, 0.79879, 0.10204, 0.020394, 0.0011572, 0.10304, 0.27711, 0.46922, 0.014997]
Predicted label: 2
Correct prediction
Energy consumption = 144.496011 pJ
sum error= 258
Actual label: 9
Output voltages: [0.20764, 0.025985, 0.015949, 0.17416, 0.12222, 0.021851, 0.0058535, 0.033596, 0.5529, 0.79823]
Predicted label: 9
Correct prediction
Energy consumption = 144.878285 pJ
sum error= 258
Actual label: 7
Output voltages: [0.030096, 0.27464, 0.46834, 0.0092406, 0.025193, 0.0010713, 0.0010706, 0.79861, 0.13414, 0.040913]
Predicted label: 7
Correct prediction
Energy consumption = 144.487864 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79872, 0.026408, 0.026286, 0.014273, 0.016941, 0.013739, 0.54677, 0.032594, 0.23094, 0.02834]
Predicted label: 0
Correct prediction
Energy consumption = 145.747453 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79789, 0.18117, 0.30527, 0.014003, 0.0027334, 0.0011043, 0.39508, 0.022342, 0.3913, 0.044086]
Predicted label: 0
Correct prediction
Energy consumption = 134.230459 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 511 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 511 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 511 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.040685, 0.58571, 0.46228, 0.042477, 0.030253, 0.0010772, 0.0012002, 0.79876, 0.021808, 0.05751]
Predicted label: 7
Correct prediction
Energy consumption = 166.505920 pJ
sum error= 258
Actual label: 5
Output voltages: [0.43836, 0.0011016, 0.0011362, 0.52566, 0.039713, 0.79865, 0.2622, 0.02563, 0.66575, 0.025208]
Predicted label: 5
Correct prediction
Energy consumption = 140.932550 pJ
sum error= 258
Actual label: 1
Output voltages: [0.16421, 0.79875, 0.16501, 0.036914, 0.36552, 0.0011693, 0.59781, 0.0011014, 0.028767, 0.045688]
Predicted label: 1
Correct prediction
Energy consumption = 157.348749 pJ
sum error= 258
Actual label: 1
Output voltages: [0.015315, 0.79874, 0.03401, 0.035784, 0.74056, 0.0011315, 0.25436, 0.0015872, 0.0058561, 0.034584]
Predicted label: 1
Correct prediction
Energy consumption = 144.584843 pJ
sum error= 258
Actual label: 7
Output voltages: [0.72675, 0.017281, 0.075384, 0.010358, 0.10025, 0.0010923, 0.001151, 0.79875, 0.087055, 0.2643]
Predicted label: 7
Correct prediction
Energy consumption = 159.003172 pJ
sum error= 258
Actual label: 6
Output voltages: [0.26746, 0.054355, 0.045646, 0.01909, 0.30211, 0.27467, 0.79879, 0.0010904, 0.42737, 0.03254]
Predicted label: 6
Correct prediction
Energy consumption = 151.529033 pJ
sum error= 258
Actual label: 6
Output voltages: [0.1917, 0.026807, 0.22244, 0.0011492, 0.47134, 0.24993, 0.7987, 0.0011881, 0.42816, 0.0080393]
Predicted label: 6
Correct prediction
Energy consumption = 133.102006 pJ
sum error= 258
Actual label: 6
Output voltages: [0.1601, 0.29733, 0.38763, 0.0029815, 0.31868, 0.029362, 0.79875, 0.0010786, 0.44855, 0.020592]
Predicted label: 6
Correct prediction
Energy consumption = 134.494775 pJ
sum error= 258
Actual label: 8
Output voltages: [0.021885, 0.011841, 0.034312, 0.45227, 0.0014586, 0.3809, 0.031077, 0.011266, 0.79879, 0.12025]
Predicted label: 8
Correct prediction
Energy consumption = 148.426539 pJ
sum error= 258
Actual label: 2
Output voltages: [0.16295, 0.27194, 0.79879, 0.2433, 0.017879, 0.0011742, 0.041709, 0.0028395, 0.2586, 0.12984]
Predicted label: 2
Correct prediction
Energy consumption = 146.606527 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 512 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 512 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 512 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.039296, 0.073596, 0.79876, 0.43588, 0.01954, 0.0010889, 0.069689, 0.013257, 0.57007, 0.014822]
Predicted label: 2
Correct prediction
Energy consumption = 164.614309 pJ
sum error= 258
Actual label: 7
Output voltages: [0.029389, 0.21872, 0.033978, 0.0022731, 0.61636, 0.0010843, 0.0012021, 0.79717, 0.055581, 0.2062]
Predicted label: 7
Correct prediction
Energy consumption = 151.906582 pJ
sum error= 258
Actual label: 7
Output voltages: [0.079034, 0.41181, 0.44967, 0.011876, 0.0024351, 0.0011342, 0.0010681, 0.79869, 0.2181, 0.056375]
Predicted label: 7
Correct prediction
Energy consumption = 141.196193 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0041005, 0.010567, 0.10496, 0.017497, 0.79864, 0.010751, 0.1813, 0.54446, 0.028744, 0.0041446]
Predicted label: 4
Correct prediction
Energy consumption = 150.209795 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79871, 0.039302, 0.03031, 0.016121, 0.015366, 0.011818, 0.45051, 0.021771, 0.061431, 0.10565]
Predicted label: 0
Correct prediction
Energy consumption = 146.854062 pJ
sum error= 258
Actual label: 2
Output voltages: [0.10504, 0.15153, 0.79868, 0.014156, 0.012655, 0.0011721, 0.051086, 0.25943, 0.52241, 0.017508]
Predicted label: 2
Correct prediction
Energy consumption = 143.696203 pJ
sum error= 258
Actual label: 4
Output voltages: [0.040309, 0.025865, 0.3972, 0.10897, 0.79878, 0.0010661, 0.077151, 0.042243, 0.0064795, 0.0432]
Predicted label: 4
Correct prediction
Energy consumption = 147.816255 pJ
sum error= 258
Actual label: 2
Output voltages: [0.2243, 0.093095, 0.79863, 0.033821, 0.0057917, 0.0010777, 0.013612, 0.6604, 0.72078, 0.0096381]
Predicted label: 2
Correct prediction
Energy consumption = 141.446642 pJ
sum error= 258
Actual label: 1
Output voltages: [0.029194, 0.79868, 0.14897, 0.024404, 0.094727, 0.0010857, 0.42046, 0.0062821, 0.03345, 0.024513]
Predicted label: 1
Correct prediction
Energy consumption = 158.073607 pJ
sum error= 258
Actual label: 8
Output voltages: [0.016876, 0.016591, 0.023461, 0.31569, 0.001645, 0.22934, 0.012482, 0.00117, 0.79878, 0.082314]
Predicted label: 8
Correct prediction
Energy consumption = 150.533021 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 513 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 513 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 513 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.19633, 0.0020769, 0.018278, 0.082625, 0.35543, 0.0029232, 0.0011034, 0.050113, 0.4959, 0.79801]
Predicted label: 9
Correct prediction
Energy consumption = 166.496927 pJ
sum error= 258
Actual label: 6
Output voltages: [0.11442, 0.047613, 0.10688, 0.013051, 0.18744, 0.23923, 0.79877, 0.0049086, 0.68446, 0.032964]
Predicted label: 6
Correct prediction
Energy consumption = 152.199745 pJ
sum error= 258
Actual label: 1
Output voltages: [0.062462, 0.79879, 0.24132, 0.0032604, 0.65224, 0.0026728, 0.52185, 0.0011618, 0.54675, 0.36577]
Predicted label: 1
Correct prediction
Energy consumption = 155.672602 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79879, 0.045745, 0.08149, 0.018079, 0.0073352, 0.00312, 0.54199, 0.019139, 0.11914, 0.040841]
Predicted label: 0
Correct prediction
Energy consumption = 144.218735 pJ
sum error= 258
Actual label: 5
Output voltages: [0.38458, 0.001066, 0.0011134, 0.040358, 0.0143, 0.79874, 0.57398, 0.027195, 0.63554, 0.0024966]
Predicted label: 5
Correct prediction
Energy consumption = 137.327703 pJ
sum error= 258
Actual label: 9
Output voltages: [0.26986, 0.0057964, 0.032851, 0.059552, 0.23819, 0.028049, 0.0087819, 0.083648, 0.34765, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 141.848363 pJ
sum error= 258
Actual label: 6
Output voltages: [0.46383, 0.27373, 0.2554, 0.027643, 0.12649, 0.02156, 0.79869, 0.0011822, 0.56581, 0.0072151]
Predicted label: 6
Correct prediction
Energy consumption = 150.665842 pJ
sum error= 258
Actual label: 9
Output voltages: [0.31845, 0.011847, 0.03647, 0.012939, 0.044519, 0.027633, 0.0012861, 0.0404, 0.63672, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 149.109454 pJ
sum error= 258
Actual label: 8
Output voltages: [0.097683, 0.0040602, 0.019243, 0.032635, 0.013003, 0.61724, 0.028912, 0.0034916, 0.79879, 0.022799]
Predicted label: 8
Correct prediction
Energy consumption = 146.583410 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79803, 0.041312, 0.030245, 0.027064, 0.023202, 0.0017753, 0.67597, 0.017938, 0.17664, 0.044861]
Predicted label: 0
Correct prediction
Energy consumption = 144.647376 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 514 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 514 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 514 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.055969, 0.0011832, 0.10682, 0.58437, 0.0057764, 0.041209, 0.040938, 0.0010663, 0.77138, 0.010412]
Predicted label: 8
Wrong prediction!
Energy consumption = 159.636018 pJ
sum error= 259
Actual label: 0
Output voltages: [0.79862, 0.032344, 0.027042, 0.030164, 0.035358, 0.0029218, 0.62644, 0.018329, 0.54332, 0.03485]
Predicted label: 0
Correct prediction
Energy consumption = 143.580332 pJ
sum error= 259
Actual label: 8
Output voltages: [0.0016562, 0.09797, 0.30421, 0.17294, 0.0063336, 0.014187, 0.0023973, 0.14251, 0.79879, 0.021632]
Predicted label: 8
Correct prediction
Energy consumption = 148.693671 pJ
sum error= 259
Actual label: 3
Output voltages: [0.26449, 0.0010954, 0.13772, 0.79846, 0.0086856, 0.32581, 0.0081501, 0.016147, 0.72132, 0.0075735]
Predicted label: 3
Correct prediction
Energy consumption = 139.283180 pJ
sum error= 259
Actual label: 9
Output voltages: [0.35279, 0.0051667, 0.010508, 0.060197, 0.43016, 0.0047431, 0.0027285, 0.016894, 0.53702, 0.79507]
Predicted label: 9
Correct prediction
Energy consumption = 146.857116 pJ
sum error= 259
Actual label: 6
Output voltages: [0.7217, 0.034853, 0.020911, 0.0038098, 0.048733, 0.020398, 0.79868, 0.0034946, 0.27999, 0.016158]
Predicted label: 6
Correct prediction
Energy consumption = 144.358330 pJ
sum error= 259
Actual label: 3
Output voltages: [0.15078, 0.0071112, 0.19053, 0.79878, 0.049827, 0.29696, 0.025053, 0.010637, 0.74437, 0.033292]
Predicted label: 3
Correct prediction
Energy consumption = 146.639091 pJ
sum error= 259
Actual label: 0
Output voltages: [0.79873, 0.053753, 0.026999, 0.029898, 0.013434, 0.031847, 0.45723, 0.031457, 0.14308, 0.026639]
Predicted label: 0
Correct prediction
Energy consumption = 143.626963 pJ
sum error= 259
Actual label: 1
Output voltages: [0.0099689, 0.79879, 0.041378, 0.0092087, 0.33204, 0.0025799, 0.76758, 0.0011084, 0.21937, 0.11751]
Predicted label: 1
Correct prediction
Energy consumption = 159.435172 pJ
sum error= 259
Actual label: 2
Output voltages: [0.38678, 0.054532, 0.79879, 0.15968, 0.024491, 0.0012137, 0.40239, 0.024801, 0.76404, 0.030052]
Predicted label: 2
Correct prediction
Energy consumption = 144.020096 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 515 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 515 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 515 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36929, 0.0060797, 0.36986, 0.79872, 0.050184, 0.026376, 0.011477, 0.018764, 0.62134, 0.093725]
Predicted label: 3
Correct prediction
Energy consumption = 166.647743 pJ
sum error= 259
Actual label: 4
Output voltages: [0.0072361, 0.0060138, 0.055132, 0.032446, 0.79872, 0.0019753, 0.17188, 0.17535, 0.17175, 0.023167]
Predicted label: 4
Correct prediction
Energy consumption = 160.168012 pJ
sum error= 259
Actual label: 5
Output voltages: [0.032253, 0.0010676, 0.0013633, 0.40331, 0.20467, 0.79825, 0.042312, 0.019579, 0.77236, 0.016451]
Predicted label: 5
Correct prediction
Energy consumption = 138.642851 pJ
sum error= 259
Actual label: 6
Output voltages: [0.057243, 0.070468, 0.39055, 0.0012211, 0.18213, 0.19705, 0.7987, 0.0037676, 0.51586, 0.0073962]
Predicted label: 6
Correct prediction
Energy consumption = 138.762117 pJ
sum error= 259
Actual label: 7
Output voltages: [0.11659, 0.078622, 0.62968, 0.15886, 0.001966, 0.0010819, 0.0010811, 0.79879, 0.2366, 0.13267]
Predicted label: 7
Correct prediction
Energy consumption = 160.322085 pJ
sum error= 259
Actual label: 0
Output voltages: [0.79859, 0.024151, 0.064758, 0.0054811, 0.017486, 0.0013291, 0.71573, 0.013044, 0.097834, 0.08643]
Predicted label: 0
Correct prediction
Energy consumption = 139.298846 pJ
sum error= 259
Actual label: 1
Output voltages: [0.010232, 0.79858, 0.028113, 0.04235, 0.024828, 0.0010765, 0.75961, 0.0091665, 0.22737, 0.048416]
Predicted label: 1
Correct prediction
Energy consumption = 155.325922 pJ
sum error= 259
Actual label: 2
Output voltages: [0.31529, 0.31101, 0.79877, 0.41979, 0.022535, 0.0013509, 0.27352, 0.0054147, 0.24167, 0.028239]
Predicted label: 2
Correct prediction
Energy consumption = 148.357666 pJ
sum error= 259
Actual label: 3
Output voltages: [0.40397, 0.0093091, 0.20112, 0.79878, 0.0073189, 0.04005, 0.014794, 0.0088671, 0.31892, 0.030447]
Predicted label: 3
Correct prediction
Energy consumption = 136.270395 pJ
sum error= 259
Actual label: 4
Output voltages: [0.0024411, 0.016659, 0.36949, 0.0011304, 0.79862, 0.0012305, 0.038502, 0.038156, 0.17308, 0.48567]
Predicted label: 4
Correct prediction
Energy consumption = 151.284099 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 516 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 516 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 516 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.095125, 0.0010812, 0.0011303, 0.43851, 0.128, 0.79869, 0.2036, 0.0097172, 0.63699, 0.024459]
Predicted label: 5
Correct prediction
Energy consumption = 158.752520 pJ
sum error= 259
Actual label: 6
Output voltages: [0.045061, 0.033813, 0.24271, 0.001891, 0.31975, 0.17121, 0.79872, 0.0080917, 0.38568, 0.0085136]
Predicted label: 6
Correct prediction
Energy consumption = 142.426359 pJ
sum error= 259
Actual label: 7
Output voltages: [0.41681, 0.35837, 0.018134, 0.040294, 0.0013991, 0.0037889, 0.0087304, 0.78881, 0.027925, 0.55329]
Predicted label: 7
Correct prediction
Energy consumption = 160.704198 pJ
sum error= 259
Actual label: 8
Output voltages: [0.018217, 0.0042014, 0.15012, 0.037593, 0.0038738, 0.20822, 0.0085974, 0.0060072, 0.79876, 0.044084]
Predicted label: 8
Correct prediction
Energy consumption = 142.311194 pJ
sum error= 259
Actual label: 9
Output voltages: [0.24725, 0.012181, 0.02011, 0.044249, 0.046671, 0.0031437, 0.0041994, 0.008964, 0.63468, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 143.501168 pJ
sum error= 259
Actual label: 0
Output voltages: [0.7955, 0.20098, 0.13678, 0.0093172, 0.0026193, 0.0093628, 0.66981, 0.027861, 0.65812, 0.009429]
Predicted label: 0
Correct prediction
Energy consumption = 140.435545 pJ
sum error= 259
Actual label: 1
Output voltages: [0.19326, 0.79879, 0.010735, 0.012575, 0.41835, 0.0017145, 0.41302, 0.0030353, 0.32216, 0.040554]
Predicted label: 1
Correct prediction
Energy consumption = 155.043341 pJ
sum error= 259
Actual label: 2
Output voltages: [0.56523, 0.036492, 0.79879, 0.43823, 0.0014301, 0.0011291, 0.023717, 0.037862, 0.67443, 0.0085739]
Predicted label: 2
Correct prediction
Energy consumption = 143.345843 pJ
sum error= 259
Actual label: 3
Output voltages: [0.19507, 0.0276, 0.05707, 0.79863, 0.036404, 0.0054298, 0.013625, 0.021638, 0.62487, 0.072452]
Predicted label: 3
Correct prediction
Energy consumption = 139.084033 pJ
sum error= 259
Actual label: 4
Output voltages: [0.012363, 0.025873, 0.076777, 0.019933, 0.7987, 0.006335, 0.3172, 0.1433, 0.074761, 0.010216]
Predicted label: 4
Correct prediction
Energy consumption = 157.768656 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 517 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 517 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 517 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.029572, 0.0011867, 0.0012101, 0.67379, 0.13252, 0.79818, 0.054312, 0.04155, 0.7069, 0.026702]
Predicted label: 5
Correct prediction
Energy consumption = 158.715064 pJ
sum error= 259
Actual label: 6
Output voltages: [0.059819, 0.11963, 0.33662, 0.0015641, 0.19821, 0.11479, 0.79872, 0.0030611, 0.3625, 0.0064361]
Predicted label: 6
Correct prediction
Energy consumption = 141.011826 pJ
sum error= 259
Actual label: 7
Output voltages: [0.091522, 0.039627, 0.098864, 0.29001, 0.0096722, 0.017403, 0.0011396, 0.79847, 0.053843, 0.20009]
Predicted label: 7
Correct prediction
Energy consumption = 156.740232 pJ
sum error= 259
Actual label: 8
Output voltages: [0.024547, 0.0098718, 0.12323, 0.031816, 0.0048665, 0.20796, 0.20324, 0.011802, 0.79846, 0.019866]
Predicted label: 8
Correct prediction
Energy consumption = 147.782010 pJ
sum error= 259
Actual label: 5
Output voltages: [0.018229, 0.0010848, 0.014928, 0.10965, 0.0093638, 0.7984, 0.011376, 0.05706, 0.7945, 0.02694]
Predicted label: 5
Correct prediction
Energy consumption = 144.699235 pJ
sum error= 259
Actual label: 4
Output voltages: [0.011296, 0.021582, 0.039706, 0.017777, 0.79877, 0.0010678, 0.14827, 0.093409, 0.038575, 0.046401]
Predicted label: 4
Correct prediction
Energy consumption = 162.420627 pJ
sum error= 259
Actual label: 8
Output voltages: [0.030987, 0.029804, 0.32127, 0.0086723, 0.73561, 0.01488, 0.034524, 0.010394, 0.79638, 0.0030215]
Predicted label: 8
Correct prediction
Energy consumption = 136.067719 pJ
sum error= 259
Actual label: 7
Output voltages: [0.31631, 0.33362, 0.15031, 0.045628, 0.0029323, 0.0026693, 0.0017087, 0.79877, 0.071984, 0.14737]
Predicted label: 7
Correct prediction
Energy consumption = 155.031311 pJ
sum error= 259
Actual label: 4
Output voltages: [0.0035207, 0.010249, 0.18448, 0.01187, 0.79866, 0.0010662, 0.0442, 0.036955, 0.016184, 0.24023]
Predicted label: 4
Correct prediction
Energy consumption = 160.397464 pJ
sum error= 259
Actual label: 7
Output voltages: [0.17854, 0.0088171, 0.019402, 0.40285, 0.018617, 0.011167, 0.001112, 0.79872, 0.3848, 0.58134]
Predicted label: 7
Correct prediction
Energy consumption = 148.560867 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 518 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 518 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 518 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.14797, 0.024172, 0.13298, 0.32086, 0.0010725, 0.0041699, 0.001066, 0.79865, 0.050199, 0.089235]
Predicted label: 7
Correct prediction
Energy consumption = 174.069158 pJ
sum error= 259
Actual label: 3
Output voltages: [0.048419, 0.027045, 0.29809, 0.79867, 0.039469, 0.02002, 0.006582, 0.029832, 0.73379, 0.018641]
Predicted label: 3
Correct prediction
Energy consumption = 138.280734 pJ
sum error= 259
Actual label: 9
Output voltages: [0.36868, 0.0018701, 0.020231, 0.19292, 0.28628, 0.0016138, 0.0010672, 0.029336, 0.38063, 0.79598]
Predicted label: 9
Correct prediction
Energy consumption = 148.681884 pJ
sum error= 259
Actual label: 8
Output voltages: [0.0086802, 0.0045365, 0.022382, 0.012518, 0.24517, 0.055045, 0.019641, 0.025992, 0.79874, 0.008678]
Predicted label: 8
Correct prediction
Energy consumption = 146.919081 pJ
sum error= 259
Actual label: 8
Output voltages: [0.0043542, 0.025143, 0.012523, 0.14098, 0.014939, 0.099753, 0.0075003, 0.014626, 0.79878, 0.043731]
Predicted label: 8
Correct prediction
Energy consumption = 141.838677 pJ
sum error= 259
Actual label: 3
Output voltages: [0.14437, 0.009533, 0.055775, 0.79869, 0.025671, 0.11981, 0.017891, 0.021584, 0.75788, 0.01652]
Predicted label: 3
Correct prediction
Energy consumption = 135.741366 pJ
sum error= 259
Actual label: 1
Output voltages: [0.02743, 0.79854, 0.48112, 0.039483, 0.029731, 0.0010841, 0.43263, 0.0033583, 0.17534, 0.045361]
Predicted label: 1
Correct prediction
Energy consumption = 159.795523 pJ
sum error= 259
Actual label: 5
Output voltages: [0.050911, 0.0010672, 0.001471, 0.5492, 0.18027, 0.79854, 0.040401, 0.052461, 0.75692, 0.020691]
Predicted label: 5
Correct prediction
Energy consumption = 142.021905 pJ
sum error= 259
Actual label: 8
Output voltages: [0.021325, 0.004249, 0.0055289, 0.051413, 0.010557, 0.35367, 0.065042, 0.021099, 0.79872, 0.013541]
Predicted label: 8
Correct prediction
Energy consumption = 141.701474 pJ
sum error= 259
Actual label: 2
Output voltages: [0.12429, 0.1918, 0.79879, 0.14362, 0.0061677, 0.00114, 0.092801, 0.0014248, 0.67003, 0.037025]
Predicted label: 2
Correct prediction
Energy consumption = 141.660868 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 519 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 519 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 519 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.19293, 0.078189, 0.75793, 0.060846, 0.01081, 0.0010659, 0.001068, 0.79875, 0.092999, 0.28033]
Predicted label: 7
Correct prediction
Energy consumption = 169.067011 pJ
sum error= 259
Actual label: 4
Output voltages: [0.022755, 0.0032891, 0.10346, 0.0026027, 0.79866, 0.018391, 0.039967, 0.055645, 0.06878, 0.025727]
Predicted label: 4
Correct prediction
Energy consumption = 157.097161 pJ
sum error= 259
Actual label: 2
Output voltages: [0.59914, 0.028724, 0.79878, 0.18097, 0.0076714, 0.0013005, 0.065822, 0.092002, 0.63593, 0.015232]
Predicted label: 2
Correct prediction
Energy consumption = 149.208060 pJ
sum error= 259
Actual label: 1
Output voltages: [0.010388, 0.79858, 0.019825, 0.025544, 0.025911, 0.0024987, 0.7487, 0.0050799, 0.41062, 0.044408]
Predicted label: 1
Correct prediction
Energy consumption = 153.002105 pJ
sum error= 259
Actual label: 5
Output voltages: [0.032636, 0.0011707, 0.0014023, 0.35592, 0.24084, 0.79647, 0.26852, 0.0038484, 0.77444, 0.016193]
Predicted label: 5
Correct prediction
Energy consumption = 148.206942 pJ
sum error= 259
Actual label: 4
Output voltages: [0.016993, 0.0022251, 0.30531, 0.023792, 0.79867, 0.010732, 0.57474, 0.035079, 0.012763, 0.024359]
Predicted label: 4
Correct prediction
Energy consumption = 154.224137 pJ
sum error= 259
Actual label: 5
Output voltages: [0.027501, 0.0012784, 0.0010719, 0.29529, 0.33871, 0.79805, 0.47076, 0.0014693, 0.76488, 0.045952]
Predicted label: 5
Correct prediction
Energy consumption = 140.969686 pJ
sum error= 259
Actual label: 5
Output voltages: [0.05204, 0.0010946, 0.0010692, 0.28018, 0.47703, 0.79869, 0.27456, 0.010054, 0.7851, 0.031746]
Predicted label: 5
Correct prediction
Energy consumption = 127.185162 pJ
sum error= 259
Actual label: 8
Output voltages: [0.0030671, 0.030388, 0.023704, 0.018421, 0.077097, 0.03667, 0.031173, 0.019337, 0.79877, 0.017511]
Predicted label: 8
Correct prediction
Energy consumption = 140.042351 pJ
sum error= 259
Actual label: 6
Output voltages: [0.29868, 0.048306, 0.56374, 0.0010693, 0.51816, 0.003358, 0.79872, 0.0019583, 0.012317, 0.058675]
Predicted label: 6
Correct prediction
Energy consumption = 142.904976 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 520 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 520 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 520 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0079708, 0.0039257, 0.085499, 0.040404, 0.7987, 0.014058, 0.17997, 0.03468, 0.061384, 0.056285]
Predicted label: 4
Correct prediction
Energy consumption = 173.276410 pJ
sum error= 259
Actual label: 4
Output voltages: [0.37898, 0.0052606, 0.040564, 0.0073213, 0.74724, 0.0012687, 0.73472, 0.0010676, 0.033309, 0.74331]
Predicted label: 4
Correct prediction
Energy consumption = 153.373044 pJ
sum error= 259
Actual label: 4
Output voltages: [0.0023644, 0.0185, 0.15988, 0.0094841, 0.79855, 0.012683, 0.11272, 0.045344, 0.043366, 0.033363]
Predicted label: 4
Correct prediction
Energy consumption = 147.839849 pJ
sum error= 259
Actual label: 1
Output voltages: [0.13368, 0.79872, 0.54615, 0.43479, 0.22835, 0.0012807, 0.0047196, 0.01547, 0.03678, 0.073416]
Predicted label: 1
Correct prediction
Energy consumption = 165.706938 pJ
sum error= 259
Actual label: 8
Output voltages: [0.0074632, 0.084096, 0.11292, 0.23616, 0.0011116, 0.030966, 0.018642, 0.038989, 0.79874, 0.065114]
Predicted label: 8
Correct prediction
Energy consumption = 143.527009 pJ
sum error= 259
Actual label: 7
Output voltages: [0.039589, 0.063992, 0.75341, 0.023715, 0.0090851, 0.0010689, 0.001066, 0.7987, 0.43412, 0.37042]
Predicted label: 7
Correct prediction
Energy consumption = 144.850862 pJ
sum error= 259
Actual label: 5
Output voltages: [0.033335, 0.001082, 0.0010934, 0.34196, 0.17173, 0.79827, 0.47569, 0.028372, 0.68125, 0.038651]
Predicted label: 5
Correct prediction
Energy consumption = 142.322331 pJ
sum error= 259
Actual label: 5
Output voltages: [0.012799, 0.001066, 0.0013145, 0.053604, 0.32332, 0.79865, 0.42836, 0.0025344, 0.77417, 0.084163]
Predicted label: 5
Correct prediction
Energy consumption = 129.375724 pJ
sum error= 259
Actual label: 1
Output voltages: [0.023665, 0.79861, 0.050241, 0.0067571, 0.050943, 0.021092, 0.75685, 0.016039, 0.38545, 0.014936]
Predicted label: 1
Correct prediction
Energy consumption = 156.162956 pJ
sum error= 259
Actual label: 8
Output voltages: [0.12064, 0.0057081, 0.016526, 0.052778, 0.0084529, 0.33644, 0.46482, 0.005656, 0.79873, 0.011145]
Predicted label: 8
Correct prediction
Energy consumption = 140.999773 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 521 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 521 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 521 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.050779, 0.0011757, 0.038263, 0.27249, 0.036199, 0.36116, 0.001121, 0.67431, 0.63516, 0.5939]
Predicted label: 7
Wrong prediction!
Energy consumption = 170.961337 pJ
sum error= 260
Actual label: 1
Output voltages: [0.021782, 0.79844, 0.054671, 0.18594, 0.031587, 0.0025011, 0.48841, 0.027048, 0.062164, 0.068594]
Predicted label: 1
Correct prediction
Energy consumption = 169.817734 pJ
sum error= 260
Actual label: 3
Output voltages: [0.12119, 0.012965, 0.32119, 0.79879, 0.006785, 0.0012315, 0.011134, 0.010163, 0.78036, 0.00747]
Predicted label: 3
Correct prediction
Energy consumption = 147.082089 pJ
sum error= 260
Actual label: 6
Output voltages: [0.049373, 0.0098138, 0.10421, 0.0015816, 0.4982, 0.059321, 0.79877, 0.0010763, 0.72597, 0.0050865]
Predicted label: 6
Correct prediction
Energy consumption = 145.566087 pJ
sum error= 260
Actual label: 3
Output voltages: [0.042554, 0.018841, 0.19555, 0.79878, 0.023409, 0.010429, 0.0027583, 0.011495, 0.74139, 0.023096]
Predicted label: 3
Correct prediction
Energy consumption = 148.574054 pJ
sum error= 260
Actual label: 3
Output voltages: [0.031136, 0.02578, 0.11182, 0.79875, 0.021224, 0.0059875, 0.0071912, 0.015956, 0.75369, 0.086863]
Predicted label: 3
Correct prediction
Energy consumption = 129.613683 pJ
sum error= 260
Actual label: 2
Output voltages: [0.46436, 0.038839, 0.79876, 0.22678, 0.0088388, 0.0011576, 0.15307, 0.022955, 0.74856, 0.017989]
Predicted label: 2
Correct prediction
Energy consumption = 140.274977 pJ
sum error= 260
Actual label: 2
Output voltages: [0.12653, 0.029571, 0.78625, 0.73184, 0.0012767, 0.0011075, 0.1113, 0.0018412, 0.71868, 0.027809]
Predicted label: 2
Correct prediction
Energy consumption = 136.458881 pJ
sum error= 260
Actual label: 6
Output voltages: [0.042367, 0.02732, 0.20622, 0.0010662, 0.56472, 0.068186, 0.79878, 0.0013469, 0.17135, 0.01422]
Predicted label: 6
Correct prediction
Energy consumption = 146.561379 pJ
sum error= 260
Actual label: 9
Output voltages: [0.30473, 0.024224, 0.011343, 0.041245, 0.044767, 0.022172, 0.0016659, 0.0054364, 0.60084, 0.79807]
Predicted label: 9
Correct prediction
Energy consumption = 147.120647 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 522 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 522 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 522 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.35273, 0.010684, 0.027654, 0.024357, 0.20919, 0.018654, 0.005929, 0.0098226, 0.5637, 0.79865]
Predicted label: 9
Correct prediction
Energy consumption = 174.419097 pJ
sum error= 260
Actual label: 6
Output voltages: [0.6316, 0.012621, 0.34747, 0.001066, 0.63595, 0.0017226, 0.79418, 0.0016037, 0.020824, 0.1647]
Predicted label: 6
Correct prediction
Energy consumption = 146.907121 pJ
sum error= 260
Actual label: 5
Output voltages: [0.038498, 0.0010959, 0.0012149, 0.053062, 0.17778, 0.79841, 0.39605, 0.020529, 0.78491, 0.067223]
Predicted label: 5
Correct prediction
Energy consumption = 141.549902 pJ
sum error= 260
Actual label: 5
Output voltages: [0.029519, 0.0010825, 0.0036488, 0.194, 0.081814, 0.79848, 0.50834, 0.022679, 0.78881, 0.0027987]
Predicted label: 5
Correct prediction
Energy consumption = 127.148147 pJ
sum error= 260
Actual label: 3
Output voltages: [0.11125, 0.0057529, 0.044715, 0.79879, 0.03677, 0.1259, 0.0041953, 0.0027612, 0.76087, 0.038701]
Predicted label: 3
Correct prediction
Energy consumption = 137.676646 pJ
sum error= 260
Actual label: 3
Output voltages: [0.075198, 0.0095445, 0.1593, 0.79876, 0.10607, 0.02668, 0.017735, 0.016761, 0.78259, 0.042376]
Predicted label: 3
Correct prediction
Energy consumption = 131.122843 pJ
sum error= 260
Actual label: 8
Output voltages: [0.0032105, 0.012008, 0.070667, 0.057888, 0.014844, 0.041967, 0.091691, 0.011213, 0.79871, 0.043561]
Predicted label: 8
Correct prediction
Energy consumption = 135.215564 pJ
sum error= 260
Actual label: 1
Output voltages: [0.015668, 0.79871, 0.28338, 0.047698, 0.1443, 0.0010664, 0.74598, 0.0045335, 0.19965, 0.0084447]
Predicted label: 1
Correct prediction
Energy consumption = 158.260996 pJ
sum error= 260
Actual label: 6
Output voltages: [0.14845, 0.035905, 0.013223, 0.0010716, 0.79091, 0.15773, 0.74411, 0.026099, 0.0053056, 0.0032092]
Predicted label: 4
Wrong prediction!
Energy consumption = 152.712372 pJ
sum error= 261
Actual label: 5
Output voltages: [0.052981, 0.0018833, 0.001086, 0.67471, 0.03042, 0.79875, 0.065165, 0.013182, 0.64442, 0.039618]
Predicted label: 5
Correct prediction
Energy consumption = 147.993765 pJ
sum error= 261
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 523 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 523 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 523 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.046632, 0.032072, 0.2122, 0.0030619, 0.40316, 0.24675, 0.79876, 0.0013601, 0.76323, 0.0084028]
Predicted label: 6
Correct prediction
Energy consumption = 166.907557 pJ
sum error= 261
Actual label: 8
Output voltages: [0.0070206, 0.029247, 0.037978, 0.028801, 0.21373, 0.21797, 0.13256, 0.053031, 0.79863, 0.029034]
Predicted label: 8
Correct prediction
Energy consumption = 143.552030 pJ
sum error= 261
Actual label: 1
Output voltages: [0.013526, 0.79854, 0.020086, 0.031578, 0.023262, 0.0032924, 0.44941, 0.0061476, 0.19396, 0.031209]
Predicted label: 1
Correct prediction
Energy consumption = 151.264567 pJ
sum error= 261
Actual label: 9
Output voltages: [0.16334, 0.019738, 0.028227, 0.18067, 0.25856, 0.022837, 0.014952, 0.03718, 0.21695, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 158.509768 pJ
sum error= 261
Actual label: 7
Output voltages: [0.23045, 0.11684, 0.49292, 0.044558, 0.0027076, 0.0010946, 0.001068, 0.7987, 0.21265, 0.1383]
Predicted label: 7
Correct prediction
Energy consumption = 152.680661 pJ
sum error= 261
Actual label: 6
Output voltages: [0.067352, 0.030404, 0.16618, 0.002605, 0.67318, 0.027824, 0.79877, 0.0010658, 0.3238, 0.023698]
Predicted label: 6
Correct prediction
Energy consumption = 145.238335 pJ
sum error= 261
Actual label: 8
Output voltages: [0.0023354, 0.012955, 0.058849, 0.1273, 0.015707, 0.52194, 0.39775, 0.044085, 0.79877, 0.0061877]
Predicted label: 8
Correct prediction
Energy consumption = 153.205403 pJ
sum error= 261
Actual label: 3
Output voltages: [0.13966, 0.0097537, 0.47679, 0.79879, 0.0072253, 0.0010891, 0.015372, 0.016848, 0.76787, 0.0072502]
Predicted label: 3
Correct prediction
Energy consumption = 145.063485 pJ
sum error= 261
Actual label: 7
Output voltages: [0.69683, 0.0026709, 0.47008, 0.076128, 0.0058454, 0.0011538, 0.0010755, 0.79874, 0.087426, 0.026746]
Predicted label: 7
Correct prediction
Energy consumption = 148.003236 pJ
sum error= 261
Actual label: 4
Output voltages: [0.009977, 0.0091764, 0.042541, 0.0068745, 0.79868, 0.0019447, 0.026603, 0.04758, 0.054838, 0.014885]
Predicted label: 4
Correct prediction
Energy consumption = 147.062944 pJ
sum error= 261
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 524 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 524 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 524 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.21923, 0.05174, 0.032447, 0.62586, 0.0013453, 0.0027571, 0.0019125, 0.79601, 0.011973, 0.28605]
Predicted label: 7
Correct prediction
Energy consumption = 178.667478 pJ
sum error= 261
Actual label: 0
Output voltages: [0.79878, 0.21016, 0.057577, 0.018563, 0.005128, 0.005079, 0.61106, 0.0071292, 0.075931, 0.10496]
Predicted label: 0
Correct prediction
Energy consumption = 147.525352 pJ
sum error= 261
Actual label: 9
Output voltages: [0.073762, 0.0012507, 0.028325, 0.052433, 0.017861, 0.038764, 0.0022514, 0.71207, 0.56217, 0.77341]
Predicted label: 9
Correct prediction
Energy consumption = 149.053654 pJ
sum error= 261
Actual label: 0
Output voltages: [0.79875, 0.047142, 0.022749, 0.017086, 0.0055724, 0.011878, 0.57374, 0.0077432, 0.058924, 0.20146]
Predicted label: 0
Correct prediction
Energy consumption = 134.188310 pJ
sum error= 261
Actual label: 0
Output voltages: [0.7978, 0.0028155, 0.010936, 0.04002, 0.024639, 0.050415, 0.76167, 0.0014768, 0.047829, 0.58346]
Predicted label: 0
Correct prediction
Energy consumption = 132.839145 pJ
sum error= 261
Actual label: 3
Output voltages: [0.23106, 0.051568, 0.16572, 0.7986, 0.0087232, 0.020153, 0.0045143, 0.20182, 0.39744, 0.21801]
Predicted label: 3
Correct prediction
Energy consumption = 148.715026 pJ
sum error= 261
Actual label: 7
Output voltages: [0.045817, 0.076411, 0.7936, 0.053607, 0.0034265, 0.0012244, 0.0042563, 0.7798, 0.43331, 0.75098]
Predicted label: 2
Wrong prediction!
Energy consumption = 145.856123 pJ
sum error= 262
Actual label: 9
Output voltages: [0.52318, 0.021719, 0.007843, 0.21051, 0.40848, 0.0021279, 0.0010961, 0.0016547, 0.24675, 0.79824]
Predicted label: 9
Correct prediction
Energy consumption = 145.577790 pJ
sum error= 262
Actual label: 3
Output voltages: [0.15607, 0.010759, 0.099854, 0.79868, 0.043184, 0.01818, 0.0036655, 0.012223, 0.75185, 0.019919]
Predicted label: 3
Correct prediction
Energy consumption = 141.689703 pJ
sum error= 262
Actual label: 0
Output voltages: [0.79877, 0.099756, 0.018765, 0.018793, 0.019304, 0.0048179, 0.72989, 0.0096166, 0.2778, 0.043732]
Predicted label: 0
Correct prediction
Energy consumption = 146.131038 pJ
sum error= 262
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 525 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 525 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 525 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.03782, 0.0064875, 0.79878, 0.48091, 0.0065081, 0.0010751, 0.015859, 0.027331, 0.78127, 0.006978]
Predicted label: 2
Correct prediction
Energy consumption = 151.609953 pJ
sum error= 262
Actual label: 0
Output voltages: [0.79876, 0.027312, 0.058951, 0.01775, 0.0086169, 0.01724, 0.41465, 0.032547, 0.02623, 0.065372]
Predicted label: 0
Correct prediction
Energy consumption = 142.367930 pJ
sum error= 262
Actual label: 1
Output voltages: [0.017271, 0.79874, 0.027197, 0.052683, 0.39759, 0.0014914, 0.41148, 0.023216, 0.041144, 0.01466]
Predicted label: 1
Correct prediction
Energy consumption = 153.527376 pJ
sum error= 262
Actual label: 0
Output voltages: [0.79609, 0.037555, 0.61127, 0.019053, 0.0074597, 0.0010816, 0.46868, 0.02339, 0.46008, 0.02287]
Predicted label: 0
Correct prediction
Energy consumption = 146.917447 pJ
sum error= 262
Actual label: 1
Output voltages: [0.059395, 0.79876, 0.11549, 0.024366, 0.4418, 0.0022435, 0.73952, 0.0011243, 0.037564, 0.035153]
Predicted label: 1
Correct prediction
Energy consumption = 150.187577 pJ
sum error= 262
Actual label: 0
Output voltages: [0.79588, 0.29513, 0.19845, 0.01993, 0.0063832, 0.043595, 0.74978, 0.011125, 0.36541, 0.0067113]
Predicted label: 0
Correct prediction
Energy consumption = 155.258484 pJ
sum error= 262
Actual label: 4
Output voltages: [0.014249, 0.0063757, 0.31685, 0.0079017, 0.79869, 0.0024745, 0.11613, 0.032652, 0.014932, 0.058138]
Predicted label: 4
Correct prediction
Energy consumption = 152.444688 pJ
sum error= 262
Actual label: 0
Output voltages: [0.79879, 0.015786, 0.050253, 0.016128, 0.021137, 0.003761, 0.092917, 0.027413, 0.57271, 0.011419]
Predicted label: 0
Correct prediction
Energy consumption = 150.456163 pJ
sum error= 262
Actual label: 1
Output voltages: [0.18683, 0.7979, 0.11823, 0.0013377, 0.73359, 0.010978, 0.23665, 0.0010945, 0.24057, 0.13985]
Predicted label: 1
Correct prediction
Energy consumption = 149.079781 pJ
sum error= 262
Actual label: 0
Output voltages: [0.7986, 0.039046, 0.018443, 0.015153, 0.019098, 0.022015, 0.2, 0.020584, 0.041273, 0.024863]
Predicted label: 0
Correct prediction
Energy consumption = 143.204739 pJ
sum error= 262
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 526 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 526 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 526 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.034484, 0.0081952, 0.22398, 0.0013048, 0.79855, 0.0011259, 0.03799, 0.01961, 0.56939, 0.016051]
Predicted label: 4
Correct prediction
Energy consumption = 158.166494 pJ
sum error= 262
Actual label: 7
Output voltages: [0.032073, 0.053404, 0.78928, 0.012545, 0.003959, 0.0011442, 0.0010717, 0.79879, 0.33704, 0.29263]
Predicted label: 7
Correct prediction
Energy consumption = 151.862058 pJ
sum error= 262
Actual label: 9
Output voltages: [0.40261, 0.015767, 0.019182, 0.049813, 0.23805, 0.0071056, 0.0010816, 0.014252, 0.37729, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 150.282331 pJ
sum error= 262
Actual label: 6
Output voltages: [0.05309, 0.024034, 0.23608, 0.0010743, 0.3399, 0.11384, 0.79877, 0.0017101, 0.38917, 0.0030047]
Predicted label: 6
Correct prediction
Energy consumption = 143.750946 pJ
sum error= 262
Actual label: 2
Output voltages: [0.47694, 0.03963, 0.79879, 0.2454, 0.027884, 0.0011202, 0.30963, 0.0088347, 0.74826, 0.093807]
Predicted label: 2
Correct prediction
Energy consumption = 144.870860 pJ
sum error= 262
Actual label: 6
Output voltages: [0.032336, 0.003627, 0.13525, 0.0012503, 0.61732, 0.010346, 0.79877, 0.0010665, 0.38639, 0.010911]
Predicted label: 6
Correct prediction
Energy consumption = 138.213735 pJ
sum error= 262
Actual label: 2
Output voltages: [0.3791, 0.35201, 0.79829, 0.55011, 0.011633, 0.0011249, 0.1661, 0.003582, 0.53253, 0.050733]
Predicted label: 2
Correct prediction
Energy consumption = 151.576588 pJ
sum error= 262
Actual label: 2
Output voltages: [0.4735, 0.02018, 0.79877, 0.42117, 0.0032598, 0.001066, 0.048784, 0.052724, 0.7692, 0.026346]
Predicted label: 2
Correct prediction
Energy consumption = 130.631088 pJ
sum error= 262
Actual label: 9
Output voltages: [0.033717, 0.0010709, 0.042383, 0.031762, 0.026303, 0.027153, 0.0011484, 0.33318, 0.79442, 0.78129]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.407429 pJ
sum error= 263
Actual label: 9
Output voltages: [0.45909, 0.0018724, 0.2119, 0.0044308, 0.3524, 0.0020049, 0.0011742, 0.029305, 0.66035, 0.78871]
Predicted label: 9
Correct prediction
Energy consumption = 138.242030 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 527 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 527 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 527 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.027812, 0.02078, 0.01533, 0.051095, 0.020862, 0.65202, 0.012522, 0.16775, 0.061716]
Predicted label: 0
Correct prediction
Energy consumption = 173.231490 pJ
sum error= 263
Actual label: 1
Output voltages: [0.028446, 0.7986, 0.31209, 0.061084, 0.023319, 0.0011372, 0.72122, 0.0068597, 0.1167, 0.011978]
Predicted label: 1
Correct prediction
Energy consumption = 158.536711 pJ
sum error= 263
Actual label: 2
Output voltages: [0.58236, 0.017378, 0.79872, 0.30287, 0.0063332, 0.0011778, 0.0073326, 0.043666, 0.56356, 0.001806]
Predicted label: 2
Correct prediction
Energy consumption = 148.362475 pJ
sum error= 263
Actual label: 3
Output voltages: [0.36392, 0.0044459, 0.06153, 0.79869, 0.033754, 0.039046, 0.073246, 0.032963, 0.54835, 0.16104]
Predicted label: 3
Correct prediction
Energy consumption = 148.885733 pJ
sum error= 263
Actual label: 4
Output voltages: [0.0073709, 0.016736, 0.13822, 0.0075757, 0.79869, 0.014938, 0.18291, 0.30418, 0.089351, 0.0040097]
Predicted label: 4
Correct prediction
Energy consumption = 154.128997 pJ
sum error= 263
Actual label: 5
Output voltages: [0.06411, 0.0040645, 0.016266, 0.58794, 0.020333, 0.7985, 0.064665, 0.023605, 0.74888, 0.29008]
Predicted label: 5
Correct prediction
Energy consumption = 152.679153 pJ
sum error= 263
Actual label: 6
Output voltages: [0.18751, 0.02572, 0.10509, 0.0063299, 0.36197, 0.21076, 0.79871, 0.0012913, 0.56209, 0.010159]
Predicted label: 6
Correct prediction
Energy consumption = 143.972456 pJ
sum error= 263
Actual label: 7
Output voltages: [0.13838, 0.026887, 0.39359, 0.047598, 0.0075618, 0.0010716, 0.0015749, 0.7987, 0.24704, 0.025414]
Predicted label: 7
Correct prediction
Energy consumption = 160.085787 pJ
sum error= 263
Actual label: 8
Output voltages: [0.079189, 0.13462, 0.31441, 0.0038623, 0.0082601, 0.0012745, 0.026635, 0.018558, 0.79768, 0.55416]
Predicted label: 8
Correct prediction
Energy consumption = 141.662002 pJ
sum error= 263
Actual label: 9
Output voltages: [0.27084, 0.0054032, 0.023973, 0.015512, 0.16801, 0.016678, 0.0017779, 0.074106, 0.65741, 0.79683]
Predicted label: 9
Correct prediction
Energy consumption = 141.730745 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 528 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 528 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 528 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79405, 0.025708, 0.039483, 0.01869, 0.039854, 0.0025841, 0.75224, 0.0045146, 0.36917, 0.030571]
Predicted label: 0
Correct prediction
Energy consumption = 174.189822 pJ
sum error= 263
Actual label: 1
Output voltages: [0.026479, 0.79878, 0.21549, 0.016536, 0.4143, 0.00108, 0.34635, 0.0045949, 0.045886, 0.083295]
Predicted label: 1
Correct prediction
Energy consumption = 158.259686 pJ
sum error= 263
Actual label: 2
Output voltages: [0.72129, 0.013, 0.79879, 0.074347, 0.039912, 0.001066, 0.047933, 0.048897, 0.56855, 0.015275]
Predicted label: 2
Correct prediction
Energy consumption = 145.530120 pJ
sum error= 263
Actual label: 3
Output voltages: [0.034726, 0.013663, 0.3013, 0.79619, 0.012893, 0.0092473, 0.013159, 0.0097817, 0.77698, 0.24779]
Predicted label: 3
Correct prediction
Energy consumption = 141.934504 pJ
sum error= 263
Actual label: 4
Output voltages: [0.032971, 0.018663, 0.095497, 0.0039316, 0.79866, 0.0027527, 0.099574, 0.042628, 0.032949, 0.01202]
Predicted label: 4
Correct prediction
Energy consumption = 150.460012 pJ
sum error= 263
Actual label: 5
Output voltages: [0.03843, 0.001066, 0.00242, 0.12875, 0.082963, 0.79875, 0.14109, 0.016288, 0.78123, 0.24193]
Predicted label: 5
Correct prediction
Energy consumption = 146.283507 pJ
sum error= 263
Actual label: 6
Output voltages: [0.041954, 0.02871, 0.091647, 0.020543, 0.24903, 0.36688, 0.79879, 0.0020679, 0.76417, 0.0067097]
Predicted label: 6
Correct prediction
Energy consumption = 148.375238 pJ
sum error= 263
Actual label: 7
Output voltages: [0.54493, 0.19424, 0.016723, 0.12122, 0.010568, 0.019158, 0.0010789, 0.79865, 0.66287, 0.24101]
Predicted label: 7
Correct prediction
Energy consumption = 157.882975 pJ
sum error= 263
Actual label: 8
Output voltages: [0.31998, 0.012455, 0.58089, 0.001104, 0.023228, 0.0011442, 0.0080522, 0.015916, 0.79621, 0.42246]
Predicted label: 8
Correct prediction
Energy consumption = 142.202546 pJ
sum error= 263
Actual label: 9
Output voltages: [0.35506, 0.0082122, 0.021346, 0.025888, 0.061023, 0.035558, 0.001454, 0.12452, 0.58422, 0.79676]
Predicted label: 9
Correct prediction
Energy consumption = 148.490409 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 529 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 529 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 529 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79858, 0.037973, 0.22951, 0.0023513, 0.0086552, 0.0012196, 0.56277, 0.0067674, 0.3125, 0.2056]
Predicted label: 0
Correct prediction
Energy consumption = 170.857313 pJ
sum error= 263
Actual label: 1
Output voltages: [0.0015125, 0.79878, 0.089961, 0.029044, 0.18508, 0.0011633, 0.48492, 0.0014379, 0.41575, 0.050076]
Predicted label: 1
Correct prediction
Energy consumption = 156.601648 pJ
sum error= 263
Actual label: 2
Output voltages: [0.5855, 0.0013935, 0.79879, 0.28478, 0.0053881, 0.0013685, 0.022262, 0.12514, 0.57435, 0.0037351]
Predicted label: 2
Correct prediction
Energy consumption = 142.687959 pJ
sum error= 263
Actual label: 3
Output voltages: [0.63256, 0.01344, 0.16473, 0.7987, 0.06185, 0.0059119, 0.024949, 0.0085293, 0.63902, 0.055268]
Predicted label: 3
Correct prediction
Energy consumption = 141.337045 pJ
sum error= 263
Actual label: 4
Output voltages: [0.0087897, 0.0052071, 0.081611, 0.015995, 0.79866, 0.0045113, 0.16256, 0.07629, 0.032018, 0.010475]
Predicted label: 4
Correct prediction
Energy consumption = 153.867464 pJ
sum error= 263
Actual label: 5
Output voltages: [0.021897, 0.0012562, 0.022577, 0.2685, 0.026167, 0.79825, 0.037012, 0.025414, 0.78866, 0.045457]
Predicted label: 5
Correct prediction
Energy consumption = 152.326201 pJ
sum error= 263
Actual label: 6
Output voltages: [0.045659, 0.039368, 0.28218, 0.0013488, 0.15342, 0.073862, 0.79876, 0.0025027, 0.75351, 0.010534]
Predicted label: 6
Correct prediction
Energy consumption = 147.490155 pJ
sum error= 263
Actual label: 7
Output voltages: [0.25744, 0.020013, 0.3567, 0.059321, 0.0099962, 0.0011562, 0.0010846, 0.79869, 0.2711, 0.02934]
Predicted label: 7
Correct prediction
Energy consumption = 151.300718 pJ
sum error= 263
Actual label: 8
Output voltages: [0.069705, 0.16452, 0.49287, 0.012392, 0.021103, 0.0016433, 0.013019, 0.0048018, 0.79878, 0.22755]
Predicted label: 8
Correct prediction
Energy consumption = 141.854206 pJ
sum error= 263
Actual label: 9
Output voltages: [0.11871, 0.0096998, 0.028834, 0.029157, 0.03851, 0.061486, 0.0022684, 0.064, 0.74001, 0.79401]
Predicted label: 9
Correct prediction
Energy consumption = 145.925273 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 530 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 530 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 530 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.051318, 0.54752, 0.23571, 0.13804, 0.0081847, 0.0025521, 0.13603, 0.0036663, 0.79873, 0.41877]
Predicted label: 8
Correct prediction
Energy consumption = 172.000545 pJ
sum error= 263
Actual label: 0
Output voltages: [0.79794, 0.39679, 0.18698, 0.017221, 0.0045216, 0.0014185, 0.70223, 0.03921, 0.36961, 0.15384]
Predicted label: 0
Correct prediction
Energy consumption = 157.898077 pJ
sum error= 263
Actual label: 5
Output voltages: [0.015015, 0.0010847, 0.0050206, 0.45861, 0.023934, 0.78282, 0.020426, 0.027755, 0.69044, 0.19443]
Predicted label: 5
Correct prediction
Energy consumption = 150.533657 pJ
sum error= 263
Actual label: 6
Output voltages: [0.15553, 0.017689, 0.11814, 0.0046053, 0.48253, 0.5081, 0.79878, 0.0060968, 0.70173, 0.0027158]
Predicted label: 6
Correct prediction
Energy consumption = 147.625092 pJ
sum error= 263
Actual label: 6
Output voltages: [0.23828, 0.086763, 0.044312, 0.039628, 0.23191, 0.33428, 0.79878, 0.0059925, 0.6529, 0.028203]
Predicted label: 6
Correct prediction
Energy consumption = 142.592287 pJ
sum error= 263
Actual label: 0
Output voltages: [0.79879, 0.055159, 0.039772, 0.035246, 0.016111, 0.0050309, 0.5171, 0.03221, 0.056376, 0.17683]
Predicted label: 0
Correct prediction
Energy consumption = 148.238152 pJ
sum error= 263
Actual label: 8
Output voltages: [0.015137, 0.11328, 0.15115, 0.14751, 0.0046598, 0.033147, 0.0138, 0.0062982, 0.79872, 0.1423]
Predicted label: 8
Correct prediction
Energy consumption = 143.127409 pJ
sum error= 263
Actual label: 0
Output voltages: [0.79871, 0.22434, 0.15262, 0.018409, 0.11457, 0.013805, 0.30211, 0.017242, 0.44776, 0.077083]
Predicted label: 0
Correct prediction
Energy consumption = 150.560182 pJ
sum error= 263
Actual label: 2
Output voltages: [0.65405, 0.0010826, 0.79771, 0.73535, 0.0021567, 0.0011304, 0.0073276, 0.060494, 0.63602, 0.0093812]
Predicted label: 2
Correct prediction
Energy consumption = 139.364583 pJ
sum error= 263
Actual label: 3
Output voltages: [0.74506, 0.017874, 0.039317, 0.79869, 0.014714, 0.011756, 0.0067691, 0.0072722, 0.48357, 0.020573]
Predicted label: 3
Correct prediction
Energy consumption = 138.188977 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 531 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 531 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 531 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.032745, 0.02842, 0.7096, 0.018779, 0.0043712, 0.0012377, 0.0055452, 0.79878, 0.54878, 0.023803]
Predicted label: 7
Correct prediction
Energy consumption = 169.970986 pJ
sum error= 263
Actual label: 9
Output voltages: [0.36586, 0.0017189, 0.018886, 0.047861, 0.037281, 0.026188, 0.0011407, 0.36933, 0.55321, 0.77746]
Predicted label: 9
Correct prediction
Energy consumption = 152.618948 pJ
sum error= 263
Actual label: 4
Output voltages: [0.0076042, 0.0032766, 0.055966, 0.027463, 0.79872, 0.0014184, 0.074699, 0.020746, 0.030753, 0.016963]
Predicted label: 4
Correct prediction
Energy consumption = 146.785781 pJ
sum error= 263
Actual label: 7
Output voltages: [0.064844, 0.031952, 0.058963, 0.094327, 0.0076865, 0.0086894, 0.0010678, 0.79849, 0.1927, 0.20804]
Predicted label: 7
Correct prediction
Energy consumption = 145.868414 pJ
sum error= 263
Actual label: 1
Output voltages: [0.04304, 0.79879, 0.35558, 0.037989, 0.2482, 0.0027001, 0.79087, 0.0011231, 0.016403, 0.0088802]
Predicted label: 1
Correct prediction
Energy consumption = 159.015625 pJ
sum error= 263
Actual label: 9
Output voltages: [0.62619, 0.0015252, 0.014705, 0.031539, 0.24466, 0.014686, 0.0010662, 0.27433, 0.39432, 0.79482]
Predicted label: 9
Correct prediction
Energy consumption = 160.094747 pJ
sum error= 263
Actual label: 1
Output voltages: [0.038782, 0.79868, 0.41052, 0.010643, 0.21664, 0.0011578, 0.31983, 0.0089396, 0.021197, 0.031385]
Predicted label: 1
Correct prediction
Energy consumption = 160.645147 pJ
sum error= 263
Actual label: 7
Output voltages: [0.084615, 0.027237, 0.29159, 0.091241, 0.023796, 0.0023942, 0.0010828, 0.79849, 0.17894, 0.17182]
Predicted label: 7
Correct prediction
Energy consumption = 147.425179 pJ
sum error= 263
Actual label: 1
Output voltages: [0.0047365, 0.7986, 0.035076, 0.064095, 0.025431, 0.0010929, 0.6695, 0.016826, 0.06988, 0.035153]
Predicted label: 1
Correct prediction
Energy consumption = 154.595600 pJ
sum error= 263
Actual label: 4
Output voltages: [0.015871, 0.011275, 0.11826, 0.027532, 0.79871, 0.0010998, 0.58941, 0.063244, 0.002774, 0.0070956]
Predicted label: 4
Correct prediction
Energy consumption = 149.878487 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 532 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 532 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 532 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.024134, 0.011365, 0.20346, 0.0021725, 0.18218, 0.16498, 0.011846, 0.46558, 0.12215]
Predicted label: 0
Correct prediction
Energy consumption = 178.071328 pJ
sum error= 263
Actual label: 0
Output voltages: [0.79878, 0.11732, 0.030897, 0.021304, 0.029739, 0.0056498, 0.5746, 0.015063, 0.064246, 0.12852]
Predicted label: 0
Correct prediction
Energy consumption = 147.697406 pJ
sum error= 263
Actual label: 4
Output voltages: [0.025378, 0.017553, 0.038775, 0.030028, 0.79874, 0.0010723, 0.0049876, 0.020681, 0.019281, 0.30304]
Predicted label: 4
Correct prediction
Energy consumption = 157.052289 pJ
sum error= 263
Actual label: 1
Output voltages: [0.0053822, 0.79879, 0.013181, 0.0044424, 0.68259, 0.0049068, 0.39749, 0.017825, 0.22139, 0.048687]
Predicted label: 1
Correct prediction
Energy consumption = 158.708956 pJ
sum error= 263
Actual label: 7
Output voltages: [0.50375, 0.028826, 0.24409, 0.26799, 0.0036325, 0.0010659, 0.0011039, 0.79877, 0.14022, 0.049044]
Predicted label: 7
Correct prediction
Energy consumption = 159.070424 pJ
sum error= 263
Actual label: 5
Output voltages: [0.019641, 0.0035669, 0.0029983, 0.45912, 0.031334, 0.79879, 0.10247, 0.214, 0.74599, 0.35636]
Predicted label: 5
Correct prediction
Energy consumption = 146.071363 pJ
sum error= 263
Actual label: 7
Output voltages: [0.034092, 0.10811, 0.053704, 0.04446, 0.0075325, 0.0012335, 0.0013381, 0.79862, 0.17743, 0.17919]
Predicted label: 7
Correct prediction
Energy consumption = 151.817568 pJ
sum error= 263
Actual label: 1
Output voltages: [0.051889, 0.79876, 0.11054, 0.002665, 0.50688, 0.0011204, 0.30357, 0.0040426, 0.20019, 0.078543]
Predicted label: 1
Correct prediction
Energy consumption = 154.597466 pJ
sum error= 263
Actual label: 3
Output voltages: [0.15226, 0.0084562, 0.19782, 0.79873, 0.04223, 0.012236, 0.0054406, 0.042632, 0.65364, 0.21687]
Predicted label: 3
Correct prediction
Energy consumption = 154.545601 pJ
sum error= 263
Actual label: 3
Output voltages: [0.54219, 0.019072, 0.043256, 0.79867, 0.024027, 0.13754, 0.037737, 0.011764, 0.61869, 0.21733]
Predicted label: 3
Correct prediction
Energy consumption = 132.975501 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 533 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 533 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 533 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.48472, 0.013322, 0.032216, 0.79867, 0.014661, 0.029199, 0.023702, 0.015627, 0.6715, 0.046945]
Predicted label: 3
Correct prediction
Energy consumption = 167.444132 pJ
sum error= 263
Actual label: 1
Output voltages: [0.56393, 0.79832, 0.043091, 0.13234, 0.056375, 0.18239, 0.79841, 0.0030356, 0.12503, 0.0026961]
Predicted label: 6
Wrong prediction!
Energy consumption = 162.463801 pJ
sum error= 264
Actual label: 6
Output voltages: [0.08103, 0.012417, 0.36599, 0.0047249, 0.23163, 0.2371, 0.79878, 0.0010663, 0.64206, 0.08777]
Predicted label: 6
Correct prediction
Energy consumption = 147.631797 pJ
sum error= 264
Actual label: 9
Output voltages: [0.42955, 0.0013348, 0.0078842, 0.028105, 0.32329, 0.01833, 0.0011445, 0.040552, 0.62319, 0.79739]
Predicted label: 9
Correct prediction
Energy consumption = 150.437590 pJ
sum error= 264
Actual label: 7
Output voltages: [0.45817, 0.0056579, 0.54412, 0.21339, 0.0026091, 0.0012045, 0.0010708, 0.79878, 0.30712, 0.017584]
Predicted label: 7
Correct prediction
Energy consumption = 148.554617 pJ
sum error= 264
Actual label: 4
Output voltages: [0.010307, 0.0044984, 0.052904, 0.043576, 0.79868, 0.0010799, 0.051997, 0.028571, 0.015821, 0.032354]
Predicted label: 4
Correct prediction
Energy consumption = 145.548582 pJ
sum error= 264
Actual label: 3
Output voltages: [0.18004, 0.0041953, 0.33847, 0.7987, 0.033843, 0.018487, 0.02323, 0.0061147, 0.48792, 0.2316]
Predicted label: 3
Correct prediction
Energy consumption = 147.100579 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79871, 0.08722, 0.040533, 0.0035564, 0.0086902, 0.0044969, 0.67836, 0.012676, 0.042622, 0.11805]
Predicted label: 0
Correct prediction
Energy consumption = 156.395952 pJ
sum error= 264
Actual label: 2
Output voltages: [0.45788, 0.0086077, 0.79871, 0.26231, 0.015991, 0.0010715, 0.022903, 0.016263, 0.51072, 0.0061093]
Predicted label: 2
Correct prediction
Energy consumption = 146.206139 pJ
sum error= 264
Actual label: 5
Output voltages: [0.30883, 0.0010715, 0.005947, 0.65373, 0.016395, 0.79835, 0.0032711, 0.041814, 0.72663, 0.055664]
Predicted label: 5
Correct prediction
Energy consumption = 145.859006 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 534 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 534 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 534 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.45832, 0.0099414, 0.79868, 0.028001, 0.027495, 0.0010719, 0.049882, 0.041897, 0.57028, 0.0046504]
Predicted label: 2
Correct prediction
Energy consumption = 161.087219 pJ
sum error= 264
Actual label: 6
Output voltages: [0.072824, 0.17182, 0.037446, 0.010552, 0.049067, 0.7444, 0.79874, 0.022013, 0.56641, 0.0025832]
Predicted label: 6
Correct prediction
Energy consumption = 155.226639 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79846, 0.027744, 0.031305, 0.0089991, 0.036082, 0.0019309, 0.70688, 0.017361, 0.33614, 0.032583]
Predicted label: 0
Correct prediction
Energy consumption = 149.588046 pJ
sum error= 264
Actual label: 8
Output voltages: [0.026479, 0.27872, 0.04845, 0.15766, 0.0095283, 0.0070782, 0.038425, 0.0024773, 0.79733, 0.57884]
Predicted label: 8
Correct prediction
Energy consumption = 157.246913 pJ
sum error= 264
Actual label: 9
Output voltages: [0.73273, 0.019234, 0.01477, 0.038008, 0.21501, 0.02227, 0.0050043, 0.0078845, 0.19433, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 152.995457 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0077304, 0.011294, 0.41653, 0.030095, 0.79862, 0.0058972, 0.32587, 0.076383, 0.023702, 0.075706]
Predicted label: 4
Correct prediction
Energy consumption = 154.642721 pJ
sum error= 264
Actual label: 3
Output voltages: [0.43447, 0.0095859, 0.42746, 0.79879, 0.029152, 0.0073566, 0.0050834, 0.012687, 0.33816, 0.20153]
Predicted label: 3
Correct prediction
Energy consumption = 147.707885 pJ
sum error= 264
Actual label: 5
Output voltages: [0.029836, 0.0049039, 0.0058398, 0.59463, 0.022433, 0.79857, 0.1127, 0.064142, 0.76359, 0.11635]
Predicted label: 5
Correct prediction
Energy consumption = 142.010870 pJ
sum error= 264
Actual label: 4
Output voltages: [0.020488, 0.039506, 0.053603, 0.025028, 0.79878, 0.0071076, 0.12884, 0.099974, 0.028449, 0.019153]
Predicted label: 4
Correct prediction
Energy consumption = 154.747038 pJ
sum error= 264
Actual label: 8
Output voltages: [0.025208, 0.26199, 0.35685, 0.03515, 0.026941, 0.0070594, 0.025315, 0.0037236, 0.79878, 0.25817]
Predicted label: 8
Correct prediction
Energy consumption = 149.065453 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 535 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 535 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 535 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.012819, 0.79869, 0.53428, 0.028635, 0.073271, 0.0010936, 0.099416, 0.015608, 0.06789, 0.048567]
Predicted label: 1
Correct prediction
Energy consumption = 177.548731 pJ
sum error= 264
Actual label: 5
Output voltages: [0.036154, 0.0038854, 0.001066, 0.5932, 0.023934, 0.79879, 0.017491, 0.03739, 0.76471, 0.018454]
Predicted label: 5
Correct prediction
Energy consumption = 148.628977 pJ
sum error= 264
Actual label: 9
Output voltages: [0.19688, 0.0017297, 0.026869, 0.022839, 0.28663, 0.0016829, 0.0025084, 0.069142, 0.32246, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 153.314520 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79861, 0.016682, 0.0038575, 0.019672, 0.041132, 0.013914, 0.72822, 0.00867, 0.24843, 0.025743]
Predicted label: 0
Correct prediction
Energy consumption = 151.058719 pJ
sum error= 264
Actual label: 6
Output voltages: [0.21223, 0.032975, 0.20329, 0.002379, 0.29424, 0.27392, 0.79873, 0.0015501, 0.44606, 0.0091102]
Predicted label: 6
Correct prediction
Energy consumption = 144.453305 pJ
sum error= 264
Actual label: 4
Output voltages: [0.056625, 0.017409, 0.25015, 0.010692, 0.79867, 0.0026741, 0.21191, 0.027158, 0.043924, 0.0096679]
Predicted label: 4
Correct prediction
Energy consumption = 147.085333 pJ
sum error= 264
Actual label: 3
Output voltages: [0.18562, 0.022823, 0.056775, 0.79868, 0.029121, 0.0087781, 0.0075018, 0.014087, 0.59861, 0.16782]
Predicted label: 3
Correct prediction
Energy consumption = 145.308821 pJ
sum error= 264
Actual label: 6
Output voltages: [0.1297, 0.050112, 0.10677, 0.0039693, 0.34638, 0.058976, 0.79878, 0.0049421, 0.69851, 0.0037716]
Predicted label: 6
Correct prediction
Energy consumption = 146.408781 pJ
sum error= 264
Actual label: 3
Output voltages: [0.25313, 0.014103, 0.16442, 0.79876, 0.016424, 0.030139, 0.0034653, 0.0032677, 0.75786, 0.036448]
Predicted label: 3
Correct prediction
Energy consumption = 148.383452 pJ
sum error= 264
Actual label: 3
Output voltages: [0.076357, 0.020772, 0.049103, 0.79871, 0.030619, 0.020685, 0.011383, 0.0022969, 0.53955, 0.22478]
Predicted label: 3
Correct prediction
Energy consumption = 136.503675 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 536 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 536 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 536 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.01745, 0.26341, 0.28785, 0.029883, 0.004417, 0.0035817, 0.014896, 0.016394, 0.79878, 0.46427]
Predicted label: 8
Correct prediction
Energy consumption = 166.915148 pJ
sum error= 264
Actual label: 1
Output voltages: [0.02769, 0.79864, 0.17676, 0.036001, 0.4103, 0.0010692, 0.26714, 0.003854, 0.023733, 0.058393]
Predicted label: 1
Correct prediction
Energy consumption = 158.818610 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0098868, 0.0041415, 0.075079, 0.026923, 0.79869, 0.001419, 0.057309, 0.034251, 0.02663, 0.035445]
Predicted label: 4
Correct prediction
Energy consumption = 151.047953 pJ
sum error= 264
Actual label: 7
Output voltages: [0.22073, 0.030711, 0.028337, 0.25615, 0.0046712, 0.013021, 0.0011763, 0.79873, 0.2243, 0.44732]
Predicted label: 7
Correct prediction
Energy consumption = 147.795863 pJ
sum error= 264
Actual label: 5
Output voltages: [0.03517, 0.0010676, 0.018824, 0.44425, 0.068295, 0.79875, 0.05733, 0.19357, 0.78285, 0.039734]
Predicted label: 5
Correct prediction
Energy consumption = 142.101659 pJ
sum error= 264
Actual label: 7
Output voltages: [0.28098, 0.01176, 0.051173, 0.056634, 0.015273, 0.029417, 0.0010718, 0.7985, 0.11632, 0.35763]
Predicted label: 7
Correct prediction
Energy consumption = 152.846010 pJ
sum error= 264
Actual label: 2
Output voltages: [0.46508, 0.024863, 0.79862, 0.028448, 0.01126, 0.0010839, 0.036519, 0.037125, 0.4614, 0.0041313]
Predicted label: 2
Correct prediction
Energy consumption = 138.436987 pJ
sum error= 264
Actual label: 2
Output voltages: [0.55077, 0.0016126, 0.79877, 0.05255, 0.010635, 0.0010661, 0.030062, 0.13689, 0.58347, 0.0018268]
Predicted label: 2
Correct prediction
Energy consumption = 131.687973 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79877, 0.075387, 0.039952, 0.017752, 0.027471, 0.0018761, 0.74793, 0.014943, 0.18687, 0.26124]
Predicted label: 0
Correct prediction
Energy consumption = 155.715896 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79879, 0.042811, 0.023649, 0.028137, 0.012264, 0.0059526, 0.64143, 0.02348, 0.25184, 0.10624]
Predicted label: 0
Correct prediction
Energy consumption = 140.106077 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 537 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 537 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 537 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.014384, 0.79847, 0.20928, 0.031092, 0.023654, 0.0028746, 0.52815, 0.0049046, 0.45399, 0.037239]
Predicted label: 1
Correct prediction
Energy consumption = 185.553333 pJ
sum error= 264
Actual label: 7
Output voltages: [0.30198, 0.17276, 0.015607, 0.047444, 0.0043781, 0.071107, 0.0012525, 0.79876, 0.19925, 0.49915]
Predicted label: 7
Correct prediction
Energy consumption = 155.907851 pJ
sum error= 264
Actual label: 7
Output voltages: [0.064823, 0.4339, 0.33617, 0.014927, 0.0023936, 0.0010702, 0.0011729, 0.79859, 0.099583, 0.04104]
Predicted label: 7
Correct prediction
Energy consumption = 141.990244 pJ
sum error= 264
Actual label: 9
Output voltages: [0.34742, 0.009057, 0.024114, 0.11575, 0.13293, 0.0091784, 0.0021833, 0.026335, 0.31301, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 145.968675 pJ
sum error= 264
Actual label: 5
Output voltages: [0.03122, 0.0020124, 0.001083, 0.74458, 0.013847, 0.79873, 0.014965, 0.033022, 0.75227, 0.013648]
Predicted label: 5
Correct prediction
Energy consumption = 142.450898 pJ
sum error= 264
Actual label: 9
Output voltages: [0.16703, 0.024542, 0.012687, 0.024668, 0.026938, 0.0028744, 0.0011809, 0.027721, 0.57969, 0.79819]
Predicted label: 9
Correct prediction
Energy consumption = 153.250241 pJ
sum error= 264
Actual label: 8
Output voltages: [0.026076, 0.13484, 0.40363, 0.014804, 0.13632, 0.0083112, 0.063621, 0.0032928, 0.79878, 0.069025]
Predicted label: 8
Correct prediction
Energy consumption = 144.579582 pJ
sum error= 264
Actual label: 9
Output voltages: [0.53798, 0.0017255, 0.051963, 0.0053313, 0.45048, 0.01367, 0.0021914, 0.031553, 0.48202, 0.79463]
Predicted label: 9
Correct prediction
Energy consumption = 148.262828 pJ
sum error= 264
Actual label: 6
Output voltages: [0.033364, 0.033869, 0.12102, 0.0028328, 0.14672, 0.20593, 0.79879, 0.0062135, 0.6965, 0.0013428]
Predicted label: 6
Correct prediction
Energy consumption = 147.137398 pJ
sum error= 264
Actual label: 8
Output voltages: [0.043218, 0.038116, 0.051049, 0.030897, 0.029374, 0.0030873, 0.013811, 0.030754, 0.79878, 0.082041]
Predicted label: 8
Correct prediction
Energy consumption = 149.973576 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 538 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 538 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 538 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.053489, 0.0081082, 0.13541, 0.036305, 0.0071838, 0.042551, 0.0086353, 0.021215, 0.79873, 0.14959]
Predicted label: 8
Correct prediction
Energy consumption = 171.065331 pJ
sum error= 264
Actual label: 2
Output voltages: [0.7457, 0.0020322, 0.79875, 0.1002, 0.019023, 0.0011327, 0.018361, 0.098601, 0.59652, 0.014826]
Predicted label: 2
Correct prediction
Energy consumption = 144.253993 pJ
sum error= 264
Actual label: 3
Output voltages: [0.55293, 0.010212, 0.20601, 0.79873, 0.017795, 0.025314, 0.02277, 0.027994, 0.2594, 0.061185]
Predicted label: 3
Correct prediction
Energy consumption = 143.925263 pJ
sum error= 264
Actual label: 6
Output voltages: [0.098872, 0.15274, 0.14735, 0.0075552, 0.054001, 0.59057, 0.7987, 0.0069459, 0.36474, 0.0036873]
Predicted label: 6
Correct prediction
Energy consumption = 149.680456 pJ
sum error= 264
Actual label: 1
Output voltages: [0.012721, 0.79847, 0.1912, 0.078172, 0.055101, 0.001089, 0.14503, 0.019676, 0.050663, 0.023433]
Predicted label: 1
Correct prediction
Energy consumption = 164.174060 pJ
sum error= 264
Actual label: 2
Output voltages: [0.44072, 0.018515, 0.79877, 0.17442, 0.043168, 0.001186, 0.2288, 0.035907, 0.42906, 0.017518]
Predicted label: 2
Correct prediction
Energy consumption = 152.399451 pJ
sum error= 264
Actual label: 9
Output voltages: [0.49607, 0.019999, 0.018936, 0.065073, 0.22417, 0.036172, 0.0030241, 0.02436, 0.37047, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 153.357102 pJ
sum error= 264
Actual label: 8
Output voltages: [0.081241, 0.18977, 0.20994, 0.28574, 0.0074735, 0.022048, 0.026225, 0.0063616, 0.79879, 0.30953]
Predicted label: 8
Correct prediction
Energy consumption = 147.874401 pJ
sum error= 264
Actual label: 9
Output voltages: [0.43377, 0.025436, 0.0099594, 0.049586, 0.17357, 0.024734, 0.016115, 0.011087, 0.35035, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 150.253936 pJ
sum error= 264
Actual label: 5
Output voltages: [0.15421, 0.001992, 0.0134, 0.51565, 0.0094567, 0.79867, 0.022638, 0.15478, 0.76983, 0.036936]
Predicted label: 5
Correct prediction
Energy consumption = 139.789234 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 539 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 539 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 539 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33306, 0.011164, 0.79873, 0.11171, 0.037175, 0.0010714, 0.014121, 0.0089903, 0.66161, 0.0091577]
Predicted label: 2
Correct prediction
Energy consumption = 157.858896 pJ
sum error= 264
Actual label: 6
Output voltages: [0.095444, 0.052739, 0.07434, 0.0099505, 0.24466, 0.10798, 0.79878, 0.0011347, 0.60951, 0.0046394]
Predicted label: 6
Correct prediction
Energy consumption = 147.341541 pJ
sum error= 264
Actual label: 2
Output voltages: [0.71176, 0.063301, 0.79876, 0.050431, 0.0034182, 0.0011112, 0.039223, 0.04055, 0.3623, 0.019174]
Predicted label: 2
Correct prediction
Energy consumption = 152.316709 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0047933, 0.0023912, 0.28711, 0.0067525, 0.79861, 0.0018991, 0.31555, 0.047829, 0.036108, 0.011906]
Predicted label: 4
Correct prediction
Energy consumption = 149.703536 pJ
sum error= 264
Actual label: 8
Output voltages: [0.20122, 0.070113, 0.043681, 0.0030769, 0.064044, 0.0013233, 0.030017, 0.0030186, 0.79827, 0.53037]
Predicted label: 8
Correct prediction
Energy consumption = 152.913054 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0051891, 0.017234, 0.048065, 0.0036199, 0.79879, 0.0022174, 0.26553, 0.0513, 0.03721, 0.0094733]
Predicted label: 4
Correct prediction
Energy consumption = 152.552209 pJ
sum error= 264
Actual label: 6
Output voltages: [0.026457, 0.0070792, 0.045275, 0.0021211, 0.37098, 0.088085, 0.79879, 0.014889, 0.59941, 0.014796]
Predicted label: 6
Correct prediction
Energy consumption = 149.503103 pJ
sum error= 264
Actual label: 5
Output voltages: [0.14267, 0.001101, 0.019042, 0.34308, 0.0080095, 0.79879, 0.0184, 0.21635, 0.79665, 0.040663]
Predicted label: 5
Correct prediction
Energy consumption = 142.789597 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79869, 0.086297, 0.12185, 0.0062763, 0.026256, 0.013604, 0.11486, 0.049088, 0.038781, 0.29211]
Predicted label: 0
Correct prediction
Energy consumption = 162.742630 pJ
sum error= 264
Actual label: 1
Output voltages: [0.041707, 0.79864, 0.46962, 0.019727, 0.044227, 0.0010667, 0.64204, 0.0089102, 0.046836, 0.023334]
Predicted label: 1
Correct prediction
Energy consumption = 155.349831 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 540 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 540 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 540 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.047933, 0.0010667, 0.001079, 0.38581, 0.11082, 0.79879, 0.41583, 0.0076141, 0.70179, 0.048501]
Predicted label: 5
Correct prediction
Energy consumption = 161.258340 pJ
sum error= 264
Actual label: 6
Output voltages: [0.2595, 0.017567, 0.16623, 0.0021696, 0.54671, 0.30939, 0.79879, 0.0020818, 0.53526, 0.0059728]
Predicted label: 6
Correct prediction
Energy consumption = 150.282156 pJ
sum error= 264
Actual label: 7
Output voltages: [0.13944, 0.038807, 0.033352, 0.065897, 0.010123, 0.0053025, 0.001073, 0.79874, 0.34636, 0.55876]
Predicted label: 7
Correct prediction
Energy consumption = 160.449149 pJ
sum error= 264
Actual label: 8
Output voltages: [0.20632, 0.017602, 0.11281, 0.13781, 0.20834, 0.0010712, 0.026569, 0.0034011, 0.79707, 0.1297]
Predicted label: 8
Correct prediction
Energy consumption = 151.468581 pJ
sum error= 264
Actual label: 9
Output voltages: [0.24783, 0.01025, 0.012214, 0.14574, 0.12707, 0.0076573, 0.0029457, 0.017908, 0.63022, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 146.270499 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79776, 0.18645, 0.023467, 0.005104, 0.01709, 0.0038193, 0.52379, 0.16988, 0.17738, 0.06122]
Predicted label: 0
Correct prediction
Energy consumption = 144.887511 pJ
sum error= 264
Actual label: 1
Output voltages: [0.0086849, 0.79879, 0.26062, 0.0062234, 0.45525, 0.0013086, 0.36892, 0.012911, 0.30681, 0.025431]
Predicted label: 1
Correct prediction
Energy consumption = 157.743346 pJ
sum error= 264
Actual label: 2
Output voltages: [0.15851, 0.040334, 0.79877, 0.041807, 0.008858, 0.0013255, 0.054923, 0.40968, 0.39068, 0.14937]
Predicted label: 2
Correct prediction
Energy consumption = 144.340195 pJ
sum error= 264
Actual label: 3
Output voltages: [0.42292, 0.0108, 0.047709, 0.79873, 0.0049272, 0.031306, 0.0072509, 0.014567, 0.74974, 0.014822]
Predicted label: 3
Correct prediction
Energy consumption = 144.422927 pJ
sum error= 264
Actual label: 4
Output voltages: [0.18582, 0.0036125, 0.17814, 0.0018829, 0.79879, 0.015832, 0.69757, 0.013275, 0.10233, 0.0091654]
Predicted label: 4
Correct prediction
Energy consumption = 152.516782 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 541 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 541 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 541 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.042762, 0.0011199, 0.0017664, 0.036833, 0.053585, 0.79863, 0.18996, 0.0049583, 0.79646, 0.011357]
Predicted label: 5
Correct prediction
Energy consumption = 163.866932 pJ
sum error= 264
Actual label: 6
Output voltages: [0.26122, 0.08623, 0.27271, 0.0032696, 0.21643, 0.30332, 0.79876, 0.0014875, 0.34962, 0.012703]
Predicted label: 6
Correct prediction
Energy consumption = 142.274223 pJ
sum error= 264
Actual label: 7
Output voltages: [0.47658, 0.026905, 0.035738, 0.033839, 0.0050609, 0.001485, 0.0010891, 0.79872, 0.63503, 0.31577]
Predicted label: 7
Correct prediction
Energy consumption = 159.212612 pJ
sum error= 264
Actual label: 8
Output voltages: [0.0048545, 0.022642, 0.031951, 0.44303, 0.035528, 0.010321, 0.013459, 0.018307, 0.79879, 0.0434]
Predicted label: 8
Correct prediction
Energy consumption = 143.346483 pJ
sum error= 264
Actual label: 9
Output voltages: [0.20333, 0.0069249, 0.022617, 0.023616, 0.054628, 0.021389, 0.0026985, 0.26343, 0.67139, 0.79377]
Predicted label: 9
Correct prediction
Energy consumption = 142.289096 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79873, 0.12737, 0.022866, 0.019098, 0.0051601, 0.022029, 0.28572, 0.01501, 0.017369, 0.031056]
Predicted label: 0
Correct prediction
Energy consumption = 147.003756 pJ
sum error= 264
Actual label: 1
Output voltages: [0.0019143, 0.79854, 0.031477, 0.041995, 0.080434, 0.0033848, 0.38079, 0.0023698, 0.20854, 0.12814]
Predicted label: 1
Correct prediction
Energy consumption = 158.747622 pJ
sum error= 264
Actual label: 2
Output voltages: [0.0516, 0.35078, 0.79879, 0.3267, 0.022265, 0.0012782, 0.021813, 0.35706, 0.069216, 0.034317]
Predicted label: 2
Correct prediction
Energy consumption = 150.419548 pJ
sum error= 264
Actual label: 3
Output voltages: [0.14954, 0.0029837, 0.68328, 0.79819, 0.0029826, 0.0011092, 0.011828, 0.0075179, 0.76259, 0.0091093]
Predicted label: 3
Correct prediction
Energy consumption = 135.041380 pJ
sum error= 264
Actual label: 4
Output voltages: [0.02482, 0.023655, 0.024675, 0.016894, 0.7987, 0.020061, 0.34038, 0.084604, 0.021862, 0.0014637]
Predicted label: 4
Correct prediction
Energy consumption = 150.172811 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 542 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 542 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 542 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.034052, 0.001209, 0.0011208, 0.16286, 0.027573, 0.7987, 0.16424, 0.019757, 0.78205, 0.003174]
Predicted label: 5
Correct prediction
Energy consumption = 160.283095 pJ
sum error= 264
Actual label: 6
Output voltages: [0.039391, 0.13654, 0.41816, 0.0010699, 0.32981, 0.047585, 0.7987, 0.00129, 0.27485, 0.005307]
Predicted label: 6
Correct prediction
Energy consumption = 145.513535 pJ
sum error= 264
Actual label: 7
Output voltages: [0.52195, 0.0037096, 0.0087546, 0.35862, 0.01726, 0.028847, 0.0012313, 0.79875, 0.47048, 0.38892]
Predicted label: 7
Correct prediction
Energy consumption = 158.808174 pJ
sum error= 264
Actual label: 8
Output voltages: [0.01767, 0.049092, 0.28358, 0.19649, 0.0042477, 0.016959, 0.031583, 0.011553, 0.79876, 0.419]
Predicted label: 8
Correct prediction
Energy consumption = 149.804855 pJ
sum error= 264
Actual label: 9
Output voltages: [0.38542, 0.0096021, 0.011181, 0.18385, 0.24454, 0.013561, 0.0010757, 0.23991, 0.47234, 0.78781]
Predicted label: 9
Correct prediction
Energy consumption = 147.974393 pJ
sum error= 264
Actual label: 7
Output voltages: [0.30422, 0.013778, 0.035323, 0.0024037, 0.037663, 0.0016478, 0.0010683, 0.79862, 0.172, 0.043175]
Predicted label: 7
Correct prediction
Energy consumption = 149.934176 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0012097, 0.030878, 0.067727, 0.018666, 0.79866, 0.0038161, 0.32794, 0.36764, 0.0079869, 0.08015]
Predicted label: 4
Correct prediction
Energy consumption = 151.619871 pJ
sum error= 264
Actual label: 2
Output voltages: [0.10817, 0.058054, 0.79866, 0.014303, 0.0094482, 0.0011373, 0.046578, 0.012792, 0.41161, 0.027599]
Predicted label: 2
Correct prediction
Energy consumption = 149.868756 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79871, 0.027514, 0.32291, 0.020078, 0.0064659, 0.019717, 0.35019, 0.014112, 0.13395, 0.0083094]
Predicted label: 0
Correct prediction
Energy consumption = 143.472375 pJ
sum error= 264
Actual label: 9
Output voltages: [0.13558, 0.014288, 0.013332, 0.12269, 0.079353, 0.0053554, 0.0072495, 0.1129, 0.61743, 0.79812]
Predicted label: 9
Correct prediction
Energy consumption = 145.176968 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 543 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 543 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 543 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79871, 0.031185, 0.11903, 0.026039, 0.0031457, 0.013041, 0.28035, 0.025181, 0.048459, 0.042755]
Predicted label: 0
Correct prediction
Energy consumption = 165.058087 pJ
sum error= 264
Actual label: 1
Output voltages: [0.0097037, 0.79858, 0.21294, 0.022997, 0.09341, 0.0016296, 0.74628, 0.0077939, 0.28207, 0.047573]
Predicted label: 1
Correct prediction
Energy consumption = 157.928066 pJ
sum error= 264
Actual label: 5
Output voltages: [0.10883, 0.0011016, 0.00109, 0.10717, 0.16215, 0.79879, 0.36736, 0.016999, 0.77367, 0.026713]
Predicted label: 5
Correct prediction
Energy consumption = 147.279046 pJ
sum error= 264
Actual label: 8
Output voltages: [0.014282, 0.22315, 0.23051, 0.061083, 0.012205, 0.010013, 0.044577, 0.13201, 0.79868, 0.092494]
Predicted label: 8
Correct prediction
Energy consumption = 150.058869 pJ
sum error= 264
Actual label: 8
Output voltages: [0.024935, 0.049657, 0.034798, 0.023379, 0.011197, 0.016195, 0.1419, 0.028959, 0.79872, 0.4602]
Predicted label: 8
Correct prediction
Energy consumption = 145.386811 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79877, 0.032678, 0.13326, 0.028131, 0.034957, 0.010591, 0.34214, 0.2342, 0.39038, 0.13183]
Predicted label: 0
Correct prediction
Energy consumption = 158.460896 pJ
sum error= 264
Actual label: 2
Output voltages: [0.56615, 0.012275, 0.79876, 0.25275, 0.030811, 0.0010675, 0.034025, 0.12671, 0.47633, 0.013857]
Predicted label: 2
Correct prediction
Energy consumption = 142.357977 pJ
sum error= 264
Actual label: 7
Output voltages: [0.046568, 0.016683, 0.035678, 0.03772, 0.0043269, 0.01469, 0.0010871, 0.79866, 0.37348, 0.46908]
Predicted label: 7
Correct prediction
Energy consumption = 146.705713 pJ
sum error= 264
Actual label: 8
Output voltages: [0.031492, 0.011486, 0.027894, 0.39924, 0.0026875, 0.02908, 0.0091405, 0.0057436, 0.79858, 0.38474]
Predicted label: 8
Correct prediction
Energy consumption = 146.781321 pJ
sum error= 264
Actual label: 4
Output voltages: [0.23523, 0.0047534, 0.11168, 0.0060048, 0.79879, 0.0024212, 0.73346, 0.022959, 0.021834, 0.0047777]
Predicted label: 4
Correct prediction
Energy consumption = 148.696753 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 544 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 544 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 544 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0094755, 0.0015255, 0.32913, 0.014676, 0.79864, 0.0010722, 0.054038, 0.06728, 0.0058411, 0.027977]
Predicted label: 4
Correct prediction
Energy consumption = 171.467233 pJ
sum error= 264
Actual label: 6
Output voltages: [0.087081, 0.38215, 0.46691, 0.016314, 0.055423, 0.030303, 0.79866, 0.0055516, 0.04586, 0.11762]
Predicted label: 6
Correct prediction
Energy consumption = 148.925793 pJ
sum error= 264
Actual label: 1
Output voltages: [0.0017568, 0.79856, 0.044316, 0.031014, 0.040048, 0.0024179, 0.7097, 0.019192, 0.085216, 0.02181]
Predicted label: 1
Correct prediction
Energy consumption = 154.670413 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79879, 0.22012, 0.010354, 0.014191, 0.0024258, 0.011349, 0.59417, 0.027433, 0.36209, 0.053612]
Predicted label: 0
Correct prediction
Energy consumption = 149.080695 pJ
sum error= 264
Actual label: 4
Output voltages: [0.034095, 0.0014325, 0.025657, 0.0023395, 0.79879, 0.0056603, 0.63006, 0.041849, 0.26315, 0.0012869]
Predicted label: 4
Correct prediction
Energy consumption = 152.259698 pJ
sum error= 264
Actual label: 5
Output voltages: [0.10196, 0.0010738, 0.0011725, 0.14542, 0.056169, 0.79866, 0.39611, 0.054413, 0.74136, 0.012281]
Predicted label: 5
Correct prediction
Energy consumption = 143.182363 pJ
sum error= 264
Actual label: 3
Output voltages: [0.13474, 0.007265, 0.13556, 0.79873, 0.010261, 0.036883, 0.0072449, 0.019866, 0.50916, 0.036181]
Predicted label: 3
Correct prediction
Energy consumption = 140.665750 pJ
sum error= 264
Actual label: 9
Output voltages: [0.34414, 0.0023596, 0.016262, 0.014559, 0.40214, 0.0047534, 0.0023501, 0.028984, 0.50921, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 145.379056 pJ
sum error= 264
Actual label: 4
Output voltages: [0.013233, 0.022667, 0.20336, 0.051002, 0.79874, 0.0010764, 0.0084656, 0.11039, 0.0050949, 0.31852]
Predicted label: 4
Correct prediction
Energy consumption = 148.425515 pJ
sum error= 264
Actual label: 2
Output voltages: [0.39497, 0.0029218, 0.79684, 0.44869, 0.023895, 0.0010726, 0.0062055, 0.06789, 0.78057, 0.055756]
Predicted label: 2
Correct prediction
Energy consumption = 144.547452 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 545 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 545 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 545 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.78714, 0.014371, 0.0017548, 0.059636, 0.0035697, 0.23948, 0.27139, 0.47367, 0.49873, 0.19333]
Predicted label: 0
Correct prediction
Energy consumption = 163.698517 pJ
sum error= 264
Actual label: 5
Output voltages: [0.030474, 0.0010841, 0.0032691, 0.17677, 0.014794, 0.79877, 0.54664, 0.027955, 0.74618, 0.0044259]
Predicted label: 5
Correct prediction
Energy consumption = 141.248308 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79875, 0.090322, 0.016059, 0.010892, 0.0085285, 0.0095781, 0.41975, 0.03385, 0.10959, 0.046957]
Predicted label: 0
Correct prediction
Energy consumption = 143.153770 pJ
sum error= 264
Actual label: 1
Output voltages: [0.028483, 0.7985, 0.022787, 0.058253, 0.067096, 0.0019297, 0.5313, 0.009901, 0.0776, 0.06656]
Predicted label: 1
Correct prediction
Energy consumption = 163.899278 pJ
sum error= 264
Actual label: 3
Output voltages: [0.061297, 0.0029103, 0.013469, 0.79879, 0.14151, 0.30794, 0.026275, 0.0024898, 0.63586, 0.049986]
Predicted label: 3
Correct prediction
Energy consumption = 150.635328 pJ
sum error= 264
Actual label: 2
Output voltages: [0.43162, 0.015149, 0.79879, 0.1934, 0.024884, 0.0012454, 0.23577, 0.069799, 0.63014, 0.039048]
Predicted label: 2
Correct prediction
Energy consumption = 147.978907 pJ
sum error= 264
Actual label: 9
Output voltages: [0.15461, 0.031884, 0.044965, 0.051647, 0.043417, 0.027474, 0.013113, 0.11183, 0.44851, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 150.852030 pJ
sum error= 264
Actual label: 1
Output voltages: [0.57791, 0.79857, 0.029623, 0.10492, 0.2994, 0.0022988, 0.33581, 0.0013634, 0.71547, 0.14637]
Predicted label: 1
Correct prediction
Energy consumption = 159.349455 pJ
sum error= 264
Actual label: 6
Output voltages: [0.074203, 0.11054, 0.42555, 0.0010664, 0.20692, 0.038654, 0.79876, 0.0010696, 0.34099, 0.0029662]
Predicted label: 6
Correct prediction
Energy consumption = 150.079163 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79879, 0.030106, 0.034186, 0.024463, 0.0022766, 0.012181, 0.35075, 0.070165, 0.2799, 0.027561]
Predicted label: 0
Correct prediction
Energy consumption = 140.651787 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 546 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 546 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 546 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.033669, 0.79864, 0.021995, 0.011045, 0.33316, 0.016284, 0.66042, 0.0040764, 0.20741, 0.13942]
Predicted label: 1
Correct prediction
Energy consumption = 178.579008 pJ
sum error= 264
Actual label: 1
Output voltages: [0.018143, 0.79872, 0.4508, 0.0068583, 0.09448, 0.0010672, 0.35045, 0.0081522, 0.15216, 0.01622]
Predicted label: 1
Correct prediction
Energy consumption = 145.511064 pJ
sum error= 264
Actual label: 8
Output voltages: [0.0095415, 0.01146, 0.039502, 0.2881, 0.0079287, 0.024574, 0.0061005, 0.0029767, 0.79878, 0.039293]
Predicted label: 8
Correct prediction
Energy consumption = 148.880270 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79876, 0.0057456, 0.019951, 0.0078856, 0.030805, 0.023616, 0.48699, 0.015085, 0.08955, 0.029442]
Predicted label: 0
Correct prediction
Energy consumption = 147.136650 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0054492, 0.0033837, 0.022409, 0.011716, 0.79814, 0.079236, 0.089925, 0.028013, 0.22012, 0.16926]
Predicted label: 4
Correct prediction
Energy consumption = 159.618644 pJ
sum error= 264
Actual label: 7
Output voltages: [0.20894, 0.034196, 0.015334, 0.045161, 0.0064712, 0.0063241, 0.0010775, 0.79868, 0.45888, 0.35468]
Predicted label: 7
Correct prediction
Energy consumption = 157.032894 pJ
sum error= 264
Actual label: 7
Output voltages: [0.32894, 0.047103, 0.037567, 0.014499, 0.0060288, 0.0010719, 0.0011066, 0.79875, 0.50415, 0.15588]
Predicted label: 7
Correct prediction
Energy consumption = 134.789206 pJ
sum error= 264
Actual label: 6
Output voltages: [0.06246, 0.0368, 0.27372, 0.0017545, 0.36641, 0.16909, 0.79873, 0.0022446, 0.41792, 0.0054845]
Predicted label: 6
Correct prediction
Energy consumption = 149.048138 pJ
sum error= 264
Actual label: 3
Output voltages: [0.31555, 0.0011413, 0.50749, 0.79725, 0.0037378, 0.021683, 0.002912, 0.0015704, 0.71822, 0.011137]
Predicted label: 3
Correct prediction
Energy consumption = 148.100772 pJ
sum error= 264
Actual label: 6
Output voltages: [0.20756, 0.063832, 0.24159, 0.0014729, 0.57808, 0.11182, 0.79875, 0.0010803, 0.42916, 0.0036891]
Predicted label: 6
Correct prediction
Energy consumption = 145.811558 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 547 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 547 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 547 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.014612, 0.019603, 0.055849, 0.0026677, 0.06393, 0.60897, 0.20322, 0.2366, 0.019315]
Predicted label: 0
Correct prediction
Energy consumption = 166.157404 pJ
sum error= 264
Actual label: 7
Output voltages: [0.29801, 0.017334, 0.065939, 0.55525, 0.011172, 0.0053267, 0.0012728, 0.79878, 0.19258, 0.50218]
Predicted label: 7
Correct prediction
Energy consumption = 154.959998 pJ
sum error= 264
Actual label: 3
Output voltages: [0.48593, 0.0042094, 0.088632, 0.79872, 0.010831, 0.0071581, 0.0023985, 0.02884, 0.75677, 0.002391]
Predicted label: 3
Correct prediction
Energy consumption = 142.978973 pJ
sum error= 264
Actual label: 5
Output voltages: [0.034768, 0.0013472, 0.0031077, 0.46043, 0.025496, 0.79861, 0.39238, 0.016694, 0.78153, 0.033697]
Predicted label: 5
Correct prediction
Energy consumption = 140.938443 pJ
sum error= 264
Actual label: 4
Output voltages: [0.048492, 0.0044137, 0.16161, 0.003767, 0.79869, 0.026143, 0.60332, 0.093839, 0.028759, 0.0028884]
Predicted label: 4
Correct prediction
Energy consumption = 152.792259 pJ
sum error= 264
Actual label: 2
Output voltages: [0.47165, 0.049892, 0.79872, 0.048816, 0.023699, 0.0012289, 0.42256, 0.046636, 0.62388, 0.035791]
Predicted label: 2
Correct prediction
Energy consumption = 150.241430 pJ
sum error= 264
Actual label: 4
Output voltages: [0.034312, 0.0031063, 0.37005, 0.0012821, 0.79862, 0.005193, 0.64918, 0.11157, 0.049101, 0.0079156]
Predicted label: 4
Correct prediction
Energy consumption = 148.506780 pJ
sum error= 264
Actual label: 1
Output voltages: [0.020469, 0.7986, 0.039618, 0.023443, 0.17829, 0.0012116, 0.63968, 0.01821, 0.028588, 0.10609]
Predicted label: 1
Correct prediction
Energy consumption = 154.151221 pJ
sum error= 264
Actual label: 8
Output voltages: [0.012011, 0.14691, 0.12165, 0.049138, 0.010339, 0.003214, 0.024539, 0.026698, 0.79871, 0.34166]
Predicted label: 8
Correct prediction
Energy consumption = 151.238958 pJ
sum error= 264
Actual label: 3
Output voltages: [0.25011, 0.01944, 0.029061, 0.79866, 0.019444, 0.43255, 0.0050352, 0.0060429, 0.61076, 0.025091]
Predicted label: 3
Correct prediction
Energy consumption = 140.536144 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 548 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 548 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 548 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.032068, 0.0010671, 0.0021012, 0.2977, 0.032157, 0.79873, 0.5302, 0.0075369, 0.77173, 0.0049774]
Predicted label: 5
Correct prediction
Energy consumption = 160.142965 pJ
sum error= 264
Actual label: 6
Output voltages: [0.1039, 0.25762, 0.15122, 0.0030223, 0.37025, 0.72938, 0.79869, 0.0021468, 0.2889, 0.0080278]
Predicted label: 6
Correct prediction
Energy consumption = 138.830664 pJ
sum error= 264
Actual label: 7
Output voltages: [0.050957, 0.062738, 0.11715, 0.14812, 0.0040223, 0.0010667, 0.0010844, 0.79866, 0.4378, 0.13248]
Predicted label: 7
Correct prediction
Energy consumption = 157.121440 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79732, 0.054938, 0.024682, 0.011581, 0.049686, 0.013064, 0.70492, 0.04625, 0.11246, 0.041127]
Predicted label: 0
Correct prediction
Energy consumption = 151.116083 pJ
sum error= 264
Actual label: 6
Output voltages: [0.13139, 0.095874, 0.25148, 0.0021481, 0.31418, 0.15971, 0.79873, 0.0013564, 0.33405, 0.011205]
Predicted label: 6
Correct prediction
Energy consumption = 144.718507 pJ
sum error= 264
Actual label: 7
Output voltages: [0.25244, 0.0135, 0.049577, 0.048302, 0.0034425, 0.0031731, 0.0011958, 0.79862, 0.61568, 0.21334]
Predicted label: 7
Correct prediction
Energy consumption = 158.051226 pJ
sum error= 264
Actual label: 1
Output voltages: [0.14481, 0.79877, 0.10495, 0.0026631, 0.53482, 0.0021943, 0.34959, 0.0010741, 0.026229, 0.13462]
Predicted label: 1
Correct prediction
Energy consumption = 155.172033 pJ
sum error= 264
Actual label: 2
Output voltages: [0.43437, 0.04681, 0.7987, 0.062873, 0.017864, 0.0012721, 0.14639, 0.052352, 0.35309, 0.02523]
Predicted label: 2
Correct prediction
Energy consumption = 143.404673 pJ
sum error= 264
Actual label: 5
Output voltages: [0.027341, 0.00109, 0.021245, 0.43916, 0.018666, 0.79874, 0.027922, 0.24439, 0.77926, 0.14267]
Predicted label: 5
Correct prediction
Energy consumption = 146.298883 pJ
sum error= 264
Actual label: 8
Output voltages: [0.0051306, 0.082352, 0.23054, 0.028592, 0.014635, 0.0040726, 0.025174, 0.051999, 0.79872, 0.20908]
Predicted label: 8
Correct prediction
Energy consumption = 141.182723 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 549 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 549 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 549 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.037899, 0.79876, 0.071339, 0.012007, 0.063923, 0.0010909, 0.11421, 0.053904, 0.12569, 0.12731]
Predicted label: 1
Correct prediction
Energy consumption = 177.961449 pJ
sum error= 264
Actual label: 9
Output voltages: [0.29052, 0.011578, 0.032272, 0.025342, 0.46995, 0.0063732, 0.0071426, 0.0023928, 0.36974, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 153.919397 pJ
sum error= 264
Actual label: 3
Output voltages: [0.35354, 0.0016674, 0.68802, 0.7987, 0.0054282, 0.01287, 0.02459, 0.0058069, 0.79416, 0.01659]
Predicted label: 3
Correct prediction
Energy consumption = 144.075081 pJ
sum error= 264
Actual label: 8
Output voltages: [0.02014, 0.0055917, 0.21904, 0.14692, 0.0011229, 0.23916, 0.0055502, 0.096418, 0.79872, 0.016792]
Predicted label: 8
Correct prediction
Energy consumption = 143.087707 pJ
sum error= 264
Actual label: 2
Output voltages: [0.19516, 0.037989, 0.79877, 0.11476, 0.017761, 0.0012442, 0.22528, 0.0087682, 0.58552, 0.026054]
Predicted label: 2
Correct prediction
Energy consumption = 146.755998 pJ
sum error= 264
Actual label: 8
Output voltages: [0.014208, 0.03223, 0.043864, 0.22437, 0.0043633, 0.02346, 0.0082261, 0.029664, 0.79876, 0.2407]
Predicted label: 8
Correct prediction
Energy consumption = 146.551000 pJ
sum error= 264
Actual label: 7
Output voltages: [0.067353, 0.15485, 0.52697, 0.14376, 0.0014566, 0.0010674, 0.0010659, 0.79878, 0.65579, 0.17507]
Predicted label: 7
Correct prediction
Energy consumption = 144.934432 pJ
sum error= 264
Actual label: 6
Output voltages: [0.096556, 0.032149, 0.3751, 0.0010943, 0.21869, 0.037459, 0.79878, 0.0013446, 0.31004, 0.0012053]
Predicted label: 6
Correct prediction
Energy consumption = 145.308866 pJ
sum error= 264
Actual label: 7
Output voltages: [0.17993, 0.029076, 0.23205, 0.52259, 0.005063, 0.0040042, 0.001213, 0.79862, 0.57454, 0.118]
Predicted label: 7
Correct prediction
Energy consumption = 159.925146 pJ
sum error= 264
Actual label: 1
Output voltages: [0.030053, 0.79879, 0.067106, 0.0091265, 0.30209, 0.001066, 0.0052557, 0.28929, 0.033614, 0.12141]
Predicted label: 1
Correct prediction
Energy consumption = 150.407244 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 550 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 550 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 550 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.018895, 0.006586, 0.059863, 0.006594, 0.79868, 0.0030511, 0.16078, 0.40928, 0.031835, 0.0043246]
Predicted label: 4
Correct prediction
Energy consumption = 164.023083 pJ
sum error= 264
Actual label: 6
Output voltages: [0.05666, 0.050528, 0.36442, 0.0014009, 0.56127, 0.12938, 0.79868, 0.0022005, 0.36462, 0.0054718]
Predicted label: 6
Correct prediction
Energy consumption = 146.159145 pJ
sum error= 264
Actual label: 2
Output voltages: [0.57554, 0.017078, 0.79879, 0.34159, 0.02051, 0.0011223, 0.28055, 0.02213, 0.57946, 0.016345]
Predicted label: 2
Correct prediction
Energy consumption = 149.058688 pJ
sum error= 264
Actual label: 9
Output voltages: [0.39553, 0.0097945, 0.022923, 0.31271, 0.31311, 0.043734, 0.0070666, 0.10607, 0.58813, 0.79805]
Predicted label: 9
Correct prediction
Energy consumption = 148.314627 pJ
sum error= 264
Actual label: 3
Output voltages: [0.42273, 0.003489, 0.1167, 0.79875, 0.0071723, 0.10049, 0.0023063, 0.016958, 0.76166, 0.02713]
Predicted label: 3
Correct prediction
Energy consumption = 145.858586 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79878, 0.069246, 0.017311, 0.031397, 0.011524, 0.22876, 0.57512, 0.025827, 0.46597, 0.047459]
Predicted label: 0
Correct prediction
Energy consumption = 158.313062 pJ
sum error= 264
Actual label: 1
Output voltages: [0.011911, 0.79859, 0.083371, 0.26021, 0.011694, 0.00124, 0.14144, 0.011937, 0.36715, 0.028898]
Predicted label: 1
Correct prediction
Energy consumption = 159.637905 pJ
sum error= 264
Actual label: 2
Output voltages: [0.28784, 0.36662, 0.7985, 0.098659, 0.026183, 0.0013072, 0.58449, 0.015666, 0.38537, 0.016589]
Predicted label: 2
Correct prediction
Energy consumption = 142.953357 pJ
sum error= 264
Actual label: 3
Output voltages: [0.053755, 0.019302, 0.087655, 0.79868, 0.030584, 0.037558, 0.032766, 0.024679, 0.37447, 0.12923]
Predicted label: 3
Correct prediction
Energy consumption = 146.974040 pJ
sum error= 264
Actual label: 4
Output voltages: [0.019381, 0.011928, 0.18744, 0.022724, 0.79877, 0.0013289, 0.30469, 0.12803, 0.0088282, 0.73318]
Predicted label: 4
Correct prediction
Energy consumption = 152.736753 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 551 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 551 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 551 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.016182, 0.0010771, 0.0034744, 0.75282, 0.011509, 0.78267, 0.064342, 0.057182, 0.58756, 0.018843]
Predicted label: 5
Correct prediction
Energy consumption = 162.532532 pJ
sum error= 264
Actual label: 6
Output voltages: [0.17243, 0.063375, 0.30051, 0.0044289, 0.41157, 0.39896, 0.79866, 0.0025522, 0.34158, 0.0078502]
Predicted label: 6
Correct prediction
Energy consumption = 151.282929 pJ
sum error= 264
Actual label: 7
Output voltages: [0.081443, 0.063978, 0.012841, 0.0087742, 0.022069, 0.015819, 0.0011482, 0.79868, 0.14429, 0.43746]
Predicted label: 7
Correct prediction
Energy consumption = 162.648028 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79871, 0.15203, 0.042311, 0.015018, 0.0059577, 0.029806, 0.62676, 0.0036559, 0.036703, 0.018251]
Predicted label: 0
Correct prediction
Energy consumption = 156.865587 pJ
sum error= 264
Actual label: 1
Output voltages: [0.018658, 0.7986, 0.10827, 0.074507, 0.017474, 0.0013194, 0.17074, 0.0034957, 0.18561, 0.12208]
Predicted label: 1
Correct prediction
Energy consumption = 167.573699 pJ
sum error= 264
Actual label: 2
Output voltages: [0.3467, 0.72121, 0.7849, 0.5626, 0.025485, 0.0012815, 0.3337, 0.001112, 0.2008, 0.012074]
Predicted label: 2
Correct prediction
Energy consumption = 150.220961 pJ
sum error= 264
Actual label: 3
Output voltages: [0.54097, 0.02929, 0.045643, 0.79869, 0.0047225, 0.030189, 0.021062, 0.034528, 0.44358, 0.019868]
Predicted label: 3
Correct prediction
Energy consumption = 138.530777 pJ
sum error= 264
Actual label: 4
Output voltages: [0.018395, 0.012612, 0.059733, 0.011032, 0.79863, 0.0018413, 0.10118, 0.052863, 0.1282, 0.055601]
Predicted label: 4
Correct prediction
Energy consumption = 163.013061 pJ
sum error= 264
Actual label: 5
Output voltages: [0.24607, 0.001206, 0.024388, 0.35522, 0.016747, 0.79873, 0.13837, 0.017985, 0.78616, 0.037037]
Predicted label: 5
Correct prediction
Energy consumption = 146.591946 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79304, 0.047956, 0.013153, 0.011972, 0.035912, 0.22219, 0.78632, 0.016158, 0.24241, 0.045235]
Predicted label: 0
Correct prediction
Energy consumption = 152.433319 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 552 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 552 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 552 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.021998, 0.79847, 0.063635, 0.27977, 0.19249, 0.03383, 0.30295, 0.019301, 0.011693, 0.19456]
Predicted label: 1
Correct prediction
Energy consumption = 183.020921 pJ
sum error= 264
Actual label: 2
Output voltages: [0.38717, 0.44462, 0.79852, 0.040123, 0.0086995, 0.0013915, 0.52409, 0.0037267, 0.43383, 0.047218]
Predicted label: 2
Correct prediction
Energy consumption = 149.101594 pJ
sum error= 264
Actual label: 8
Output voltages: [0.39224, 0.0065983, 0.30021, 0.035504, 0.0105, 0.037356, 0.0013215, 0.0020713, 0.79878, 0.33583]
Predicted label: 8
Correct prediction
Energy consumption = 150.303408 pJ
sum error= 264
Actual label: 9
Output voltages: [0.302, 0.0011461, 0.020264, 0.037867, 0.11891, 0.0070803, 0.0017684, 0.23463, 0.3009, 0.79757]
Predicted label: 9
Correct prediction
Energy consumption = 153.953139 pJ
sum error= 264
Actual label: 1
Output voltages: [0.037209, 0.7984, 0.12789, 0.22932, 0.066622, 0.0081614, 0.17957, 0.010227, 0.071167, 0.16099]
Predicted label: 1
Correct prediction
Energy consumption = 171.492366 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0097381, 0.037966, 0.093136, 0.0013951, 0.79874, 0.0010867, 0.17844, 0.014445, 0.017907, 0.29635]
Predicted label: 4
Correct prediction
Energy consumption = 150.997941 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79868, 0.062468, 0.061491, 0.010666, 0.029345, 0.0054258, 0.23162, 0.070172, 0.56947, 0.158]
Predicted label: 0
Correct prediction
Energy consumption = 159.486230 pJ
sum error= 264
Actual label: 9
Output voltages: [0.42044, 0.010697, 0.064317, 0.051069, 0.39407, 0.030059, 0.031296, 0.0040933, 0.067119, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 153.405466 pJ
sum error= 264
Actual label: 5
Output voltages: [0.03404, 0.0031064, 0.0055511, 0.39984, 0.011848, 0.79851, 0.045685, 0.066187, 0.78388, 0.13625]
Predicted label: 5
Correct prediction
Energy consumption = 148.960790 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79876, 0.09954, 0.053739, 0.025079, 0.025111, 0.024521, 0.54517, 0.033994, 0.11195, 0.058992]
Predicted label: 0
Correct prediction
Energy consumption = 154.354632 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 553 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 553 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 553 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.41905, 0.010726, 0.20755, 0.61735, 0.0035958, 0.25345, 0.029025, 0.0013238, 0.79878, 0.31378]
Predicted label: 8
Correct prediction
Energy consumption = 171.126237 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79873, 0.015961, 0.025349, 0.0087435, 0.018322, 0.0050112, 0.59874, 0.0024774, 0.045313, 0.034857]
Predicted label: 0
Correct prediction
Energy consumption = 152.312038 pJ
sum error= 264
Actual label: 7
Output voltages: [0.20695, 0.040915, 0.0012069, 0.068614, 0.035803, 0.005792, 0.0010724, 0.79857, 0.41799, 0.41754]
Predicted label: 7
Correct prediction
Energy consumption = 161.914352 pJ
sum error= 264
Actual label: 7
Output voltages: [0.077826, 0.02084, 0.019548, 0.067399, 0.036556, 0.0029284, 0.001066, 0.79864, 0.27074, 0.35082]
Predicted label: 7
Correct prediction
Energy consumption = 145.482291 pJ
sum error= 264
Actual label: 1
Output voltages: [0.0063841, 0.79851, 0.13682, 0.22361, 0.042823, 0.0011249, 0.48179, 0.0077679, 0.20708, 0.044104]
Predicted label: 1
Correct prediction
Energy consumption = 165.169394 pJ
sum error= 264
Actual label: 1
Output voltages: [0.065683, 0.79854, 0.066924, 0.27102, 0.038587, 0.0011138, 0.27682, 0.0081182, 0.018978, 0.52008]
Predicted label: 1
Correct prediction
Energy consumption = 156.259974 pJ
sum error= 264
Actual label: 2
Output voltages: [0.32916, 0.10537, 0.79872, 0.053716, 0.0079534, 0.0012784, 0.24787, 0.04495, 0.48443, 0.025323]
Predicted label: 2
Correct prediction
Energy consumption = 149.273165 pJ
sum error= 264
Actual label: 9
Output voltages: [0.3915, 0.024817, 0.024195, 0.20467, 0.052529, 0.036823, 0.02119, 0.019634, 0.089523, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 158.413716 pJ
sum error= 264
Actual label: 3
Output voltages: [0.025805, 0.0092905, 0.046688, 0.79879, 0.010487, 0.010036, 0.007709, 0.01297, 0.76951, 0.024773]
Predicted label: 3
Correct prediction
Energy consumption = 139.082105 pJ
sum error= 264
Actual label: 6
Output voltages: [0.7157, 0.28869, 0.057513, 0.0174, 0.23547, 0.019771, 0.7979, 0.0010895, 0.49434, 0.0036481]
Predicted label: 6
Correct prediction
Energy consumption = 155.231089 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 554 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 554 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 554 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.075305, 0.030722, 0.36132, 0.040874, 0.0011173, 0.0011119, 0.0010685, 0.7987, 0.33348, 0.049814]
Predicted label: 7
Correct prediction
Energy consumption = 175.714206 pJ
sum error= 264
Actual label: 2
Output voltages: [0.42183, 0.13693, 0.79874, 0.22538, 0.031363, 0.0012435, 0.27989, 0.018386, 0.43042, 0.046333]
Predicted label: 2
Correct prediction
Energy consumption = 147.832106 pJ
sum error= 264
Actual label: 3
Output voltages: [0.22706, 0.0060601, 0.36597, 0.7987, 0.039402, 0.015466, 0.0088351, 0.043651, 0.31536, 0.080093]
Predicted label: 3
Correct prediction
Energy consumption = 141.790601 pJ
sum error= 264
Actual label: 8
Output voltages: [0.26232, 0.016101, 0.38811, 0.40737, 0.022629, 0.018697, 0.025199, 0.0020771, 0.79877, 0.25041]
Predicted label: 8
Correct prediction
Energy consumption = 149.922962 pJ
sum error= 264
Actual label: 1
Output voltages: [0.016886, 0.79862, 0.36455, 0.073224, 0.18744, 0.0011027, 0.36922, 0.002087, 0.069962, 0.034452]
Predicted label: 1
Correct prediction
Energy consumption = 167.594460 pJ
sum error= 264
Actual label: 2
Output voltages: [0.47209, 0.0066532, 0.7986, 0.26334, 0.027901, 0.0011714, 0.23265, 0.054465, 0.76022, 0.014077]
Predicted label: 2
Correct prediction
Energy consumption = 146.118689 pJ
sum error= 264
Actual label: 9
Output voltages: [0.26048, 0.023705, 0.038271, 0.048819, 0.52591, 0.0024755, 0.02416, 0.0021095, 0.30578, 0.78951]
Predicted label: 9
Correct prediction
Energy consumption = 148.303185 pJ
sum error= 264
Actual label: 8
Output voltages: [0.38097, 0.018691, 0.10821, 0.66403, 0.0060247, 0.04062, 0.10376, 0.0010659, 0.79847, 0.35106]
Predicted label: 8
Correct prediction
Energy consumption = 154.241576 pJ
sum error= 264
Actual label: 8
Output voltages: [0.45449, 0.006185, 0.51756, 0.10244, 0.018187, 0.0026366, 0.021898, 0.0043524, 0.79874, 0.22572]
Predicted label: 8
Correct prediction
Energy consumption = 143.771815 pJ
sum error= 264
Actual label: 7
Output voltages: [0.036251, 0.047616, 0.07151, 0.025716, 0.0016518, 0.0012335, 0.0020318, 0.79874, 0.35841, 0.063498]
Predicted label: 7
Correct prediction
Energy consumption = 157.564435 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 555 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 555 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 555 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.035422, 0.79836, 0.036627, 0.33903, 0.019586, 0.0081459, 0.74502, 0.0012208, 0.035689, 0.20043]
Predicted label: 1
Correct prediction
Energy consumption = 177.943366 pJ
sum error= 264
Actual label: 7
Output voltages: [0.33025, 0.12094, 0.0085398, 0.0091588, 0.0024824, 0.013437, 0.001661, 0.79878, 0.25533, 0.41033]
Predicted label: 7
Correct prediction
Energy consumption = 164.225811 pJ
sum error= 264
Actual label: 1
Output voltages: [0.46315, 0.79877, 0.48855, 0.3829, 0.20208, 0.0011909, 0.045102, 0.0015623, 0.017607, 0.090493]
Predicted label: 1
Correct prediction
Energy consumption = 163.028310 pJ
sum error= 264
Actual label: 1
Output voltages: [0.034535, 0.79837, 0.1305, 0.12384, 0.011605, 0.0027962, 0.71738, 0.0043553, 0.028022, 0.08181]
Predicted label: 1
Correct prediction
Energy consumption = 149.676623 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79879, 0.067167, 0.005637, 0.031772, 0.0089083, 0.18332, 0.7119, 0.017079, 0.28028, 0.019348]
Predicted label: 0
Correct prediction
Energy consumption = 157.264099 pJ
sum error= 264
Actual label: 3
Output voltages: [0.25158, 0.0067619, 0.12589, 0.79866, 0.026551, 0.065709, 0.029371, 0.040592, 0.74334, 0.11239]
Predicted label: 3
Correct prediction
Energy consumption = 150.470170 pJ
sum error= 264
Actual label: 4
Output voltages: [0.23252, 0.0027537, 0.2114, 0.0011854, 0.79878, 0.0011377, 0.039664, 0.017641, 0.048758, 0.13782]
Predicted label: 4
Correct prediction
Energy consumption = 146.325703 pJ
sum error= 264
Actual label: 2
Output voltages: [0.37361, 0.038515, 0.79871, 0.14202, 0.0020783, 0.001189, 0.15477, 0.15067, 0.71142, 0.012024]
Predicted label: 2
Correct prediction
Energy consumption = 147.288760 pJ
sum error= 264
Actual label: 6
Output voltages: [0.094124, 0.030809, 0.18078, 0.0010737, 0.38137, 0.065728, 0.79878, 0.001891, 0.49068, 0.0035323]
Predicted label: 6
Correct prediction
Energy consumption = 143.219730 pJ
sum error= 264
Actual label: 4
Output voltages: [0.044583, 0.0067686, 0.33545, 0.0023641, 0.79872, 0.0010707, 0.35759, 0.0048459, 0.021517, 0.089359]
Predicted label: 4
Correct prediction
Energy consumption = 145.298809 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 556 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 556 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 556 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28269, 0.015691, 0.012769, 0.049839, 0.011564, 0.012862, 0.001134, 0.79875, 0.54288, 0.56463]
Predicted label: 7
Correct prediction
Energy consumption = 176.682006 pJ
sum error= 264
Actual label: 4
Output voltages: [0.17645, 0.018793, 0.2322, 0.0010715, 0.79877, 0.0010795, 0.30335, 0.0012158, 0.13122, 0.19133]
Predicted label: 4
Correct prediction
Energy consumption = 147.620739 pJ
sum error= 264
Actual label: 2
Output voltages: [0.034278, 0.36348, 0.79856, 0.30356, 0.0047573, 0.0012646, 0.19952, 0.025514, 0.49601, 0.063418]
Predicted label: 2
Correct prediction
Energy consumption = 152.451044 pJ
sum error= 264
Actual label: 7
Output voltages: [0.058016, 0.11566, 0.31431, 0.1416, 0.0038942, 0.0010675, 0.0011022, 0.79866, 0.5831, 0.24855]
Predicted label: 7
Correct prediction
Energy consumption = 159.404010 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0099037, 0.027804, 0.36881, 0.0011406, 0.79742, 0.0010764, 0.68257, 0.098108, 0.33956, 0.035373]
Predicted label: 4
Correct prediction
Energy consumption = 143.887029 pJ
sum error= 264
Actual label: 9
Output voltages: [0.48638, 0.014125, 0.018286, 0.021526, 0.40372, 0.011885, 0.0063182, 0.016892, 0.086015, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 156.801945 pJ
sum error= 264
Actual label: 1
Output voltages: [0.12674, 0.79855, 0.039228, 0.19945, 0.0093073, 0.0072973, 0.75568, 0.0047337, 0.027449, 0.052241]
Predicted label: 1
Correct prediction
Energy consumption = 162.639721 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79846, 0.033904, 0.033527, 0.022217, 0.021413, 0.015952, 0.75609, 0.021965, 0.054073, 0.097115]
Predicted label: 0
Correct prediction
Energy consumption = 156.941837 pJ
sum error= 264
Actual label: 6
Output voltages: [0.22481, 0.27827, 0.37632, 0.0069625, 0.23365, 0.12615, 0.79868, 0.0014128, 0.24212, 0.034577]
Predicted label: 6
Correct prediction
Energy consumption = 142.123571 pJ
sum error= 264
Actual label: 8
Output voltages: [0.27111, 0.013379, 0.60014, 0.024353, 0.0089718, 0.01476, 0.0033705, 0.0039388, 0.79879, 0.36549]
Predicted label: 8
Correct prediction
Energy consumption = 145.873997 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 557 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 557 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 557 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.018496, 0.001066, 0.0023888, 0.15463, 0.018188, 0.79879, 0.24355, 0.079755, 0.72761, 0.051351]
Predicted label: 5
Correct prediction
Energy consumption = 163.978402 pJ
sum error= 264
Actual label: 5
Output voltages: [0.0047805, 0.001183, 0.0034147, 0.59938, 0.043259, 0.79817, 0.035597, 0.1351, 0.7658, 0.10435]
Predicted label: 5
Correct prediction
Energy consumption = 131.941714 pJ
sum error= 264
Actual label: 5
Output voltages: [0.23216, 0.0011145, 0.0014701, 0.33652, 0.046181, 0.79879, 0.11955, 0.043112, 0.76474, 0.032873]
Predicted label: 5
Correct prediction
Energy consumption = 132.734320 pJ
sum error= 264
Actual label: 3
Output voltages: [0.20419, 0.0017687, 0.066636, 0.79875, 0.030252, 0.31173, 0.010548, 0.022616, 0.73455, 0.026637]
Predicted label: 3
Correct prediction
Energy consumption = 139.973669 pJ
sum error= 264
Actual label: 5
Output voltages: [0.035273, 0.0010809, 0.0020449, 0.31682, 0.066356, 0.79875, 0.022867, 0.17883, 0.77591, 0.034816]
Predicted label: 5
Correct prediction
Energy consumption = 141.723252 pJ
sum error= 264
Actual label: 9
Output voltages: [0.23677, 0.023687, 0.025381, 0.031159, 0.25594, 0.0052824, 0.019609, 0.026973, 0.13497, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 156.530447 pJ
sum error= 264
Actual label: 7
Output voltages: [0.035165, 0.10054, 0.40268, 0.030418, 0.017753, 0.0011153, 0.0018552, 0.79868, 0.090565, 0.093748]
Predicted label: 7
Correct prediction
Energy consumption = 148.239336 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0095998, 0.021154, 0.015199, 0.063454, 0.79879, 0.0010992, 0.11803, 0.029991, 0.013565, 0.017803]
Predicted label: 4
Correct prediction
Energy consumption = 149.605153 pJ
sum error= 264
Actual label: 8
Output voltages: [0.20182, 0.047573, 0.14814, 0.237, 0.042446, 0.0041059, 0.20637, 0.0010729, 0.79763, 0.63221]
Predicted label: 8
Correct prediction
Energy consumption = 163.626653 pJ
sum error= 264
Actual label: 5
Output voltages: [0.041278, 0.0011419, 0.0029525, 0.1574, 0.057262, 0.79852, 0.18362, 0.026633, 0.79086, 0.020762]
Predicted label: 5
Correct prediction
Energy consumption = 137.365908 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 558 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 558 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 558 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.34913, 0.021003, 0.11271, 0.14063, 0.2439, 0.03903, 0.023807, 0.017619, 0.073708, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 174.086955 pJ
sum error= 264
Actual label: 6
Output voltages: [0.024044, 0.18073, 0.34133, 0.0034128, 0.17417, 0.19894, 0.79866, 0.0025716, 0.5451, 0.015618]
Predicted label: 6
Correct prediction
Energy consumption = 150.411448 pJ
sum error= 264
Actual label: 9
Output voltages: [0.5325, 0.015676, 0.022119, 0.025602, 0.23336, 0.043721, 0.002564, 0.023876, 0.36197, 0.79841]
Predicted label: 9
Correct prediction
Energy consumption = 156.810640 pJ
sum error= 264
Actual label: 3
Output voltages: [0.05595, 0.0082379, 0.030327, 0.79879, 0.012532, 0.047044, 0.0032888, 0.023639, 0.72102, 0.045727]
Predicted label: 3
Correct prediction
Energy consumption = 142.082086 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79877, 0.397, 0.024817, 0.012341, 0.027294, 0.021237, 0.69032, 0.018254, 0.050029, 0.074584]
Predicted label: 0
Correct prediction
Energy consumption = 157.449732 pJ
sum error= 264
Actual label: 3
Output voltages: [0.15016, 0.026858, 0.039612, 0.7986, 0.027056, 0.0069787, 0.023856, 0.033712, 0.60034, 0.045751]
Predicted label: 3
Correct prediction
Energy consumption = 147.946665 pJ
sum error= 264
Actual label: 8
Output voltages: [0.44687, 0.0090825, 0.38548, 0.43944, 0.009255, 0.0023199, 0.013403, 0.0013742, 0.7961, 0.52127]
Predicted label: 8
Correct prediction
Energy consumption = 150.572999 pJ
sum error= 264
Actual label: 9
Output voltages: [0.23376, 0.017833, 0.046334, 0.027047, 0.068812, 0.023152, 0.0060373, 0.1198, 0.5524, 0.79616]
Predicted label: 9
Correct prediction
Energy consumption = 150.901363 pJ
sum error= 264
Actual label: 1
Output voltages: [0.015602, 0.79854, 0.011954, 0.010598, 0.018963, 0.0047793, 0.47297, 0.0022532, 0.71893, 0.025754]
Predicted label: 1
Correct prediction
Energy consumption = 168.791651 pJ
sum error= 264
Actual label: 8
Output voltages: [0.025269, 0.10073, 0.45768, 0.017941, 0.029495, 0.0050265, 0.023731, 0.004247, 0.79873, 0.12895]
Predicted label: 8
Correct prediction
Energy consumption = 149.583634 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 559 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 559 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 559 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0026065, 0.79862, 0.041934, 0.031606, 0.013823, 0.0010667, 0.59408, 0.0011716, 0.26606, 0.04853]
Predicted label: 1
Correct prediction
Energy consumption = 176.176005 pJ
sum error= 264
Actual label: 6
Output voltages: [0.16852, 0.1632, 0.047963, 0.037393, 0.36929, 0.16057, 0.79878, 0.0013488, 0.53594, 0.021112]
Predicted label: 6
Correct prediction
Energy consumption = 150.480315 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79879, 0.095982, 0.29878, 0.033275, 0.033798, 0.01445, 0.38122, 0.038255, 0.49923, 0.038112]
Predicted label: 0
Correct prediction
Energy consumption = 158.652573 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79694, 0.050493, 0.52382, 0.020365, 0.0069955, 0.001072, 0.49837, 0.0072388, 0.31931, 0.069762]
Predicted label: 0
Correct prediction
Energy consumption = 139.836372 pJ
sum error= 264
Actual label: 1
Output voltages: [0.0084654, 0.79871, 0.053392, 0.12613, 0.036647, 0.0012791, 0.52325, 0.0065327, 0.39001, 0.020459]
Predicted label: 1
Correct prediction
Energy consumption = 159.688383 pJ
sum error= 264
Actual label: 2
Output voltages: [0.33931, 0.14209, 0.79865, 0.68679, 0.034365, 0.0012004, 0.15386, 0.010028, 0.22875, 0.028041]
Predicted label: 2
Correct prediction
Energy consumption = 147.855523 pJ
sum error= 264
Actual label: 3
Output voltages: [0.044481, 0.0032813, 0.13475, 0.79877, 0.19449, 0.16658, 0.018428, 0.01898, 0.42302, 0.18124]
Predicted label: 3
Correct prediction
Energy consumption = 144.791245 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0010958, 0.063805, 0.1756, 0.0109, 0.79878, 0.0011011, 0.063638, 0.07646, 0.021593, 0.18425]
Predicted label: 4
Correct prediction
Energy consumption = 153.451602 pJ
sum error= 264
Actual label: 5
Output voltages: [0.039154, 0.0014549, 0.0011514, 0.39971, 0.016923, 0.79868, 0.2333, 0.019475, 0.77441, 0.0017921]
Predicted label: 5
Correct prediction
Energy consumption = 151.918402 pJ
sum error= 264
Actual label: 6
Output voltages: [0.075449, 0.0033436, 0.018304, 0.027561, 0.51786, 0.29873, 0.79877, 0.0011013, 0.72422, 0.10318]
Predicted label: 6
Correct prediction
Energy consumption = 144.032320 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 560 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 560 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 560 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.68972, 0.11238, 0.0013026, 0.0014636, 0.037061, 0.0010696, 0.0062133, 0.41583, 0.24904, 0.76052]
Predicted label: 9
Wrong prediction!
Energy consumption = 187.812167 pJ
sum error= 265
Actual label: 8
Output voltages: [0.13637, 0.025303, 0.24518, 0.03776, 0.35546, 0.0010661, 0.067025, 0.0011676, 0.7932, 0.045463]
Predicted label: 8
Correct prediction
Energy consumption = 151.377298 pJ
sum error= 265
Actual label: 9
Output voltages: [0.21629, 0.017036, 0.12658, 0.010105, 0.034555, 0.03144, 0.0035571, 0.1456, 0.73259, 0.79137]
Predicted label: 9
Correct prediction
Energy consumption = 149.203949 pJ
sum error= 265
Actual label: 0
Output voltages: [0.79815, 0.01659, 0.15973, 0.036351, 0.0057011, 0.061879, 0.42626, 0.001066, 0.4538, 0.24789]
Predicted label: 0
Correct prediction
Energy consumption = 146.613834 pJ
sum error= 265
Actual label: 1
Output voltages: [0.0056478, 0.79862, 0.039121, 0.57446, 0.069368, 0.0010693, 0.037511, 0.046496, 0.066074, 0.15384]
Predicted label: 1
Correct prediction
Energy consumption = 166.933549 pJ
sum error= 265
Actual label: 2
Output voltages: [0.61875, 0.0092631, 0.79754, 0.47132, 0.0068792, 0.0011269, 0.024537, 0.0076033, 0.29127, 0.003106]
Predicted label: 2
Correct prediction
Energy consumption = 146.378716 pJ
sum error= 265
Actual label: 3
Output voltages: [0.22625, 0.033465, 0.03561, 0.79865, 0.013434, 0.0098944, 0.016191, 0.009842, 0.51717, 0.078281]
Predicted label: 3
Correct prediction
Energy consumption = 140.881223 pJ
sum error= 265
Actual label: 4
Output voltages: [0.031808, 0.037398, 0.050804, 0.0029704, 0.79872, 0.0061366, 0.025757, 0.042326, 0.032285, 0.48609]
Predicted label: 4
Correct prediction
Energy consumption = 149.580852 pJ
sum error= 265
Actual label: 5
Output voltages: [0.079148, 0.0010914, 0.0011069, 0.64834, 0.096871, 0.79876, 0.45478, 0.018193, 0.76633, 0.025157]
Predicted label: 5
Correct prediction
Energy consumption = 145.414188 pJ
sum error= 265
Actual label: 6
Output voltages: [0.057185, 0.19897, 0.30119, 0.0011187, 0.37573, 0.13338, 0.79869, 0.0011583, 0.39178, 0.011604]
Predicted label: 6
Correct prediction
Energy consumption = 136.561009 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 561 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 561 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 561 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.48078, 0.026032, 0.04517, 0.006871, 0.069585, 0.0032603, 0.0073336, 0.79879, 0.027936, 0.62673]
Predicted label: 7
Correct prediction
Energy consumption = 177.083189 pJ
sum error= 265
Actual label: 8
Output voltages: [0.043111, 0.018938, 0.095496, 0.26461, 0.0096977, 0.035122, 0.16254, 0.003083, 0.79867, 0.079785]
Predicted label: 8
Correct prediction
Energy consumption = 156.898686 pJ
sum error= 265
Actual label: 9
Output voltages: [0.19385, 0.03908, 0.035449, 0.062895, 0.036992, 0.030546, 0.011817, 0.046132, 0.46871, 0.7985]
Predicted label: 9
Correct prediction
Energy consumption = 152.830664 pJ
sum error= 265
Actual label: 0
Output voltages: [0.79364, 0.013726, 0.034996, 0.00567, 0.036838, 0.078117, 0.78317, 0.0020905, 0.20004, 0.21788]
Predicted label: 0
Correct prediction
Energy consumption = 142.055978 pJ
sum error= 265
Actual label: 1
Output voltages: [0.0074433, 0.7984, 0.055283, 0.074055, 0.028177, 0.0095332, 0.1397, 0.0029019, 0.066135, 0.18379]
Predicted label: 1
Correct prediction
Energy consumption = 162.702136 pJ
sum error= 265
Actual label: 2
Output voltages: [0.19008, 0.1193, 0.79878, 0.38361, 0.024778, 0.0013033, 0.42708, 0.0079286, 0.5672, 0.054509]
Predicted label: 2
Correct prediction
Energy consumption = 143.244852 pJ
sum error= 265
Actual label: 3
Output voltages: [0.27131, 0.015251, 0.36221, 0.79878, 0.033091, 0.0024739, 0.012645, 0.0031598, 0.73027, 0.14233]
Predicted label: 3
Correct prediction
Energy consumption = 144.713992 pJ
sum error= 265
Actual label: 4
Output voltages: [0.0011294, 0.042718, 0.0011182, 0.0012751, 0.79873, 0.0010676, 0.043474, 0.21281, 0.37343, 0.021393]
Predicted label: 4
Correct prediction
Energy consumption = 154.101650 pJ
sum error= 265
Actual label: 5
Output voltages: [0.064016, 0.0034496, 0.021864, 0.48606, 0.010786, 0.79817, 0.02976, 0.0085734, 0.79867, 0.054547]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.307101 pJ
sum error= 266
Actual label: 6
Output voltages: [0.039755, 0.052619, 0.63049, 0.0010707, 0.51855, 0.21212, 0.79871, 0.0011458, 0.044652, 0.003474]
Predicted label: 6
Correct prediction
Energy consumption = 144.620409 pJ
sum error= 266
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 562 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 562 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 562 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.10155, 0.037523, 0.046891, 0.002749, 0.03554, 0.0020321, 0.0096097, 0.7987, 0.19784, 0.55709]
Predicted label: 7
Correct prediction
Energy consumption = 174.623891 pJ
sum error= 266
Actual label: 8
Output voltages: [0.014439, 0.0071612, 0.018306, 0.031339, 0.049891, 0.057006, 0.2866, 0.02097, 0.79875, 0.054788]
Predicted label: 8
Correct prediction
Energy consumption = 152.262414 pJ
sum error= 266
Actual label: 9
Output voltages: [0.38427, 0.015977, 0.018245, 0.042553, 0.42794, 0.020162, 0.011587, 0.034075, 0.072413, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 156.468000 pJ
sum error= 266
Actual label: 3
Output voltages: [0.67474, 0.010777, 0.021187, 0.79879, 0.0021314, 0.26456, 0.0041703, 0.10526, 0.30946, 0.016105]
Predicted label: 3
Correct prediction
Energy consumption = 147.145097 pJ
sum error= 266
Actual label: 5
Output voltages: [0.017748, 0.0015537, 0.004898, 0.59546, 0.010327, 0.79266, 0.083084, 0.004792, 0.75513, 0.039641]
Predicted label: 5
Correct prediction
Energy consumption = 139.134011 pJ
sum error= 266
Actual label: 3
Output voltages: [0.29758, 0.0092146, 0.035333, 0.79873, 0.02543, 0.018925, 0.031423, 0.0052616, 0.41125, 0.036869]
Predicted label: 3
Correct prediction
Energy consumption = 142.649310 pJ
sum error= 266
Actual label: 2
Output voltages: [0.23178, 0.037727, 0.79877, 0.089426, 0.015752, 0.0013038, 0.45424, 0.067799, 0.5096, 0.012559]
Predicted label: 2
Correct prediction
Energy consumption = 138.560539 pJ
sum error= 266
Actual label: 9
Output voltages: [0.22314, 0.037628, 0.032279, 0.13961, 0.099206, 0.014318, 0.012287, 0.013467, 0.086958, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 158.322353 pJ
sum error= 266
Actual label: 3
Output voltages: [0.44686, 0.0017417, 0.2803, 0.79878, 0.0037572, 0.080863, 0.0044235, 0.0092664, 0.52971, 0.0086428]
Predicted label: 3
Correct prediction
Energy consumption = 149.631416 pJ
sum error= 266
Actual label: 2
Output voltages: [0.35234, 0.020667, 0.79879, 0.10296, 0.028167, 0.0012292, 0.1331, 0.015666, 0.65707, 0.03221]
Predicted label: 2
Correct prediction
Energy consumption = 141.488369 pJ
sum error= 266
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 563 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 563 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 563 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0033128, 0.79879, 0.061885, 0.56212, 0.065346, 0.001066, 0.021532, 0.28148, 0.11875, 0.040432]
Predicted label: 1
Correct prediction
Energy consumption = 187.759191 pJ
sum error= 266
Actual label: 4
Output voltages: [0.0038259, 0.017552, 0.1451, 0.024341, 0.79868, 0.0011051, 0.035488, 0.24813, 0.021726, 0.064106]
Predicted label: 4
Correct prediction
Energy consumption = 153.166303 pJ
sum error= 266
Actual label: 5
Output voltages: [0.033593, 0.0010733, 0.001374, 0.41653, 0.07726, 0.79879, 0.14934, 0.01537, 0.73271, 0.094938]
Predicted label: 5
Correct prediction
Energy consumption = 153.043678 pJ
sum error= 266
Actual label: 5
Output voltages: [0.21512, 0.0010715, 0.0012407, 0.12126, 0.021694, 0.79873, 0.29167, 0.013896, 0.71897, 0.0027288]
Predicted label: 5
Correct prediction
Energy consumption = 142.000007 pJ
sum error= 266
Actual label: 2
Output voltages: [0.43378, 0.036251, 0.79351, 0.74635, 0.0032833, 0.0012128, 0.014453, 0.010765, 0.74696, 0.015926]
Predicted label: 2
Correct prediction
Energy consumption = 150.251009 pJ
sum error= 266
Actual label: 3
Output voltages: [0.12363, 0.0148, 0.14025, 0.79875, 0.033498, 0.03174, 0.0059909, 0.036122, 0.72351, 0.19059]
Predicted label: 3
Correct prediction
Energy consumption = 139.518661 pJ
sum error= 266
Actual label: 2
Output voltages: [0.31988, 0.041033, 0.79858, 0.53401, 0.036457, 0.0012874, 0.13804, 0.012735, 0.48712, 0.01876]
Predicted label: 2
Correct prediction
Energy consumption = 140.261837 pJ
sum error= 266
Actual label: 1
Output voltages: [0.022011, 0.79844, 0.02224, 0.39084, 0.029072, 0.01626, 0.32829, 0.010962, 0.25701, 0.44433]
Predicted label: 1
Correct prediction
Energy consumption = 162.557599 pJ
sum error= 266
Actual label: 3
Output voltages: [0.2553, 0.016633, 0.019245, 0.79874, 0.0021496, 0.020742, 0.12835, 0.121, 0.31974, 0.0019542]
Predicted label: 3
Correct prediction
Energy consumption = 148.420338 pJ
sum error= 266
Actual label: 9
Output voltages: [0.30054, 0.009589, 0.017205, 0.10376, 0.0061175, 0.01921, 0.0020849, 0.32899, 0.61205, 0.79787]
Predicted label: 9
Correct prediction
Energy consumption = 150.818525 pJ
sum error= 266
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 564 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 564 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 564 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.07754, 0.027832, 0.023027, 0.029951, 0.014495, 0.0038071, 0.0010677, 0.79867, 0.11009, 0.52878]
Predicted label: 7
Correct prediction
Energy consumption = 173.800382 pJ
sum error= 266
Actual label: 2
Output voltages: [0.147, 0.0048975, 0.79878, 0.27867, 0.025096, 0.001096, 0.085437, 0.013602, 0.6922, 0.0081263]
Predicted label: 2
Correct prediction
Energy consumption = 147.606725 pJ
sum error= 266
Actual label: 1
Output voltages: [0.26409, 0.78379, 0.0013718, 0.0053451, 0.065377, 0.62676, 0.29065, 0.0047769, 0.768, 0.0020998]
Predicted label: 1
Correct prediction
Energy consumption = 167.375737 pJ
sum error= 266
Actual label: 2
Output voltages: [0.056394, 0.0026029, 0.78256, 0.73415, 0.02452, 0.0014431, 0.01827, 0.0084198, 0.78958, 0.0060372]
Predicted label: 8
Wrong prediction!
Energy consumption = 142.458346 pJ
sum error= 267
Actual label: 8
Output voltages: [0.0034103, 0.019067, 0.0043286, 0.049879, 0.016213, 0.072991, 0.52954, 0.011456, 0.79849, 0.018292]
Predicted label: 8
Correct prediction
Energy consumption = 149.679021 pJ
sum error= 267
Actual label: 9
Output voltages: [0.28907, 0.0083689, 0.013489, 0.017745, 0.15672, 0.0066846, 0.0026016, 0.029236, 0.45698, 0.79824]
Predicted label: 9
Correct prediction
Energy consumption = 151.578280 pJ
sum error= 267
Actual label: 1
Output voltages: [0.010017, 0.79848, 0.018052, 0.040936, 0.012221, 0.0015856, 0.75398, 0.0062974, 0.41776, 0.039867]
Predicted label: 1
Correct prediction
Energy consumption = 166.627286 pJ
sum error= 267
Actual label: 8
Output voltages: [0.0066259, 0.083926, 0.036427, 0.028057, 0.10971, 0.26745, 0.6129, 0.01228, 0.79871, 0.0049017]
Predicted label: 8
Correct prediction
Energy consumption = 152.306446 pJ
sum error= 267
Actual label: 8
Output voltages: [0.0060519, 0.037622, 0.05028, 0.036719, 0.056852, 0.048851, 0.055946, 0.025303, 0.7987, 0.040848]
Predicted label: 8
Correct prediction
Energy consumption = 151.933162 pJ
sum error= 267
Actual label: 7
Output voltages: [0.3482, 0.10239, 0.0017394, 0.0010745, 0.037294, 0.0053483, 0.0023759, 0.76265, 0.53773, 0.59367]
Predicted label: 7
Correct prediction
Energy consumption = 157.418273 pJ
sum error= 267
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 565 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 565 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 565 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0058651, 0.006831, 0.010473, 0.013032, 0.11976, 0.042284, 0.22732, 0.048064, 0.79869, 0.02336]
Predicted label: 8
Correct prediction
Energy consumption = 164.722157 pJ
sum error= 267
Actual label: 1
Output voltages: [0.27959, 0.79864, 0.024749, 0.027562, 0.048598, 0.0011974, 0.18358, 0.0029751, 0.29822, 0.21285]
Predicted label: 1
Correct prediction
Energy consumption = 164.047040 pJ
sum error= 267
Actual label: 0
Output voltages: [0.79845, 0.068995, 0.014709, 0.021477, 0.096375, 0.0099336, 0.76606, 0.0099832, 0.16794, 0.022034]
Predicted label: 0
Correct prediction
Energy consumption = 158.193305 pJ
sum error= 267
Actual label: 0
Output voltages: [0.79853, 0.030336, 0.10075, 0.02009, 0.05194, 0.010369, 0.7652, 0.018807, 0.39115, 0.047684]
Predicted label: 0
Correct prediction
Energy consumption = 143.007113 pJ
sum error= 267
Actual label: 7
Output voltages: [0.53618, 0.24892, 0.41792, 0.023619, 0.26492, 0.0012897, 0.025615, 0.032337, 0.083928, 0.71096]
Predicted label: 9
Wrong prediction!
Energy consumption = 161.627396 pJ
sum error= 268
Actual label: 7
Output voltages: [0.27581, 0.35645, 0.64126, 0.0015578, 0.0049275, 0.0011108, 0.0014506, 0.79678, 0.39849, 0.19254]
Predicted label: 7
Correct prediction
Energy consumption = 149.088629 pJ
sum error= 268
Actual label: 8
Output voltages: [0.0087748, 0.019406, 0.047791, 0.34548, 0.0098597, 0.016582, 0.048969, 0.0029421, 0.79876, 0.051543]
Predicted label: 8
Correct prediction
Energy consumption = 152.896638 pJ
sum error= 268
Actual label: 7
Output voltages: [0.1613, 0.050036, 0.023917, 0.077502, 0.010922, 0.0068887, 0.0010829, 0.79869, 0.047777, 0.46979]
Predicted label: 7
Correct prediction
Energy consumption = 154.055706 pJ
sum error= 268
Actual label: 5
Output voltages: [0.040225, 0.0011634, 0.0010728, 0.52008, 0.048086, 0.79879, 0.15462, 0.074709, 0.75956, 0.026034]
Predicted label: 5
Correct prediction
Energy consumption = 141.590416 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79873, 0.041521, 0.082842, 0.0051787, 0.0086368, 0.0017348, 0.70386, 0.0096003, 0.048166, 0.18434]
Predicted label: 0
Correct prediction
Energy consumption = 151.827170 pJ
sum error= 268
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 566 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 566 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 566 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.089623, 0.054534, 0.18277, 0.017096, 0.12567, 0.53111, 0.79867, 0.0071066, 0.37174, 0.019509]
Predicted label: 6
Correct prediction
Energy consumption = 164.391149 pJ
sum error= 268
Actual label: 1
Output voltages: [0.001862, 0.79877, 0.021233, 0.047911, 0.011647, 0.022051, 0.6476, 0.020166, 0.60089, 0.0013984]
Predicted label: 1
Correct prediction
Energy consumption = 157.506926 pJ
sum error= 268
Actual label: 5
Output voltages: [0.087225, 0.0014276, 0.0070381, 0.53434, 0.018017, 0.79859, 0.05341, 0.037895, 0.76337, 0.082825]
Predicted label: 5
Correct prediction
Energy consumption = 149.965050 pJ
sum error= 268
Actual label: 7
Output voltages: [0.073311, 0.094568, 0.026508, 0.055365, 0.025741, 0.00809, 0.0017772, 0.7987, 0.04575, 0.67362]
Predicted label: 7
Correct prediction
Energy consumption = 156.961949 pJ
sum error= 268
Actual label: 4
Output voltages: [0.0081381, 0.016503, 0.016744, 0.0054024, 0.79875, 0.0010864, 0.021495, 0.026415, 0.20988, 0.019682]
Predicted label: 4
Correct prediction
Energy consumption = 144.251498 pJ
sum error= 268
Actual label: 6
Output voltages: [0.40226, 0.019471, 0.039092, 0.020462, 0.39734, 0.27968, 0.79878, 0.0012167, 0.50827, 0.022542]
Predicted label: 6
Correct prediction
Energy consumption = 155.136926 pJ
sum error= 268
Actual label: 1
Output voltages: [0.011152, 0.79865, 0.023842, 0.082972, 0.040262, 0.0032649, 0.68837, 0.010261, 0.39287, 0.0166]
Predicted label: 1
Correct prediction
Energy consumption = 162.954280 pJ
sum error= 268
Actual label: 2
Output voltages: [0.19846, 0.0043518, 0.79879, 0.18311, 0.0059332, 0.0011777, 0.072439, 0.052573, 0.6506, 0.0094243]
Predicted label: 2
Correct prediction
Energy consumption = 144.949146 pJ
sum error= 268
Actual label: 5
Output voltages: [0.025162, 0.0017233, 0.010365, 0.027844, 0.046939, 0.79683, 0.16194, 0.0027002, 0.7839, 0.025248]
Predicted label: 5
Correct prediction
Energy consumption = 148.127121 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79871, 0.043397, 0.045547, 0.022111, 0.0081658, 0.034428, 0.57706, 0.0068953, 0.34334, 0.37246]
Predicted label: 0
Correct prediction
Energy consumption = 152.831732 pJ
sum error= 268
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 567 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 567 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 567 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.063188, 0.11449, 0.050821, 0.018035, 0.017983, 0.049183, 0.0010663, 0.79859, 0.28781, 0.25703]
Predicted label: 7
Correct prediction
Energy consumption = 173.574271 pJ
sum error= 268
Actual label: 9
Output voltages: [0.27707, 0.024777, 0.016826, 0.052831, 0.38629, 0.0098631, 0.0011498, 0.0070159, 0.26645, 0.7979]
Predicted label: 9
Correct prediction
Energy consumption = 146.470541 pJ
sum error= 268
Actual label: 9
Output voltages: [0.23605, 0.0081081, 0.033162, 0.017086, 0.39662, 0.0078505, 0.010295, 0.0040113, 0.46511, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 143.749839 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79874, 0.21965, 0.04057, 0.032068, 0.0020962, 0.018684, 0.17884, 0.0041543, 0.216, 0.52466]
Predicted label: 0
Correct prediction
Energy consumption = 147.211924 pJ
sum error= 268
Actual label: 3
Output voltages: [0.75491, 0.016238, 0.034302, 0.79865, 0.012295, 0.041725, 0.0049334, 0.018546, 0.34729, 0.026044]
Predicted label: 3
Correct prediction
Energy consumption = 149.640807 pJ
sum error= 268
Actual label: 8
Output voltages: [0.024162, 0.001213, 0.19458, 0.046429, 0.046619, 0.0052169, 0.63147, 0.0038067, 0.79869, 0.018184]
Predicted label: 8
Correct prediction
Energy consumption = 154.186205 pJ
sum error= 268
Actual label: 4
Output voltages: [0.033188, 0.13703, 0.29608, 0.010882, 0.79067, 0.0012452, 0.34803, 0.25377, 0.10049, 0.13935]
Predicted label: 4
Correct prediction
Energy consumption = 140.783538 pJ
sum error= 268
Actual label: 4
Output voltages: [0.0017077, 0.44283, 0.2952, 0.001134, 0.79874, 0.0084767, 0.095478, 0.025919, 0.020882, 0.037053]
Predicted label: 4
Correct prediction
Energy consumption = 146.132523 pJ
sum error= 268
Actual label: 8
Output voltages: [0.006186, 0.025002, 0.0050612, 0.23002, 0.02646, 0.0288, 0.70562, 0.0049749, 0.79823, 0.0077175]
Predicted label: 8
Correct prediction
Energy consumption = 153.692272 pJ
sum error= 268
Actual label: 1
Output voltages: [0.0045969, 0.79869, 0.14244, 0.1844, 0.031989, 0.001066, 0.02875, 0.012249, 0.23407, 0.095644]
Predicted label: 1
Correct prediction
Energy consumption = 161.234833 pJ
sum error= 268
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 568 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 568 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 568 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.013227, 0.0038362, 0.014344, 0.11092, 0.007069, 0.065887, 0.53354, 0.0057141, 0.79879, 0.022722]
Predicted label: 8
Correct prediction
Energy consumption = 174.310258 pJ
sum error= 268
Actual label: 6
Output voltages: [0.2966, 0.02273, 0.20391, 0.013327, 0.43525, 0.35954, 0.79876, 0.0018714, 0.57583, 0.0063448]
Predicted label: 6
Correct prediction
Energy consumption = 148.446966 pJ
sum error= 268
Actual label: 5
Output voltages: [0.27176, 0.0011812, 0.010979, 0.46492, 0.010733, 0.79879, 0.2071, 0.038339, 0.73348, 0.064297]
Predicted label: 5
Correct prediction
Energy consumption = 151.807665 pJ
sum error= 268
Actual label: 9
Output voltages: [0.4281, 0.011379, 0.0065063, 0.03976, 0.12008, 0.021793, 0.0031146, 0.030195, 0.41733, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 148.821717 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79879, 0.17618, 0.015771, 0.013724, 0.0065705, 0.0096402, 0.54978, 0.030222, 0.19784, 0.040843]
Predicted label: 0
Correct prediction
Energy consumption = 151.271428 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79877, 0.028302, 0.012059, 0.0083731, 0.013126, 0.26343, 0.3621, 0.006333, 0.35463, 0.017008]
Predicted label: 0
Correct prediction
Energy consumption = 149.312712 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79852, 0.051874, 0.023901, 0.0027518, 0.0088268, 0.012349, 0.58328, 0.012152, 0.037001, 0.32049]
Predicted label: 0
Correct prediction
Energy consumption = 144.482436 pJ
sum error= 268
Actual label: 3
Output voltages: [0.18624, 0.0073543, 0.033971, 0.7987, 0.034605, 0.022329, 0.036293, 0.015224, 0.6993, 0.2628]
Predicted label: 3
Correct prediction
Energy consumption = 150.420395 pJ
sum error= 268
Actual label: 7
Output voltages: [0.38036, 0.041188, 0.013498, 0.085453, 0.0051577, 0.085467, 0.0010923, 0.78996, 0.72362, 0.7733]
Predicted label: 7
Correct prediction
Energy consumption = 160.461496 pJ
sum error= 268
Actual label: 1
Output voltages: [0.40559, 0.7985, 0.0039324, 0.40948, 0.001913, 0.0088467, 0.5807, 0.012559, 0.093582, 0.057622]
Predicted label: 1
Correct prediction
Energy consumption = 164.144831 pJ
sum error= 268
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 569 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 569 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 569 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.15669, 0.022539, 0.12439, 0.012487, 0.40804, 0.26357, 0.79877, 0.0016128, 0.41514, 0.016979]
Predicted label: 6
Correct prediction
Energy consumption = 165.880018 pJ
sum error= 268
Actual label: 4
Output voltages: [0.013995, 0.53523, 0.051952, 0.08262, 0.79452, 0.0011183, 0.10048, 0.30439, 0.045596, 0.033417]
Predicted label: 4
Correct prediction
Energy consumption = 155.610010 pJ
sum error= 268
Actual label: 2
Output voltages: [0.40253, 0.11085, 0.79872, 0.076998, 0.036535, 0.0012218, 0.55531, 0.025807, 0.50322, 0.075744]
Predicted label: 2
Correct prediction
Energy consumption = 143.992370 pJ
sum error= 268
Actual label: 6
Output voltages: [0.13735, 0.045284, 0.087326, 0.0088157, 0.35895, 0.55167, 0.79872, 0.0026356, 0.51059, 0.003274]
Predicted label: 6
Correct prediction
Energy consumption = 145.234717 pJ
sum error= 268
Actual label: 6
Output voltages: [0.055627, 0.11873, 0.26762, 0.0040845, 0.28546, 0.38321, 0.79869, 0.0016482, 0.44687, 0.022168]
Predicted label: 6
Correct prediction
Energy consumption = 133.233373 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79272, 0.035997, 0.046627, 0.0073926, 0.004798, 0.0088612, 0.10003, 0.0060439, 0.7754, 0.037502]
Predicted label: 0
Correct prediction
Energy consumption = 153.079995 pJ
sum error= 268
Actual label: 4
Output voltages: [0.0037266, 0.0071454, 0.067292, 0.0087264, 0.79868, 0.0016006, 0.55969, 0.021867, 0.027629, 0.027881]
Predicted label: 4
Correct prediction
Energy consumption = 148.905905 pJ
sum error= 268
Actual label: 5
Output voltages: [0.047321, 0.0011232, 0.0020061, 0.53539, 0.015344, 0.79844, 0.066973, 0.037443, 0.72719, 0.21577]
Predicted label: 5
Correct prediction
Energy consumption = 148.755104 pJ
sum error= 268
Actual label: 4
Output voltages: [0.0016853, 0.22264, 0.021848, 0.0010716, 0.79879, 0.04168, 0.13402, 0.073365, 0.25737, 0.064443]
Predicted label: 4
Correct prediction
Energy consumption = 158.440928 pJ
sum error= 268
Actual label: 1
Output voltages: [0.018894, 0.79844, 0.043841, 0.14742, 0.23255, 0.010488, 0.16438, 0.015031, 0.03582, 0.29279]
Predicted label: 1
Correct prediction
Energy consumption = 158.077417 pJ
sum error= 268
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 570 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 570 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 570 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.27661, 0.039262, 0.025777, 0.79866, 0.0083325, 0.0066063, 0.023114, 0.0048985, 0.44112, 0.1357]
Predicted label: 3
Correct prediction
Energy consumption = 169.018498 pJ
sum error= 268
Actual label: 8
Output voltages: [0.0097115, 0.043355, 0.30142, 0.0040543, 0.2584, 0.0060166, 0.04089, 0.0025297, 0.79874, 0.15665]
Predicted label: 8
Correct prediction
Energy consumption = 152.996059 pJ
sum error= 268
Actual label: 6
Output voltages: [0.059472, 0.039008, 0.3618, 0.0015845, 0.48376, 0.47978, 0.79868, 0.0020622, 0.13897, 0.004924]
Predicted label: 6
Correct prediction
Energy consumption = 145.279309 pJ
sum error= 268
Actual label: 3
Output voltages: [0.06962, 0.0061649, 0.15418, 0.79879, 0.03776, 0.022675, 0.016018, 0.034415, 0.76121, 0.10704]
Predicted label: 3
Correct prediction
Energy consumption = 148.553591 pJ
sum error= 268
Actual label: 9
Output voltages: [0.041796, 0.0078108, 0.022625, 0.12385, 0.41732, 0.22322, 0.23392, 0.019334, 0.18663, 0.79865]
Predicted label: 9
Correct prediction
Energy consumption = 155.578217 pJ
sum error= 268
Actual label: 9
Output voltages: [0.35012, 0.012638, 0.026145, 0.21379, 0.55673, 0.010095, 0.002869, 0.036365, 0.053519, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 143.241782 pJ
sum error= 268
Actual label: 5
Output voltages: [0.10598, 0.0011006, 0.044093, 0.1363, 0.0062197, 0.79652, 0.083549, 0.0017926, 0.7984, 0.045483]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.232323 pJ
sum error= 269
Actual label: 9
Output voltages: [0.12287, 0.03901, 0.033728, 0.14024, 0.022215, 0.044336, 0.034552, 0.21964, 0.39088, 0.79717]
Predicted label: 9
Correct prediction
Energy consumption = 147.001819 pJ
sum error= 269
Actual label: 3
Output voltages: [0.23132, 0.029458, 0.03659, 0.79859, 0.016111, 0.019357, 0.010876, 0.024544, 0.51766, 0.063173]
Predicted label: 3
Correct prediction
Energy consumption = 151.334097 pJ
sum error= 269
Actual label: 7
Output voltages: [0.24884, 0.28819, 0.0082451, 0.0068032, 0.0014626, 0.016612, 0.0035123, 0.79872, 0.11649, 0.69543]
Predicted label: 7
Correct prediction
Energy consumption = 159.714500 pJ
sum error= 269
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 571 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 571 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 571 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.018778, 0.022422, 0.014767, 0.63236, 0.0058677, 0.01858, 0.18537, 0.0015442, 0.79846, 0.44959]
Predicted label: 8
Correct prediction
Energy consumption = 171.298390 pJ
sum error= 269
Actual label: 5
Output voltages: [0.05302, 0.0012093, 0.0015577, 0.39212, 0.022553, 0.79835, 0.15215, 0.0065083, 0.75304, 0.13355]
Predicted label: 5
Correct prediction
Energy consumption = 147.871049 pJ
sum error= 269
Actual label: 6
Output voltages: [0.23426, 0.064684, 0.30891, 0.005104, 0.44391, 0.49306, 0.79861, 0.0040425, 0.45439, 0.0062035]
Predicted label: 6
Correct prediction
Energy consumption = 144.260235 pJ
sum error= 269
Actual label: 4
Output voltages: [0.0050738, 0.039645, 0.26864, 0.0015906, 0.7987, 0.002704, 0.051116, 0.61948, 0.072137, 0.2928]
Predicted label: 4
Correct prediction
Energy consumption = 150.887963 pJ
sum error= 269
Actual label: 7
Output voltages: [0.19428, 0.057613, 0.093082, 0.040218, 0.007867, 0.021465, 0.0013199, 0.79854, 0.2165, 0.25238]
Predicted label: 7
Correct prediction
Energy consumption = 160.776364 pJ
sum error= 269
Actual label: 6
Output voltages: [0.045187, 0.044144, 0.17514, 0.002318, 0.4184, 0.23255, 0.79871, 0.0022595, 0.53083, 0.0097417]
Predicted label: 6
Correct prediction
Energy consumption = 151.239337 pJ
sum error= 269
Actual label: 2
Output voltages: [0.41908, 0.043914, 0.79876, 0.17384, 0.048045, 0.0011835, 0.43328, 0.033003, 0.66404, 0.050389]
Predicted label: 2
Correct prediction
Energy consumption = 145.949935 pJ
sum error= 269
Actual label: 2
Output voltages: [0.14269, 0.022584, 0.79879, 0.022466, 0.0025932, 0.0011111, 0.036614, 0.022381, 0.73155, 0.024282]
Predicted label: 2
Correct prediction
Energy consumption = 140.422571 pJ
sum error= 269
Actual label: 0
Output voltages: [0.79756, 0.19149, 0.020668, 0.0040624, 0.0070455, 0.011601, 0.63432, 0.0020874, 0.32123, 0.091439]
Predicted label: 0
Correct prediction
Energy consumption = 158.317006 pJ
sum error= 269
Actual label: 9
Output voltages: [0.23493, 0.018755, 0.016823, 0.087242, 0.32472, 0.19413, 0.019357, 0.027658, 0.086594, 0.79862]
Predicted label: 9
Correct prediction
Energy consumption = 151.896484 pJ
sum error= 269
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 572 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 572 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 572 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0010859, 0.28757, 0.015754, 0.035364, 0.79474, 0.0012001, 0.14258, 0.0090048, 0.40157, 0.0089366]
Predicted label: 4
Correct prediction
Energy consumption = 166.896950 pJ
sum error= 269
Actual label: 0
Output voltages: [0.79879, 0.030895, 0.042362, 0.0080521, 0.039398, 0.0058371, 0.54586, 0.024138, 0.057071, 0.20789]
Predicted label: 0
Correct prediction
Energy consumption = 161.032391 pJ
sum error= 269
Actual label: 1
Output voltages: [0.007397, 0.79865, 0.017229, 0.024099, 0.014415, 0.0010691, 0.64129, 0.0023225, 0.47754, 0.01858]
Predicted label: 1
Correct prediction
Energy consumption = 158.397661 pJ
sum error= 269
Actual label: 2
Output voltages: [0.51384, 0.015907, 0.79877, 0.023788, 0.0085596, 0.0011935, 0.061554, 0.041442, 0.54378, 0.013598]
Predicted label: 2
Correct prediction
Energy consumption = 145.863771 pJ
sum error= 269
Actual label: 3
Output voltages: [0.055483, 0.027223, 0.049522, 0.79874, 0.012245, 0.0025787, 0.011123, 0.013405, 0.73811, 0.033017]
Predicted label: 3
Correct prediction
Energy consumption = 145.572440 pJ
sum error= 269
Actual label: 4
Output voltages: [0.035238, 0.0048273, 0.27542, 0.0022225, 0.79861, 0.0015607, 0.23806, 0.048045, 0.05017, 0.031087]
Predicted label: 4
Correct prediction
Energy consumption = 157.250593 pJ
sum error= 269
Actual label: 5
Output voltages: [0.026156, 0.0011677, 0.0063986, 0.1074, 0.038606, 0.79726, 0.038494, 0.010393, 0.78793, 0.16244]
Predicted label: 5
Correct prediction
Energy consumption = 145.373795 pJ
sum error= 269
Actual label: 6
Output voltages: [0.081968, 0.04753, 0.40712, 0.0015267, 0.45908, 0.292, 0.79875, 0.0034897, 0.18067, 0.0022468]
Predicted label: 6
Correct prediction
Energy consumption = 147.910502 pJ
sum error= 269
Actual label: 7
Output voltages: [0.049145, 0.0011081, 0.016367, 0.038295, 0.20318, 0.026764, 0.0011173, 0.79871, 0.59161, 0.32734]
Predicted label: 7
Correct prediction
Energy consumption = 156.183133 pJ
sum error= 269
Actual label: 8
Output voltages: [0.0054797, 0.061055, 0.24094, 0.048524, 0.0044343, 0.018814, 0.022395, 0.032574, 0.79872, 0.18591]
Predicted label: 8
Correct prediction
Energy consumption = 138.003346 pJ
sum error= 269
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 573 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 573 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 573 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.48125, 0.014062, 0.027123, 0.0217, 0.19641, 0.021719, 0.0028315, 0.031913, 0.50767, 0.79784]
Predicted label: 9
Correct prediction
Energy consumption = 165.088269 pJ
sum error= 269
Actual label: 0
Output voltages: [0.79809, 0.062909, 0.052338, 0.27344, 0.0025083, 0.0013785, 0.47218, 0.0012415, 0.10059, 0.56816]
Predicted label: 0
Correct prediction
Energy consumption = 154.654696 pJ
sum error= 269
Actual label: 1
Output voltages: [0.0046483, 0.79857, 0.24653, 0.18793, 0.0024949, 0.0010934, 0.3161, 0.0056852, 0.26902, 0.011044]
Predicted label: 1
Correct prediction
Energy consumption = 164.376340 pJ
sum error= 269
Actual label: 2
Output voltages: [0.46751, 0.11368, 0.7987, 0.15469, 0.090093, 0.0010748, 0.37029, 0.032735, 0.37236, 0.034577]
Predicted label: 2
Correct prediction
Energy consumption = 144.201336 pJ
sum error= 269
Actual label: 3
Output voltages: [0.024043, 0.027299, 0.51597, 0.79815, 0.0011464, 0.011202, 0.0069428, 0.47081, 0.044771, 0.33259]
Predicted label: 3
Correct prediction
Energy consumption = 137.496357 pJ
sum error= 269
Actual label: 5
Output voltages: [0.0071224, 0.0014003, 0.11576, 0.19358, 0.024447, 0.77458, 0.49311, 0.0068101, 0.78173, 0.029951]
Predicted label: 8
Wrong prediction!
Energy consumption = 155.760195 pJ
sum error= 270
Actual label: 6
Output voltages: [0.037172, 0.0013884, 0.23066, 0.052097, 0.69707, 0.038115, 0.79449, 0.0046191, 0.45425, 0.032404]
Predicted label: 6
Correct prediction
Energy consumption = 135.904005 pJ
sum error= 270
Actual label: 0
Output voltages: [0.79864, 0.32514, 0.032991, 0.2982, 0.0043497, 0.11746, 0.30076, 0.003833, 0.12978, 0.17152]
Predicted label: 0
Correct prediction
Energy consumption = 153.546515 pJ
sum error= 270
Actual label: 1
Output voltages: [0.0054735, 0.79846, 0.034938, 0.080987, 0.0057072, 0.001409, 0.7446, 0.016098, 0.13995, 0.022856]
Predicted label: 1
Correct prediction
Energy consumption = 160.238483 pJ
sum error= 270
Actual label: 2
Output voltages: [0.12921, 0.24784, 0.79879, 0.29898, 0.031246, 0.0013135, 0.045187, 0.042949, 0.2345, 0.042192]
Predicted label: 2
Correct prediction
Energy consumption = 140.956907 pJ
sum error= 270
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 574 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 574 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 574 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.029462, 0.003993, 0.028217, 0.79878, 0.19678, 0.054868, 0.044148, 0.038029, 0.36317, 0.053237]
Predicted label: 3
Correct prediction
Energy consumption = 168.931445 pJ
sum error= 270
Actual label: 4
Output voltages: [0.0060401, 0.012952, 0.030006, 0.0023113, 0.79867, 0.0030347, 0.25601, 0.54877, 0.082255, 0.0075469]
Predicted label: 4
Correct prediction
Energy consumption = 151.265360 pJ
sum error= 270
Actual label: 5
Output voltages: [0.051408, 0.0010661, 0.0040168, 0.61278, 0.009914, 0.79613, 0.004255, 0.020336, 0.76091, 0.16044]
Predicted label: 5
Correct prediction
Energy consumption = 151.227575 pJ
sum error= 270
Actual label: 6
Output voltages: [0.023312, 0.011015, 0.31729, 0.007819, 0.27043, 0.28938, 0.79875, 0.0035398, 0.731, 0.0013845]
Predicted label: 6
Correct prediction
Energy consumption = 148.436490 pJ
sum error= 270
Actual label: 8
Output voltages: [0.0065776, 0.039025, 0.12132, 0.099265, 0.0053461, 0.036929, 0.021803, 0.030785, 0.79874, 0.2307]
Predicted label: 8
Correct prediction
Energy consumption = 143.824349 pJ
sum error= 270
Actual label: 7
Output voltages: [0.08113, 0.68554, 0.21729, 0.2005, 0.014221, 0.0012783, 0.0014702, 0.77713, 0.28743, 0.090837]
Predicted label: 7
Correct prediction
Energy consumption = 152.620309 pJ
sum error= 270
Actual label: 1
Output voltages: [0.034471, 0.79879, 0.042361, 0.0023063, 0.040623, 0.0022025, 0.35161, 0.0064723, 0.50536, 0.074136]
Predicted label: 1
Correct prediction
Energy consumption = 156.485236 pJ
sum error= 270
Actual label: 3
Output voltages: [0.29334, 0.0081574, 0.60188, 0.79878, 0.01548, 0.003055, 0.0032485, 0.040805, 0.41249, 0.097202]
Predicted label: 3
Correct prediction
Energy consumption = 152.984936 pJ
sum error= 270
Actual label: 2
Output voltages: [0.20105, 0.019006, 0.79879, 0.081862, 0.024393, 0.0010717, 0.098669, 0.043789, 0.75202, 0.008095]
Predicted label: 2
Correct prediction
Energy consumption = 136.764368 pJ
sum error= 270
Actual label: 8
Output voltages: [0.0056177, 0.0027218, 0.037359, 0.0010754, 0.060719, 0.68896, 0.61371, 0.02692, 0.79498, 0.0016352]
Predicted label: 8
Correct prediction
Energy consumption = 140.378113 pJ
sum error= 270
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 575 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 575 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 575 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79822, 0.3164, 0.22003, 0.021343, 0.0018556, 0.0010661, 0.50084, 0.012313, 0.17761, 0.21168]
Predicted label: 0
Correct prediction
Energy consumption = 167.127333 pJ
sum error= 270
Actual label: 7
Output voltages: [0.27466, 0.023379, 0.096385, 0.44325, 0.0024145, 0.0015651, 0.0012132, 0.79859, 0.54279, 0.15624]
Predicted label: 7
Correct prediction
Energy consumption = 154.692896 pJ
sum error= 270
Actual label: 5
Output voltages: [0.5196, 0.0010788, 0.0095917, 0.78601, 0.0010662, 0.77157, 0.017994, 0.010627, 0.51773, 0.076797]
Predicted label: 3
Wrong prediction!
Energy consumption = 143.865604 pJ
sum error= 271
Actual label: 9
Output voltages: [0.30203, 0.0064934, 0.048889, 0.36247, 0.69749, 0.0062336, 0.0054649, 0.054019, 0.028786, 0.79788]
Predicted label: 9
Correct prediction
Energy consumption = 144.794836 pJ
sum error= 271
Actual label: 9
Output voltages: [0.1982, 0.0014185, 0.085787, 0.014307, 0.61731, 0.007309, 0.034625, 0.3053, 0.011392, 0.78906]
Predicted label: 9
Correct prediction
Energy consumption = 146.990413 pJ
sum error= 271
Actual label: 6
Output voltages: [0.041478, 0.036359, 0.48326, 0.0011522, 0.32032, 0.20484, 0.79875, 0.0025325, 0.62756, 0.0024958]
Predicted label: 6
Correct prediction
Energy consumption = 139.015812 pJ
sum error= 271
Actual label: 0
Output voltages: [0.79573, 0.01575, 0.22425, 0.049946, 0.21448, 0.0010901, 0.61031, 0.011533, 0.2177, 0.26078]
Predicted label: 0
Correct prediction
Energy consumption = 139.626620 pJ
sum error= 271
Actual label: 9
Output voltages: [0.73585, 0.0077389, 0.0036426, 0.1385, 0.37781, 0.036586, 0.003935, 0.0048065, 0.33812, 0.79459]
Predicted label: 9
Correct prediction
Energy consumption = 148.792048 pJ
sum error= 271
Actual label: 4
Output voltages: [0.0014407, 0.018148, 0.063978, 0.0052532, 0.79862, 0.0047002, 0.14518, 0.35403, 0.14334, 0.0035504]
Predicted label: 4
Correct prediction
Energy consumption = 150.819962 pJ
sum error= 271
Actual label: 1
Output voltages: [0.41037, 0.79575, 0.064053, 0.0017125, 0.5713, 0.0042214, 0.60899, 0.0013966, 0.048128, 0.021625]
Predicted label: 1
Correct prediction
Energy consumption = 150.284861 pJ
sum error= 271
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 576 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 576 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 576 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.55931, 0.0080122, 0.47098, 0.79875, 0.016634, 0.0017451, 0.011995, 0.026486, 0.34178, 0.012065]
Predicted label: 3
Correct prediction
Energy consumption = 163.807316 pJ
sum error= 271
Actual label: 2
Output voltages: [0.46715, 0.0018941, 0.79874, 0.034663, 0.014484, 0.0011295, 0.014251, 0.091504, 0.63901, 0.0017091]
Predicted label: 2
Correct prediction
Energy consumption = 132.078177 pJ
sum error= 271
Actual label: 1
Output voltages: [0.030782, 0.79877, 0.53767, 0.14242, 0.28744, 0.0011563, 0.22502, 0.0016513, 0.025338, 0.28559]
Predicted label: 1
Correct prediction
Energy consumption = 164.629316 pJ
sum error= 271
Actual label: 2
Output voltages: [0.44184, 0.018084, 0.79878, 0.046264, 0.0054366, 0.0012177, 0.068887, 0.13605, 0.75075, 0.012059]
Predicted label: 2
Correct prediction
Energy consumption = 137.996081 pJ
sum error= 271
Actual label: 3
Output voltages: [0.23991, 0.024216, 0.0714, 0.79862, 0.042347, 0.01759, 0.0092905, 0.013237, 0.72597, 0.030738]
Predicted label: 3
Correct prediction
Energy consumption = 147.763422 pJ
sum error= 271
Actual label: 8
Output voltages: [0.023273, 0.0077512, 0.32801, 0.064628, 0.029585, 0.0052382, 0.014915, 0.034784, 0.79874, 0.024002]
Predicted label: 8
Correct prediction
Energy consumption = 139.040055 pJ
sum error= 271
Actual label: 3
Output voltages: [0.10022, 0.14615, 0.26509, 0.79869, 0.0095586, 0.010027, 0.001784, 0.011824, 0.74168, 0.060235]
Predicted label: 3
Correct prediction
Energy consumption = 140.260371 pJ
sum error= 271
Actual label: 2
Output voltages: [0.65319, 0.10745, 0.7987, 0.052416, 0.030597, 0.0011914, 0.38383, 0.047943, 0.22477, 0.095532]
Predicted label: 2
Correct prediction
Energy consumption = 138.622375 pJ
sum error= 271
Actual label: 6
Output voltages: [0.049448, 0.034956, 0.4109, 0.0012403, 0.30667, 0.17943, 0.79874, 0.0038929, 0.40884, 0.0043456]
Predicted label: 6
Correct prediction
Energy consumption = 142.160799 pJ
sum error= 271
Actual label: 5
Output voltages: [0.29263, 0.003775, 0.023015, 0.16867, 0.032093, 0.75492, 0.77734, 0.0011397, 0.76224, 0.016425]
Predicted label: 6
Wrong prediction!
Energy consumption = 137.989394 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 577 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 577 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 577 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.061853, 0.045319, 0.41757, 0.0015463, 0.29646, 0.12108, 0.79879, 0.0012459, 0.55046, 0.0027663]
Predicted label: 6
Correct prediction
Energy consumption = 164.573001 pJ
sum error= 272
Actual label: 8
Output voltages: [0.049936, 0.0043166, 0.11013, 0.25609, 0.0050736, 0.037547, 0.016064, 0.0018687, 0.79879, 0.38601]
Predicted label: 8
Correct prediction
Energy consumption = 143.947249 pJ
sum error= 272
Actual label: 2
Output voltages: [0.56955, 0.0427, 0.79875, 0.065469, 0.01565, 0.0011983, 0.049618, 0.24757, 0.42639, 0.03419]
Predicted label: 2
Correct prediction
Energy consumption = 145.923133 pJ
sum error= 272
Actual label: 7
Output voltages: [0.26933, 0.03314, 0.0021427, 0.24455, 0.0034242, 0.0029573, 0.0012573, 0.78995, 0.44736, 0.75503]
Predicted label: 7
Correct prediction
Energy consumption = 151.094283 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0034015, 0.017793, 0.029079, 0.025702, 0.79869, 0.0010741, 0.1571, 0.048261, 0.07466, 0.016483]
Predicted label: 4
Correct prediction
Energy consumption = 156.697371 pJ
sum error= 272
Actual label: 8
Output voltages: [0.0065066, 0.0638, 0.20386, 0.022982, 0.025927, 0.0053353, 0.056672, 0.0058599, 0.79873, 0.44447]
Predicted label: 8
Correct prediction
Energy consumption = 139.684825 pJ
sum error= 272
Actual label: 1
Output voltages: [0.03165, 0.7985, 0.10549, 0.011357, 0.10358, 0.0041452, 0.6393, 0.0084706, 0.18084, 0.056864]
Predicted label: 1
Correct prediction
Energy consumption = 160.590899 pJ
sum error= 272
Actual label: 8
Output voltages: [0.0064648, 0.032642, 0.1067, 0.040251, 0.024105, 0.010144, 0.18166, 0.010397, 0.79873, 0.32006]
Predicted label: 8
Correct prediction
Energy consumption = 142.405957 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79843, 0.080754, 0.33834, 0.02007, 0.15755, 0.0010731, 0.23073, 0.039792, 0.22812, 0.0080061]
Predicted label: 0
Correct prediction
Energy consumption = 156.970192 pJ
sum error= 272
Actual label: 5
Output voltages: [0.034872, 0.0017149, 0.0010922, 0.66549, 0.0082636, 0.79875, 0.1269, 0.034283, 0.68966, 0.035798]
Predicted label: 5
Correct prediction
Energy consumption = 153.928367 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 578 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 578 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 578 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.52849, 0.018862, 0.44083, 0.79875, 0.018033, 0.0023872, 0.0020708, 0.036372, 0.5767, 0.022007]
Predicted label: 3
Correct prediction
Energy consumption = 165.370296 pJ
sum error= 272
Actual label: 9
Output voltages: [0.17981, 0.012313, 0.01392, 0.058971, 0.046924, 0.009032, 0.001529, 0.024276, 0.71121, 0.79843]
Predicted label: 9
Correct prediction
Energy consumption = 149.213493 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0012467, 0.015975, 0.446, 0.0073931, 0.7986, 0.0044836, 0.13749, 0.043531, 0.032474, 0.15223]
Predicted label: 4
Correct prediction
Energy consumption = 151.210003 pJ
sum error= 272
Actual label: 1
Output voltages: [0.047347, 0.79865, 0.21206, 0.045011, 0.056747, 0.0010659, 0.61157, 0.0010721, 0.12419, 0.026179]
Predicted label: 1
Correct prediction
Energy consumption = 164.180283 pJ
sum error= 272
Actual label: 9
Output voltages: [0.25588, 0.0070327, 0.0058514, 0.053303, 0.66613, 0.020736, 0.030984, 0.094744, 0.013865, 0.79407]
Predicted label: 9
Correct prediction
Energy consumption = 155.564307 pJ
sum error= 272
Actual label: 2
Output voltages: [0.39553, 0.032285, 0.79864, 0.032728, 0.0084582, 0.0011326, 0.20917, 0.024163, 0.4342, 0.023459]
Predicted label: 2
Correct prediction
Energy consumption = 135.217689 pJ
sum error= 272
Actual label: 1
Output voltages: [0.0091632, 0.79852, 0.16267, 0.10558, 0.017536, 0.0014304, 0.74858, 0.0046213, 0.11232, 0.047475]
Predicted label: 1
Correct prediction
Energy consumption = 156.143748 pJ
sum error= 272
Actual label: 9
Output voltages: [0.46356, 0.0070914, 0.024444, 0.017527, 0.12421, 0.021221, 0.0032468, 0.020331, 0.45208, 0.79866]
Predicted label: 9
Correct prediction
Energy consumption = 151.716222 pJ
sum error= 272
Actual label: 6
Output voltages: [0.042217, 0.047199, 0.18598, 0.0077361, 0.3724, 0.30035, 0.79872, 0.0029646, 0.60174, 0.0050872]
Predicted label: 6
Correct prediction
Energy consumption = 149.202086 pJ
sum error= 272
Actual label: 7
Output voltages: [0.11888, 0.017047, 0.034172, 0.10378, 0.0044097, 0.0040647, 0.0011528, 0.79872, 0.59993, 0.39985]
Predicted label: 7
Correct prediction
Energy consumption = 159.155944 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 579 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 579 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 579 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.67021, 0.0027832, 0.023774, 0.0078452, 0.058611, 0.059161, 0.0040103, 0.047632, 0.75526, 0.79798]
Predicted label: 9
Correct prediction
Energy consumption = 166.989855 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79791, 0.034175, 0.1732, 0.036556, 0.022819, 0.0042832, 0.76968, 0.016964, 0.16833, 0.016986]
Predicted label: 0
Correct prediction
Energy consumption = 150.315716 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0074349, 0.0056055, 0.052581, 0.0070135, 0.79871, 0.019952, 0.20559, 0.38248, 0.14372, 0.0015909]
Predicted label: 4
Correct prediction
Energy consumption = 156.914346 pJ
sum error= 272
Actual label: 6
Output voltages: [0.21673, 0.12669, 0.35265, 0.0044431, 0.26513, 0.22631, 0.79873, 0.0016595, 0.17888, 0.0063489]
Predicted label: 6
Correct prediction
Energy consumption = 146.727179 pJ
sum error= 272
Actual label: 1
Output voltages: [0.0069922, 0.79874, 0.032794, 0.0031843, 0.24413, 0.016149, 0.76148, 0.0018445, 0.46558, 0.016186]
Predicted label: 1
Correct prediction
Energy consumption = 157.334723 pJ
sum error= 272
Actual label: 7
Output voltages: [0.016562, 0.022776, 0.055915, 0.038051, 0.0098265, 0.0012621, 0.0011923, 0.79879, 0.76152, 0.15064]
Predicted label: 7
Correct prediction
Energy consumption = 154.145155 pJ
sum error= 272
Actual label: 3
Output voltages: [0.53263, 0.047521, 0.031693, 0.7986, 0.022648, 0.020367, 0.040856, 0.0030034, 0.5682, 0.22728]
Predicted label: 3
Correct prediction
Energy consumption = 147.279917 pJ
sum error= 272
Actual label: 8
Output voltages: [0.015172, 0.037218, 0.065633, 0.62719, 0.0012687, 0.026366, 0.036537, 0.032822, 0.79877, 0.013359]
Predicted label: 8
Correct prediction
Energy consumption = 146.087711 pJ
sum error= 272
Actual label: 7
Output voltages: [0.24306, 0.022932, 0.019384, 0.20478, 0.0031629, 0.0083582, 0.0011396, 0.79879, 0.42895, 0.7113]
Predicted label: 7
Correct prediction
Energy consumption = 152.594368 pJ
sum error= 272
Actual label: 2
Output voltages: [0.31743, 0.05537, 0.79876, 0.11459, 0.016542, 0.0012928, 0.36474, 0.053682, 0.64198, 0.047582]
Predicted label: 2
Correct prediction
Energy consumption = 143.271525 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 580 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 580 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 580 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.21248, 0.0073795, 0.042461, 0.37491, 0.095806, 0.061213, 0.04937, 0.072729, 0.17881, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 172.561774 pJ
sum error= 272
Actual label: 6
Output voltages: [0.52119, 0.2343, 0.13433, 0.0199, 0.20958, 0.042838, 0.79561, 0.0010936, 0.53694, 0.0047289]
Predicted label: 6
Correct prediction
Energy consumption = 148.329090 pJ
sum error= 272
Actual label: 5
Output voltages: [0.045085, 0.0054675, 0.008946, 0.48116, 0.010197, 0.79855, 0.026705, 0.012788, 0.78143, 0.068791]
Predicted label: 5
Correct prediction
Energy consumption = 148.396232 pJ
sum error= 272
Actual label: 8
Output voltages: [0.016219, 0.003008, 0.034156, 0.24919, 0.0042242, 0.18749, 0.029716, 0.0011171, 0.7987, 0.040534]
Predicted label: 8
Correct prediction
Energy consumption = 138.518152 pJ
sum error= 272
Actual label: 3
Output voltages: [0.39617, 0.036621, 0.040854, 0.79858, 0.013692, 0.027832, 0.007994, 0.029559, 0.70261, 0.03801]
Predicted label: 3
Correct prediction
Energy consumption = 146.307411 pJ
sum error= 272
Actual label: 9
Output voltages: [0.45321, 0.014659, 0.0068752, 0.18635, 0.17313, 0.014706, 0.0023649, 0.019719, 0.47432, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 143.448913 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79879, 0.04918, 0.074907, 0.049911, 0.14854, 0.0011195, 0.57653, 0.0058887, 0.14805, 0.065703]
Predicted label: 0
Correct prediction
Energy consumption = 152.385061 pJ
sum error= 272
Actual label: 5
Output voltages: [0.16739, 0.001103, 0.026095, 0.35394, 0.0026817, 0.79811, 0.016694, 0.10954, 0.76054, 0.056866]
Predicted label: 5
Correct prediction
Energy consumption = 152.629223 pJ
sum error= 272
Actual label: 7
Output voltages: [0.26, 0.11618, 0.31119, 0.35109, 0.0044151, 0.0021319, 0.0012023, 0.79871, 0.25602, 0.16431]
Predicted label: 7
Correct prediction
Energy consumption = 155.085319 pJ
sum error= 272
Actual label: 1
Output voltages: [0.0063634, 0.79866, 0.031507, 0.015799, 0.16662, 0.0082043, 0.47421, 0.016385, 0.20149, 0.029927]
Predicted label: 1
Correct prediction
Energy consumption = 150.581491 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 581 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 581 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 581 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.072729, 0.025188, 0.11481, 0.0016556, 0.32672, 0.35312, 0.79866, 0.0057413, 0.53072, 0.01125]
Predicted label: 6
Correct prediction
Energy consumption = 165.156624 pJ
sum error= 272
Actual label: 1
Output voltages: [0.012998, 0.79864, 0.40863, 0.014517, 0.50718, 0.0011112, 0.28195, 0.014131, 0.073971, 0.014236]
Predicted label: 1
Correct prediction
Energy consumption = 155.408023 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79879, 0.035122, 0.23592, 0.047437, 0.04159, 0.0011466, 0.15211, 0.011822, 0.12573, 0.12159]
Predicted label: 0
Correct prediction
Energy consumption = 155.521091 pJ
sum error= 272
Actual label: 9
Output voltages: [0.54547, 0.004008, 0.017332, 0.028376, 0.2052, 0.005745, 0.0012269, 0.052756, 0.44991, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 152.439793 pJ
sum error= 272
Actual label: 3
Output voltages: [0.75352, 0.065422, 0.034565, 0.79879, 0.0046546, 0.4228, 0.13173, 0.037942, 0.19051, 0.0024329]
Predicted label: 3
Correct prediction
Energy consumption = 153.103609 pJ
sum error= 272
Actual label: 3
Output voltages: [0.73911, 0.012034, 0.064743, 0.79862, 0.024959, 0.093038, 0.013458, 0.023094, 0.62377, 0.039259]
Predicted label: 3
Correct prediction
Energy consumption = 133.815806 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0077754, 0.004867, 0.46157, 0.0096473, 0.7987, 0.0014134, 0.50362, 0.48492, 0.01307, 0.0068002]
Predicted label: 4
Correct prediction
Energy consumption = 144.756589 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0021404, 0.0041526, 0.30766, 0.0073512, 0.79862, 0.0012078, 0.42753, 0.093458, 0.017561, 0.022923]
Predicted label: 4
Correct prediction
Energy consumption = 146.380716 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79855, 0.036134, 0.043766, 0.020661, 0.024974, 0.0026609, 0.63002, 0.0056115, 0.080148, 0.065149]
Predicted label: 0
Correct prediction
Energy consumption = 159.690595 pJ
sum error= 272
Actual label: 6
Output voltages: [0.29401, 0.10854, 0.19034, 0.0039262, 0.30682, 0.12964, 0.79876, 0.0012263, 0.48395, 0.0046124]
Predicted label: 6
Correct prediction
Energy consumption = 143.306407 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 582 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 582 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 582 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.24856, 0.019334, 0.79879, 0.1541, 0.013755, 0.0011233, 0.15913, 0.24049, 0.47976, 0.0043038]
Predicted label: 2
Correct prediction
Energy consumption = 158.985418 pJ
sum error= 272
Actual label: 5
Output voltages: [0.050569, 0.0052628, 0.0025955, 0.45633, 0.018953, 0.79879, 0.16984, 0.039622, 0.7283, 0.04581]
Predicted label: 5
Correct prediction
Energy consumption = 150.249615 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0081231, 0.012157, 0.053502, 0.0072701, 0.79874, 0.0011144, 0.40871, 0.22247, 0.044258, 0.018822]
Predicted label: 4
Correct prediction
Energy consumption = 158.769351 pJ
sum error= 272
Actual label: 2
Output voltages: [0.23218, 0.065757, 0.79876, 0.024773, 0.0042138, 0.0012154, 0.034765, 0.043783, 0.28374, 0.037581]
Predicted label: 2
Correct prediction
Energy consumption = 150.920968 pJ
sum error= 272
Actual label: 3
Output voltages: [0.042857, 0.025308, 0.031165, 0.79874, 0.027598, 0.011251, 0.0041339, 0.024616, 0.70242, 0.069457]
Predicted label: 3
Correct prediction
Energy consumption = 136.324879 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0029248, 0.0049112, 0.36785, 0.001498, 0.79851, 0.0076882, 0.20394, 0.14287, 0.072906, 0.087484]
Predicted label: 4
Correct prediction
Energy consumption = 151.667379 pJ
sum error= 272
Actual label: 6
Output voltages: [0.12384, 0.044788, 0.30773, 0.0016985, 0.12549, 0.091882, 0.79878, 0.0017742, 0.44298, 0.015034]
Predicted label: 6
Correct prediction
Energy consumption = 138.707559 pJ
sum error= 272
Actual label: 0
Output voltages: [0.7986, 0.036068, 0.21049, 0.03544, 0.022706, 0.001194, 0.57977, 0.015615, 0.29544, 0.19128]
Predicted label: 0
Correct prediction
Energy consumption = 156.568553 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79878, 0.015737, 0.0395, 0.062443, 0.0071732, 0.037842, 0.66307, 0.0020229, 0.03165, 0.31196]
Predicted label: 0
Correct prediction
Energy consumption = 140.233706 pJ
sum error= 272
Actual label: 2
Output voltages: [0.34641, 0.16085, 0.79496, 0.74518, 0.20478, 0.0011027, 0.017582, 0.081354, 0.044079, 0.029468]
Predicted label: 2
Correct prediction
Energy consumption = 144.694199 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 583 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 583 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 583 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79869, 0.029076, 0.016485, 0.03502, 0.037504, 0.017868, 0.31057, 0.034477, 0.24286, 0.33666]
Predicted label: 0
Correct prediction
Energy consumption = 165.040020 pJ
sum error= 272
Actual label: 1
Output voltages: [0.022903, 0.79856, 0.018389, 0.04363, 0.017215, 0.038704, 0.76953, 0.033769, 0.19263, 0.0064191]
Predicted label: 1
Correct prediction
Energy consumption = 163.942582 pJ
sum error= 272
Actual label: 4
Output voltages: [0.007454, 0.0013393, 0.38806, 0.0011835, 0.79857, 0.0012436, 0.072785, 0.021014, 0.06909, 0.049754]
Predicted label: 4
Correct prediction
Energy consumption = 143.196413 pJ
sum error= 272
Actual label: 5
Output voltages: [0.027572, 0.0013666, 0.0050678, 0.55563, 0.0082093, 0.79877, 0.017855, 0.048997, 0.75925, 0.071131]
Predicted label: 5
Correct prediction
Energy consumption = 143.236994 pJ
sum error= 272
Actual label: 6
Output voltages: [0.10504, 0.04507, 0.14812, 0.0032756, 0.17309, 0.14172, 0.79878, 0.0016798, 0.6583, 0.0085291]
Predicted label: 6
Correct prediction
Energy consumption = 147.289175 pJ
sum error= 272
Actual label: 7
Output voltages: [0.45599, 0.0015277, 0.62162, 0.058638, 0.040573, 0.0010843, 0.081087, 0.77716, 0.032694, 0.66484]
Predicted label: 7
Correct prediction
Energy consumption = 159.376943 pJ
sum error= 272
Actual label: 8
Output voltages: [0.0041265, 0.035176, 0.21151, 0.074714, 0.0031381, 0.03131, 0.055658, 0.0089539, 0.79875, 0.047413]
Predicted label: 8
Correct prediction
Energy consumption = 149.048346 pJ
sum error= 272
Actual label: 9
Output voltages: [0.39215, 0.0091563, 0.040537, 0.021346, 0.26394, 0.029912, 0.013426, 0.020426, 0.19423, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 153.434253 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79863, 0.034197, 0.038289, 0.013456, 0.036469, 0.14628, 0.46804, 0.041386, 0.031852, 0.020579]
Predicted label: 0
Correct prediction
Energy consumption = 144.325314 pJ
sum error= 272
Actual label: 1
Output voltages: [0.014673, 0.79866, 0.060386, 0.019609, 0.071544, 0.0016774, 0.28184, 0.0010802, 0.31307, 0.038706]
Predicted label: 1
Correct prediction
Energy consumption = 155.499287 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 584 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 584 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 584 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.032371, 0.0036257, 0.79879, 0.12911, 0.0040405, 0.001067, 0.30902, 0.064023, 0.71931, 0.0026304]
Predicted label: 2
Correct prediction
Energy consumption = 164.519452 pJ
sum error= 272
Actual label: 3
Output voltages: [0.59053, 0.010556, 0.0086593, 0.79877, 0.0011096, 0.65533, 0.041145, 0.14008, 0.16999, 0.0011607]
Predicted label: 3
Correct prediction
Energy consumption = 137.281861 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0011568, 0.0095816, 0.047067, 0.011545, 0.79879, 0.0010882, 0.038534, 0.66925, 0.020533, 0.045615]
Predicted label: 4
Correct prediction
Energy consumption = 146.438512 pJ
sum error= 272
Actual label: 5
Output voltages: [0.030093, 0.0011489, 0.0074719, 0.14544, 0.015345, 0.79845, 0.21205, 0.0088242, 0.76795, 0.056572]
Predicted label: 5
Correct prediction
Energy consumption = 145.322476 pJ
sum error= 272
Actual label: 6
Output voltages: [0.072077, 0.047947, 0.43569, 0.0021342, 0.3628, 0.23401, 0.7987, 0.0034184, 0.66228, 0.026272]
Predicted label: 6
Correct prediction
Energy consumption = 138.823134 pJ
sum error= 272
Actual label: 7
Output voltages: [0.54649, 0.00108, 0.14683, 0.020103, 0.40597, 0.00108, 0.0012032, 0.79879, 0.24542, 0.11693]
Predicted label: 7
Correct prediction
Energy consumption = 151.513199 pJ
sum error= 272
Actual label: 8
Output voltages: [0.0056515, 0.011659, 0.048324, 0.039206, 0.0045639, 0.1273, 0.027878, 0.028204, 0.79869, 0.039555]
Predicted label: 8
Correct prediction
Energy consumption = 145.928172 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79878, 0.015189, 0.047982, 0.047244, 0.061673, 0.011685, 0.016773, 0.31159, 0.3863, 0.029058]
Predicted label: 0
Correct prediction
Energy consumption = 151.481072 pJ
sum error= 272
Actual label: 1
Output voltages: [0.010238, 0.79858, 0.13424, 0.052088, 0.0019498, 0.0012064, 0.38923, 0.0082286, 0.38894, 0.01712]
Predicted label: 1
Correct prediction
Energy consumption = 167.536664 pJ
sum error= 272
Actual label: 2
Output voltages: [0.49854, 0.030645, 0.7964, 0.48688, 0.017919, 0.001133, 0.21561, 0.015084, 0.68732, 0.016027]
Predicted label: 2
Correct prediction
Energy consumption = 141.738884 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 585 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 585 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 585 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.74058, 0.0086634, 0.12702, 0.79878, 0.0061444, 0.25693, 0.0013423, 0.061401, 0.29004, 0.0058496]
Predicted label: 3
Correct prediction
Energy consumption = 164.331110 pJ
sum error= 272
Actual label: 4
Output voltages: [0.052559, 0.040537, 0.19975, 0.043105, 0.79871, 0.0012737, 0.34248, 0.039208, 0.0075435, 0.037018]
Predicted label: 4
Correct prediction
Energy consumption = 149.406635 pJ
sum error= 272
Actual label: 5
Output voltages: [0.048762, 0.0016843, 0.0011295, 0.46334, 0.049752, 0.79878, 0.22267, 0.038926, 0.64443, 0.17404]
Predicted label: 5
Correct prediction
Energy consumption = 151.414629 pJ
sum error= 272
Actual label: 6
Output voltages: [0.032623, 0.010926, 0.075248, 0.0082642, 0.32666, 0.28445, 0.79877, 0.0045502, 0.62947, 0.017164]
Predicted label: 6
Correct prediction
Energy consumption = 147.287512 pJ
sum error= 272
Actual label: 7
Output voltages: [0.24445, 0.0037205, 0.022138, 0.024545, 0.073628, 0.0012916, 0.0010738, 0.79877, 0.40166, 0.27208]
Predicted label: 7
Correct prediction
Energy consumption = 151.565678 pJ
sum error= 272
Actual label: 8
Output voltages: [0.16754, 0.061038, 0.19683, 0.48328, 0.0064877, 0.014654, 0.19799, 0.0079043, 0.79879, 0.033929]
Predicted label: 8
Correct prediction
Energy consumption = 152.174293 pJ
sum error= 272
Actual label: 9
Output voltages: [0.63238, 0.012702, 0.004554, 0.12036, 0.601, 0.1658, 0.020354, 0.027667, 0.13025, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 155.915804 pJ
sum error= 272
Actual label: 8
Output voltages: [0.16464, 0.034205, 0.42611, 0.17929, 0.023831, 0.0025314, 0.039901, 0.0012286, 0.79873, 0.090673]
Predicted label: 8
Correct prediction
Energy consumption = 150.353171 pJ
sum error= 272
Actual label: 7
Output voltages: [0.24433, 0.0011592, 0.0066703, 0.67126, 0.31038, 0.0011074, 0.0011459, 0.70246, 0.62, 0.32339]
Predicted label: 7
Correct prediction
Energy consumption = 144.643071 pJ
sum error= 272
Actual label: 1
Output voltages: [0.014608, 0.7984, 0.37415, 0.14829, 0.027072, 0.0025751, 0.58576, 0.0042061, 0.030725, 0.069954]
Predicted label: 1
Correct prediction
Energy consumption = 155.859991 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 586 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 586 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 586 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.4757, 0.001069, 0.023725, 0.79876, 0.089238, 0.48682, 0.005782, 0.0087065, 0.39318, 0.014718]
Predicted label: 3
Correct prediction
Energy consumption = 160.472598 pJ
sum error= 272
Actual label: 7
Output voltages: [0.027954, 0.020641, 0.1458, 0.04286, 0.031889, 0.0011027, 0.0012415, 0.79862, 0.12452, 0.017455]
Predicted label: 7
Correct prediction
Energy consumption = 151.204791 pJ
sum error= 272
Actual label: 5
Output voltages: [0.18078, 0.0018791, 0.0025784, 0.74365, 0.026784, 0.79872, 0.042915, 0.14847, 0.54406, 0.21738]
Predicted label: 5
Correct prediction
Energy consumption = 147.276473 pJ
sum error= 272
Actual label: 2
Output voltages: [0.30042, 0.030917, 0.79879, 0.03173, 0.013838, 0.0012928, 0.38802, 0.021558, 0.65363, 0.021087]
Predicted label: 2
Correct prediction
Energy consumption = 152.312619 pJ
sum error= 272
Actual label: 8
Output voltages: [0.010859, 0.020952, 0.054923, 0.018374, 0.013289, 0.013384, 0.056447, 0.010803, 0.79873, 0.25524]
Predicted label: 8
Correct prediction
Energy consumption = 150.402440 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79873, 0.046708, 0.044839, 0.018542, 0.024163, 0.018896, 0.19064, 0.012686, 0.24406, 0.033522]
Predicted label: 0
Correct prediction
Energy consumption = 156.322564 pJ
sum error= 272
Actual label: 7
Output voltages: [0.13496, 0.0091441, 0.074007, 0.0050927, 0.36185, 0.0010919, 0.0011721, 0.79866, 0.036436, 0.027392]
Predicted label: 7
Correct prediction
Energy consumption = 151.772362 pJ
sum error= 272
Actual label: 5
Output voltages: [0.20923, 0.0015257, 0.0021019, 0.7071, 0.030907, 0.79852, 0.059579, 0.028121, 0.61569, 0.17023]
Predicted label: 5
Correct prediction
Energy consumption = 148.346963 pJ
sum error= 272
Actual label: 9
Output voltages: [0.23665, 0.042671, 0.038003, 0.26636, 0.27638, 0.027226, 0.021947, 0.027896, 0.16833, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 149.616514 pJ
sum error= 272
Actual label: 9
Output voltages: [0.24898, 0.020916, 0.028119, 0.19903, 0.39861, 0.067808, 0.022183, 0.01514, 0.058273, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 138.246010 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 587 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 587 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 587 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79873, 0.050016, 0.23588, 0.011773, 0.039934, 0.001608, 0.10926, 0.027403, 0.25918, 0.04261]
Predicted label: 0
Correct prediction
Energy consumption = 177.641435 pJ
sum error= 272
Actual label: 9
Output voltages: [0.17189, 0.014765, 0.0037509, 0.26194, 0.62334, 0.31199, 0.10473, 0.019205, 0.027688, 0.79837]
Predicted label: 9
Correct prediction
Energy consumption = 147.267518 pJ
sum error= 272
Actual label: 1
Output voltages: [0.048303, 0.79866, 0.34463, 0.31969, 0.024076, 0.001114, 0.28881, 0.0013556, 0.11033, 0.13962]
Predicted label: 1
Correct prediction
Energy consumption = 170.184183 pJ
sum error= 272
Actual label: 1
Output voltages: [0.072407, 0.7985, 0.024953, 0.14183, 0.006539, 0.0037039, 0.7564, 0.0020642, 0.24672, 0.037247]
Predicted label: 1
Correct prediction
Energy consumption = 154.434678 pJ
sum error= 272
Actual label: 5
Output voltages: [0.029789, 0.001135, 0.0041747, 0.75852, 0.012219, 0.79494, 0.082349, 0.033792, 0.59883, 0.046188]
Predicted label: 5
Correct prediction
Energy consumption = 149.712872 pJ
sum error= 272
Actual label: 8
Output voltages: [0.028223, 0.15317, 0.090159, 0.12731, 0.025221, 0.0077456, 0.041097, 0.0093175, 0.79874, 0.47953]
Predicted label: 8
Correct prediction
Energy consumption = 150.546910 pJ
sum error= 272
Actual label: 8
Output voltages: [0.020416, 0.016243, 0.33308, 0.084561, 0.0059212, 0.011967, 0.029458, 0.022649, 0.79875, 0.18988]
Predicted label: 8
Correct prediction
Energy consumption = 143.538681 pJ
sum error= 272
Actual label: 6
Output voltages: [0.62845, 0.10673, 0.02524, 0.0089916, 0.038817, 0.77497, 0.7976, 0.017285, 0.26542, 0.001066]
Predicted label: 6
Correct prediction
Energy consumption = 152.904881 pJ
sum error= 272
Actual label: 3
Output voltages: [0.3324, 0.0010663, 0.27147, 0.79764, 0.016383, 0.48659, 0.003673, 0.0052045, 0.62551, 0.0076506]
Predicted label: 3
Correct prediction
Energy consumption = 142.695769 pJ
sum error= 272
Actual label: 2
Output voltages: [0.58214, 0.084293, 0.79879, 0.20143, 0.030914, 0.0011861, 0.46457, 0.027449, 0.41412, 0.048203]
Predicted label: 2
Correct prediction
Energy consumption = 139.387865 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 588 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 588 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 588 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.038049, 0.79836, 0.019902, 0.079034, 0.034955, 0.022389, 0.49694, 0.010329, 0.041937, 0.10288]
Predicted label: 1
Correct prediction
Energy consumption = 180.458050 pJ
sum error= 272
Actual label: 8
Output voltages: [0.015208, 0.046766, 0.22223, 0.035585, 0.0040999, 0.033374, 0.02027, 0.023028, 0.79866, 0.047068]
Predicted label: 8
Correct prediction
Energy consumption = 157.692758 pJ
sum error= 272
Actual label: 3
Output voltages: [0.17991, 0.026956, 0.20833, 0.79879, 0.0082276, 0.027908, 0.0026767, 0.0010825, 0.7516, 0.019869]
Predicted label: 3
Correct prediction
Energy consumption = 143.637926 pJ
sum error= 272
Actual label: 2
Output voltages: [0.41955, 0.036403, 0.79878, 0.053195, 0.015053, 0.0011983, 0.38125, 0.023752, 0.68479, 0.013285]
Predicted label: 2
Correct prediction
Energy consumption = 142.229021 pJ
sum error= 272
Actual label: 6
Output voltages: [0.048264, 0.29521, 0.20561, 0.0067438, 0.25361, 0.32398, 0.79858, 0.0036594, 0.30529, 0.022107]
Predicted label: 6
Correct prediction
Energy consumption = 148.308712 pJ
sum error= 272
Actual label: 5
Output voltages: [0.032176, 0.0019823, 0.0083879, 0.44234, 0.015054, 0.79864, 0.059498, 0.066393, 0.75516, 0.30414]
Predicted label: 5
Correct prediction
Energy consumption = 149.840000 pJ
sum error= 272
Actual label: 6
Output voltages: [0.097237, 0.050718, 0.065715, 0.0094883, 0.049968, 0.24163, 0.79869, 0.0018493, 0.59, 0.0042978]
Predicted label: 6
Correct prediction
Energy consumption = 150.894203 pJ
sum error= 272
Actual label: 7
Output voltages: [0.79152, 0.36179, 0.64612, 0.0031577, 0.0874, 0.0011025, 0.044596, 0.041822, 0.23051, 0.67745]
Predicted label: 0
Wrong prediction!
Energy consumption = 154.590750 pJ
sum error= 273
Actual label: 4
Output voltages: [0.66173, 0.020966, 0.44555, 0.049049, 0.61592, 0.0010839, 0.69102, 0.0019311, 0.20016, 0.11961]
Predicted label: 6
Wrong prediction!
Energy consumption = 150.318184 pJ
sum error= 274
Actual label: 1
Output voltages: [0.0028833, 0.79875, 0.62006, 0.50888, 0.43461, 0.0027211, 0.32168, 0.028045, 0.03244, 0.095606]
Predicted label: 1
Correct prediction
Energy consumption = 164.921713 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 589 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 589 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 589 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79866, 0.056746, 0.01403, 0.0027808, 0.018328, 0.050513, 0.73927, 0.17709, 0.49125, 0.027446]
Predicted label: 0
Correct prediction
Energy consumption = 184.547745 pJ
sum error= 274
Actual label: 5
Output voltages: [0.59466, 0.001066, 0.024688, 0.59917, 0.0046326, 0.77928, 0.42696, 0.020656, 0.7293, 0.016477]
Predicted label: 5
Correct prediction
Energy consumption = 141.976130 pJ
sum error= 274
Actual label: 3
Output voltages: [0.70329, 0.022309, 0.060104, 0.79865, 0.017631, 0.011564, 0.019995, 0.023593, 0.55124, 0.027471]
Predicted label: 3
Correct prediction
Energy consumption = 142.157524 pJ
sum error= 274
Actual label: 1
Output voltages: [0.0060334, 0.79844, 0.015659, 0.23884, 0.053992, 0.014921, 0.33077, 0.0099712, 0.12193, 0.18697]
Predicted label: 1
Correct prediction
Energy consumption = 166.115929 pJ
sum error= 274
Actual label: 9
Output voltages: [0.43146, 0.010555, 0.0056202, 0.043706, 0.050188, 0.22038, 0.029918, 0.2136, 0.59082, 0.79847]
Predicted label: 9
Correct prediction
Energy consumption = 156.487022 pJ
sum error= 274
Actual label: 2
Output voltages: [0.2045, 0.11756, 0.79835, 0.061496, 0.01924, 0.001178, 0.30966, 0.027155, 0.44945, 0.0073862]
Predicted label: 2
Correct prediction
Energy consumption = 151.685049 pJ
sum error= 274
Actual label: 1
Output voltages: [0.031026, 0.79836, 0.016036, 0.080888, 0.024229, 0.014426, 0.55266, 0.025116, 0.13572, 0.096797]
Predicted label: 1
Correct prediction
Energy consumption = 158.605571 pJ
sum error= 274
Actual label: 9
Output voltages: [0.45753, 0.0016001, 0.022964, 0.0058907, 0.44626, 0.012602, 0.013669, 0.016751, 0.26267, 0.79854]
Predicted label: 9
Correct prediction
Energy consumption = 151.366143 pJ
sum error= 274
Actual label: 6
Output voltages: [0.042915, 0.10303, 0.13377, 0.010306, 0.32868, 0.32315, 0.79867, 0.002927, 0.5271, 0.011377]
Predicted label: 6
Correct prediction
Energy consumption = 146.606382 pJ
sum error= 274
Actual label: 0
Output voltages: [0.79599, 0.055255, 0.060901, 0.024076, 0.011459, 0.0025968, 0.78209, 0.0083249, 0.1622, 0.07366]
Predicted label: 0
Correct prediction
Energy consumption = 155.633745 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 590 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 590 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 590 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0012994, 0.014536, 0.29257, 0.013923, 0.79867, 0.0096572, 0.23238, 0.065879, 0.031603, 0.21024]
Predicted label: 4
Correct prediction
Energy consumption = 162.858472 pJ
sum error= 274
Actual label: 6
Output voltages: [0.073152, 0.044774, 0.19147, 0.0039559, 0.43955, 0.10636, 0.79871, 0.0018548, 0.54349, 0.0034575]
Predicted label: 6
Correct prediction
Energy consumption = 150.895044 pJ
sum error= 274
Actual label: 1
Output voltages: [0.02319, 0.79838, 0.042261, 0.042218, 0.0058498, 0.0016545, 0.50943, 0.0046294, 0.32212, 0.024171]
Predicted label: 1
Correct prediction
Energy consumption = 165.819952 pJ
sum error= 274
Actual label: 7
Output voltages: [0.030569, 0.23717, 0.025756, 0.04298, 0.019447, 0.0024671, 0.0045971, 0.7987, 0.038397, 0.48612]
Predicted label: 7
Correct prediction
Energy consumption = 159.152674 pJ
sum error= 274
Actual label: 3
Output voltages: [0.046957, 0.043271, 0.18395, 0.79875, 0.019985, 0.04464, 0.0022895, 0.0070447, 0.68466, 0.126]
Predicted label: 3
Correct prediction
Energy consumption = 146.558048 pJ
sum error= 274
Actual label: 8
Output voltages: [0.021015, 0.12988, 0.1021, 0.49582, 0.0023808, 0.026379, 0.016804, 0.0068712, 0.79875, 0.10302]
Predicted label: 8
Correct prediction
Energy consumption = 148.196347 pJ
sum error= 274
Actual label: 7
Output voltages: [0.30949, 0.011841, 0.0045024, 0.48073, 0.64422, 0.0010662, 0.0022206, 0.79876, 0.023053, 0.4662]
Predicted label: 7
Correct prediction
Energy consumption = 155.715669 pJ
sum error= 274
Actual label: 2
Output voltages: [0.09588, 0.40785, 0.79772, 0.33993, 0.0013619, 0.0012925, 0.21559, 0.0014002, 0.42187, 0.017552]
Predicted label: 2
Correct prediction
Energy consumption = 145.800682 pJ
sum error= 274
Actual label: 9
Output voltages: [0.2505, 0.029308, 0.027121, 0.71518, 0.16372, 0.0049704, 0.0055297, 0.038702, 0.037739, 0.7984]
Predicted label: 9
Correct prediction
Energy consumption = 150.326719 pJ
sum error= 274
Actual label: 6
Output voltages: [0.1789, 0.039812, 0.080901, 0.0017437, 0.49936, 0.071207, 0.79879, 0.0017196, 0.63127, 0.0024222]
Predicted label: 6
Correct prediction
Energy consumption = 147.817988 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 591 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 591 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 591 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.032318, 0.0013945, 0.0015566, 0.65291, 0.017066, 0.79872, 0.1296, 0.40261, 0.73986, 0.049583]
Predicted label: 5
Correct prediction
Energy consumption = 163.734385 pJ
sum error= 274
Actual label: 8
Output voltages: [0.027396, 0.0053542, 0.027884, 0.052171, 0.026135, 0.033931, 0.016275, 0.010001, 0.79872, 0.12246]
Predicted label: 8
Correct prediction
Energy consumption = 150.665691 pJ
sum error= 274
Actual label: 3
Output voltages: [0.69297, 0.0034813, 0.0092375, 0.79676, 0.011681, 0.36551, 0.053376, 0.052704, 0.4518, 0.0020273]
Predicted label: 3
Correct prediction
Energy consumption = 142.852405 pJ
sum error= 274
Actual label: 5
Output voltages: [0.71496, 0.025203, 0.016285, 0.69793, 0.0022649, 0.79773, 0.39259, 0.0028203, 0.58695, 0.0080402]
Predicted label: 5
Correct prediction
Energy consumption = 137.035281 pJ
sum error= 274
Actual label: 7
Output voltages: [0.12453, 0.020031, 0.010484, 0.019937, 0.44727, 0.0011238, 0.001121, 0.79874, 0.44754, 0.027349]
Predicted label: 7
Correct prediction
Energy consumption = 157.216085 pJ
sum error= 274
Actual label: 1
Output voltages: [0.0023441, 0.79849, 0.037364, 0.14907, 0.0065644, 0.014706, 0.77669, 0.065463, 0.09831, 0.017608]
Predicted label: 1
Correct prediction
Energy consumption = 167.673225 pJ
sum error= 274
Actual label: 6
Output voltages: [0.21965, 0.08344, 0.21604, 0.0011221, 0.31202, 0.13792, 0.79877, 0.001158, 0.39684, 0.0044151]
Predicted label: 6
Correct prediction
Energy consumption = 147.801750 pJ
sum error= 274
Actual label: 1
Output voltages: [0.0072616, 0.79857, 0.10813, 0.12848, 0.055751, 0.0014249, 0.37925, 0.0015354, 0.18827, 0.33903]
Predicted label: 1
Correct prediction
Energy consumption = 164.946257 pJ
sum error= 274
Actual label: 0
Output voltages: [0.79536, 0.051212, 0.15652, 0.019946, 0.022852, 0.0041402, 0.6225, 0.0080747, 0.52103, 0.016055]
Predicted label: 0
Correct prediction
Energy consumption = 165.278799 pJ
sum error= 274
Actual label: 9
Output voltages: [0.1405, 0.0068173, 0.043636, 0.036864, 0.28623, 0.01048, 0.16398, 0.013944, 0.099291, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 153.537500 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 592 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 592 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 592 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.12718, 0.0321, 0.22915, 0.002864, 0.4006, 0.22692, 0.79874, 0.0015335, 0.60916, 0.0061998]
Predicted label: 6
Correct prediction
Energy consumption = 168.853288 pJ
sum error= 274
Actual label: 2
Output voltages: [0.1951, 0.42653, 0.7975, 0.10805, 0.0016323, 0.0012115, 0.077255, 0.12206, 0.43668, 0.042678]
Predicted label: 2
Correct prediction
Energy consumption = 156.965680 pJ
sum error= 274
Actual label: 5
Output voltages: [0.75501, 0.0010665, 0.019923, 0.36705, 0.0020322, 0.79821, 0.031482, 0.031942, 0.65873, 0.048887]
Predicted label: 5
Correct prediction
Energy consumption = 152.843456 pJ
sum error= 274
Actual label: 4
Output voltages: [0.0021704, 0.14836, 0.20301, 0.0016732, 0.79867, 0.0012569, 0.35169, 0.32271, 0.0048133, 0.13042]
Predicted label: 4
Correct prediction
Energy consumption = 150.933619 pJ
sum error= 274
Actual label: 2
Output voltages: [0.3158, 0.22817, 0.79875, 0.09447, 0.0048481, 0.0012955, 0.33317, 0.11055, 0.30439, 0.0099898]
Predicted label: 2
Correct prediction
Energy consumption = 156.583637 pJ
sum error= 274
Actual label: 3
Output voltages: [0.3877, 0.0028724, 0.14488, 0.79877, 0.039318, 0.4128, 0.0096735, 0.025324, 0.63603, 0.021319]
Predicted label: 3
Correct prediction
Energy consumption = 146.768283 pJ
sum error= 274
Actual label: 4
Output voltages: [0.0024892, 0.011988, 0.063469, 0.060393, 0.79877, 0.0057608, 0.011626, 0.12518, 0.041562, 0.28858]
Predicted label: 4
Correct prediction
Energy consumption = 157.290335 pJ
sum error= 274
Actual label: 4
Output voltages: [0.011507, 0.003337, 0.36804, 0.013877, 0.79857, 0.0055463, 0.069379, 0.032828, 0.02798, 0.21284]
Predicted label: 4
Correct prediction
Energy consumption = 146.639554 pJ
sum error= 274
Actual label: 6
Output voltages: [0.070735, 0.048449, 0.26493, 0.0021045, 0.22645, 0.046891, 0.79874, 0.0011349, 0.35561, 0.0081421]
Predicted label: 6
Correct prediction
Energy consumption = 146.237977 pJ
sum error= 274
Actual label: 0
Output voltages: [0.79844, 0.20071, 0.30119, 0.014623, 0.02081, 0.0019738, 0.42436, 0.0021554, 0.48952, 0.051813]
Predicted label: 0
Correct prediction
Energy consumption = 150.876051 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 593 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 593 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 593 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79823, 0.06112, 0.054105, 0.012437, 0.0068306, 0.0037916, 0.74854, 0.0055634, 0.24199, 0.023442]
Predicted label: 0
Correct prediction
Energy consumption = 174.194769 pJ
sum error= 274
Actual label: 2
Output voltages: [0.47131, 0.11101, 0.79873, 0.050647, 0.038642, 0.0012015, 0.57961, 0.021758, 0.46555, 0.048204]
Predicted label: 2
Correct prediction
Energy consumption = 142.688145 pJ
sum error= 274
Actual label: 0
Output voltages: [0.79877, 0.048871, 0.0070597, 0.01701, 0.010423, 0.019117, 0.55405, 0.02156, 0.12019, 0.07324]
Predicted label: 0
Correct prediction
Energy consumption = 152.902672 pJ
sum error= 274
Actual label: 1
Output voltages: [0.015981, 0.79852, 0.26678, 0.10096, 0.021318, 0.010616, 0.40277, 0.0016895, 0.017064, 0.052235]
Predicted label: 1
Correct prediction
Energy consumption = 166.306736 pJ
sum error= 274
Actual label: 2
Output voltages: [0.28518, 0.3382, 0.79875, 0.28317, 0.031005, 0.0012166, 0.42552, 0.051579, 0.071663, 0.027549]
Predicted label: 2
Correct prediction
Energy consumption = 152.925600 pJ
sum error= 274
Actual label: 3
Output voltages: [0.71918, 0.013661, 0.068996, 0.79834, 0.0076663, 0.022323, 0.0059502, 0.012927, 0.34328, 0.19652]
Predicted label: 3
Correct prediction
Energy consumption = 152.057566 pJ
sum error= 274
Actual label: 4
Output voltages: [0.04937, 0.024159, 0.035996, 0.019071, 0.75181, 0.049486, 0.010004, 0.46395, 0.035068, 0.78738]
Predicted label: 9
Wrong prediction!
Energy consumption = 150.594012 pJ
sum error= 275
Actual label: 5
Output voltages: [0.022788, 0.001085, 0.016159, 0.76517, 0.11072, 0.58137, 0.0083424, 0.024689, 0.30393, 0.52414]
Predicted label: 3
Wrong prediction!
Energy consumption = 147.394361 pJ
sum error= 276
Actual label: 6
Output voltages: [0.049328, 0.046008, 0.26536, 0.0019435, 0.35789, 0.22838, 0.79869, 0.0025591, 0.53383, 0.0090061]
Predicted label: 6
Correct prediction
Energy consumption = 149.253020 pJ
sum error= 276
Actual label: 7
Output voltages: [0.12674, 0.025877, 0.016398, 0.035658, 0.016751, 0.0012331, 0.0011166, 0.79832, 0.1404, 0.57404]
Predicted label: 7
Correct prediction
Energy consumption = 155.708875 pJ
sum error= 276
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 594 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 594 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 594 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.12676, 0.0047753, 0.64742, 0.048003, 0.019238, 0.008896, 0.02178, 0.0039598, 0.79878, 0.27767]
Predicted label: 8
Correct prediction
Energy consumption = 169.255932 pJ
sum error= 276
Actual label: 9
Output voltages: [0.60085, 0.0046498, 0.016726, 0.030718, 0.13917, 0.016993, 0.0011227, 0.0096783, 0.55024, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 148.467528 pJ
sum error= 276
Actual label: 0
Output voltages: [0.79863, 0.031716, 0.034036, 0.0097932, 0.0041528, 0.016655, 0.71507, 0.012285, 0.24714, 0.03153]
Predicted label: 0
Correct prediction
Energy consumption = 144.885803 pJ
sum error= 276
Actual label: 1
Output voltages: [0.0247, 0.7986, 0.080135, 0.25698, 0.0082531, 0.0019726, 0.65518, 0.0013006, 0.061314, 0.018614]
Predicted label: 1
Correct prediction
Energy consumption = 155.872149 pJ
sum error= 276
Actual label: 2
Output voltages: [0.21429, 0.18752, 0.79867, 0.012502, 0.0094127, 0.0012625, 0.073024, 0.035495, 0.2934, 0.046121]
Predicted label: 2
Correct prediction
Energy consumption = 152.296765 pJ
sum error= 276
Actual label: 3
Output voltages: [0.32635, 0.059777, 0.02551, 0.79876, 0.015784, 0.11373, 0.012204, 0.0013758, 0.72117, 0.12843]
Predicted label: 3
Correct prediction
Energy consumption = 147.486660 pJ
sum error= 276
Actual label: 4
Output voltages: [0.0063526, 0.0037627, 0.27337, 0.053403, 0.79862, 0.033352, 0.014922, 0.049035, 0.090407, 0.50441]
Predicted label: 4
Correct prediction
Energy consumption = 154.189617 pJ
sum error= 276
Actual label: 5
Output voltages: [0.19384, 0.0011081, 0.0037263, 0.44307, 0.015733, 0.79828, 0.0317, 0.19226, 0.77689, 0.028857]
Predicted label: 5
Correct prediction
Energy consumption = 146.125420 pJ
sum error= 276
Actual label: 6
Output voltages: [0.034044, 0.032627, 0.39755, 0.0013164, 0.55404, 0.18656, 0.79868, 0.0043597, 0.42974, 0.013737]
Predicted label: 6
Correct prediction
Energy consumption = 148.285369 pJ
sum error= 276
Actual label: 7
Output voltages: [0.46787, 0.25366, 0.0055838, 0.56712, 0.0010738, 0.047139, 0.0012414, 0.79731, 0.041526, 0.61481]
Predicted label: 7
Correct prediction
Energy consumption = 156.540776 pJ
sum error= 276
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 595 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 595 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 595 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.47788, 0.0020488, 0.73051, 0.3656, 0.003511, 0.0011638, 0.048789, 0.0021175, 0.78802, 0.57442]
Predicted label: 8
Correct prediction
Energy consumption = 170.180856 pJ
sum error= 276
Actual label: 9
Output voltages: [0.442, 0.011293, 0.029408, 0.019208, 0.038268, 0.001146, 0.001267, 0.033551, 0.60379, 0.7981]
Predicted label: 9
Correct prediction
Energy consumption = 147.505820 pJ
sum error= 276
Actual label: 0
Output voltages: [0.7987, 0.071768, 0.011012, 0.0095337, 0.004382, 0.017308, 0.58019, 0.0080742, 0.05752, 0.33754]
Predicted label: 0
Correct prediction
Energy consumption = 155.246136 pJ
sum error= 276
Actual label: 1
Output voltages: [0.0072175, 0.79863, 0.57195, 0.4828, 0.41526, 0.0017815, 0.028692, 0.032369, 0.0065876, 0.041018]
Predicted label: 1
Correct prediction
Energy consumption = 161.168675 pJ
sum error= 276
Actual label: 2
Output voltages: [0.1038, 0.022165, 0.79879, 0.2322, 0.035946, 0.0011156, 0.045666, 0.1159, 0.058456, 0.010724]
Predicted label: 2
Correct prediction
Energy consumption = 142.792170 pJ
sum error= 276
Actual label: 3
Output voltages: [0.44724, 0.029322, 0.2955, 0.099349, 0.0041401, 0.0035193, 0.010192, 0.0013455, 0.79837, 0.73435]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.847491 pJ
sum error= 277
Actual label: 4
Output voltages: [0.018146, 0.0032222, 0.19887, 0.014633, 0.79861, 0.0035737, 0.064749, 0.010925, 0.051078, 0.19902]
Predicted label: 4
Correct prediction
Energy consumption = 151.197733 pJ
sum error= 277
Actual label: 5
Output voltages: [0.16858, 0.0011447, 0.013901, 0.070173, 0.021258, 0.7942, 0.048348, 0.024686, 0.79541, 0.28174]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.699224 pJ
sum error= 278
Actual label: 6
Output voltages: [0.085391, 0.044829, 0.47071, 0.001069, 0.72844, 0.12465, 0.79868, 0.0013221, 0.066345, 0.020057]
Predicted label: 6
Correct prediction
Energy consumption = 147.388087 pJ
sum error= 278
Actual label: 7
Output voltages: [0.097688, 0.020973, 0.026998, 0.026115, 0.021436, 0.007296, 0.0010963, 0.79819, 0.078264, 0.77034]
Predicted label: 7
Correct prediction
Energy consumption = 157.160549 pJ
sum error= 278
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 596 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 596 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 596 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.03632, 0.0025411, 0.75011, 0.10597, 0.0041644, 0.0021307, 0.037206, 0.0052995, 0.79857, 0.1968]
Predicted label: 8
Correct prediction
Energy consumption = 173.938763 pJ
sum error= 278
Actual label: 9
Output voltages: [0.084571, 0.036807, 0.104, 0.25929, 0.04904, 0.0014189, 0.0011073, 0.41791, 0.022835, 0.79354]
Predicted label: 9
Correct prediction
Energy consumption = 157.106853 pJ
sum error= 278
Actual label: 8
Output voltages: [0.15522, 0.013583, 0.64951, 0.031751, 0.030694, 0.013554, 0.32069, 0.0022205, 0.79816, 0.28236]
Predicted label: 8
Correct prediction
Energy consumption = 152.434613 pJ
sum error= 278
Actual label: 6
Output voltages: [0.077303, 0.023642, 0.055766, 0.0053054, 0.52145, 0.28273, 0.79874, 0.0093844, 0.69908, 0.0048697]
Predicted label: 6
Correct prediction
Energy consumption = 148.006821 pJ
sum error= 278
Actual label: 5
Output voltages: [0.040559, 0.0014609, 0.0038541, 0.50915, 0.019518, 0.79797, 0.062425, 0.024537, 0.73662, 0.088403]
Predicted label: 5
Correct prediction
Energy consumption = 143.987592 pJ
sum error= 278
Actual label: 0
Output voltages: [0.79873, 0.0083613, 0.038983, 0.0077318, 0.00722, 0.0033371, 0.52279, 0.045068, 0.26641, 0.042275]
Predicted label: 0
Correct prediction
Energy consumption = 154.800072 pJ
sum error= 278
Actual label: 6
Output voltages: [0.53342, 0.033447, 0.098819, 0.012659, 0.081444, 0.10282, 0.79876, 0.0012089, 0.61074, 0.020984]
Predicted label: 6
Correct prediction
Energy consumption = 142.710065 pJ
sum error= 278
Actual label: 8
Output voltages: [0.16, 0.014892, 0.6659, 0.026962, 0.01532, 0.0017286, 0.013934, 0.0078765, 0.79879, 0.22161]
Predicted label: 8
Correct prediction
Energy consumption = 151.010534 pJ
sum error= 278
Actual label: 9
Output voltages: [0.40843, 0.014692, 0.041155, 0.034284, 0.061278, 0.0092096, 0.013784, 0.13204, 0.43874, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.253330 pJ
sum error= 278
Actual label: 4
Output voltages: [0.0032467, 0.009429, 0.057512, 0.025991, 0.79879, 0.13474, 0.012346, 0.0046468, 0.19507, 0.74128]
Predicted label: 4
Correct prediction
Energy consumption = 154.338911 pJ
sum error= 278
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 597 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 597 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 597 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.013144, 0.79879, 0.26084, 0.045321, 0.031272, 0.0012656, 0.67028, 0.0010712, 0.10838, 0.048377]
Predicted label: 1
Correct prediction
Energy consumption = 180.403729 pJ
sum error= 278
Actual label: 9
Output voltages: [0.19439, 0.010304, 0.018467, 0.091765, 0.12126, 0.0057028, 0.018254, 0.05416, 0.39504, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 154.106470 pJ
sum error= 278
Actual label: 5
Output voltages: [0.040658, 0.001093, 0.018047, 0.74895, 0.025411, 0.74062, 0.0039253, 0.042051, 0.77313, 0.075647]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.568980 pJ
sum error= 279
Actual label: 3
Output voltages: [0.052772, 0.045582, 0.038169, 0.79844, 0.0020743, 0.0020157, 0.035885, 0.0040802, 0.79352, 0.06886]
Predicted label: 3
Correct prediction
Energy consumption = 148.992153 pJ
sum error= 279
Actual label: 0
Output voltages: [0.79879, 0.038559, 0.036717, 0.020229, 0.021597, 0.0046204, 0.7065, 0.034153, 0.24171, 0.19644]
Predicted label: 0
Correct prediction
Energy consumption = 160.623439 pJ
sum error= 279
Actual label: 4
Output voltages: [0.011286, 0.0013671, 0.052934, 0.019595, 0.77367, 0.022766, 0.28338, 0.017957, 0.24182, 0.74522]
Predicted label: 4
Correct prediction
Energy consumption = 160.422196 pJ
sum error= 279
Actual label: 8
Output voltages: [0.029622, 0.02524, 0.099802, 0.017729, 0.017104, 0.044634, 0.024812, 0.0039373, 0.79873, 0.3696]
Predicted label: 8
Correct prediction
Energy consumption = 150.201235 pJ
sum error= 279
Actual label: 9
Output voltages: [0.6772, 0.0064405, 0.02648, 0.023208, 0.12124, 0.01217, 0.0010685, 0.0050197, 0.40592, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 147.938007 pJ
sum error= 279
Actual label: 1
Output voltages: [0.001681, 0.79879, 0.45016, 0.34579, 0.11306, 0.0012475, 0.032956, 0.15338, 0.031385, 0.032134]
Predicted label: 1
Correct prediction
Energy consumption = 166.316150 pJ
sum error= 279
Actual label: 4
Output voltages: [0.066284, 0.022597, 0.16166, 0.037319, 0.79878, 0.011656, 0.0042793, 0.0084575, 0.019204, 0.75883]
Predicted label: 4
Correct prediction
Energy consumption = 150.849084 pJ
sum error= 279
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 598 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 598 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 598 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.016786, 0.033275, 0.0018834, 0.19668, 0.0061239, 0.72413, 0.041644, 0.025702, 0.019249]
Predicted label: 0
Correct prediction
Energy consumption = 170.644115 pJ
sum error= 279
Actual label: 5
Output voltages: [0.11185, 0.0011124, 0.010728, 0.1521, 0.039119, 0.068098, 0.006687, 0.018998, 0.72109, 0.7783]
Predicted label: 9
Wrong prediction!
Energy consumption = 153.309217 pJ
sum error= 280
Actual label: 5
Output voltages: [0.048733, 0.0010667, 0.031423, 0.73218, 0.0032534, 0.76792, 0.0041092, 0.020107, 0.765, 0.042135]
Predicted label: 5
Correct prediction
Energy consumption = 147.496953 pJ
sum error= 280
Actual label: 2
Output voltages: [0.5585, 0.05686, 0.79875, 0.20053, 0.024692, 0.0011724, 0.15929, 0.32523, 0.4162, 0.0097423]
Predicted label: 2
Correct prediction
Energy consumption = 147.305680 pJ
sum error= 280
Actual label: 1
Output voltages: [0.0087591, 0.7987, 0.50752, 0.43042, 0.41426, 0.001524, 0.034828, 0.098364, 0.0019929, 0.033308]
Predicted label: 1
Correct prediction
Energy consumption = 158.332952 pJ
sum error= 280
Actual label: 5
Output voltages: [0.0013449, 0.0016369, 0.016642, 0.64246, 0.050396, 0.59365, 0.12944, 0.0086189, 0.77862, 0.30614]
Predicted label: 8
Wrong prediction!
Energy consumption = 155.845563 pJ
sum error= 281
Actual label: 4
Output voltages: [0.04388, 0.034291, 0.39426, 0.032251, 0.7966, 0.034339, 0.0068959, 0.0044727, 0.1906, 0.74722]
Predicted label: 4
Correct prediction
Energy consumption = 157.186762 pJ
sum error= 281
Actual label: 0
Output voltages: [0.79872, 0.040072, 0.19267, 0.0083315, 0.013605, 0.0010787, 0.56926, 0.026963, 0.049297, 0.26403]
Predicted label: 0
Correct prediction
Energy consumption = 158.270954 pJ
sum error= 281
Actual label: 7
Output voltages: [0.20851, 0.33516, 0.29827, 0.74656, 0.012153, 0.0017322, 0.001066, 0.79829, 0.011454, 0.65947]
Predicted label: 7
Correct prediction
Energy consumption = 154.785351 pJ
sum error= 281
Actual label: 6
Output voltages: [0.23308, 0.040694, 0.023089, 0.075949, 0.41654, 0.54541, 0.79879, 0.005451, 0.36374, 0.0013991]
Predicted label: 6
Correct prediction
Energy consumption = 154.795930 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 599 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 599 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 599 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79866, 0.067541, 0.023296, 0.0097334, 0.052882, 0.014363, 0.7407, 0.022374, 0.036917, 0.03481]
Predicted label: 0
Correct prediction
Energy consumption = 173.432181 pJ
sum error= 281
Actual label: 1
Output voltages: [0.025886, 0.79841, 0.13973, 0.22525, 0.043147, 0.0067906, 0.4352, 0.0046404, 0.0094383, 0.2679]
Predicted label: 1
Correct prediction
Energy consumption = 164.658626 pJ
sum error= 281
Actual label: 7
Output voltages: [0.24769, 0.090637, 0.014271, 0.32263, 0.0012209, 0.0074375, 0.0012038, 0.79876, 0.043264, 0.62334]
Predicted label: 7
Correct prediction
Energy consumption = 152.742816 pJ
sum error= 281
Actual label: 0
Output voltages: [0.79875, 0.03422, 0.017163, 0.0046905, 0.03639, 0.022027, 0.58784, 0.011536, 0.018562, 0.069459]
Predicted label: 0
Correct prediction
Energy consumption = 153.712955 pJ
sum error= 281
Actual label: 6
Output voltages: [0.08247, 0.043311, 0.13982, 0.0050924, 0.32877, 0.52503, 0.79872, 0.0024584, 0.52502, 0.0055384]
Predicted label: 6
Correct prediction
Energy consumption = 150.265732 pJ
sum error= 281
Actual label: 8
Output voltages: [0.047295, 0.042691, 0.55912, 0.041044, 0.020042, 0.0085757, 0.023167, 0.0034472, 0.79878, 0.2908]
Predicted label: 8
Correct prediction
Energy consumption = 154.036993 pJ
sum error= 281
Actual label: 9
Output voltages: [0.57442, 0.0015859, 0.32679, 0.0039767, 0.25929, 0.0020785, 0.021445, 0.0015695, 0.12628, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 141.421670 pJ
sum error= 281
Actual label: 5
Output voltages: [0.088064, 0.0044991, 0.025414, 0.31326, 0.00354, 0.78156, 0.005993, 0.014694, 0.78518, 0.4514]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.621175 pJ
sum error= 282
Actual label: 1
Output voltages: [0.01514, 0.79839, 0.11866, 0.22421, 0.0038576, 0.01051, 0.15057, 0.0021833, 0.096042, 0.077974]
Predicted label: 1
Correct prediction
Energy consumption = 161.949996 pJ
sum error= 282
Actual label: 7
Output voltages: [0.10769, 0.024858, 0.014275, 0.15593, 0.0060242, 0.0032088, 0.0012119, 0.79879, 0.27899, 0.40342]
Predicted label: 7
Correct prediction
Energy consumption = 154.243619 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 600 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 600 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 600 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.56279, 0.0011393, 0.019563, 0.11716, 0.038343, 0.022934, 0.0011686, 0.77719, 0.40726, 0.7855]
Predicted label: 9
Correct prediction
Energy consumption = 173.218057 pJ
sum error= 282
Actual label: 8
Output voltages: [0.2641, 0.01359, 0.13066, 0.74419, 0.011118, 0.01211, 0.036257, 0.0013719, 0.79827, 0.073192]
Predicted label: 8
Correct prediction
Energy consumption = 156.161057 pJ
sum error= 282
Actual label: 6
Output voltages: [0.12592, 0.30503, 0.20251, 0.015717, 0.24813, 0.24448, 0.79867, 0.0044723, 0.26549, 0.014701]
Predicted label: 6
Correct prediction
Energy consumption = 148.691654 pJ
sum error= 282
Actual label: 0
Output voltages: [0.79864, 0.035068, 0.014729, 0.010752, 0.040423, 0.0087602, 0.75041, 0.025654, 0.25369, 0.034553]
Predicted label: 0
Correct prediction
Energy consumption = 151.195616 pJ
sum error= 282
Actual label: 8
Output voltages: [0.33486, 0.0053308, 0.13177, 0.0032918, 0.028542, 0.0078496, 0.0027243, 0.028817, 0.78081, 0.77684]
Predicted label: 8
Correct prediction
Energy consumption = 153.745548 pJ
sum error= 282
Actual label: 1
Output voltages: [0.0046012, 0.79855, 0.71377, 0.16035, 0.54705, 0.0010977, 0.0082158, 0.011988, 0.011697, 0.067035]
Predicted label: 1
Correct prediction
Energy consumption = 164.328338 pJ
sum error= 282
Actual label: 7
Output voltages: [0.043014, 0.24886, 0.0092228, 0.035643, 0.0012153, 0.033581, 0.0010662, 0.79286, 0.046608, 0.77452]
Predicted label: 7
Correct prediction
Energy consumption = 158.284094 pJ
sum error= 282
Actual label: 7
Output voltages: [0.15887, 0.066205, 0.0021322, 0.028917, 0.0031296, 0.0072091, 0.0010672, 0.79879, 0.25092, 0.72726]
Predicted label: 7
Correct prediction
Energy consumption = 143.511440 pJ
sum error= 282
Actual label: 1
Output voltages: [0.0010736, 0.79873, 0.10058, 0.37584, 0.4888, 0.0028194, 0.10316, 0.036411, 0.13143, 0.035558]
Predicted label: 1
Correct prediction
Energy consumption = 163.488974 pJ
sum error= 282
Actual label: 3
Output voltages: [0.49599, 0.031088, 0.21351, 0.79871, 0.11892, 0.0036423, 0.049917, 0.01242, 0.55731, 0.10843]
Predicted label: 3
Correct prediction
Energy consumption = 149.932013 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 601 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 601 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 601 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.24319, 0.019113, 0.79879, 0.3029, 0.012738, 0.0011673, 0.25603, 0.29349, 0.65878, 0.046123]
Predicted label: 2
Correct prediction
Energy consumption = 169.967100 pJ
sum error= 282
Actual label: 3
Output voltages: [0.7968, 0.013298, 0.16601, 0.44107, 0.0010679, 0.36594, 0.30814, 0.0020796, 0.094442, 0.28112]
Predicted label: 0
Wrong prediction!
Energy consumption = 157.022133 pJ
sum error= 283
Actual label: 1
Output voltages: [0.015725, 0.79836, 0.16892, 0.1572, 0.0039721, 0.004032, 0.70514, 0.0082344, 0.037666, 0.052537]
Predicted label: 1
Correct prediction
Energy consumption = 160.571697 pJ
sum error= 283
Actual label: 4
Output voltages: [0.035272, 0.0017434, 0.45468, 0.041315, 0.79874, 0.0076027, 0.051828, 0.038556, 0.011971, 0.51277]
Predicted label: 4
Correct prediction
Energy consumption = 156.526202 pJ
sum error= 283
Actual label: 2
Output voltages: [0.4912, 0.48284, 0.79377, 0.42237, 0.01168, 0.0011517, 0.045476, 0.041096, 0.011926, 0.017982]
Predicted label: 2
Correct prediction
Energy consumption = 154.441268 pJ
sum error= 283
Actual label: 0
Output voltages: [0.79871, 0.038211, 0.0084309, 0.013607, 0.0089896, 0.036272, 0.7208, 0.0053233, 0.067018, 0.039338]
Predicted label: 0
Correct prediction
Energy consumption = 153.945297 pJ
sum error= 283
Actual label: 0
Output voltages: [0.79874, 0.039288, 0.032931, 0.0094671, 0.053715, 0.0095042, 0.58687, 0.031057, 0.042782, 0.035773]
Predicted label: 0
Correct prediction
Energy consumption = 142.500012 pJ
sum error= 283
Actual label: 7
Output voltages: [0.41728, 0.033088, 0.72131, 0.068694, 0.0023736, 0.0011525, 0.002233, 0.79879, 0.23743, 0.10349]
Predicted label: 7
Correct prediction
Energy consumption = 160.469963 pJ
sum error= 283
Actual label: 8
Output voltages: [0.10006, 0.010872, 0.46573, 0.031048, 0.0085248, 0.02122, 0.0086952, 0.0014942, 0.79879, 0.32844]
Predicted label: 8
Correct prediction
Energy consumption = 148.732938 pJ
sum error= 283
Actual label: 4
Output voltages: [0.012333, 0.0040064, 0.011636, 0.013614, 0.79873, 0.023231, 0.029382, 0.032014, 0.48114, 0.20075]
Predicted label: 4
Correct prediction
Energy consumption = 152.800175 pJ
sum error= 283
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 602 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 602 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 602 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.22622, 0.010788, 0.074464, 0.0065501, 0.4289, 0.21444, 0.79877, 0.006421, 0.65985, 0.0016143]
Predicted label: 6
Correct prediction
Energy consumption = 165.852276 pJ
sum error= 283
Actual label: 4
Output voltages: [0.023135, 0.019196, 0.031849, 0.11117, 0.79869, 0.039452, 0.034941, 0.029279, 0.068246, 0.44679]
Predicted label: 4
Correct prediction
Energy consumption = 155.814300 pJ
sum error= 283
Actual label: 9
Output voltages: [0.18736, 0.014821, 0.035356, 0.3886, 0.021403, 0.016997, 0.0066052, 0.07129, 0.14386, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.737576 pJ
sum error= 283
Actual label: 3
Output voltages: [0.082567, 0.042669, 0.019195, 0.79876, 0.09372, 0.25823, 0.045362, 0.0010831, 0.47246, 0.23824]
Predicted label: 3
Correct prediction
Energy consumption = 145.648713 pJ
sum error= 283
Actual label: 8
Output voltages: [0.033719, 0.014365, 0.050476, 0.46836, 0.0011547, 0.042424, 0.0062285, 0.0083403, 0.79879, 0.38665]
Predicted label: 8
Correct prediction
Energy consumption = 147.000880 pJ
sum error= 283
Actual label: 4
Output voltages: [0.036375, 0.0087612, 0.40963, 0.054964, 0.79877, 0.0077592, 0.011422, 0.0026064, 0.0091996, 0.56741]
Predicted label: 4
Correct prediction
Energy consumption = 156.453962 pJ
sum error= 283
Actual label: 7
Output voltages: [0.24807, 0.70766, 0.040802, 0.46457, 0.0017621, 0.010729, 0.001082, 0.79637, 0.012471, 0.75326]
Predicted label: 7
Correct prediction
Energy consumption = 155.674936 pJ
sum error= 283
Actual label: 2
Output voltages: [0.12842, 0.13471, 0.79879, 0.013459, 0.0026622, 0.0012634, 0.561, 0.044906, 0.44254, 0.020611]
Predicted label: 2
Correct prediction
Energy consumption = 152.743530 pJ
sum error= 283
Actual label: 5
Output voltages: [0.043158, 0.0010892, 0.003093, 0.3592, 0.01483, 0.79487, 0.052613, 0.044301, 0.75811, 0.064611]
Predicted label: 5
Correct prediction
Energy consumption = 150.751675 pJ
sum error= 283
Actual label: 6
Output voltages: [0.19729, 0.016061, 0.0099798, 0.13537, 0.081446, 0.77978, 0.79877, 0.0010845, 0.39635, 0.0018253]
Predicted label: 6
Correct prediction
Energy consumption = 146.489593 pJ
sum error= 283
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 603 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 603 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 603 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.19386, 0.10029, 0.016886, 0.79878, 0.0028299, 0.029391, 0.12958, 0.004919, 0.57563, 0.02635]
Predicted label: 3
Correct prediction
Energy consumption = 164.307829 pJ
sum error= 283
Actual label: 6
Output voltages: [0.018862, 0.058629, 0.13854, 0.016034, 0.22551, 0.26685, 0.79876, 0.030949, 0.65206, 0.0016003]
Predicted label: 6
Correct prediction
Energy consumption = 150.347012 pJ
sum error= 283
Actual label: 9
Output voltages: [0.39668, 0.0021847, 0.017969, 0.019387, 0.041206, 0.0011717, 0.0013517, 0.044741, 0.50768, 0.79661]
Predicted label: 9
Correct prediction
Energy consumption = 154.666304 pJ
sum error= 283
Actual label: 6
Output voltages: [0.1097, 0.04101, 0.022482, 0.034569, 0.23781, 0.61199, 0.79879, 0.0023245, 0.62629, 0.0018265]
Predicted label: 6
Correct prediction
Energy consumption = 157.385467 pJ
sum error= 283
Actual label: 3
Output voltages: [0.030675, 0.0047196, 0.021042, 0.79879, 0.065514, 0.029603, 0.054655, 0.0047851, 0.66363, 0.076522]
Predicted label: 3
Correct prediction
Energy consumption = 156.902367 pJ
sum error= 283
Actual label: 2
Output voltages: [0.79808, 0.018598, 0.14843, 0.054111, 0.013605, 0.0031999, 0.19168, 0.032419, 0.0029175, 0.57469]
Predicted label: 0
Wrong prediction!
Energy consumption = 156.171139 pJ
sum error= 284
Actual label: 2
Output voltages: [0.39202, 0.020521, 0.79649, 0.46884, 0.011831, 0.0013007, 0.048188, 0.047749, 0.45729, 0.014734]
Predicted label: 2
Correct prediction
Energy consumption = 146.241370 pJ
sum error= 284
Actual label: 4
Output voltages: [0.011333, 0.023298, 0.11209, 0.11449, 0.79789, 0.062995, 0.01445, 0.018878, 0.17042, 0.72466]
Predicted label: 4
Correct prediction
Energy consumption = 157.476179 pJ
sum error= 284
Actual label: 6
Output voltages: [0.13676, 0.022475, 0.17639, 0.0048467, 0.26622, 0.26286, 0.79867, 0.0016587, 0.67706, 0.029861]
Predicted label: 6
Correct prediction
Energy consumption = 147.144520 pJ
sum error= 284
Actual label: 9
Output voltages: [0.29742, 0.024649, 0.048432, 0.39043, 0.047241, 0.024976, 0.0081214, 0.22807, 0.19413, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 152.370330 pJ
sum error= 284
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 604 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 604 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 604 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.0095423, 0.0041559, 0.0097518, 0.046114, 0.024746, 0.6697, 0.015928, 0.041781, 0.16473]
Predicted label: 0
Correct prediction
Energy consumption = 175.891731 pJ
sum error= 284
Actual label: 2
Output voltages: [0.50399, 0.48379, 0.79832, 0.10401, 0.0040339, 0.0013187, 0.21213, 0.0054367, 0.15801, 0.0068824]
Predicted label: 2
Correct prediction
Energy consumption = 160.831385 pJ
sum error= 284
Actual label: 5
Output voltages: [0.060028, 0.0010722, 0.036521, 0.039539, 0.009219, 0.75424, 0.0013901, 0.019482, 0.79648, 0.59822]
Predicted label: 8
Wrong prediction!
Energy consumption = 151.156376 pJ
sum error= 285
Actual label: 5
Output voltages: [0.054685, 0.0011899, 0.001177, 0.19453, 0.030146, 0.79463, 0.1092, 0.079727, 0.77788, 0.041768]
Predicted label: 5
Correct prediction
Energy consumption = 136.528985 pJ
sum error= 285
Actual label: 1
Output voltages: [0.023654, 0.79879, 0.1822, 0.015402, 0.42753, 0.012653, 0.71786, 0.0013654, 0.038452, 0.025948]
Predicted label: 1
Correct prediction
Energy consumption = 171.283276 pJ
sum error= 285
Actual label: 3
Output voltages: [0.037179, 0.023814, 0.049025, 0.79879, 0.0061725, 0.0064651, 0.045248, 0.0053462, 0.75722, 0.074552]
Predicted label: 3
Correct prediction
Energy consumption = 149.343645 pJ
sum error= 285
Actual label: 3
Output voltages: [0.041731, 0.043791, 0.3252, 0.79875, 0.021856, 0.0011399, 0.20051, 0.0077313, 0.7518, 0.12949]
Predicted label: 3
Correct prediction
Energy consumption = 139.834673 pJ
sum error= 285
Actual label: 9
Output voltages: [0.39516, 0.001416, 0.026901, 0.025993, 0.031107, 0.0010661, 0.0013122, 0.058229, 0.60558, 0.79723]
Predicted label: 9
Correct prediction
Energy consumption = 145.423714 pJ
sum error= 285
Actual label: 7
Output voltages: [0.18576, 0.48291, 0.72225, 0.026397, 0.044221, 0.0013272, 0.0013831, 0.79603, 0.0058115, 0.68198]
Predicted label: 7
Correct prediction
Energy consumption = 159.181988 pJ
sum error= 285
Actual label: 8
Output voltages: [0.3967, 0.0013544, 0.43986, 0.473, 0.0099808, 0.0065675, 0.048322, 0.0016333, 0.79765, 0.31903]
Predicted label: 8
Correct prediction
Energy consumption = 151.895676 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 605 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 605 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 605 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.053366, 0.062291, 0.080996, 0.025674, 0.020203, 0.027567, 0.0011002, 0.79864, 0.05291, 0.50826]
Predicted label: 7
Correct prediction
Energy consumption = 177.777071 pJ
sum error= 285
Actual label: 2
Output voltages: [0.18491, 0.042028, 0.79877, 0.044143, 0.038061, 0.0012499, 0.2714, 0.30246, 0.39426, 0.02916]
Predicted label: 2
Correct prediction
Energy consumption = 157.623482 pJ
sum error= 285
Actual label: 2
Output voltages: [0.37771, 0.44637, 0.79879, 0.031462, 0.01327, 0.0011939, 0.31199, 0.0074086, 0.13754, 0.031696]
Predicted label: 2
Correct prediction
Energy consumption = 145.964060 pJ
sum error= 285
Actual label: 5
Output voltages: [0.0039053, 0.0016667, 0.050265, 0.42095, 0.048333, 0.36696, 0.0037921, 0.014606, 0.79007, 0.40275]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.792399 pJ
sum error= 286
Actual label: 7
Output voltages: [0.058498, 0.29226, 0.38083, 0.21911, 0.0015596, 0.0011089, 0.0015008, 0.79879, 0.019636, 0.71515]
Predicted label: 7
Correct prediction
Energy consumption = 159.361952 pJ
sum error= 286
Actual label: 9
Output voltages: [0.48286, 0.011054, 0.037686, 0.034308, 0.023327, 0.010749, 0.0016414, 0.13417, 0.52933, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 150.805501 pJ
sum error= 286
Actual label: 8
Output voltages: [0.18826, 0.011102, 0.041484, 0.51106, 0.0013385, 0.12472, 0.0071802, 0.0018628, 0.79878, 0.35044]
Predicted label: 8
Correct prediction
Energy consumption = 144.430287 pJ
sum error= 286
Actual label: 2
Output voltages: [0.19298, 0.22222, 0.79875, 0.026741, 0.023138, 0.0014166, 0.30694, 0.027262, 0.2051, 0.02533]
Predicted label: 2
Correct prediction
Energy consumption = 154.441975 pJ
sum error= 286
Actual label: 1
Output voltages: [0.041734, 0.79853, 0.056553, 0.11769, 0.074759, 0.0011642, 0.41878, 0.0010695, 0.051189, 0.25715]
Predicted label: 1
Correct prediction
Energy consumption = 158.500728 pJ
sum error= 286
Actual label: 3
Output voltages: [0.039168, 0.029481, 0.080128, 0.79875, 0.0041008, 0.046589, 0.037586, 0.0090358, 0.52687, 0.04456]
Predicted label: 3
Correct prediction
Energy consumption = 153.739435 pJ
sum error= 286
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 606 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 606 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 606 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.015187, 0.79872, 0.0069304, 0.091693, 0.013435, 0.034062, 0.13899, 0.0034601, 0.40886, 0.015356]
Predicted label: 1
Correct prediction
Energy consumption = 185.329274 pJ
sum error= 286
Actual label: 3
Output voltages: [0.39743, 0.016185, 0.07905, 0.79869, 0.018336, 0.03682, 0.037329, 0.029603, 0.39709, 0.052171]
Predicted label: 3
Correct prediction
Energy consumption = 150.103582 pJ
sum error= 286
Actual label: 0
Output voltages: [0.79877, 0.11305, 0.018811, 0.011292, 0.016956, 0.0085823, 0.39809, 0.036436, 0.26292, 0.039202]
Predicted label: 0
Correct prediction
Energy consumption = 146.567752 pJ
sum error= 286
Actual label: 1
Output voltages: [0.018489, 0.79849, 0.13087, 0.31934, 0.0021673, 0.0010927, 0.76298, 0.0056089, 0.038724, 0.020219]
Predicted label: 1
Correct prediction
Energy consumption = 163.055114 pJ
sum error= 286
Actual label: 2
Output voltages: [0.58913, 0.031982, 0.79848, 0.32531, 0.016763, 0.0012005, 0.15007, 0.0082451, 0.56007, 0.021273]
Predicted label: 2
Correct prediction
Energy consumption = 150.589328 pJ
sum error= 286
Actual label: 3
Output voltages: [0.090388, 0.0082443, 0.37975, 0.7959, 0.0012637, 0.0012872, 0.0015661, 0.19765, 0.79504, 0.0022857]
Predicted label: 3
Correct prediction
Energy consumption = 144.451131 pJ
sum error= 286
Actual label: 4
Output voltages: [0.0039351, 0.011618, 0.055718, 0.015296, 0.79861, 0.0028456, 0.30841, 0.3297, 0.035107, 0.03624]
Predicted label: 4
Correct prediction
Energy consumption = 142.772714 pJ
sum error= 286
Actual label: 5
Output voltages: [0.027067, 0.0010962, 0.0019091, 0.073206, 0.12064, 0.79843, 0.15975, 0.039107, 0.77966, 0.052833]
Predicted label: 5
Correct prediction
Energy consumption = 144.062315 pJ
sum error= 286
Actual label: 6
Output voltages: [0.23935, 0.030879, 0.29084, 0.001843, 0.30592, 0.30581, 0.79877, 0.0023033, 0.59451, 0.01373]
Predicted label: 6
Correct prediction
Energy consumption = 139.468014 pJ
sum error= 286
Actual label: 7
Output voltages: [0.044231, 0.0078615, 0.013792, 0.041601, 0.036617, 0.014585, 0.0010682, 0.79869, 0.58105, 0.34433]
Predicted label: 7
Correct prediction
Energy consumption = 152.780636 pJ
sum error= 286
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 607 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 607 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 607 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.6184, 0.014305, 0.50671, 0.42551, 0.0084394, 0.0013158, 0.071218, 0.001127, 0.79566, 0.35189]
Predicted label: 8
Correct prediction
Energy consumption = 170.161206 pJ
sum error= 286
Actual label: 9
Output voltages: [0.08063, 0.0010662, 0.039637, 0.28283, 0.035538, 0.049169, 0.0041607, 0.0027113, 0.78, 0.4462]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.942560 pJ
sum error= 287
Actual label: 0
Output voltages: [0.79876, 0.020092, 0.029647, 0.0065984, 0.027243, 0.0041349, 0.69256, 0.018226, 0.097264, 0.064627]
Predicted label: 0
Correct prediction
Energy consumption = 141.132808 pJ
sum error= 287
Actual label: 1
Output voltages: [0.013759, 0.79853, 0.04461, 0.23476, 0.0010664, 0.0011398, 0.7671, 0.013742, 0.065241, 0.0306]
Predicted label: 1
Correct prediction
Energy consumption = 159.231489 pJ
sum error= 287
Actual label: 2
Output voltages: [0.44988, 0.05629, 0.79879, 0.3543, 0.023271, 0.0012143, 0.38852, 0.028432, 0.50209, 0.05409]
Predicted label: 2
Correct prediction
Energy consumption = 148.266328 pJ
sum error= 287
Actual label: 3
Output voltages: [0.16058, 0.0010704, 0.056673, 0.79875, 0.06719, 0.31898, 0.0049752, 0.04063, 0.77257, 0.024277]
Predicted label: 3
Correct prediction
Energy consumption = 145.458933 pJ
sum error= 287
Actual label: 4
Output voltages: [0.03274, 0.023881, 0.23726, 0.0083964, 0.79873, 0.0028018, 0.2247, 0.03293, 0.021812, 0.55535]
Predicted label: 4
Correct prediction
Energy consumption = 149.796251 pJ
sum error= 287
Actual label: 5
Output voltages: [0.033641, 0.0013547, 0.011446, 0.099648, 0.015524, 0.79879, 0.56091, 0.026534, 0.78936, 0.0027995]
Predicted label: 5
Correct prediction
Energy consumption = 146.902482 pJ
sum error= 287
Actual label: 6
Output voltages: [0.14339, 0.013122, 0.34352, 0.0010716, 0.51936, 0.16223, 0.79878, 0.0012628, 0.37395, 0.003036]
Predicted label: 6
Correct prediction
Energy consumption = 143.225471 pJ
sum error= 287
Actual label: 7
Output voltages: [0.14616, 0.13153, 0.050972, 0.081576, 0.0080459, 0.0053368, 0.0011332, 0.79855, 0.1474, 0.34895]
Predicted label: 7
Correct prediction
Energy consumption = 160.462606 pJ
sum error= 287
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 608 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 608 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 608 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.044847, 0.0098093, 0.7528, 0.018257, 0.025424, 0.0013199, 0.69161, 0.0018861, 0.79743, 0.08831]
Predicted label: 8
Correct prediction
Energy consumption = 167.610667 pJ
sum error= 287
Actual label: 9
Output voltages: [0.7546, 0.004652, 0.15777, 0.19242, 0.014468, 0.021806, 0.0080902, 0.0010891, 0.78325, 0.64896]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.652764 pJ
sum error= 288
Actual label: 0
Output voltages: [0.79879, 0.101, 0.025731, 0.026343, 0.015178, 0.014531, 0.62111, 0.033834, 0.29597, 0.049205]
Predicted label: 0
Correct prediction
Energy consumption = 139.413442 pJ
sum error= 288
Actual label: 1
Output voltages: [0.030594, 0.79878, 0.019355, 0.11028, 0.34193, 0.0030376, 0.45095, 0.0010663, 0.63672, 0.044703]
Predicted label: 1
Correct prediction
Energy consumption = 162.751511 pJ
sum error= 288
Actual label: 2
Output voltages: [0.38899, 0.050463, 0.79879, 0.2558, 0.01132, 0.0012707, 0.045828, 0.032727, 0.38251, 0.020577]
Predicted label: 2
Correct prediction
Energy consumption = 145.240414 pJ
sum error= 288
Actual label: 3
Output voltages: [0.10739, 0.0016635, 0.25778, 0.7971, 0.0013671, 0.031565, 0.0011864, 0.031323, 0.7982, 0.0046388]
Predicted label: 8
Wrong prediction!
Energy consumption = 140.212184 pJ
sum error= 289
Actual label: 4
Output voltages: [0.0083084, 0.020003, 0.032022, 0.0073237, 0.79867, 0.0034078, 0.3334, 0.099767, 0.039764, 0.037543]
Predicted label: 4
Correct prediction
Energy consumption = 144.505169 pJ
sum error= 289
Actual label: 5
Output voltages: [0.28739, 0.0012528, 0.0055274, 0.14656, 0.016689, 0.79727, 0.096986, 0.014591, 0.78206, 0.0029997]
Predicted label: 5
Correct prediction
Energy consumption = 144.296257 pJ
sum error= 289
Actual label: 6
Output voltages: [0.04267, 0.036975, 0.14687, 0.014597, 0.31143, 0.51422, 0.79877, 0.0029029, 0.74596, 0.011061]
Predicted label: 6
Correct prediction
Energy consumption = 140.965776 pJ
sum error= 289
Actual label: 7
Output voltages: [0.15235, 0.089659, 0.048911, 0.035969, 0.0012685, 0.0014898, 0.0011242, 0.7987, 0.23834, 0.23871]
Predicted label: 7
Correct prediction
Energy consumption = 155.697394 pJ
sum error= 289
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 609 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 609 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 609 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.28909, 0.0013701, 0.23896, 0.12272, 0.010174, 0.034301, 0.033759, 0.001652, 0.79876, 0.14648]
Predicted label: 8
Correct prediction
Energy consumption = 172.683937 pJ
sum error= 289
Actual label: 9
Output voltages: [0.68269, 0.0011093, 0.015935, 0.063146, 0.0019709, 0.33107, 0.0056523, 0.0014776, 0.79132, 0.25749]
Predicted label: 8
Wrong prediction!
Energy consumption = 141.721691 pJ
sum error= 290
Actual label: 1
Output voltages: [0.032507, 0.7987, 0.26662, 0.12306, 0.35593, 0.0013401, 0.3027, 0.0083505, 0.1304, 0.019519]
Predicted label: 1
Correct prediction
Energy consumption = 163.862194 pJ
sum error= 290
Actual label: 2
Output voltages: [0.062512, 0.016376, 0.79878, 0.049292, 0.0075915, 0.0012458, 0.14158, 0.028935, 0.74329, 0.028984]
Predicted label: 2
Correct prediction
Energy consumption = 142.747704 pJ
sum error= 290
Actual label: 6
Output voltages: [0.15439, 0.048538, 0.053634, 0.0017298, 0.31573, 0.35149, 0.79878, 0.0053128, 0.45174, 0.0013631]
Predicted label: 6
Correct prediction
Energy consumption = 153.104125 pJ
sum error= 290
Actual label: 5
Output voltages: [0.069518, 0.001145, 0.0018122, 0.059791, 0.052066, 0.79874, 0.27491, 0.017991, 0.77237, 0.00859]
Predicted label: 5
Correct prediction
Energy consumption = 143.606883 pJ
sum error= 290
Actual label: 3
Output voltages: [0.15501, 0.0158, 0.037419, 0.79863, 0.034414, 0.019785, 0.0098702, 0.039758, 0.61028, 0.14772]
Predicted label: 3
Correct prediction
Energy consumption = 144.039672 pJ
sum error= 290
Actual label: 0
Output voltages: [0.79874, 0.1542, 0.019091, 0.014703, 0.0073068, 0.013803, 0.5632, 0.04137, 0.24482, 0.026937]
Predicted label: 0
Correct prediction
Energy consumption = 147.094460 pJ
sum error= 290
Actual label: 7
Output voltages: [0.04287, 0.032397, 0.14719, 0.096539, 0.0013092, 0.0015653, 0.0011776, 0.79872, 0.54291, 0.32303]
Predicted label: 7
Correct prediction
Energy consumption = 162.372604 pJ
sum error= 290
Actual label: 0
Output voltages: [0.7987, 0.10729, 0.023872, 0.013301, 0.010409, 0.0060769, 0.62867, 0.030796, 0.24849, 0.025535]
Predicted label: 0
Correct prediction
Energy consumption = 142.036611 pJ
sum error= 290
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 610 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 610 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 610 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.014016, 0.023192, 0.31419, 0.0015045, 0.79872, 0.029367, 0.21749, 0.083687, 0.051278, 0.021383]
Predicted label: 4
Correct prediction
Energy consumption = 165.423956 pJ
sum error= 290
Actual label: 1
Output voltages: [0.059543, 0.7871, 0.013693, 0.69452, 0.0010686, 0.038513, 0.43468, 0.0016846, 0.77145, 0.0081488]
Predicted label: 1
Correct prediction
Energy consumption = 166.711642 pJ
sum error= 290
Actual label: 4
Output voltages: [0.012392, 0.0070069, 0.058047, 0.002884, 0.79877, 0.0010681, 0.52658, 0.14988, 0.010863, 0.011154]
Predicted label: 4
Correct prediction
Energy consumption = 156.683604 pJ
sum error= 290
Actual label: 3
Output voltages: [0.099811, 0.0095503, 0.05885, 0.79872, 0.032419, 0.21688, 0.047823, 0.041566, 0.68464, 0.045411]
Predicted label: 3
Correct prediction
Energy consumption = 143.385257 pJ
sum error= 290
Actual label: 6
Output voltages: [0.12104, 0.047734, 0.33952, 0.0016276, 0.28055, 0.23433, 0.79874, 0.0025125, 0.6782, 0.013859]
Predicted label: 6
Correct prediction
Energy consumption = 144.685441 pJ
sum error= 290
Actual label: 7
Output voltages: [0.051522, 0.029385, 0.1938, 0.027561, 0.0013918, 0.0015575, 0.0012106, 0.79876, 0.78173, 0.14961]
Predicted label: 7
Correct prediction
Energy consumption = 153.198160 pJ
sum error= 290
Actual label: 2
Output voltages: [0.44516, 0.022676, 0.79874, 0.13345, 0.026646, 0.0012398, 0.3805, 0.042664, 0.72579, 0.062865]
Predicted label: 2
Correct prediction
Energy consumption = 139.773505 pJ
sum error= 290
Actual label: 3
Output voltages: [0.031254, 0.0049669, 0.035652, 0.79878, 0.014135, 0.0088344, 0.0091303, 0.021708, 0.78146, 0.026983]
Predicted label: 3
Correct prediction
Energy consumption = 138.036699 pJ
sum error= 290
Actual label: 1
Output voltages: [0.0033974, 0.7985, 0.059746, 0.021214, 0.014241, 0.0013852, 0.76429, 0.025223, 0.21371, 0.020043]
Predicted label: 1
Correct prediction
Energy consumption = 153.648034 pJ
sum error= 290
Actual label: 2
Output voltages: [0.24723, 0.038538, 0.79875, 0.033968, 0.0059901, 0.0011758, 0.02488, 0.74238, 0.6827, 0.0017894]
Predicted label: 2
Correct prediction
Energy consumption = 134.582643 pJ
sum error= 290
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 611 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 611 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 611 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.022666, 0.79816, 0.0068697, 0.69909, 0.017248, 0.001068, 0.69556, 0.0010772, 0.67686, 0.34569]
Predicted label: 1
Correct prediction
Energy consumption = 182.758810 pJ
sum error= 290
Actual label: 2
Output voltages: [0.2888, 0.030502, 0.79879, 0.046339, 0.011548, 0.0012277, 0.058018, 0.29593, 0.73505, 0.019086]
Predicted label: 2
Correct prediction
Energy consumption = 144.072761 pJ
sum error= 290
Actual label: 9
Output voltages: [0.74129, 0.0014262, 0.033146, 0.018772, 0.02838, 0.017542, 0.016897, 0.0058746, 0.64471, 0.78228]
Predicted label: 9
Correct prediction
Energy consumption = 144.314232 pJ
sum error= 290
Actual label: 6
Output voltages: [0.12147, 0.040718, 0.26253, 0.0014406, 0.33649, 0.03733, 0.79875, 0.0027922, 0.42046, 0.007569]
Predicted label: 6
Correct prediction
Energy consumption = 142.943344 pJ
sum error= 290
Actual label: 0
Output voltages: [0.79879, 0.050194, 0.0057197, 0.018697, 0.019302, 0.013883, 0.66927, 0.018155, 0.13689, 0.049262]
Predicted label: 0
Correct prediction
Energy consumption = 144.933979 pJ
sum error= 290
Actual label: 1
Output voltages: [0.049992, 0.79878, 0.01177, 0.12157, 0.33257, 0.0010931, 0.11543, 0.0010846, 0.61943, 0.13773]
Predicted label: 1
Correct prediction
Energy consumption = 162.535998 pJ
sum error= 290
Actual label: 3
Output voltages: [0.19124, 0.026534, 0.039386, 0.7987, 0.018548, 0.0050744, 0.0090051, 0.022127, 0.74065, 0.031819]
Predicted label: 3
Correct prediction
Energy consumption = 139.098991 pJ
sum error= 290
Actual label: 0
Output voltages: [0.79389, 0.027475, 0.022467, 0.012737, 0.029608, 0.0016725, 0.66204, 0.024691, 0.45599, 0.032147]
Predicted label: 0
Correct prediction
Energy consumption = 150.890088 pJ
sum error= 290
Actual label: 2
Output voltages: [0.54626, 0.061626, 0.7987, 0.051538, 0.008935, 0.0012253, 0.092575, 0.050675, 0.41333, 0.01821]
Predicted label: 2
Correct prediction
Energy consumption = 148.018388 pJ
sum error= 290
Actual label: 7
Output voltages: [0.046651, 0.052198, 0.058907, 0.015845, 0.011589, 0.0010695, 0.0011096, 0.79876, 0.73997, 0.10426]
Predicted label: 7
Correct prediction
Energy consumption = 148.806816 pJ
sum error= 290
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 612 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 612 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 612 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.047381, 0.0010661, 0.0034713, 0.038959, 0.030101, 0.79875, 0.64314, 0.020547, 0.78051, 0.0012042]
Predicted label: 5
Correct prediction
Energy consumption = 154.074141 pJ
sum error= 290
Actual label: 7
Output voltages: [0.51889, 0.21995, 0.06956, 0.021247, 0.019533, 0.0015521, 0.0010666, 0.79878, 0.183, 0.01038]
Predicted label: 7
Correct prediction
Energy consumption = 153.719487 pJ
sum error= 290
Actual label: 6
Output voltages: [0.32875, 0.032436, 0.030398, 0.017349, 0.2166, 0.46137, 0.7987, 0.0014274, 0.56642, 0.016358]
Predicted label: 6
Correct prediction
Energy consumption = 148.957383 pJ
sum error= 290
Actual label: 2
Output voltages: [0.37021, 0.039633, 0.79878, 0.082813, 0.015775, 0.0012638, 0.32477, 0.027962, 0.68136, 0.026268]
Predicted label: 2
Correct prediction
Energy consumption = 143.932493 pJ
sum error= 290
Actual label: 9
Output voltages: [0.18747, 0.0011251, 0.031971, 0.011993, 0.018297, 0.38875, 0.0029443, 0.008532, 0.78838, 0.44847]
Predicted label: 8
Wrong prediction!
Energy consumption = 151.246711 pJ
sum error= 291
Actual label: 1
Output voltages: [0.016254, 0.79836, 0.071536, 0.15712, 0.0070369, 0.015441, 0.76448, 0.013546, 0.068993, 0.06206]
Predicted label: 1
Correct prediction
Energy consumption = 168.563483 pJ
sum error= 291
Actual label: 9
Output voltages: [0.30326, 0.0019755, 0.033856, 0.027239, 0.011674, 0.03842, 0.01307, 0.0035406, 0.75869, 0.7702]
Predicted label: 9
Correct prediction
Energy consumption = 145.652244 pJ
sum error= 291
Actual label: 0
Output voltages: [0.79867, 0.080911, 0.043503, 0.016867, 0.0040412, 0.044001, 0.21111, 0.036229, 0.080685, 0.0088316]
Predicted label: 0
Correct prediction
Energy consumption = 144.455514 pJ
sum error= 291
Actual label: 6
Output voltages: [0.072302, 0.05795, 0.23319, 0.0016032, 0.32154, 0.33856, 0.79867, 0.0023113, 0.30113, 0.023635]
Predicted label: 6
Correct prediction
Energy consumption = 142.313259 pJ
sum error= 291
Actual label: 0
Output voltages: [0.79869, 0.13285, 0.039057, 0.022776, 0.0064915, 0.03798, 0.26804, 0.0056672, 0.060885, 0.067212]
Predicted label: 0
Correct prediction
Energy consumption = 144.715025 pJ
sum error= 291
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 613 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 613 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 613 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.04848, 0.043366, 0.30321, 0.0011512, 0.27985, 0.067128, 0.79874, 0.003675, 0.35457, 0.0074177]
Predicted label: 6
Correct prediction
Energy consumption = 162.727900 pJ
sum error= 291
Actual label: 0
Output voltages: [0.79869, 0.039407, 0.036423, 0.013425, 0.0093665, 0.01235, 0.41909, 0.010273, 0.065149, 0.050014]
Predicted label: 0
Correct prediction
Energy consumption = 147.229180 pJ
sum error= 291
Actual label: 2
Output voltages: [0.29078, 0.049824, 0.79878, 0.03786, 0.017711, 0.0012982, 0.3972, 0.026399, 0.67891, 0.035739]
Predicted label: 2
Correct prediction
Energy consumption = 147.671389 pJ
sum error= 291
Actual label: 0
Output voltages: [0.79875, 0.10136, 0.016414, 0.1069, 0.0093755, 0.14595, 0.42506, 0.01698, 0.032579, 0.039527]
Predicted label: 0
Correct prediction
Energy consumption = 151.052873 pJ
sum error= 291
Actual label: 6
Output voltages: [0.054234, 0.032235, 0.10141, 0.0051272, 0.1252, 0.31891, 0.79879, 0.0012168, 0.63419, 0.011142]
Predicted label: 6
Correct prediction
Energy consumption = 149.127381 pJ
sum error= 291
Actual label: 1
Output voltages: [0.026098, 0.79863, 0.048037, 0.19804, 0.077394, 0.0010664, 0.74393, 0.0015944, 0.28621, 0.041317]
Predicted label: 1
Correct prediction
Energy consumption = 163.579602 pJ
sum error= 291
Actual label: 5
Output voltages: [0.048808, 0.0011097, 0.0011275, 0.40298, 0.007878, 0.79873, 0.31202, 0.01975, 0.754, 0.010625]
Predicted label: 5
Correct prediction
Energy consumption = 140.837301 pJ
sum error= 291
Actual label: 8
Output voltages: [0.18269, 0.018461, 0.32454, 0.065006, 0.059803, 0.007358, 0.092295, 0.0015988, 0.79879, 0.18366]
Predicted label: 8
Correct prediction
Energy consumption = 141.162095 pJ
sum error= 291
Actual label: 4
Output voltages: [0.0053696, 0.0039593, 0.071168, 0.015307, 0.79855, 0.0035831, 0.26226, 0.15142, 0.032874, 0.016326]
Predicted label: 4
Correct prediction
Energy consumption = 154.357918 pJ
sum error= 291
Actual label: 3
Output voltages: [0.28124, 0.0039335, 0.53655, 0.79866, 0.013687, 0.0011328, 0.012001, 0.0011332, 0.7445, 0.020917]
Predicted label: 3
Correct prediction
Energy consumption = 139.781795 pJ
sum error= 291
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 614 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 614 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 614 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.068671, 0.014092, 0.028556, 0.0051683, 0.025258, 0.61119, 0.031179, 0.26649, 0.028259]
Predicted label: 0
Correct prediction
Energy consumption = 162.009916 pJ
sum error= 291
Actual label: 1
Output voltages: [0.29552, 0.79867, 0.1305, 0.14382, 0.013124, 0.0011159, 0.55693, 0.0012372, 0.022496, 0.1245]
Predicted label: 1
Correct prediction
Energy consumption = 158.022269 pJ
sum error= 291
Actual label: 5
Output voltages: [0.12224, 0.0012131, 0.0015145, 0.069454, 0.042196, 0.79835, 0.16739, 0.0084229, 0.7823, 0.0015375]
Predicted label: 5
Correct prediction
Energy consumption = 146.999439 pJ
sum error= 291
Actual label: 4
Output voltages: [0.026379, 0.008321, 0.020158, 0.0011281, 0.79879, 0.0040417, 0.29464, 0.16405, 0.26306, 0.0028017]
Predicted label: 4
Correct prediction
Energy consumption = 149.954265 pJ
sum error= 291
Actual label: 4
Output voltages: [0.05186, 0.0035722, 0.37622, 0.0037938, 0.79875, 0.0020041, 0.40628, 0.035734, 0.020782, 0.011575]
Predicted label: 4
Correct prediction
Energy consumption = 138.491244 pJ
sum error= 291
Actual label: 8
Output voltages: [0.022319, 0.10267, 0.14777, 0.15624, 0.016327, 0.0189, 0.035746, 0.0071068, 0.79871, 0.36758]
Predicted label: 8
Correct prediction
Energy consumption = 152.896748 pJ
sum error= 291
Actual label: 5
Output voltages: [0.01506, 0.0012031, 0.011129, 0.055005, 0.010056, 0.78577, 0.30284, 0.0039683, 0.7724, 0.025222]
Predicted label: 5
Correct prediction
Energy consumption = 141.001352 pJ
sum error= 291
Actual label: 7
Output voltages: [0.23606, 0.034829, 0.001465, 0.12755, 0.0097138, 0.0043756, 0.0011123, 0.79796, 0.22812, 0.7235]
Predicted label: 7
Correct prediction
Energy consumption = 152.175603 pJ
sum error= 291
Actual label: 5
Output voltages: [0.028931, 0.0022465, 0.0027027, 0.26523, 0.011241, 0.79875, 0.28877, 0.049932, 0.75797, 0.010871]
Predicted label: 5
Correct prediction
Energy consumption = 145.114681 pJ
sum error= 291
Actual label: 7
Output voltages: [0.053394, 0.065761, 0.13627, 0.12819, 0.0053761, 0.0011274, 0.0011165, 0.79868, 0.6592, 0.039324]
Predicted label: 7
Correct prediction
Energy consumption = 150.280201 pJ
sum error= 291
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 615 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 615 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 615 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.17783, 0.022853, 0.52485, 0.031246, 0.022364, 0.011449, 0.015286, 0.0014766, 0.79876, 0.05856]
Predicted label: 8
Correct prediction
Energy consumption = 167.877247 pJ
sum error= 291
Actual label: 3
Output voltages: [0.39726, 0.0058955, 0.051408, 0.7986, 0.050657, 0.025339, 0.018808, 0.039698, 0.63126, 0.10167]
Predicted label: 3
Correct prediction
Energy consumption = 146.017589 pJ
sum error= 291
Actual label: 4
Output voltages: [0.008885, 0.030357, 0.028717, 0.0012017, 0.79871, 0.0020296, 0.091426, 0.032286, 0.10226, 0.057271]
Predicted label: 4
Correct prediction
Energy consumption = 154.111168 pJ
sum error= 291
Actual label: 8
Output voltages: [0.050991, 0.013458, 0.11825, 0.27503, 0.01491, 0.12544, 0.011037, 0.001258, 0.79879, 0.50843]
Predicted label: 8
Correct prediction
Energy consumption = 151.404452 pJ
sum error= 291
Actual label: 8
Output voltages: [0.046751, 0.0084422, 0.10802, 0.15928, 0.002983, 0.39968, 0.022026, 0.0010756, 0.79879, 0.059989]
Predicted label: 8
Correct prediction
Energy consumption = 146.525807 pJ
sum error= 291
Actual label: 5
Output voltages: [0.049825, 0.0011697, 0.0016072, 0.17217, 0.15259, 0.79876, 0.51897, 0.019849, 0.73951, 0.023283]
Predicted label: 5
Correct prediction
Energy consumption = 148.232323 pJ
sum error= 291
Actual label: 2
Output voltages: [0.35616, 0.056197, 0.79873, 0.032745, 0.04742, 0.0012414, 0.37949, 0.017094, 0.55008, 0.039209]
Predicted label: 2
Correct prediction
Energy consumption = 152.096822 pJ
sum error= 291
Actual label: 9
Output voltages: [0.7783, 0.0071185, 0.049617, 0.084048, 0.11382, 0.0022844, 0.088024, 0.0010679, 0.73865, 0.74621]
Predicted label: 0
Wrong prediction!
Energy consumption = 150.749532 pJ
sum error= 292
Actual label: 7
Output voltages: [0.057388, 0.020498, 0.025724, 0.15774, 0.0076631, 0.010617, 0.0011063, 0.79874, 0.66492, 0.38466]
Predicted label: 7
Correct prediction
Energy consumption = 151.855261 pJ
sum error= 292
Actual label: 1
Output voltages: [0.14235, 0.79852, 0.28548, 0.10981, 0.015605, 0.0010662, 0.37692, 0.0023973, 0.32328, 0.12413]
Predicted label: 1
Correct prediction
Energy consumption = 158.477382 pJ
sum error= 292
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 616 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 616 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 616 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.08331, 0.024568, 0.38772, 0.79875, 0.019056, 0.0017078, 0.023854, 0.013005, 0.75079, 0.0396]
Predicted label: 3
Correct prediction
Energy consumption = 156.589005 pJ
sum error= 292
Actual label: 8
Output voltages: [0.11315, 0.0085228, 0.31977, 0.019415, 0.050186, 0.0081812, 0.047676, 0.0026475, 0.79878, 0.021208]
Predicted label: 8
Correct prediction
Energy consumption = 145.558857 pJ
sum error= 292
Actual label: 1
Output voltages: [0.086618, 0.79867, 0.031071, 0.058011, 0.16034, 0.010719, 0.38975, 0.0040149, 0.10875, 0.087829]
Predicted label: 1
Correct prediction
Energy consumption = 166.763782 pJ
sum error= 292
Actual label: 0
Output voltages: [0.79876, 0.056582, 0.03768, 0.014366, 0.0077619, 0.0043239, 0.56754, 0.022052, 0.16163, 0.022522]
Predicted label: 0
Correct prediction
Energy consumption = 151.939887 pJ
sum error= 292
Actual label: 7
Output voltages: [0.062201, 0.027436, 0.012875, 0.10243, 0.049097, 0.0059769, 0.0010667, 0.79878, 0.48151, 0.39068]
Predicted label: 7
Correct prediction
Energy consumption = 157.711858 pJ
sum error= 292
Actual label: 5
Output voltages: [0.046693, 0.0010857, 0.010055, 0.29859, 0.025266, 0.78796, 0.044445, 0.023022, 0.79349, 0.072845]
Predicted label: 8
Wrong prediction!
Energy consumption = 145.298632 pJ
sum error= 293
Actual label: 9
Output voltages: [0.55575, 0.0027654, 0.014125, 0.22276, 0.0038965, 0.045886, 0.011691, 0.0010847, 0.79757, 0.37055]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.339976 pJ
sum error= 294
Actual label: 6
Output voltages: [0.085103, 0.026842, 0.20093, 0.0086115, 0.36421, 0.28842, 0.79875, 0.0011372, 0.60732, 0.0084639]
Predicted label: 6
Correct prediction
Energy consumption = 143.474948 pJ
sum error= 294
Actual label: 9
Output voltages: [0.28819, 0.0038855, 0.027599, 0.027741, 0.094953, 0.0037029, 0.011391, 0.005551, 0.76751, 0.76234]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.793665 pJ
sum error= 295
Actual label: 4
Output voltages: [0.004902, 0.022424, 0.10787, 0.0030434, 0.79878, 0.0015119, 0.43211, 0.2024, 0.032179, 0.026889]
Predicted label: 4
Correct prediction
Energy consumption = 145.533140 pJ
sum error= 295
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 617 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 617 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 617 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.4967, 0.14809, 0.20934, 0.2202, 0.0060182, 0.0012794, 0.0011516, 0.79858, 0.42986, 0.1515]
Predicted label: 7
Correct prediction
Energy consumption = 172.711305 pJ
sum error= 295
Actual label: 7
Output voltages: [0.1756, 0.10362, 0.33232, 0.093337, 0.012177, 0.002204, 0.0010827, 0.79856, 0.18609, 0.17559]
Predicted label: 7
Correct prediction
Energy consumption = 142.206243 pJ
sum error= 295
Actual label: 9
Output voltages: [0.76427, 0.0023247, 0.029749, 0.21608, 0.017861, 0.046836, 0.1138, 0.0010673, 0.75112, 0.58393]
Predicted label: 0
Wrong prediction!
Energy consumption = 150.885918 pJ
sum error= 296
Actual label: 9
Output voltages: [0.79492, 0.0011653, 0.14871, 0.078637, 0.15285, 0.0010664, 0.0089815, 0.032618, 0.64761, 0.33832]
Predicted label: 0
Wrong prediction!
Energy consumption = 136.930945 pJ
sum error= 297
Actual label: 3
Output voltages: [0.19697, 0.021094, 0.3331, 0.79863, 0.042148, 0.030094, 0.047864, 0.042828, 0.76831, 0.080071]
Predicted label: 3
Correct prediction
Energy consumption = 136.822544 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0073402, 0.0016395, 0.022714, 0.0020414, 0.79868, 0.001071, 0.077078, 0.041777, 0.31086, 0.013094]
Predicted label: 4
Correct prediction
Energy consumption = 154.196127 pJ
sum error= 297
Actual label: 4
Output voltages: [0.063201, 0.0094792, 0.045568, 0.0011012, 0.79877, 0.0023807, 0.091039, 0.017842, 0.15659, 0.024638]
Predicted label: 4
Correct prediction
Energy consumption = 137.713843 pJ
sum error= 297
Actual label: 3
Output voltages: [0.13018, 0.004372, 0.084146, 0.79872, 0.0086529, 0.041117, 0.0048806, 0.020451, 0.44364, 0.040037]
Predicted label: 3
Correct prediction
Energy consumption = 143.136048 pJ
sum error= 297
Actual label: 8
Output voltages: [0.27794, 0.019177, 0.30714, 0.038846, 0.010344, 0.019656, 0.0017062, 0.0010718, 0.79867, 0.45686]
Predicted label: 8
Correct prediction
Energy consumption = 146.439405 pJ
sum error= 297
Actual label: 6
Output voltages: [0.082843, 0.00852, 0.21113, 0.0012833, 0.26165, 0.45409, 0.79864, 0.0011518, 0.73597, 0.060564]
Predicted label: 6
Correct prediction
Energy consumption = 147.471785 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 618 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 618 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 618 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36564, 0.0062477, 0.79878, 0.24804, 0.006441, 0.0012066, 0.38315, 0.080585, 0.50931, 0.026679]
Predicted label: 2
Correct prediction
Energy consumption = 162.215206 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79597, 0.08504, 0.019462, 0.0055206, 0.018767, 0.0011928, 0.39894, 0.043152, 0.48473, 0.27937]
Predicted label: 0
Correct prediction
Energy consumption = 147.334397 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0029928, 0.79851, 0.24079, 0.24099, 0.041211, 0.0022131, 0.50104, 0.012913, 0.40185, 0.055739]
Predicted label: 1
Correct prediction
Energy consumption = 161.297384 pJ
sum error= 297
Actual label: 2
Output voltages: [0.45048, 0.01999, 0.79823, 0.51189, 0.0028782, 0.0011022, 0.11814, 0.01732, 0.37636, 0.021218]
Predicted label: 2
Correct prediction
Energy consumption = 151.717225 pJ
sum error= 297
Actual label: 3
Output voltages: [0.11008, 0.021343, 0.094413, 0.79878, 0.0036782, 0.0082154, 0.0022635, 0.030782, 0.7703, 0.0095743]
Predicted label: 3
Correct prediction
Energy consumption = 139.555747 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0057578, 0.02227, 0.16979, 0.0083722, 0.79877, 0.0080212, 0.035638, 0.070186, 0.076952, 0.013396]
Predicted label: 4
Correct prediction
Energy consumption = 151.019737 pJ
sum error= 297
Actual label: 5
Output voltages: [0.037401, 0.0010678, 0.0011522, 0.76206, 0.034329, 0.79696, 0.065739, 0.027047, 0.74987, 0.039145]
Predicted label: 5
Correct prediction
Energy consumption = 149.014262 pJ
sum error= 297
Actual label: 6
Output voltages: [0.090419, 0.043032, 0.44501, 0.0011198, 0.21801, 0.17216, 0.79875, 0.0031525, 0.40662, 0.0022339]
Predicted label: 6
Correct prediction
Energy consumption = 146.759983 pJ
sum error= 297
Actual label: 7
Output voltages: [0.16115, 0.34604, 0.06523, 0.11202, 0.0035932, 0.0026652, 0.0010681, 0.79879, 0.23892, 0.34305]
Predicted label: 7
Correct prediction
Energy consumption = 161.441842 pJ
sum error= 297
Actual label: 8
Output voltages: [0.025198, 0.18277, 0.0394, 0.69225, 0.0016081, 0.029415, 0.022622, 0.0022586, 0.79875, 0.072587]
Predicted label: 8
Correct prediction
Energy consumption = 147.262380 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 619 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 619 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 619 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.10937, 0.010089, 0.015185, 0.057321, 0.044372, 0.01598, 0.0021701, 0.047077, 0.72453, 0.79704]
Predicted label: 9
Correct prediction
Energy consumption = 168.524460 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79878, 0.063402, 0.18334, 0.023765, 0.0024913, 0.0036088, 0.38177, 0.017473, 0.048317, 0.054445]
Predicted label: 0
Correct prediction
Energy consumption = 144.570520 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0055605, 0.79876, 0.20037, 0.041199, 0.36979, 0.0010679, 0.75731, 0.0034206, 0.18282, 0.013433]
Predicted label: 1
Correct prediction
Energy consumption = 161.715036 pJ
sum error= 297
Actual label: 2
Output voltages: [0.6722, 0.053056, 0.79879, 0.16631, 0.018774, 0.0010857, 0.037929, 0.069767, 0.53357, 0.0045908]
Predicted label: 2
Correct prediction
Energy consumption = 146.995582 pJ
sum error= 297
Actual label: 3
Output voltages: [0.66324, 0.015181, 0.22532, 0.79873, 0.015275, 0.0095181, 0.0047459, 0.02249, 0.54407, 0.031149]
Predicted label: 3
Correct prediction
Energy consumption = 142.349440 pJ
sum error= 297
Actual label: 4
Output voltages: [0.015503, 0.005183, 0.42357, 0.0025821, 0.79869, 0.0035278, 0.072116, 0.039155, 0.024443, 0.035079]
Predicted label: 4
Correct prediction
Energy consumption = 153.375093 pJ
sum error= 297
Actual label: 5
Output voltages: [0.029678, 0.0010704, 0.0024189, 0.16104, 0.03469, 0.79879, 0.089947, 0.023253, 0.77742, 0.043815]
Predicted label: 5
Correct prediction
Energy consumption = 151.814149 pJ
sum error= 297
Actual label: 6
Output voltages: [0.094552, 0.018107, 0.19864, 0.006051, 0.35897, 0.23773, 0.79877, 0.0010834, 0.60944, 0.0090163]
Predicted label: 6
Correct prediction
Energy consumption = 142.046758 pJ
sum error= 297
Actual label: 7
Output voltages: [0.2377, 0.02136, 0.024754, 0.20166, 0.012436, 0.026115, 0.0010941, 0.79867, 0.18082, 0.39401]
Predicted label: 7
Correct prediction
Energy consumption = 158.538396 pJ
sum error= 297
Actual label: 8
Output voltages: [0.017, 0.019493, 0.12185, 0.057605, 0.0061341, 0.13717, 0.029887, 0.0058447, 0.79868, 0.11325]
Predicted label: 8
Correct prediction
Energy consumption = 143.220190 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 620 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 620 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 620 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.13532, 0.011444, 0.037616, 0.020571, 0.045933, 0.049495, 0.017129, 0.11092, 0.69929, 0.79841]
Predicted label: 9
Correct prediction
Energy consumption = 172.010326 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.057634, 0.059559, 0.021699, 0.0057225, 0.0039685, 0.43378, 0.015571, 0.041434, 0.10775]
Predicted label: 0
Correct prediction
Energy consumption = 151.388994 pJ
sum error= 297
Actual label: 1
Output voltages: [0.033682, 0.79858, 0.21885, 0.01571, 0.019957, 0.0051036, 0.7373, 0.0012913, 0.32867, 0.019866]
Predicted label: 1
Correct prediction
Energy consumption = 162.946637 pJ
sum error= 297
Actual label: 2
Output voltages: [0.52799, 0.017082, 0.79876, 0.031502, 0.021554, 0.0011668, 0.057222, 0.036601, 0.40067, 0.015712]
Predicted label: 2
Correct prediction
Energy consumption = 150.226888 pJ
sum error= 297
Actual label: 3
Output voltages: [0.5537, 0.027158, 0.048044, 0.79864, 0.015682, 0.05446, 0.010131, 0.085306, 0.69692, 0.024334]
Predicted label: 3
Correct prediction
Energy consumption = 146.975974 pJ
sum error= 297
Actual label: 4
Output voltages: [0.010444, 0.00708, 0.03701, 0.0085506, 0.79872, 0.019774, 0.18957, 0.12325, 0.12528, 0.0015895]
Predicted label: 4
Correct prediction
Energy consumption = 150.576475 pJ
sum error= 297
Actual label: 5
Output voltages: [0.043623, 0.0012912, 0.0013161, 0.49016, 0.034144, 0.79722, 0.20057, 0.011649, 0.68165, 0.18821]
Predicted label: 5
Correct prediction
Energy consumption = 148.108429 pJ
sum error= 297
Actual label: 6
Output voltages: [0.091029, 0.02313, 0.26498, 0.0010829, 0.43035, 0.046985, 0.79875, 0.0012398, 0.48852, 0.0036056]
Predicted label: 6
Correct prediction
Energy consumption = 145.506693 pJ
sum error= 297
Actual label: 7
Output voltages: [0.28892, 0.078098, 0.016099, 0.051007, 0.0034958, 0.0017859, 0.0011643, 0.79877, 0.44686, 0.48625]
Predicted label: 7
Correct prediction
Energy consumption = 156.001425 pJ
sum error= 297
Actual label: 8
Output voltages: [0.026849, 0.054642, 0.18114, 0.12536, 0.0046413, 0.029841, 0.0233, 0.0079976, 0.79863, 0.19277]
Predicted label: 8
Correct prediction
Energy consumption = 146.916478 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 621 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 621 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 621 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.70908, 0.0015975, 0.039115, 0.0081272, 0.30569, 0.025076, 0.0013712, 0.040368, 0.57437, 0.79623]
Predicted label: 9
Correct prediction
Energy consumption = 165.057774 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.093106, 0.02032, 0.01987, 0.036648, 0.016289, 0.68633, 0.0033001, 0.069708, 0.018662]
Predicted label: 0
Correct prediction
Energy consumption = 152.058628 pJ
sum error= 297
Actual label: 8
Output voltages: [0.043134, 0.025049, 0.033071, 0.2681, 0.0056266, 0.029907, 0.015408, 0.0015962, 0.7987, 0.40605]
Predicted label: 8
Correct prediction
Energy consumption = 154.236933 pJ
sum error= 297
Actual label: 3
Output voltages: [0.12433, 0.015649, 0.04463, 0.79878, 0.023838, 0.30071, 0.067397, 0.056386, 0.64031, 0.043356]
Predicted label: 3
Correct prediction
Energy consumption = 144.429150 pJ
sum error= 297
Actual label: 9
Output voltages: [0.21738, 0.020189, 0.022226, 0.027152, 0.16491, 0.018708, 0.0012581, 0.013427, 0.38807, 0.7978]
Predicted label: 9
Correct prediction
Energy consumption = 151.763045 pJ
sum error= 297
Actual label: 5
Output voltages: [0.14102, 0.0011502, 0.0039481, 0.39822, 0.02178, 0.79767, 0.72191, 0.0062634, 0.76191, 0.0089078]
Predicted label: 5
Correct prediction
Energy consumption = 149.399477 pJ
sum error= 297
Actual label: 5
Output voltages: [0.056068, 0.001473, 0.0063506, 0.46363, 0.0080754, 0.79879, 0.21283, 0.045863, 0.75932, 0.067514]
Predicted label: 5
Correct prediction
Energy consumption = 133.610894 pJ
sum error= 297
Actual label: 2
Output voltages: [0.51113, 0.0098869, 0.79877, 0.19119, 0.015079, 0.0010752, 0.043532, 0.24857, 0.62539, 0.0064949]
Predicted label: 2
Correct prediction
Energy consumption = 144.502203 pJ
sum error= 297
Actual label: 6
Output voltages: [0.18579, 0.066647, 0.43759, 0.0010662, 0.3815, 0.020841, 0.79879, 0.0010698, 0.10379, 0.0040639]
Predicted label: 6
Correct prediction
Energy consumption = 145.337451 pJ
sum error= 297
Actual label: 8
Output voltages: [0.02205, 0.15584, 0.037749, 0.73878, 0.0033977, 0.027692, 0.090898, 0.011183, 0.79878, 0.10877]
Predicted label: 8
Correct prediction
Energy consumption = 151.098608 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 622 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 622 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 622 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.013672, 0.0030539, 0.13065, 0.0012802, 0.79872, 0.0011363, 0.42932, 0.074208, 0.033366, 0.0082912]
Predicted label: 4
Correct prediction
Energy consumption = 174.845866 pJ
sum error= 297
Actual label: 9
Output voltages: [0.19962, 0.028025, 0.012488, 0.051917, 0.3055, 0.017307, 0.0033489, 0.01155, 0.25298, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 146.310445 pJ
sum error= 297
Actual label: 1
Output voltages: [0.024274, 0.79861, 0.31342, 0.057431, 0.40313, 0.0010915, 0.43137, 0.0015845, 0.044748, 0.038577]
Predicted label: 1
Correct prediction
Energy consumption = 170.852133 pJ
sum error= 297
Actual label: 7
Output voltages: [0.051503, 0.05921, 0.046305, 0.19555, 0.0055405, 0.034698, 0.0010892, 0.79854, 0.057293, 0.37023]
Predicted label: 7
Correct prediction
Energy consumption = 149.559544 pJ
sum error= 297
Actual label: 1
Output voltages: [0.017263, 0.79863, 0.024138, 0.16522, 0.44884, 0.001152, 0.43403, 0.035479, 0.036958, 0.055381]
Predicted label: 1
Correct prediction
Energy consumption = 162.883509 pJ
sum error= 297
Actual label: 2
Output voltages: [0.45327, 0.010893, 0.79879, 0.33415, 0.0070312, 0.0010663, 0.020444, 0.038034, 0.69682, 0.0017931]
Predicted label: 2
Correct prediction
Energy consumption = 146.854026 pJ
sum error= 297
Actual label: 3
Output voltages: [0.48292, 0.0015654, 0.075865, 0.79878, 0.082634, 0.031706, 0.0052037, 0.0028002, 0.5368, 0.010207]
Predicted label: 3
Correct prediction
Energy consumption = 144.359074 pJ
sum error= 297
Actual label: 5
Output voltages: [0.017799, 0.0010671, 0.0012503, 0.73671, 0.049025, 0.79872, 0.0039819, 0.049572, 0.76832, 0.0055501]
Predicted label: 5
Correct prediction
Energy consumption = 137.916362 pJ
sum error= 297
Actual label: 9
Output voltages: [0.2769, 0.002041, 0.021758, 0.018355, 0.036933, 0.027284, 0.0021499, 0.034772, 0.78055, 0.79039]
Predicted label: 9
Correct prediction
Energy consumption = 145.496672 pJ
sum error= 297
Actual label: 6
Output voltages: [0.035928, 0.026223, 0.34101, 0.0012617, 0.34335, 0.028646, 0.79878, 0.0011831, 0.45133, 0.0031199]
Predicted label: 6
Correct prediction
Energy consumption = 144.940639 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 623 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 623 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 623 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.24985, 0.017663, 0.02445, 0.056347, 0.044837, 0.061196, 0.006403, 0.11575, 0.53737, 0.79758]
Predicted label: 9
Correct prediction
Energy consumption = 170.111205 pJ
sum error= 297
Actual label: 1
Output voltages: [0.050735, 0.7987, 0.055773, 0.02004, 0.054637, 0.0011022, 0.56292, 0.0010831, 0.13854, 0.020475]
Predicted label: 1
Correct prediction
Energy consumption = 167.476060 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0077211, 0.79876, 0.022547, 0.27311, 0.043559, 0.0020122, 0.22914, 0.0027141, 0.5531, 0.41995]
Predicted label: 1
Correct prediction
Energy consumption = 156.286626 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0055096, 0.79852, 0.13958, 0.041157, 0.0088189, 0.0020653, 0.74692, 0.025121, 0.19397, 0.014473]
Predicted label: 1
Correct prediction
Energy consumption = 149.782084 pJ
sum error= 297
Actual label: 2
Output voltages: [0.15611, 0.041571, 0.79869, 0.62815, 0.018077, 0.0010904, 0.023332, 0.042333, 0.41014, 0.0047904]
Predicted label: 2
Correct prediction
Energy consumption = 152.249270 pJ
sum error= 297
Actual label: 9
Output voltages: [0.22025, 0.014859, 0.015653, 0.043394, 0.026814, 0.021474, 0.015216, 0.21555, 0.61453, 0.79544]
Predicted label: 9
Correct prediction
Energy consumption = 152.197110 pJ
sum error= 297
Actual label: 5
Output voltages: [0.013161, 0.0011291, 0.0099148, 0.099229, 0.015684, 0.79843, 0.051126, 0.027133, 0.791, 0.01779]
Predicted label: 5
Correct prediction
Energy consumption = 142.725673 pJ
sum error= 297
Actual label: 6
Output voltages: [0.082219, 0.04892, 0.48482, 0.0017397, 0.25401, 0.057939, 0.79877, 0.0027516, 0.080836, 0.011599]
Predicted label: 6
Correct prediction
Energy consumption = 146.496475 pJ
sum error= 297
Actual label: 8
Output voltages: [0.53639, 0.056163, 0.44088, 0.021747, 0.0064498, 0.30268, 0.02171, 0.010045, 0.79877, 0.0055397]
Predicted label: 8
Correct prediction
Energy consumption = 152.883125 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0034688, 0.79874, 0.026039, 0.0083133, 0.013481, 0.0030401, 0.27338, 0.029279, 0.32879, 0.043942]
Predicted label: 1
Correct prediction
Energy consumption = 149.267519 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 624 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 624 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 624 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.6376, 0.038766, 0.79874, 0.05828, 0.014106, 0.0010885, 0.054118, 0.1854, 0.47148, 0.014211]
Predicted label: 2
Correct prediction
Energy consumption = 163.141577 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79877, 0.033996, 0.027252, 0.02558, 0.25632, 0.0099367, 0.66196, 0.016536, 0.046925, 0.036025]
Predicted label: 0
Correct prediction
Energy consumption = 153.124328 pJ
sum error= 297
Actual label: 7
Output voltages: [0.13863, 0.084968, 0.01168, 0.024085, 0.0052559, 0.018282, 0.0010834, 0.79869, 0.060434, 0.40448]
Predicted label: 7
Correct prediction
Energy consumption = 155.635763 pJ
sum error= 297
Actual label: 7
Output voltages: [0.11742, 0.0062335, 0.0016379, 0.0014437, 0.3719, 0.25384, 0.0031137, 0.79855, 0.13608, 0.046781]
Predicted label: 7
Correct prediction
Energy consumption = 143.532995 pJ
sum error= 297
Actual label: 5
Output voltages: [0.031778, 0.0013601, 0.0011233, 0.42335, 0.080147, 0.79875, 0.1561, 0.020437, 0.72676, 0.0061708]
Predicted label: 5
Correct prediction
Energy consumption = 145.698222 pJ
sum error= 297
Actual label: 8
Output voltages: [0.014954, 0.021541, 0.33056, 0.25445, 0.0085994, 0.29773, 0.024314, 0.14304, 0.79861, 0.014915]
Predicted label: 8
Correct prediction
Energy consumption = 151.639763 pJ
sum error= 297
Actual label: 2
Output voltages: [0.29104, 0.03591, 0.79866, 0.034778, 0.01383, 0.0010913, 0.105, 0.036736, 0.54992, 0.016107]
Predicted label: 2
Correct prediction
Energy consumption = 141.807096 pJ
sum error= 297
Actual label: 9
Output voltages: [0.50255, 0.015038, 0.028908, 0.028693, 0.22637, 0.031164, 0.0016633, 0.040706, 0.39895, 0.79802]
Predicted label: 9
Correct prediction
Energy consumption = 150.002997 pJ
sum error= 297
Actual label: 8
Output voltages: [0.019197, 0.15056, 0.27466, 0.096141, 0.011361, 0.015782, 0.016598, 0.031043, 0.79862, 0.12521]
Predicted label: 8
Correct prediction
Energy consumption = 148.226108 pJ
sum error= 297
Actual label: 9
Output voltages: [0.18798, 0.033529, 0.025379, 0.04889, 0.088478, 0.038631, 0.018597, 0.021046, 0.34153, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.909191 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 625 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 625 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 625 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.039497, 0.02127, 0.015156, 0.030048, 0.010079, 0.75508, 0.022114, 0.21691, 0.10998]
Predicted label: 0
Correct prediction
Energy consumption = 168.546915 pJ
sum error= 297
Actual label: 4
Output voltages: [0.002498, 0.025672, 0.2826, 0.018912, 0.79865, 0.0015549, 0.18275, 0.05186, 0.023432, 0.20563]
Predicted label: 4
Correct prediction
Energy consumption = 157.698876 pJ
sum error= 297
Actual label: 6
Output voltages: [0.038989, 0.0050179, 0.095096, 0.0017693, 0.42026, 0.018428, 0.79879, 0.001483, 0.48648, 0.0092396]
Predicted label: 6
Correct prediction
Energy consumption = 144.118212 pJ
sum error= 297
Actual label: 7
Output voltages: [0.044446, 0.060547, 0.016278, 0.030122, 0.0097092, 0.0032356, 0.0010664, 0.79872, 0.041618, 0.55174]
Predicted label: 7
Correct prediction
Energy consumption = 154.565333 pJ
sum error= 297
Actual label: 1
Output voltages: [0.02271, 0.79848, 0.017976, 0.034177, 0.032082, 0.0016609, 0.49775, 0.011343, 0.057625, 0.040358]
Predicted label: 1
Correct prediction
Energy consumption = 157.942286 pJ
sum error= 297
Actual label: 3
Output voltages: [0.4177, 0.038294, 0.022609, 0.79858, 0.0083861, 0.027421, 0.0088885, 0.007793, 0.66013, 0.14013]
Predicted label: 3
Correct prediction
Energy consumption = 153.237569 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0050656, 0.0074465, 0.17697, 0.0068278, 0.79868, 0.0034847, 0.11258, 0.034733, 0.17533, 0.021723]
Predicted label: 4
Correct prediction
Energy consumption = 156.213674 pJ
sum error= 297
Actual label: 5
Output voltages: [0.068912, 0.0011121, 0.0019636, 0.097765, 0.060316, 0.79879, 0.23487, 0.039407, 0.78767, 0.022888]
Predicted label: 5
Correct prediction
Energy consumption = 146.576644 pJ
sum error= 297
Actual label: 6
Output voltages: [0.12621, 0.006294, 0.0089817, 0.15672, 0.47825, 0.55795, 0.79868, 0.0011036, 0.70938, 0.085552]
Predicted label: 6
Correct prediction
Energy consumption = 144.020658 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79878, 0.081798, 0.032808, 0.010685, 0.055324, 0.029535, 0.50626, 0.0098915, 0.033733, 0.23853]
Predicted label: 0
Correct prediction
Energy consumption = 150.415709 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 626 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 626 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 626 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.5623, 0.047277, 0.1558, 0.79862, 0.0099971, 0.0085072, 0.0023484, 0.0038267, 0.63967, 0.049974]
Predicted label: 3
Correct prediction
Energy consumption = 167.136286 pJ
sum error= 297
Actual label: 6
Output voltages: [0.043868, 0.039617, 0.41529, 0.0011255, 0.13584, 0.045732, 0.79879, 0.0017824, 0.52975, 0.0017627]
Predicted label: 6
Correct prediction
Energy consumption = 154.873793 pJ
sum error= 297
Actual label: 8
Output voltages: [0.035455, 0.014364, 0.21987, 0.66724, 0.005664, 0.0066676, 0.0024613, 0.0030424, 0.79811, 0.12261]
Predicted label: 8
Correct prediction
Energy consumption = 150.328591 pJ
sum error= 297
Actual label: 7
Output voltages: [0.21201, 0.0095566, 0.02146, 0.063722, 0.012656, 0.0086432, 0.0011051, 0.79861, 0.048357, 0.19237]
Predicted label: 7
Correct prediction
Energy consumption = 146.399004 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79834, 0.031137, 0.042317, 0.015117, 0.019577, 0.002927, 0.68973, 0.010795, 0.061964, 0.039825]
Predicted label: 0
Correct prediction
Energy consumption = 151.590722 pJ
sum error= 297
Actual label: 4
Output voltages: [0.039579, 0.0055469, 0.16367, 0.0042371, 0.7987, 0.0039174, 0.029089, 0.023185, 0.22589, 0.012751]
Predicted label: 4
Correct prediction
Energy consumption = 150.721136 pJ
sum error= 297
Actual label: 2
Output voltages: [0.019681, 0.032569, 0.79854, 0.19169, 0.016338, 0.001068, 0.10616, 0.036254, 0.563, 0.011198]
Predicted label: 2
Correct prediction
Energy consumption = 157.022620 pJ
sum error= 297
Actual label: 7
Output voltages: [0.087171, 0.03021, 0.049491, 0.0599, 0.0068295, 0.0069317, 0.0011652, 0.79877, 0.050537, 0.73546]
Predicted label: 7
Correct prediction
Energy consumption = 152.931130 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0040764, 0.01101, 0.040109, 0.0076059, 0.79871, 0.0011994, 0.25529, 0.14117, 0.041218, 0.023965]
Predicted label: 4
Correct prediction
Energy consumption = 154.491857 pJ
sum error= 297
Actual label: 7
Output voltages: [0.3544, 0.029022, 0.013171, 0.017688, 0.022365, 0.027616, 0.0010719, 0.79861, 0.41463, 0.17207]
Predicted label: 7
Correct prediction
Energy consumption = 149.526074 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 627 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 627 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 627 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.036821, 0.0010763, 0.0024693, 0.060899, 0.018673, 0.79878, 0.22593, 0.10285, 0.769, 0.028069]
Predicted label: 5
Correct prediction
Energy consumption = 163.889996 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0014476, 0.014021, 0.11872, 0.010377, 0.79876, 0.0010854, 0.10663, 0.014061, 0.046248, 0.036525]
Predicted label: 4
Correct prediction
Energy consumption = 155.137701 pJ
sum error= 297
Actual label: 3
Output voltages: [0.13091, 0.010365, 0.2521, 0.79879, 0.012594, 0.0024005, 0.02302, 0.011433, 0.71992, 0.11804]
Predicted label: 3
Correct prediction
Energy consumption = 145.869970 pJ
sum error= 297
Actual label: 4
Output voltages: [0.22665, 0.017807, 0.064018, 0.0025418, 0.79877, 0.0016656, 0.017818, 0.016008, 0.016737, 0.50716]
Predicted label: 4
Correct prediction
Energy consumption = 152.705403 pJ
sum error= 297
Actual label: 2
Output voltages: [0.64851, 0.016365, 0.79879, 0.083907, 0.016765, 0.0011377, 0.028634, 0.049447, 0.3441, 0.010752]
Predicted label: 2
Correct prediction
Energy consumption = 151.687659 pJ
sum error= 297
Actual label: 8
Output voltages: [0.024128, 0.15289, 0.26678, 0.18614, 0.010614, 0.0098698, 0.022049, 0.0045366, 0.79874, 0.30147]
Predicted label: 8
Correct prediction
Energy consumption = 150.914598 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0047857, 0.79857, 0.021069, 0.026872, 0.036231, 0.003178, 0.71938, 0.018049, 0.37565, 0.016282]
Predicted label: 1
Correct prediction
Energy consumption = 151.498955 pJ
sum error= 297
Actual label: 5
Output voltages: [0.026581, 0.0011434, 0.0010662, 0.36831, 0.1584, 0.79878, 0.62855, 0.025451, 0.56691, 0.041278]
Predicted label: 5
Correct prediction
Energy consumption = 149.960533 pJ
sum error= 297
Actual label: 1
Output voltages: [0.022755, 0.79865, 0.33314, 0.021765, 0.36135, 0.0012072, 0.52498, 0.028648, 0.080959, 0.030841]
Predicted label: 1
Correct prediction
Energy consumption = 163.240399 pJ
sum error= 297
Actual label: 2
Output voltages: [0.047853, 0.019194, 0.79863, 0.037144, 0.03476, 0.0011119, 0.030681, 0.076083, 0.48199, 0.042078]
Predicted label: 2
Correct prediction
Energy consumption = 132.556371 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 628 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 628 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 628 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.073292, 0.017359, 0.021249, 0.026031, 0.018548, 0.72254, 0.017817, 0.15906, 0.033304]
Predicted label: 0
Correct prediction
Energy consumption = 172.581608 pJ
sum error= 297
Actual label: 2
Output voltages: [0.21099, 0.021756, 0.79874, 0.3504, 0.12857, 0.0011122, 0.031674, 0.03638, 0.36938, 0.055781]
Predicted label: 2
Correct prediction
Energy consumption = 143.880800 pJ
sum error= 297
Actual label: 5
Output voltages: [0.026517, 0.0010885, 0.0019897, 0.27337, 0.018963, 0.79591, 0.038608, 0.0090763, 0.76315, 0.12951]
Predicted label: 5
Correct prediction
Energy consumption = 149.289768 pJ
sum error= 297
Actual label: 6
Output voltages: [0.049853, 0.013444, 0.20335, 0.0041145, 0.3339, 0.23715, 0.79879, 0.0017873, 0.61389, 0.0017327]
Predicted label: 6
Correct prediction
Energy consumption = 146.642319 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0096721, 0.0083763, 0.048046, 0.0043933, 0.79868, 0.0049674, 0.13033, 0.10679, 0.058202, 0.020282]
Predicted label: 4
Correct prediction
Energy consumption = 149.748782 pJ
sum error= 297
Actual label: 3
Output voltages: [0.57047, 0.0016506, 0.25747, 0.79878, 0.030552, 0.1313, 0.017301, 0.016059, 0.78488, 0.0067939]
Predicted label: 3
Correct prediction
Energy consumption = 146.279896 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.15498, 0.031056, 0.016738, 0.0050582, 0.0036001, 0.46198, 0.014447, 0.051343, 0.32958]
Predicted label: 0
Correct prediction
Energy consumption = 142.372314 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.089652, 0.1032, 0.0092496, 0.007729, 0.0035779, 0.21472, 0.027786, 0.2453, 0.21432]
Predicted label: 0
Correct prediction
Energy consumption = 134.770947 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.25121, 0.045604, 0.021875, 0.0078975, 0.0079849, 0.51422, 0.0035439, 0.077358, 0.066776]
Predicted label: 0
Correct prediction
Energy consumption = 145.594107 pJ
sum error= 297
Actual label: 3
Output voltages: [0.050912, 0.0029128, 0.19119, 0.79879, 0.039989, 0.084419, 0.004329, 0.14483, 0.73541, 0.10368]
Predicted label: 3
Correct prediction
Energy consumption = 145.943500 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 629 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 629 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 629 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.76232, 0.0079663, 0.38758, 0.79868, 0.040778, 0.017754, 0.0192, 0.025073, 0.76689, 0.0082942]
Predicted label: 3
Correct prediction
Energy consumption = 166.911005 pJ
sum error= 297
Actual label: 5
Output voltages: [0.036483, 0.0013199, 0.0010802, 0.2879, 0.11662, 0.79878, 0.47241, 0.019703, 0.48139, 0.053417]
Predicted label: 5
Correct prediction
Energy consumption = 145.955145 pJ
sum error= 297
Actual label: 7
Output voltages: [0.050338, 0.061182, 0.041052, 0.034243, 0.0062499, 0.0048048, 0.0010725, 0.79857, 0.046098, 0.19191]
Predicted label: 7
Correct prediction
Energy consumption = 153.050637 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79875, 0.054313, 0.025797, 0.037292, 0.016306, 0.011116, 0.51661, 0.041059, 0.26197, 0.0577]
Predicted label: 0
Correct prediction
Energy consumption = 148.988052 pJ
sum error= 297
Actual label: 6
Output voltages: [0.044103, 0.051926, 0.28314, 0.0010785, 0.42681, 0.056192, 0.79878, 0.0020472, 0.48797, 0.0056709]
Predicted label: 6
Correct prediction
Energy consumption = 143.488338 pJ
sum error= 297
Actual label: 4
Output voltages: [0.001782, 0.005099, 0.086809, 0.01093, 0.7987, 0.0012732, 0.24068, 0.04587, 0.068325, 0.022587]
Predicted label: 4
Correct prediction
Energy consumption = 148.952413 pJ
sum error= 297
Actual label: 8
Output voltages: [0.022103, 0.040729, 0.42933, 0.26225, 0.002248, 0.11801, 0.029721, 0.035218, 0.79861, 0.042231]
Predicted label: 8
Correct prediction
Energy consumption = 152.735139 pJ
sum error= 297
Actual label: 8
Output voltages: [0.022065, 0.0025192, 0.002842, 0.22047, 0.020031, 0.14031, 0.019114, 0.0056465, 0.79879, 0.14107]
Predicted label: 8
Correct prediction
Energy consumption = 141.586585 pJ
sum error= 297
Actual label: 6
Output voltages: [0.33517, 0.36556, 0.0077015, 0.068379, 0.04841, 0.52167, 0.79875, 0.0013285, 0.32611, 0.0013881]
Predicted label: 6
Correct prediction
Energy consumption = 150.770637 pJ
sum error= 297
Actual label: 3
Output voltages: [0.49806, 0.015053, 0.082326, 0.79877, 0.0066606, 0.0058387, 0.0086599, 0.014, 0.26555, 0.018417]
Predicted label: 3
Correct prediction
Energy consumption = 148.447243 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 630 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 630 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 630 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0048047, 0.0031114, 0.23413, 0.0020292, 0.79873, 0.0034736, 0.19719, 0.067385, 0.13064, 0.0079189]
Predicted label: 4
Correct prediction
Energy consumption = 166.358398 pJ
sum error= 297
Actual label: 6
Output voltages: [0.092735, 0.23713, 0.26436, 0.0081726, 0.32238, 0.043639, 0.7987, 0.0011203, 0.31044, 0.02455]
Predicted label: 6
Correct prediction
Energy consumption = 145.953383 pJ
sum error= 297
Actual label: 9
Output voltages: [0.19256, 0.020582, 0.039521, 0.018926, 0.039605, 0.011388, 0.0066361, 0.022036, 0.7543, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 148.674860 pJ
sum error= 297
Actual label: 9
Output voltages: [0.19848, 0.0010691, 0.019639, 0.025501, 0.022181, 0.059826, 0.0012221, 0.41183, 0.70658, 0.7712]
Predicted label: 9
Correct prediction
Energy consumption = 138.391830 pJ
sum error= 297
Actual label: 8
Output voltages: [0.018683, 0.16617, 0.054676, 0.1922, 0.0014323, 0.035762, 0.033479, 0.081643, 0.79865, 0.016341]
Predicted label: 8
Correct prediction
Energy consumption = 154.978439 pJ
sum error= 297
Actual label: 2
Output voltages: [0.36507, 0.0014038, 0.79753, 0.56536, 0.011178, 0.0016983, 0.019283, 0.0094006, 0.74545, 0.026357]
Predicted label: 2
Correct prediction
Energy consumption = 141.678736 pJ
sum error= 297
Actual label: 7
Output voltages: [0.039658, 0.01956, 0.50948, 0.027136, 0.0023396, 0.0011241, 0.0011324, 0.79878, 0.74951, 0.045226]
Predicted label: 7
Correct prediction
Energy consumption = 139.093971 pJ
sum error= 297
Actual label: 7
Output voltages: [0.093283, 0.11617, 0.26311, 0.10429, 0.0020044, 0.0015148, 0.0010764, 0.79865, 0.47388, 0.26325]
Predicted label: 7
Correct prediction
Energy consumption = 135.466308 pJ
sum error= 297
Actual label: 1
Output voltages: [0.019733, 0.79843, 0.0094421, 0.047213, 0.036786, 0.0064828, 0.67204, 0.023907, 0.048841, 0.12085]
Predicted label: 1
Correct prediction
Energy consumption = 159.015221 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79877, 0.022149, 0.03895, 0.011709, 0.022697, 0.0073057, 0.73304, 0.011979, 0.21942, 0.046333]
Predicted label: 0
Correct prediction
Energy consumption = 157.452115 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 631 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 631 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 631 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.03746, 0.79873, 0.63555, 0.055793, 0.052113, 0.0011073, 0.47625, 0.0032782, 0.070161, 0.031691]
Predicted label: 1
Correct prediction
Energy consumption = 182.481131 pJ
sum error= 297
Actual label: 2
Output voltages: [0.38551, 0.0169, 0.7987, 0.049137, 0.022638, 0.0011619, 0.25381, 0.032527, 0.29239, 0.014418]
Predicted label: 2
Correct prediction
Energy consumption = 141.600937 pJ
sum error= 297
Actual label: 3
Output voltages: [0.0092743, 0.013733, 0.027191, 0.79879, 0.028796, 0.0085947, 0.0010951, 0.050989, 0.71262, 0.18029]
Predicted label: 3
Correct prediction
Energy consumption = 139.012374 pJ
sum error= 297
Actual label: 4
Output voltages: [0.032056, 0.018196, 0.038758, 0.0021922, 0.79868, 0.0038876, 0.12581, 0.050827, 0.050898, 0.009828]
Predicted label: 4
Correct prediction
Energy consumption = 151.700324 pJ
sum error= 297
Actual label: 5
Output voltages: [0.22277, 0.0039764, 0.0093312, 0.47464, 0.011498, 0.79862, 0.47618, 0.026176, 0.67435, 0.14933]
Predicted label: 5
Correct prediction
Energy consumption = 154.006148 pJ
sum error= 297
Actual label: 6
Output voltages: [0.073025, 0.18654, 0.17048, 0.021578, 0.16256, 0.31305, 0.79867, 0.0046977, 0.39097, 0.023652]
Predicted label: 6
Correct prediction
Energy consumption = 150.396777 pJ
sum error= 297
Actual label: 7
Output voltages: [0.16511, 0.029485, 0.10445, 0.35444, 0.0013715, 0.001097, 0.0010678, 0.7987, 0.11714, 0.11028]
Predicted label: 7
Correct prediction
Energy consumption = 160.072849 pJ
sum error= 297
Actual label: 8
Output voltages: [0.037407, 0.016736, 0.72954, 0.16051, 0.0025646, 0.016709, 0.02191, 0.012144, 0.79874, 0.048977]
Predicted label: 8
Correct prediction
Energy consumption = 143.136396 pJ
sum error= 297
Actual label: 9
Output voltages: [0.29178, 0.029388, 0.022631, 0.15151, 0.19574, 0.015521, 0.014109, 0.018137, 0.24823, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.953521 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79878, 0.019836, 0.021544, 0.010567, 0.026054, 0.017812, 0.55798, 0.0043698, 0.10794, 0.034777]
Predicted label: 0
Correct prediction
Energy consumption = 149.752955 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 632 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 632 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 632 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.041518, 0.79858, 0.3254, 0.013255, 0.33184, 0.0012487, 0.47924, 0.0023606, 0.064461, 0.10258]
Predicted label: 1
Correct prediction
Energy consumption = 181.740106 pJ
sum error= 297
Actual label: 2
Output voltages: [0.70594, 0.0042956, 0.7987, 0.19366, 0.021604, 0.0010738, 0.0496, 0.035186, 0.43669, 0.010926]
Predicted label: 2
Correct prediction
Energy consumption = 147.925536 pJ
sum error= 297
Actual label: 3
Output voltages: [0.54365, 0.032209, 0.056139, 0.79872, 0.0039171, 0.0072455, 0.013514, 0.018851, 0.54483, 0.012045]
Predicted label: 3
Correct prediction
Energy consumption = 142.770595 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0058748, 0.0040391, 0.24917, 0.0089097, 0.79874, 0.0023736, 0.15501, 0.041869, 0.12537, 0.02]
Predicted label: 4
Correct prediction
Energy consumption = 153.576442 pJ
sum error= 297
Actual label: 5
Output voltages: [0.025392, 0.0071667, 0.0018432, 0.1087, 0.035455, 0.79866, 0.29558, 0.040806, 0.66081, 0.033771]
Predicted label: 5
Correct prediction
Energy consumption = 152.317646 pJ
sum error= 297
Actual label: 6
Output voltages: [0.1312, 0.10951, 0.35868, 0.0012024, 0.2435, 0.15282, 0.79871, 0.0018417, 0.46066, 0.0049814]
Predicted label: 6
Correct prediction
Energy consumption = 148.430426 pJ
sum error= 297
Actual label: 7
Output voltages: [0.45636, 0.018747, 0.01386, 0.017626, 0.011125, 0.030348, 0.0017128, 0.79847, 0.35455, 0.046478]
Predicted label: 7
Correct prediction
Energy consumption = 158.480011 pJ
sum error= 297
Actual label: 8
Output voltages: [0.12054, 0.024825, 0.449, 0.08101, 0.022125, 0.0041667, 0.14997, 0.0032283, 0.79878, 0.1036]
Predicted label: 8
Correct prediction
Energy consumption = 151.240869 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79853, 0.028389, 0.022587, 0.0059128, 0.11158, 0.011735, 0.76208, 0.011525, 0.035262, 0.019469]
Predicted label: 0
Correct prediction
Energy consumption = 156.287850 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0084253, 0.79858, 0.23235, 0.037649, 0.21306, 0.0010931, 0.38837, 0.0157, 0.16274, 0.061862]
Predicted label: 1
Correct prediction
Energy consumption = 160.610329 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 633 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 633 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 633 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.63233, 0.020736, 0.79874, 0.21594, 0.025024, 0.0011497, 0.074018, 0.071317, 0.38793, 0.02619]
Predicted label: 2
Correct prediction
Energy consumption = 160.013923 pJ
sum error= 297
Actual label: 3
Output voltages: [0.75556, 0.0037904, 0.16049, 0.79876, 0.010557, 0.021186, 0.0041073, 0.032541, 0.21131, 0.0028686]
Predicted label: 3
Correct prediction
Energy consumption = 143.918081 pJ
sum error= 297
Actual label: 4
Output voltages: [0.009128, 0.0029954, 0.16802, 0.0021478, 0.79867, 0.0011709, 0.086528, 0.01968, 0.066131, 0.036522]
Predicted label: 4
Correct prediction
Energy consumption = 153.426513 pJ
sum error= 297
Actual label: 5
Output voltages: [0.10617, 0.0014542, 0.0013913, 0.26025, 0.04727, 0.79867, 0.034585, 0.027229, 0.66888, 0.10411]
Predicted label: 5
Correct prediction
Energy consumption = 149.516837 pJ
sum error= 297
Actual label: 6
Output voltages: [0.17385, 0.025598, 0.28113, 0.0011181, 0.32853, 0.090411, 0.79879, 0.0015117, 0.55269, 0.0052412]
Predicted label: 6
Correct prediction
Energy consumption = 144.309331 pJ
sum error= 297
Actual label: 7
Output voltages: [0.20559, 0.047347, 0.038085, 0.15434, 0.03197, 0.0027199, 0.001095, 0.79858, 0.19335, 0.28552]
Predicted label: 7
Correct prediction
Energy consumption = 157.623963 pJ
sum error= 297
Actual label: 8
Output voltages: [0.038821, 0.041538, 0.5514, 0.030452, 0.031138, 0.0043011, 0.023412, 0.012662, 0.79879, 0.17923]
Predicted label: 8
Correct prediction
Energy consumption = 148.756272 pJ
sum error= 297
Actual label: 2
Output voltages: [0.51798, 0.017869, 0.79877, 0.078325, 0.021507, 0.0013717, 0.035574, 0.049286, 0.50728, 0.006327]
Predicted label: 2
Correct prediction
Energy consumption = 141.312599 pJ
sum error= 297
Actual label: 1
Output voltages: [0.045993, 0.79879, 0.0046015, 0.27368, 0.23929, 0.0074883, 0.010283, 0.0016285, 0.78002, 0.21006]
Predicted label: 1
Correct prediction
Energy consumption = 170.352969 pJ
sum error= 297
Actual label: 7
Output voltages: [0.060666, 0.017701, 0.0096584, 0.19006, 0.032845, 0.014767, 0.0010661, 0.79877, 0.16252, 0.57016]
Predicted label: 7
Correct prediction
Energy consumption = 153.949152 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 634 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 634 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 634 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.49857, 0.0061272, 0.79879, 0.070041, 0.061353, 0.0020742, 0.094942, 0.063411, 0.29025, 0.0045371]
Predicted label: 2
Correct prediction
Energy consumption = 167.728184 pJ
sum error= 297
Actual label: 5
Output voltages: [0.036772, 0.0010959, 0.0074933, 0.30019, 0.055602, 0.79873, 0.12417, 0.24422, 0.77018, 0.043712]
Predicted label: 5
Correct prediction
Energy consumption = 143.645391 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.18521, 0.04701, 0.032624, 0.018287, 0.0028595, 0.58404, 0.0035073, 0.19662, 0.029796]
Predicted label: 0
Correct prediction
Energy consumption = 156.258824 pJ
sum error= 297
Actual label: 8
Output voltages: [0.051345, 0.039516, 0.3938, 0.035995, 0.047282, 0.0085072, 0.039609, 0.0052138, 0.79874, 0.20823]
Predicted label: 8
Correct prediction
Energy consumption = 150.504597 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79833, 0.034767, 0.029567, 0.013732, 0.0094643, 0.0034005, 0.74941, 0.04233, 0.20548, 0.15635]
Predicted label: 0
Correct prediction
Energy consumption = 148.761689 pJ
sum error= 297
Actual label: 2
Output voltages: [0.42216, 0.03083, 0.79866, 0.021098, 0.017237, 0.0011611, 0.16319, 0.01148, 0.29108, 0.017086]
Predicted label: 2
Correct prediction
Energy consumption = 139.506669 pJ
sum error= 297
Actual label: 7
Output voltages: [0.1295, 0.011293, 0.018988, 0.33846, 0.012622, 0.0079964, 0.0010814, 0.79869, 0.25996, 0.56831]
Predicted label: 7
Correct prediction
Energy consumption = 153.606175 pJ
sum error= 297
Actual label: 8
Output voltages: [0.36896, 0.015509, 0.048385, 0.73426, 0.0011048, 0.0013007, 0.49752, 0.0010747, 0.72961, 0.047132]
Predicted label: 3
Wrong prediction!
Energy consumption = 159.858039 pJ
sum error= 298
Actual label: 8
Output voltages: [0.054746, 0.015013, 0.60216, 0.016055, 0.020988, 0.011321, 0.035803, 0.0077987, 0.79877, 0.13453]
Predicted label: 8
Correct prediction
Energy consumption = 149.947438 pJ
sum error= 298
Actual label: 3
Output voltages: [0.41285, 0.014362, 0.16319, 0.79872, 0.022852, 0.0018062, 0.021187, 0.0035055, 0.46796, 0.041376]
Predicted label: 3
Correct prediction
Energy consumption = 142.746027 pJ
sum error= 298
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 635 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 635 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 635 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.046964, 0.08509, 0.28585, 0.0042842, 0.2176, 0.19139, 0.79871, 0.0021652, 0.622, 0.0045129]
Predicted label: 6
Correct prediction
Energy consumption = 163.504576 pJ
sum error= 298
Actual label: 0
Output voltages: [0.79879, 0.068645, 0.090896, 0.016976, 0.014645, 0.0023215, 0.63655, 0.015536, 0.19067, 0.17293]
Predicted label: 0
Correct prediction
Energy consumption = 147.137209 pJ
sum error= 298
Actual label: 2
Output voltages: [0.71563, 0.019277, 0.79879, 0.33268, 0.013311, 0.0025653, 0.092772, 0.019225, 0.33509, 0.041072]
Predicted label: 2
Correct prediction
Energy consumption = 142.451675 pJ
sum error= 298
Actual label: 7
Output voltages: [0.31292, 0.01413, 0.004534, 0.031925, 0.17889, 0.060716, 0.0011076, 0.7987, 0.018187, 0.39534]
Predicted label: 7
Correct prediction
Energy consumption = 160.674166 pJ
sum error= 298
Actual label: 6
Output voltages: [0.13508, 0.068937, 0.13352, 0.0066919, 0.34957, 0.19769, 0.79871, 0.004085, 0.48475, 0.010467]
Predicted label: 6
Correct prediction
Energy consumption = 153.607133 pJ
sum error= 298
Actual label: 6
Output voltages: [0.062732, 0.050155, 0.24509, 0.0028722, 0.27302, 0.26982, 0.79872, 0.0015353, 0.62116, 0.0048967]
Predicted label: 6
Correct prediction
Energy consumption = 133.878580 pJ
sum error= 298
Actual label: 1
Output voltages: [0.061783, 0.79879, 0.10753, 0.047197, 0.042334, 0.0010843, 0.15506, 0.0060004, 0.54585, 0.099059]
Predicted label: 1
Correct prediction
Energy consumption = 161.648013 pJ
sum error= 298
Actual label: 2
Output voltages: [0.54456, 0.0055711, 0.79875, 0.14562, 0.024949, 0.0012074, 0.051129, 0.053772, 0.53682, 0.0080983]
Predicted label: 2
Correct prediction
Energy consumption = 145.389859 pJ
sum error= 298
Actual label: 8
Output voltages: [0.027988, 0.057176, 0.036952, 0.51362, 0.0010822, 0.13603, 0.015102, 0.0052082, 0.79879, 0.23079]
Predicted label: 8
Correct prediction
Energy consumption = 152.556372 pJ
sum error= 298
Actual label: 8
Output voltages: [0.055481, 0.0096082, 0.66628, 0.1033, 0.006738, 0.0010657, 0.030935, 0.0014139, 0.79804, 0.35164]
Predicted label: 8
Correct prediction
Energy consumption = 143.158112 pJ
sum error= 298
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 636 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 636 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 636 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28406, 0.043663, 0.0074505, 0.57589, 0.0066799, 0.017291, 0.0011324, 0.79869, 0.025992, 0.43001]
Predicted label: 7
Correct prediction
Energy consumption = 171.405880 pJ
sum error= 298
Actual label: 7
Output voltages: [0.030573, 0.19645, 0.087518, 0.12932, 0.0040384, 0.0013674, 0.0010661, 0.79851, 0.20655, 0.037838]
Predicted label: 7
Correct prediction
Energy consumption = 148.043739 pJ
sum error= 298
Actual label: 4
Output voltages: [0.015381, 0.016168, 0.034489, 0.0071285, 0.79864, 0.0010715, 0.18655, 0.051105, 0.0235, 0.010124]
Predicted label: 4
Correct prediction
Energy consumption = 156.131015 pJ
sum error= 298
Actual label: 7
Output voltages: [0.37485, 0.0058428, 0.016329, 0.036139, 0.11922, 0.038537, 0.0012683, 0.79852, 0.089251, 0.29363]
Predicted label: 7
Correct prediction
Energy consumption = 152.774831 pJ
sum error= 298
Actual label: 7
Output voltages: [0.22975, 0.043644, 0.01231, 0.4395, 0.0047021, 0.0017229, 0.0010708, 0.79872, 0.064679, 0.58363]
Predicted label: 7
Correct prediction
Energy consumption = 139.370911 pJ
sum error= 298
Actual label: 3
Output voltages: [0.50072, 0.0071684, 0.22479, 0.79872, 0.0331, 0.016245, 0.0209, 0.013382, 0.57014, 0.042069]
Predicted label: 3
Correct prediction
Energy consumption = 137.291666 pJ
sum error= 298
Actual label: 7
Output voltages: [0.21435, 0.0065912, 0.0076196, 0.030235, 0.023906, 0.017589, 0.0010714, 0.79858, 0.52242, 0.19685]
Predicted label: 7
Correct prediction
Energy consumption = 147.999286 pJ
sum error= 298
Actual label: 4
Output voltages: [0.0026964, 0.0028537, 0.081393, 0.020799, 0.79869, 0.0011019, 0.21187, 0.10119, 0.033006, 0.021936]
Predicted label: 4
Correct prediction
Energy consumption = 151.630757 pJ
sum error= 298
Actual label: 5
Output voltages: [0.11719, 0.0014588, 0.0011971, 0.38946, 0.013454, 0.79875, 0.23714, 0.014361, 0.66208, 0.03858]
Predicted label: 5
Correct prediction
Energy consumption = 151.254156 pJ
sum error= 298
Actual label: 4
Output voltages: [0.0019198, 0.019142, 0.04683, 0.020574, 0.79879, 0.0010779, 0.05728, 0.10443, 0.023152, 0.020286]
Predicted label: 4
Correct prediction
Energy consumption = 156.456235 pJ
sum error= 298
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 637 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 637 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 637 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.43811, 0.022398, 0.28156, 0.79879, 0.0053568, 0.0011871, 0.019673, 0.0012675, 0.30488, 0.024498]
Predicted label: 3
Correct prediction
Energy consumption = 164.507422 pJ
sum error= 298
Actual label: 3
Output voltages: [0.13522, 0.013501, 0.036607, 0.79873, 0.014282, 0.0047808, 0.0040938, 0.016561, 0.73057, 0.054567]
Predicted label: 3
Correct prediction
Energy consumption = 131.810542 pJ
sum error= 298
Actual label: 8
Output voltages: [0.056705, 0.043456, 0.22502, 0.40401, 0.010561, 0.003907, 0.19933, 0.004795, 0.79873, 0.23797]
Predicted label: 8
Correct prediction
Energy consumption = 148.937484 pJ
sum error= 298
Actual label: 4
Output voltages: [0.0015424, 0.03138, 0.081861, 0.01429, 0.79852, 0.014086, 0.37795, 0.33386, 0.02287, 0.035296]
Predicted label: 4
Correct prediction
Energy consumption = 152.470195 pJ
sum error= 298
Actual label: 1
Output voltages: [0.028017, 0.79854, 0.0602, 0.50929, 0.23653, 0.0042275, 0.50438, 0.0018961, 0.22601, 0.16175]
Predicted label: 1
Correct prediction
Energy consumption = 164.234172 pJ
sum error= 298
Actual label: 1
Output voltages: [0.037779, 0.79835, 0.069039, 0.1595, 0.0135, 0.0081737, 0.74391, 0.0048316, 0.058859, 0.059937]
Predicted label: 1
Correct prediction
Energy consumption = 151.626626 pJ
sum error= 298
Actual label: 9
Output voltages: [0.39559, 0.023468, 0.0059054, 0.029633, 0.048275, 0.010609, 0.0012614, 0.007724, 0.38534, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 155.426364 pJ
sum error= 298
Actual label: 7
Output voltages: [0.092247, 0.028166, 0.031353, 0.032619, 0.034687, 0.0041088, 0.0010681, 0.79857, 0.043019, 0.28831]
Predicted label: 7
Correct prediction
Energy consumption = 152.140005 pJ
sum error= 298
Actual label: 4
Output voltages: [0.0021705, 0.020046, 0.040969, 0.0018323, 0.79846, 0.0086925, 0.046315, 0.31196, 0.21218, 0.053314]
Predicted label: 4
Correct prediction
Energy consumption = 155.585713 pJ
sum error= 298
Actual label: 3
Output voltages: [0.10136, 0.027345, 0.16325, 0.79879, 0.0038504, 0.0011106, 0.0081862, 0.0036886, 0.51033, 0.2139]
Predicted label: 3
Correct prediction
Energy consumption = 148.098883 pJ
sum error= 298
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 638 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 638 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 638 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.3575, 0.03405, 0.022936, 0.2236, 0.020741, 0.030175, 0.0010723, 0.79859, 0.20369, 0.47617]
Predicted label: 7
Correct prediction
Energy consumption = 172.578334 pJ
sum error= 298
Actual label: 3
Output voltages: [0.1886, 0.034172, 0.29045, 0.79878, 0.019265, 0.0015952, 0.020967, 0.0021202, 0.63287, 0.10094]
Predicted label: 3
Correct prediction
Energy consumption = 147.562828 pJ
sum error= 298
Actual label: 3
Output voltages: [0.30049, 0.028292, 0.023043, 0.79863, 0.012263, 0.0026017, 0.014963, 0.01352, 0.48982, 0.031958]
Predicted label: 3
Correct prediction
Energy consumption = 132.508275 pJ
sum error= 298
Actual label: 0
Output voltages: [0.79878, 0.0085654, 0.022696, 0.11679, 0.3913, 0.0035691, 0.5046, 0.028419, 0.42569, 0.027191]
Predicted label: 0
Correct prediction
Energy consumption = 157.076162 pJ
sum error= 298
Actual label: 2
Output voltages: [0.53017, 0.16243, 0.79869, 0.046998, 0.010462, 0.0011351, 0.12361, 0.022395, 0.30446, 0.023623]
Predicted label: 2
Correct prediction
Energy consumption = 144.170808 pJ
sum error= 298
Actual label: 5
Output voltages: [0.2631, 0.0010674, 0.002958, 0.39578, 0.0095918, 0.79878, 0.59792, 0.063062, 0.65331, 0.0093819]
Predicted label: 5
Correct prediction
Energy consumption = 146.017745 pJ
sum error= 298
Actual label: 5
Output voltages: [0.017571, 0.0011429, 0.0010741, 0.095394, 0.038961, 0.7779, 0.1874, 0.019949, 0.78522, 0.027427]
Predicted label: 8
Wrong prediction!
Energy consumption = 127.535704 pJ
sum error= 299
Actual label: 6
Output voltages: [0.079643, 0.087063, 0.34686, 0.0047698, 0.3857, 0.29028, 0.79872, 0.0019314, 0.51588, 0.016048]
Predicted label: 6
Correct prediction
Energy consumption = 142.763105 pJ
sum error= 299
Actual label: 6
Output voltages: [0.2293, 0.03784, 0.13633, 0.0010673, 0.32807, 0.23518, 0.79874, 0.00461, 0.45021, 0.0072808]
Predicted label: 6
Correct prediction
Energy consumption = 133.756914 pJ
sum error= 299
Actual label: 3
Output voltages: [0.20007, 0.0019767, 0.14246, 0.79879, 0.034963, 0.037526, 0.012197, 0.015027, 0.52643, 0.12011]
Predicted label: 3
Correct prediction
Energy consumption = 143.251140 pJ
sum error= 299
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 639 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 639 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 639 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.2406, 0.0011426, 0.0054459, 0.081524, 0.0074335, 0.79864, 0.24115, 0.021889, 0.77847, 0.015627]
Predicted label: 5
Correct prediction
Energy consumption = 159.781209 pJ
sum error= 299
Actual label: 2
Output voltages: [0.75185, 0.031373, 0.79865, 0.4721, 0.0066168, 0.0010851, 0.036007, 0.048089, 0.55354, 0.0081034]
Predicted label: 2
Correct prediction
Energy consumption = 145.428743 pJ
sum error= 299
Actual label: 5
Output voltages: [0.28332, 0.0010715, 0.013357, 0.19091, 0.092595, 0.79022, 0.50658, 0.002334, 0.78918, 0.0045459]
Predicted label: 5
Correct prediction
Energy consumption = 142.932826 pJ
sum error= 299
Actual label: 9
Output voltages: [0.52078, 0.017211, 0.0079213, 0.025293, 0.76776, 0.037174, 0.035616, 0.014982, 0.19067, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 152.254053 pJ
sum error= 299
Actual label: 9
Output voltages: [0.42814, 0.012546, 0.02254, 0.025526, 0.082881, 0.015526, 0.01171, 0.028223, 0.39001, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 147.453892 pJ
sum error= 299
Actual label: 8
Output voltages: [0.023373, 0.029716, 0.24277, 0.03603, 0.022911, 0.027705, 0.034729, 0.0085252, 0.79867, 0.061312]
Predicted label: 8
Correct prediction
Energy consumption = 150.634193 pJ
sum error= 299
Actual label: 4
Output voltages: [0.0025078, 0.011616, 0.049505, 0.022177, 0.79871, 0.001546, 0.033965, 0.10113, 0.085845, 0.013276]
Predicted label: 4
Correct prediction
Energy consumption = 145.404378 pJ
sum error= 299
Actual label: 1
Output voltages: [0.026476, 0.79879, 0.10338, 0.67957, 0.32746, 0.0010689, 0.02001, 0.029723, 0.092695, 0.196]
Predicted label: 1
Correct prediction
Energy consumption = 166.001976 pJ
sum error= 299
Actual label: 0
Output voltages: [0.79869, 0.10224, 0.034448, 0.025808, 0.022612, 0.024901, 0.069156, 0.014209, 0.34506, 0.045109]
Predicted label: 0
Correct prediction
Energy consumption = 161.271879 pJ
sum error= 299
Actual label: 6
Output voltages: [0.19895, 0.10125, 0.27365, 0.0071186, 0.37807, 0.22357, 0.79872, 0.0022515, 0.3142, 0.024022]
Predicted label: 6
Correct prediction
Energy consumption = 144.041330 pJ
sum error= 299
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 640 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 640 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 640 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7832, 0.085107, 0.078492, 0.0078729, 0.036014, 0.0022174, 0.75466, 0.019171, 0.27524, 0.010763]
Predicted label: 0
Correct prediction
Energy consumption = 172.986946 pJ
sum error= 299
Actual label: 9
Output voltages: [0.23183, 0.024729, 0.012618, 0.090943, 0.13639, 0.0069676, 0.010689, 0.012039, 0.13864, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 158.003981 pJ
sum error= 299
Actual label: 6
Output voltages: [0.052939, 0.14846, 0.13514, 0.0017543, 0.61872, 0.060801, 0.79875, 0.0020811, 0.04211, 0.0028895]
Predicted label: 6
Correct prediction
Energy consumption = 158.276610 pJ
sum error= 299
Actual label: 8
Output voltages: [0.1016, 0.052373, 0.76203, 0.12159, 0.0096063, 0.014404, 0.13902, 0.0082288, 0.79879, 0.10496]
Predicted label: 8
Correct prediction
Energy consumption = 149.375956 pJ
sum error= 299
Actual label: 8
Output voltages: [0.057835, 0.017223, 0.54687, 0.20507, 0.044795, 0.0021998, 0.084131, 0.0054302, 0.79875, 0.054345]
Predicted label: 8
Correct prediction
Energy consumption = 139.248604 pJ
sum error= 299
Actual label: 5
Output voltages: [0.014123, 0.0010968, 0.0019598, 0.37257, 0.039321, 0.79833, 0.40636, 0.014523, 0.76646, 0.027741]
Predicted label: 5
Correct prediction
Energy consumption = 144.183851 pJ
sum error= 299
Actual label: 6
Output voltages: [0.075749, 0.23032, 0.41216, 0.0012229, 0.22361, 0.027329, 0.7987, 0.0011255, 0.42073, 0.011404]
Predicted label: 6
Correct prediction
Energy consumption = 138.580088 pJ
sum error= 299
Actual label: 1
Output voltages: [0.01178, 0.79854, 0.35605, 0.34075, 0.019473, 0.0010961, 0.73071, 0.0099271, 0.087408, 0.018656]
Predicted label: 1
Correct prediction
Energy consumption = 161.770982 pJ
sum error= 299
Actual label: 1
Output voltages: [0.010236, 0.7986, 0.012099, 0.28136, 0.30788, 0.002764, 0.023824, 0.0024183, 0.17991, 0.16938]
Predicted label: 1
Correct prediction
Energy consumption = 158.793880 pJ
sum error= 299
Actual label: 9
Output voltages: [0.47169, 0.0024686, 0.05695, 0.047967, 0.5743, 0.032332, 0.12757, 0.013418, 0.023374, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 157.945490 pJ
sum error= 299
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 641 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 641 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 641 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18811, 0.017967, 0.20491, 0.27101, 0.0022893, 0.017557, 0.5147, 0.0013201, 0.79552, 0.052707]
Predicted label: 8
Correct prediction
Energy consumption = 168.531640 pJ
sum error= 299
Actual label: 9
Output voltages: [0.012971, 0.0060602, 0.053372, 0.15492, 0.21773, 0.0015646, 0.01014, 0.019322, 0.61521, 0.79539]
Predicted label: 9
Correct prediction
Energy consumption = 158.931145 pJ
sum error= 299
Actual label: 2
Output voltages: [0.78088, 0.049026, 0.79878, 0.20298, 0.0016602, 0.0010716, 0.07031, 0.027629, 0.30307, 0.016714]
Predicted label: 2
Correct prediction
Energy consumption = 149.720883 pJ
sum error= 299
Actual label: 3
Output voltages: [0.51293, 0.019233, 0.037001, 0.79869, 0.009234, 0.0095994, 0.020839, 0.005553, 0.36175, 0.038573]
Predicted label: 3
Correct prediction
Energy consumption = 145.376736 pJ
sum error= 299
Actual label: 5
Output voltages: [0.021446, 0.0010825, 0.0019786, 0.41978, 0.028957, 0.79614, 0.09209, 0.01885, 0.78087, 0.026777]
Predicted label: 5
Correct prediction
Energy consumption = 139.924134 pJ
sum error= 299
Actual label: 5
Output voltages: [0.0055944, 0.0010801, 0.011396, 0.17383, 0.011436, 0.79662, 0.052333, 0.0046269, 0.78273, 0.021724]
Predicted label: 5
Correct prediction
Energy consumption = 132.910365 pJ
sum error= 299
Actual label: 9
Output voltages: [0.74852, 0.0011129, 0.040745, 0.041915, 0.076151, 0.0084323, 0.011746, 0.086064, 0.099032, 0.79507]
Predicted label: 9
Correct prediction
Energy consumption = 149.811173 pJ
sum error= 299
Actual label: 4
Output voltages: [0.0012363, 0.025889, 0.0049388, 0.011803, 0.79841, 0.0038486, 0.4359, 0.028483, 0.25742, 0.0098264]
Predicted label: 4
Correct prediction
Energy consumption = 153.535583 pJ
sum error= 299
Actual label: 2
Output voltages: [0.20542, 0.035045, 0.79831, 0.75411, 0.029859, 0.001066, 0.012789, 0.02791, 0.22124, 0.0081814]
Predicted label: 2
Correct prediction
Energy consumption = 132.720141 pJ
sum error= 299
Actual label: 1
Output voltages: [0.0037598, 0.79859, 0.45833, 0.28478, 0.093062, 0.001079, 0.27467, 0.002739, 0.027016, 0.30409]
Predicted label: 1
Correct prediction
Energy consumption = 161.340526 pJ
sum error= 299
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 642 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 642 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 642 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.046471, 0.02307, 0.0099864, 0.20624, 0.78056, 0.044135, 0.016101, 0.0025315, 0.18354, 0.76828]
Predicted label: 4
Wrong prediction!
Energy consumption = 172.348450 pJ
sum error= 300
Actual label: 3
Output voltages: [0.25359, 0.015196, 0.50514, 0.79849, 0.015882, 0.0010955, 0.084015, 0.0012196, 0.68443, 0.069975]
Predicted label: 3
Correct prediction
Energy consumption = 156.727326 pJ
sum error= 300
Actual label: 9
Output voltages: [0.45209, 0.0012008, 0.027349, 0.010704, 0.06816, 0.031889, 0.015513, 0.53926, 0.42237, 0.77897]
Predicted label: 9
Correct prediction
Energy consumption = 159.128851 pJ
sum error= 300
Actual label: 2
Output voltages: [0.5062, 0.049848, 0.79875, 0.12434, 0.02182, 0.0010681, 0.35105, 0.032925, 0.22411, 0.015255]
Predicted label: 2
Correct prediction
Energy consumption = 144.316276 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79833, 0.047624, 0.052894, 0.012036, 0.010556, 0.0012525, 0.75032, 0.021032, 0.31211, 0.072548]
Predicted label: 0
Correct prediction
Energy consumption = 147.215905 pJ
sum error= 300
Actual label: 6
Output voltages: [0.34085, 0.35654, 0.27297, 0.0015934, 0.079125, 0.019473, 0.79858, 0.0010767, 0.54888, 0.033928]
Predicted label: 6
Correct prediction
Energy consumption = 146.171270 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.026049, 0.031869, 0.0048688, 0.029277, 0.012396, 0.77387, 0.021034, 0.10377, 0.27011]
Predicted label: 0
Correct prediction
Energy consumption = 150.438924 pJ
sum error= 300
Actual label: 4
Output voltages: [0.0092602, 0.0080638, 0.029148, 0.010472, 0.79871, 0.0029674, 0.04809, 0.26067, 0.07433, 0.0057003]
Predicted label: 4
Correct prediction
Energy consumption = 150.022087 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.046977, 0.16525, 0.010373, 0.010076, 0.0014336, 0.63679, 0.011938, 0.18975, 0.056904]
Predicted label: 0
Correct prediction
Energy consumption = 154.938816 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79878, 0.06636, 0.647, 0.063239, 0.014694, 0.010933, 0.33462, 0.022368, 0.13661, 0.0084266]
Predicted label: 0
Correct prediction
Energy consumption = 141.847529 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 643 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 643 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 643 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.041265, 0.79874, 0.070784, 0.15224, 0.068305, 0.0010661, 0.7118, 0.00395, 0.079717, 0.04551]
Predicted label: 1
Correct prediction
Energy consumption = 176.911258 pJ
sum error= 300
Actual label: 2
Output voltages: [0.21741, 0.023061, 0.7987, 0.034186, 0.01924, 0.0011114, 0.20579, 0.036255, 0.55391, 0.0090038]
Predicted label: 2
Correct prediction
Energy consumption = 147.270880 pJ
sum error= 300
Actual label: 3
Output voltages: [0.05267, 0.023489, 0.21266, 0.79879, 0.0094846, 0.001273, 0.0068093, 0.0037436, 0.65912, 0.041797]
Predicted label: 3
Correct prediction
Energy consumption = 140.381904 pJ
sum error= 300
Actual label: 4
Output voltages: [0.0059755, 0.012182, 0.039995, 0.11691, 0.79879, 0.0010683, 0.047262, 0.052309, 0.030879, 0.0099754]
Predicted label: 4
Correct prediction
Energy consumption = 149.268311 pJ
sum error= 300
Actual label: 7
Output voltages: [0.028537, 0.031237, 0.018189, 0.0093427, 0.49971, 0.0010928, 0.0011465, 0.79815, 0.25906, 0.13295]
Predicted label: 7
Correct prediction
Energy consumption = 150.373033 pJ
sum error= 300
Actual label: 8
Output voltages: [0.041952, 0.043407, 0.49433, 0.014184, 0.036871, 0.007631, 0.01381, 0.014474, 0.79875, 0.16447]
Predicted label: 8
Correct prediction
Energy consumption = 144.209172 pJ
sum error= 300
Actual label: 9
Output voltages: [0.42745, 0.039737, 0.0079863, 0.25868, 0.48686, 0.0040868, 0.003345, 0.0037032, 0.069723, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.717364 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79874, 0.22882, 0.086514, 0.028284, 0.026414, 0.022249, 0.20462, 0.027805, 0.10995, 0.060087]
Predicted label: 0
Correct prediction
Energy consumption = 146.865495 pJ
sum error= 300
Actual label: 1
Output voltages: [0.081166, 0.79864, 0.047585, 0.020762, 0.14853, 0.0082627, 0.39628, 0.0040861, 0.029795, 0.0084461]
Predicted label: 1
Correct prediction
Energy consumption = 152.606630 pJ
sum error= 300
Actual label: 2
Output voltages: [0.19172, 0.11652, 0.79878, 0.020507, 0.044303, 0.0010987, 0.1334, 0.019584, 0.61597, 0.05199]
Predicted label: 2
Correct prediction
Energy consumption = 142.766816 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 644 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 644 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 644 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.1759, 0.022731, 0.033826, 0.7987, 0.010196, 0.0063221, 0.009431, 0.0038918, 0.52923, 0.042607]
Predicted label: 3
Correct prediction
Energy consumption = 161.681439 pJ
sum error= 300
Actual label: 7
Output voltages: [0.20662, 0.0095991, 0.0059326, 0.010326, 0.53626, 0.0015991, 0.0011342, 0.79867, 0.37274, 0.10179]
Predicted label: 7
Correct prediction
Energy consumption = 150.427102 pJ
sum error= 300
Actual label: 8
Output voltages: [0.019243, 0.11164, 0.3938, 0.045091, 0.0024696, 0.030398, 0.014513, 0.083017, 0.79869, 0.04859]
Predicted label: 8
Correct prediction
Energy consumption = 143.020073 pJ
sum error= 300
Actual label: 9
Output voltages: [0.37264, 0.036628, 0.025742, 0.1332, 0.39148, 0.01181, 0.023401, 0.0072584, 0.073188, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 153.975145 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79878, 0.019901, 0.038869, 0.012763, 0.012509, 0.0028083, 0.41675, 0.035468, 0.32653, 0.043986]
Predicted label: 0
Correct prediction
Energy consumption = 152.530688 pJ
sum error= 300
Actual label: 1
Output voltages: [0.044648, 0.79751, 0.19093, 0.001066, 0.7054, 0.0039392, 0.34346, 0.0010779, 0.32194, 0.35998]
Predicted label: 1
Correct prediction
Energy consumption = 158.408653 pJ
sum error= 300
Actual label: 2
Output voltages: [0.031504, 0.039462, 0.79878, 0.14086, 0.015766, 0.0011611, 0.26734, 0.020313, 0.67404, 0.030735]
Predicted label: 2
Correct prediction
Energy consumption = 142.216466 pJ
sum error= 300
Actual label: 3
Output voltages: [0.095727, 0.0015333, 0.050376, 0.79875, 0.06784, 0.082521, 0.011523, 0.0023512, 0.41942, 0.048201]
Predicted label: 3
Correct prediction
Energy consumption = 143.434196 pJ
sum error= 300
Actual label: 4
Output voltages: [0.016433, 0.0034835, 0.1438, 0.019152, 0.79867, 0.0011707, 0.015043, 0.055495, 0.046128, 0.024207]
Predicted label: 4
Correct prediction
Energy consumption = 153.316331 pJ
sum error= 300
Actual label: 7
Output voltages: [0.054074, 0.054374, 0.025938, 0.09737, 0.029282, 0.008216, 0.0011141, 0.79864, 0.085693, 0.33219]
Predicted label: 7
Correct prediction
Energy consumption = 144.755149 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 645 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 645 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 645 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.09657, 0.006716, 0.1543, 0.050368, 0.033807, 0.081225, 0.0072882, 0.012803, 0.79867, 0.0090576]
Predicted label: 8
Correct prediction
Energy consumption = 165.080931 pJ
sum error= 300
Actual label: 9
Output voltages: [0.14444, 0.023375, 0.042561, 0.033743, 0.065678, 0.030072, 0.0098341, 0.042911, 0.35323, 0.79717]
Predicted label: 9
Correct prediction
Energy consumption = 150.146423 pJ
sum error= 300
Actual label: 7
Output voltages: [0.16683, 0.0021462, 0.016499, 0.26017, 0.029248, 0.020362, 0.0011595, 0.7987, 0.58072, 0.029773]
Predicted label: 7
Correct prediction
Energy consumption = 149.846728 pJ
sum error= 300
Actual label: 3
Output voltages: [0.20504, 0.014627, 0.14269, 0.79872, 0.070165, 0.1037, 0.02516, 0.022729, 0.73744, 0.2781]
Predicted label: 3
Correct prediction
Energy consumption = 144.451162 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.037242, 0.18139, 0.0091926, 0.0224, 0.0035555, 0.32738, 0.0052464, 0.31184, 0.079567]
Predicted label: 0
Correct prediction
Energy consumption = 150.354829 pJ
sum error= 300
Actual label: 3
Output voltages: [0.56159, 0.0023272, 0.21072, 0.79871, 0.10737, 0.044479, 0.0036193, 0.0022733, 0.62561, 0.022436]
Predicted label: 3
Correct prediction
Energy consumption = 148.253041 pJ
sum error= 300
Actual label: 1
Output voltages: [0.061265, 0.7987, 0.033859, 0.02553, 0.069999, 0.0011522, 0.48927, 0.0056025, 0.089852, 0.030236]
Predicted label: 1
Correct prediction
Energy consumption = 158.986744 pJ
sum error= 300
Actual label: 8
Output voltages: [0.043672, 0.036834, 0.55067, 0.027814, 0.0062153, 0.0096646, 0.032074, 0.032963, 0.7987, 0.031634]
Predicted label: 8
Correct prediction
Energy consumption = 146.072191 pJ
sum error= 300
Actual label: 7
Output voltages: [0.20619, 0.29329, 0.028796, 0.2889, 0.17858, 0.0012056, 0.0012093, 0.79821, 0.20275, 0.25616]
Predicted label: 7
Correct prediction
Energy consumption = 151.036050 pJ
sum error= 300
Actual label: 6
Output voltages: [0.21743, 0.0059954, 0.22966, 0.0052149, 0.34877, 0.23381, 0.79879, 0.0017077, 0.55466, 0.043904]
Predicted label: 6
Correct prediction
Energy consumption = 146.116971 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 646 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 646 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 646 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0082903, 0.095463, 0.38198, 0.0075252, 0.7986, 0.031011, 0.071083, 0.20889, 0.13073, 0.017634]
Predicted label: 4
Correct prediction
Energy consumption = 164.660486 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.030473, 0.022867, 0.019326, 0.060195, 0.0054084, 0.68711, 0.017197, 0.07185, 0.03397]
Predicted label: 0
Correct prediction
Energy consumption = 153.030928 pJ
sum error= 300
Actual label: 2
Output voltages: [0.38231, 0.023645, 0.79872, 0.019187, 0.012516, 0.0010811, 0.073148, 0.031288, 0.54145, 0.020032]
Predicted label: 2
Correct prediction
Energy consumption = 143.111118 pJ
sum error= 300
Actual label: 6
Output voltages: [0.060907, 0.013571, 0.06896, 0.0011863, 0.28853, 0.050612, 0.79879, 0.0010985, 0.61793, 0.0020799]
Predicted label: 6
Correct prediction
Energy consumption = 141.257502 pJ
sum error= 300
Actual label: 8
Output voltages: [0.024809, 0.084666, 0.33251, 0.012221, 0.030882, 0.0088452, 0.011228, 0.0085108, 0.79875, 0.1299]
Predicted label: 8
Correct prediction
Energy consumption = 145.357755 pJ
sum error= 300
Actual label: 3
Output voltages: [0.70473, 0.010582, 0.055367, 0.79868, 0.0095965, 0.030829, 0.006652, 0.021521, 0.32401, 0.0248]
Predicted label: 3
Correct prediction
Energy consumption = 141.616433 pJ
sum error= 300
Actual label: 2
Output voltages: [0.29667, 0.043627, 0.79867, 0.020765, 0.0048761, 0.0011645, 0.19192, 0.37218, 0.63443, 0.001487]
Predicted label: 2
Correct prediction
Energy consumption = 140.598913 pJ
sum error= 300
Actual label: 8
Output voltages: [0.01328, 0.052182, 0.29051, 0.14854, 0.008696, 0.049939, 0.030887, 0.025803, 0.79861, 0.041875]
Predicted label: 8
Correct prediction
Energy consumption = 142.061447 pJ
sum error= 300
Actual label: 1
Output voltages: [0.021093, 0.79879, 0.072907, 0.012132, 0.2889, 0.0010675, 0.30273, 0.0026021, 0.40963, 0.2067]
Predicted label: 1
Correct prediction
Energy consumption = 154.786651 pJ
sum error= 300
Actual label: 2
Output voltages: [0.12499, 0.29156, 0.79872, 0.027166, 0.0076696, 0.0010997, 0.03999, 0.046075, 0.3513, 0.03252]
Predicted label: 2
Correct prediction
Energy consumption = 139.738303 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 647 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 647 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 647 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79848, 0.028352, 0.10193, 0.022232, 0.0094269, 0.0021636, 0.50283, 0.022759, 0.12135, 0.031118]
Predicted label: 0
Correct prediction
Energy consumption = 168.236279 pJ
sum error= 300
Actual label: 7
Output voltages: [0.071122, 0.045499, 0.030908, 0.021458, 0.53919, 0.0010686, 0.0012375, 0.79863, 0.31187, 0.01838]
Predicted label: 7
Correct prediction
Energy consumption = 151.861788 pJ
sum error= 300
Actual label: 1
Output voltages: [0.010768, 0.79879, 0.19685, 0.005069, 0.43436, 0.0016342, 0.54356, 0.0010675, 0.037477, 0.08181]
Predicted label: 1
Correct prediction
Energy consumption = 154.802465 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.020943, 0.34775, 0.0096891, 0.04151, 0.001136, 0.137, 0.011352, 0.22757, 0.032081]
Predicted label: 0
Correct prediction
Energy consumption = 151.317047 pJ
sum error= 300
Actual label: 4
Output voltages: [0.0091123, 0.028248, 0.17075, 0.055976, 0.79873, 0.001315, 0.16635, 0.15757, 0.020654, 0.010191]
Predicted label: 4
Correct prediction
Energy consumption = 144.728627 pJ
sum error= 300
Actual label: 4
Output voltages: [0.0081308, 0.0032618, 0.47809, 0.02581, 0.79864, 0.0012544, 0.1421, 0.16638, 0.0081298, 0.036516]
Predicted label: 4
Correct prediction
Energy consumption = 137.549785 pJ
sum error= 300
Actual label: 5
Output voltages: [0.011136, 0.0010664, 0.0012302, 0.29441, 0.025175, 0.79848, 0.35136, 0.0035173, 0.77338, 0.010544]
Predicted label: 5
Correct prediction
Energy consumption = 141.786816 pJ
sum error= 300
Actual label: 8
Output voltages: [0.0079045, 0.043922, 0.19231, 0.02296, 0.028207, 0.016264, 0.027813, 0.0053531, 0.79878, 0.29004]
Predicted label: 8
Correct prediction
Energy consumption = 140.681556 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.06512, 0.033277, 0.047848, 0.017114, 0.03211, 0.67501, 0.019025, 0.25433, 0.029372]
Predicted label: 0
Correct prediction
Energy consumption = 153.471254 pJ
sum error= 300
Actual label: 6
Output voltages: [0.024016, 0.056844, 0.03186, 0.020359, 0.17248, 0.17739, 0.79879, 0.0073283, 0.75571, 0.0056954]
Predicted label: 6
Correct prediction
Energy consumption = 137.018142 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 648 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 648 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 648 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.045249, 0.0058602, 0.79879, 0.11463, 0.020082, 0.0012897, 0.34275, 0.076464, 0.36477, 0.014881]
Predicted label: 2
Correct prediction
Energy consumption = 163.566580 pJ
sum error= 300
Actual label: 3
Output voltages: [0.42855, 0.017709, 0.066219, 0.79867, 0.076046, 0.036451, 0.018186, 0.031179, 0.76767, 0.041318]
Predicted label: 3
Correct prediction
Energy consumption = 144.012518 pJ
sum error= 300
Actual label: 1
Output voltages: [0.014728, 0.79857, 0.31304, 0.16316, 0.032486, 0.0010734, 0.5425, 0.0095112, 0.026641, 0.013016]
Predicted label: 1
Correct prediction
Energy consumption = 154.819958 pJ
sum error= 300
Actual label: 5
Output voltages: [0.079911, 0.0011569, 0.0011135, 0.50648, 0.10615, 0.79866, 0.54052, 0.040928, 0.73663, 0.024543]
Predicted label: 5
Correct prediction
Energy consumption = 150.100812 pJ
sum error= 300
Actual label: 1
Output voltages: [0.037613, 0.79879, 0.54543, 0.041108, 0.39423, 0.0011181, 0.14204, 0.0096501, 0.20295, 0.061274]
Predicted label: 1
Correct prediction
Energy consumption = 162.204775 pJ
sum error= 300
Actual label: 8
Output voltages: [0.027523, 0.12198, 0.55217, 0.022537, 0.04773, 0.029123, 0.018228, 0.0048697, 0.79876, 0.030287]
Predicted label: 8
Correct prediction
Energy consumption = 153.359239 pJ
sum error= 300
Actual label: 5
Output voltages: [0.37731, 0.001452, 0.0011203, 0.67571, 0.35748, 0.79861, 0.43406, 0.01177, 0.54132, 0.0131]
Predicted label: 5
Correct prediction
Energy consumption = 143.153794 pJ
sum error= 300
Actual label: 9
Output voltages: [0.38306, 0.042556, 0.015844, 0.1818, 0.25727, 0.017008, 0.022302, 0.014451, 0.10038, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.218990 pJ
sum error= 300
Actual label: 4
Output voltages: [0.041102, 0.0051782, 0.1873, 0.029085, 0.79877, 0.0010905, 0.018709, 0.045243, 0.01696, 0.0070549]
Predicted label: 4
Correct prediction
Energy consumption = 150.436079 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79875, 0.028452, 0.12931, 0.027255, 0.023775, 0.0031226, 0.19504, 0.020541, 0.10771, 0.046817]
Predicted label: 0
Correct prediction
Energy consumption = 149.749013 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 649 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 649 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 649 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.40454, 0.066058, 0.020345, 0.032258, 0.37406, 0.0011029, 0.0011883, 0.79867, 0.15741, 0.010317]
Predicted label: 7
Correct prediction
Energy consumption = 167.040547 pJ
sum error= 300
Actual label: 5
Output voltages: [0.29935, 0.0010701, 0.0010988, 0.30049, 0.2581, 0.79854, 0.065963, 0.026447, 0.60836, 0.041782]
Predicted label: 5
Correct prediction
Energy consumption = 145.584421 pJ
sum error= 300
Actual label: 8
Output voltages: [0.020378, 0.13448, 0.28025, 0.012589, 0.017185, 0.0024616, 0.015691, 0.0091368, 0.79879, 0.41383]
Predicted label: 8
Correct prediction
Energy consumption = 149.302456 pJ
sum error= 300
Actual label: 8
Output voltages: [0.0096273, 0.14168, 0.21427, 0.028126, 0.01916, 0.011734, 0.090981, 0.0027163, 0.79878, 0.35941]
Predicted label: 8
Correct prediction
Energy consumption = 141.994288 pJ
sum error= 300
Actual label: 3
Output voltages: [0.27204, 0.0018597, 0.034828, 0.79871, 0.016888, 0.11974, 0.13121, 0.023442, 0.63835, 0.049402]
Predicted label: 3
Correct prediction
Energy consumption = 148.494135 pJ
sum error= 300
Actual label: 8
Output voltages: [0.042786, 0.0058659, 0.13111, 0.0083239, 0.025612, 0.0057226, 0.025958, 0.0024554, 0.79878, 0.13428]
Predicted label: 8
Correct prediction
Energy consumption = 148.840774 pJ
sum error= 300
Actual label: 9
Output voltages: [0.073398, 0.060558, 0.02637, 0.10359, 0.051278, 0.0092158, 0.008007, 0.013264, 0.39336, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 144.035268 pJ
sum error= 300
Actual label: 2
Output voltages: [0.42237, 0.032962, 0.79873, 0.020529, 0.0053402, 0.0011147, 0.033619, 0.31014, 0.72548, 0.001622]
Predicted label: 2
Correct prediction
Energy consumption = 147.468175 pJ
sum error= 300
Actual label: 6
Output voltages: [0.1892, 0.0094791, 0.031812, 0.0089211, 0.40935, 0.16786, 0.79878, 0.0010791, 0.63167, 0.012014]
Predicted label: 6
Correct prediction
Energy consumption = 142.014414 pJ
sum error= 300
Actual label: 2
Output voltages: [0.25316, 0.033672, 0.79878, 0.038485, 0.046353, 0.0010931, 0.13477, 0.03821, 0.61333, 0.037409]
Predicted label: 2
Correct prediction
Energy consumption = 138.247914 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 650 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 650 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 650 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.018047, 0.0011576, 0.0045693, 0.058603, 0.070164, 0.79875, 0.27738, 0.0068894, 0.7911, 0.0042759]
Predicted label: 5
Correct prediction
Energy consumption = 160.001375 pJ
sum error= 300
Actual label: 3
Output voltages: [0.22956, 0.0027706, 0.058399, 0.79879, 0.025919, 0.20819, 0.020015, 0.0023338, 0.64268, 0.038839]
Predicted label: 3
Correct prediction
Energy consumption = 145.090022 pJ
sum error= 300
Actual label: 1
Output voltages: [0.026124, 0.7987, 0.053498, 0.0025492, 0.65126, 0.0010718, 0.2971, 0.0010826, 0.013806, 0.44571]
Predicted label: 1
Correct prediction
Energy consumption = 159.190445 pJ
sum error= 300
Actual label: 7
Output voltages: [0.031648, 0.059826, 0.025671, 0.045143, 0.036537, 0.0068011, 0.001121, 0.79867, 0.063658, 0.10966]
Predicted label: 7
Correct prediction
Energy consumption = 150.286287 pJ
sum error= 300
Actual label: 3
Output voltages: [0.098423, 0.016828, 0.11093, 0.79871, 0.048942, 0.0029489, 0.0087123, 0.0062105, 0.46799, 0.040281]
Predicted label: 3
Correct prediction
Energy consumption = 144.582936 pJ
sum error= 300
Actual label: 9
Output voltages: [0.76357, 0.040874, 0.37512, 0.03348, 0.065029, 0.0010659, 0.52424, 0.0080097, 0.056135, 0.73412]
Predicted label: 0
Wrong prediction!
Energy consumption = 148.931306 pJ
sum error= 301
Actual label: 1
Output voltages: [0.055609, 0.79871, 0.32193, 0.031771, 0.53163, 0.0010752, 0.43065, 0.0021403, 0.014524, 0.028199]
Predicted label: 1
Correct prediction
Energy consumption = 145.904472 pJ
sum error= 301
Actual label: 9
Output voltages: [0.47627, 0.019652, 0.018211, 0.17342, 0.26917, 0.009384, 0.043506, 0.0030603, 0.23499, 0.7941]
Predicted label: 9
Correct prediction
Energy consumption = 148.491544 pJ
sum error= 301
Actual label: 9
Output voltages: [0.23838, 0.014136, 0.012447, 0.034007, 0.045938, 0.043978, 0.0045409, 0.089338, 0.62592, 0.79748]
Predicted label: 9
Correct prediction
Energy consumption = 138.775539 pJ
sum error= 301
Actual label: 6
Output voltages: [0.17487, 0.040263, 0.30524, 0.0011323, 0.38581, 0.080567, 0.79877, 0.0011641, 0.52398, 0.0043084]
Predicted label: 6
Correct prediction
Energy consumption = 144.500401 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 651 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 651 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 651 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79861, 0.032306, 0.042934, 0.01088, 0.011584, 0.01397, 0.32959, 0.025961, 0.065994, 0.048922]
Predicted label: 0
Correct prediction
Energy consumption = 164.251179 pJ
sum error= 301
Actual label: 3
Output voltages: [0.30775, 0.0011122, 0.01165, 0.79607, 0.015355, 0.73453, 0.0096902, 0.019005, 0.6786, 0.079909]
Predicted label: 3
Correct prediction
Energy consumption = 148.711415 pJ
sum error= 301
Actual label: 9
Output voltages: [0.59026, 0.0097079, 0.031698, 0.029712, 0.23022, 0.017476, 0.016049, 0.0083392, 0.34077, 0.79693]
Predicted label: 9
Correct prediction
Energy consumption = 147.923163 pJ
sum error= 301
Actual label: 2
Output voltages: [0.41809, 0.1161, 0.7987, 0.05475, 0.025159, 0.001215, 0.086484, 0.060719, 0.38648, 0.040136]
Predicted label: 2
Correct prediction
Energy consumption = 148.724807 pJ
sum error= 301
Actual label: 8
Output voltages: [0.024575, 0.10566, 0.58738, 0.009129, 0.0095975, 0.022696, 0.041225, 0.0016916, 0.79874, 0.13005]
Predicted label: 8
Correct prediction
Energy consumption = 142.952606 pJ
sum error= 301
Actual label: 1
Output voltages: [0.083584, 0.79879, 0.58219, 0.0014273, 0.47603, 0.021468, 0.37291, 0.0010678, 0.23877, 0.039353]
Predicted label: 1
Correct prediction
Energy consumption = 155.475939 pJ
sum error= 301
Actual label: 4
Output voltages: [0.005908, 0.0070598, 0.020302, 0.015215, 0.79862, 0.012857, 0.12236, 0.062256, 0.084076, 0.015373]
Predicted label: 4
Correct prediction
Energy consumption = 141.790760 pJ
sum error= 301
Actual label: 3
Output voltages: [0.76812, 0.0012533, 0.46391, 0.78561, 0.0010882, 0.027343, 0.006985, 0.016548, 0.07986, 0.0010986]
Predicted label: 3
Correct prediction
Energy consumption = 147.965336 pJ
sum error= 301
Actual label: 5
Output voltages: [0.028551, 0.0012855, 0.0015358, 0.44766, 0.02486, 0.79879, 0.34751, 0.0065717, 0.71879, 0.0014291]
Predicted label: 5
Correct prediction
Energy consumption = 139.575243 pJ
sum error= 301
Actual label: 2
Output voltages: [0.40554, 0.02673, 0.79873, 0.025028, 0.012741, 0.0010853, 0.055778, 0.017432, 0.43053, 0.018995]
Predicted label: 2
Correct prediction
Energy consumption = 146.865195 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 652 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 652 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 652 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.26882, 0.028034, 0.019668, 0.064953, 0.34443, 0.009622, 0.0020331, 0.00311, 0.28017, 0.79859]
Predicted label: 9
Correct prediction
Energy consumption = 166.028070 pJ
sum error= 301
Actual label: 2
Output voltages: [0.25285, 0.011884, 0.79874, 0.018128, 0.012224, 0.0011122, 0.035267, 0.044196, 0.4745, 0.0086072]
Predicted label: 2
Correct prediction
Energy consumption = 149.401899 pJ
sum error= 301
Actual label: 5
Output voltages: [0.038877, 0.0011082, 0.0011032, 0.48925, 0.25614, 0.79878, 0.28048, 0.023581, 0.77828, 0.0075302]
Predicted label: 5
Correct prediction
Energy consumption = 145.553075 pJ
sum error= 301
Actual label: 8
Output voltages: [0.025808, 0.53504, 0.2196, 0.031418, 0.027823, 0.0015425, 0.0051419, 0.02494, 0.79816, 0.29781]
Predicted label: 8
Correct prediction
Energy consumption = 154.049079 pJ
sum error= 301
Actual label: 9
Output voltages: [0.40643, 0.023885, 0.026298, 0.18151, 0.16598, 0.014373, 0.0023925, 0.019664, 0.33567, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 152.373160 pJ
sum error= 301
Actual label: 5
Output voltages: [0.026844, 0.0010891, 0.0023557, 0.2196, 0.047511, 0.79876, 0.27221, 0.028658, 0.77063, 0.0046033]
Predicted label: 5
Correct prediction
Energy consumption = 146.064382 pJ
sum error= 301
Actual label: 0
Output voltages: [0.79877, 0.044532, 0.036061, 0.022672, 0.0018957, 0.020444, 0.4383, 0.13858, 0.1529, 0.011005]
Predicted label: 0
Correct prediction
Energy consumption = 141.423486 pJ
sum error= 301
Actual label: 1
Output voltages: [0.16664, 0.79879, 0.24235, 0.030392, 0.34111, 0.0010695, 0.048738, 0.0076915, 0.029617, 0.043036]
Predicted label: 1
Correct prediction
Energy consumption = 159.680494 pJ
sum error= 301
Actual label: 2
Output voltages: [0.011013, 0.035864, 0.79873, 0.18337, 0.07483, 0.0014599, 0.031784, 0.11938, 0.44911, 0.011605]
Predicted label: 2
Correct prediction
Energy consumption = 141.558325 pJ
sum error= 301
Actual label: 4
Output voltages: [0.042438, 0.016533, 0.15853, 0.022516, 0.79859, 0.0010703, 0.038893, 0.020152, 0.17659, 0.025716]
Predicted label: 4
Correct prediction
Energy consumption = 139.724587 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 653 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 653 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 653 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.047849, 0.001093, 0.001816, 0.24144, 0.03738, 0.79879, 0.1963, 0.0022715, 0.64761, 0.020731]
Predicted label: 5
Correct prediction
Energy consumption = 156.022994 pJ
sum error= 301
Actual label: 6
Output voltages: [0.19521, 0.044662, 0.2635, 0.0064476, 0.36602, 0.15597, 0.7987, 0.0032409, 0.26929, 0.031975]
Predicted label: 6
Correct prediction
Energy consumption = 138.791688 pJ
sum error= 301
Actual label: 0
Output voltages: [0.79878, 0.010106, 0.0010699, 0.11283, 0.0019934, 0.75414, 0.0058903, 0.016784, 0.13569, 0.003378]
Predicted label: 0
Correct prediction
Energy consumption = 144.992444 pJ
sum error= 301
Actual label: 1
Output voltages: [0.0074822, 0.79856, 0.036095, 0.027666, 0.011049, 0.0013251, 0.46437, 0.013108, 0.57672, 0.0075461]
Predicted label: 1
Correct prediction
Energy consumption = 163.108595 pJ
sum error= 301
Actual label: 2
Output voltages: [0.30079, 0.018468, 0.79878, 0.1898, 0.010835, 0.0011987, 0.038092, 0.46531, 0.56958, 0.019985]
Predicted label: 2
Correct prediction
Energy consumption = 141.579516 pJ
sum error= 301
Actual label: 3
Output voltages: [0.18017, 0.19781, 0.12049, 0.79866, 0.012915, 0.017038, 0.0098889, 0.027093, 0.47473, 0.32146]
Predicted label: 3
Correct prediction
Energy consumption = 144.032899 pJ
sum error= 301
Actual label: 4
Output voltages: [0.026518, 0.007629, 0.10264, 0.018175, 0.79872, 0.0011651, 0.065534, 0.12737, 0.21248, 0.0085269]
Predicted label: 4
Correct prediction
Energy consumption = 150.033510 pJ
sum error= 301
Actual label: 5
Output voltages: [0.15941, 0.0010695, 0.0049615, 0.23062, 0.11025, 0.79866, 0.32217, 0.013488, 0.41006, 0.035394]
Predicted label: 5
Correct prediction
Energy consumption = 146.057081 pJ
sum error= 301
Actual label: 6
Output voltages: [0.025693, 0.34074, 0.1472, 0.023858, 0.22184, 0.0081478, 0.79869, 0.0023209, 0.18805, 0.24515]
Predicted label: 6
Correct prediction
Energy consumption = 140.435131 pJ
sum error= 301
Actual label: 7
Output voltages: [0.27552, 0.014292, 0.02579, 0.20871, 0.031645, 0.018377, 0.0010842, 0.7987, 0.19843, 0.66201]
Predicted label: 7
Correct prediction
Energy consumption = 149.220839 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 654 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 654 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 654 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.018819, 0.79835, 0.0099551, 0.030657, 0.020452, 0.0049168, 0.5126, 0.019013, 0.047559, 0.3126]
Predicted label: 1
Correct prediction
Energy consumption = 179.445831 pJ
sum error= 301
Actual label: 2
Output voltages: [0.25226, 0.34363, 0.79879, 0.36646, 0.018427, 0.0013333, 0.18225, 0.033879, 0.23276, 0.024001]
Predicted label: 2
Correct prediction
Energy consumption = 149.231553 pJ
sum error= 301
Actual label: 3
Output voltages: [0.26886, 0.11106, 0.24306, 0.79847, 0.029918, 0.0010667, 0.0012877, 0.63491, 0.065839, 0.016205]
Predicted label: 3
Correct prediction
Energy consumption = 141.172902 pJ
sum error= 301
Actual label: 4
Output voltages: [0.0010661, 0.0084478, 0.30977, 0.060337, 0.79873, 0.0010892, 0.064696, 0.30685, 0.0090477, 0.050957]
Predicted label: 4
Correct prediction
Energy consumption = 141.416927 pJ
sum error= 301
Actual label: 5
Output voltages: [0.052295, 0.0010765, 0.0010751, 0.31468, 0.048214, 0.79797, 0.33747, 0.0022, 0.65539, 0.21859]
Predicted label: 5
Correct prediction
Energy consumption = 154.133723 pJ
sum error= 301
Actual label: 1
Output voltages: [0.032404, 0.79872, 0.43784, 0.07622, 0.1957, 0.0011139, 0.57205, 0.0061975, 0.038325, 0.026376]
Predicted label: 1
Correct prediction
Energy consumption = 171.108461 pJ
sum error= 301
Actual label: 0
Output voltages: [0.79837, 0.029552, 0.026018, 0.038343, 0.0010803, 0.011497, 0.59322, 0.007799, 0.40492, 0.35155]
Predicted label: 0
Correct prediction
Energy consumption = 141.086078 pJ
sum error= 301
Actual label: 4
Output voltages: [0.0038106, 0.014837, 0.045338, 0.0013599, 0.79852, 0.0012189, 0.5988, 0.061818, 0.028461, 0.026461]
Predicted label: 4
Correct prediction
Energy consumption = 144.167907 pJ
sum error= 301
Actual label: 5
Output voltages: [0.0091845, 0.0013141, 0.0010939, 0.24315, 0.22458, 0.79878, 0.28328, 0.020606, 0.54773, 0.13107]
Predicted label: 5
Correct prediction
Energy consumption = 144.609051 pJ
sum error= 301
Actual label: 6
Output voltages: [0.17417, 0.033071, 0.20222, 0.0018891, 0.25313, 0.048257, 0.79878, 0.0010916, 0.20554, 0.015262]
Predicted label: 6
Correct prediction
Energy consumption = 136.858014 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 655 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 655 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 655 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.062392, 0.12957, 0.26386, 0.017647, 0.26815, 0.18807, 0.79867, 0.0028558, 0.28369, 0.016407]
Predicted label: 6
Correct prediction
Energy consumption = 160.717554 pJ
sum error= 301
Actual label: 3
Output voltages: [0.58574, 0.059342, 0.23125, 0.79855, 0.053865, 0.022356, 0.026728, 0.11233, 0.46545, 0.10499]
Predicted label: 3
Correct prediction
Energy consumption = 151.491527 pJ
sum error= 301
Actual label: 4
Output voltages: [0.025963, 0.0077885, 0.5016, 0.015441, 0.79875, 0.0036059, 0.4028, 0.043111, 0.032132, 0.01975]
Predicted label: 4
Correct prediction
Energy consumption = 149.669078 pJ
sum error= 301
Actual label: 4
Output voltages: [0.010554, 0.0036229, 0.033119, 0.60655, 0.78804, 0.0014781, 0.05036, 0.012005, 0.24212, 0.038386]
Predicted label: 4
Correct prediction
Energy consumption = 140.186817 pJ
sum error= 301
Actual label: 2
Output voltages: [0.039069, 0.0061863, 0.79548, 0.23403, 0.016281, 0.0012642, 0.024565, 0.24668, 0.71643, 0.12705]
Predicted label: 2
Correct prediction
Energy consumption = 133.645413 pJ
sum error= 301
Actual label: 8
Output voltages: [0.018369, 0.016757, 0.025497, 0.22474, 0.0053006, 0.0097251, 0.0010705, 0.32363, 0.79562, 0.78136]
Predicted label: 8
Correct prediction
Energy consumption = 143.869237 pJ
sum error= 301
Actual label: 1
Output voltages: [0.01227, 0.79853, 0.016919, 0.16431, 0.050117, 0.003219, 0.57747, 0.034372, 0.055775, 0.23915]
Predicted label: 1
Correct prediction
Energy consumption = 155.858104 pJ
sum error= 301
Actual label: 0
Output voltages: [0.78057, 0.02411, 0.76586, 0.045082, 0.0010668, 0.0011382, 0.41049, 0.26656, 0.48358, 0.0076974]
Predicted label: 0
Correct prediction
Energy consumption = 152.163226 pJ
sum error= 301
Actual label: 6
Output voltages: [0.043524, 0.13217, 0.77518, 0.0033119, 0.01238, 0.014967, 0.79501, 0.016474, 0.72608, 0.0017502]
Predicted label: 6
Correct prediction
Energy consumption = 136.969269 pJ
sum error= 301
Actual label: 4
Output voltages: [0.0016169, 0.009921, 0.45438, 0.18943, 0.79841, 0.001872, 0.0070898, 0.36298, 0.038855, 0.084198]
Predicted label: 4
Correct prediction
Energy consumption = 150.341025 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 656 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 656 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 656 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.077478, 0.027824, 0.0014617, 0.77017, 0.61133, 0.55065, 0.25303, 0.0017396, 0.01901, 0.74925]
Predicted label: 3
Wrong prediction!
Energy consumption = 165.893559 pJ
sum error= 302
Actual label: 7
Output voltages: [0.1135, 0.73252, 0.16965, 0.44871, 0.0015637, 0.0011603, 0.0011146, 0.79875, 0.2801, 0.49068]
Predicted label: 7
Correct prediction
Energy consumption = 158.307437 pJ
sum error= 302
Actual label: 2
Output voltages: [0.44083, 0.11682, 0.79878, 0.045938, 0.0041866, 0.0010778, 0.0042362, 0.74837, 0.46528, 0.011261]
Predicted label: 2
Correct prediction
Energy consumption = 136.671361 pJ
sum error= 302
Actual label: 3
Output voltages: [0.16727, 0.025075, 0.17354, 0.79862, 0.0022582, 0.12645, 0.0064535, 0.12001, 0.29102, 0.026532]
Predicted label: 3
Correct prediction
Energy consumption = 146.558127 pJ
sum error= 302
Actual label: 3
Output voltages: [0.072694, 0.0041466, 0.083494, 0.79879, 0.23785, 0.096706, 0.02023, 0.074177, 0.31472, 0.20918]
Predicted label: 3
Correct prediction
Energy consumption = 142.659638 pJ
sum error= 302
Actual label: 9
Output voltages: [0.26353, 0.018831, 0.026484, 0.040592, 0.025297, 0.015343, 0.0032379, 0.036828, 0.73606, 0.79847]
Predicted label: 9
Correct prediction
Energy consumption = 148.229798 pJ
sum error= 302
Actual label: 2
Output voltages: [0.34229, 0.0043751, 0.79796, 0.12079, 0.42135, 0.0010664, 0.022542, 0.010375, 0.62266, 0.014408]
Predicted label: 2
Correct prediction
Energy consumption = 147.421437 pJ
sum error= 302
Actual label: 0
Output voltages: [0.79878, 0.079476, 0.032696, 0.0082495, 0.0047228, 0.0097651, 0.64179, 0.030719, 0.24531, 0.038672]
Predicted label: 0
Correct prediction
Energy consumption = 141.468786 pJ
sum error= 302
Actual label: 9
Output voltages: [0.019681, 0.018893, 0.058324, 0.13851, 0.014376, 0.0043089, 0.0085797, 0.0055023, 0.76335, 0.79831]
Predicted label: 9
Correct prediction
Energy consumption = 142.949887 pJ
sum error= 302
Actual label: 3
Output voltages: [0.40929, 0.04809, 0.29718, 0.79838, 0.0061979, 0.0036662, 0.001145, 0.012251, 0.14737, 0.45852]
Predicted label: 3
Correct prediction
Energy consumption = 146.695944 pJ
sum error= 302
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 657 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 657 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 657 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.27557, 0.01823, 0.056591, 0.79868, 0.0077431, 0.0084542, 0.0052106, 0.054604, 0.491, 0.01763]
Predicted label: 3
Correct prediction
Energy consumption = 165.673176 pJ
sum error= 302
Actual label: 9
Output voltages: [0.23964, 0.028932, 0.059201, 0.39606, 0.053478, 0.059014, 0.0044232, 0.75658, 0.19945, 0.7982]
Predicted label: 9
Correct prediction
Energy consumption = 140.135107 pJ
sum error= 302
Actual label: 1
Output voltages: [0.032766, 0.79879, 0.56427, 0.3172, 0.0010661, 0.020449, 0.084087, 0.015417, 0.30564, 0.083102]
Predicted label: 1
Correct prediction
Energy consumption = 156.153043 pJ
sum error= 302
Actual label: 5
Output voltages: [0.11032, 0.0030568, 0.012169, 0.79696, 0.027, 0.76873, 0.051679, 0.0038292, 0.3804, 0.011259]
Predicted label: 3
Wrong prediction!
Energy consumption = 144.808202 pJ
sum error= 303
Actual label: 2
Output voltages: [0.65967, 0.001091, 0.78821, 0.038415, 0.025428, 0.001254, 0.074133, 0.49284, 0.40188, 0.017063]
Predicted label: 2
Correct prediction
Energy consumption = 133.550765 pJ
sum error= 303
Actual label: 3
Output voltages: [0.29672, 0.0080667, 0.053839, 0.79872, 0.036054, 0.033748, 0.015672, 0.028326, 0.61491, 0.13778]
Predicted label: 3
Correct prediction
Energy consumption = 146.773947 pJ
sum error= 303
Actual label: 7
Output voltages: [0.19003, 0.78887, 0.31766, 0.083865, 0.0032739, 0.0012463, 0.0053091, 0.74069, 0.52987, 0.0073625]
Predicted label: 1
Wrong prediction!
Energy consumption = 149.476361 pJ
sum error= 304
Actual label: 7
Output voltages: [0.03936, 0.49132, 0.7552, 0.22375, 0.0015924, 0.0010748, 0.0010769, 0.79878, 0.33564, 0.39888]
Predicted label: 7
Correct prediction
Energy consumption = 138.812312 pJ
sum error= 304
Actual label: 8
Output voltages: [0.026011, 0.0069319, 0.046849, 0.054164, 0.001092, 0.62627, 0.097219, 0.0056519, 0.79848, 0.015644]
Predicted label: 8
Correct prediction
Energy consumption = 148.855413 pJ
sum error= 304
Actual label: 4
Output voltages: [0.011389, 0.0022431, 0.072691, 0.014749, 0.79868, 0.0010792, 0.044367, 0.022267, 0.10315, 0.0052503]
Predicted label: 4
Correct prediction
Energy consumption = 148.780538 pJ
sum error= 304
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 658 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 658 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 658 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79876, 0.081187, 0.13578, 0.02525, 0.0031207, 0.0093706, 0.061114, 0.032164, 0.14167, 0.13609]
Predicted label: 0
Correct prediction
Energy consumption = 168.340018 pJ
sum error= 304
Actual label: 2
Output voltages: [0.53899, 0.15797, 0.79879, 0.23021, 0.21841, 0.0011655, 0.10112, 0.73115, 0.1128, 0.25301]
Predicted label: 2
Correct prediction
Energy consumption = 147.488530 pJ
sum error= 304
Actual label: 4
Output voltages: [0.0012575, 0.11429, 0.1419, 0.0062042, 0.79869, 0.0019849, 0.68753, 0.42064, 0.0013446, 0.02102]
Predicted label: 4
Correct prediction
Energy consumption = 151.516030 pJ
sum error= 304
Actual label: 0
Output voltages: [0.79877, 0.077783, 0.012258, 0.071508, 0.0019873, 0.16659, 0.26671, 0.018029, 0.028398, 0.032367]
Predicted label: 0
Correct prediction
Energy consumption = 158.264835 pJ
sum error= 304
Actual label: 2
Output voltages: [0.71215, 0.056492, 0.79875, 0.034477, 0.0011449, 0.0012423, 0.02739, 0.18516, 0.27519, 0.0406]
Predicted label: 2
Correct prediction
Energy consumption = 148.394620 pJ
sum error= 304
Actual label: 4
Output voltages: [0.0025482, 0.00379, 0.17433, 0.015803, 0.79872, 0.001451, 0.3005, 0.12486, 0.040197, 0.016234]
Predicted label: 4
Correct prediction
Energy consumption = 154.532621 pJ
sum error= 304
Actual label: 7
Output voltages: [0.050508, 0.022986, 0.10202, 0.23354, 0.015357, 0.0010699, 0.0010885, 0.79869, 0.13506, 0.18043]
Predicted label: 7
Correct prediction
Energy consumption = 153.169132 pJ
sum error= 304
Actual label: 8
Output voltages: [0.0082627, 0.25786, 0.20366, 0.028849, 0.019187, 0.038975, 0.014115, 0.28388, 0.79872, 0.025929]
Predicted label: 8
Correct prediction
Energy consumption = 149.579034 pJ
sum error= 304
Actual label: 0
Output voltages: [0.79879, 0.026874, 0.24349, 0.014126, 0.040376, 0.0022382, 0.045467, 0.010144, 0.077842, 0.13704]
Predicted label: 0
Correct prediction
Energy consumption = 154.114431 pJ
sum error= 304
Actual label: 7
Output voltages: [0.2068, 0.021321, 0.49867, 0.059507, 0.0026398, 0.001066, 0.0011114, 0.79866, 0.059517, 0.22356]
Predicted label: 7
Correct prediction
Energy consumption = 147.763632 pJ
sum error= 304
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 659 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 659 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 659 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79875, 0.026888, 0.013594, 0.16954, 0.0011295, 0.39304, 0.25942, 0.0023168, 0.051541, 0.023364]
Predicted label: 0
Correct prediction
Energy consumption = 167.202720 pJ
sum error= 304
Actual label: 6
Output voltages: [0.12789, 0.041621, 0.17844, 0.0098134, 0.21829, 0.19459, 0.79868, 0.0021589, 0.31391, 0.034567]
Predicted label: 6
Correct prediction
Energy consumption = 139.044025 pJ
sum error= 304
Actual label: 9
Output voltages: [0.053437, 0.0051963, 0.0014252, 0.14111, 0.55055, 0.64347, 0.5459, 0.023053, 0.047508, 0.78784]
Predicted label: 9
Correct prediction
Energy consumption = 150.839417 pJ
sum error= 304
Actual label: 3
Output voltages: [0.092311, 0.011889, 0.14386, 0.79869, 0.016109, 0.0093581, 0.0036103, 0.16181, 0.26929, 0.15056]
Predicted label: 3
Correct prediction
Energy consumption = 143.839862 pJ
sum error= 304
Actual label: 2
Output voltages: [0.16306, 0.003135, 0.79879, 0.34436, 0.14741, 0.0011383, 0.17492, 0.095515, 0.46997, 0.027899]
Predicted label: 2
Correct prediction
Energy consumption = 136.357386 pJ
sum error= 304
Actual label: 8
Output voltages: [0.0079452, 0.041448, 0.062229, 0.039739, 0.015225, 0.055602, 0.0021549, 0.065171, 0.79867, 0.027089]
Predicted label: 8
Correct prediction
Energy consumption = 151.713774 pJ
sum error= 304
Actual label: 6
Output voltages: [0.24102, 0.0098123, 0.19308, 0.0028091, 0.61471, 0.081259, 0.79877, 0.0012754, 0.67643, 0.0074234]
Predicted label: 6
Correct prediction
Energy consumption = 138.729684 pJ
sum error= 304
Actual label: 0
Output voltages: [0.63064, 0.19501, 0.072309, 0.48863, 0.011656, 0.0055659, 0.002106, 0.79872, 0.010138, 0.070098]
Predicted label: 7
Wrong prediction!
Energy consumption = 149.078090 pJ
sum error= 305
Actual label: 5
Output voltages: [0.21086, 0.0058759, 0.049158, 0.1186, 0.0017175, 0.7929, 0.76789, 0.0052293, 0.27711, 0.0016896]
Predicted label: 5
Correct prediction
Energy consumption = 141.566865 pJ
sum error= 305
Actual label: 7
Output voltages: [0.034433, 0.31836, 0.38243, 0.0026624, 0.0080115, 0.0010875, 0.0011288, 0.79842, 0.32441, 0.38024]
Predicted label: 7
Correct prediction
Energy consumption = 143.241893 pJ
sum error= 305
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 660 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 660 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 660 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.031216, 0.0011599, 0.0010878, 0.040411, 0.35528, 0.79876, 0.3348, 0.00633, 0.75419, 0.019116]
Predicted label: 5
Correct prediction
Energy consumption = 158.360748 pJ
sum error= 305
Actual label: 1
Output voltages: [0.13983, 0.79861, 0.51323, 0.065197, 0.060016, 0.0010697, 0.33507, 0.020481, 0.03686, 0.06094]
Predicted label: 1
Correct prediction
Energy consumption = 167.848058 pJ
sum error= 305
Actual label: 0
Output voltages: [0.79878, 0.034988, 0.058222, 0.016985, 0.010221, 0.058053, 0.33807, 0.048294, 0.57131, 0.34387]
Predicted label: 0
Correct prediction
Energy consumption = 158.747316 pJ
sum error= 305
Actual label: 8
Output voltages: [0.59458, 0.0029696, 0.082661, 0.0084971, 0.012832, 0.017602, 0.0013959, 0.056284, 0.79446, 0.56964]
Predicted label: 8
Correct prediction
Energy consumption = 147.076194 pJ
sum error= 305
Actual label: 1
Output voltages: [0.029667, 0.79849, 0.18458, 0.02941, 0.006963, 0.0030619, 0.71399, 0.0020147, 0.40088, 0.041497]
Predicted label: 1
Correct prediction
Energy consumption = 163.331832 pJ
sum error= 305
Actual label: 6
Output voltages: [0.19614, 0.027758, 0.16605, 0.0018258, 0.37325, 0.50177, 0.79877, 0.0013728, 0.2797, 0.0034633]
Predicted label: 6
Correct prediction
Energy consumption = 146.902511 pJ
sum error= 305
Actual label: 7
Output voltages: [0.028927, 0.023321, 0.23655, 0.021154, 0.028446, 0.001306, 0.0011753, 0.79858, 0.47341, 0.083722]
Predicted label: 7
Correct prediction
Energy consumption = 148.596884 pJ
sum error= 305
Actual label: 2
Output voltages: [0.61169, 0.0056542, 0.79802, 0.19422, 0.10719, 0.0010885, 0.012699, 0.018791, 0.51045, 0.0057431]
Predicted label: 2
Correct prediction
Energy consumption = 144.808220 pJ
sum error= 305
Actual label: 9
Output voltages: [0.45886, 0.0028741, 0.001095, 0.18517, 0.28169, 0.57566, 0.044194, 0.0047046, 0.052258, 0.7961]
Predicted label: 9
Correct prediction
Energy consumption = 157.514945 pJ
sum error= 305
Actual label: 7
Output voltages: [0.045127, 0.1983, 0.72524, 0.032466, 0.012021, 0.0011744, 0.0022476, 0.79879, 0.11723, 0.14084]
Predicted label: 7
Correct prediction
Energy consumption = 149.736706 pJ
sum error= 305
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 661 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 661 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 661 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.015481, 0.01581, 0.0024551, 0.50978, 0.20388, 0.64898, 0.15336, 0.0066324, 0.36382, 0.71387]
Predicted label: 9
Correct prediction
Energy consumption = 168.789024 pJ
sum error= 305
Actual label: 5
Output voltages: [0.31313, 0.0013284, 0.0010678, 0.39585, 0.16993, 0.79869, 0.33471, 0.024402, 0.65389, 0.0035003]
Predicted label: 5
Correct prediction
Energy consumption = 132.668765 pJ
sum error= 305
Actual label: 8
Output voltages: [0.017267, 0.028401, 0.35454, 0.077875, 0.0042288, 0.03496, 0.025397, 0.032951, 0.79871, 0.036094]
Predicted label: 8
Correct prediction
Energy consumption = 150.461950 pJ
sum error= 305
Actual label: 6
Output voltages: [0.42808, 0.0025254, 0.035557, 0.016073, 0.0064517, 0.21653, 0.77515, 0.78566, 0.020303, 0.059685]
Predicted label: 7
Wrong prediction!
Energy consumption = 137.886103 pJ
sum error= 306
Actual label: 2
Output voltages: [0.72195, 0.031889, 0.79873, 0.040949, 0.0018809, 0.0011473, 0.053627, 0.58618, 0.23074, 0.036261]
Predicted label: 2
Correct prediction
Energy consumption = 146.586592 pJ
sum error= 306
Actual label: 6
Output voltages: [0.036319, 0.012013, 0.3244, 0.0012652, 0.16084, 0.08319, 0.79879, 0.0024897, 0.44814, 0.0014795]
Predicted label: 6
Correct prediction
Energy consumption = 147.448049 pJ
sum error= 306
Actual label: 2
Output voltages: [0.65437, 0.0024144, 0.79877, 0.074144, 0.0019949, 0.0010662, 0.029348, 0.2157, 0.6812, 0.0094877]
Predicted label: 2
Correct prediction
Energy consumption = 143.942477 pJ
sum error= 306
Actual label: 8
Output voltages: [0.044691, 0.017075, 0.55815, 0.006922, 0.022965, 0.0046745, 0.017874, 0.0037046, 0.79878, 0.10722]
Predicted label: 8
Correct prediction
Energy consumption = 142.406691 pJ
sum error= 306
Actual label: 1
Output voltages: [0.015554, 0.79848, 0.21924, 0.03108, 0.036311, 0.0011564, 0.3814, 0.0045343, 0.41245, 0.044198]
Predicted label: 1
Correct prediction
Energy consumption = 156.829795 pJ
sum error= 306
Actual label: 7
Output voltages: [0.5023, 0.035199, 0.0055898, 0.020789, 0.19092, 0.065998, 0.0016145, 0.79877, 0.45165, 0.39567]
Predicted label: 7
Correct prediction
Energy consumption = 147.468943 pJ
sum error= 306
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 662 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 662 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 662 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.043147, 0.0010824, 0.0010979, 0.046675, 0.037973, 0.79879, 0.26719, 0.038912, 0.76733, 0.008522]
Predicted label: 5
Correct prediction
Energy consumption = 164.857737 pJ
sum error= 306
Actual label: 0
Output voltages: [0.79868, 0.020464, 0.054958, 0.065343, 0.0092098, 0.023892, 0.038605, 0.025365, 0.29136, 0.083791]
Predicted label: 0
Correct prediction
Energy consumption = 155.695114 pJ
sum error= 306
Actual label: 1
Output voltages: [0.014437, 0.79864, 0.0058877, 0.023401, 0.15225, 0.0019636, 0.35199, 0.0081829, 0.35763, 0.10245]
Predicted label: 1
Correct prediction
Energy consumption = 165.158212 pJ
sum error= 306
Actual label: 1
Output voltages: [0.024764, 0.79836, 0.050347, 0.062678, 0.0083859, 0.029512, 0.53568, 0.017088, 0.14064, 0.022804]
Predicted label: 1
Correct prediction
Energy consumption = 149.921322 pJ
sum error= 306
Actual label: 3
Output voltages: [0.20611, 0.0078396, 0.11271, 0.79868, 0.075765, 0.046324, 0.026908, 0.019605, 0.40655, 0.20384]
Predicted label: 3
Correct prediction
Energy consumption = 151.084551 pJ
sum error= 306
Actual label: 8
Output voltages: [0.014362, 0.053446, 0.5261, 0.018352, 0.0093826, 0.0011428, 0.24705, 0.15505, 0.79241, 0.038343]
Predicted label: 8
Correct prediction
Energy consumption = 147.094160 pJ
sum error= 306
Actual label: 4
Output voltages: [0.0087481, 0.016378, 0.098512, 0.046272, 0.7987, 0.0030005, 0.036629, 0.043475, 0.033943, 0.0095717]
Predicted label: 4
Correct prediction
Energy consumption = 150.459540 pJ
sum error= 306
Actual label: 9
Output voltages: [0.31827, 0.0063423, 0.009795, 0.030146, 0.53152, 0.0050305, 0.0017907, 0.0037027, 0.31002, 0.79629]
Predicted label: 9
Correct prediction
Energy consumption = 137.757873 pJ
sum error= 306
Actual label: 1
Output voltages: [0.0050434, 0.79872, 0.29861, 0.33822, 0.58006, 0.0011039, 0.016671, 0.013273, 0.014943, 0.29363]
Predicted label: 1
Correct prediction
Energy consumption = 164.784918 pJ
sum error= 306
Actual label: 8
Output voltages: [0.12134, 0.010579, 0.062693, 0.12134, 0.0053933, 0.49287, 0.013929, 0.019631, 0.79865, 0.036022]
Predicted label: 8
Correct prediction
Energy consumption = 147.532942 pJ
sum error= 306
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 663 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 663 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 663 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.063724, 0.033957, 0.32374, 0.0012238, 0.28198, 0.10669, 0.79876, 0.0016054, 0.5227, 0.0019895]
Predicted label: 6
Correct prediction
Energy consumption = 161.347202 pJ
sum error= 306
Actual label: 8
Output voltages: [0.22585, 0.035642, 0.50774, 0.0064904, 0.029028, 0.0012944, 0.016286, 0.0024741, 0.79848, 0.43256]
Predicted label: 8
Correct prediction
Energy consumption = 148.125169 pJ
sum error= 306
Actual label: 9
Output voltages: [0.15375, 0.0092674, 0.0020057, 0.014778, 0.054187, 0.3531, 0.001607, 0.03477, 0.30525, 0.77741]
Predicted label: 9
Correct prediction
Energy consumption = 152.751017 pJ
sum error= 306
Actual label: 0
Output voltages: [0.79879, 0.039648, 0.11663, 0.016305, 0.010671, 0.0072702, 0.26599, 0.016251, 0.30611, 0.019846]
Predicted label: 0
Correct prediction
Energy consumption = 152.611112 pJ
sum error= 306
Actual label: 1
Output voltages: [0.018805, 0.79857, 0.137, 0.034624, 0.21673, 0.0011815, 0.47339, 0.021758, 0.25831, 0.030555]
Predicted label: 1
Correct prediction
Energy consumption = 161.640498 pJ
sum error= 306
Actual label: 2
Output voltages: [0.061247, 0.044779, 0.79878, 0.086043, 0.011207, 0.0011699, 0.3237, 0.31107, 0.51998, 0.01171]
Predicted label: 2
Correct prediction
Energy consumption = 143.373805 pJ
sum error= 306
Actual label: 3
Output voltages: [0.51646, 0.012778, 0.037269, 0.79876, 0.0030412, 0.01732, 0.0086077, 0.010719, 0.76585, 0.0080957]
Predicted label: 3
Correct prediction
Energy consumption = 142.733309 pJ
sum error= 306
Actual label: 4
Output voltages: [0.046035, 0.043799, 0.047973, 0.026871, 0.79874, 0.0010663, 0.043616, 0.17039, 0.1396, 0.039099]
Predicted label: 4
Correct prediction
Energy consumption = 150.685579 pJ
sum error= 306
Actual label: 5
Output voltages: [0.022166, 0.0010997, 0.0030932, 0.46493, 0.057934, 0.79868, 0.54074, 0.29001, 0.72001, 0.028523]
Predicted label: 5
Correct prediction
Energy consumption = 149.801134 pJ
sum error= 306
Actual label: 6
Output voltages: [0.035585, 0.043436, 0.42178, 0.0037902, 0.16986, 0.14992, 0.79879, 0.0020773, 0.74733, 0.016207]
Predicted label: 6
Correct prediction
Energy consumption = 144.251207 pJ
sum error= 306
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 664 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 664 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 664 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.15725, 0.18125, 0.2206, 0.037906, 0.0269, 0.0011339, 0.0010669, 0.79857, 0.085811, 0.034318]
Predicted label: 7
Correct prediction
Energy consumption = 166.425599 pJ
sum error= 306
Actual label: 8
Output voltages: [0.028631, 0.013909, 0.10267, 0.29752, 0.0010982, 0.21169, 0.011941, 0.0016336, 0.79878, 0.035594]
Predicted label: 8
Correct prediction
Energy consumption = 149.083441 pJ
sum error= 306
Actual label: 9
Output voltages: [0.01555, 0.015893, 0.0010851, 0.086249, 0.5905, 0.46691, 0.0014127, 0.013936, 0.32279, 0.74211]
Predicted label: 9
Correct prediction
Energy consumption = 145.512073 pJ
sum error= 306
Actual label: 0
Output voltages: [0.79872, 0.048693, 0.049526, 0.018767, 0.0019594, 0.0058122, 0.16199, 0.24893, 0.25709, 0.022708]
Predicted label: 0
Correct prediction
Energy consumption = 150.004931 pJ
sum error= 306
Actual label: 1
Output voltages: [0.044112, 0.79876, 0.14893, 0.012683, 0.29678, 0.001066, 0.26111, 0.0015085, 0.035648, 0.016122]
Predicted label: 1
Correct prediction
Energy consumption = 155.401245 pJ
sum error= 306
Actual label: 2
Output voltages: [0.14033, 0.064882, 0.79876, 0.030775, 0.025719, 0.0011295, 0.034709, 0.031125, 0.51061, 0.028138]
Predicted label: 2
Correct prediction
Energy consumption = 143.495982 pJ
sum error= 306
Actual label: 3
Output voltages: [0.069184, 0.0058554, 0.048716, 0.79871, 0.018501, 0.040352, 0.026103, 0.033743, 0.75425, 0.02967]
Predicted label: 3
Correct prediction
Energy consumption = 141.228966 pJ
sum error= 306
Actual label: 4
Output voltages: [0.0053901, 0.0059884, 0.038536, 0.0082369, 0.79864, 0.0012053, 0.068372, 0.10936, 0.035596, 0.0042471]
Predicted label: 4
Correct prediction
Energy consumption = 148.962329 pJ
sum error= 306
Actual label: 7
Output voltages: [0.18737, 0.050904, 0.75927, 0.034623, 0.011663, 0.0010668, 0.0010666, 0.79872, 0.17563, 0.24144]
Predicted label: 7
Correct prediction
Energy consumption = 148.868018 pJ
sum error= 306
Actual label: 8
Output voltages: [0.021245, 0.021056, 0.055274, 0.15782, 0.0022307, 0.060756, 0.026259, 0.00335, 0.79874, 0.063926]
Predicted label: 8
Correct prediction
Energy consumption = 146.940529 pJ
sum error= 306
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 665 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 665 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 665 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.12452, 0.0039469, 0.0047095, 0.026932, 0.20008, 0.0082867, 0.0037165, 0.015074, 0.70705, 0.79847]
Predicted label: 9
Correct prediction
Energy consumption = 157.432868 pJ
sum error= 306
Actual label: 0
Output voltages: [0.67833, 0.77649, 0.39867, 0.011434, 0.36005, 0.0095922, 0.078106, 0.0041828, 0.20289, 0.010008]
Predicted label: 1
Wrong prediction!
Energy consumption = 150.162999 pJ
sum error= 307
Actual label: 1
Output voltages: [0.021868, 0.79847, 0.20263, 0.0048385, 0.38297, 0.0010782, 0.3145, 0.0018393, 0.17866, 0.017079]
Predicted label: 1
Correct prediction
Energy consumption = 141.678027 pJ
sum error= 307
Actual label: 7
Output voltages: [0.19833, 0.062588, 0.57256, 0.0076869, 0.019383, 0.0010674, 0.0015843, 0.79861, 0.08542, 0.047022]
Predicted label: 7
Correct prediction
Energy consumption = 141.455504 pJ
sum error= 307
Actual label: 8
Output voltages: [0.021387, 0.016136, 0.050283, 0.57153, 0.0014003, 0.37521, 0.029941, 0.002652, 0.79879, 0.053128]
Predicted label: 8
Correct prediction
Energy consumption = 148.473837 pJ
sum error= 307
Actual label: 9
Output voltages: [0.049551, 0.0040598, 0.017473, 0.018794, 0.031094, 0.016452, 0.0011929, 0.050572, 0.78298, 0.79107]
Predicted label: 9
Correct prediction
Energy consumption = 137.437949 pJ
sum error= 307
Actual label: 9
Output voltages: [0.049952, 0.0039937, 0.020798, 0.023462, 0.057333, 0.0086905, 0.0014908, 0.038706, 0.77328, 0.79243]
Predicted label: 9
Correct prediction
Energy consumption = 130.464183 pJ
sum error= 307
Actual label: 8
Output voltages: [0.029398, 0.014757, 0.029176, 0.58302, 0.0012333, 0.66675, 0.019634, 0.0072741, 0.79879, 0.076315]
Predicted label: 8
Correct prediction
Energy consumption = 143.055518 pJ
sum error= 307
Actual label: 9
Output voltages: [0.055015, 0.010618, 0.019049, 0.019563, 0.047657, 0.0056526, 0.0015918, 0.024122, 0.77807, 0.79747]
Predicted label: 9
Correct prediction
Energy consumption = 139.743967 pJ
sum error= 307
Actual label: 8
Output voltages: [0.29081, 0.021856, 0.13726, 0.034802, 0.057509, 0.099884, 0.019713, 0.0043375, 0.79879, 0.034753]
Predicted label: 8
Correct prediction
Energy consumption = 139.074794 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 666 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 666 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 666 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0078676, 0.02499, 0.080228, 0.030325, 0.79874, 0.015624, 0.05248, 0.13432, 0.039302, 0.0087941]
Predicted label: 4
Correct prediction
Energy consumption = 163.671853 pJ
sum error= 307
Actual label: 1
Output voltages: [0.0080679, 0.79867, 0.040815, 0.027783, 0.028436, 0.0024327, 0.42741, 0.0014033, 0.39909, 0.026696]
Predicted label: 1
Correct prediction
Energy consumption = 145.945271 pJ
sum error= 307
Actual label: 7
Output voltages: [0.40551, 0.047846, 0.74396, 0.069832, 0.0010804, 0.0010713, 0.0012462, 0.79877, 0.45207, 0.025303]
Predicted label: 7
Correct prediction
Energy consumption = 149.840051 pJ
sum error= 307
Actual label: 7
Output voltages: [0.056633, 0.04429, 0.69892, 0.0092291, 0.009971, 0.0010705, 0.002385, 0.7986, 0.26494, 0.060018]
Predicted label: 7
Correct prediction
Energy consumption = 132.772219 pJ
sum error= 307
Actual label: 3
Output voltages: [0.48004, 0.0010664, 0.46534, 0.79819, 0.02526, 0.0094382, 0.0041469, 0.0054253, 0.51341, 0.002706]
Predicted label: 3
Correct prediction
Energy consumption = 140.288340 pJ
sum error= 307
Actual label: 3
Output voltages: [0.18053, 0.021236, 0.030582, 0.79871, 0.0021838, 0.012543, 0.0046533, 0.19532, 0.69041, 0.024878]
Predicted label: 3
Correct prediction
Energy consumption = 132.399159 pJ
sum error= 307
Actual label: 7
Output voltages: [0.3424, 0.010429, 0.036343, 0.041939, 0.024841, 0.0063487, 0.0020199, 0.79871, 0.045288, 0.54077]
Predicted label: 7
Correct prediction
Energy consumption = 137.894434 pJ
sum error= 307
Actual label: 6
Output voltages: [0.51232, 0.00287, 0.003134, 0.11661, 0.026159, 0.77208, 0.79253, 0.0011635, 0.64458, 0.14163]
Predicted label: 6
Correct prediction
Energy consumption = 142.180885 pJ
sum error= 307
Actual label: 6
Output voltages: [0.19623, 0.0012239, 0.032501, 0.0088441, 0.41518, 0.6376, 0.79603, 0.0010659, 0.75383, 0.010274]
Predicted label: 6
Correct prediction
Energy consumption = 135.705099 pJ
sum error= 307
Actual label: 6
Output voltages: [0.12345, 0.0025511, 0.015084, 0.02093, 0.17242, 0.66868, 0.79735, 0.0011928, 0.60436, 0.08635]
Predicted label: 6
Correct prediction
Energy consumption = 132.275907 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 667 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 667 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 667 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0024443, 0.79879, 0.02514, 0.21356, 0.25048, 0.0010686, 0.061088, 0.009719, 0.087467, 0.058612]
Predicted label: 1
Correct prediction
Energy consumption = 170.238527 pJ
sum error= 307
Actual label: 9
Output voltages: [0.26768, 0.028395, 0.019348, 0.064938, 0.25196, 0.036141, 0.0047508, 0.013196, 0.58588, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 148.948562 pJ
sum error= 307
Actual label: 0
Output voltages: [0.79764, 0.029052, 0.026692, 0.00524, 0.024478, 0.0067014, 0.74105, 0.17998, 0.041132, 0.20133]
Predicted label: 0
Correct prediction
Energy consumption = 144.254560 pJ
sum error= 307
Actual label: 1
Output voltages: [0.019796, 0.79708, 0.0061762, 0.0016989, 0.33637, 0.0011017, 0.018686, 0.0039302, 0.72799, 0.054033]
Predicted label: 1
Correct prediction
Energy consumption = 147.223420 pJ
sum error= 307
Actual label: 7
Output voltages: [0.23701, 0.013535, 0.017932, 0.093709, 0.020526, 0.018403, 0.0010781, 0.79857, 0.072373, 0.34351]
Predicted label: 7
Correct prediction
Energy consumption = 147.062010 pJ
sum error= 307
Actual label: 6
Output voltages: [0.27705, 0.028159, 0.15807, 0.0026332, 0.2935, 0.037181, 0.79755, 0.001095, 0.75796, 0.0048621]
Predicted label: 6
Correct prediction
Energy consumption = 146.926582 pJ
sum error= 307
Actual label: 3
Output voltages: [0.39768, 0.0034985, 0.33574, 0.79878, 0.027962, 0.018104, 0.0017677, 0.0068649, 0.65715, 0.008732]
Predicted label: 3
Correct prediction
Energy consumption = 143.568802 pJ
sum error= 307
Actual label: 2
Output voltages: [0.061858, 0.035237, 0.79879, 0.11043, 0.0060971, 0.001156, 0.006361, 0.76014, 0.5937, 0.011389]
Predicted label: 2
Correct prediction
Energy consumption = 132.000599 pJ
sum error= 307
Actual label: 1
Output voltages: [0.033188, 0.79872, 0.01221, 0.0083147, 0.37081, 0.011641, 0.21132, 0.011683, 0.34022, 0.070741]
Predicted label: 1
Correct prediction
Energy consumption = 162.048796 pJ
sum error= 307
Actual label: 7
Output voltages: [0.04109, 0.063922, 0.2755, 0.046256, 0.002184, 0.0019554, 0.0012543, 0.79879, 0.38323, 0.31584]
Predicted label: 7
Correct prediction
Energy consumption = 141.165776 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 668 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 668 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 668 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.026201, 0.7987, 0.0020374, 0.025259, 0.24939, 0.01075, 0.25657, 0.010242, 0.052094, 0.042112]
Predicted label: 1
Correct prediction
Energy consumption = 173.269042 pJ
sum error= 307
Actual label: 3
Output voltages: [0.69524, 0.012189, 0.19316, 0.79868, 0.0051063, 0.027474, 0.019884, 0.015541, 0.54245, 0.011933]
Predicted label: 3
Correct prediction
Energy consumption = 146.697898 pJ
sum error= 307
Actual label: 9
Output voltages: [0.38005, 0.035423, 0.013802, 0.063202, 0.21385, 0.019668, 0.0029735, 0.0051947, 0.26939, 0.79806]
Predicted label: 9
Correct prediction
Energy consumption = 146.353106 pJ
sum error= 307
Actual label: 1
Output voltages: [0.018737, 0.79874, 0.036693, 0.0072449, 0.25872, 0.0012324, 0.26176, 0.020661, 0.11897, 0.022819]
Predicted label: 1
Correct prediction
Energy consumption = 158.087021 pJ
sum error= 307
Actual label: 7
Output voltages: [0.16312, 0.40296, 0.70743, 0.019603, 0.032426, 0.001154, 0.0013125, 0.79877, 0.025141, 0.046638]
Predicted label: 7
Correct prediction
Energy consumption = 144.072104 pJ
sum error= 307
Actual label: 6
Output voltages: [0.099829, 0.013626, 0.31745, 0.0010695, 0.32514, 0.31022, 0.79877, 0.001791, 0.63581, 0.0033545]
Predicted label: 6
Correct prediction
Energy consumption = 148.937990 pJ
sum error= 307
Actual label: 8
Output voltages: [0.13811, 0.07177, 0.027935, 0.46157, 0.0044312, 0.19071, 0.051759, 0.0032724, 0.79876, 0.018595]
Predicted label: 8
Correct prediction
Energy consumption = 142.973715 pJ
sum error= 307
Actual label: 4
Output voltages: [0.0082393, 0.034417, 0.044878, 0.026174, 0.79873, 0.002079, 0.048351, 0.16968, 0.010186, 0.026636]
Predicted label: 4
Correct prediction
Energy consumption = 148.885417 pJ
sum error= 307
Actual label: 1
Output voltages: [0.030667, 0.79667, 0.048723, 0.0046775, 0.50506, 0.0011737, 0.013068, 0.013511, 0.05143, 0.019114]
Predicted label: 1
Correct prediction
Energy consumption = 142.404348 pJ
sum error= 307
Actual label: 4
Output voltages: [0.030329, 0.004844, 0.11388, 0.0289, 0.79873, 0.029924, 0.43512, 0.026781, 0.055166, 0.0027671]
Predicted label: 4
Correct prediction
Energy consumption = 135.223706 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 669 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 669 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 669 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.021871, 0.029204, 0.065689, 0.79879, 0.025084, 0.033139, 0.0023755, 0.039677, 0.79315, 0.021355]
Predicted label: 3
Correct prediction
Energy consumption = 155.948766 pJ
sum error= 307
Actual label: 6
Output voltages: [0.11217, 0.023003, 0.054108, 0.012163, 0.19904, 0.42195, 0.7941, 0.00107, 0.78673, 0.010094]
Predicted label: 6
Correct prediction
Energy consumption = 145.996500 pJ
sum error= 307
Actual label: 9
Output voltages: [0.30722, 0.002406, 0.002868, 0.024574, 0.1399, 0.041454, 0.0012525, 0.062157, 0.45429, 0.79781]
Predicted label: 9
Correct prediction
Energy consumption = 141.527638 pJ
sum error= 307
Actual label: 6
Output voltages: [0.27226, 0.013133, 0.049595, 0.0052634, 0.43789, 0.048469, 0.79859, 0.001239, 0.70057, 0.0085709]
Predicted label: 6
Correct prediction
Energy consumption = 140.906653 pJ
sum error= 307
Actual label: 1
Output voltages: [0.049406, 0.79787, 0.3762, 0.030099, 0.46673, 0.0010663, 0.090466, 0.017441, 0.21354, 0.0022938]
Predicted label: 1
Correct prediction
Energy consumption = 149.480411 pJ
sum error= 307
Actual label: 4
Output voltages: [0.015662, 0.0012517, 0.48262, 0.034292, 0.79877, 0.0011319, 0.0016016, 0.01328, 0.23224, 0.041831]
Predicted label: 4
Correct prediction
Energy consumption = 143.337811 pJ
sum error= 307
Actual label: 4
Output voltages: [0.015245, 0.0076684, 0.24484, 0.061181, 0.79878, 0.0010789, 0.014645, 0.046818, 0.022178, 0.02404]
Predicted label: 4
Correct prediction
Energy consumption = 138.753657 pJ
sum error= 307
Actual label: 7
Output voltages: [0.21913, 0.034703, 0.13245, 0.26418, 0.0016524, 0.001736, 0.0011571, 0.79873, 0.30019, 0.25617]
Predicted label: 7
Correct prediction
Energy consumption = 148.141764 pJ
sum error= 307
Actual label: 2
Output voltages: [0.54284, 0.0094446, 0.79874, 0.032547, 0.021965, 0.0010879, 0.029796, 0.02955, 0.47021, 0.0036066]
Predicted label: 2
Correct prediction
Energy consumption = 143.670446 pJ
sum error= 307
Actual label: 4
Output voltages: [0.0064132, 0.12322, 0.23214, 0.040025, 0.79877, 0.0010696, 0.034087, 0.079358, 0.0020022, 0.48301]
Predicted label: 4
Correct prediction
Energy consumption = 150.707317 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 670 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 670 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 670 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.25982, 0.1085, 0.069014, 0.0050484, 0.79878, 0.0040681, 0.56701, 0.0026199, 0.03741, 0.044519]
Predicted label: 4
Correct prediction
Energy consumption = 164.723143 pJ
sum error= 307
Actual label: 0
Output voltages: [0.79843, 0.033961, 0.04083, 0.01078, 0.016473, 0.0013574, 0.66562, 0.030691, 0.30296, 0.043786]
Predicted label: 0
Correct prediction
Energy consumption = 153.104909 pJ
sum error= 307
Actual label: 1
Output voltages: [0.0026157, 0.79851, 0.034827, 0.018176, 0.0061598, 0.0022077, 0.70231, 0.014301, 0.42279, 0.018822]
Predicted label: 1
Correct prediction
Energy consumption = 158.777797 pJ
sum error= 307
Actual label: 2
Output voltages: [0.59894, 0.010657, 0.79877, 0.195, 0.013585, 0.0011277, 0.013778, 0.044755, 0.45206, 0.0046975]
Predicted label: 2
Correct prediction
Energy consumption = 146.314908 pJ
sum error= 307
Actual label: 3
Output voltages: [0.57053, 0.0074379, 0.48753, 0.79879, 0.0039875, 0.0013043, 0.0016353, 0.0056493, 0.56841, 0.0068527]
Predicted label: 3
Correct prediction
Energy consumption = 132.759993 pJ
sum error= 307
Actual label: 4
Output voltages: [0.035675, 0.0090744, 0.16872, 0.0018581, 0.79867, 0.026347, 0.15453, 0.04989, 0.17163, 0.0052125]
Predicted label: 4
Correct prediction
Energy consumption = 153.902072 pJ
sum error= 307
Actual label: 5
Output voltages: [0.02988, 0.0018843, 0.0095703, 0.55193, 0.020448, 0.79015, 0.036738, 0.23568, 0.44323, 0.66082]
Predicted label: 5
Correct prediction
Energy consumption = 137.387978 pJ
sum error= 307
Actual label: 6
Output voltages: [0.14613, 0.035194, 0.29633, 0.0017242, 0.34924, 0.049221, 0.79879, 0.0012585, 0.29543, 0.0054074]
Predicted label: 6
Correct prediction
Energy consumption = 144.079741 pJ
sum error= 307
Actual label: 7
Output voltages: [0.42404, 0.012548, 0.2585, 0.025828, 0.016763, 0.0011282, 0.0012163, 0.79798, 0.62316, 0.35932]
Predicted label: 7
Correct prediction
Energy consumption = 144.943317 pJ
sum error= 307
Actual label: 8
Output voltages: [0.011547, 0.025256, 0.019537, 0.026697, 0.010955, 0.09107, 0.3807, 0.0098902, 0.79866, 0.0089771]
Predicted label: 8
Correct prediction
Energy consumption = 139.875927 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 671 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 671 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 671 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.74938, 0.008235, 0.0061751, 0.030095, 0.039038, 0.01845, 0.048866, 0.010955, 0.33177, 0.79693]
Predicted label: 9
Correct prediction
Energy consumption = 166.222526 pJ
sum error= 307
Actual label: 0
Output voltages: [0.79875, 0.074795, 0.13577, 0.033691, 0.0077316, 0.0017758, 0.18673, 0.012924, 0.33225, 0.063731]
Predicted label: 0
Correct prediction
Energy consumption = 145.227716 pJ
sum error= 307
Actual label: 1
Output voltages: [0.028872, 0.79863, 0.28103, 0.0050543, 0.15056, 0.0038474, 0.45722, 0.0016247, 0.10725, 0.014161]
Predicted label: 1
Correct prediction
Energy consumption = 154.809166 pJ
sum error= 307
Actual label: 2
Output voltages: [0.60653, 0.0027981, 0.79875, 0.14654, 0.010258, 0.0010905, 0.025897, 0.087984, 0.70361, 0.0050047]
Predicted label: 2
Correct prediction
Energy consumption = 144.288590 pJ
sum error= 307
Actual label: 3
Output voltages: [0.21409, 0.027455, 0.03619, 0.79859, 0.015348, 0.017246, 0.010595, 0.021528, 0.54731, 0.047364]
Predicted label: 3
Correct prediction
Energy consumption = 136.835834 pJ
sum error= 307
Actual label: 4
Output voltages: [0.034028, 0.010259, 0.045065, 0.0065155, 0.79875, 0.0045587, 0.36176, 0.030517, 0.1172, 0.0028738]
Predicted label: 4
Correct prediction
Energy consumption = 145.120761 pJ
sum error= 307
Actual label: 5
Output voltages: [0.053692, 0.0017345, 0.0010889, 0.25786, 0.34872, 0.79878, 0.58396, 0.0026387, 0.40299, 0.033829]
Predicted label: 5
Correct prediction
Energy consumption = 133.552375 pJ
sum error= 307
Actual label: 6
Output voltages: [0.038521, 0.028589, 0.38859, 0.0011822, 0.3939, 0.037134, 0.79876, 0.001076, 0.27144, 0.0045388]
Predicted label: 6
Correct prediction
Energy consumption = 138.790284 pJ
sum error= 307
Actual label: 9
Output voltages: [0.25441, 0.0020922, 0.014988, 0.0093209, 0.10029, 0.017557, 0.030024, 0.0066456, 0.68326, 0.77884]
Predicted label: 9
Correct prediction
Energy consumption = 140.596471 pJ
sum error= 307
Actual label: 0
Output voltages: [0.79877, 0.036918, 0.072502, 0.029417, 0.021565, 0.0030308, 0.50255, 0.026659, 0.060571, 0.33368]
Predicted label: 0
Correct prediction
Energy consumption = 137.680203 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 672 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 672 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 672 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0084663, 0.79878, 0.014384, 0.060308, 0.75636, 0.0011094, 0.07493, 0.0011778, 0.042653, 0.33922]
Predicted label: 1
Correct prediction
Energy consumption = 176.530611 pJ
sum error= 307
Actual label: 2
Output voltages: [0.021561, 0.023824, 0.79878, 0.069491, 0.048015, 0.0012017, 0.028469, 0.6222, 0.40333, 0.046286]
Predicted label: 2
Correct prediction
Energy consumption = 132.279903 pJ
sum error= 307
Actual label: 3
Output voltages: [0.63543, 0.0032297, 0.44543, 0.79879, 0.0066255, 0.0065057, 0.0014252, 0.0012997, 0.60282, 0.0069606]
Predicted label: 3
Correct prediction
Energy consumption = 136.538448 pJ
sum error= 307
Actual label: 4
Output voltages: [0.017857, 0.018187, 0.21457, 0.0030167, 0.79865, 0.0011301, 0.27147, 0.046529, 0.03016, 0.014536]
Predicted label: 4
Correct prediction
Energy consumption = 142.328190 pJ
sum error= 307
Actual label: 7
Output voltages: [0.042454, 0.05381, 0.041484, 0.13477, 0.0083858, 0.0011102, 0.0011276, 0.79878, 0.42595, 0.50251]
Predicted label: 7
Correct prediction
Energy consumption = 146.069320 pJ
sum error= 307
Actual label: 8
Output voltages: [0.017025, 0.010144, 0.22676, 0.016685, 0.19612, 0.0056452, 0.32505, 0.0010684, 0.79863, 0.1135]
Predicted label: 8
Correct prediction
Energy consumption = 134.599980 pJ
sum error= 307
Actual label: 1
Output voltages: [0.030071, 0.79872, 0.27233, 0.020804, 0.43969, 0.002419, 0.11648, 0.0129, 0.052582, 0.01263]
Predicted label: 1
Correct prediction
Energy consumption = 157.686053 pJ
sum error= 307
Actual label: 3
Output voltages: [0.039362, 0.009501, 0.037952, 0.79871, 0.050214, 0.0022324, 0.013283, 0.18892, 0.73886, 0.041448]
Predicted label: 3
Correct prediction
Energy consumption = 144.919083 pJ
sum error= 307
Actual label: 5
Output voltages: [0.25515, 0.0012465, 0.0014313, 0.46734, 0.0094018, 0.79869, 0.26064, 0.060656, 0.74944, 0.0061045]
Predicted label: 5
Correct prediction
Energy consumption = 146.076089 pJ
sum error= 307
Actual label: 1
Output voltages: [0.008428, 0.79849, 0.043099, 0.016584, 0.050797, 0.0016291, 0.66189, 0.021512, 0.23681, 0.022322]
Predicted label: 1
Correct prediction
Energy consumption = 151.740149 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 673 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 673 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 673 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.03934, 0.026418, 0.18279, 0.13063, 0.033999, 0.001117, 0.001213, 0.79871, 0.54271, 0.15104]
Predicted label: 7
Correct prediction
Energy consumption = 155.693435 pJ
sum error= 307
Actual label: 7
Output voltages: [0.056369, 0.47251, 0.14503, 0.1611, 0.022102, 0.0012987, 0.0011172, 0.79879, 0.051685, 0.42504]
Predicted label: 7
Correct prediction
Energy consumption = 131.500376 pJ
sum error= 307
Actual label: 2
Output voltages: [0.23725, 0.025913, 0.79874, 0.33114, 0.035637, 0.0012103, 0.020943, 0.14238, 0.15906, 0.029358]
Predicted label: 2
Correct prediction
Energy consumption = 132.479487 pJ
sum error= 307
Actual label: 1
Output voltages: [0.016319, 0.79874, 0.10448, 0.0099071, 0.056013, 0.01844, 0.51676, 0.0018187, 0.46088, 0.014968]
Predicted label: 1
Correct prediction
Energy consumption = 148.107539 pJ
sum error= 307
Actual label: 4
Output voltages: [0.024424, 0.030373, 0.09413, 0.0075153, 0.79872, 0.0078249, 0.35883, 0.059032, 0.09976, 0.0084045]
Predicted label: 4
Correct prediction
Energy consumption = 143.038406 pJ
sum error= 307
Actual label: 8
Output voltages: [0.30805, 0.096452, 0.024943, 0.028064, 0.015049, 0.048565, 0.12624, 0.0018476, 0.79879, 0.029261]
Predicted label: 8
Correct prediction
Energy consumption = 148.453408 pJ
sum error= 307
Actual label: 3
Output voltages: [0.36853, 0.0052867, 0.12038, 0.79875, 0.044843, 0.030096, 0.0068415, 0.0031334, 0.57043, 0.032248]
Predicted label: 3
Correct prediction
Energy consumption = 145.705290 pJ
sum error= 307
Actual label: 4
Output voltages: [0.055482, 0.0021779, 0.14735, 0.0013446, 0.79873, 0.0035779, 0.2355, 0.020049, 0.37208, 0.0011744]
Predicted label: 4
Correct prediction
Energy consumption = 144.762011 pJ
sum error= 307
Actual label: 4
Output voltages: [0.0045306, 0.038823, 0.045429, 0.0099878, 0.79865, 0.027288, 0.3751, 0.3873, 0.019609, 0.010375]
Predicted label: 4
Correct prediction
Energy consumption = 140.593482 pJ
sum error= 307
Actual label: 3
Output voltages: [0.28896, 0.0012443, 0.42498, 0.79869, 0.0010998, 0.036451, 0.0011409, 0.028442, 0.78791, 0.0068]
Predicted label: 3
Correct prediction
Energy consumption = 138.958509 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 674 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 674 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 674 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.77275, 0.0012193, 0.029942, 0.042172, 0.0073194, 0.016535, 0.039315, 0.0244, 0.19686, 0.7581]
Predicted label: 0
Wrong prediction!
Energy consumption = 162.273951 pJ
sum error= 308
Actual label: 7
Output voltages: [0.32306, 0.0077681, 0.029947, 0.079824, 0.024174, 0.0068728, 0.001332, 0.79879, 0.52181, 0.54896]
Predicted label: 7
Correct prediction
Energy consumption = 136.729154 pJ
sum error= 308
Actual label: 4
Output voltages: [0.023105, 0.0073969, 0.23237, 0.018993, 0.79861, 0.0011581, 0.038964, 0.015947, 0.031884, 0.027547]
Predicted label: 4
Correct prediction
Energy consumption = 144.243151 pJ
sum error= 308
Actual label: 1
Output voltages: [0.052345, 0.79838, 0.30252, 0.035499, 0.40939, 0.0011118, 0.086141, 0.0041927, 0.030435, 0.014818]
Predicted label: 1
Correct prediction
Energy consumption = 148.538260 pJ
sum error= 308
Actual label: 2
Output voltages: [0.016414, 0.0029683, 0.79658, 0.1283, 0.0048572, 0.0010902, 0.050218, 0.78793, 0.76869, 0.0023098]
Predicted label: 2
Correct prediction
Energy consumption = 135.444410 pJ
sum error= 308
Actual label: 3
Output voltages: [0.26309, 0.0041679, 0.053689, 0.79876, 0.038472, 0.097683, 0.027239, 0.006071, 0.37175, 0.02358]
Predicted label: 3
Correct prediction
Energy consumption = 145.624273 pJ
sum error= 308
Actual label: 5
Output voltages: [0.026288, 0.001074, 0.004061, 0.030904, 0.22067, 0.78206, 0.55315, 0.0016517, 0.73899, 0.0017097]
Predicted label: 5
Correct prediction
Energy consumption = 124.481532 pJ
sum error= 308
Actual label: 9
Output voltages: [0.44943, 0.0018573, 0.013321, 0.055854, 0.49408, 0.0027653, 0.0028061, 0.0012069, 0.57163, 0.78145]
Predicted label: 9
Correct prediction
Energy consumption = 143.855447 pJ
sum error= 308
Actual label: 1
Output voltages: [0.0065804, 0.79853, 0.054916, 0.0032086, 0.12557, 0.0013788, 0.43556, 0.0013706, 0.54578, 0.11993]
Predicted label: 1
Correct prediction
Energy consumption = 152.598587 pJ
sum error= 308
Actual label: 6
Output voltages: [0.2857, 0.026062, 0.034573, 0.051862, 0.27475, 0.46369, 0.79868, 0.0053957, 0.63142, 0.019005]
Predicted label: 6
Correct prediction
Energy consumption = 141.479601 pJ
sum error= 308
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 675 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 675 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 675 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.029177, 0.12773, 0.003848, 0.0037433, 0.0023961, 0.55953, 0.030816, 0.11254, 0.30279]
Predicted label: 0
Correct prediction
Energy consumption = 161.214890 pJ
sum error= 308
Actual label: 1
Output voltages: [0.16936, 0.79681, 0.15103, 0.0083553, 0.6312, 0.0013419, 0.042294, 0.0015664, 0.089412, 0.19495]
Predicted label: 1
Correct prediction
Energy consumption = 157.559260 pJ
sum error= 308
Actual label: 0
Output voltages: [0.79879, 0.17086, 0.094377, 0.02234, 0.0080856, 0.0021818, 0.40785, 0.014758, 0.10177, 0.14808]
Predicted label: 0
Correct prediction
Energy consumption = 143.412219 pJ
sum error= 308
Actual label: 0
Output voltages: [0.79873, 0.11468, 0.047498, 0.010628, 0.013427, 0.0085985, 0.49419, 0.017463, 0.069342, 0.052023]
Predicted label: 0
Correct prediction
Energy consumption = 132.253545 pJ
sum error= 308
Actual label: 2
Output voltages: [0.034486, 0.014397, 0.7966, 0.51423, 0.090215, 0.0013647, 0.010197, 0.53632, 0.13762, 0.035502]
Predicted label: 2
Correct prediction
Energy consumption = 141.753063 pJ
sum error= 308
Actual label: 8
Output voltages: [0.15162, 0.027577, 0.1644, 0.036787, 0.016148, 0.0045272, 0.0045906, 0.0081421, 0.79877, 0.5781]
Predicted label: 8
Correct prediction
Energy consumption = 149.378201 pJ
sum error= 308
Actual label: 7
Output voltages: [0.29335, 0.004403, 0.7358, 0.057058, 0.008524, 0.001081, 0.0010666, 0.76388, 0.78123, 0.24788]
Predicted label: 8
Wrong prediction!
Energy consumption = 130.989124 pJ
sum error= 309
Actual label: 1
Output voltages: [0.15756, 0.7986, 0.29029, 0.041078, 0.12271, 0.0013812, 0.42158, 0.0013627, 0.0971, 0.042096]
Predicted label: 1
Correct prediction
Energy consumption = 150.279898 pJ
sum error= 309
Actual label: 1
Output voltages: [0.018218, 0.79803, 0.19774, 0.038741, 0.1949, 0.001228, 0.41971, 0.00602, 0.033111, 0.23951]
Predicted label: 1
Correct prediction
Energy consumption = 136.378472 pJ
sum error= 309
Actual label: 4
Output voltages: [0.027745, 0.0015695, 0.27873, 0.0010672, 0.79877, 0.0017617, 0.20515, 0.032572, 0.36812, 0.0039885]
Predicted label: 4
Correct prediction
Energy consumption = 135.520618 pJ
sum error= 309
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 676 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 676 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 676 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79773, 0.044011, 0.018317, 0.01268, 0.0079356, 0.0079805, 0.77916, 0.0079219, 0.30978, 0.12383]
Predicted label: 0
Correct prediction
Energy consumption = 160.752787 pJ
sum error= 309
Actual label: 4
Output voltages: [0.022111, 0.0049167, 0.027925, 0.027909, 0.79876, 0.0017472, 0.20081, 0.018, 0.048204, 0.0020191]
Predicted label: 4
Correct prediction
Energy consumption = 141.465447 pJ
sum error= 309
Actual label: 7
Output voltages: [0.22811, 0.018169, 0.75311, 0.070427, 0.0025585, 0.00112, 0.0011001, 0.79868, 0.61395, 0.17562]
Predicted label: 7
Correct prediction
Energy consumption = 146.304167 pJ
sum error= 309
Actual label: 3
Output voltages: [0.66481, 0.0020389, 0.32114, 0.79874, 0.048278, 0.02476, 0.0012729, 0.0014785, 0.57018, 0.013048]
Predicted label: 3
Correct prediction
Energy consumption = 143.423875 pJ
sum error= 309
Actual label: 6
Output voltages: [0.044878, 0.0020105, 0.069591, 0.0056505, 0.29923, 0.40674, 0.79879, 0.0012546, 0.47397, 0.015583]
Predicted label: 6
Correct prediction
Energy consumption = 146.583745 pJ
sum error= 309
Actual label: 8
Output voltages: [0.27217, 0.0022286, 0.002666, 0.05814, 0.30167, 0.33366, 0.63578, 0.0011114, 0.79564, 0.0050659]
Predicted label: 8
Correct prediction
Energy consumption = 131.153340 pJ
sum error= 309
Actual label: 0
Output voltages: [0.79876, 0.040926, 0.044816, 0.024396, 0.020128, 0.0076474, 0.29854, 0.015258, 0.13299, 0.26736]
Predicted label: 0
Correct prediction
Energy consumption = 146.295795 pJ
sum error= 309
Actual label: 3
Output voltages: [0.67756, 0.002972, 0.25246, 0.79877, 0.0068285, 0.023287, 0.011662, 0.045757, 0.75656, 0.0029473]
Predicted label: 3
Correct prediction
Energy consumption = 143.283817 pJ
sum error= 309
Actual label: 7
Output voltages: [0.010918, 0.029173, 0.78243, 0.19474, 0.0026531, 0.0011827, 0.0011117, 0.7969, 0.64421, 0.014507]
Predicted label: 7
Correct prediction
Energy consumption = 138.253218 pJ
sum error= 309
Actual label: 4
Output voltages: [0.046984, 0.0073933, 0.3896, 0.0015248, 0.7974, 0.0058756, 0.053529, 0.0058276, 0.6807, 0.0030836]
Predicted label: 4
Correct prediction
Energy consumption = 141.363070 pJ
sum error= 309
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 677 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 677 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 677 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79869, 0.028455, 0.1351, 0.014102, 0.0056445, 0.010386, 0.29253, 0.038206, 0.038479, 0.040401]
Predicted label: 0
Correct prediction
Energy consumption = 164.680175 pJ
sum error= 309
Actual label: 6
Output voltages: [0.064762, 0.040572, 0.35524, 0.0038928, 0.41993, 0.14053, 0.79874, 0.0024405, 0.40647, 0.0064328]
Predicted label: 6
Correct prediction
Energy consumption = 140.229926 pJ
sum error= 309
Actual label: 9
Output voltages: [0.36207, 0.0068782, 0.020758, 0.032129, 0.73152, 0.003337, 0.0024116, 0.0010664, 0.23744, 0.78956]
Predicted label: 9
Correct prediction
Energy consumption = 151.856339 pJ
sum error= 309
Actual label: 2
Output voltages: [0.54605, 0.0016442, 0.79863, 0.19968, 0.010454, 0.0010927, 0.034477, 0.060485, 0.71744, 0.0057902]
Predicted label: 2
Correct prediction
Energy consumption = 148.158401 pJ
sum error= 309
Actual label: 6
Output voltages: [0.032979, 0.026063, 0.43392, 0.0012396, 0.151, 0.052881, 0.79879, 0.0016027, 0.60083, 0.0015158]
Predicted label: 6
Correct prediction
Energy consumption = 142.275720 pJ
sum error= 309
Actual label: 5
Output voltages: [0.022588, 0.0011979, 0.0013495, 0.25417, 0.009884, 0.79682, 0.087194, 0.016885, 0.75387, 0.054424]
Predicted label: 5
Correct prediction
Energy consumption = 137.505545 pJ
sum error= 309
Actual label: 8
Output voltages: [0.0096003, 0.020034, 0.23644, 0.043125, 0.0074717, 0.031547, 0.10932, 0.021153, 0.79866, 0.0097084]
Predicted label: 8
Correct prediction
Energy consumption = 142.151873 pJ
sum error= 309
Actual label: 6
Output voltages: [0.13943, 0.12995, 0.3276, 0.0030137, 0.24674, 0.032796, 0.79879, 0.0010725, 0.68406, 0.026987]
Predicted label: 6
Correct prediction
Energy consumption = 144.667947 pJ
sum error= 309
Actual label: 9
Output voltages: [0.12371, 0.01283, 0.027348, 0.016296, 0.070904, 0.01437, 0.0035726, 0.015414, 0.59748, 0.79785]
Predicted label: 9
Correct prediction
Energy consumption = 150.518155 pJ
sum error= 309
Actual label: 0
Output voltages: [0.79861, 0.067306, 0.012142, 0.015876, 0.026651, 0.052188, 0.18795, 0.0084955, 0.16817, 0.047665]
Predicted label: 0
Correct prediction
Energy consumption = 146.288657 pJ
sum error= 309
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 678 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 678 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 678 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.062086, 0.0011758, 0.50207, 0.0040384, 0.76596, 0.0028149, 0.026233, 0.0010721, 0.75422, 0.20108]
Predicted label: 4
Correct prediction
Energy consumption = 160.441109 pJ
sum error= 309
Actual label: 0
Output voltages: [0.79612, 0.052349, 0.051856, 0.016897, 0.051876, 0.0011712, 0.7723, 0.0060916, 0.44531, 0.053499]
Predicted label: 0
Correct prediction
Energy consumption = 141.990878 pJ
sum error= 309
Actual label: 6
Output voltages: [0.059052, 0.0019342, 0.027463, 0.01751, 0.36345, 0.097435, 0.79802, 0.0010811, 0.76311, 0.044261]
Predicted label: 6
Correct prediction
Energy consumption = 140.127793 pJ
sum error= 309
Actual label: 1
Output voltages: [0.050314, 0.46172, 0.12038, 0.054054, 0.51721, 0.024372, 0.79382, 0.0036206, 0.63889, 0.0024734]
Predicted label: 6
Wrong prediction!
Energy consumption = 152.882196 pJ
sum error= 310
Actual label: 9
Output voltages: [0.54194, 0.0015909, 0.022283, 0.041903, 0.6715, 0.001118, 0.0021024, 0.0058363, 0.30013, 0.77942]
Predicted label: 9
Correct prediction
Energy consumption = 144.158328 pJ
sum error= 310
Actual label: 2
Output voltages: [0.023967, 0.0014822, 0.78671, 0.76907, 0.03878, 0.0010661, 0.023086, 0.023079, 0.61693, 0.003699]
Predicted label: 2
Correct prediction
Energy consumption = 128.866226 pJ
sum error= 310
Actual label: 0
Output voltages: [0.79879, 0.037576, 0.17324, 0.011509, 0.026113, 0.0015822, 0.38457, 0.02436, 0.22001, 0.030286]
Predicted label: 0
Correct prediction
Energy consumption = 149.851744 pJ
sum error= 310
Actual label: 9
Output voltages: [0.29886, 0.0050108, 0.0050925, 0.034465, 0.31104, 0.0012794, 0.0013862, 0.010813, 0.68206, 0.79765]
Predicted label: 9
Correct prediction
Energy consumption = 150.694785 pJ
sum error= 310
Actual label: 5
Output voltages: [0.033447, 0.0073668, 0.013342, 0.79691, 0.039627, 0.7531, 0.025431, 0.0046292, 0.59866, 0.0055852]
Predicted label: 3
Wrong prediction!
Energy consumption = 135.409892 pJ
sum error= 311
Actual label: 1
Output voltages: [0.020591, 0.79874, 0.40211, 0.034131, 0.52738, 0.001091, 0.39765, 0.010647, 0.010166, 0.021115]
Predicted label: 1
Correct prediction
Energy consumption = 151.259494 pJ
sum error= 311
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 679 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 679 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 679 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.19001, 0.001388, 0.60194, 0.79791, 0.036516, 0.025101, 0.0012952, 0.0010913, 0.56469, 0.067096]
Predicted label: 3
Correct prediction
Energy consumption = 162.454331 pJ
sum error= 311
Actual label: 7
Output voltages: [0.023392, 0.23259, 0.66441, 0.022036, 0.015209, 0.0010881, 0.0011505, 0.79876, 0.40834, 0.061929]
Predicted label: 7
Correct prediction
Energy consumption = 140.331163 pJ
sum error= 311
Actual label: 6
Output voltages: [0.24587, 0.030024, 0.057323, 0.0094037, 0.28335, 0.074215, 0.79878, 0.001128, 0.51994, 0.026713]
Predicted label: 6
Correct prediction
Energy consumption = 150.896237 pJ
sum error= 311
Actual label: 9
Output voltages: [0.3197, 0.0054004, 0.041932, 0.024555, 0.22687, 0.0082264, 0.0091143, 0.018005, 0.677, 0.79138]
Predicted label: 9
Correct prediction
Energy consumption = 144.577915 pJ
sum error= 311
Actual label: 3
Output voltages: [0.2485, 0.0017262, 0.03393, 0.79879, 0.022954, 0.012356, 0.0022467, 0.34743, 0.76424, 0.031504]
Predicted label: 3
Correct prediction
Energy consumption = 140.545497 pJ
sum error= 311
Actual label: 0
Output voltages: [0.79878, 0.027433, 0.0085113, 0.013561, 0.037652, 0.012014, 0.54907, 0.0064531, 0.088991, 0.027227]
Predicted label: 0
Correct prediction
Energy consumption = 147.549989 pJ
sum error= 311
Actual label: 2
Output voltages: [0.49059, 0.0026223, 0.79229, 0.027675, 0.0323, 0.0010758, 0.0016669, 0.79774, 0.081182, 0.010498]
Predicted label: 7
Wrong prediction!
Energy consumption = 131.556588 pJ
sum error= 312
Actual label: 2
Output voltages: [0.4682, 0.10302, 0.79871, 0.047911, 0.0040427, 0.0011851, 0.037287, 0.29341, 0.40995, 0.018615]
Predicted label: 2
Correct prediction
Energy consumption = 140.623778 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79878, 0.24356, 0.012787, 0.015889, 0.031006, 0.015693, 0.43434, 0.026245, 0.035018, 0.16136]
Predicted label: 0
Correct prediction
Energy consumption = 151.633136 pJ
sum error= 312
Actual label: 1
Output voltages: [0.0085067, 0.7985, 0.043969, 0.1369, 0.030738, 0.0013223, 0.68616, 0.0098687, 0.1436, 0.01995]
Predicted label: 1
Correct prediction
Energy consumption = 159.155765 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 680 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 680 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 680 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.20206, 0.15679, 0.78007, 0.66298, 0.0064692, 0.0012023, 0.41698, 0.002898, 0.51213, 0.012648]
Predicted label: 2
Correct prediction
Energy consumption = 167.808992 pJ
sum error= 312
Actual label: 3
Output voltages: [0.51966, 0.004995, 0.41135, 0.79877, 0.0031395, 0.016893, 0.023582, 0.034709, 0.34078, 0.0035365]
Predicted label: 3
Correct prediction
Energy consumption = 140.710839 pJ
sum error= 312
Actual label: 4
Output voltages: [0.0020964, 0.0077397, 0.041917, 0.0011466, 0.79865, 0.010632, 0.29141, 0.14709, 0.32919, 0.029271]
Predicted label: 4
Correct prediction
Energy consumption = 160.672738 pJ
sum error= 312
Actual label: 5
Output voltages: [0.022664, 0.0010692, 0.0018906, 0.067351, 0.17425, 0.79873, 0.46361, 0.026107, 0.60606, 0.033702]
Predicted label: 5
Correct prediction
Energy consumption = 140.556212 pJ
sum error= 312
Actual label: 6
Output voltages: [0.15095, 0.035761, 0.1269, 0.0063333, 0.46903, 0.41028, 0.79873, 0.0058812, 0.50424, 0.0067737]
Predicted label: 6
Correct prediction
Energy consumption = 142.237119 pJ
sum error= 312
Actual label: 7
Output voltages: [0.06323, 0.2535, 0.21709, 0.26874, 0.0019808, 0.0011554, 0.0040246, 0.79879, 0.021576, 0.5495]
Predicted label: 7
Correct prediction
Energy consumption = 166.196197 pJ
sum error= 312
Actual label: 8
Output voltages: [0.048313, 0.056195, 0.035118, 0.57787, 0.0012135, 0.013303, 0.0041988, 0.0017741, 0.79831, 0.25169]
Predicted label: 8
Correct prediction
Energy consumption = 145.619482 pJ
sum error= 312
Actual label: 9
Output voltages: [0.16045, 0.010158, 0.026159, 0.030467, 0.074708, 0.032853, 0.0050199, 0.07241, 0.71817, 0.7934]
Predicted label: 9
Correct prediction
Energy consumption = 150.499572 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79879, 0.041287, 0.045083, 0.02765, 0.022358, 0.020863, 0.59024, 0.027883, 0.046344, 0.046815]
Predicted label: 0
Correct prediction
Energy consumption = 156.814606 pJ
sum error= 312
Actual label: 1
Output voltages: [0.067501, 0.7984, 0.0040405, 0.042267, 0.031067, 0.0029564, 0.20641, 0.00824, 0.26938, 0.18995]
Predicted label: 1
Correct prediction
Energy consumption = 162.063854 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 681 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 681 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 681 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.408, 0.59143, 0.79831, 0.027601, 0.021214, 0.0013974, 0.43927, 0.036635, 0.29721, 0.080922]
Predicted label: 2
Correct prediction
Energy consumption = 173.112936 pJ
sum error= 312
Actual label: 3
Output voltages: [0.31585, 0.0078621, 0.03591, 0.79865, 0.23301, 0.0414, 0.047705, 0.014231, 0.42773, 0.033964]
Predicted label: 3
Correct prediction
Energy consumption = 147.846407 pJ
sum error= 312
Actual label: 4
Output voltages: [0.017467, 0.028382, 0.091768, 0.0016902, 0.79866, 0.0016077, 0.33177, 0.032038, 0.031473, 0.035709]
Predicted label: 4
Correct prediction
Energy consumption = 157.608939 pJ
sum error= 312
Actual label: 5
Output voltages: [0.010231, 0.001103, 0.0015223, 0.032316, 0.047516, 0.79721, 0.14981, 0.015221, 0.78705, 0.02836]
Predicted label: 5
Correct prediction
Energy consumption = 139.451463 pJ
sum error= 312
Actual label: 6
Output voltages: [0.051311, 0.0053358, 0.037365, 0.0073016, 0.57589, 0.19743, 0.79876, 0.0017665, 0.76437, 0.0085652]
Predicted label: 6
Correct prediction
Energy consumption = 137.653894 pJ
sum error= 312
Actual label: 7
Output voltages: [0.069625, 0.015985, 0.043739, 0.044819, 0.0163, 0.010908, 0.0010742, 0.79853, 0.075682, 0.3953]
Predicted label: 7
Correct prediction
Energy consumption = 156.001367 pJ
sum error= 312
Actual label: 8
Output voltages: [0.025321, 0.018045, 0.30974, 0.44714, 0.0090719, 0.0030146, 0.05232, 0.027898, 0.79868, 0.19177]
Predicted label: 8
Correct prediction
Energy consumption = 152.537279 pJ
sum error= 312
Actual label: 9
Output voltages: [0.30154, 0.0039318, 0.0034161, 0.035563, 0.10501, 0.0038835, 0.0010664, 0.26897, 0.47981, 0.79458]
Predicted label: 9
Correct prediction
Energy consumption = 157.068865 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79877, 0.018411, 0.011418, 0.11313, 0.044357, 0.01565, 0.49801, 0.0097385, 0.23516, 0.052569]
Predicted label: 0
Correct prediction
Energy consumption = 153.633429 pJ
sum error= 312
Actual label: 1
Output voltages: [0.0025, 0.79853, 0.063664, 0.050208, 0.038772, 0.0050447, 0.75179, 0.0018523, 0.16174, 0.18211]
Predicted label: 1
Correct prediction
Energy consumption = 162.811006 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 682 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 682 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 682 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.18673, 0.43442, 0.79874, 0.092493, 0.029928, 0.0013417, 0.17711, 0.027135, 0.036414, 0.018313]
Predicted label: 2
Correct prediction
Energy consumption = 170.369076 pJ
sum error= 312
Actual label: 3
Output voltages: [0.67472, 0.039985, 0.18676, 0.79874, 0.0019679, 0.03422, 0.018315, 0.080866, 0.2088, 0.0013264]
Predicted label: 3
Correct prediction
Energy consumption = 144.807811 pJ
sum error= 312
Actual label: 4
Output voltages: [0.013838, 0.0018226, 0.27009, 0.0073517, 0.79866, 0.001789, 0.05711, 0.019742, 0.037356, 0.0345]
Predicted label: 4
Correct prediction
Energy consumption = 158.913864 pJ
sum error= 312
Actual label: 5
Output voltages: [0.0092302, 0.0010693, 0.0018785, 0.27189, 0.028897, 0.79864, 0.28135, 0.024148, 0.73869, 0.1157]
Predicted label: 5
Correct prediction
Energy consumption = 145.426023 pJ
sum error= 312
Actual label: 6
Output voltages: [0.21807, 0.15811, 0.26096, 0.0051056, 0.34274, 0.1848, 0.79872, 0.0011047, 0.29781, 0.0096278]
Predicted label: 6
Correct prediction
Energy consumption = 145.646179 pJ
sum error= 312
Actual label: 7
Output voltages: [0.21861, 0.058762, 0.033975, 0.59398, 0.0024608, 0.0010779, 0.0010706, 0.79879, 0.28786, 0.57541]
Predicted label: 7
Correct prediction
Energy consumption = 164.872315 pJ
sum error= 312
Actual label: 8
Output voltages: [0.034433, 0.010855, 0.11881, 0.041915, 0.0081755, 0.024994, 0.033755, 0.0024331, 0.79877, 0.35698]
Predicted label: 8
Correct prediction
Energy consumption = 145.713648 pJ
sum error= 312
Actual label: 9
Output voltages: [0.16772, 0.015406, 0.0059103, 0.0148, 0.028655, 0.0012901, 0.0010697, 0.011824, 0.68093, 0.79733]
Predicted label: 9
Correct prediction
Energy consumption = 146.433797 pJ
sum error= 312
Actual label: 2
Output voltages: [0.3009, 0.23393, 0.79868, 0.061516, 0.037428, 0.0012694, 0.30473, 0.048866, 0.17265, 0.080338]
Predicted label: 2
Correct prediction
Energy consumption = 154.058743 pJ
sum error= 312
Actual label: 1
Output voltages: [0.038917, 0.79857, 0.020048, 0.039186, 0.0019744, 0.0023956, 0.24813, 0.0032218, 0.67311, 0.039109]
Predicted label: 1
Correct prediction
Energy consumption = 157.519856 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 683 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 683 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 683 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.24189, 0.021864, 0.045012, 0.079091, 0.016488, 0.019191, 0.0010671, 0.79874, 0.12217, 0.68152]
Predicted label: 7
Correct prediction
Energy consumption = 171.478827 pJ
sum error= 312
Actual label: 2
Output voltages: [0.26671, 0.23644, 0.79879, 0.081128, 0.012472, 0.0013541, 0.30151, 0.0093926, 0.40969, 0.12726]
Predicted label: 2
Correct prediction
Energy consumption = 150.149056 pJ
sum error= 312
Actual label: 5
Output voltages: [0.15059, 0.001066, 0.0022433, 0.42336, 0.011676, 0.79877, 0.13492, 0.036183, 0.74186, 0.041]
Predicted label: 5
Correct prediction
Energy consumption = 147.483453 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79879, 0.081772, 0.025761, 0.032541, 0.0087287, 0.0069591, 0.47408, 0.0038581, 0.036989, 0.70291]
Predicted label: 0
Correct prediction
Energy consumption = 155.715251 pJ
sum error= 312
Actual label: 8
Output voltages: [0.093464, 0.0056782, 0.056132, 0.065975, 0.0098907, 0.034267, 0.0084241, 0.0091943, 0.79874, 0.2131]
Predicted label: 8
Correct prediction
Energy consumption = 152.477687 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79851, 0.039634, 0.14213, 0.0097999, 0.013448, 0.038725, 0.66982, 0.0028637, 0.026542, 0.041269]
Predicted label: 0
Correct prediction
Energy consumption = 152.992250 pJ
sum error= 312
Actual label: 2
Output voltages: [0.30327, 0.18644, 0.76773, 0.17007, 0.0019115, 0.001203, 0.4265, 0.030026, 0.4914, 0.0034348]
Predicted label: 2
Correct prediction
Energy consumption = 152.902952 pJ
sum error= 312
Actual label: 7
Output voltages: [0.061054, 0.016589, 0.40952, 0.035753, 0.0029282, 0.0010807, 0.0010766, 0.79866, 0.47249, 0.13198]
Predicted label: 7
Correct prediction
Energy consumption = 148.709490 pJ
sum error= 312
Actual label: 8
Output voltages: [0.012608, 0.068649, 0.072355, 0.049058, 0.017498, 0.0067562, 0.016838, 0.029199, 0.79877, 0.28032]
Predicted label: 8
Correct prediction
Energy consumption = 149.428455 pJ
sum error= 312
Actual label: 8
Output voltages: [0.23126, 0.0080206, 0.054452, 0.24728, 0.0057527, 0.33075, 0.0046004, 0.018914, 0.79874, 0.36989]
Predicted label: 8
Correct prediction
Energy consumption = 148.460511 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 684 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 684 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 684 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.76006, 0.026566, 0.14947, 0.79873, 0.0025767, 0.018511, 0.016635, 0.027626, 0.55111, 0.0031351]
Predicted label: 3
Correct prediction
Energy consumption = 165.480681 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79876, 0.0079354, 0.31825, 0.22542, 0.0093068, 0.0051704, 0.051896, 0.0037212, 0.23663, 0.084358]
Predicted label: 0
Correct prediction
Energy consumption = 155.793247 pJ
sum error= 312
Actual label: 6
Output voltages: [0.26753, 0.26077, 0.35005, 0.030813, 0.22782, 0.081507, 0.79873, 0.0011047, 0.31251, 0.047406]
Predicted label: 6
Correct prediction
Energy consumption = 146.588765 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79879, 0.0081975, 0.034754, 0.0056923, 0.046695, 0.0061787, 0.74716, 0.028675, 0.099806, 0.27273]
Predicted label: 0
Correct prediction
Energy consumption = 151.143322 pJ
sum error= 312
Actual label: 2
Output voltages: [0.46536, 0.53688, 0.79872, 0.51267, 0.011868, 0.0011688, 0.37565, 0.0037647, 0.22992, 0.035318]
Predicted label: 2
Correct prediction
Energy consumption = 150.502802 pJ
sum error= 312
Actual label: 7
Output voltages: [0.35084, 0.042393, 0.080563, 0.47801, 0.0016629, 0.0010988, 0.0010863, 0.79865, 0.039525, 0.39334]
Predicted label: 7
Correct prediction
Energy consumption = 157.722996 pJ
sum error= 312
Actual label: 6
Output voltages: [0.077647, 0.063339, 0.26783, 0.0098045, 0.46979, 0.54481, 0.79863, 0.0073891, 0.12163, 0.027905]
Predicted label: 6
Correct prediction
Energy consumption = 147.446792 pJ
sum error= 312
Actual label: 6
Output voltages: [0.032542, 0.0098036, 0.021847, 0.0054539, 0.45701, 0.19814, 0.79877, 0.013287, 0.17518, 0.030666]
Predicted label: 6
Correct prediction
Energy consumption = 136.558973 pJ
sum error= 312
Actual label: 1
Output voltages: [0.022589, 0.79834, 0.32005, 0.28202, 0.0026441, 0.0036945, 0.41099, 0.029466, 0.024653, 0.078569]
Predicted label: 1
Correct prediction
Energy consumption = 170.943331 pJ
sum error= 312
Actual label: 2
Output voltages: [0.28346, 0.50075, 0.79634, 0.32089, 0.01875, 0.0012908, 0.25627, 0.0069911, 0.22655, 0.035902]
Predicted label: 2
Correct prediction
Energy consumption = 148.355500 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 685 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 685 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 685 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.037784, 0.028201, 0.25819, 0.033083, 0.023547, 0.0060749, 0.013566, 0.0029535, 0.79871, 0.11264]
Predicted label: 8
Correct prediction
Energy consumption = 170.766354 pJ
sum error= 312
Actual label: 8
Output voltages: [0.043685, 0.019973, 0.75834, 0.030416, 0.030141, 0.0012222, 0.062492, 0.0023908, 0.79878, 0.17296]
Predicted label: 8
Correct prediction
Energy consumption = 140.486832 pJ
sum error= 312
Actual label: 7
Output voltages: [0.19485, 0.17132, 0.0093528, 0.29613, 0.024712, 0.0010663, 0.0014579, 0.79879, 0.0068027, 0.37247]
Predicted label: 7
Correct prediction
Energy consumption = 161.173762 pJ
sum error= 312
Actual label: 7
Output voltages: [0.062266, 0.048496, 0.050629, 0.1569, 0.010762, 0.0010868, 0.0010662, 0.79865, 0.22694, 0.2186]
Predicted label: 7
Correct prediction
Energy consumption = 147.495388 pJ
sum error= 312
Actual label: 4
Output voltages: [0.0011189, 0.10191, 0.0010878, 0.0010902, 0.79863, 0.011958, 0.37951, 0.04124, 0.33063, 0.3108]
Predicted label: 4
Correct prediction
Energy consumption = 154.968836 pJ
sum error= 312
Actual label: 7
Output voltages: [0.2327, 0.0073155, 0.019627, 0.03775, 0.041419, 0.017508, 0.0010748, 0.79852, 0.13502, 0.41167]
Predicted label: 7
Correct prediction
Energy consumption = 152.409483 pJ
sum error= 312
Actual label: 7
Output voltages: [0.21239, 0.28444, 0.019685, 0.068104, 0.0055682, 0.0027153, 0.0010941, 0.79874, 0.012593, 0.54683]
Predicted label: 7
Correct prediction
Energy consumption = 140.415122 pJ
sum error= 312
Actual label: 3
Output voltages: [0.53091, 0.031601, 0.10696, 0.7986, 0.032265, 0.022079, 0.016486, 0.0051516, 0.54337, 0.043988]
Predicted label: 3
Correct prediction
Energy consumption = 145.697917 pJ
sum error= 312
Actual label: 7
Output voltages: [0.21356, 0.0067522, 0.0021724, 0.15844, 0.02398, 0.016099, 0.001224, 0.79879, 0.10662, 0.21041]
Predicted label: 7
Correct prediction
Energy consumption = 156.548839 pJ
sum error= 312
Actual label: 4
Output voltages: [0.0039638, 0.019368, 0.042904, 0.0073931, 0.79877, 0.0024813, 0.066241, 0.59371, 0.19254, 0.0044209]
Predicted label: 4
Correct prediction
Energy consumption = 146.264247 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 686 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 686 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 686 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.15759, 0.0016285, 0.0040692, 0.40722, 0.01588, 0.79879, 0.34102, 0.050069, 0.70974, 0.078711]
Predicted label: 5
Correct prediction
Energy consumption = 160.806677 pJ
sum error= 312
Actual label: 4
Output voltages: [0.016901, 0.0047264, 0.050601, 0.009223, 0.7986, 0.0013355, 0.046323, 0.20898, 0.039253, 0.033797]
Predicted label: 4
Correct prediction
Energy consumption = 159.340658 pJ
sum error= 312
Actual label: 3
Output voltages: [0.32173, 0.043728, 0.025827, 0.7987, 0.010996, 0.0061398, 0.016703, 0.0028593, 0.47761, 0.09251]
Predicted label: 3
Correct prediction
Energy consumption = 150.354071 pJ
sum error= 312
Actual label: 3
Output voltages: [0.39493, 0.028545, 0.15494, 0.7987, 0.037207, 0.0080303, 0.016628, 0.0124, 0.56539, 0.075095]
Predicted label: 3
Correct prediction
Energy consumption = 133.418677 pJ
sum error= 312
Actual label: 8
Output voltages: [0.044428, 0.012187, 0.31623, 0.36549, 0.0011255, 0.013439, 0.0077201, 0.0081286, 0.79879, 0.093069]
Predicted label: 8
Correct prediction
Energy consumption = 153.437132 pJ
sum error= 312
Actual label: 4
Output voltages: [0.0055232, 0.011794, 0.080756, 0.015489, 0.79867, 0.001799, 0.24808, 0.12632, 0.099025, 0.021834]
Predicted label: 4
Correct prediction
Energy consumption = 159.942472 pJ
sum error= 312
Actual label: 5
Output voltages: [0.037078, 0.0012382, 0.0019784, 0.17761, 0.049693, 0.79871, 0.41006, 0.062925, 0.73998, 0.20676]
Predicted label: 5
Correct prediction
Energy consumption = 152.195177 pJ
sum error= 312
Actual label: 4
Output voltages: [0.0061317, 0.034468, 0.013018, 0.03329, 0.79875, 0.0010676, 0.044838, 0.051334, 0.048927, 0.019305]
Predicted label: 4
Correct prediction
Energy consumption = 157.039582 pJ
sum error= 312
Actual label: 1
Output voltages: [0.025218, 0.79864, 0.41, 0.016221, 0.044147, 0.0010739, 0.56803, 0.0099418, 0.046373, 0.024477]
Predicted label: 1
Correct prediction
Energy consumption = 163.718396 pJ
sum error= 312
Actual label: 1
Output voltages: [0.0087656, 0.79873, 0.21162, 0.45145, 0.045458, 0.0010712, 0.026602, 0.0015502, 0.42846, 0.3331]
Predicted label: 1
Correct prediction
Energy consumption = 158.594724 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 687 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 687 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 687 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.4825, 0.0029816, 0.041532, 0.0047018, 0.095542, 0.033009, 0.0038173, 0.22072, 0.67494, 0.79636]
Predicted label: 9
Correct prediction
Energy consumption = 170.402766 pJ
sum error= 312
Actual label: 7
Output voltages: [0.15033, 0.013569, 0.14901, 0.5936, 0.0026161, 0.0017061, 0.0022983, 0.79879, 0.41898, 0.50056]
Predicted label: 7
Correct prediction
Energy consumption = 154.645096 pJ
sum error= 312
Actual label: 4
Output voltages: [0.05848, 0.0072443, 0.35992, 0.0035569, 0.79878, 0.0011015, 0.44512, 0.033378, 0.026339, 0.027643]
Predicted label: 4
Correct prediction
Energy consumption = 154.906004 pJ
sum error= 312
Actual label: 3
Output voltages: [0.40327, 0.021629, 0.2283, 0.79865, 0.18005, 0.0061219, 0.025999, 0.008457, 0.70055, 0.1228]
Predicted label: 3
Correct prediction
Energy consumption = 144.365565 pJ
sum error= 312
Actual label: 7
Output voltages: [0.097287, 0.11242, 0.37602, 0.42542, 0.0057883, 0.001073, 0.0023861, 0.79865, 0.21559, 0.34588]
Predicted label: 7
Correct prediction
Energy consumption = 154.964740 pJ
sum error= 312
Actual label: 3
Output voltages: [0.56147, 0.010389, 0.048049, 0.7986, 0.067233, 0.0095091, 0.027122, 0.0071338, 0.69096, 0.040068]
Predicted label: 3
Correct prediction
Energy consumption = 146.166888 pJ
sum error= 312
Actual label: 3
Output voltages: [0.61561, 0.04301, 0.11201, 0.79873, 0.0015008, 0.008265, 0.024933, 0.027724, 0.28519, 0.0059079]
Predicted label: 3
Correct prediction
Energy consumption = 136.146327 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79879, 0.023876, 0.22052, 0.029791, 0.034471, 0.015293, 0.70056, 0.020583, 0.028091, 0.3682]
Predicted label: 0
Correct prediction
Energy consumption = 157.350941 pJ
sum error= 312
Actual label: 2
Output voltages: [0.25964, 0.69631, 0.7637, 0.39185, 0.23361, 0.01222, 0.77142, 0.0043185, 0.033961, 0.0012617]
Predicted label: 6
Wrong prediction!
Energy consumption = 152.238749 pJ
sum error= 313
Actual label: 5
Output voltages: [0.041494, 0.001135, 0.0040537, 0.36744, 0.030891, 0.79713, 0.037607, 0.038613, 0.78028, 0.040555]
Predicted label: 5
Correct prediction
Energy consumption = 141.270097 pJ
sum error= 313
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 688 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 688 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 688 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.1443, 0.0010984, 0.01874, 0.40673, 0.033848, 0.79879, 0.012277, 0.043442, 0.78749, 0.17496]
Predicted label: 5
Correct prediction
Energy consumption = 160.144877 pJ
sum error= 313
Actual label: 6
Output voltages: [0.11133, 0.1082, 0.33484, 0.0030702, 0.32679, 0.29357, 0.79862, 0.0029245, 0.26911, 0.024629]
Predicted label: 6
Correct prediction
Energy consumption = 147.738707 pJ
sum error= 313
Actual label: 3
Output voltages: [0.41999, 0.037596, 0.030122, 0.79859, 0.015589, 0.01993, 0.029796, 0.010367, 0.56731, 0.1613]
Predicted label: 3
Correct prediction
Energy consumption = 151.555536 pJ
sum error= 313
Actual label: 1
Output voltages: [0.0046998, 0.79871, 0.4471, 0.041552, 0.032928, 0.0010861, 0.76149, 0.014004, 0.033135, 0.035043]
Predicted label: 1
Correct prediction
Energy consumption = 148.927661 pJ
sum error= 313
Actual label: 5
Output voltages: [0.022529, 0.0010682, 0.010131, 0.29917, 0.010567, 0.79809, 0.20415, 0.0059704, 0.77379, 0.018512]
Predicted label: 5
Correct prediction
Energy consumption = 151.281280 pJ
sum error= 313
Actual label: 2
Output voltages: [0.0502, 0.51135, 0.78598, 0.077338, 0.068724, 0.0011946, 0.45251, 0.022881, 0.41449, 0.015148]
Predicted label: 2
Correct prediction
Energy consumption = 156.287845 pJ
sum error= 313
Actual label: 5
Output voltages: [0.1524, 0.0010669, 0.0011558, 0.49133, 0.044805, 0.78738, 0.5162, 0.018098, 0.38302, 0.035876]
Predicted label: 5
Correct prediction
Energy consumption = 143.261882 pJ
sum error= 313
Actual label: 9
Output voltages: [0.26887, 0.0083929, 0.065341, 0.020818, 0.048951, 0.0083088, 0.0016695, 0.10478, 0.5871, 0.79236]
Predicted label: 9
Correct prediction
Energy consumption = 153.149793 pJ
sum error= 313
Actual label: 9
Output voltages: [0.48536, 0.020797, 0.012503, 0.040201, 0.11451, 0.018537, 0.0056662, 0.019476, 0.43207, 0.79848]
Predicted label: 9
Correct prediction
Energy consumption = 138.894439 pJ
sum error= 313
Actual label: 8
Output voltages: [0.030252, 0.016304, 0.27708, 0.016285, 0.017792, 0.023832, 0.0092986, 0.0023272, 0.79879, 0.40738]
Predicted label: 8
Correct prediction
Energy consumption = 141.582963 pJ
sum error= 313
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 689 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 689 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 689 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0041972, 0.0094115, 0.040132, 0.006846, 0.79859, 0.0014937, 0.051734, 0.082355, 0.041923, 0.044161]
Predicted label: 4
Correct prediction
Energy consumption = 168.071328 pJ
sum error= 313
Actual label: 1
Output voltages: [0.031143, 0.79837, 0.044088, 0.32552, 0.017133, 0.0054736, 0.48577, 0.016826, 0.16938, 0.31068]
Predicted label: 1
Correct prediction
Energy consumption = 165.713928 pJ
sum error= 313
Actual label: 0
Output voltages: [0.79875, 0.025792, 0.015293, 0.0042088, 0.024915, 0.0132, 0.51828, 0.0051249, 0.030154, 0.045856]
Predicted label: 0
Correct prediction
Energy consumption = 163.054794 pJ
sum error= 313
Actual label: 6
Output voltages: [0.25758, 0.13535, 0.19181, 0.010014, 0.28768, 0.18924, 0.79868, 0.001382, 0.32053, 0.039663]
Predicted label: 6
Correct prediction
Energy consumption = 142.062360 pJ
sum error= 313
Actual label: 0
Output voltages: [0.79871, 0.02298, 0.3641, 0.031258, 0.010476, 0.0050584, 0.3477, 0.11765, 0.39494, 0.17909]
Predicted label: 0
Correct prediction
Energy consumption = 154.915484 pJ
sum error= 313
Actual label: 9
Output voltages: [0.11166, 0.056379, 0.0021343, 0.25094, 0.028433, 0.0024208, 0.0032632, 0.020152, 0.21902, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 156.238352 pJ
sum error= 313
Actual label: 6
Output voltages: [0.20188, 0.12041, 0.23105, 0.049948, 0.075863, 0.28656, 0.79865, 0.0028775, 0.069747, 0.092636]
Predicted label: 6
Correct prediction
Energy consumption = 151.643942 pJ
sum error= 313
Actual label: 8
Output voltages: [0.073192, 0.0065235, 0.65843, 0.015028, 0.014981, 0.0078483, 0.076294, 0.0042763, 0.79878, 0.046967]
Predicted label: 8
Correct prediction
Energy consumption = 152.426915 pJ
sum error= 313
Actual label: 8
Output voltages: [0.021133, 0.05168, 0.13378, 0.043124, 0.0065389, 0.011063, 0.024396, 0.0027825, 0.79879, 0.5356]
Predicted label: 8
Correct prediction
Energy consumption = 146.662944 pJ
sum error= 313
Actual label: 5
Output voltages: [0.015325, 0.0013842, 0.0065366, 0.12258, 0.021398, 0.79199, 0.067374, 0.0033622, 0.76204, 0.15111]
Predicted label: 5
Correct prediction
Energy consumption = 138.142017 pJ
sum error= 313
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 690 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 690 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 690 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.098277, 0.21804, 0.10323, 0.036644, 0.15035, 0.43848, 0.7987, 0.0091598, 0.36392, 0.010297]
Predicted label: 6
Correct prediction
Energy consumption = 165.570876 pJ
sum error= 313
Actual label: 1
Output voltages: [0.020326, 0.79849, 0.0063792, 0.09522, 0.049958, 0.01016, 0.26104, 0.014506, 0.24611, 0.10083]
Predicted label: 1
Correct prediction
Energy consumption = 166.930532 pJ
sum error= 313
Actual label: 1
Output voltages: [0.059705, 0.79847, 0.0022764, 0.021263, 0.020062, 0.0012055, 0.062096, 0.025943, 0.25165, 0.41083]
Predicted label: 1
Correct prediction
Energy consumption = 158.924942 pJ
sum error= 313
Actual label: 9
Output voltages: [0.12912, 0.007444, 0.018632, 0.025781, 0.10189, 0.0068626, 0.0015127, 0.050147, 0.5235, 0.79223]
Predicted label: 9
Correct prediction
Energy consumption = 145.734278 pJ
sum error= 313
Actual label: 8
Output voltages: [0.0086335, 0.061993, 0.53584, 0.21732, 0.0065731, 0.0091969, 0.024045, 0.018727, 0.79875, 0.19301]
Predicted label: 8
Correct prediction
Energy consumption = 145.579783 pJ
sum error= 313
Actual label: 9
Output voltages: [0.079199, 0.010395, 0.014687, 0.021835, 0.12316, 0.0020868, 0.0028767, 0.020897, 0.52461, 0.79862]
Predicted label: 9
Correct prediction
Energy consumption = 154.042452 pJ
sum error= 313
Actual label: 2
Output voltages: [0.4608, 0.30971, 0.60289, 0.47566, 0.4653, 0.01373, 0.78854, 0.14567, 0.0016324, 0.001637]
Predicted label: 6
Wrong prediction!
Energy consumption = 154.940456 pJ
sum error= 314
Actual label: 3
Output voltages: [0.72585, 0.016009, 0.026446, 0.79864, 0.014392, 0.028959, 0.014609, 0.0094016, 0.46492, 0.23161]
Predicted label: 3
Correct prediction
Energy consumption = 145.643258 pJ
sum error= 314
Actual label: 5
Output voltages: [0.047369, 0.0011316, 0.0033145, 0.40413, 0.0061506, 0.7985, 0.16981, 0.02666, 0.70858, 0.041566]
Predicted label: 5
Correct prediction
Energy consumption = 141.766285 pJ
sum error= 314
Actual label: 5
Output voltages: [0.0013067, 0.006999, 0.011695, 0.2018, 0.022177, 0.78339, 0.016603, 0.083197, 0.75965, 0.28611]
Predicted label: 5
Correct prediction
Energy consumption = 131.654782 pJ
sum error= 314
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 691 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 691 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 691 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.29009, 0.001396, 0.035167, 0.05425, 0.66683, 0.0010873, 0.0010982, 0.19116, 0.47548, 0.78823]
Predicted label: 9
Correct prediction
Energy consumption = 168.277615 pJ
sum error= 314
Actual label: 4
Output voltages: [0.0072893, 0.0047695, 0.024438, 0.003574, 0.79862, 0.0010825, 0.099748, 0.065573, 0.080888, 0.024371]
Predicted label: 4
Correct prediction
Energy consumption = 148.579489 pJ
sum error= 314
Actual label: 2
Output voltages: [0.32393, 0.023441, 0.79823, 0.19403, 0.011336, 0.0012263, 0.14549, 0.58538, 0.14928, 0.030364]
Predicted label: 2
Correct prediction
Energy consumption = 145.198546 pJ
sum error= 314
Actual label: 1
Output voltages: [0.027849, 0.79842, 0.21471, 0.10017, 0.01928, 0.0030023, 0.42853, 0.0044584, 0.36777, 0.044083]
Predicted label: 1
Correct prediction
Energy consumption = 162.477660 pJ
sum error= 314
Actual label: 9
Output voltages: [0.071273, 0.091456, 0.1562, 0.0016696, 0.33035, 0.0053849, 0.0011224, 0.060029, 0.33185, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 155.087997 pJ
sum error= 314
Actual label: 4
Output voltages: [0.0080466, 0.043321, 0.022085, 0.038958, 0.79879, 0.001067, 0.02806, 0.25981, 0.020903, 0.042358]
Predicted label: 4
Correct prediction
Energy consumption = 152.320404 pJ
sum error= 314
Actual label: 9
Output voltages: [0.24297, 0.0031102, 0.028033, 0.014444, 0.32356, 0.017385, 0.01099, 0.15995, 0.42345, 0.79757]
Predicted label: 9
Correct prediction
Energy consumption = 149.945409 pJ
sum error= 314
Actual label: 1
Output voltages: [0.020958, 0.7984, 0.201, 0.20936, 0.059579, 0.0051168, 0.56359, 0.015409, 0.052557, 0.12712]
Predicted label: 1
Correct prediction
Energy consumption = 166.180433 pJ
sum error= 314
Actual label: 3
Output voltages: [0.40875, 0.02492, 0.04937, 0.79869, 0.0078558, 0.0056444, 0.0090396, 0.0066114, 0.33051, 0.034058]
Predicted label: 3
Correct prediction
Energy consumption = 144.057787 pJ
sum error= 314
Actual label: 9
Output voltages: [0.20745, 0.0062987, 0.012576, 0.0015768, 0.077385, 0.0011687, 0.0010662, 0.030614, 0.50199, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 153.432521 pJ
sum error= 314
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 692 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 692 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 692 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.48088, 0.46144, 0.79879, 0.020335, 0.0070413, 0.0013613, 0.22838, 0.035056, 0.18162, 0.017753]
Predicted label: 2
Correct prediction
Energy consumption = 171.832779 pJ
sum error= 314
Actual label: 0
Output voltages: [0.79878, 0.085752, 0.033957, 0.004498, 0.0084447, 0.0016933, 0.40972, 0.0076461, 0.071763, 0.075515]
Predicted label: 0
Correct prediction
Energy consumption = 152.661355 pJ
sum error= 314
Actual label: 6
Output voltages: [0.034882, 0.013621, 0.031381, 0.018292, 0.40536, 0.231, 0.79875, 0.0048664, 0.76066, 0.008188]
Predicted label: 6
Correct prediction
Energy consumption = 142.280818 pJ
sum error= 314
Actual label: 0
Output voltages: [0.79867, 0.065985, 0.11254, 0.010535, 0.057008, 0.010809, 0.21609, 0.042077, 0.15772, 0.25142]
Predicted label: 0
Correct prediction
Energy consumption = 153.389746 pJ
sum error= 314
Actual label: 4
Output voltages: [0.0094262, 0.0065811, 0.012597, 0.0057104, 0.79879, 0.0012056, 0.029239, 0.050192, 0.45745, 0.064794]
Predicted label: 4
Correct prediction
Energy consumption = 151.222435 pJ
sum error= 314
Actual label: 0
Output voltages: [0.7987, 0.02542, 0.47824, 0.014325, 0.014387, 0.0044702, 0.36501, 0.050479, 0.41433, 0.2411]
Predicted label: 0
Correct prediction
Energy consumption = 159.842809 pJ
sum error= 314
Actual label: 6
Output voltages: [0.013646, 0.0030174, 0.029569, 0.0097854, 0.79228, 0.096062, 0.77294, 0.02994, 0.2057, 0.020078]
Predicted label: 4
Wrong prediction!
Energy consumption = 146.183102 pJ
sum error= 315
Actual label: 0
Output voltages: [0.79877, 0.13565, 0.085201, 0.012132, 0.013045, 0.0018007, 0.59412, 0.019972, 0.07735, 0.27653]
Predicted label: 0
Correct prediction
Energy consumption = 159.368696 pJ
sum error= 315
Actual label: 1
Output voltages: [0.0091558, 0.79859, 0.18434, 0.092595, 0.077836, 0.0014972, 0.5703, 0.0037733, 0.38539, 0.1251]
Predicted label: 1
Correct prediction
Energy consumption = 164.168839 pJ
sum error= 315
Actual label: 2
Output voltages: [0.37641, 0.21525, 0.79872, 0.18791, 0.005241, 0.0011316, 0.16965, 0.0199, 0.16682, 0.037162]
Predicted label: 2
Correct prediction
Energy consumption = 141.764589 pJ
sum error= 315
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 693 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 693 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 693 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.59626, 0.0084027, 0.26655, 0.79877, 0.027209, 0.0025775, 0.0031529, 0.0067463, 0.45489, 0.031952]
Predicted label: 3
Correct prediction
Energy consumption = 168.055734 pJ
sum error= 315
Actual label: 4
Output voltages: [0.0022165, 0.011117, 0.088869, 0.14437, 0.7987, 0.0010665, 0.023343, 0.044446, 0.019027, 0.027707]
Predicted label: 4
Correct prediction
Energy consumption = 155.470981 pJ
sum error= 315
Actual label: 5
Output voltages: [0.026404, 0.0010903, 0.0010827, 0.31759, 0.19038, 0.79876, 0.42031, 0.017125, 0.66249, 0.046475]
Predicted label: 5
Correct prediction
Energy consumption = 147.856267 pJ
sum error= 315
Actual label: 6
Output voltages: [0.054957, 0.049628, 0.43757, 0.0012433, 0.15612, 0.16215, 0.79877, 0.0022193, 0.42518, 0.0016326]
Predicted label: 6
Correct prediction
Energy consumption = 142.302388 pJ
sum error= 315
Actual label: 7
Output voltages: [0.30384, 0.022165, 0.029178, 0.035028, 0.0066808, 0.023345, 0.001101, 0.79858, 0.11209, 0.25307]
Predicted label: 7
Correct prediction
Energy consumption = 161.209701 pJ
sum error= 315
Actual label: 8
Output voltages: [0.014941, 0.11416, 0.3283, 0.045208, 0.021665, 0.0031224, 0.01701, 0.017712, 0.79875, 0.19937]
Predicted label: 8
Correct prediction
Energy consumption = 150.385819 pJ
sum error= 315
Actual label: 9
Output voltages: [0.49672, 0.0024631, 0.019512, 0.0042253, 0.15605, 0.06163, 0.0063063, 0.25261, 0.34733, 0.78901]
Predicted label: 9
Correct prediction
Energy consumption = 147.366234 pJ
sum error= 315
Actual label: 0
Output voltages: [0.7987, 0.038918, 0.20371, 0.038072, 0.012157, 0.0019653, 0.51891, 0.023379, 0.042772, 0.067759]
Predicted label: 0
Correct prediction
Energy consumption = 150.719694 pJ
sum error= 315
Actual label: 1
Output voltages: [0.0034116, 0.7985, 0.13554, 0.044727, 0.51526, 0.022575, 0.41237, 0.01938, 0.051718, 0.071384]
Predicted label: 1
Correct prediction
Energy consumption = 173.148028 pJ
sum error= 315
Actual label: 2
Output voltages: [0.50799, 0.027267, 0.79878, 0.055817, 0.02346, 0.0010858, 0.043428, 0.090659, 0.40228, 0.013971]
Predicted label: 2
Correct prediction
Energy consumption = 150.953601 pJ
sum error= 315
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 694 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 694 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 694 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.10111, 0.0047764, 0.052921, 0.79873, 0.24696, 0.63867, 0.014968, 0.0090907, 0.53809, 0.0045734]
Predicted label: 3
Correct prediction
Energy consumption = 166.502570 pJ
sum error= 315
Actual label: 4
Output voltages: [0.0023366, 0.0044124, 0.040708, 0.017718, 0.79864, 0.0033602, 0.14154, 0.22103, 0.11304, 0.013253]
Predicted label: 4
Correct prediction
Energy consumption = 146.988122 pJ
sum error= 315
Actual label: 5
Output voltages: [0.030654, 0.0011193, 0.0010805, 0.68455, 0.033403, 0.79869, 0.37675, 0.0044121, 0.65762, 0.034634]
Predicted label: 5
Correct prediction
Energy consumption = 143.411397 pJ
sum error= 315
Actual label: 6
Output voltages: [0.11912, 0.020066, 0.12745, 0.0046711, 0.33975, 0.063324, 0.79879, 0.0065537, 0.59786, 0.0021775]
Predicted label: 6
Correct prediction
Energy consumption = 145.138500 pJ
sum error= 315
Actual label: 7
Output voltages: [0.41963, 0.013208, 0.047564, 0.22549, 0.010226, 0.041468, 0.0011341, 0.79856, 0.29029, 0.35839]
Predicted label: 7
Correct prediction
Energy consumption = 155.738463 pJ
sum error= 315
Actual label: 8
Output voltages: [0.22596, 0.059946, 0.02438, 0.025646, 0.0043457, 0.0016477, 0.0010832, 0.40722, 0.79837, 0.69173]
Predicted label: 8
Correct prediction
Energy consumption = 144.831144 pJ
sum error= 315
Actual label: 9
Output voltages: [0.3284, 0.016705, 0.023031, 0.0316, 0.29138, 0.01027, 0.0047182, 0.0066359, 0.47738, 0.79867]
Predicted label: 9
Correct prediction
Energy consumption = 141.352955 pJ
sum error= 315
Actual label: 0
Output voltages: [0.79875, 0.087785, 0.030369, 0.014286, 0.032885, 0.017961, 0.57985, 0.014649, 0.032896, 0.062554]
Predicted label: 0
Correct prediction
Energy consumption = 148.228839 pJ
sum error= 315
Actual label: 1
Output voltages: [0.012558, 0.79867, 0.37059, 0.023504, 0.02446, 0.0012563, 0.76384, 0.0058563, 0.1164, 0.01083]
Predicted label: 1
Correct prediction
Energy consumption = 162.443981 pJ
sum error= 315
Actual label: 2
Output voltages: [0.43392, 0.04795, 0.79864, 0.015597, 0.016027, 0.0011358, 0.059319, 0.15049, 0.5104, 0.0080007]
Predicted label: 2
Correct prediction
Energy consumption = 144.323124 pJ
sum error= 315
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 695 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 695 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 695 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.32089, 0.008079, 0.039803, 0.79879, 0.015614, 0.075017, 0.0010712, 0.035489, 0.76332, 0.062959]
Predicted label: 3
Correct prediction
Energy consumption = 164.881397 pJ
sum error= 315
Actual label: 4
Output voltages: [0.0060801, 0.011872, 0.049958, 0.024728, 0.79862, 0.0016396, 0.095122, 0.05883, 0.025856, 0.015045]
Predicted label: 4
Correct prediction
Energy consumption = 153.781580 pJ
sum error= 315
Actual label: 5
Output voltages: [0.32877, 0.0010897, 0.0013397, 0.18623, 0.092314, 0.79865, 0.039059, 0.032571, 0.69921, 0.011708]
Predicted label: 5
Correct prediction
Energy consumption = 143.984607 pJ
sum error= 315
Actual label: 6
Output voltages: [0.32716, 0.12519, 0.038078, 0.011181, 0.1713, 0.72747, 0.79878, 0.0029128, 0.51107, 0.014318]
Predicted label: 6
Correct prediction
Energy consumption = 145.619476 pJ
sum error= 315
Actual label: 7
Output voltages: [0.41986, 0.3133, 0.79657, 0.037049, 0.0012529, 0.0010778, 0.0058542, 0.79398, 0.36565, 0.085085]
Predicted label: 2
Wrong prediction!
Energy consumption = 155.545922 pJ
sum error= 316
Actual label: 8
Output voltages: [0.046956, 0.056219, 0.16904, 0.050568, 0.025782, 0.043107, 0.033372, 0.0032344, 0.79873, 0.06566]
Predicted label: 8
Correct prediction
Energy consumption = 151.029885 pJ
sum error= 316
Actual label: 9
Output voltages: [0.23076, 0.016508, 0.023279, 0.024549, 0.042815, 0.021948, 0.0055985, 0.040724, 0.64722, 0.79806]
Predicted label: 9
Correct prediction
Energy consumption = 139.564370 pJ
sum error= 316
Actual label: 3
Output voltages: [0.34796, 0.012555, 0.036804, 0.79873, 0.015227, 0.0044496, 0.0079848, 0.0017281, 0.47989, 0.035323]
Predicted label: 3
Correct prediction
Energy consumption = 151.634367 pJ
sum error= 316
Actual label: 8
Output voltages: [0.02927, 0.19068, 0.032702, 0.31522, 0.0079334, 0.019329, 0.012152, 0.010127, 0.79868, 0.37832]
Predicted label: 8
Correct prediction
Energy consumption = 140.462104 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79875, 0.050346, 0.10563, 0.030196, 0.025418, 0.0049121, 0.56583, 0.03317, 0.059385, 0.053739]
Predicted label: 0
Correct prediction
Energy consumption = 157.914910 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 696 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 696 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 696 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.19923, 0.023782, 0.05771, 0.12136, 0.0015952, 0.011627, 0.0011492, 0.79859, 0.23968, 0.26602]
Predicted label: 7
Correct prediction
Energy consumption = 175.711112 pJ
sum error= 316
Actual label: 1
Output voltages: [0.0074369, 0.79859, 0.24078, 0.19862, 0.032295, 0.0011295, 0.63333, 0.0074706, 0.2426, 0.038394]
Predicted label: 1
Correct prediction
Energy consumption = 164.935376 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79841, 0.048382, 0.3256, 0.02154, 0.031204, 0.0010661, 0.76229, 0.013085, 0.41852, 0.1902]
Predicted label: 0
Correct prediction
Energy consumption = 159.626323 pJ
sum error= 316
Actual label: 7
Output voltages: [0.16625, 0.04505, 0.18174, 0.03852, 0.0043766, 0.0010681, 0.0010823, 0.79862, 0.41915, 0.11161]
Predicted label: 7
Correct prediction
Energy consumption = 154.643843 pJ
sum error= 316
Actual label: 5
Output voltages: [0.51049, 0.0049495, 0.0037769, 0.56978, 0.0062671, 0.7987, 0.1322, 0.020962, 0.73397, 0.020129]
Predicted label: 5
Correct prediction
Energy consumption = 149.620473 pJ
sum error= 316
Actual label: 5
Output voltages: [0.055219, 0.0023459, 0.0010685, 0.50667, 0.032803, 0.79877, 0.29106, 0.0037345, 0.65187, 0.026608]
Predicted label: 5
Correct prediction
Energy consumption = 143.517282 pJ
sum error= 316
Actual label: 6
Output voltages: [0.050808, 0.03635, 0.11128, 0.0026016, 0.21127, 0.15032, 0.79876, 0.0017629, 0.43497, 0.0026259]
Predicted label: 6
Correct prediction
Energy consumption = 148.131564 pJ
sum error= 316
Actual label: 9
Output voltages: [0.46317, 0.0094774, 0.0073569, 0.029931, 0.20372, 0.005508, 0.0019691, 0.0025648, 0.33603, 0.79741]
Predicted label: 9
Correct prediction
Energy consumption = 155.066724 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79875, 0.17303, 0.21209, 0.038322, 0.010653, 0.0065849, 0.76268, 0.04412, 0.35147, 0.040504]
Predicted label: 0
Correct prediction
Energy consumption = 151.741944 pJ
sum error= 316
Actual label: 1
Output voltages: [0.027192, 0.79857, 0.29626, 0.02859, 0.045581, 0.0012681, 0.49824, 0.0011832, 0.057577, 0.020017]
Predicted label: 1
Correct prediction
Energy consumption = 152.449750 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 697 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 697 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 697 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79773, 0.032592, 0.48312, 0.025971, 0.011393, 0.0011419, 0.16872, 0.0024578, 0.47995, 0.048374]
Predicted label: 0
Correct prediction
Energy consumption = 170.748766 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79879, 0.036526, 0.50102, 0.018828, 0.028038, 0.0013145, 0.13447, 0.014928, 0.25336, 0.091348]
Predicted label: 0
Correct prediction
Energy consumption = 148.542642 pJ
sum error= 316
Actual label: 8
Output voltages: [0.20515, 0.0061649, 0.45605, 0.011106, 0.024603, 0.0161, 0.0063725, 0.047844, 0.79872, 0.028155]
Predicted label: 8
Correct prediction
Energy consumption = 146.631605 pJ
sum error= 316
Actual label: 3
Output voltages: [0.76418, 0.0096952, 0.22388, 0.79875, 0.023994, 0.015622, 0.0084888, 0.020972, 0.32175, 0.0077621]
Predicted label: 3
Correct prediction
Energy consumption = 145.420338 pJ
sum error= 316
Actual label: 4
Output voltages: [0.011618, 0.0049403, 0.029914, 0.012368, 0.79859, 0.0012815, 0.18856, 0.03102, 0.18498, 0.0062175]
Predicted label: 4
Correct prediction
Energy consumption = 153.309215 pJ
sum error= 316
Actual label: 3
Output voltages: [0.70233, 0.0013409, 0.70205, 0.79831, 0.020264, 0.0014883, 0.0011935, 0.020822, 0.4253, 0.0044952]
Predicted label: 3
Correct prediction
Energy consumption = 142.007287 pJ
sum error= 316
Actual label: 1
Output voltages: [0.016188, 0.7986, 0.022287, 0.037763, 0.031621, 0.0011561, 0.65534, 0.019351, 0.03163, 0.039237]
Predicted label: 1
Correct prediction
Energy consumption = 152.904832 pJ
sum error= 316
Actual label: 5
Output voltages: [0.13063, 0.00855, 0.0011101, 0.57884, 0.030447, 0.79873, 0.039367, 0.011816, 0.72635, 0.057277]
Predicted label: 5
Correct prediction
Energy consumption = 155.128070 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79879, 0.14724, 0.067566, 0.018337, 0.0659, 0.0027936, 0.72888, 0.0097116, 0.13365, 0.072353]
Predicted label: 0
Correct prediction
Energy consumption = 162.118605 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79876, 0.038989, 0.015419, 0.031341, 0.091435, 0.023462, 0.63444, 0.022384, 0.074035, 0.052677]
Predicted label: 0
Correct prediction
Energy consumption = 144.361416 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 698 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 698 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 698 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.22154, 0.0021935, 0.0093425, 0.032296, 0.17699, 0.0057069, 0.0013217, 0.018202, 0.59144, 0.79798]
Predicted label: 9
Correct prediction
Energy consumption = 169.026399 pJ
sum error= 316
Actual label: 5
Output voltages: [0.071944, 0.0011838, 0.0010662, 0.1508, 0.20412, 0.79863, 0.46177, 0.0029035, 0.76863, 0.033289]
Predicted label: 5
Correct prediction
Energy consumption = 149.169463 pJ
sum error= 316
Actual label: 3
Output voltages: [0.3582, 0.010786, 0.033423, 0.79874, 0.031529, 0.030326, 0.011094, 0.025654, 0.60412, 0.018435]
Predicted label: 3
Correct prediction
Energy consumption = 148.190293 pJ
sum error= 316
Actual label: 4
Output voltages: [0.040999, 0.0069897, 0.1931, 0.010555, 0.79859, 0.0010793, 0.0011025, 0.015668, 0.13976, 0.30922]
Predicted label: 4
Correct prediction
Energy consumption = 150.989096 pJ
sum error= 316
Actual label: 9
Output voltages: [0.24236, 0.014508, 0.0078228, 0.050947, 0.36103, 0.005815, 0.0016976, 0.0033618, 0.17776, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 148.649441 pJ
sum error= 316
Actual label: 3
Output voltages: [0.52268, 0.026591, 0.036738, 0.79863, 0.034826, 0.051499, 0.0031734, 0.0034674, 0.72924, 0.02279]
Predicted label: 3
Correct prediction
Energy consumption = 144.957973 pJ
sum error= 316
Actual label: 7
Output voltages: [0.30137, 0.22447, 0.43297, 0.001368, 0.023204, 0.0012418, 0.002534, 0.79879, 0.21808, 0.065764]
Predicted label: 7
Correct prediction
Energy consumption = 155.905185 pJ
sum error= 316
Actual label: 6
Output voltages: [0.01649, 0.082412, 0.59073, 0.0017146, 0.24297, 0.056474, 0.79872, 0.0079519, 0.40091, 0.0044815]
Predicted label: 6
Correct prediction
Energy consumption = 153.137831 pJ
sum error= 316
Actual label: 9
Output voltages: [0.037139, 0.015555, 0.018551, 0.030939, 0.034999, 0.0074061, 0.0027164, 0.032424, 0.71404, 0.79694]
Predicted label: 9
Correct prediction
Energy consumption = 158.641355 pJ
sum error= 316
Actual label: 2
Output voltages: [0.36792, 0.022468, 0.79844, 0.11743, 0.049084, 0.0013725, 0.01028, 0.013167, 0.6242, 0.004705]
Predicted label: 2
Correct prediction
Energy consumption = 149.494961 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 699 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 699 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 699 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.003066, 0.0015816, 0.064424, 0.21448, 0.79872, 0.014672, 0.0098412, 0.0095546, 0.31619, 0.052238]
Predicted label: 4
Correct prediction
Energy consumption = 167.218937 pJ
sum error= 316
Actual label: 5
Output voltages: [0.057646, 0.0011605, 0.0015533, 0.39647, 0.074391, 0.79873, 0.62256, 0.021323, 0.77307, 0.007091]
Predicted label: 5
Correct prediction
Energy consumption = 139.177782 pJ
sum error= 316
Actual label: 7
Output voltages: [0.37164, 0.0088125, 0.019486, 0.063858, 0.021914, 0.020247, 0.0010788, 0.79859, 0.22796, 0.27268]
Predicted label: 7
Correct prediction
Energy consumption = 150.228020 pJ
sum error= 316
Actual label: 2
Output voltages: [0.44128, 0.040048, 0.79868, 0.038699, 0.013909, 0.0010768, 0.03197, 0.016804, 0.47626, 0.018988]
Predicted label: 2
Correct prediction
Energy consumption = 141.595100 pJ
sum error= 316
Actual label: 6
Output voltages: [0.11186, 0.024599, 0.38045, 0.0026019, 0.31907, 0.055785, 0.79879, 0.0020814, 0.45012, 0.006437]
Predicted label: 6
Correct prediction
Energy consumption = 147.131267 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0018973, 0.02172, 0.018482, 0.03308, 0.79863, 0.0048337, 0.063657, 0.056952, 0.024232, 0.029121]
Predicted label: 4
Correct prediction
Energy consumption = 147.198910 pJ
sum error= 316
Actual label: 9
Output voltages: [0.54932, 0.023472, 0.008487, 0.062915, 0.39983, 0.0090621, 0.012732, 0.0014371, 0.19633, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 146.957714 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0021912, 0.020577, 0.03154, 0.026868, 0.79875, 0.074904, 0.025189, 0.0029579, 0.37172, 0.12205]
Predicted label: 4
Correct prediction
Energy consumption = 150.910146 pJ
sum error= 316
Actual label: 9
Output voltages: [0.27875, 0.0062995, 0.011755, 0.02566, 0.30253, 0.0024392, 0.0071956, 0.0026027, 0.43397, 0.79828]
Predicted label: 9
Correct prediction
Energy consumption = 144.333070 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0096516, 0.023335, 0.044084, 0.033638, 0.79869, 0.0010712, 0.030799, 0.027677, 0.049556, 0.019437]
Predicted label: 4
Correct prediction
Energy consumption = 146.655186 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 700 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 700 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 700 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0047357, 0.79859, 0.011451, 0.039677, 0.013208, 0.0029456, 0.70599, 0.0093678, 0.41438, 0.018715]
Predicted label: 1
Correct prediction
Energy consumption = 174.865766 pJ
sum error= 316
Actual label: 2
Output voltages: [0.25004, 0.025308, 0.79878, 0.19437, 0.23585, 0.0010707, 0.18672, 0.019429, 0.5484, 0.096704]
Predicted label: 2
Correct prediction
Energy consumption = 151.511757 pJ
sum error= 316
Actual label: 2
Output voltages: [0.12107, 0.019067, 0.79879, 0.037096, 0.0054735, 0.00109, 0.040287, 0.036061, 0.73908, 0.0091727]
Predicted label: 2
Correct prediction
Energy consumption = 146.640788 pJ
sum error= 316
Actual label: 5
Output voltages: [0.051363, 0.0010738, 0.0011796, 0.74935, 0.029953, 0.79877, 0.15541, 0.025586, 0.34778, 0.19401]
Predicted label: 5
Correct prediction
Energy consumption = 151.578079 pJ
sum error= 316
Actual label: 8
Output voltages: [0.013966, 0.07153, 0.10843, 0.042682, 0.0060389, 0.0036585, 0.025599, 0.0058908, 0.79869, 0.20619]
Predicted label: 8
Correct prediction
Energy consumption = 155.382245 pJ
sum error= 316
Actual label: 1
Output voltages: [0.0061985, 0.79867, 0.58056, 0.028886, 0.048384, 0.0010822, 0.38628, 0.022892, 0.077373, 0.013649]
Predicted label: 1
Correct prediction
Energy consumption = 159.638136 pJ
sum error= 316
Actual label: 3
Output voltages: [0.30136, 0.014423, 0.20297, 0.79869, 0.018713, 0.015062, 0.0070205, 0.016528, 0.4207, 0.033701]
Predicted label: 3
Correct prediction
Energy consumption = 144.472532 pJ
sum error= 316
Actual label: 2
Output voltages: [0.30477, 0.042533, 0.79873, 0.07869, 0.019198, 0.0010906, 0.22019, 0.060834, 0.44785, 0.017064]
Predicted label: 2
Correct prediction
Energy consumption = 146.588863 pJ
sum error= 316
Actual label: 9
Output voltages: [0.11698, 0.034802, 0.059768, 0.1594, 0.041529, 0.016145, 0.01419, 0.035822, 0.46186, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 158.810679 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0081978, 0.024866, 0.1753, 0.095563, 0.79876, 0.0017057, 0.014058, 0.020744, 0.035061, 0.014138]
Predicted label: 4
Correct prediction
Energy consumption = 151.337344 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 701 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 701 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 701 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.11533, 0.032452, 0.093766, 0.79879, 0.0038928, 0.0035018, 0.0027475, 0.012314, 0.71973, 0.032576]
Predicted label: 3
Correct prediction
Energy consumption = 160.274084 pJ
sum error= 316
Actual label: 8
Output voltages: [0.056409, 0.014952, 0.12087, 0.024029, 0.047582, 0.0342, 0.013645, 0.019252, 0.79858, 0.021798]
Predicted label: 8
Correct prediction
Energy consumption = 143.200043 pJ
sum error= 316
Actual label: 2
Output voltages: [0.28089, 0.022307, 0.79872, 0.029766, 0.013996, 0.0010811, 0.040827, 0.034504, 0.49457, 0.013102]
Predicted label: 2
Correct prediction
Energy consumption = 150.321530 pJ
sum error= 316
Actual label: 2
Output voltages: [0.433, 0.026764, 0.79869, 0.034933, 0.019974, 0.0010759, 0.067558, 0.065713, 0.51771, 0.020707]
Predicted label: 2
Correct prediction
Energy consumption = 133.260861 pJ
sum error= 316
Actual label: 1
Output voltages: [0.042067, 0.79872, 0.69066, 0.2432, 0.023953, 0.0011442, 0.11759, 0.0011845, 0.084319, 0.068878]
Predicted label: 1
Correct prediction
Energy consumption = 159.941691 pJ
sum error= 316
Actual label: 2
Output voltages: [0.32933, 0.014189, 0.79877, 0.15004, 0.045464, 0.0010762, 0.051029, 0.063294, 0.3719, 0.0080349]
Predicted label: 2
Correct prediction
Energy consumption = 145.021489 pJ
sum error= 316
Actual label: 8
Output voltages: [0.18486, 0.017905, 0.19267, 0.67064, 0.01083, 0.0052502, 0.034264, 0.0018413, 0.79879, 0.2224]
Predicted label: 8
Correct prediction
Energy consumption = 151.860652 pJ
sum error= 316
Actual label: 6
Output voltages: [0.055698, 0.044675, 0.13638, 0.012381, 0.44499, 0.37623, 0.79867, 0.011103, 0.52034, 0.016053]
Predicted label: 6
Correct prediction
Energy consumption = 146.513355 pJ
sum error= 316
Actual label: 5
Output voltages: [0.062134, 0.0010677, 0.0015392, 0.32775, 0.018612, 0.79804, 0.05651, 0.023016, 0.64732, 0.18362]
Predicted label: 5
Correct prediction
Energy consumption = 145.381465 pJ
sum error= 316
Actual label: 1
Output voltages: [0.055716, 0.79878, 0.30126, 0.094382, 0.4536, 0.0010966, 0.513, 0.0031412, 0.037139, 0.032642]
Predicted label: 1
Correct prediction
Energy consumption = 168.266807 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 702 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 702 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 702 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.15536, 0.22726, 0.026463, 0.020055, 0.21998, 0.69441, 0.79871, 0.0059677, 0.42827, 0.0043784]
Predicted label: 6
Correct prediction
Energy consumption = 166.986393 pJ
sum error= 316
Actual label: 7
Output voltages: [0.29637, 0.098669, 0.3795, 0.4175, 0.0010723, 0.0011731, 0.0013139, 0.79474, 0.53894, 0.083348]
Predicted label: 7
Correct prediction
Energy consumption = 160.721887 pJ
sum error= 316
Actual label: 2
Output voltages: [0.4301, 0.017359, 0.79877, 0.20052, 0.036833, 0.0010773, 0.047036, 0.010604, 0.41672, 0.019977]
Predicted label: 2
Correct prediction
Energy consumption = 145.830207 pJ
sum error= 316
Actual label: 1
Output voltages: [0.18566, 0.79871, 0.22658, 0.021073, 0.65316, 0.0017595, 0.34821, 0.0012716, 0.024218, 0.12232]
Predicted label: 1
Correct prediction
Energy consumption = 165.334599 pJ
sum error= 316
Actual label: 3
Output voltages: [0.74998, 0.013056, 0.14785, 0.79875, 0.023886, 0.064876, 0.0036784, 0.019054, 0.67514, 0.009308]
Predicted label: 3
Correct prediction
Energy consumption = 151.477270 pJ
sum error= 316
Actual label: 9
Output voltages: [0.045319, 0.0056031, 0.022606, 0.36703, 0.056559, 0.002079, 0.0017076, 0.043292, 0.26343, 0.79492]
Predicted label: 9
Correct prediction
Energy consumption = 147.320857 pJ
sum error= 316
Actual label: 3
Output voltages: [0.7647, 0.016673, 0.030225, 0.79867, 0.023478, 0.051457, 0.0045512, 0.015909, 0.48552, 0.0294]
Predicted label: 3
Correct prediction
Energy consumption = 142.974383 pJ
sum error= 316
Actual label: 8
Output voltages: [0.026173, 0.033534, 0.057798, 0.015895, 0.003474, 0.038478, 0.0060182, 0.019945, 0.79862, 0.032757]
Predicted label: 8
Correct prediction
Energy consumption = 143.984964 pJ
sum error= 316
Actual label: 7
Output voltages: [0.054187, 0.017411, 0.01846, 0.20244, 0.014755, 0.0056447, 0.0010687, 0.79865, 0.068089, 0.33496]
Predicted label: 7
Correct prediction
Energy consumption = 153.842078 pJ
sum error= 316
Actual label: 5
Output voltages: [0.43448, 0.024849, 0.0011273, 0.73829, 0.24659, 0.79873, 0.43952, 0.0015697, 0.50802, 0.061356]
Predicted label: 5
Correct prediction
Energy consumption = 146.195473 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 703 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 703 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 703 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.13815, 0.048091, 0.68047, 0.016611, 0.038892, 0.0011171, 0.0011215, 0.79873, 0.28317, 0.32752]
Predicted label: 7
Correct prediction
Energy consumption = 170.066115 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79742, 0.066001, 0.69031, 0.032327, 0.0094085, 0.0010659, 0.091949, 0.002019, 0.69253, 0.66131]
Predicted label: 0
Correct prediction
Energy consumption = 154.460066 pJ
sum error= 316
Actual label: 7
Output voltages: [0.02962, 0.027289, 0.03145, 0.057691, 0.038162, 0.0015556, 0.0010721, 0.7987, 0.54662, 0.52729]
Predicted label: 7
Correct prediction
Energy consumption = 159.001087 pJ
sum error= 316
Actual label: 4
Output voltages: [0.041102, 0.002858, 0.021497, 0.035782, 0.79879, 0.0010741, 0.013317, 0.013825, 0.14496, 0.044696]
Predicted label: 4
Correct prediction
Energy consumption = 148.085721 pJ
sum error= 316
Actual label: 8
Output voltages: [0.01168, 0.038096, 0.32438, 0.02852, 0.019259, 0.0028548, 0.023841, 0.0067984, 0.79869, 0.070866]
Predicted label: 8
Correct prediction
Energy consumption = 145.752400 pJ
sum error= 316
Actual label: 8
Output voltages: [0.66615, 0.0066458, 0.039724, 0.78098, 0.0010661, 0.020565, 0.014625, 0.001285, 0.79654, 0.053109]
Predicted label: 8
Correct prediction
Energy consumption = 155.235149 pJ
sum error= 316
Actual label: 5
Output voltages: [0.023192, 0.0011201, 0.0019602, 0.25439, 0.092418, 0.79879, 0.31783, 0.017252, 0.78551, 0.0014038]
Predicted label: 5
Correct prediction
Energy consumption = 137.589238 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79822, 0.037797, 0.019684, 0.016926, 0.045616, 0.016976, 0.76907, 0.027533, 0.052374, 0.031114]
Predicted label: 0
Correct prediction
Energy consumption = 153.860011 pJ
sum error= 316
Actual label: 6
Output voltages: [0.066224, 0.10833, 0.31053, 0.0043795, 0.28004, 0.071112, 0.79873, 0.0020153, 0.46834, 0.018664]
Predicted label: 6
Correct prediction
Energy consumption = 142.079033 pJ
sum error= 316
Actual label: 6
Output voltages: [0.1519, 0.018276, 0.082007, 0.0046119, 0.50622, 0.27117, 0.79879, 0.0023874, 0.74957, 0.0019193]
Predicted label: 6
Correct prediction
Energy consumption = 129.935897 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 704 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 704 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 704 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.41434, 0.0017866, 0.13739, 0.79879, 0.0081294, 0.047161, 0.0014207, 0.022761, 0.7713, 0.010122]
Predicted label: 3
Correct prediction
Energy consumption = 166.058940 pJ
sum error= 316
Actual label: 7
Output voltages: [0.34486, 0.019418, 0.19427, 0.2797, 0.0090121, 0.0090123, 0.001233, 0.79873, 0.28058, 0.37061]
Predicted label: 7
Correct prediction
Energy consumption = 148.232644 pJ
sum error= 316
Actual label: 6
Output voltages: [0.13991, 0.027649, 0.038607, 0.0029487, 0.26681, 0.55684, 0.79877, 0.0084584, 0.47704, 0.0088809]
Predicted label: 6
Correct prediction
Energy consumption = 155.206567 pJ
sum error= 316
Actual label: 9
Output voltages: [0.42524, 0.0087467, 0.022022, 0.033788, 0.5448, 0.0075717, 0.021801, 0.0016119, 0.69033, 0.79829]
Predicted label: 9
Correct prediction
Energy consumption = 149.797246 pJ
sum error= 316
Actual label: 9
Output voltages: [0.49349, 0.0091893, 0.0033341, 0.062393, 0.56608, 0.0018109, 0.0020339, 0.0019013, 0.27109, 0.79863]
Predicted label: 9
Correct prediction
Energy consumption = 139.866865 pJ
sum error= 316
Actual label: 4
Output voltages: [0.026779, 0.029765, 0.17413, 0.020271, 0.7986, 0.001208, 0.056929, 0.024212, 0.012911, 0.035492]
Predicted label: 4
Correct prediction
Energy consumption = 149.542385 pJ
sum error= 316
Actual label: 8
Output voltages: [0.041749, 0.036872, 0.073832, 0.079332, 0.0094642, 0.045724, 0.0322, 0.011329, 0.79873, 0.042142]
Predicted label: 8
Correct prediction
Energy consumption = 152.195525 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0041463, 0.0094172, 0.047609, 0.072429, 0.79874, 0.0065508, 0.0068878, 0.0080112, 0.12306, 0.027777]
Predicted label: 4
Correct prediction
Energy consumption = 145.762707 pJ
sum error= 316
Actual label: 1
Output voltages: [0.021178, 0.79865, 0.058641, 0.14988, 0.37861, 0.0010673, 0.60236, 0.0075192, 0.014699, 0.23843]
Predicted label: 1
Correct prediction
Energy consumption = 158.770659 pJ
sum error= 316
Actual label: 0
Output voltages: [0.798, 0.0085875, 0.11486, 0.035171, 0.0067449, 0.0045028, 0.36516, 0.042315, 0.39124, 0.021626]
Predicted label: 0
Correct prediction
Energy consumption = 150.115920 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 705 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 705 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 705 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.30391, 0.0194, 0.050262, 0.0054449, 0.53945, 0.053833, 0.79871, 0.0027653, 0.64773, 0.0029375]
Predicted label: 6
Correct prediction
Energy consumption = 166.649899 pJ
sum error= 316
Actual label: 6
Output voltages: [0.19678, 0.055363, 0.02337, 0.014051, 0.2485, 0.14118, 0.79761, 0.0049313, 0.74835, 0.016857]
Predicted label: 6
Correct prediction
Energy consumption = 133.251639 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79833, 0.064957, 0.23769, 0.01084, 0.027471, 0.0013759, 0.69485, 0.013255, 0.19512, 0.13109]
Predicted label: 0
Correct prediction
Energy consumption = 149.312659 pJ
sum error= 316
Actual label: 1
Output voltages: [0.020586, 0.79847, 0.03202, 0.016791, 0.03298, 0.0031143, 0.64015, 0.0092464, 0.16497, 0.03472]
Predicted label: 1
Correct prediction
Energy consumption = 159.356694 pJ
sum error= 316
Actual label: 2
Output voltages: [0.52926, 0.1741, 0.79879, 0.010623, 0.031239, 0.0012711, 0.018157, 0.76899, 0.11852, 0.023592]
Predicted label: 2
Correct prediction
Energy consumption = 147.105343 pJ
sum error= 316
Actual label: 3
Output voltages: [0.05134, 0.017078, 0.031068, 0.79872, 0.020841, 0.0055008, 0.0039434, 0.014498, 0.58407, 0.03168]
Predicted label: 3
Correct prediction
Energy consumption = 143.213301 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0029003, 0.0059048, 0.024452, 0.0069456, 0.79864, 0.0040864, 0.24101, 0.57451, 0.25201, 0.0041254]
Predicted label: 4
Correct prediction
Energy consumption = 142.509892 pJ
sum error= 316
Actual label: 5
Output voltages: [0.036415, 0.0010709, 0.0017791, 0.13808, 0.010968, 0.79856, 0.41218, 0.0065637, 0.74037, 0.0063845]
Predicted label: 5
Correct prediction
Energy consumption = 140.816791 pJ
sum error= 316
Actual label: 6
Output voltages: [0.14181, 0.041204, 0.12759, 0.001269, 0.29498, 0.28825, 0.79877, 0.0065363, 0.28189, 0.001593]
Predicted label: 6
Correct prediction
Energy consumption = 140.560120 pJ
sum error= 316
Actual label: 7
Output voltages: [0.24757, 0.21366, 0.77858, 0.027992, 0.005977, 0.0010803, 0.0011293, 0.79879, 0.35735, 0.077772]
Predicted label: 7
Correct prediction
Energy consumption = 152.946471 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 706 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 706 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 706 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.036755, 0.029045, 0.033347, 0.56423, 0.001642, 0.65584, 0.020267, 0.0027984, 0.79873, 0.043787]
Predicted label: 8
Correct prediction
Energy consumption = 166.814675 pJ
sum error= 316
Actual label: 9
Output voltages: [0.46597, 0.0063264, 0.029767, 0.014643, 0.59004, 0.0020189, 0.0010904, 0.028845, 0.35861, 0.79554]
Predicted label: 9
Correct prediction
Energy consumption = 153.609651 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79849, 0.041811, 0.064754, 0.015833, 0.013018, 0.0053851, 0.5202, 0.012949, 0.11584, 0.0099403]
Predicted label: 0
Correct prediction
Energy consumption = 151.638482 pJ
sum error= 316
Actual label: 1
Output voltages: [0.033362, 0.79864, 0.18594, 0.11736, 0.066197, 0.0016187, 0.50078, 0.0048072, 0.15671, 0.043574]
Predicted label: 1
Correct prediction
Energy consumption = 165.415112 pJ
sum error= 316
Actual label: 2
Output voltages: [0.024258, 0.25771, 0.79876, 0.10868, 0.015141, 0.0012781, 0.022908, 0.5195, 0.25526, 0.0098511]
Predicted label: 2
Correct prediction
Energy consumption = 141.850061 pJ
sum error= 316
Actual label: 3
Output voltages: [0.46999, 0.04625, 0.038253, 0.79856, 0.064327, 0.016631, 0.023983, 0.014045, 0.42943, 0.4121]
Predicted label: 3
Correct prediction
Energy consumption = 146.031630 pJ
sum error= 316
Actual label: 4
Output voltages: [0.011785, 0.016115, 0.019041, 0.0018309, 0.79873, 0.02404, 0.085676, 0.44011, 0.22724, 0.0041508]
Predicted label: 4
Correct prediction
Energy consumption = 150.955805 pJ
sum error= 316
Actual label: 5
Output voltages: [0.011161, 0.001104, 0.0014374, 0.058905, 0.10674, 0.79737, 0.33854, 0.0020227, 0.77773, 0.016519]
Predicted label: 5
Correct prediction
Energy consumption = 144.915258 pJ
sum error= 316
Actual label: 6
Output voltages: [0.031513, 0.050208, 0.21986, 0.0015632, 0.17709, 0.10504, 0.79876, 0.001722, 0.75853, 0.0062348]
Predicted label: 6
Correct prediction
Energy consumption = 145.628835 pJ
sum error= 316
Actual label: 7
Output voltages: [0.43094, 0.01044, 0.044241, 0.10091, 0.0026802, 0.0011147, 0.0011608, 0.79865, 0.49477, 0.14137]
Predicted label: 7
Correct prediction
Energy consumption = 149.248907 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 707 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 707 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 707 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.019395, 0.21745, 0.21498, 0.16572, 0.020995, 0.0012645, 0.0060111, 0.036677, 0.79872, 0.043042]
Predicted label: 8
Correct prediction
Energy consumption = 167.504452 pJ
sum error= 316
Actual label: 9
Output voltages: [0.28275, 0.0029867, 0.0065649, 0.055903, 0.55292, 0.0046945, 0.0040856, 0.0044283, 0.34848, 0.79611]
Predicted label: 9
Correct prediction
Energy consumption = 145.352010 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79864, 0.21108, 0.035438, 0.058593, 0.0013439, 0.025081, 0.51515, 0.021133, 0.044315, 0.02216]
Predicted label: 0
Correct prediction
Energy consumption = 154.386710 pJ
sum error= 316
Actual label: 1
Output voltages: [0.010279, 0.79852, 0.042707, 0.051289, 0.0096946, 0.0018139, 0.61882, 0.015695, 0.40231, 0.014523]
Predicted label: 1
Correct prediction
Energy consumption = 156.826907 pJ
sum error= 316
Actual label: 2
Output voltages: [0.54413, 0.051814, 0.79877, 0.059691, 0.0036903, 0.0012292, 0.15868, 0.30644, 0.32556, 0.010606]
Predicted label: 2
Correct prediction
Energy consumption = 151.176198 pJ
sum error= 316
Actual label: 3
Output voltages: [0.50467, 0.0016682, 0.36376, 0.79877, 0.03357, 0.024007, 0.0034818, 0.0068617, 0.53552, 0.029159]
Predicted label: 3
Correct prediction
Energy consumption = 142.671545 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0028886, 0.0083372, 0.013673, 0.015776, 0.7987, 0.0013809, 0.045348, 0.040643, 0.15315, 0.0042612]
Predicted label: 4
Correct prediction
Energy consumption = 150.221856 pJ
sum error= 316
Actual label: 5
Output voltages: [0.034397, 0.0010966, 0.0010941, 0.25862, 0.046779, 0.79878, 0.39459, 0.013836, 0.53395, 0.032926]
Predicted label: 5
Correct prediction
Energy consumption = 144.871819 pJ
sum error= 316
Actual label: 6
Output voltages: [0.3633, 0.03286, 0.24492, 0.0010663, 0.33915, 0.033556, 0.79877, 0.001066, 0.12546, 0.0079048]
Predicted label: 6
Correct prediction
Energy consumption = 145.547834 pJ
sum error= 316
Actual label: 7
Output voltages: [0.072746, 0.064453, 0.038233, 0.27945, 0.0024002, 0.0010673, 0.0011408, 0.7987, 0.34415, 0.066088]
Predicted label: 7
Correct prediction
Energy consumption = 153.937739 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 708 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 708 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 708 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.30521, 0.13862, 0.49677, 0.039708, 0.022698, 0.0027503, 0.047178, 0.0015693, 0.79877, 0.15071]
Predicted label: 8
Correct prediction
Energy consumption = 171.437092 pJ
sum error= 316
Actual label: 9
Output voltages: [0.23188, 0.0015751, 0.015877, 0.0082079, 0.78051, 0.019059, 0.016779, 0.016557, 0.34725, 0.79623]
Predicted label: 9
Correct prediction
Energy consumption = 146.660369 pJ
sum error= 316
Actual label: 7
Output voltages: [0.17656, 0.024607, 0.031457, 0.046954, 0.001907, 0.0025675, 0.0011751, 0.79879, 0.76758, 0.44164]
Predicted label: 7
Correct prediction
Energy consumption = 150.655263 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0011336, 0.0022206, 0.014095, 0.023646, 0.79871, 0.0041433, 0.0051377, 0.1102, 0.33312, 0.021155]
Predicted label: 4
Correct prediction
Energy consumption = 152.432337 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79878, 0.13573, 0.2546, 0.025254, 0.014067, 0.0064104, 0.084872, 0.0068278, 0.17441, 0.28187]
Predicted label: 0
Correct prediction
Energy consumption = 164.335536 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0023324, 0.001301, 0.0082493, 0.0040645, 0.79864, 0.0014459, 0.23634, 0.36767, 0.43055, 0.0014126]
Predicted label: 4
Correct prediction
Energy consumption = 149.354102 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79878, 0.026838, 0.094057, 0.0078033, 0.027014, 0.0043871, 0.18587, 0.027515, 0.17754, 0.014456]
Predicted label: 0
Correct prediction
Energy consumption = 154.659958 pJ
sum error= 316
Actual label: 1
Output voltages: [0.18765, 0.79857, 0.50382, 0.03258, 0.19688, 0.0010881, 0.26933, 0.0014742, 0.030081, 0.048028]
Predicted label: 1
Correct prediction
Energy consumption = 160.296670 pJ
sum error= 316
Actual label: 7
Output voltages: [0.32994, 0.032049, 0.16476, 0.13007, 0.014761, 0.0014579, 0.0011055, 0.79854, 0.30648, 0.22008]
Predicted label: 7
Correct prediction
Energy consumption = 154.608147 pJ
sum error= 316
Actual label: 9
Output voltages: [0.14156, 0.014036, 0.046787, 0.027793, 0.73541, 0.0064283, 0.01881, 0.027322, 0.19635, 0.79625]
Predicted label: 9
Correct prediction
Energy consumption = 146.662101 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 709 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 709 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 709 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.028088, 0.0053515, 0.0018594, 0.44903, 0.028499, 0.79879, 0.25105, 0.032981, 0.36145, 0.055594]
Predicted label: 5
Correct prediction
Energy consumption = 169.575735 pJ
sum error= 316
Actual label: 1
Output voltages: [0.053849, 0.79876, 0.43719, 0.024781, 0.32271, 0.0012569, 0.54607, 0.0013868, 0.043506, 0.0063648]
Predicted label: 1
Correct prediction
Energy consumption = 161.666661 pJ
sum error= 316
Actual label: 4
Output voltages: [0.01445, 0.0065018, 0.024748, 0.0020365, 0.79873, 0.0040183, 0.27364, 0.45526, 0.16884, 0.0019359]
Predicted label: 4
Correct prediction
Energy consumption = 144.387817 pJ
sum error= 316
Actual label: 2
Output voltages: [0.28398, 0.097628, 0.7987, 0.081718, 0.0078972, 0.0012121, 0.024468, 0.40975, 0.59839, 0.014375]
Predicted label: 2
Correct prediction
Energy consumption = 152.117490 pJ
sum error= 316
Actual label: 8
Output voltages: [0.10866, 0.028478, 0.082367, 0.045997, 0.0042779, 0.020841, 0.0044624, 0.0171, 0.79842, 0.75538]
Predicted label: 8
Correct prediction
Energy consumption = 150.128218 pJ
sum error= 316
Actual label: 9
Output voltages: [0.20948, 0.0054058, 0.018459, 0.028619, 0.40078, 0.0032435, 0.0041229, 0.015762, 0.39916, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 138.070934 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0029924, 0.0091977, 0.013737, 0.0022129, 0.79875, 0.0054889, 0.23328, 0.46708, 0.27231, 0.0044672]
Predicted label: 4
Correct prediction
Energy consumption = 140.474608 pJ
sum error= 316
Actual label: 3
Output voltages: [0.33626, 0.05695, 0.018776, 0.79862, 0.0062259, 0.026696, 0.0020359, 0.41583, 0.72153, 0.019159]
Predicted label: 3
Correct prediction
Energy consumption = 149.528232 pJ
sum error= 316
Actual label: 7
Output voltages: [0.269, 0.01218, 0.022276, 0.66012, 0.0044129, 0.01194, 0.0012497, 0.79877, 0.54892, 0.47502]
Predicted label: 7
Correct prediction
Energy consumption = 143.299017 pJ
sum error= 316
Actual label: 8
Output voltages: [0.010825, 0.26481, 0.024008, 0.21628, 0.0020272, 0.065939, 0.0044394, 0.015663, 0.79872, 0.18543]
Predicted label: 8
Correct prediction
Energy consumption = 143.662303 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 710 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 710 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 710 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.16304, 0.019982, 0.79876, 0.26342, 0.011245, 0.0012095, 0.030245, 0.30161, 0.33023, 0.026879]
Predicted label: 2
Correct prediction
Energy consumption = 161.726195 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0020414, 0.0024532, 0.017791, 0.0096946, 0.79868, 0.0025996, 0.054878, 0.059854, 0.32168, 0.0042928]
Predicted label: 4
Correct prediction
Energy consumption = 150.027719 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0020086, 0.0041217, 0.04289, 0.026566, 0.79876, 0.03893, 0.053631, 0.12057, 0.43698, 0.010224]
Predicted label: 4
Correct prediction
Energy consumption = 141.537499 pJ
sum error= 316
Actual label: 3
Output voltages: [0.24544, 0.023612, 0.13241, 0.79859, 0.030607, 0.025267, 0.018231, 0.04122, 0.46602, 0.13105]
Predicted label: 3
Correct prediction
Energy consumption = 147.294955 pJ
sum error= 316
Actual label: 3
Output voltages: [0.043593, 0.018183, 0.10484, 0.79874, 0.01621, 0.010489, 0.0031536, 0.061394, 0.59433, 0.039088]
Predicted label: 3
Correct prediction
Energy consumption = 129.863021 pJ
sum error= 316
Actual label: 6
Output voltages: [0.078485, 0.049028, 0.22763, 0.0012357, 0.19565, 0.2058, 0.79877, 0.0019132, 0.32677, 0.0017398]
Predicted label: 6
Correct prediction
Energy consumption = 146.154178 pJ
sum error= 316
Actual label: 9
Output voltages: [0.41568, 0.023319, 0.0018459, 0.22473, 0.47448, 0.0040874, 0.0025338, 0.0026726, 0.17861, 0.7983]
Predicted label: 9
Correct prediction
Energy consumption = 145.958726 pJ
sum error= 316
Actual label: 9
Output voltages: [0.34538, 0.0090757, 0.018156, 0.17976, 0.61687, 0.0019699, 0.0035504, 0.024008, 0.084494, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 132.646262 pJ
sum error= 316
Actual label: 5
Output voltages: [0.5021, 0.013506, 0.0011145, 0.49243, 0.058436, 0.79878, 0.29156, 0.017207, 0.26095, 0.067762]
Predicted label: 5
Correct prediction
Energy consumption = 146.245252 pJ
sum error= 316
Actual label: 8
Output voltages: [0.028714, 0.070829, 0.21794, 0.21326, 0.017042, 0.0069891, 0.037754, 0.0030358, 0.79866, 0.31977]
Predicted label: 8
Correct prediction
Energy consumption = 143.641539 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 711 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 711 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 711 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.13916, 0.023367, 0.13313, 0.0088623, 0.4093, 0.4311, 0.79876, 0.0018611, 0.6696, 0.0045174]
Predicted label: 6
Correct prediction
Energy consumption = 168.885496 pJ
sum error= 316
Actual label: 7
Output voltages: [0.044806, 0.015564, 0.088999, 0.48062, 0.0020016, 0.013766, 0.0011639, 0.79854, 0.20496, 0.40018]
Predicted label: 7
Correct prediction
Energy consumption = 156.323701 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79662, 0.073093, 0.052977, 0.015764, 0.0023786, 0.00122, 0.69675, 0.02157, 0.23176, 0.16792]
Predicted label: 0
Correct prediction
Energy consumption = 156.070912 pJ
sum error= 316
Actual label: 6
Output voltages: [0.23345, 0.021721, 0.3586, 0.0010759, 0.35683, 0.0495, 0.79873, 0.0011523, 0.059828, 0.0033991]
Predicted label: 6
Correct prediction
Energy consumption = 138.419961 pJ
sum error= 316
Actual label: 8
Output voltages: [0.025622, 0.06101, 0.28103, 0.10108, 0.021532, 0.025176, 0.026357, 0.028981, 0.79868, 0.14473]
Predicted label: 8
Correct prediction
Energy consumption = 152.632726 pJ
sum error= 316
Actual label: 2
Output voltages: [0.055265, 0.014418, 0.79879, 0.34314, 0.029699, 0.0012012, 0.0092078, 0.49314, 0.33219, 0.026642]
Predicted label: 2
Correct prediction
Energy consumption = 141.307010 pJ
sum error= 316
Actual label: 6
Output voltages: [0.04513, 0.10681, 0.4322, 0.0011592, 0.2843, 0.044614, 0.79878, 0.0012263, 0.30753, 0.0019385]
Predicted label: 6
Correct prediction
Energy consumption = 141.502205 pJ
sum error= 316
Actual label: 3
Output voltages: [0.019, 0.017539, 0.27935, 0.79875, 0.0011423, 0.0041947, 0.003876, 0.027373, 0.78514, 0.016911]
Predicted label: 3
Correct prediction
Energy consumption = 142.091039 pJ
sum error= 316
Actual label: 9
Output voltages: [0.052397, 0.019723, 0.021992, 0.063523, 0.036747, 0.014629, 0.0013007, 0.023705, 0.49362, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 148.965392 pJ
sum error= 316
Actual label: 3
Output voltages: [0.26171, 0.052414, 0.042889, 0.79869, 0.012312, 0.017232, 0.015967, 0.016886, 0.70722, 0.033902]
Predicted label: 3
Correct prediction
Energy consumption = 138.100768 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 712 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 712 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 712 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.13598, 0.12123, 0.79815, 0.40509, 0.04687, 0.0010953, 0.030144, 0.5249, 0.73069, 0.0098115]
Predicted label: 2
Correct prediction
Energy consumption = 168.273290 pJ
sum error= 316
Actual label: 8
Output voltages: [0.033424, 0.029422, 0.030201, 0.032052, 0.0059296, 0.0024245, 0.0023433, 0.0035199, 0.79737, 0.74176]
Predicted label: 8
Correct prediction
Energy consumption = 155.051122 pJ
sum error= 316
Actual label: 6
Output voltages: [0.19019, 0.13928, 0.069393, 0.0058697, 0.37166, 0.23032, 0.79871, 0.003327, 0.19662, 0.0035999]
Predicted label: 6
Correct prediction
Energy consumption = 156.216076 pJ
sum error= 316
Actual label: 1
Output voltages: [0.02253, 0.79864, 0.29306, 0.039468, 0.11916, 0.0010681, 0.5512, 0.0069784, 0.05928, 0.024325]
Predicted label: 1
Correct prediction
Energy consumption = 159.121565 pJ
sum error= 316
Actual label: 7
Output voltages: [0.10714, 0.047043, 0.75591, 0.039674, 0.0014488, 0.0011576, 0.0010696, 0.79879, 0.58935, 0.049965]
Predicted label: 7
Correct prediction
Energy consumption = 148.344565 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0032909, 0.0073105, 0.036898, 0.0082542, 0.79871, 0.0094452, 0.11709, 0.36908, 0.26188, 0.0016126]
Predicted label: 4
Correct prediction
Energy consumption = 148.774977 pJ
sum error= 316
Actual label: 8
Output voltages: [0.0060852, 0.022014, 0.061392, 0.037304, 0.018369, 0.027229, 0.014883, 0.01618, 0.79872, 0.059016]
Predicted label: 8
Correct prediction
Energy consumption = 143.909571 pJ
sum error= 316
Actual label: 8
Output voltages: [0.0057076, 0.24256, 0.030665, 0.3784, 0.0025934, 0.0059413, 0.0036723, 0.027286, 0.79879, 0.23627]
Predicted label: 8
Correct prediction
Energy consumption = 136.201537 pJ
sum error= 316
Actual label: 9
Output voltages: [0.24937, 0.0072144, 0.026629, 0.021399, 0.43766, 0.0029899, 0.0013365, 0.021981, 0.42104, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 144.591836 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79822, 0.18141, 0.14457, 0.023823, 0.01526, 0.0031643, 0.13777, 0.01015, 0.087093, 0.018302]
Predicted label: 0
Correct prediction
Energy consumption = 150.509735 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 713 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 713 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 713 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.065276, 0.13126, 0.037635, 0.79866, 0.0052797, 0.0019635, 0.0041263, 0.035407, 0.45042, 0.16256]
Predicted label: 3
Correct prediction
Energy consumption = 165.897600 pJ
sum error= 316
Actual label: 3
Output voltages: [0.13361, 0.048789, 0.060529, 0.79852, 0.013269, 0.02119, 0.0060745, 0.055211, 0.53048, 0.040069]
Predicted label: 3
Correct prediction
Energy consumption = 135.732935 pJ
sum error= 316
Actual label: 9
Output voltages: [0.1557, 0.0057724, 0.01733, 0.01642, 0.32324, 0.023287, 0.023845, 0.012783, 0.43404, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 146.066815 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79853, 0.050744, 0.12407, 0.047651, 0.019017, 0.0016031, 0.59251, 0.019288, 0.35211, 0.058656]
Predicted label: 0
Correct prediction
Energy consumption = 156.940590 pJ
sum error= 316
Actual label: 5
Output voltages: [0.036704, 0.0010859, 0.0010673, 0.18496, 0.20502, 0.79876, 0.461, 0.01193, 0.73768, 0.026845]
Predicted label: 5
Correct prediction
Energy consumption = 143.661233 pJ
sum error= 316
Actual label: 2
Output voltages: [0.11438, 0.033842, 0.79879, 0.34751, 0.010753, 0.0011935, 0.017341, 0.38781, 0.22463, 0.012804]
Predicted label: 2
Correct prediction
Energy consumption = 145.074856 pJ
sum error= 316
Actual label: 9
Output voltages: [0.047923, 0.015069, 0.035801, 0.025061, 0.058835, 0.0051541, 0.0049693, 0.0041865, 0.7473, 0.79357]
Predicted label: 9
Correct prediction
Energy consumption = 146.034243 pJ
sum error= 316
Actual label: 4
Output voltages: [0.039833, 0.0059189, 0.30827, 0.0096456, 0.79879, 0.0088822, 0.065834, 0.022333, 0.31629, 0.0014572]
Predicted label: 4
Correct prediction
Energy consumption = 137.696151 pJ
sum error= 316
Actual label: 1
Output voltages: [0.019019, 0.79879, 0.38139, 0.049237, 0.2002, 0.001078, 0.54745, 0.014694, 0.029368, 0.0027986]
Predicted label: 1
Correct prediction
Energy consumption = 149.692395 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79874, 0.026532, 0.083542, 0.018284, 0.017801, 0.0019898, 0.34972, 0.0063734, 0.33289, 0.048825]
Predicted label: 0
Correct prediction
Energy consumption = 146.137244 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 714 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 714 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 714 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.4734, 0.022423, 0.040339, 0.79862, 0.020192, 0.015875, 0.022364, 0.018536, 0.39979, 0.034236]
Predicted label: 3
Correct prediction
Energy consumption = 166.364192 pJ
sum error= 316
Actual label: 7
Output voltages: [0.045268, 0.03991, 0.1848, 0.40083, 0.0028035, 0.0010822, 0.0010997, 0.79865, 0.42969, 0.20083]
Predicted label: 7
Correct prediction
Energy consumption = 152.614810 pJ
sum error= 316
Actual label: 5
Output voltages: [0.034907, 0.0011076, 0.0010707, 0.062316, 0.17813, 0.79869, 0.18207, 0.021394, 0.7219, 0.043604]
Predicted label: 5
Correct prediction
Energy consumption = 149.066653 pJ
sum error= 316
Actual label: 8
Output voltages: [0.025266, 0.089582, 0.3397, 0.068606, 0.0085638, 0.010043, 0.03862, 0.027107, 0.79876, 0.14349]
Predicted label: 8
Correct prediction
Energy consumption = 142.222583 pJ
sum error= 316
Actual label: 7
Output voltages: [0.36059, 0.048828, 0.02995, 0.22067, 0.013728, 0.0012461, 0.0010864, 0.79868, 0.6371, 0.21697]
Predicted label: 7
Correct prediction
Energy consumption = 151.552331 pJ
sum error= 316
Actual label: 7
Output voltages: [0.4365, 0.11811, 0.38996, 0.0032215, 0.022415, 0.0010825, 0.0022044, 0.79877, 0.40068, 0.14154]
Predicted label: 7
Correct prediction
Energy consumption = 139.836774 pJ
sum error= 316
Actual label: 8
Output voltages: [0.035971, 0.030528, 0.28696, 0.065955, 0.024862, 0.019134, 0.01709, 0.013155, 0.79871, 0.055457]
Predicted label: 8
Correct prediction
Energy consumption = 147.665830 pJ
sum error= 316
Actual label: 2
Output voltages: [0.44593, 0.011236, 0.79877, 0.047002, 0.013637, 0.0010682, 0.10868, 0.24584, 0.68069, 0.0088221]
Predicted label: 2
Correct prediction
Energy consumption = 142.826114 pJ
sum error= 316
Actual label: 9
Output voltages: [0.090899, 0.023236, 0.03117, 0.18774, 0.081556, 0.0097284, 0.0053277, 0.033792, 0.56705, 0.79843]
Predicted label: 9
Correct prediction
Energy consumption = 151.549298 pJ
sum error= 316
Actual label: 7
Output voltages: [0.1093, 0.039929, 0.29603, 0.049325, 0.017478, 0.0018364, 0.0012855, 0.79879, 0.36862, 0.2467]
Predicted label: 7
Correct prediction
Energy consumption = 138.486301 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 715 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 715 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 715 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.046361, 0.79878, 0.15268, 0.053424, 0.42834, 0.0010926, 0.2083, 0.0026808, 0.028209, 0.067127]
Predicted label: 1
Correct prediction
Energy consumption = 172.979460 pJ
sum error= 316
Actual label: 2
Output voltages: [0.29789, 0.010951, 0.79879, 0.28235, 0.03542, 0.0011796, 0.020856, 0.19692, 0.55831, 0.036296]
Predicted label: 2
Correct prediction
Energy consumption = 142.173868 pJ
sum error= 316
Actual label: 6
Output voltages: [0.087013, 0.046309, 0.16187, 0.0011905, 0.35153, 0.054545, 0.79873, 0.001066, 0.43636, 0.0025272]
Predicted label: 6
Correct prediction
Energy consumption = 148.612920 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0011813, 0.01559, 0.066285, 0.0010872, 0.79876, 0.02376, 0.029007, 0.043235, 0.66655, 0.020665]
Predicted label: 4
Correct prediction
Energy consumption = 146.607207 pJ
sum error= 316
Actual label: 2
Output voltages: [0.19189, 0.044205, 0.79878, 0.12236, 0.01527, 0.0013113, 0.050107, 0.40331, 0.48414, 0.024205]
Predicted label: 2
Correct prediction
Energy consumption = 151.223788 pJ
sum error= 316
Actual label: 5
Output voltages: [0.11843, 0.0010826, 0.0034224, 0.4316, 0.063975, 0.79879, 0.27312, 0.01457, 0.69409, 0.008354]
Predicted label: 5
Correct prediction
Energy consumption = 143.668380 pJ
sum error= 316
Actual label: 2
Output voltages: [0.041179, 0.15637, 0.7987, 0.026061, 0.017088, 0.0011693, 0.017615, 0.62134, 0.13256, 0.039152]
Predicted label: 2
Correct prediction
Energy consumption = 148.605528 pJ
sum error= 316
Actual label: 3
Output voltages: [0.17731, 0.051558, 0.091875, 0.79861, 0.018065, 0.0091452, 0.0082719, 0.02617, 0.67826, 0.028032]
Predicted label: 3
Correct prediction
Energy consumption = 146.497522 pJ
sum error= 316
Actual label: 6
Output voltages: [0.22753, 0.078321, 0.069376, 0.0064561, 0.37432, 0.54873, 0.79875, 0.0093963, 0.41246, 0.0025028]
Predicted label: 6
Correct prediction
Energy consumption = 158.146243 pJ
sum error= 316
Actual label: 6
Output voltages: [0.1885, 0.12411, 0.2196, 0.0030383, 0.10837, 0.32607, 0.79873, 0.0059836, 0.27727, 0.01198]
Predicted label: 6
Correct prediction
Energy consumption = 134.970331 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 716 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 716 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 716 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.047525, 0.0010791, 0.0011121, 0.68462, 0.16371, 0.79879, 0.62246, 0.011317, 0.688, 0.025222]
Predicted label: 5
Correct prediction
Energy consumption = 164.657176 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79855, 0.046938, 0.14394, 0.012706, 0.03704, 0.0050884, 0.30053, 0.016614, 0.14498, 0.011865]
Predicted label: 0
Correct prediction
Energy consumption = 157.572842 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79548, 0.0064477, 0.21645, 0.033078, 0.028628, 0.0020646, 0.52612, 0.0061404, 0.63666, 0.29621]
Predicted label: 0
Correct prediction
Energy consumption = 151.692182 pJ
sum error= 316
Actual label: 2
Output voltages: [0.11855, 0.069532, 0.79879, 0.20195, 0.027558, 0.0011415, 0.043574, 0.72335, 0.52071, 0.092615]
Predicted label: 2
Correct prediction
Energy consumption = 147.388451 pJ
sum error= 316
Actual label: 8
Output voltages: [0.0064881, 0.11911, 0.22359, 0.061103, 0.024213, 0.016357, 0.011013, 0.036515, 0.79867, 0.076892]
Predicted label: 8
Correct prediction
Energy consumption = 150.832048 pJ
sum error= 316
Actual label: 1
Output voltages: [0.051158, 0.79879, 0.062454, 0.0045584, 0.56782, 0.002179, 0.17323, 0.0010742, 0.17005, 0.054389]
Predicted label: 1
Correct prediction
Energy consumption = 154.814056 pJ
sum error= 316
Actual label: 6
Output voltages: [0.02165, 0.019691, 0.42572, 0.001068, 0.29603, 0.042888, 0.79878, 0.0016487, 0.52886, 0.0014545]
Predicted label: 6
Correct prediction
Energy consumption = 140.382621 pJ
sum error= 316
Actual label: 1
Output voltages: [0.018178, 0.79858, 0.037682, 0.012318, 0.038333, 0.001519, 0.59615, 0.010473, 0.25598, 0.020983]
Predicted label: 1
Correct prediction
Energy consumption = 156.230884 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79877, 0.068772, 0.44046, 0.011392, 0.031794, 0.0014961, 0.28554, 0.011492, 0.34967, 0.048992]
Predicted label: 0
Correct prediction
Energy consumption = 153.856534 pJ
sum error= 316
Actual label: 4
Output voltages: [0.003082, 0.021221, 0.037711, 0.004363, 0.79875, 0.014739, 0.033837, 0.38809, 0.41556, 0.0035832]
Predicted label: 4
Correct prediction
Energy consumption = 148.878532 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 717 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 717 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 717 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.048813, 0.31821, 0.10089, 0.79876, 0.0011357, 0.0051387, 0.0019656, 0.34905, 0.78241, 0.011648]
Predicted label: 3
Correct prediction
Energy consumption = 165.260487 pJ
sum error= 316
Actual label: 1
Output voltages: [0.03962, 0.79857, 0.12271, 0.048162, 0.31772, 0.0010667, 0.37012, 0.0054453, 0.037405, 0.15344]
Predicted label: 1
Correct prediction
Energy consumption = 156.354473 pJ
sum error= 316
Actual label: 6
Output voltages: [0.021393, 0.027397, 0.32539, 0.0015145, 0.52606, 0.069427, 0.79869, 0.002004, 0.40398, 0.005458]
Predicted label: 6
Correct prediction
Energy consumption = 144.995881 pJ
sum error= 316
Actual label: 1
Output voltages: [0.028032, 0.79871, 0.17333, 0.030415, 0.080964, 0.0013961, 0.73124, 0.0010801, 0.15749, 0.022187]
Predicted label: 1
Correct prediction
Energy consumption = 145.684189 pJ
sum error= 316
Actual label: 9
Output voltages: [0.19631, 0.0032858, 0.024802, 0.01661, 0.28216, 0.0023059, 0.0034442, 0.013607, 0.55382, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 150.145614 pJ
sum error= 316
Actual label: 0
Output voltages: [0.7987, 0.26946, 0.027137, 0.023333, 0.024521, 0.015099, 0.27206, 0.011175, 0.041832, 0.16458]
Predicted label: 0
Correct prediction
Energy consumption = 144.777999 pJ
sum error= 316
Actual label: 1
Output voltages: [0.04174, 0.79848, 0.048607, 0.14864, 0.021142, 0.0013907, 0.65992, 0.049308, 0.035367, 0.032671]
Predicted label: 1
Correct prediction
Energy consumption = 163.348730 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0022397, 0.024829, 0.048344, 0.028039, 0.79862, 0.0010769, 0.022107, 0.056571, 0.023109, 0.044914]
Predicted label: 4
Correct prediction
Energy consumption = 156.927911 pJ
sum error= 316
Actual label: 5
Output voltages: [0.015343, 0.0010757, 0.0014498, 0.51308, 0.057603, 0.7985, 0.039276, 0.032814, 0.66414, 0.16616]
Predicted label: 5
Correct prediction
Energy consumption = 144.501359 pJ
sum error= 316
Actual label: 6
Output voltages: [0.031754, 0.0026995, 0.034232, 0.012842, 0.1244, 0.22616, 0.79869, 0.0010726, 0.76677, 0.054652]
Predicted label: 6
Correct prediction
Energy consumption = 133.547206 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 718 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 718 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 718 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.038248, 0.038294, 0.16448, 0.056848, 0.01028, 0.0010671, 0.0020742, 0.79857, 0.022802, 0.1395]
Predicted label: 7
Correct prediction
Energy consumption = 174.317875 pJ
sum error= 316
Actual label: 8
Output voltages: [0.036171, 0.024961, 0.47473, 0.51632, 0.0027844, 0.0058437, 0.019041, 0.0012286, 0.79879, 0.045621]
Predicted label: 8
Correct prediction
Energy consumption = 150.386312 pJ
sum error= 316
Actual label: 9
Output voltages: [0.03953, 0.0012613, 0.044516, 0.040443, 0.0082575, 0.071132, 0.014763, 0.30088, 0.50781, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 152.505426 pJ
sum error= 316
Actual label: 1
Output voltages: [0.015155, 0.79846, 0.24161, 0.044137, 0.028943, 0.0044618, 0.56412, 0.01202, 0.29035, 0.023384]
Predicted label: 1
Correct prediction
Energy consumption = 168.340490 pJ
sum error= 316
Actual label: 2
Output voltages: [0.67483, 0.0014532, 0.79877, 0.12725, 0.006695, 0.0010741, 0.020299, 0.060259, 0.60235, 0.0040915]
Predicted label: 2
Correct prediction
Energy consumption = 142.199974 pJ
sum error= 316
Actual label: 3
Output voltages: [0.4181, 0.0032094, 0.030599, 0.79869, 0.011465, 0.04797, 0.0095958, 0.012541, 0.46467, 0.020731]
Predicted label: 3
Correct prediction
Energy consumption = 144.645998 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0014136, 0.003275, 0.042803, 0.035338, 0.79867, 0.0016452, 0.014955, 0.011478, 0.11675, 0.039438]
Predicted label: 4
Correct prediction
Energy consumption = 141.381674 pJ
sum error= 316
Actual label: 5
Output voltages: [0.26456, 0.0011817, 0.0010859, 0.7405, 0.029033, 0.79874, 0.31984, 0.044138, 0.57588, 0.055357]
Predicted label: 5
Correct prediction
Energy consumption = 139.159117 pJ
sum error= 316
Actual label: 6
Output voltages: [0.023123, 0.0083879, 0.17389, 0.0032694, 0.19472, 0.32786, 0.79879, 0.0034437, 0.65931, 0.0018528]
Predicted label: 6
Correct prediction
Energy consumption = 141.559493 pJ
sum error= 316
Actual label: 7
Output voltages: [0.096232, 0.24363, 0.37767, 0.23995, 0.0037096, 0.0011323, 0.0012274, 0.79879, 0.039342, 0.23779]
Predicted label: 7
Correct prediction
Energy consumption = 148.861501 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 719 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 719 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 719 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.035841, 0.039021, 0.014758, 0.0020616, 0.010452, 0.58561, 0.031692, 0.084629, 0.029755]
Predicted label: 0
Correct prediction
Energy consumption = 158.524793 pJ
sum error= 316
Actual label: 1
Output voltages: [0.045151, 0.79879, 0.14365, 0.009477, 0.15789, 0.0010931, 0.67297, 0.0014954, 0.19416, 0.0069729]
Predicted label: 1
Correct prediction
Energy consumption = 156.938913 pJ
sum error= 316
Actual label: 2
Output voltages: [0.4543, 0.0068696, 0.79876, 0.023505, 0.0071512, 0.0011113, 0.038217, 0.042171, 0.59033, 0.001675]
Predicted label: 2
Correct prediction
Energy consumption = 140.793021 pJ
sum error= 316
Actual label: 3
Output voltages: [0.74794, 0.023083, 0.11624, 0.79878, 0.004523, 0.028086, 0.0082385, 0.0064199, 0.31122, 0.012272]
Predicted label: 3
Correct prediction
Energy consumption = 137.144629 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0029689, 0.026004, 0.12136, 0.078121, 0.79869, 0.0015519, 0.052414, 0.066501, 0.005358, 0.041273]
Predicted label: 4
Correct prediction
Energy consumption = 144.217419 pJ
sum error= 316
Actual label: 5
Output voltages: [0.27799, 0.0010908, 0.0012073, 0.41662, 0.024382, 0.79875, 0.42449, 0.043777, 0.50752, 0.010944]
Predicted label: 5
Correct prediction
Energy consumption = 133.004346 pJ
sum error= 316
Actual label: 6
Output voltages: [0.19277, 0.0056735, 0.10505, 0.0032344, 0.15756, 0.1243, 0.79874, 0.0010665, 0.71747, 0.023008]
Predicted label: 6
Correct prediction
Energy consumption = 138.715106 pJ
sum error= 316
Actual label: 7
Output voltages: [0.71559, 0.016211, 0.011199, 0.056995, 0.14059, 0.023615, 0.0064475, 0.79869, 0.17753, 0.28766]
Predicted label: 7
Correct prediction
Energy consumption = 150.968119 pJ
sum error= 316
Actual label: 8
Output voltages: [0.36536, 0.013945, 0.58211, 0.26797, 0.01262, 0.001066, 0.024846, 0.0028954, 0.78989, 0.29971]
Predicted label: 8
Correct prediction
Energy consumption = 145.755830 pJ
sum error= 316
Actual label: 9
Output voltages: [0.2309, 0.013471, 0.013594, 0.04196, 0.052867, 0.02216, 0.0012712, 0.038332, 0.48965, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 141.046787 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 720 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 720 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 720 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.025228, 0.28257, 0.053108, 0.36095, 0.02186, 0.0043133, 0.049179, 0.003755, 0.79877, 0.3743]
Predicted label: 8
Correct prediction
Energy consumption = 172.952092 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0089368, 0.033255, 0.093708, 0.020451, 0.79867, 0.0012899, 0.020873, 0.036059, 0.03645, 0.0132]
Predicted label: 4
Correct prediction
Energy consumption = 152.209926 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79877, 0.31579, 0.031789, 0.027694, 0.0059488, 0.023024, 0.35939, 0.076109, 0.049717, 0.038048]
Predicted label: 0
Correct prediction
Energy consumption = 148.939376 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79879, 0.04345, 0.03718, 0.022582, 0.01665, 0.0035786, 0.40343, 0.014204, 0.10659, 0.033856]
Predicted label: 0
Correct prediction
Energy consumption = 140.391408 pJ
sum error= 316
Actual label: 7
Output voltages: [0.22293, 0.060382, 0.75572, 0.033962, 0.0034974, 0.0011578, 0.0010669, 0.79868, 0.27911, 0.062952]
Predicted label: 7
Correct prediction
Energy consumption = 151.633062 pJ
sum error= 316
Actual label: 2
Output voltages: [0.13739, 0.034135, 0.79868, 0.026607, 0.0027572, 0.0011547, 0.012195, 0.36926, 0.38593, 0.032551]
Predicted label: 2
Correct prediction
Energy consumption = 128.953927 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0017686, 0.042624, 0.086149, 0.028505, 0.79867, 0.0026808, 0.10747, 0.24791, 0.019748, 0.030083]
Predicted label: 4
Correct prediction
Energy consumption = 144.479030 pJ
sum error= 316
Actual label: 3
Output voltages: [0.34907, 0.015365, 0.031115, 0.79868, 0.013657, 0.029669, 0.0035291, 0.012546, 0.6317, 0.020059]
Predicted label: 3
Correct prediction
Energy consumption = 143.109886 pJ
sum error= 316
Actual label: 8
Output voltages: [0.014859, 0.1197, 0.73852, 0.45693, 0.0010669, 0.0015025, 0.02287, 0.37407, 0.7984, 0.19596]
Predicted label: 8
Correct prediction
Energy consumption = 137.651724 pJ
sum error= 316
Actual label: 6
Output voltages: [0.089675, 0.0013593, 0.016065, 0.014438, 0.063316, 0.76387, 0.79708, 0.0012088, 0.77466, 0.027995]
Predicted label: 6
Correct prediction
Energy consumption = 141.948795 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 721 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 721 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 721 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29086, 0.037203, 0.014573, 0.023017, 0.40349, 0.17221, 0.79876, 0.0028198, 0.70946, 0.019439]
Predicted label: 6
Correct prediction
Energy consumption = 170.593414 pJ
sum error= 316
Actual label: 3
Output voltages: [0.23795, 0.0011675, 0.048819, 0.79879, 0.035166, 0.52695, 0.013927, 0.030759, 0.70989, 0.014231]
Predicted label: 3
Correct prediction
Energy consumption = 145.591529 pJ
sum error= 316
Actual label: 2
Output voltages: [0.030146, 0.0035286, 0.79879, 0.22247, 0.046297, 0.0011519, 0.013782, 0.19855, 0.17973, 0.037482]
Predicted label: 2
Correct prediction
Energy consumption = 131.115391 pJ
sum error= 316
Actual label: 6
Output voltages: [0.12152, 0.019873, 0.29283, 0.0017054, 0.36904, 0.34614, 0.79879, 0.0010735, 0.51335, 0.015903]
Predicted label: 6
Correct prediction
Energy consumption = 136.516920 pJ
sum error= 316
Actual label: 3
Output voltages: [0.40027, 0.0091256, 0.036205, 0.79868, 0.0072275, 0.016274, 0.010581, 0.018965, 0.5113, 0.026611]
Predicted label: 3
Correct prediction
Energy consumption = 148.309250 pJ
sum error= 316
Actual label: 3
Output voltages: [0.19709, 0.034664, 0.035998, 0.79862, 0.0073164, 0.043771, 0.0046929, 0.070545, 0.72594, 0.020527]
Predicted label: 3
Correct prediction
Energy consumption = 131.312528 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79854, 0.09531, 0.042911, 0.15372, 0.0012517, 0.0048096, 0.72726, 0.04638, 0.45125, 0.035923]
Predicted label: 0
Correct prediction
Energy consumption = 143.580395 pJ
sum error= 316
Actual label: 1
Output voltages: [0.10334, 0.79873, 0.45703, 0.0035797, 0.45921, 0.0025591, 0.056314, 0.0045253, 0.019334, 0.23373]
Predicted label: 1
Correct prediction
Energy consumption = 157.444413 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0014967, 0.088794, 0.019803, 0.01853, 0.79857, 0.020839, 0.11888, 0.33144, 0.0058171, 0.062373]
Predicted label: 4
Correct prediction
Energy consumption = 145.426298 pJ
sum error= 316
Actual label: 7
Output voltages: [0.32484, 0.065388, 0.025791, 0.014076, 0.022928, 0.011623, 0.0019356, 0.79855, 0.064135, 0.15513]
Predicted label: 7
Correct prediction
Energy consumption = 151.721902 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 722 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 722 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 722 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.038022, 0.042913, 0.047749, 0.4866, 0.005413, 0.0095176, 0.037117, 0.0088526, 0.79733, 0.52018]
Predicted label: 8
Correct prediction
Energy consumption = 165.346337 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79875, 0.1413, 0.020074, 0.028268, 0.032322, 0.01161, 0.28281, 0.021678, 0.082856, 0.41652]
Predicted label: 0
Correct prediction
Energy consumption = 147.579671 pJ
sum error= 316
Actual label: 3
Output voltages: [0.19454, 0.016416, 0.017362, 0.79868, 0.009725, 0.0075468, 0.0084703, 0.01138, 0.54974, 0.045295]
Predicted label: 3
Correct prediction
Energy consumption = 142.460306 pJ
sum error= 316
Actual label: 1
Output voltages: [0.32822, 0.79865, 0.0078768, 0.038592, 0.63863, 0.0081644, 0.20848, 0.0011407, 0.33902, 0.051452]
Predicted label: 1
Correct prediction
Energy consumption = 152.590980 pJ
sum error= 316
Actual label: 9
Output voltages: [0.29876, 0.080873, 0.032618, 0.22625, 0.059934, 0.036491, 0.016381, 0.03349, 0.44666, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 150.999654 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79878, 0.089561, 0.023329, 0.027571, 0.019107, 0.012051, 0.46798, 0.0087681, 0.041489, 0.11947]
Predicted label: 0
Correct prediction
Energy consumption = 155.740882 pJ
sum error= 316
Actual label: 1
Output voltages: [0.029636, 0.79879, 0.019333, 0.063292, 0.14714, 0.0013549, 0.59292, 0.0042724, 0.07786, 0.052882]
Predicted label: 1
Correct prediction
Energy consumption = 153.440004 pJ
sum error= 316
Actual label: 9
Output voltages: [0.58294, 0.04292, 0.015018, 0.16167, 0.38223, 0.018766, 0.0074991, 0.0031748, 0.24117, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 149.424828 pJ
sum error= 316
Actual label: 1
Output voltages: [0.068401, 0.79558, 0.045324, 0.0017149, 0.4146, 0.0010849, 0.44275, 0.0010676, 0.55129, 0.032444]
Predicted label: 1
Correct prediction
Energy consumption = 160.223343 pJ
sum error= 316
Actual label: 2
Output voltages: [0.077514, 0.0020059, 0.79875, 0.034607, 0.014136, 0.0010661, 0.036215, 0.29368, 0.75164, 0.014402]
Predicted label: 2
Correct prediction
Energy consumption = 138.926431 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 723 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 723 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 723 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25209, 0.15809, 0.31898, 0.03671, 0.019884, 0.0026039, 0.0010671, 0.79865, 0.035951, 0.30048]
Predicted label: 7
Correct prediction
Energy consumption = 173.348631 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79878, 0.043264, 0.0062967, 0.030085, 0.032393, 0.0097085, 0.53687, 0.029575, 0.2641, 0.12607]
Predicted label: 0
Correct prediction
Energy consumption = 145.838842 pJ
sum error= 316
Actual label: 1
Output voltages: [0.021272, 0.79878, 0.025078, 0.0022473, 0.36912, 0.0029128, 0.3248, 0.0046789, 0.25231, 0.033243]
Predicted label: 1
Correct prediction
Energy consumption = 159.806341 pJ
sum error= 316
Actual label: 3
Output voltages: [0.79814, 0.001075, 0.0084285, 0.79602, 0.0011275, 0.54069, 0.0039034, 0.077732, 0.38822, 0.014903]
Predicted label: 0
Wrong prediction!
Energy consumption = 149.511250 pJ
sum error= 317
Actual label: 8
Output voltages: [0.11079, 0.027994, 0.56139, 0.038464, 0.0021074, 0.00194, 0.008697, 0.023965, 0.79879, 0.31139]
Predicted label: 8
Correct prediction
Energy consumption = 141.818281 pJ
sum error= 317
Actual label: 2
Output voltages: [0.059503, 0.001066, 0.79879, 0.041084, 0.025967, 0.0040601, 0.018042, 0.46746, 0.78021, 0.0037693]
Predicted label: 2
Correct prediction
Energy consumption = 133.617102 pJ
sum error= 317
Actual label: 9
Output voltages: [0.47096, 0.0083576, 0.042576, 0.046841, 0.25515, 0.024418, 0.016317, 0.016971, 0.44472, 0.79353]
Predicted label: 9
Correct prediction
Energy consumption = 146.609166 pJ
sum error= 317
Actual label: 2
Output voltages: [0.59373, 0.0012954, 0.79837, 0.40858, 0.0075408, 0.010712, 0.011151, 0.03085, 0.73085, 0.0018362]
Predicted label: 2
Correct prediction
Energy consumption = 140.029907 pJ
sum error= 317
Actual label: 7
Output voltages: [0.22577, 0.21753, 0.66597, 0.026608, 0.024384, 0.0010895, 0.020796, 0.79875, 0.0051407, 0.13515]
Predicted label: 7
Correct prediction
Energy consumption = 151.111256 pJ
sum error= 317
Actual label: 6
Output voltages: [0.20078, 0.04729, 0.17974, 0.003875, 0.24517, 0.17931, 0.79876, 0.0022202, 0.68194, 0.0033693]
Predicted label: 6
Correct prediction
Energy consumption = 139.628777 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 724 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 724 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 724 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.025008, 0.0011013, 0.010119, 0.76489, 0.23257, 0.79769, 0.026446, 0.023603, 0.58016, 0.0010987]
Predicted label: 5
Correct prediction
Energy consumption = 153.939912 pJ
sum error= 317
Actual label: 5
Output voltages: [0.031635, 0.0014285, 0.0010779, 0.21254, 0.52508, 0.79848, 0.34634, 0.004925, 0.51716, 0.0552]
Predicted label: 5
Correct prediction
Energy consumption = 120.417753 pJ
sum error= 317
Actual label: 9
Output voltages: [0.53472, 0.0092697, 0.019208, 0.047904, 0.28733, 0.042798, 0.017072, 0.0058266, 0.49234, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 146.068213 pJ
sum error= 317
Actual label: 9
Output voltages: [0.20365, 0.030911, 0.01584, 0.18023, 0.13729, 0.020933, 0.028103, 0.03041, 0.64235, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 129.470845 pJ
sum error= 317
Actual label: 8
Output voltages: [0.050804, 0.019318, 0.051552, 0.053581, 0.0094204, 0.047528, 0.0075922, 0.0033391, 0.79873, 0.3995]
Predicted label: 8
Correct prediction
Energy consumption = 137.689344 pJ
sum error= 317
Actual label: 2
Output voltages: [0.32145, 0.0045657, 0.79874, 0.091067, 0.0049505, 0.0010968, 0.041037, 0.10544, 0.73199, 0.0062401]
Predicted label: 2
Correct prediction
Energy consumption = 138.689023 pJ
sum error= 317
Actual label: 9
Output voltages: [0.25546, 0.0074322, 0.016077, 0.025877, 0.046029, 0.015148, 0.0034792, 0.050371, 0.60967, 0.79563]
Predicted label: 9
Correct prediction
Energy consumption = 146.755080 pJ
sum error= 317
Actual label: 1
Output voltages: [0.024436, 0.79833, 0.31577, 0.0069218, 0.27486, 0.0011253, 0.4786, 0.0019077, 0.080712, 0.0081192]
Predicted label: 1
Correct prediction
Energy consumption = 152.006130 pJ
sum error= 317
Actual label: 3
Output voltages: [0.049782, 0.0011879, 0.053791, 0.79879, 0.0057038, 0.16449, 0.01882, 0.022979, 0.35269, 0.0036865]
Predicted label: 3
Correct prediction
Energy consumption = 139.389626 pJ
sum error= 317
Actual label: 2
Output voltages: [0.52302, 0.0010675, 0.79839, 0.21587, 0.012726, 0.0070614, 0.041957, 0.27754, 0.75803, 0.0035099]
Predicted label: 2
Correct prediction
Energy consumption = 129.058800 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 725 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 725 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 725 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.49285, 0.0042918, 0.13333, 0.79879, 0.012373, 0.38341, 0.0016867, 0.0061185, 0.75635, 0.0035837]
Predicted label: 3
Correct prediction
Energy consumption = 159.105373 pJ
sum error= 317
Actual label: 4
Output voltages: [0.027392, 0.02433, 0.078181, 0.001693, 0.79867, 0.0029675, 0.27616, 0.31443, 0.03745, 0.0053708]
Predicted label: 4
Correct prediction
Energy consumption = 146.710990 pJ
sum error= 317
Actual label: 3
Output voltages: [0.66966, 0.0073399, 0.022654, 0.79873, 0.024235, 0.062316, 0.0067676, 0.0072614, 0.56749, 0.016813]
Predicted label: 3
Correct prediction
Energy consumption = 144.631159 pJ
sum error= 317
Actual label: 1
Output voltages: [0.17928, 0.79819, 0.51754, 0.0030165, 0.66463, 0.0010689, 0.30136, 0.0014662, 0.037932, 0.0085863]
Predicted label: 1
Correct prediction
Energy consumption = 152.809274 pJ
sum error= 317
Actual label: 9
Output voltages: [0.3353, 0.023383, 0.022379, 0.057871, 0.17646, 0.021923, 0.010501, 0.01219, 0.44459, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 145.485149 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79873, 0.038433, 0.088154, 0.010245, 0.019623, 0.013288, 0.19884, 0.033219, 0.12736, 0.12161]
Predicted label: 0
Correct prediction
Energy consumption = 144.640530 pJ
sum error= 317
Actual label: 9
Output voltages: [0.047585, 0.009134, 0.013077, 0.40227, 0.03429, 0.0026803, 0.0015101, 0.05545, 0.61935, 0.798]
Predicted label: 9
Correct prediction
Energy consumption = 150.392642 pJ
sum error= 317
Actual label: 3
Output voltages: [0.75928, 0.0017026, 0.09689, 0.79875, 0.040859, 0.19032, 0.0070622, 0.0083894, 0.2555, 0.020705]
Predicted label: 3
Correct prediction
Energy consumption = 143.242802 pJ
sum error= 317
Actual label: 6
Output voltages: [0.26544, 0.0031009, 0.035431, 0.0034838, 0.24142, 0.34812, 0.79809, 0.0011089, 0.74434, 0.036771]
Predicted label: 6
Correct prediction
Energy consumption = 145.909103 pJ
sum error= 317
Actual label: 8
Output voltages: [0.019275, 0.11003, 0.29049, 0.41325, 0.0011523, 0.0010941, 0.028849, 0.042671, 0.79779, 0.52485]
Predicted label: 8
Correct prediction
Energy consumption = 137.404968 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 726 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 726 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 726 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.26642, 0.1261, 0.14704, 0.0039335, 0.037669, 0.0028218, 0.0014629, 0.79878, 0.053067, 0.22941]
Predicted label: 7
Correct prediction
Energy consumption = 168.974001 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79731, 0.055003, 0.21472, 0.01834, 0.0015758, 0.0015684, 0.6023, 0.016172, 0.18862, 0.076821]
Predicted label: 0
Correct prediction
Energy consumption = 142.578145 pJ
sum error= 317
Actual label: 1
Output voltages: [0.009844, 0.7987, 0.027045, 0.0093849, 0.47394, 0.0018228, 0.14414, 0.0012949, 0.58634, 0.42449]
Predicted label: 1
Correct prediction
Energy consumption = 147.760388 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79879, 0.026612, 0.16717, 0.031272, 0.026701, 0.0014371, 0.32393, 0.01004, 0.201, 0.043662]
Predicted label: 0
Correct prediction
Energy consumption = 142.892277 pJ
sum error= 317
Actual label: 5
Output voltages: [0.30519, 0.0010933, 0.002081, 0.52351, 0.046161, 0.79862, 0.32313, 0.025896, 0.78036, 0.031809]
Predicted label: 5
Correct prediction
Energy consumption = 142.114758 pJ
sum error= 317
Actual label: 8
Output voltages: [0.028821, 0.014803, 0.050917, 0.72596, 0.0048018, 0.024418, 0.0069649, 0.0014362, 0.79869, 0.30163]
Predicted label: 8
Correct prediction
Energy consumption = 145.388039 pJ
sum error= 317
Actual label: 2
Output voltages: [0.29187, 0.0065196, 0.79868, 0.022991, 0.0027635, 0.0022974, 0.037175, 0.23428, 0.56753, 0.021578]
Predicted label: 2
Correct prediction
Energy consumption = 140.495488 pJ
sum error= 317
Actual label: 7
Output voltages: [0.46026, 0.040976, 0.17162, 0.03699, 0.0015684, 0.012116, 0.17668, 0.79808, 0.017182, 0.055491]
Predicted label: 7
Correct prediction
Energy consumption = 145.763749 pJ
sum error= 317
Actual label: 7
Output voltages: [0.31944, 0.026218, 0.028987, 0.0015019, 0.15926, 0.0011809, 0.0011723, 0.78446, 0.18976, 0.5511]
Predicted label: 7
Correct prediction
Energy consumption = 150.523449 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79877, 0.046688, 0.063205, 0.013719, 0.26126, 0.0061744, 0.3215, 0.0043729, 0.26529, 0.10129]
Predicted label: 0
Correct prediction
Energy consumption = 152.962240 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 727 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 727 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 727 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.024161, 0.79838, 0.030078, 0.13765, 0.016617, 0.0033741, 0.67234, 0.0055775, 0.046647, 0.041708]
Predicted label: 1
Correct prediction
Energy consumption = 182.011390 pJ
sum error= 317
Actual label: 2
Output voltages: [0.12746, 0.068849, 0.79691, 0.57325, 0.013856, 0.0011009, 0.0064642, 0.43496, 0.74451, 0.003615]
Predicted label: 2
Correct prediction
Energy consumption = 151.667748 pJ
sum error= 317
Actual label: 3
Output voltages: [0.057719, 0.034397, 0.1727, 0.79872, 0.026957, 0.0074861, 0.012999, 0.0075235, 0.46268, 0.24077]
Predicted label: 3
Correct prediction
Energy consumption = 151.200200 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0022848, 0.015279, 0.033266, 0.033031, 0.79867, 0.0011229, 0.026143, 0.050937, 0.025825, 0.027317]
Predicted label: 4
Correct prediction
Energy consumption = 151.882399 pJ
sum error= 317
Actual label: 5
Output voltages: [0.037836, 0.001066, 0.0063397, 0.41681, 0.026729, 0.79878, 0.1708, 0.19243, 0.73826, 0.064208]
Predicted label: 5
Correct prediction
Energy consumption = 149.731070 pJ
sum error= 317
Actual label: 6
Output voltages: [0.30672, 0.085302, 0.033069, 0.018108, 0.34309, 0.52552, 0.79874, 0.0011894, 0.58235, 0.001139]
Predicted label: 6
Correct prediction
Energy consumption = 147.462179 pJ
sum error= 317
Actual label: 7
Output voltages: [0.58367, 0.033325, 0.044944, 0.032552, 0.031006, 0.0010775, 0.001084, 0.79879, 0.12186, 0.22945]
Predicted label: 7
Correct prediction
Energy consumption = 162.914348 pJ
sum error= 317
Actual label: 8
Output voltages: [0.15022, 0.010201, 0.28303, 0.017194, 0.11207, 0.006329, 0.020958, 0.0051222, 0.79878, 0.30502]
Predicted label: 8
Correct prediction
Energy consumption = 143.753578 pJ
sum error= 317
Actual label: 9
Output voltages: [0.39123, 0.0091696, 0.023804, 0.010984, 0.05343, 0.0082813, 0.0016136, 0.028039, 0.64129, 0.7985]
Predicted label: 9
Correct prediction
Energy consumption = 151.777608 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79861, 0.038266, 0.3857, 0.029526, 0.0012269, 0.0040396, 0.26612, 0.0017286, 0.068336, 0.019228]
Predicted label: 0
Correct prediction
Energy consumption = 149.749832 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 728 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 728 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 728 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.033194, 0.79843, 0.14601, 0.17656, 0.39384, 0.0033959, 0.45895, 0.025485, 0.028461, 0.096167]
Predicted label: 1
Correct prediction
Energy consumption = 186.354961 pJ
sum error= 317
Actual label: 2
Output voltages: [0.6367, 0.13338, 0.79859, 0.054406, 0.01327, 0.001069, 0.19547, 0.055539, 0.28045, 0.042648]
Predicted label: 2
Correct prediction
Energy consumption = 144.611380 pJ
sum error= 317
Actual label: 3
Output voltages: [0.28606, 0.042398, 0.46071, 0.79879, 0.030102, 0.0010811, 0.010195, 0.0011502, 0.69252, 0.063335]
Predicted label: 3
Correct prediction
Energy consumption = 146.305030 pJ
sum error= 317
Actual label: 4
Output voltages: [0.024124, 0.04417, 0.025206, 0.022315, 0.79875, 0.0011113, 0.17574, 0.027348, 0.016521, 0.040519]
Predicted label: 4
Correct prediction
Energy consumption = 155.231287 pJ
sum error= 317
Actual label: 5
Output voltages: [0.025626, 0.0015742, 0.010539, 0.44304, 0.016765, 0.79803, 0.19299, 0.0061004, 0.77055, 0.020613]
Predicted label: 5
Correct prediction
Energy consumption = 153.896279 pJ
sum error= 317
Actual label: 6
Output voltages: [0.029554, 0.038967, 0.090732, 0.012637, 0.45507, 0.11803, 0.79872, 0.0022431, 0.63515, 0.012859]
Predicted label: 6
Correct prediction
Energy consumption = 147.665557 pJ
sum error= 317
Actual label: 7
Output voltages: [0.33784, 0.061614, 0.014887, 0.029809, 0.0048321, 0.02072, 0.001092, 0.79864, 0.11731, 0.29238]
Predicted label: 7
Correct prediction
Energy consumption = 158.383748 pJ
sum error= 317
Actual label: 8
Output voltages: [0.42756, 0.022526, 0.34124, 0.18356, 0.034739, 0.031511, 0.13134, 0.0032997, 0.79877, 0.040634]
Predicted label: 8
Correct prediction
Energy consumption = 156.596383 pJ
sum error= 317
Actual label: 9
Output voltages: [0.10575, 0.020481, 0.0096363, 0.34325, 0.15688, 0.015436, 0.0011205, 0.02497, 0.11724, 0.79818]
Predicted label: 9
Correct prediction
Energy consumption = 154.974112 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79874, 0.082993, 0.016463, 0.016381, 0.01656, 0.0068024, 0.73955, 0.016829, 0.22608, 0.047569]
Predicted label: 0
Correct prediction
Energy consumption = 150.099936 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 729 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 729 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 729 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0080283, 0.79854, 0.49036, 0.067852, 0.029212, 0.0010782, 0.40994, 0.0029723, 0.16882, 0.051202]
Predicted label: 1
Correct prediction
Energy consumption = 185.667052 pJ
sum error= 317
Actual label: 2
Output voltages: [0.47437, 0.23976, 0.79876, 0.29185, 0.0014076, 0.0011261, 0.050047, 0.0331, 0.33698, 0.057358]
Predicted label: 2
Correct prediction
Energy consumption = 152.699254 pJ
sum error= 317
Actual label: 3
Output voltages: [0.43949, 0.010231, 0.033286, 0.7987, 0.02363, 0.0043927, 0.031618, 0.0029957, 0.4125, 0.25152]
Predicted label: 3
Correct prediction
Energy consumption = 144.514138 pJ
sum error= 317
Actual label: 4
Output voltages: [0.09554, 0.014643, 0.006883, 0.036487, 0.79878, 0.02903, 0.018509, 0.29799, 0.0039143, 0.68338]
Predicted label: 4
Correct prediction
Energy consumption = 165.005153 pJ
sum error= 317
Actual label: 5
Output voltages: [0.041856, 0.0010929, 0.0013462, 0.58863, 0.022958, 0.79878, 0.29226, 0.023019, 0.75268, 0.18778]
Predicted label: 5
Correct prediction
Energy consumption = 153.971776 pJ
sum error= 317
Actual label: 6
Output voltages: [0.077738, 0.037851, 0.35676, 0.0019667, 0.28459, 0.33521, 0.79869, 0.0051288, 0.41474, 0.004875]
Predicted label: 6
Correct prediction
Energy consumption = 147.575368 pJ
sum error= 317
Actual label: 7
Output voltages: [0.048228, 0.06618, 0.01107, 0.049476, 0.015025, 0.0151, 0.0012707, 0.79879, 0.13853, 0.64312]
Predicted label: 7
Correct prediction
Energy consumption = 160.698638 pJ
sum error= 317
Actual label: 8
Output voltages: [0.02117, 0.058885, 0.60894, 0.098319, 0.024688, 0.027366, 0.059885, 0.020833, 0.79876, 0.20787]
Predicted label: 8
Correct prediction
Energy consumption = 149.875592 pJ
sum error= 317
Actual label: 9
Output voltages: [0.36818, 0.0066577, 0.019521, 0.024379, 0.2727, 0.0052369, 0.0011704, 0.032664, 0.44801, 0.79674]
Predicted label: 9
Correct prediction
Energy consumption = 156.322076 pJ
sum error= 317
Actual label: 1
Output voltages: [0.0087334, 0.79844, 0.051141, 0.13103, 0.039494, 0.0029524, 0.62974, 0.044048, 0.090281, 0.054186]
Predicted label: 1
Correct prediction
Energy consumption = 163.260490 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 730 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 730 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 730 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.15959, 0.024542, 0.010913, 0.14883, 0.01538, 0.021339, 0.0010666, 0.79877, 0.20941, 0.61933]
Predicted label: 7
Correct prediction
Energy consumption = 174.747840 pJ
sum error= 317
Actual label: 4
Output voltages: [0.01599, 0.41706, 0.12815, 0.63316, 0.79879, 0.0010686, 0.19967, 0.21495, 0.0014522, 0.045813]
Predicted label: 4
Correct prediction
Energy consumption = 155.852131 pJ
sum error= 317
Actual label: 8
Output voltages: [0.13137, 0.040347, 0.55423, 0.36024, 0.026038, 0.0017767, 0.046183, 0.0022064, 0.79865, 0.40851]
Predicted label: 8
Correct prediction
Energy consumption = 154.415455 pJ
sum error= 317
Actual label: 1
Output voltages: [0.0020354, 0.79861, 0.088558, 0.045914, 0.072331, 0.0011891, 0.24784, 0.0053991, 0.29001, 0.093474]
Predicted label: 1
Correct prediction
Energy consumption = 162.979849 pJ
sum error= 317
Actual label: 5
Output voltages: [0.031293, 0.0010827, 0.0010941, 0.46929, 0.016703, 0.79851, 0.11091, 0.022328, 0.67995, 0.081451]
Predicted label: 5
Correct prediction
Energy consumption = 154.313940 pJ
sum error= 317
Actual label: 6
Output voltages: [0.066964, 0.036094, 0.3896, 0.0010755, 0.28776, 0.030044, 0.79879, 0.0011854, 0.41447, 0.0028291]
Predicted label: 6
Correct prediction
Energy consumption = 145.149741 pJ
sum error= 317
Actual label: 5
Output voltages: [0.048, 0.0010865, 0.0010745, 0.31284, 0.19831, 0.79873, 0.28581, 0.020828, 0.66909, 0.005045]
Predicted label: 5
Correct prediction
Energy consumption = 148.427176 pJ
sum error= 317
Actual label: 7
Output voltages: [0.42188, 0.042697, 0.016733, 0.18348, 0.015952, 0.0017577, 0.0012078, 0.79879, 0.040792, 0.27201]
Predicted label: 7
Correct prediction
Energy consumption = 157.690650 pJ
sum error= 317
Actual label: 2
Output voltages: [0.5583, 0.0097897, 0.79877, 0.077394, 0.038395, 0.0011144, 0.054374, 0.045639, 0.47358, 0.039648]
Predicted label: 2
Correct prediction
Energy consumption = 139.758955 pJ
sum error= 317
Actual label: 8
Output voltages: [0.48785, 0.0089562, 0.2427, 0.13921, 0.0029772, 0.018185, 0.03435, 0.017528, 0.79874, 0.016225]
Predicted label: 8
Correct prediction
Energy consumption = 150.131149 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 731 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 731 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 731 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.040793, 0.020392, 0.36398, 0.0019776, 0.33927, 0.070444, 0.79877, 0.0032748, 0.46031, 0.0017638]
Predicted label: 6
Correct prediction
Energy consumption = 165.268663 pJ
sum error= 317
Actual label: 3
Output voltages: [0.429, 0.030627, 0.49869, 0.79872, 0.041872, 0.0079361, 0.0071218, 0.014727, 0.52363, 0.05391]
Predicted label: 3
Correct prediction
Energy consumption = 149.856585 pJ
sum error= 317
Actual label: 3
Output voltages: [0.11119, 0.020497, 0.062096, 0.79866, 0.035091, 0.0043823, 0.010641, 0.025089, 0.6513, 0.052392]
Predicted label: 3
Correct prediction
Energy consumption = 128.298388 pJ
sum error= 317
Actual label: 8
Output voltages: [0.027126, 0.033466, 0.18399, 0.096244, 0.020856, 0.024883, 0.023374, 0.0055953, 0.79867, 0.33032]
Predicted label: 8
Correct prediction
Energy consumption = 142.593826 pJ
sum error= 317
Actual label: 6
Output voltages: [0.028646, 0.020032, 0.29634, 0.0016245, 0.23822, 0.17546, 0.79876, 0.0033176, 0.6092, 0.0017428]
Predicted label: 6
Correct prediction
Energy consumption = 150.412470 pJ
sum error= 317
Actual label: 5
Output voltages: [0.0065747, 0.0058825, 0.017173, 0.77739, 0.14939, 0.79781, 0.039866, 0.12492, 0.52251, 0.071966]
Predicted label: 5
Correct prediction
Energy consumption = 154.717106 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0076029, 0.004431, 0.023412, 0.0040651, 0.79856, 0.0059749, 0.20992, 0.23256, 0.097684, 0.010115]
Predicted label: 4
Correct prediction
Energy consumption = 155.188249 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79864, 0.026633, 0.022793, 0.010021, 0.023327, 0.013954, 0.1493, 0.030375, 0.14647, 0.024873]
Predicted label: 0
Correct prediction
Energy consumption = 149.378022 pJ
sum error= 317
Actual label: 9
Output voltages: [0.47301, 0.018341, 0.03028, 0.33768, 0.15503, 0.029207, 0.006161, 0.18574, 0.078098, 0.79797]
Predicted label: 9
Correct prediction
Energy consumption = 159.315213 pJ
sum error= 317
Actual label: 1
Output voltages: [0.017613, 0.79862, 0.059578, 0.013948, 0.018794, 0.0010691, 0.45016, 0.0011093, 0.29615, 0.028124]
Predicted label: 1
Correct prediction
Energy consumption = 163.792719 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 732 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 732 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 732 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.32646, 0.016378, 0.023063, 0.023426, 0.013613, 0.016853, 0.0010765, 0.79869, 0.51332, 0.31721]
Predicted label: 7
Correct prediction
Energy consumption = 180.174664 pJ
sum error= 317
Actual label: 2
Output voltages: [0.31321, 0.050307, 0.79871, 0.0093566, 0.020166, 0.0011516, 0.1172, 0.13299, 0.61679, 0.020359]
Predicted label: 2
Correct prediction
Energy consumption = 150.652081 pJ
sum error= 317
Actual label: 9
Output voltages: [0.23453, 0.012844, 0.079248, 0.37869, 0.2755, 0.015038, 0.025077, 0.26538, 0.46996, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 164.334142 pJ
sum error= 317
Actual label: 1
Output voltages: [0.024157, 0.79843, 0.044628, 0.09706, 0.034309, 0.0079039, 0.63572, 0.0042486, 0.077181, 0.071088]
Predicted label: 1
Correct prediction
Energy consumption = 170.602233 pJ
sum error= 317
Actual label: 5
Output voltages: [0.035617, 0.0071643, 0.0018531, 0.74036, 0.037688, 0.79854, 0.028564, 0.016239, 0.75584, 0.15138]
Predicted label: 5
Correct prediction
Energy consumption = 148.644045 pJ
sum error= 317
Actual label: 1
Output voltages: [0.055005, 0.79875, 0.28979, 0.069978, 0.44241, 0.0011073, 0.49665, 0.0074543, 0.024928, 0.020393]
Predicted label: 1
Correct prediction
Energy consumption = 166.806644 pJ
sum error= 317
Actual label: 3
Output voltages: [0.39679, 0.019524, 0.20613, 0.79864, 0.029021, 0.022073, 0.0039125, 0.013691, 0.745, 0.038878]
Predicted label: 3
Correct prediction
Energy consumption = 146.493923 pJ
sum error= 317
Actual label: 2
Output voltages: [0.40665, 0.045079, 0.79875, 0.28768, 0.020889, 0.0010669, 0.036259, 0.097873, 0.15543, 0.030601]
Predicted label: 2
Correct prediction
Energy consumption = 143.570110 pJ
sum error= 317
Actual label: 2
Output voltages: [0.35484, 0.34937, 0.79878, 0.1309, 0.015124, 0.0012458, 0.054593, 0.054065, 0.048354, 0.013636]
Predicted label: 2
Correct prediction
Energy consumption = 139.715317 pJ
sum error= 317
Actual label: 3
Output voltages: [0.44564, 0.0019538, 0.020393, 0.79873, 0.0071377, 0.02333, 0.0034032, 0.031131, 0.75931, 0.018884]
Predicted label: 3
Correct prediction
Energy consumption = 137.146254 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 733 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 733 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 733 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79868, 0.025756, 0.04792, 0.0086348, 0.019347, 0.0090474, 0.26774, 0.037777, 0.025312, 0.036486]
Predicted label: 0
Correct prediction
Energy consumption = 167.011791 pJ
sum error= 317
Actual label: 6
Output voltages: [0.1021, 0.0044301, 0.21172, 0.0012695, 0.65776, 0.54184, 0.79878, 0.0010739, 0.1515, 0.0042892]
Predicted label: 6
Correct prediction
Energy consumption = 142.111399 pJ
sum error= 317
Actual label: 4
Output voltages: [0.016563, 0.0039022, 0.041238, 0.03554, 0.79861, 0.0010756, 0.10767, 0.01566, 0.031436, 0.0089051]
Predicted label: 4
Correct prediction
Energy consumption = 157.598874 pJ
sum error= 317
Actual label: 3
Output voltages: [0.19383, 0.0085909, 0.24594, 0.79566, 0.016906, 0.0016025, 0.0083137, 0.0055068, 0.7907, 0.025955]
Predicted label: 3
Correct prediction
Energy consumption = 147.139156 pJ
sum error= 317
Actual label: 7
Output voltages: [0.69631, 0.050181, 0.49359, 0.53279, 0.0066583, 0.0010664, 0.001069, 0.79873, 0.033101, 0.25041]
Predicted label: 7
Correct prediction
Energy consumption = 151.602520 pJ
sum error= 317
Actual label: 6
Output voltages: [0.23512, 0.027075, 0.084336, 0.0024616, 0.48366, 0.1699, 0.79875, 0.0033181, 0.5309, 0.01381]
Predicted label: 6
Correct prediction
Energy consumption = 152.945986 pJ
sum error= 317
Actual label: 9
Output voltages: [0.43407, 0.014725, 0.068481, 0.039032, 0.041189, 0.0056015, 0.0011657, 0.10499, 0.39496, 0.79796]
Predicted label: 9
Correct prediction
Energy consumption = 156.931759 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79816, 0.056003, 0.1114, 0.059365, 0.0082074, 0.0040466, 0.41914, 0.0048375, 0.6949, 0.0068762]
Predicted label: 0
Correct prediction
Energy consumption = 154.069974 pJ
sum error= 317
Actual label: 4
Output voltages: [0.03044, 0.004728, 0.024739, 0.039198, 0.79811, 0.0011667, 0.089711, 0.0018374, 0.18381, 0.010936]
Predicted label: 4
Correct prediction
Energy consumption = 156.351969 pJ
sum error= 317
Actual label: 8
Output voltages: [0.46596, 0.0042719, 0.14784, 0.4639, 0.011802, 0.0012226, 0.011788, 0.0014678, 0.79575, 0.20917]
Predicted label: 8
Correct prediction
Energy consumption = 150.193335 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 734 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 734 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 734 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.036868, 0.79849, 0.31295, 0.32911, 0.010237, 0.0010741, 0.24884, 0.0035003, 0.21316, 0.034314]
Predicted label: 1
Correct prediction
Energy consumption = 185.273825 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0051188, 0.024935, 0.081484, 0.019309, 0.7987, 0.0012164, 0.31434, 0.061329, 0.025953, 0.11104]
Predicted label: 4
Correct prediction
Energy consumption = 160.440431 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79866, 0.0042989, 0.030304, 0.012, 0.016232, 0.016451, 0.29208, 0.0062222, 0.3561, 0.02137]
Predicted label: 0
Correct prediction
Energy consumption = 162.205808 pJ
sum error= 317
Actual label: 6
Output voltages: [0.068482, 0.018446, 0.13261, 0.0016191, 0.28456, 0.30381, 0.79876, 0.0047063, 0.61008, 0.004945]
Predicted label: 6
Correct prediction
Energy consumption = 146.015726 pJ
sum error= 317
Actual label: 1
Output voltages: [0.065521, 0.79872, 0.41953, 0.1027, 0.27562, 0.0011342, 0.71939, 0.016712, 0.032011, 0.029838]
Predicted label: 1
Correct prediction
Energy consumption = 164.240928 pJ
sum error= 317
Actual label: 2
Output voltages: [0.50446, 0.64698, 0.79879, 0.026908, 0.007046, 0.0012294, 0.022557, 0.030336, 0.21673, 0.015474]
Predicted label: 2
Correct prediction
Energy consumption = 150.137674 pJ
sum error= 317
Actual label: 6
Output voltages: [0.037975, 0.054005, 0.10086, 0.0029311, 0.24965, 0.10933, 0.79876, 0.002759, 0.42559, 0.0039994]
Predicted label: 6
Correct prediction
Energy consumption = 148.710577 pJ
sum error= 317
Actual label: 9
Output voltages: [0.15079, 0.0241, 0.065761, 0.028598, 0.029738, 0.015389, 0.013043, 0.037554, 0.74258, 0.79722]
Predicted label: 9
Correct prediction
Energy consumption = 153.784199 pJ
sum error= 317
Actual label: 2
Output voltages: [0.044152, 0.10871, 0.79866, 0.1246, 0.0025883, 0.0013649, 0.054155, 0.2235, 0.54293, 0.063314]
Predicted label: 2
Correct prediction
Energy consumption = 154.767097 pJ
sum error= 317
Actual label: 2
Output voltages: [0.34483, 0.35659, 0.79879, 0.025215, 0.031613, 0.0013042, 0.03614, 0.29677, 0.34602, 0.025438]
Predicted label: 2
Correct prediction
Energy consumption = 141.340876 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 735 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 735 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 735 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.086366, 0.017017, 0.028278, 0.7986, 0.016764, 0.018265, 0.0057701, 0.028544, 0.38286, 0.071899]
Predicted label: 3
Correct prediction
Energy consumption = 165.839024 pJ
sum error= 317
Actual label: 5
Output voltages: [0.032737, 0.0011712, 0.001068, 0.39076, 0.1016, 0.79869, 0.059742, 0.01577, 0.7612, 0.01234]
Predicted label: 5
Correct prediction
Energy consumption = 144.097545 pJ
sum error= 317
Actual label: 5
Output voltages: [0.034618, 0.0010878, 0.0015843, 0.38359, 0.17157, 0.79878, 0.15098, 0.04639, 0.73717, 0.1236]
Predicted label: 5
Correct prediction
Energy consumption = 140.420229 pJ
sum error= 317
Actual label: 1
Output voltages: [0.016364, 0.79862, 0.36581, 0.028463, 0.042981, 0.0010801, 0.32924, 0.0030823, 0.22482, 0.022323]
Predicted label: 1
Correct prediction
Energy consumption = 168.112618 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79878, 0.062769, 0.037966, 0.013647, 0.038673, 0.004042, 0.7609, 0.032219, 0.25281, 0.043527]
Predicted label: 0
Correct prediction
Energy consumption = 151.842242 pJ
sum error= 317
Actual label: 7
Output voltages: [0.050373, 0.11449, 0.028992, 0.055679, 0.0081738, 0.015163, 0.0010689, 0.79867, 0.051243, 0.45335]
Predicted label: 7
Correct prediction
Energy consumption = 155.073999 pJ
sum error= 317
Actual label: 7
Output voltages: [0.28915, 0.12469, 0.78571, 0.014811, 0.0037352, 0.0011939, 0.0010792, 0.79878, 0.20574, 0.038639]
Predicted label: 7
Correct prediction
Energy consumption = 137.217904 pJ
sum error= 317
Actual label: 9
Output voltages: [0.044731, 0.03492, 0.014742, 0.036897, 0.015447, 0.0027873, 0.0010661, 0.014787, 0.72583, 0.79708]
Predicted label: 9
Correct prediction
Energy consumption = 143.336829 pJ
sum error= 317
Actual label: 6
Output voltages: [0.10285, 0.031655, 0.11554, 0.0019436, 0.60548, 0.3428, 0.79868, 0.0020752, 0.28805, 0.0094643]
Predicted label: 6
Correct prediction
Energy consumption = 152.311487 pJ
sum error= 317
Actual label: 2
Output voltages: [0.17027, 0.1909, 0.79805, 0.41432, 0.01321, 0.0011311, 0.011432, 0.018713, 0.26315, 0.0077098]
Predicted label: 2
Correct prediction
Energy consumption = 152.155472 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 736 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 736 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 736 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3251, 0.0074292, 0.015859, 0.01542, 0.20492, 0.01479, 0.0099093, 0.023353, 0.5284, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 167.166032 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0051258, 0.024174, 0.0069127, 0.024309, 0.79877, 0.0011011, 0.15431, 0.1146, 0.020912, 0.022005]
Predicted label: 4
Correct prediction
Energy consumption = 156.853131 pJ
sum error= 317
Actual label: 7
Output voltages: [0.21816, 0.0067177, 0.020388, 0.32032, 0.0028436, 0.0025714, 0.0012847, 0.79871, 0.40613, 0.3363]
Predicted label: 7
Correct prediction
Energy consumption = 151.203602 pJ
sum error= 317
Actual label: 0
Output voltages: [0.798, 0.043093, 0.16351, 0.0052189, 0.0086952, 0.0012107, 0.61674, 0.032307, 0.0371, 0.40765]
Predicted label: 0
Correct prediction
Energy consumption = 151.684705 pJ
sum error= 317
Actual label: 2
Output voltages: [0.42094, 0.40718, 0.7986, 0.38091, 0.0087577, 0.0011683, 0.044735, 0.060078, 0.034849, 0.028201]
Predicted label: 2
Correct prediction
Energy consumption = 152.055927 pJ
sum error= 317
Actual label: 3
Output voltages: [0.13085, 0.009134, 0.050125, 0.79878, 0.04357, 0.012074, 0.0018626, 0.0028235, 0.74195, 0.052105]
Predicted label: 3
Correct prediction
Energy consumption = 136.930756 pJ
sum error= 317
Actual label: 4
Output voltages: [0.002594, 0.0042261, 0.027766, 0.005778, 0.79865, 0.0032609, 0.098969, 0.34865, 0.26166, 0.001554]
Predicted label: 4
Correct prediction
Energy consumption = 151.537506 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79879, 0.025858, 0.042535, 0.013536, 0.02228, 0.0020036, 0.37324, 0.012316, 0.038526, 0.03897]
Predicted label: 0
Correct prediction
Energy consumption = 152.752119 pJ
sum error= 317
Actual label: 0
Output voltages: [0.7984, 0.028776, 0.18814, 0.00686, 0.0099921, 0.0016297, 0.47773, 0.022498, 0.32006, 0.027158]
Predicted label: 0
Correct prediction
Energy consumption = 143.909295 pJ
sum error= 317
Actual label: 8
Output voltages: [0.022786, 0.016783, 0.22365, 0.074656, 0.012285, 0.086419, 0.0076997, 0.018247, 0.79864, 0.033482]
Predicted label: 8
Correct prediction
Energy consumption = 142.593351 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 737 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 737 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 737 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.35405, 0.025972, 0.13491, 0.24836, 0.024903, 0.019318, 0.091237, 0.0011986, 0.79873, 0.19411]
Predicted label: 8
Correct prediction
Energy consumption = 169.036735 pJ
sum error= 317
Actual label: 8
Output voltages: [0.054178, 0.016427, 0.30026, 0.02351, 0.01093, 0.046511, 0.0052464, 0.0084619, 0.79878, 0.19337]
Predicted label: 8
Correct prediction
Energy consumption = 143.260210 pJ
sum error= 317
Actual label: 5
Output voltages: [0.010224, 0.0010799, 0.0060951, 0.11048, 0.020282, 0.79777, 0.29077, 0.027401, 0.75979, 0.23037]
Predicted label: 5
Correct prediction
Energy consumption = 144.240459 pJ
sum error= 317
Actual label: 1
Output voltages: [0.072181, 0.79868, 0.39999, 0.030217, 0.017022, 0.0010913, 0.57099, 0.0020964, 0.16116, 0.040194]
Predicted label: 1
Correct prediction
Energy consumption = 163.887554 pJ
sum error= 317
Actual label: 3
Output voltages: [0.2372, 0.039252, 0.056646, 0.79875, 0.0032781, 0.0057966, 0.0079476, 0.0051267, 0.64944, 0.024706]
Predicted label: 3
Correct prediction
Energy consumption = 147.357780 pJ
sum error= 317
Actual label: 7
Output voltages: [0.181, 0.20997, 0.6542, 0.18845, 0.026442, 0.0011768, 0.0010959, 0.79875, 0.15223, 0.1313]
Predicted label: 7
Correct prediction
Energy consumption = 145.577995 pJ
sum error= 317
Actual label: 4
Output voltages: [0.016159, 0.0052039, 0.19449, 0.0070803, 0.79859, 0.0078716, 0.12978, 0.043497, 0.33281, 0.0063942]
Predicted label: 4
Correct prediction
Energy consumption = 151.326298 pJ
sum error= 317
Actual label: 9
Output voltages: [0.25779, 0.028667, 0.0035042, 0.054465, 0.089262, 0.0063104, 0.0010735, 0.0028988, 0.36332, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 147.618224 pJ
sum error= 317
Actual label: 8
Output voltages: [0.1758, 0.034428, 0.097517, 0.035149, 0.0069768, 0.01145, 0.030014, 0.0011764, 0.79869, 0.029283]
Predicted label: 8
Correct prediction
Energy consumption = 146.418209 pJ
sum error= 317
Actual label: 8
Output voltages: [0.045571, 0.0026414, 0.073355, 0.244, 0.0087666, 0.0026485, 0.061254, 0.0023771, 0.79855, 0.403]
Predicted label: 8
Correct prediction
Energy consumption = 140.980572 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 738 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 738 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 738 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.37731, 0.0082341, 0.0060754, 0.012015, 0.18963, 0.0025279, 0.001715, 0.0076945, 0.60471, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 170.580003 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79879, 0.05194, 0.23038, 0.028428, 0.07915, 0.0034178, 0.16448, 0.0027904, 0.22021, 0.15742]
Predicted label: 0
Correct prediction
Energy consumption = 159.486359 pJ
sum error= 317
Actual label: 9
Output voltages: [0.2649, 0.0089459, 0.1282, 0.019004, 0.077343, 0.011928, 0.001557, 0.13582, 0.60068, 0.79676]
Predicted label: 9
Correct prediction
Energy consumption = 161.180286 pJ
sum error= 317
Actual label: 8
Output voltages: [0.048845, 0.038357, 0.429, 0.096912, 0.018721, 0.034686, 0.029739, 0.016611, 0.79878, 0.21114]
Predicted label: 8
Correct prediction
Energy consumption = 148.947853 pJ
sum error= 317
Actual label: 9
Output voltages: [0.03205, 0.0096221, 0.025295, 0.024639, 0.035996, 0.0098229, 0.0015434, 0.033822, 0.77238, 0.79124]
Predicted label: 9
Correct prediction
Energy consumption = 151.415588 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79879, 0.049211, 0.049155, 0.021834, 0.013213, 0.0055517, 0.35112, 0.015828, 0.24831, 0.031324]
Predicted label: 0
Correct prediction
Energy consumption = 148.564487 pJ
sum error= 317
Actual label: 2
Output voltages: [0.5928, 0.096598, 0.79878, 0.4769, 0.013493, 0.0011747, 0.03025, 0.044537, 0.43014, 0.027787]
Predicted label: 2
Correct prediction
Energy consumption = 154.754616 pJ
sum error= 317
Actual label: 6
Output voltages: [0.10767, 0.019478, 0.28401, 0.0010662, 0.1673, 0.034521, 0.79877, 0.0079383, 0.31819, 0.0012037]
Predicted label: 6
Correct prediction
Energy consumption = 148.441504 pJ
sum error= 317
Actual label: 5
Output voltages: [0.010449, 0.0011087, 0.0031771, 0.74074, 0.040971, 0.78384, 0.042964, 0.030998, 0.58837, 0.044798]
Predicted label: 5
Correct prediction
Energy consumption = 147.375348 pJ
sum error= 317
Actual label: 6
Output voltages: [0.047425, 0.070488, 0.34191, 0.0023622, 0.34651, 0.24029, 0.79867, 0.0071883, 0.42019, 0.0094876]
Predicted label: 6
Correct prediction
Energy consumption = 143.543110 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 739 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 739 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 739 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.31409, 0.12197, 0.75708, 0.023602, 0.005436, 0.0012067, 0.0010837, 0.79879, 0.084766, 0.024731]
Predicted label: 7
Correct prediction
Energy consumption = 166.297724 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0039121, 0.0032111, 0.024989, 0.020184, 0.79867, 0.0014151, 0.075152, 0.053879, 0.16563, 0.0064426]
Predicted label: 4
Correct prediction
Energy consumption = 152.486222 pJ
sum error= 317
Actual label: 7
Output voltages: [0.18097, 0.0417, 0.10991, 0.2436, 0.01357, 0.0030089, 0.001105, 0.79879, 0.66211, 0.30747]
Predicted label: 7
Correct prediction
Energy consumption = 161.411909 pJ
sum error= 317
Actual label: 5
Output voltages: [0.059247, 0.0011325, 0.0018075, 0.49016, 0.01939, 0.79871, 0.30281, 0.034377, 0.64148, 0.048269]
Predicted label: 5
Correct prediction
Energy consumption = 143.845996 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0085724, 0.021427, 0.0066243, 0.015939, 0.79872, 0.0018058, 0.13694, 0.030725, 0.19361, 0.055807]
Predicted label: 4
Correct prediction
Energy consumption = 155.627497 pJ
sum error= 317
Actual label: 1
Output voltages: [0.009921, 0.79876, 0.21553, 0.013178, 0.044887, 0.0013035, 0.50982, 0.0012045, 0.26459, 0.0083043]
Predicted label: 1
Correct prediction
Energy consumption = 155.731442 pJ
sum error= 317
Actual label: 3
Output voltages: [0.126, 0.055369, 0.025193, 0.79873, 0.0040064, 0.050265, 0.008989, 0.022125, 0.74935, 0.043267]
Predicted label: 3
Correct prediction
Energy consumption = 149.587514 pJ
sum error= 317
Actual label: 5
Output voltages: [0.026809, 0.001123, 0.00118, 0.053583, 0.24262, 0.79878, 0.36021, 0.035464, 0.78452, 0.0097259]
Predicted label: 5
Correct prediction
Energy consumption = 145.332942 pJ
sum error= 317
Actual label: 3
Output voltages: [0.10679, 0.011188, 0.32042, 0.79869, 0.012196, 0.38482, 0.0025406, 0.022801, 0.74132, 0.057201]
Predicted label: 3
Correct prediction
Energy consumption = 144.016387 pJ
sum error= 317
Actual label: 1
Output voltages: [0.34618, 0.79872, 0.18784, 0.015772, 0.40273, 0.0070943, 0.35519, 0.0034024, 0.022015, 0.046012]
Predicted label: 1
Correct prediction
Energy consumption = 159.752782 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 740 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 740 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 740 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.49386, 0.025273, 0.79879, 0.036825, 0.0070815, 0.0010869, 0.025685, 0.14887, 0.32872, 0.04619]
Predicted label: 2
Correct prediction
Energy consumption = 163.834147 pJ
sum error= 317
Actual label: 3
Output voltages: [0.7938, 0.029637, 0.025021, 0.7987, 0.0013875, 0.36365, 0.0012521, 0.038831, 0.28137, 0.008086]
Predicted label: 3
Correct prediction
Energy consumption = 149.206817 pJ
sum error= 317
Actual label: 4
Output voltages: [0.013673, 0.015585, 0.017747, 0.0013753, 0.79878, 0.0013054, 0.34991, 0.051682, 0.2966, 0.0098639]
Predicted label: 4
Correct prediction
Energy consumption = 159.537184 pJ
sum error= 317
Actual label: 5
Output voltages: [0.16685, 0.0019267, 0.0033504, 0.66544, 0.0062018, 0.79879, 0.077088, 0.054687, 0.76047, 0.06696]
Predicted label: 5
Correct prediction
Energy consumption = 152.988144 pJ
sum error= 317
Actual label: 6
Output voltages: [0.62979, 0.035696, 0.052394, 0.0010698, 0.37081, 0.030086, 0.79878, 0.0030517, 0.097763, 0.023299]
Predicted label: 6
Correct prediction
Energy consumption = 152.409689 pJ
sum error= 317
Actual label: 1
Output voltages: [0.011412, 0.79873, 0.15393, 0.0047283, 0.13828, 0.014061, 0.45122, 0.0041407, 0.4548, 0.00668]
Predicted label: 1
Correct prediction
Energy consumption = 146.533918 pJ
sum error= 317
Actual label: 2
Output voltages: [0.69538, 0.0023049, 0.79864, 0.20525, 0.0078422, 0.001081, 0.022958, 0.17229, 0.75843, 0.015243]
Predicted label: 2
Correct prediction
Energy consumption = 140.802616 pJ
sum error= 317
Actual label: 3
Output voltages: [0.44932, 0.01339, 0.067166, 0.79878, 0.0033839, 0.044628, 0.0011942, 0.5333, 0.22433, 0.063114]
Predicted label: 3
Correct prediction
Energy consumption = 141.139225 pJ
sum error= 317
Actual label: 4
Output voltages: [0.021763, 0.014073, 0.13685, 0.003893, 0.79875, 0.0081699, 0.25301, 0.1856, 0.21632, 0.0020994]
Predicted label: 4
Correct prediction
Energy consumption = 148.656930 pJ
sum error= 317
Actual label: 6
Output voltages: [0.29867, 0.062572, 0.35077, 0.0011076, 0.20823, 0.043201, 0.79877, 0.0010856, 0.064296, 0.0068827]
Predicted label: 6
Correct prediction
Energy consumption = 136.321872 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 741 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 741 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 741 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.030321, 0.042622, 0.019884, 0.0061465, 0.0015965, 0.27935, 0.49598, 0.11381, 0.0049361]
Predicted label: 0
Correct prediction
Energy consumption = 168.864847 pJ
sum error= 317
Actual label: 1
Output voltages: [0.0014215, 0.79867, 0.01771, 0.032472, 0.27938, 0.0029989, 0.62889, 0.0033892, 0.26637, 0.07576]
Predicted label: 1
Correct prediction
Energy consumption = 154.132686 pJ
sum error= 317
Actual label: 2
Output voltages: [0.5233, 0.003583, 0.79879, 0.17805, 0.0061291, 0.0010883, 0.014529, 0.031721, 0.52237, 0.0027626]
Predicted label: 2
Correct prediction
Energy consumption = 146.526304 pJ
sum error= 317
Actual label: 4
Output voltages: [0.74605, 0.0037419, 0.529, 0.0013674, 0.78967, 0.0011484, 0.012123, 0.040681, 0.30869, 0.017791]
Predicted label: 4
Correct prediction
Energy consumption = 143.281769 pJ
sum error= 317
Actual label: 5
Output voltages: [0.25149, 0.0010838, 0.0011091, 0.050033, 0.0087665, 0.79854, 0.058942, 0.13025, 0.77223, 0.0010675]
Predicted label: 5
Correct prediction
Energy consumption = 147.506302 pJ
sum error= 317
Actual label: 6
Output voltages: [0.036329, 0.039368, 0.11088, 0.0023819, 0.089869, 0.28072, 0.79875, 0.0089936, 0.35739, 0.0036002]
Predicted label: 6
Correct prediction
Energy consumption = 136.669448 pJ
sum error= 317
Actual label: 7
Output voltages: [0.23018, 0.048495, 0.71594, 0.035652, 0.0086065, 0.0016712, 0.0010828, 0.79872, 0.21668, 0.46213]
Predicted label: 7
Correct prediction
Energy consumption = 152.102690 pJ
sum error= 317
Actual label: 8
Output voltages: [0.043052, 0.0033343, 0.010816, 0.052739, 0.056019, 0.58212, 0.079962, 0.048367, 0.7987, 0.030235]
Predicted label: 8
Correct prediction
Energy consumption = 150.211699 pJ
sum error= 317
Actual label: 1
Output voltages: [0.014847, 0.79878, 0.21591, 0.010306, 0.07664, 0.0021675, 0.61865, 0.0027158, 0.33685, 0.0026223]
Predicted label: 1
Correct prediction
Energy consumption = 152.005765 pJ
sum error= 317
Actual label: 7
Output voltages: [0.032915, 0.19475, 0.59316, 0.1436, 0.0056752, 0.0010678, 0.001091, 0.79878, 0.3369, 0.24057]
Predicted label: 7
Correct prediction
Energy consumption = 150.046581 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 742 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 742 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 742 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.40892, 0.0015445, 0.79622, 0.041414, 0.0028631, 0.0013712, 0.021727, 0.2069, 0.79212, 0.026876]
Predicted label: 2
Correct prediction
Energy consumption = 159.936086 pJ
sum error= 317
Actual label: 4
Output voltages: [0.051091, 0.023575, 0.38009, 0.0079319, 0.79869, 0.0016146, 0.036133, 0.030375, 0.029462, 0.035605]
Predicted label: 4
Correct prediction
Energy consumption = 152.904336 pJ
sum error= 317
Actual label: 1
Output voltages: [0.0036689, 0.79865, 0.2492, 0.030077, 0.17402, 0.0014522, 0.73159, 0.009349, 0.31911, 0.0092747]
Predicted label: 1
Correct prediction
Energy consumption = 142.480083 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0011752, 0.0056125, 0.017579, 0.010178, 0.79874, 0.011338, 0.0065711, 0.0064408, 0.3352, 0.26442]
Predicted label: 4
Correct prediction
Energy consumption = 149.326629 pJ
sum error= 317
Actual label: 1
Output voltages: [0.11036, 0.79878, 0.045428, 0.001467, 0.53085, 0.0018401, 0.39238, 0.0016213, 0.25891, 0.054225]
Predicted label: 1
Correct prediction
Energy consumption = 152.827550 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0038923, 0.013909, 0.16794, 0.016964, 0.79878, 0.0075618, 0.035773, 0.024812, 0.21459, 0.014765]
Predicted label: 4
Correct prediction
Energy consumption = 154.553350 pJ
sum error= 317
Actual label: 9
Output voltages: [0.040134, 0.0012093, 0.031021, 0.019855, 0.13844, 0.28123, 0.042271, 0.24431, 0.64002, 0.74359]
Predicted label: 9
Correct prediction
Energy consumption = 148.874417 pJ
sum error= 317
Actual label: 6
Output voltages: [0.33853, 0.028548, 0.063833, 0.00108, 0.28132, 0.042086, 0.79879, 0.010545, 0.54398, 0.0013814]
Predicted label: 6
Correct prediction
Energy consumption = 141.334864 pJ
sum error= 317
Actual label: 8
Output voltages: [0.027677, 0.022071, 0.181, 0.21416, 0.016787, 0.033721, 0.023604, 0.0031176, 0.7987, 0.3167]
Predicted label: 8
Correct prediction
Energy consumption = 147.704566 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0010661, 0.024644, 0.018391, 0.044596, 0.79879, 0.015936, 0.32113, 0.051973, 0.096351, 0.030523]
Predicted label: 4
Correct prediction
Energy consumption = 146.204522 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 743 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 743 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 743 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.18811, 0.0022602, 0.0010928, 0.79151, 0.56993, 0.79546, 0.10052, 0.36785, 0.1196, 0.014556]
Predicted label: 5
Correct prediction
Energy consumption = 166.108825 pJ
sum error= 317
Actual label: 3
Output voltages: [0.63221, 0.0022457, 0.038434, 0.79879, 0.01092, 0.009665, 0.0014197, 0.057743, 0.67149, 0.02602]
Predicted label: 3
Correct prediction
Energy consumption = 138.517984 pJ
sum error= 317
Actual label: 7
Output voltages: [0.03281, 0.38569, 0.76927, 0.16061, 0.0028266, 0.0011222, 0.0027017, 0.73305, 0.78202, 0.45459]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.650307 pJ
sum error= 318
Actual label: 8
Output voltages: [0.055691, 0.017215, 0.0048488, 0.29452, 0.0084871, 0.17361, 0.2584, 0.015939, 0.79877, 0.0091261]
Predicted label: 8
Correct prediction
Energy consumption = 141.592637 pJ
sum error= 318
Actual label: 4
Output voltages: [0.0078912, 0.36144, 0.0090091, 0.052865, 0.78523, 0.0010661, 0.010024, 0.014997, 0.14193, 0.26066]
Predicted label: 4
Correct prediction
Energy consumption = 145.140875 pJ
sum error= 318
Actual label: 3
Output voltages: [0.097898, 0.018935, 0.029565, 0.79866, 0.014085, 0.0064142, 0.011173, 0.02687, 0.41511, 0.14318]
Predicted label: 3
Correct prediction
Energy consumption = 141.807721 pJ
sum error= 318
Actual label: 3
Output voltages: [0.03793, 0.0778, 0.28039, 0.79879, 0.003978, 0.0013948, 0.003897, 0.017021, 0.72609, 0.022566]
Predicted label: 3
Correct prediction
Energy consumption = 130.353506 pJ
sum error= 318
Actual label: 5
Output voltages: [0.1988, 0.0010744, 0.0010719, 0.20614, 0.039253, 0.79862, 0.25408, 0.015492, 0.79474, 0.0028159]
Predicted label: 5
Correct prediction
Energy consumption = 131.817211 pJ
sum error= 318
Actual label: 6
Output voltages: [0.034602, 0.16138, 0.17019, 0.0025331, 0.10919, 0.25548, 0.7987, 0.0031095, 0.29208, 0.0056325]
Predicted label: 6
Correct prediction
Energy consumption = 144.169466 pJ
sum error= 318
Actual label: 7
Output voltages: [0.036153, 0.026904, 0.74139, 0.06373, 0.0013498, 0.0012418, 0.0010669, 0.79574, 0.26936, 0.043533]
Predicted label: 7
Correct prediction
Energy consumption = 158.321795 pJ
sum error= 318
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 744 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 744 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 744 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79847, 0.017504, 0.11051, 0.029182, 0.21528, 0.0022914, 0.26942, 0.047075, 0.36898, 0.018844]
Predicted label: 0
Correct prediction
Energy consumption = 171.165156 pJ
sum error= 318
Actual label: 6
Output voltages: [0.30195, 0.0041739, 0.024157, 0.0013072, 0.37757, 0.25084, 0.79839, 0.0091957, 0.077676, 0.012047]
Predicted label: 6
Correct prediction
Energy consumption = 140.828162 pJ
sum error= 318
Actual label: 1
Output voltages: [0.030451, 0.79879, 0.0042639, 0.0050422, 0.24324, 0.0020386, 0.17557, 0.010246, 0.34935, 0.0143]
Predicted label: 1
Correct prediction
Energy consumption = 156.227995 pJ
sum error= 318
Actual label: 6
Output voltages: [0.21751, 0.055724, 0.4508, 0.0012221, 0.098931, 0.091197, 0.79879, 0.0011721, 0.082375, 0.0076336]
Predicted label: 6
Correct prediction
Energy consumption = 142.919376 pJ
sum error= 318
Actual label: 8
Output voltages: [0.011354, 0.0046685, 0.0026567, 0.010436, 0.20341, 0.16983, 0.13659, 0.078378, 0.79878, 0.0059846]
Predicted label: 8
Correct prediction
Energy consumption = 139.900754 pJ
sum error= 318
Actual label: 7
Output voltages: [0.034544, 0.18786, 0.75679, 0.056649, 0.0013422, 0.0013169, 0.0010782, 0.79878, 0.37824, 0.58024]
Predicted label: 7
Correct prediction
Energy consumption = 144.501799 pJ
sum error= 318
Actual label: 0
Output voltages: [0.79875, 0.018516, 0.068145, 0.014898, 0.017372, 0.00507, 0.5246, 0.078127, 0.17831, 0.23254]
Predicted label: 0
Correct prediction
Energy consumption = 143.790884 pJ
sum error= 318
Actual label: 1
Output voltages: [0.0011963, 0.79878, 0.48823, 0.039032, 0.038874, 0.0010867, 0.24316, 0.014541, 0.32643, 0.03618]
Predicted label: 1
Correct prediction
Energy consumption = 148.877880 pJ
sum error= 318
Actual label: 5
Output voltages: [0.31653, 0.0012547, 0.0011062, 0.23519, 0.034759, 0.79861, 0.12177, 0.044961, 0.69651, 0.007848]
Predicted label: 5
Correct prediction
Energy consumption = 149.660335 pJ
sum error= 318
Actual label: 0
Output voltages: [0.79876, 0.023093, 0.062785, 0.002722, 0.025301, 0.00518, 0.15682, 0.088981, 0.44662, 0.02104]
Predicted label: 0
Correct prediction
Energy consumption = 147.942603 pJ
sum error= 318
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 745 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 745 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 745 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.017858, 0.019328, 0.035079, 0.069222, 0.0014649, 0.2156, 0.04187, 0.029968, 0.79866, 0.025446]
Predicted label: 8
Correct prediction
Energy consumption = 164.433690 pJ
sum error= 318
Actual label: 5
Output voltages: [0.031379, 0.01632, 0.001066, 0.74628, 0.46967, 0.79, 0.43847, 0.001152, 0.59831, 0.036453]
Predicted label: 5
Correct prediction
Energy consumption = 134.720602 pJ
sum error= 318
Actual label: 0
Output voltages: [0.7987, 0.03453, 0.20758, 0.012999, 0.018645, 0.0092793, 0.38522, 0.053533, 0.069884, 0.11107]
Predicted label: 0
Correct prediction
Energy consumption = 148.281076 pJ
sum error= 318
Actual label: 1
Output voltages: [0.0073934, 0.79874, 0.21558, 0.0010816, 0.11937, 0.0012382, 0.3287, 0.0015239, 0.63357, 0.042792]
Predicted label: 1
Correct prediction
Energy consumption = 150.849345 pJ
sum error= 318
Actual label: 5
Output voltages: [0.060692, 0.0010678, 0.0011336, 0.18858, 0.20511, 0.79875, 0.25732, 0.02144, 0.28845, 0.033371]
Predicted label: 5
Correct prediction
Energy consumption = 140.804787 pJ
sum error= 318
Actual label: 8
Output voltages: [0.067017, 0.022344, 0.022331, 0.14918, 0.0031782, 0.27924, 0.0045015, 0.01009, 0.79873, 0.04359]
Predicted label: 8
Correct prediction
Energy consumption = 153.147531 pJ
sum error= 318
Actual label: 4
Output voltages: [0.039216, 0.020702, 0.38087, 0.0014487, 0.79875, 0.011647, 0.079541, 0.016484, 0.039725, 0.0048529]
Predicted label: 4
Correct prediction
Energy consumption = 142.250619 pJ
sum error= 318
Actual label: 2
Output voltages: [0.16284, 0.015716, 0.79875, 0.25231, 0.0027196, 0.0011039, 0.018754, 0.69654, 0.78734, 0.016009]
Predicted label: 2
Correct prediction
Energy consumption = 146.775588 pJ
sum error= 318
Actual label: 3
Output voltages: [0.44005, 0.019414, 0.10233, 0.7986, 0.022307, 0.022859, 0.011298, 0.032238, 0.56982, 0.064514]
Predicted label: 3
Correct prediction
Energy consumption = 142.714165 pJ
sum error= 318
Actual label: 9
Output voltages: [0.023498, 0.0010665, 0.0020888, 0.031864, 0.026422, 0.55661, 0.0061836, 0.0108, 0.74746, 0.70304]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.887290 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 746 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 746 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 746 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30332, 0.071765, 0.47995, 0.041148, 0.0076767, 0.001126, 0.0038917, 0.79868, 0.031961, 0.050405]
Predicted label: 7
Correct prediction
Energy consumption = 176.059258 pJ
sum error= 319
Actual label: 6
Output voltages: [0.27785, 0.016735, 0.12373, 0.0010936, 0.74042, 0.045242, 0.79877, 0.0056299, 0.040477, 0.027353]
Predicted label: 6
Correct prediction
Energy consumption = 145.957311 pJ
sum error= 319
Actual label: 9
Output voltages: [0.36258, 0.00419, 0.01671, 0.046953, 0.019734, 0.033354, 0.0027029, 0.14479, 0.70271, 0.79783]
Predicted label: 9
Correct prediction
Energy consumption = 147.095031 pJ
sum error= 319
Actual label: 1
Output voltages: [0.011715, 0.79872, 0.39176, 0.037258, 0.12585, 0.0020668, 0.056292, 0.029, 0.39508, 0.017041]
Predicted label: 1
Correct prediction
Energy consumption = 150.997262 pJ
sum error= 319
Actual label: 9
Output voltages: [0.19576, 0.0040104, 0.036356, 0.0066812, 0.015191, 0.017935, 0.0024901, 0.01272, 0.77334, 0.79593]
Predicted label: 9
Correct prediction
Energy consumption = 145.478670 pJ
sum error= 319
Actual label: 0
Output voltages: [0.77377, 0.052625, 0.082176, 0.013397, 0.37315, 0.0026743, 0.64183, 0.01844, 0.253, 0.0015458]
Predicted label: 0
Correct prediction
Energy consumption = 151.340184 pJ
sum error= 319
Actual label: 6
Output voltages: [0.36357, 0.18293, 0.040252, 0.022869, 0.18265, 0.14807, 0.79872, 0.0053544, 0.66968, 0.015477]
Predicted label: 6
Correct prediction
Energy consumption = 138.497041 pJ
sum error= 319
Actual label: 7
Output voltages: [0.15899, 0.021691, 0.59873, 0.021128, 0.0033984, 0.0011884, 0.0011077, 0.79879, 0.49348, 0.01485]
Predicted label: 7
Correct prediction
Energy consumption = 154.761702 pJ
sum error= 319
Actual label: 1
Output voltages: [0.0033512, 0.79877, 0.0071658, 0.0071446, 0.025326, 0.004584, 0.054236, 0.0045477, 0.78735, 0.034709]
Predicted label: 1
Correct prediction
Energy consumption = 138.257601 pJ
sum error= 319
Actual label: 2
Output voltages: [0.083771, 0.0088921, 0.79867, 0.036781, 0.037307, 0.0010677, 0.1416, 0.033754, 0.68004, 0.013185]
Predicted label: 2
Correct prediction
Energy consumption = 132.814371 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 747 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 747 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 747 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33229, 0.025364, 0.086806, 0.79857, 0.019874, 0.020521, 0.0096782, 0.04676, 0.63023, 0.071514]
Predicted label: 3
Correct prediction
Energy consumption = 161.318240 pJ
sum error= 319
Actual label: 9
Output voltages: [0.062111, 0.0010662, 0.0020765, 0.069811, 0.055996, 0.13565, 0.0027448, 0.060923, 0.60037, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 140.770660 pJ
sum error= 319
Actual label: 2
Output voltages: [0.30453, 0.022815, 0.79876, 0.26744, 0.018341, 0.0010861, 0.0072466, 0.28784, 0.46066, 0.20737]
Predicted label: 2
Correct prediction
Energy consumption = 139.747714 pJ
sum error= 319
Actual label: 4
Output voltages: [0.049199, 0.19559, 0.0099475, 0.010595, 0.79805, 0.0028468, 0.20967, 0.02628, 0.064247, 0.52114]
Predicted label: 4
Correct prediction
Energy consumption = 152.747810 pJ
sum error= 319
Actual label: 5
Output voltages: [0.066615, 0.0011782, 0.001074, 0.30587, 0.039143, 0.79867, 0.28973, 0.018262, 0.68133, 0.0059934]
Predicted label: 5
Correct prediction
Energy consumption = 140.436511 pJ
sum error= 319
Actual label: 5
Output voltages: [0.01421, 0.001072, 0.0017288, 0.39642, 0.071999, 0.79879, 0.20994, 0.035048, 0.75805, 0.0733]
Predicted label: 5
Correct prediction
Energy consumption = 142.519944 pJ
sum error= 319
Actual label: 3
Output voltages: [0.79359, 0.0011241, 0.17398, 0.79593, 0.0027193, 0.0074309, 0.0010674, 0.67516, 0.40448, 0.0046716]
Predicted label: 3
Correct prediction
Energy consumption = 144.555522 pJ
sum error= 319
Actual label: 7
Output voltages: [0.49969, 0.022274, 0.56221, 0.28844, 0.011042, 0.0012992, 0.0021643, 0.79626, 0.047118, 0.034602]
Predicted label: 7
Correct prediction
Energy consumption = 143.151782 pJ
sum error= 319
Actual label: 5
Output voltages: [0.18063, 0.0013476, 0.0010976, 0.11353, 0.056332, 0.79863, 0.22028, 0.0098625, 0.71462, 0.032159]
Predicted label: 5
Correct prediction
Energy consumption = 152.955590 pJ
sum error= 319
Actual label: 3
Output voltages: [0.37528, 0.04203, 0.040018, 0.79862, 0.022097, 0.15176, 0.013092, 0.0096111, 0.57156, 0.11196]
Predicted label: 3
Correct prediction
Energy consumption = 146.381068 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 748 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 748 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 748 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0044148, 0.79861, 0.17167, 0.0091541, 0.049098, 0.0016592, 0.75953, 0.0030727, 0.13531, 0.016677]
Predicted label: 1
Correct prediction
Energy consumption = 172.163016 pJ
sum error= 319
Actual label: 8
Output voltages: [0.027958, 0.041627, 0.0078553, 0.05199, 0.012681, 0.26125, 0.040029, 0.011353, 0.79879, 0.0015596]
Predicted label: 8
Correct prediction
Energy consumption = 148.915106 pJ
sum error= 319
Actual label: 2
Output voltages: [0.53376, 0.0034514, 0.79879, 0.38338, 0.0026328, 0.0011116, 0.054846, 0.45627, 0.7458, 0.012316]
Predicted label: 2
Correct prediction
Energy consumption = 141.817078 pJ
sum error= 319
Actual label: 2
Output voltages: [0.10822, 0.050169, 0.79877, 0.04327, 0.0029962, 0.0010893, 0.012467, 0.40658, 0.37825, 0.040948]
Predicted label: 2
Correct prediction
Energy consumption = 133.731387 pJ
sum error= 319
Actual label: 3
Output voltages: [0.066339, 0.075212, 0.12442, 0.79873, 0.0068484, 0.015287, 0.0021486, 0.035737, 0.7489, 0.023664]
Predicted label: 3
Correct prediction
Energy consumption = 145.083498 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79876, 0.03837, 0.032798, 0.024288, 0.017809, 0.0057086, 0.42107, 0.051031, 0.19004, 0.031191]
Predicted label: 0
Correct prediction
Energy consumption = 149.659108 pJ
sum error= 319
Actual label: 2
Output voltages: [0.58241, 0.0054448, 0.79879, 0.14308, 0.0075357, 0.0011218, 0.060002, 0.23062, 0.65662, 0.017147]
Predicted label: 2
Correct prediction
Energy consumption = 140.045993 pJ
sum error= 319
Actual label: 9
Output voltages: [0.25379, 0.004618, 0.018321, 0.025279, 0.19899, 0.027154, 0.002534, 0.0030885, 0.49958, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 141.465201 pJ
sum error= 319
Actual label: 4
Output voltages: [0.048986, 0.078095, 0.23075, 0.048414, 0.79833, 0.0040751, 0.03132, 0.054237, 0.023638, 0.010488]
Predicted label: 4
Correct prediction
Energy consumption = 147.051078 pJ
sum error= 319
Actual label: 9
Output voltages: [0.060811, 0.0053696, 0.029953, 0.092163, 0.030874, 0.016332, 0.0027917, 0.19255, 0.73758, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 141.427620 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 749 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 749 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 749 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.03994, 0.017919, 0.76648, 0.027077, 0.0030484, 0.0010852, 0.0010716, 0.79876, 0.55114, 0.25251]
Predicted label: 7
Correct prediction
Energy consumption = 160.810778 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79877, 0.020479, 0.023363, 0.0074524, 0.04523, 0.005267, 0.42114, 0.26302, 0.1449, 0.029697]
Predicted label: 0
Correct prediction
Energy consumption = 142.524640 pJ
sum error= 319
Actual label: 2
Output voltages: [0.75847, 0.036054, 0.78196, 0.26531, 0.0016687, 0.0011569, 0.015041, 0.74614, 0.58834, 0.0082203]
Predicted label: 2
Correct prediction
Energy consumption = 148.162756 pJ
sum error= 319
Actual label: 7
Output voltages: [0.054979, 0.29688, 0.75595, 0.020251, 0.012865, 0.0012135, 0.0011565, 0.79879, 0.034176, 0.10186]
Predicted label: 7
Correct prediction
Energy consumption = 149.181642 pJ
sum error= 319
Actual label: 4
Output voltages: [0.056297, 0.11033, 0.18476, 0.0094667, 0.7955, 0.0019023, 0.74528, 0.051314, 0.017543, 0.0041225]
Predicted label: 4
Correct prediction
Energy consumption = 159.676688 pJ
sum error= 319
Actual label: 9
Output voltages: [0.35433, 0.039059, 0.032269, 0.03241, 0.1778, 0.0015326, 0.0011088, 0.029384, 0.44147, 0.7978]
Predicted label: 9
Correct prediction
Energy consumption = 159.826408 pJ
sum error= 319
Actual label: 9
Output voltages: [0.41007, 0.010634, 0.014754, 0.043307, 0.30687, 0.0033511, 0.0012655, 0.042176, 0.23522, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 144.000087 pJ
sum error= 319
Actual label: 2
Output voltages: [0.2045, 0.32623, 0.7987, 0.043793, 0.024103, 0.0011487, 0.043094, 0.46651, 0.1405, 0.12353]
Predicted label: 2
Correct prediction
Energy consumption = 149.659073 pJ
sum error= 319
Actual label: 5
Output voltages: [0.44162, 0.010477, 0.0034867, 0.10502, 0.0011597, 0.79877, 0.31484, 0.03268, 0.76392, 0.0011396]
Predicted label: 5
Correct prediction
Energy consumption = 155.511541 pJ
sum error= 319
Actual label: 9
Output voltages: [0.28216, 0.013389, 0.022938, 0.018417, 0.034034, 0.0068475, 0.0010993, 0.029757, 0.67027, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 151.492000 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 750 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 750 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 750 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.011071, 0.30061, 0.16997, 0.23093, 0.0034404, 0.024357, 0.03718, 0.029151, 0.79868, 0.063777]
Predicted label: 8
Correct prediction
Energy consumption = 168.169718 pJ
sum error= 319
Actual label: 3
Output voltages: [0.42836, 0.03966, 0.23851, 0.79861, 0.0012965, 0.31581, 0.0046524, 0.10244, 0.49227, 0.008771]
Predicted label: 3
Correct prediction
Energy consumption = 149.467513 pJ
sum error= 319
Actual label: 8
Output voltages: [0.16914, 0.0094882, 0.028989, 0.49135, 0.0017185, 0.31689, 0.010341, 0.0011656, 0.79875, 0.048742]
Predicted label: 8
Correct prediction
Energy consumption = 145.523824 pJ
sum error= 319
Actual label: 6
Output voltages: [0.30288, 0.013334, 0.051692, 0.0010668, 0.23671, 0.04195, 0.79697, 0.002577, 0.53036, 0.0010788]
Predicted label: 6
Correct prediction
Energy consumption = 141.086400 pJ
sum error= 319
Actual label: 7
Output voltages: [0.022239, 0.020036, 0.7567, 0.022166, 0.0064354, 0.001068, 0.001089, 0.79874, 0.48141, 0.36717]
Predicted label: 7
Correct prediction
Energy consumption = 148.714263 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79831, 0.028566, 0.22764, 0.011925, 0.16359, 0.002672, 0.39029, 0.17214, 0.30352, 0.018674]
Predicted label: 0
Correct prediction
Energy consumption = 153.873910 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79864, 0.016643, 0.027375, 0.017111, 0.054077, 0.0051481, 0.73866, 0.0082469, 0.18737, 0.068079]
Predicted label: 0
Correct prediction
Energy consumption = 147.557360 pJ
sum error= 319
Actual label: 1
Output voltages: [0.05198, 0.79879, 0.30771, 0.016767, 0.74248, 0.0053034, 0.68123, 0.001066, 0.025056, 0.032704]
Predicted label: 1
Correct prediction
Energy consumption = 151.259652 pJ
sum error= 319
Actual label: 2
Output voltages: [0.39254, 0.053226, 0.79877, 0.054534, 0.012489, 0.0011923, 0.34243, 0.0065713, 0.67826, 0.019197]
Predicted label: 2
Correct prediction
Energy consumption = 142.144040 pJ
sum error= 319
Actual label: 3
Output voltages: [0.14762, 0.011541, 0.045892, 0.79877, 0.038801, 0.0042912, 0.009654, 0.0099452, 0.58184, 0.046782]
Predicted label: 3
Correct prediction
Energy consumption = 140.558611 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 751 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 751 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 751 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0054646, 0.0041957, 0.025824, 0.005521, 0.79863, 0.0049249, 0.36159, 0.30804, 0.1417, 0.0052875]
Predicted label: 4
Correct prediction
Energy consumption = 166.073833 pJ
sum error= 319
Actual label: 5
Output voltages: [0.13642, 0.0010891, 0.0020554, 0.75057, 0.01654, 0.79681, 0.37395, 0.052856, 0.357, 0.013226]
Predicted label: 5
Correct prediction
Energy consumption = 148.045928 pJ
sum error= 319
Actual label: 6
Output voltages: [0.018266, 0.14193, 0.47775, 0.0079975, 0.18399, 0.14045, 0.79873, 0.0015911, 0.52039, 0.010446]
Predicted label: 6
Correct prediction
Energy consumption = 143.573817 pJ
sum error= 319
Actual label: 7
Output voltages: [0.056187, 0.012113, 0.034924, 0.039869, 0.017983, 0.0062393, 0.0011256, 0.79844, 0.26153, 0.10638]
Predicted label: 7
Correct prediction
Energy consumption = 149.889418 pJ
sum error= 319
Actual label: 8
Output voltages: [0.43117, 0.0040849, 0.052607, 0.21729, 0.0064926, 0.045593, 0.30705, 0.0011473, 0.78974, 0.15262]
Predicted label: 8
Correct prediction
Energy consumption = 159.589772 pJ
sum error= 319
Actual label: 9
Output voltages: [0.27564, 0.013213, 0.035325, 0.040786, 0.3084, 0.012482, 0.0071184, 0.024444, 0.44319, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 144.291045 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79872, 0.023047, 0.029594, 0.011824, 0.033451, 0.0068861, 0.22209, 0.024466, 0.18878, 0.021973]
Predicted label: 0
Correct prediction
Energy consumption = 146.495996 pJ
sum error= 319
Actual label: 1
Output voltages: [0.25641, 0.78612, 0.21809, 0.12406, 0.021064, 0.014419, 0.76327, 0.0011467, 0.60426, 0.17101]
Predicted label: 1
Correct prediction
Energy consumption = 155.117756 pJ
sum error= 319
Actual label: 2
Output voltages: [0.22257, 0.027859, 0.79877, 0.04414, 0.0011367, 0.0011068, 0.015507, 0.055335, 0.74861, 0.0013112]
Predicted label: 2
Correct prediction
Energy consumption = 135.293906 pJ
sum error= 319
Actual label: 3
Output voltages: [0.067654, 0.01737, 0.077014, 0.79871, 0.0014287, 0.042907, 0.0026241, 0.0052431, 0.48636, 0.019233]
Predicted label: 3
Correct prediction
Energy consumption = 132.484689 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 752 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 752 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 752 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.003275, 0.021658, 0.17967, 0.033265, 0.79874, 0.0017366, 0.050004, 0.15744, 0.0057887, 0.024756]
Predicted label: 4
Correct prediction
Energy consumption = 162.195869 pJ
sum error= 319
Actual label: 5
Output voltages: [0.042012, 0.014209, 0.0011439, 0.48526, 0.082095, 0.79877, 0.55479, 0.012666, 0.24139, 0.11204]
Predicted label: 5
Correct prediction
Energy consumption = 140.842580 pJ
sum error= 319
Actual label: 6
Output voltages: [0.055807, 0.27288, 0.30695, 0.12112, 0.45786, 0.0069923, 0.79879, 0.0062549, 0.034955, 0.0015815]
Predicted label: 6
Correct prediction
Energy consumption = 144.866451 pJ
sum error= 319
Actual label: 7
Output voltages: [0.01806, 0.25053, 0.59857, 0.19875, 0.024359, 0.0010775, 0.0011084, 0.79872, 0.55326, 0.053341]
Predicted label: 7
Correct prediction
Energy consumption = 150.702350 pJ
sum error= 319
Actual label: 8
Output voltages: [0.32306, 0.015669, 0.13229, 0.073609, 0.0099503, 0.0054853, 0.10408, 0.0010814, 0.79863, 0.0096683]
Predicted label: 8
Correct prediction
Energy consumption = 151.439168 pJ
sum error= 319
Actual label: 9
Output voltages: [0.50905, 0.011803, 0.033571, 0.50248, 0.35304, 0.0023531, 0.0012335, 0.27278, 0.20257, 0.7915]
Predicted label: 9
Correct prediction
Energy consumption = 147.907753 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79878, 0.034265, 0.032796, 0.030008, 0.016975, 0.011459, 0.12355, 0.014993, 0.38024, 0.012036]
Predicted label: 0
Correct prediction
Energy consumption = 148.171840 pJ
sum error= 319
Actual label: 1
Output voltages: [0.0040442, 0.79873, 0.032972, 0.052298, 0.2646, 0.013828, 0.73477, 0.0012457, 0.4522, 0.030323]
Predicted label: 1
Correct prediction
Energy consumption = 160.134975 pJ
sum error= 319
Actual label: 2
Output voltages: [0.42046, 0.027172, 0.79873, 0.06534, 0.0019488, 0.0010886, 0.025077, 0.035348, 0.68068, 0.0023874]
Predicted label: 2
Correct prediction
Energy consumption = 145.460113 pJ
sum error= 319
Actual label: 3
Output voltages: [0.29542, 0.0035036, 0.27426, 0.7987, 0.069699, 0.008193, 0.001394, 0.014219, 0.36362, 0.23987]
Predicted label: 3
Correct prediction
Energy consumption = 146.745169 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 753 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 753 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 753 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.13183, 0.058364, 0.3061, 0.0041833, 0.79868, 0.0012194, 0.0094179, 0.057194, 0.016423, 0.48562]
Predicted label: 4
Correct prediction
Energy consumption = 166.740439 pJ
sum error= 319
Actual label: 5
Output voltages: [0.043114, 0.0011246, 0.0010679, 0.33567, 0.044917, 0.79875, 0.39855, 0.011125, 0.4721, 0.027665]
Predicted label: 5
Correct prediction
Energy consumption = 141.880166 pJ
sum error= 319
Actual label: 6
Output voltages: [0.044872, 0.019414, 0.55088, 0.016441, 0.41221, 0.0529, 0.79839, 0.031994, 0.48724, 0.0011282]
Predicted label: 6
Correct prediction
Energy consumption = 145.678047 pJ
sum error= 319
Actual label: 7
Output voltages: [0.34335, 0.040544, 0.028753, 0.04156, 0.019805, 0.015982, 0.0010732, 0.79867, 0.051168, 0.056167]
Predicted label: 7
Correct prediction
Energy consumption = 156.417419 pJ
sum error= 319
Actual label: 8
Output voltages: [0.20897, 0.0051607, 0.041581, 0.44406, 0.016594, 0.24412, 0.42051, 0.0011034, 0.79743, 0.023439]
Predicted label: 8
Correct prediction
Energy consumption = 155.061653 pJ
sum error= 319
Actual label: 9
Output voltages: [0.24865, 0.0095882, 0.030793, 0.025047, 0.40039, 0.021907, 0.0023862, 0.019432, 0.37274, 0.79623]
Predicted label: 9
Correct prediction
Energy consumption = 151.147953 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79872, 0.034611, 0.041872, 0.016699, 0.044078, 0.032646, 0.17689, 0.11541, 0.26631, 0.078791]
Predicted label: 0
Correct prediction
Energy consumption = 153.024177 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79879, 0.031479, 0.048034, 0.028893, 0.021563, 0.0032114, 0.50883, 0.026201, 0.61964, 0.013146]
Predicted label: 0
Correct prediction
Energy consumption = 144.074371 pJ
sum error= 319
Actual label: 7
Output voltages: [0.037698, 0.033987, 0.21676, 0.0029713, 0.22385, 0.0014513, 0.0010797, 0.79876, 0.03104, 0.3958]
Predicted label: 7
Correct prediction
Energy consumption = 152.008832 pJ
sum error= 319
Actual label: 2
Output voltages: [0.15306, 0.23273, 0.79517, 0.31062, 0.045637, 0.0012104, 0.0019848, 0.48313, 0.67172, 0.0015984]
Predicted label: 2
Correct prediction
Energy consumption = 144.772317 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 754 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 754 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 754 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.18233, 0.022315, 0.24696, 0.0010661, 0.29372, 0.11214, 0.79878, 0.0046923, 0.14398, 0.0018997]
Predicted label: 6
Correct prediction
Energy consumption = 163.735070 pJ
sum error= 319
Actual label: 5
Output voltages: [0.22168, 0.0087267, 0.0012158, 0.59843, 0.58842, 0.7987, 0.037078, 0.038791, 0.020447, 0.0065601]
Predicted label: 5
Correct prediction
Energy consumption = 137.901403 pJ
sum error= 319
Actual label: 5
Output voltages: [0.041922, 0.015917, 0.0010736, 0.25301, 0.1135, 0.79879, 0.4688, 0.011466, 0.39524, 0.0066829]
Predicted label: 5
Correct prediction
Energy consumption = 126.605359 pJ
sum error= 319
Actual label: 3
Output voltages: [0.43803, 0.014088, 0.39949, 0.79876, 0.0038678, 0.0030911, 0.0086445, 0.0031594, 0.73968, 0.004908]
Predicted label: 3
Correct prediction
Energy consumption = 142.054048 pJ
sum error= 319
Actual label: 7
Output voltages: [0.20157, 0.065804, 0.042856, 0.15173, 0.01237, 0.0015734, 0.0012173, 0.79871, 0.056082, 0.50626]
Predicted label: 7
Correct prediction
Energy consumption = 146.153347 pJ
sum error= 319
Actual label: 8
Output voltages: [0.34297, 0.0025816, 0.24388, 0.4681, 0.019422, 0.010301, 0.021527, 0.0010705, 0.79804, 0.16484]
Predicted label: 8
Correct prediction
Energy consumption = 152.885615 pJ
sum error= 319
Actual label: 6
Output voltages: [0.06021, 0.01595, 0.2794, 0.0035489, 0.5399, 0.17141, 0.79874, 0.0020786, 0.70055, 0.0032242]
Predicted label: 6
Correct prediction
Energy consumption = 144.811702 pJ
sum error= 319
Actual label: 6
Output voltages: [0.033162, 0.079798, 0.38355, 0.0035106, 0.2238, 0.089735, 0.79874, 0.0015853, 0.60365, 0.007964]
Predicted label: 6
Correct prediction
Energy consumption = 135.350787 pJ
sum error= 319
Actual label: 6
Output voltages: [0.085701, 0.061387, 0.35317, 0.0010748, 0.36599, 0.046669, 0.79869, 0.0013757, 0.44175, 0.0090879]
Predicted label: 6
Correct prediction
Energy consumption = 134.940726 pJ
sum error= 319
Actual label: 6
Output voltages: [0.202, 0.26614, 0.019476, 0.01097, 0.10822, 0.68097, 0.79873, 0.02254, 0.67907, 0.0011968]
Predicted label: 6
Correct prediction
Energy consumption = 140.963434 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 755 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 755 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 755 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.025959, 0.0025625, 0.37112, 0.11621, 0.79879, 0.0011131, 0.019895, 0.018336, 0.036285, 0.074556]
Predicted label: 4
Correct prediction
Energy consumption = 162.772960 pJ
sum error= 319
Actual label: 3
Output voltages: [0.49232, 0.018953, 0.027501, 0.79871, 0.026188, 0.027798, 0.026581, 0.0060591, 0.59244, 0.045937]
Predicted label: 3
Correct prediction
Energy consumption = 150.674798 pJ
sum error= 319
Actual label: 8
Output voltages: [0.11076, 0.020977, 0.051684, 0.21938, 0.0068233, 0.019582, 0.02497, 0.010613, 0.79703, 0.59008]
Predicted label: 8
Correct prediction
Energy consumption = 154.198548 pJ
sum error= 319
Actual label: 8
Output voltages: [0.55489, 0.019038, 0.18957, 0.5025, 0.025136, 0.020886, 0.039575, 0.0010712, 0.7976, 0.52411]
Predicted label: 8
Correct prediction
Energy consumption = 147.470451 pJ
sum error= 319
Actual label: 3
Output voltages: [0.52793, 0.011306, 0.024979, 0.79862, 0.02924, 0.1419, 0.0028219, 0.0019557, 0.46233, 0.068406]
Predicted label: 3
Correct prediction
Energy consumption = 146.647843 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79799, 0.057687, 0.19745, 0.02724, 0.010861, 0.0030456, 0.49021, 0.029076, 0.11515, 0.029225]
Predicted label: 0
Correct prediction
Energy consumption = 152.568652 pJ
sum error= 319
Actual label: 1
Output voltages: [0.024672, 0.79879, 0.46447, 0.09443, 0.27145, 0.0011049, 0.024086, 0.035657, 0.35848, 0.079307]
Predicted label: 1
Correct prediction
Energy consumption = 154.129766 pJ
sum error= 319
Actual label: 9
Output voltages: [0.40848, 0.035597, 0.0084528, 0.040416, 0.36265, 0.002462, 0.0012158, 0.0016812, 0.083588, 0.79866]
Predicted label: 9
Correct prediction
Energy consumption = 151.955800 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79796, 0.0060192, 0.33768, 0.014959, 0.01387, 0.0013719, 0.5129, 0.072716, 0.39554, 0.042281]
Predicted label: 0
Correct prediction
Energy consumption = 155.738945 pJ
sum error= 319
Actual label: 5
Output voltages: [0.27039, 0.0029783, 0.0065286, 0.69192, 0.015482, 0.79871, 0.075328, 0.038203, 0.55425, 0.12767]
Predicted label: 5
Correct prediction
Energy consumption = 149.890333 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 756 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 756 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 756 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0016454, 0.0086053, 0.007511, 0.013336, 0.79872, 0.030278, 0.054607, 0.68098, 0.30987, 0.0019364]
Predicted label: 4
Correct prediction
Energy consumption = 164.796557 pJ
sum error= 319
Actual label: 1
Output voltages: [0.034699, 0.79877, 0.12738, 0.018421, 0.036616, 0.0010738, 0.5309, 0.0010685, 0.22046, 0.029249]
Predicted label: 1
Correct prediction
Energy consumption = 159.387213 pJ
sum error= 319
Actual label: 9
Output voltages: [0.30632, 0.002944, 0.017005, 0.11667, 0.33796, 0.001267, 0.0011093, 0.0042522, 0.41956, 0.79716]
Predicted label: 9
Correct prediction
Energy consumption = 152.483697 pJ
sum error= 319
Actual label: 1
Output voltages: [0.010302, 0.79879, 0.30295, 0.0018984, 0.20817, 0.0025588, 0.68517, 0.001071, 0.59097, 0.051818]
Predicted label: 1
Correct prediction
Energy consumption = 151.726856 pJ
sum error= 319
Actual label: 2
Output voltages: [0.43516, 0.033791, 0.79876, 0.20969, 0.0041984, 0.0011256, 0.01367, 0.29413, 0.69161, 0.0018402]
Predicted label: 2
Correct prediction
Energy consumption = 145.925106 pJ
sum error= 319
Actual label: 7
Output voltages: [0.43318, 0.023029, 0.017774, 0.21777, 0.015021, 0.013381, 0.001873, 0.79863, 0.022059, 0.0011043]
Predicted label: 7
Correct prediction
Energy consumption = 149.562105 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79878, 0.023978, 0.41778, 0.01846, 0.01291, 0.0011396, 0.28676, 0.023677, 0.072132, 0.046117]
Predicted label: 0
Correct prediction
Energy consumption = 143.059966 pJ
sum error= 319
Actual label: 1
Output voltages: [0.0066833, 0.79874, 0.044941, 0.086087, 0.58993, 0.00107, 0.071027, 0.025363, 0.039271, 0.18535]
Predicted label: 1
Correct prediction
Energy consumption = 154.949151 pJ
sum error= 319
Actual label: 3
Output voltages: [0.32832, 0.0024308, 0.47321, 0.79612, 0.018668, 0.0040295, 0.00284, 0.0022841, 0.78114, 0.010431]
Predicted label: 3
Correct prediction
Energy consumption = 152.763405 pJ
sum error= 319
Actual label: 8
Output voltages: [0.045594, 0.048555, 0.19372, 0.17768, 0.006811, 0.017471, 0.31854, 0.0014352, 0.79855, 0.032729]
Predicted label: 8
Correct prediction
Energy consumption = 149.898458 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 757 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 757 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 757 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.37274, 0.06513, 0.79872, 0.059232, 0.013239, 0.0012795, 0.34757, 0.038637, 0.44545, 0.023049]
Predicted label: 2
Correct prediction
Energy consumption = 156.623724 pJ
sum error= 319
Actual label: 9
Output voltages: [0.51478, 0.010588, 0.036211, 0.020356, 0.14614, 0.0047983, 0.0013574, 0.018399, 0.51833, 0.79854]
Predicted label: 9
Correct prediction
Energy consumption = 146.171019 pJ
sum error= 319
Actual label: 2
Output voltages: [0.21957, 0.012995, 0.79869, 0.0595, 0.013547, 0.0010917, 0.04029, 0.10812, 0.55041, 0.015205]
Predicted label: 2
Correct prediction
Energy consumption = 140.560893 pJ
sum error= 319
Actual label: 7
Output voltages: [0.29778, 0.13743, 0.21764, 0.01477, 0.025458, 0.0013841, 0.0011194, 0.79874, 0.17142, 0.23395]
Predicted label: 7
Correct prediction
Energy consumption = 143.544114 pJ
sum error= 319
Actual label: 4
Output voltages: [0.0033982, 0.62107, 0.025228, 0.015239, 0.79871, 0.0015215, 0.048723, 0.05956, 0.0050907, 0.56501]
Predicted label: 4
Correct prediction
Energy consumption = 139.707574 pJ
sum error= 319
Actual label: 2
Output voltages: [0.25174, 0.02912, 0.79873, 0.042021, 0.0078741, 0.0013178, 0.24445, 0.054497, 0.51998, 0.015853]
Predicted label: 2
Correct prediction
Energy consumption = 151.279522 pJ
sum error= 319
Actual label: 6
Output voltages: [0.023436, 0.038464, 0.18174, 0.00783, 0.029027, 0.47554, 0.79879, 0.042957, 0.75405, 0.002788]
Predicted label: 6
Correct prediction
Energy consumption = 148.791695 pJ
sum error= 319
Actual label: 5
Output voltages: [0.18558, 0.0010873, 0.0011055, 0.36213, 0.14089, 0.79872, 0.3107, 0.023779, 0.60638, 0.026056]
Predicted label: 5
Correct prediction
Energy consumption = 131.443132 pJ
sum error= 319
Actual label: 5
Output voltages: [0.25257, 0.0015468, 0.0010667, 0.60257, 0.053272, 0.79874, 0.35065, 0.0060924, 0.58954, 0.047477]
Predicted label: 5
Correct prediction
Energy consumption = 126.290425 pJ
sum error= 319
Actual label: 9
Output voltages: [0.020335, 0.0015188, 0.0087746, 0.68434, 0.78081, 0.011018, 0.0019837, 0.040099, 0.13935, 0.77505]
Predicted label: 4
Wrong prediction!
Energy consumption = 151.344540 pJ
sum error= 320
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 758 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 758 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 758 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.20886, 0.010617, 0.0040749, 0.41655, 0.67032, 0.0016729, 0.0011977, 0.001067, 0.15351, 0.78479]
Predicted label: 9
Correct prediction
Energy consumption = 167.182349 pJ
sum error= 320
Actual label: 1
Output voltages: [0.02484, 0.79862, 0.35297, 0.018041, 0.20583, 0.0015087, 0.70691, 0.0013432, 0.18169, 0.048827]
Predicted label: 1
Correct prediction
Energy consumption = 153.960336 pJ
sum error= 320
Actual label: 1
Output voltages: [0.0090246, 0.79877, 0.016982, 0.040927, 0.44692, 0.001425, 0.10016, 0.041775, 0.1188, 0.053777]
Predicted label: 1
Correct prediction
Energy consumption = 139.286594 pJ
sum error= 320
Actual label: 5
Output voltages: [0.27646, 0.023579, 0.0011756, 0.53465, 0.60165, 0.79875, 0.2737, 0.004734, 0.16852, 0.23759]
Predicted label: 5
Correct prediction
Energy consumption = 142.644797 pJ
sum error= 320
Actual label: 7
Output voltages: [0.13385, 0.051449, 0.040217, 0.29586, 0.0095849, 0.010283, 0.0013061, 0.79879, 0.27451, 0.60661]
Predicted label: 7
Correct prediction
Energy consumption = 158.433627 pJ
sum error= 320
Actual label: 6
Output voltages: [0.049284, 0.015635, 0.18473, 0.002226, 0.24862, 0.21184, 0.79879, 0.0039999, 0.57578, 0.0026931]
Predicted label: 6
Correct prediction
Energy consumption = 155.432749 pJ
sum error= 320
Actual label: 8
Output voltages: [0.20021, 0.033869, 0.39977, 0.045896, 0.014772, 0.017669, 0.047596, 0.0014859, 0.79879, 0.11365]
Predicted label: 8
Correct prediction
Energy consumption = 152.284081 pJ
sum error= 320
Actual label: 2
Output voltages: [0.054171, 0.34742, 0.79635, 0.51804, 0.0027503, 0.001331, 0.070111, 0.0047737, 0.42749, 0.058417]
Predicted label: 2
Correct prediction
Energy consumption = 147.841822 pJ
sum error= 320
Actual label: 9
Output voltages: [0.31874, 0.016589, 0.01502, 0.043967, 0.51347, 0.0024976, 0.0012551, 0.001365, 0.2164, 0.79789]
Predicted label: 9
Correct prediction
Energy consumption = 156.664115 pJ
sum error= 320
Actual label: 4
Output voltages: [0.0065925, 0.0025798, 0.61045, 0.0070518, 0.79861, 0.0015377, 0.27592, 0.056193, 0.015566, 0.035904]
Predicted label: 4
Correct prediction
Energy consumption = 139.276764 pJ
sum error= 320
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 759 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 759 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 759 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.20564, 0.017124, 0.020664, 0.7987, 0.018983, 0.015665, 0.0088733, 0.027102, 0.67857, 0.037093]
Predicted label: 3
Correct prediction
Energy consumption = 165.753182 pJ
sum error= 320
Actual label: 1
Output voltages: [0.0085803, 0.79873, 0.31995, 0.10856, 0.2271, 0.0010991, 0.38783, 0.0047621, 0.23956, 0.063328]
Predicted label: 1
Correct prediction
Energy consumption = 158.898966 pJ
sum error= 320
Actual label: 9
Output voltages: [0.36459, 0.012216, 0.04931, 0.035944, 0.76977, 0.0026163, 0.0077932, 0.0033578, 0.10535, 0.79174]
Predicted label: 9
Correct prediction
Energy consumption = 157.102203 pJ
sum error= 320
Actual label: 0
Output voltages: [0.79591, 0.053198, 0.052766, 0.035009, 0.046273, 0.0018067, 0.77433, 0.003353, 0.17347, 0.079903]
Predicted label: 0
Correct prediction
Energy consumption = 148.012172 pJ
sum error= 320
Actual label: 9
Output voltages: [0.13516, 0.027729, 0.02598, 0.045944, 0.17554, 0.0085715, 0.0023948, 0.021209, 0.46682, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 146.189433 pJ
sum error= 320
Actual label: 3
Output voltages: [0.35637, 0.0086127, 0.29215, 0.77802, 0.0068796, 0.0060578, 0.004299, 0.0011976, 0.77907, 0.16324]
Predicted label: 8
Wrong prediction!
Energy consumption = 145.098547 pJ
sum error= 321
Actual label: 6
Output voltages: [0.027938, 0.033103, 0.45129, 0.0021074, 0.45173, 0.21222, 0.7987, 0.0080209, 0.3475, 0.0063311]
Predicted label: 6
Correct prediction
Energy consumption = 151.538258 pJ
sum error= 321
Actual label: 8
Output voltages: [0.045304, 0.0095364, 0.053595, 0.10384, 0.0080595, 0.044838, 0.0035386, 0.0013151, 0.79872, 0.030744]
Predicted label: 8
Correct prediction
Energy consumption = 147.976760 pJ
sum error= 321
Actual label: 7
Output voltages: [0.066583, 0.010984, 0.032409, 0.072556, 0.014607, 0.0047666, 0.001074, 0.79857, 0.287, 0.33842]
Predicted label: 7
Correct prediction
Energy consumption = 154.351866 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79745, 0.052586, 0.24532, 0.043849, 0.016649, 0.0015277, 0.31166, 0.019128, 0.5278, 0.048193]
Predicted label: 0
Correct prediction
Energy consumption = 155.219493 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 760 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 760 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 760 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.039881, 0.79865, 0.19811, 0.011702, 0.2549, 0.0022473, 0.40388, 0.0097737, 0.11973, 0.010963]
Predicted label: 1
Correct prediction
Energy consumption = 170.200758 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79877, 0.033021, 0.025412, 0.016293, 0.011976, 0.0050451, 0.40481, 0.051277, 0.1766, 0.029395]
Predicted label: 0
Correct prediction
Energy consumption = 149.756387 pJ
sum error= 321
Actual label: 5
Output voltages: [0.28082, 0.0010803, 0.0010894, 0.69901, 0.041611, 0.79814, 0.46297, 0.016658, 0.50712, 0.1992]
Predicted label: 5
Correct prediction
Energy consumption = 140.514198 pJ
sum error= 321
Actual label: 8
Output voltages: [0.51406, 0.019224, 0.32735, 0.063341, 0.038504, 0.012008, 0.030575, 0.0011152, 0.79874, 0.050714]
Predicted label: 8
Correct prediction
Energy consumption = 143.373461 pJ
sum error= 321
Actual label: 2
Output voltages: [0.55455, 0.020958, 0.79877, 0.28195, 0.0021012, 0.0011134, 0.038633, 0.027864, 0.57361, 0.0077091]
Predicted label: 2
Correct prediction
Energy consumption = 141.816616 pJ
sum error= 321
Actual label: 7
Output voltages: [0.036849, 0.059042, 0.17553, 0.0017991, 0.04701, 0.001067, 0.0010676, 0.79867, 0.21397, 0.2611]
Predicted label: 7
Correct prediction
Energy consumption = 150.778326 pJ
sum error= 321
Actual label: 7
Output voltages: [0.016594, 0.031442, 0.49966, 0.011219, 0.0063501, 0.0010775, 0.0011141, 0.79832, 0.7346, 0.043189]
Predicted label: 7
Correct prediction
Energy consumption = 135.761688 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79879, 0.050114, 0.020154, 0.014122, 0.07082, 0.010248, 0.70851, 0.010248, 0.079857, 0.047116]
Predicted label: 0
Correct prediction
Energy consumption = 159.403886 pJ
sum error= 321
Actual label: 1
Output voltages: [0.055952, 0.79874, 0.031062, 0.31986, 0.13562, 0.016721, 0.68125, 0.0011707, 0.10559, 0.1084]
Predicted label: 1
Correct prediction
Energy consumption = 160.892471 pJ
sum error= 321
Actual label: 2
Output voltages: [0.54773, 0.0075522, 0.79878, 0.10315, 0.026193, 0.001124, 0.061453, 0.030431, 0.44913, 0.027309]
Predicted label: 2
Correct prediction
Energy consumption = 144.410069 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 761 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 761 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 761 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.19896, 0.015693, 0.14852, 0.79877, 0.12039, 0.01794, 0.01844, 0.045152, 0.73195, 0.019428]
Predicted label: 3
Correct prediction
Energy consumption = 164.347795 pJ
sum error= 321
Actual label: 4
Output voltages: [0.010326, 0.01572, 0.26172, 0.027534, 0.79863, 0.030029, 0.063519, 0.047316, 0.031132, 0.040509]
Predicted label: 4
Correct prediction
Energy consumption = 160.811937 pJ
sum error= 321
Actual label: 5
Output voltages: [0.025661, 0.0012543, 0.0042616, 0.43583, 0.037575, 0.79873, 0.31689, 0.033266, 0.7047, 0.065264]
Predicted label: 5
Correct prediction
Energy consumption = 151.909730 pJ
sum error= 321
Actual label: 6
Output voltages: [0.18188, 0.063008, 0.18562, 0.0011345, 0.37355, 0.33554, 0.79872, 0.0018568, 0.2939, 0.015488]
Predicted label: 6
Correct prediction
Energy consumption = 148.463018 pJ
sum error= 321
Actual label: 7
Output voltages: [0.080542, 0.042902, 0.03583, 0.13054, 0.0058912, 0.0010777, 0.0011094, 0.79873, 0.42536, 0.21429]
Predicted label: 7
Correct prediction
Energy consumption = 156.163485 pJ
sum error= 321
Actual label: 8
Output voltages: [0.015807, 0.031293, 0.23538, 0.056969, 0.0080754, 0.01634, 0.037208, 0.026719, 0.79876, 0.26837]
Predicted label: 8
Correct prediction
Energy consumption = 147.752585 pJ
sum error= 321
Actual label: 9
Output voltages: [0.30557, 0.0067845, 0.034928, 0.042342, 0.42241, 0.021823, 0.013872, 0.014164, 0.21599, 0.79866]
Predicted label: 9
Correct prediction
Energy consumption = 155.829157 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79874, 0.14696, 0.038035, 0.016735, 0.018325, 0.018981, 0.16317, 0.010008, 0.031855, 0.22222]
Predicted label: 0
Correct prediction
Energy consumption = 153.280956 pJ
sum error= 321
Actual label: 1
Output voltages: [0.025467, 0.79846, 0.11221, 0.17991, 0.015276, 0.0029539, 0.73771, 0.0017613, 0.042151, 0.048551]
Predicted label: 1
Correct prediction
Energy consumption = 161.433827 pJ
sum error= 321
Actual label: 2
Output voltages: [0.34082, 0.0010909, 0.77514, 0.77737, 0.023618, 0.0011412, 0.0028533, 0.046517, 0.75336, 0.015576]
Predicted label: 3
Wrong prediction!
Energy consumption = 151.611507 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 762 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 762 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 762 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.044735, 0.019167, 0.075138, 0.79868, 0.16187, 0.010019, 0.0072142, 0.030708, 0.58296, 0.11604]
Predicted label: 3
Correct prediction
Energy consumption = 158.427867 pJ
sum error= 322
Actual label: 4
Output voltages: [0.030517, 0.012885, 0.22239, 0.012399, 0.79869, 0.0016054, 0.22971, 0.030342, 0.021486, 0.053248]
Predicted label: 4
Correct prediction
Energy consumption = 153.687627 pJ
sum error= 322
Actual label: 5
Output voltages: [0.14405, 0.0046277, 0.0012684, 0.74013, 0.035011, 0.79866, 0.26996, 0.061504, 0.76992, 0.024635]
Predicted label: 5
Correct prediction
Energy consumption = 151.001200 pJ
sum error= 322
Actual label: 8
Output voltages: [0.21154, 0.1565, 0.051545, 0.1632, 0.018158, 0.040396, 0.075508, 0.010258, 0.79876, 0.34738]
Predicted label: 8
Correct prediction
Energy consumption = 150.181599 pJ
sum error= 322
Actual label: 9
Output voltages: [0.57498, 0.014956, 0.1969, 0.62789, 0.024406, 0.009922, 0.034881, 0.042455, 0.014869, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 159.266908 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79879, 0.15137, 0.081207, 0.033569, 0.032895, 0.0082211, 0.75599, 0.0096219, 0.23564, 0.021731]
Predicted label: 0
Correct prediction
Energy consumption = 157.366364 pJ
sum error= 322
Actual label: 1
Output voltages: [0.018869, 0.79844, 0.047031, 0.15233, 0.025388, 0.0066103, 0.49378, 0.017432, 0.30508, 0.029884]
Predicted label: 1
Correct prediction
Energy consumption = 161.589921 pJ
sum error= 322
Actual label: 2
Output voltages: [0.70064, 0.0019055, 0.79874, 0.36003, 0.0037, 0.002257, 0.063528, 0.075172, 0.52339, 0.0032159]
Predicted label: 2
Correct prediction
Energy consumption = 149.761681 pJ
sum error= 322
Actual label: 3
Output voltages: [0.069777, 0.018801, 0.32553, 0.79868, 0.045892, 0.012499, 0.0051539, 0.08836, 0.53081, 0.070796]
Predicted label: 3
Correct prediction
Energy consumption = 145.114885 pJ
sum error= 322
Actual label: 4
Output voltages: [0.011887, 0.010844, 0.033866, 0.0065373, 0.79879, 0.0025859, 0.22114, 0.59832, 0.10502, 0.038021]
Predicted label: 4
Correct prediction
Energy consumption = 159.231093 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 763 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 763 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 763 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.049269, 0.0010971, 0.0036686, 0.38238, 0.035884, 0.79875, 0.23955, 0.1796, 0.77267, 0.033647]
Predicted label: 5
Correct prediction
Energy consumption = 164.049086 pJ
sum error= 322
Actual label: 6
Output voltages: [0.20106, 0.0064717, 0.15459, 0.0026143, 0.5468, 0.247, 0.79878, 0.0014042, 0.73678, 0.0093797]
Predicted label: 6
Correct prediction
Energy consumption = 148.082757 pJ
sum error= 322
Actual label: 7
Output voltages: [0.03731, 0.045984, 0.050301, 0.019738, 0.021542, 0.0018763, 0.0012461, 0.79854, 0.12631, 0.28614]
Predicted label: 7
Correct prediction
Energy consumption = 162.131787 pJ
sum error= 322
Actual label: 8
Output voltages: [0.036632, 0.13486, 0.099511, 0.27749, 0.014877, 0.0089139, 0.046502, 0.012601, 0.79875, 0.16498]
Predicted label: 8
Correct prediction
Energy consumption = 150.267352 pJ
sum error= 322
Actual label: 9
Output voltages: [0.21902, 0.020184, 0.028024, 0.103, 0.15349, 0.0057979, 0.0091727, 0.042993, 0.37202, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 155.248540 pJ
sum error= 322
Actual label: 2
Output voltages: [0.57226, 0.0014259, 0.79876, 0.068636, 0.0055652, 0.001066, 0.0093111, 0.10228, 0.59355, 0.0089722]
Predicted label: 2
Correct prediction
Energy consumption = 148.247056 pJ
sum error= 322
Actual label: 1
Output voltages: [0.0023259, 0.79857, 0.034111, 0.020448, 0.049701, 0.0019083, 0.56674, 0.0062124, 0.017837, 0.2773]
Predicted label: 1
Correct prediction
Energy consumption = 166.451865 pJ
sum error= 322
Actual label: 2
Output voltages: [0.48755, 0.0012369, 0.79875, 0.52927, 0.0024742, 0.0011452, 0.0023053, 0.18121, 0.47818, 0.011846]
Predicted label: 2
Correct prediction
Energy consumption = 154.524124 pJ
sum error= 322
Actual label: 1
Output voltages: [0.0035941, 0.7987, 0.019306, 0.34261, 0.055246, 0.015075, 0.12999, 0.0024725, 0.26861, 0.12153]
Predicted label: 1
Correct prediction
Energy consumption = 165.808287 pJ
sum error= 322
Actual label: 3
Output voltages: [0.04132, 0.0016578, 0.13607, 0.79879, 0.043092, 0.02986, 0.013733, 0.016814, 0.71881, 0.035908]
Predicted label: 3
Correct prediction
Energy consumption = 141.613615 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 764 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 764 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 764 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.28217, 0.052987, 0.0335, 0.032872, 0.089219, 0.024945, 0.0073477, 0.01699, 0.13749, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 175.652850 pJ
sum error= 322
Actual label: 9
Output voltages: [0.031856, 0.018528, 0.093718, 0.011772, 0.036238, 0.0073456, 0.017805, 0.012784, 0.53717, 0.79828]
Predicted label: 9
Correct prediction
Energy consumption = 148.552510 pJ
sum error= 322
Actual label: 8
Output voltages: [0.012064, 0.16294, 0.048647, 0.28303, 0.0077838, 0.018078, 0.043942, 0.024931, 0.79871, 0.036416]
Predicted label: 8
Correct prediction
Energy consumption = 153.119843 pJ
sum error= 322
Actual label: 5
Output voltages: [0.14618, 0.0011067, 0.0033645, 0.27227, 0.023201, 0.79868, 0.066952, 0.19457, 0.76626, 0.016721]
Predicted label: 5
Correct prediction
Energy consumption = 144.603918 pJ
sum error= 322
Actual label: 3
Output voltages: [0.44685, 0.011823, 0.065059, 0.79862, 0.023453, 0.1173, 0.013004, 0.031193, 0.57979, 0.054143]
Predicted label: 3
Correct prediction
Energy consumption = 141.713774 pJ
sum error= 322
Actual label: 7
Output voltages: [0.22648, 0.020475, 0.032601, 0.032054, 0.0052077, 0.0059383, 0.0010831, 0.79879, 0.72689, 0.50861]
Predicted label: 7
Correct prediction
Energy consumption = 141.618616 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79875, 0.10248, 0.28658, 0.0067459, 0.037989, 0.0020775, 0.073273, 0.0035182, 0.2786, 0.026879]
Predicted label: 0
Correct prediction
Energy consumption = 157.756926 pJ
sum error= 322
Actual label: 7
Output voltages: [0.032703, 0.26469, 0.42414, 0.068907, 0.0016201, 0.0011285, 0.0011517, 0.79871, 0.50665, 0.29931]
Predicted label: 7
Correct prediction
Energy consumption = 149.985266 pJ
sum error= 322
Actual label: 7
Output voltages: [0.050283, 0.29075, 0.69854, 0.036733, 0.0052172, 0.0010766, 0.0010672, 0.79867, 0.22982, 0.1684]
Predicted label: 7
Correct prediction
Energy consumption = 136.670048 pJ
sum error= 322
Actual label: 5
Output voltages: [0.036614, 0.001113, 0.0025853, 0.17697, 0.0323, 0.79876, 0.25399, 0.066402, 0.69495, 0.1884]
Predicted label: 5
Correct prediction
Energy consumption = 145.205093 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 765 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 765 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 765 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.031544, 0.16143, 0.095462, 0.18446, 0.0036648, 0.0011451, 0.0010943, 0.79872, 0.43523, 0.29494]
Predicted label: 7
Correct prediction
Energy consumption = 176.048149 pJ
sum error= 322
Actual label: 9
Output voltages: [0.022804, 0.033459, 0.039847, 0.035008, 0.28439, 0.0050492, 0.0025154, 0.0014291, 0.57516, 0.7938]
Predicted label: 9
Correct prediction
Energy consumption = 152.116328 pJ
sum error= 322
Actual label: 9
Output voltages: [0.096555, 0.006952, 0.058818, 0.018784, 0.22976, 0.003863, 0.074619, 0.0054775, 0.36956, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 140.322405 pJ
sum error= 322
Actual label: 4
Output voltages: [0.0075728, 0.029429, 0.20835, 0.038529, 0.79864, 0.0016182, 0.19358, 0.044653, 0.019388, 0.085296]
Predicted label: 4
Correct prediction
Energy consumption = 148.755935 pJ
sum error= 322
Actual label: 7
Output voltages: [0.046871, 0.041023, 0.10278, 0.096562, 0.0040734, 0.012116, 0.0010755, 0.79865, 0.45854, 0.43646]
Predicted label: 7
Correct prediction
Energy consumption = 153.648778 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79879, 0.20394, 0.032765, 0.025694, 0.014543, 0.0097932, 0.48617, 0.0032071, 0.16599, 0.010006]
Predicted label: 0
Correct prediction
Energy consumption = 158.078556 pJ
sum error= 322
Actual label: 3
Output voltages: [0.045485, 0.018968, 0.092168, 0.79872, 0.21738, 0.0015661, 0.027211, 0.25676, 0.64336, 0.02965]
Predicted label: 3
Correct prediction
Energy consumption = 152.349550 pJ
sum error= 322
Actual label: 4
Output voltages: [0.040034, 0.015901, 0.054614, 0.0090576, 0.79874, 0.0021685, 0.026441, 0.026077, 0.0090798, 0.49702]
Predicted label: 4
Correct prediction
Energy consumption = 157.662360 pJ
sum error= 322
Actual label: 1
Output voltages: [0.01562, 0.79846, 0.019493, 0.036415, 0.0094796, 0.0035854, 0.42307, 0.0062794, 0.60707, 0.04901]
Predicted label: 1
Correct prediction
Energy consumption = 166.950551 pJ
sum error= 322
Actual label: 5
Output voltages: [0.043318, 0.001095, 0.0052219, 0.36954, 0.0059142, 0.79839, 0.091687, 0.02856, 0.7551, 0.073939]
Predicted label: 5
Correct prediction
Energy consumption = 148.116664 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 766 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 766 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 766 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.038262, 0.051609, 0.23707, 0.11565, 0.0075907, 0.021427, 0.028834, 0.015441, 0.79875, 0.18574]
Predicted label: 8
Correct prediction
Energy consumption = 167.887186 pJ
sum error= 322
Actual label: 1
Output voltages: [0.0078924, 0.79841, 0.02984, 0.039511, 0.023067, 0.029559, 0.75275, 0.034531, 0.043303, 0.020178]
Predicted label: 1
Correct prediction
Energy consumption = 163.490648 pJ
sum error= 322
Actual label: 4
Output voltages: [0.0010777, 0.0091023, 0.37482, 0.023245, 0.79868, 0.0014212, 0.31898, 0.051806, 0.043531, 0.039133]
Predicted label: 4
Correct prediction
Energy consumption = 156.640925 pJ
sum error= 322
Actual label: 8
Output voltages: [0.0068371, 0.17835, 0.34556, 0.033542, 0.021134, 0.0048291, 0.022834, 0.036164, 0.79874, 0.1342]
Predicted label: 8
Correct prediction
Energy consumption = 152.038852 pJ
sum error= 322
Actual label: 4
Output voltages: [0.0086847, 0.057815, 0.083632, 0.0044146, 0.79867, 0.037424, 0.19462, 0.086623, 0.047543, 0.036818]
Predicted label: 4
Correct prediction
Energy consumption = 159.026857 pJ
sum error= 322
Actual label: 1
Output voltages: [0.0082222, 0.79855, 0.011135, 0.21915, 0.086897, 0.0066592, 0.54834, 0.0089506, 0.22845, 0.40068]
Predicted label: 1
Correct prediction
Energy consumption = 165.247509 pJ
sum error= 322
Actual label: 8
Output voltages: [0.019655, 0.035452, 0.3691, 0.032194, 0.021351, 0.0077558, 0.019215, 0.013661, 0.79865, 0.090834]
Predicted label: 8
Correct prediction
Energy consumption = 148.327695 pJ
sum error= 322
Actual label: 6
Output voltages: [0.098027, 0.19571, 0.40481, 0.0010876, 0.20792, 0.061502, 0.79871, 0.0018589, 0.5103, 0.011105]
Predicted label: 6
Correct prediction
Energy consumption = 146.676891 pJ
sum error= 322
Actual label: 6
Output voltages: [0.019418, 0.047472, 0.67227, 0.0010963, 0.28488, 0.19527, 0.79879, 0.001328, 0.23731, 0.0014757]
Predicted label: 6
Correct prediction
Energy consumption = 138.265806 pJ
sum error= 322
Actual label: 4
Output voltages: [0.0017792, 0.0045776, 0.30192, 0.0050395, 0.79874, 0.0026156, 0.098771, 0.062789, 0.013538, 0.15894]
Predicted label: 4
Correct prediction
Energy consumption = 155.654599 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 767 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 767 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 767 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.063008, 0.10053, 0.22442, 0.016774, 0.31913, 0.22118, 0.79864, 0.0025878, 0.54445, 0.022787]
Predicted label: 6
Correct prediction
Energy consumption = 165.700098 pJ
sum error= 322
Actual label: 0
Output voltages: [0.7914, 0.036765, 0.0089231, 0.0080194, 0.0188, 0.12754, 0.76742, 0.029792, 0.15851, 0.032991]
Predicted label: 0
Correct prediction
Energy consumption = 158.375058 pJ
sum error= 322
Actual label: 5
Output voltages: [0.19124, 0.0010745, 0.0065146, 0.41605, 0.003396, 0.79879, 0.04646, 0.060462, 0.79325, 0.02426]
Predicted label: 5
Correct prediction
Energy consumption = 142.177541 pJ
sum error= 322
Actual label: 5
Output voltages: [0.051389, 0.0065347, 0.0010661, 0.78309, 0.002585, 0.79416, 0.074996, 0.019845, 0.61834, 0.29321]
Predicted label: 5
Correct prediction
Energy consumption = 142.360128 pJ
sum error= 322
Actual label: 3
Output voltages: [0.26281, 0.034309, 0.063342, 0.79862, 0.012489, 0.015311, 0.008536, 0.03596, 0.37588, 0.053698]
Predicted label: 3
Correct prediction
Energy consumption = 138.165546 pJ
sum error= 322
Actual label: 3
Output voltages: [0.12469, 0.022194, 0.042033, 0.79864, 0.036541, 0.021697, 0.017977, 0.016138, 0.61468, 0.16287]
Predicted label: 3
Correct prediction
Energy consumption = 134.799861 pJ
sum error= 322
Actual label: 5
Output voltages: [0.033738, 0.0010769, 0.0030494, 0.64687, 0.023582, 0.79732, 0.14813, 0.051774, 0.75554, 0.34912]
Predicted label: 5
Correct prediction
Energy consumption = 144.348539 pJ
sum error= 322
Actual label: 7
Output voltages: [0.24069, 0.13444, 0.48764, 0.26959, 0.001663, 0.0010842, 0.0050859, 0.79878, 0.30133, 0.29095]
Predicted label: 7
Correct prediction
Energy consumption = 162.032274 pJ
sum error= 322
Actual label: 2
Output voltages: [0.58384, 0.024022, 0.79878, 0.10643, 0.033589, 0.0011078, 0.065239, 0.070255, 0.54645, 0.005545]
Predicted label: 2
Correct prediction
Energy consumption = 144.052430 pJ
sum error= 322
Actual label: 5
Output voltages: [0.33152, 0.0010679, 0.004638, 0.28934, 0.0017144, 0.79847, 0.063709, 0.36137, 0.77057, 0.028224]
Predicted label: 5
Correct prediction
Energy consumption = 149.400278 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 768 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 768 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 768 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.27335, 0.0063076, 0.029579, 0.026254, 0.33854, 0.001478, 0.024689, 0.0061007, 0.28021, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 175.134674 pJ
sum error= 322
Actual label: 6
Output voltages: [0.040236, 0.14851, 0.23645, 0.0055722, 0.29775, 0.33578, 0.7986, 0.0050284, 0.41926, 0.017962]
Predicted label: 6
Correct prediction
Energy consumption = 148.832614 pJ
sum error= 322
Actual label: 9
Output voltages: [0.17461, 0.0088622, 0.0084849, 0.013393, 0.076983, 0.0050083, 0.0015184, 0.0073648, 0.55287, 0.79843]
Predicted label: 9
Correct prediction
Energy consumption = 158.785549 pJ
sum error= 322
Actual label: 2
Output voltages: [0.76129, 0.0015819, 0.79338, 0.53159, 0.0047374, 0.0010925, 0.0066224, 0.032313, 0.71279, 0.0077264]
Predicted label: 2
Correct prediction
Energy consumption = 147.986315 pJ
sum error= 322
Actual label: 6
Output voltages: [0.13275, 0.029989, 0.35123, 0.0017196, 0.3085, 0.22787, 0.79872, 0.0023456, 0.57038, 0.005951]
Predicted label: 6
Correct prediction
Energy consumption = 144.680653 pJ
sum error= 322
Actual label: 2
Output voltages: [0.69727, 0.082405, 0.79872, 0.039377, 0.023975, 0.0011667, 0.0473, 0.048287, 0.27999, 0.027062]
Predicted label: 2
Correct prediction
Energy consumption = 150.581442 pJ
sum error= 322
Actual label: 1
Output voltages: [0.029467, 0.79847, 0.091071, 0.2307, 0.14399, 0.015511, 0.31485, 0.0020557, 0.36411, 0.21128]
Predicted label: 1
Correct prediction
Energy consumption = 158.296164 pJ
sum error= 322
Actual label: 2
Output voltages: [0.54812, 0.0056865, 0.79876, 0.22223, 0.0039442, 0.0010686, 0.35957, 0.22779, 0.41455, 0.003482]
Predicted label: 2
Correct prediction
Energy consumption = 149.836492 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79877, 0.02255, 0.024803, 0.0058636, 0.011574, 0.02904, 0.5694, 0.006615, 0.028431, 0.032646]
Predicted label: 0
Correct prediction
Energy consumption = 154.135354 pJ
sum error= 322
Actual label: 8
Output voltages: [0.34744, 0.051052, 0.035669, 0.74489, 0.0012086, 0.003147, 0.029453, 0.039856, 0.79457, 0.052956]
Predicted label: 8
Correct prediction
Energy consumption = 159.938068 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 769 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 769 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 769 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.20078, 0.023446, 0.12612, 0.7986, 0.031654, 0.011342, 0.018177, 0.049361, 0.40871, 0.10958]
Predicted label: 3
Correct prediction
Energy consumption = 163.945622 pJ
sum error= 322
Actual label: 8
Output voltages: [0.001508, 0.52643, 0.013707, 0.090083, 0.29169, 0.014183, 0.075785, 0.0067487, 0.78946, 0.14522]
Predicted label: 8
Correct prediction
Energy consumption = 157.998232 pJ
sum error= 322
Actual label: 3
Output voltages: [0.22441, 0.025891, 0.047479, 0.79866, 0.025246, 0.010337, 0.025824, 0.03384, 0.67328, 0.17344]
Predicted label: 3
Correct prediction
Energy consumption = 149.995872 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79865, 0.043434, 0.015118, 0.0074348, 0.051681, 0.017405, 0.60543, 0.0082744, 0.028817, 0.17266]
Predicted label: 0
Correct prediction
Energy consumption = 159.943110 pJ
sum error= 322
Actual label: 8
Output voltages: [0.025664, 0.0037341, 0.55481, 0.041254, 0.0014278, 0.67462, 0.10572, 0.0016506, 0.7984, 0.039919]
Predicted label: 8
Correct prediction
Energy consumption = 156.693385 pJ
sum error= 322
Actual label: 7
Output voltages: [0.19078, 0.024514, 0.23638, 0.24227, 0.0057533, 0.0013865, 0.0010733, 0.79864, 0.050882, 0.16103]
Predicted label: 7
Correct prediction
Energy consumption = 154.559056 pJ
sum error= 322
Actual label: 4
Output voltages: [0.012121, 0.0045296, 0.38927, 0.0080466, 0.79863, 0.0057432, 0.2274, 0.049196, 0.025271, 0.040517]
Predicted label: 4
Correct prediction
Energy consumption = 158.604346 pJ
sum error= 322
Actual label: 9
Output voltages: [0.43663, 0.039809, 0.0085992, 0.057876, 0.45177, 0.0012359, 0.0019959, 0.02713, 0.028052, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 154.553340 pJ
sum error= 322
Actual label: 5
Output voltages: [0.040596, 0.0014328, 0.0016602, 0.64039, 0.0049146, 0.79744, 0.057315, 0.19212, 0.58008, 0.073147]
Predicted label: 5
Correct prediction
Energy consumption = 149.711885 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79875, 0.094457, 0.029418, 0.015093, 0.012763, 0.011586, 0.40117, 0.017559, 0.053647, 0.035293]
Predicted label: 0
Correct prediction
Energy consumption = 149.225225 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 770 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 770 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 770 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.28791, 0.040625, 0.020751, 0.055837, 0.1344, 0.04602, 0.015327, 0.019569, 0.29263, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 167.682842 pJ
sum error= 322
Actual label: 7
Output voltages: [0.67419, 0.005284, 0.47854, 0.037616, 0.011645, 0.0010673, 0.0010988, 0.79866, 0.28126, 0.02228]
Predicted label: 7
Correct prediction
Energy consumption = 150.098535 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79874, 0.06391, 0.031983, 0.011833, 0.018812, 0.0015916, 0.74847, 0.02584, 0.2271, 0.11878]
Predicted label: 0
Correct prediction
Energy consumption = 151.241680 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79879, 0.21876, 0.097896, 0.044768, 0.024146, 0.010957, 0.51604, 0.020518, 0.1144, 0.25003]
Predicted label: 0
Correct prediction
Energy consumption = 146.011357 pJ
sum error= 322
Actual label: 4
Output voltages: [0.0022666, 0.022447, 0.38379, 0.011356, 0.79876, 0.0010822, 0.037162, 0.24331, 0.021141, 0.31366]
Predicted label: 4
Correct prediction
Energy consumption = 161.030302 pJ
sum error= 322
Actual label: 6
Output voltages: [0.099807, 0.11866, 0.052766, 0.018307, 0.42987, 0.31749, 0.79875, 0.0012741, 0.27153, 0.026563]
Predicted label: 6
Correct prediction
Energy consumption = 147.723340 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79879, 0.058368, 0.050452, 0.044847, 0.0090606, 0.044999, 0.74509, 0.041582, 0.23634, 0.041063]
Predicted label: 0
Correct prediction
Energy consumption = 157.655266 pJ
sum error= 322
Actual label: 9
Output voltages: [0.18227, 0.012831, 0.025781, 0.026334, 0.09401, 0.013657, 0.0068748, 0.067842, 0.41485, 0.79773]
Predicted label: 9
Correct prediction
Energy consumption = 149.264937 pJ
sum error= 322
Actual label: 1
Output voltages: [0.032519, 0.79858, 0.030148, 0.0045676, 0.23125, 0.0083238, 0.67507, 0.0070434, 0.30662, 0.047117]
Predicted label: 1
Correct prediction
Energy consumption = 158.096869 pJ
sum error= 322
Actual label: 6
Output voltages: [0.06236, 0.12714, 0.19627, 0.002337, 0.10462, 0.038954, 0.79879, 0.0011169, 0.49635, 0.0059202]
Predicted label: 6
Correct prediction
Energy consumption = 139.660672 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 771 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 771 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 771 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.35813, 0.0053566, 0.79878, 0.044844, 0.0090978, 0.0011141, 0.049699, 0.042266, 0.47529, 0.0062085]
Predicted label: 2
Correct prediction
Energy consumption = 165.491150 pJ
sum error= 322
Actual label: 7
Output voltages: [0.68785, 0.10838, 0.0060249, 0.082076, 0.01366, 0.091147, 0.0010759, 0.79875, 0.050073, 0.24211]
Predicted label: 7
Correct prediction
Energy consumption = 153.304022 pJ
sum error= 322
Actual label: 6
Output voltages: [0.34917, 0.04263, 0.34431, 0.0072096, 0.091011, 0.040715, 0.79869, 0.0012809, 0.68565, 0.037018]
Predicted label: 6
Correct prediction
Energy consumption = 142.452373 pJ
sum error= 322
Actual label: 8
Output voltages: [0.1462, 0.011357, 0.056622, 0.058775, 0.0013711, 0.74687, 0.14331, 0.0021544, 0.79879, 0.0020118]
Predicted label: 8
Correct prediction
Energy consumption = 155.187433 pJ
sum error= 322
Actual label: 3
Output voltages: [0.010867, 0.0086558, 0.26617, 0.79879, 0.032924, 0.022109, 0.0062113, 0.0073, 0.75382, 0.03281]
Predicted label: 3
Correct prediction
Energy consumption = 141.054088 pJ
sum error= 322
Actual label: 5
Output voltages: [0.038497, 0.0015951, 0.0068585, 0.3216, 0.0034545, 0.79866, 0.027348, 0.24325, 0.73664, 0.37008]
Predicted label: 5
Correct prediction
Energy consumption = 145.230344 pJ
sum error= 322
Actual label: 2
Output voltages: [0.50422, 0.0099578, 0.79879, 0.08551, 0.031536, 0.0012, 0.044432, 0.027482, 0.42925, 0.023916]
Predicted label: 2
Correct prediction
Energy consumption = 152.685114 pJ
sum error= 322
Actual label: 1
Output voltages: [0.010759, 0.79848, 0.0062298, 0.15694, 0.0054474, 0.01677, 0.72669, 0.019792, 0.52795, 0.017662]
Predicted label: 1
Correct prediction
Energy consumption = 162.561426 pJ
sum error= 322
Actual label: 8
Output voltages: [0.04577, 0.01493, 0.39928, 0.005558, 0.046964, 0.0018597, 0.024267, 0.0023502, 0.79879, 0.1887]
Predicted label: 8
Correct prediction
Energy consumption = 147.123993 pJ
sum error= 322
Actual label: 3
Output voltages: [0.18547, 0.024323, 0.053469, 0.79861, 0.038665, 0.015927, 0.025988, 0.025069, 0.56237, 0.26242]
Predicted label: 3
Correct prediction
Energy consumption = 139.978516 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 772 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 772 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 772 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.60418, 0.01647, 0.045076, 0.33253, 0.012884, 0.66488, 0.22611, 0.0019207, 0.79879, 0.044151]
Predicted label: 8
Correct prediction
Energy consumption = 173.021966 pJ
sum error= 322
Actual label: 6
Output voltages: [0.095737, 0.057585, 0.21164, 0.0015718, 0.25548, 0.42295, 0.79868, 0.0085619, 0.25658, 0.025331]
Predicted label: 6
Correct prediction
Energy consumption = 143.034093 pJ
sum error= 322
Actual label: 1
Output voltages: [0.002868, 0.7986, 0.10487, 0.012227, 0.0077739, 0.0014986, 0.53122, 0.0045372, 0.44176, 0.016006]
Predicted label: 1
Correct prediction
Energy consumption = 166.933083 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79877, 0.16007, 0.060052, 0.0069904, 0.016205, 0.005508, 0.34316, 0.005928, 0.06107, 0.10305]
Predicted label: 0
Correct prediction
Energy consumption = 150.351392 pJ
sum error= 322
Actual label: 2
Output voltages: [0.35149, 0.024941, 0.7987, 0.28699, 0.010462, 0.0011508, 0.29026, 0.022004, 0.46724, 0.020112]
Predicted label: 2
Correct prediction
Energy consumption = 150.905817 pJ
sum error= 322
Actual label: 1
Output voltages: [0.2179, 0.79853, 0.069975, 0.062354, 0.26206, 0.0049373, 0.1589, 0.0060509, 0.090941, 0.10597]
Predicted label: 1
Correct prediction
Energy consumption = 161.313386 pJ
sum error= 322
Actual label: 4
Output voltages: [0.0021261, 0.0026215, 0.39596, 0.016672, 0.79854, 0.0015559, 0.21713, 0.024853, 0.024599, 0.039902]
Predicted label: 4
Correct prediction
Energy consumption = 154.470385 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79873, 0.11783, 0.0167, 0.017485, 0.02878, 0.051461, 0.7422, 0.011519, 0.19845, 0.0018686]
Predicted label: 0
Correct prediction
Energy consumption = 156.398301 pJ
sum error= 322
Actual label: 1
Output voltages: [0.0018429, 0.79873, 0.049899, 0.18894, 0.04291, 0.0010715, 0.46063, 0.010889, 0.6146, 0.13356]
Predicted label: 1
Correct prediction
Energy consumption = 161.899295 pJ
sum error= 322
Actual label: 2
Output voltages: [0.36999, 0.018251, 0.79878, 0.030985, 0.016227, 0.0011703, 0.10541, 0.10198, 0.60324, 0.027235]
Predicted label: 2
Correct prediction
Energy consumption = 142.490994 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 773 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 773 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 773 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.4681, 0.0085246, 0.74087, 0.7986, 0.0020259, 0.0011623, 0.0073856, 0.0017884, 0.48819, 0.020839]
Predicted label: 3
Correct prediction
Energy consumption = 167.092043 pJ
sum error= 322
Actual label: 4
Output voltages: [0.010111, 0.021494, 0.04479, 0.0017655, 0.79873, 0.0087537, 0.11509, 0.58428, 0.1095, 0.011611]
Predicted label: 4
Correct prediction
Energy consumption = 147.228030 pJ
sum error= 322
Actual label: 5
Output voltages: [0.0076781, 0.00113, 0.021083, 0.1173, 0.006107, 0.76163, 0.17682, 0.0018906, 0.79438, 0.013221]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.457687 pJ
sum error= 323
Actual label: 6
Output voltages: [0.35728, 0.078848, 0.084669, 0.0032557, 0.24729, 0.086321, 0.79879, 0.0010704, 0.37615, 0.0096738]
Predicted label: 6
Correct prediction
Energy consumption = 143.524779 pJ
sum error= 323
Actual label: 7
Output voltages: [0.019299, 0.14455, 0.45553, 0.052634, 0.0013239, 0.012616, 0.0011829, 0.79867, 0.41761, 0.050272]
Predicted label: 7
Correct prediction
Energy consumption = 160.658601 pJ
sum error= 323
Actual label: 8
Output voltages: [0.25916, 0.015651, 0.14094, 0.34392, 0.0021692, 0.029843, 0.0066895, 0.0011334, 0.79879, 0.259]
Predicted label: 8
Correct prediction
Energy consumption = 154.349103 pJ
sum error= 323
Actual label: 9
Output voltages: [0.61301, 0.0074985, 0.66812, 0.017657, 0.3816, 0.0010676, 0.0011073, 0.16043, 0.61568, 0.70708]
Predicted label: 9
Correct prediction
Energy consumption = 149.830782 pJ
sum error= 323
Actual label: 0
Output voltages: [0.79878, 0.065189, 0.053285, 0.012804, 0.022112, 0.0029398, 0.60166, 0.0063344, 0.073326, 0.035046]
Predicted label: 0
Correct prediction
Energy consumption = 145.205173 pJ
sum error= 323
Actual label: 1
Output voltages: [0.013204, 0.79872, 0.0069135, 0.031951, 0.52514, 0.0014052, 0.12703, 0.0010748, 0.53367, 0.055253]
Predicted label: 1
Correct prediction
Energy consumption = 156.562172 pJ
sum error= 323
Actual label: 2
Output voltages: [0.51076, 0.0015095, 0.79865, 0.61288, 0.0059487, 0.0012068, 0.0096581, 0.055566, 0.47791, 0.013266]
Predicted label: 2
Correct prediction
Energy consumption = 150.028239 pJ
sum error= 323
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 774 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 774 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 774 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.39218, 0.010455, 0.14546, 0.7987, 0.017648, 0.0037788, 0.015496, 0.004525, 0.59404, 0.03038]
Predicted label: 3
Correct prediction
Energy consumption = 164.679466 pJ
sum error= 323
Actual label: 4
Output voltages: [0.0060058, 0.021577, 0.19504, 0.011597, 0.79869, 0.012321, 0.047391, 0.14759, 0.057883, 0.0088285]
Predicted label: 4
Correct prediction
Energy consumption = 148.277020 pJ
sum error= 323
Actual label: 5
Output voltages: [0.043401, 0.0012791, 0.0023967, 0.12111, 0.042435, 0.79847, 0.12675, 0.018834, 0.78629, 0.013766]
Predicted label: 5
Correct prediction
Energy consumption = 149.960219 pJ
sum error= 323
Actual label: 6
Output voltages: [0.0087066, 0.017367, 0.41999, 0.0015058, 0.32367, 0.47699, 0.79878, 0.0034955, 0.25278, 0.0014482]
Predicted label: 6
Correct prediction
Energy consumption = 143.453170 pJ
sum error= 323
Actual label: 7
Output voltages: [0.41046, 0.069446, 0.70354, 0.046384, 0.026302, 0.0011581, 0.0010893, 0.79876, 0.026025, 0.032208]
Predicted label: 7
Correct prediction
Energy consumption = 156.842142 pJ
sum error= 323
Actual label: 8
Output voltages: [0.03111, 0.043884, 0.49674, 0.037805, 0.010003, 0.016677, 0.032437, 0.0026019, 0.79879, 0.22499]
Predicted label: 8
Correct prediction
Energy consumption = 151.594341 pJ
sum error= 323
Actual label: 9
Output voltages: [0.50409, 0.0012306, 0.034768, 0.14143, 0.054914, 0.0011101, 0.0010664, 0.028803, 0.74857, 0.76502]
Predicted label: 9
Correct prediction
Energy consumption = 149.928647 pJ
sum error= 323
Actual label: 0
Output voltages: [0.79878, 0.025779, 0.044972, 0.012077, 0.024033, 0.0099668, 0.72524, 0.021, 0.084395, 0.33159]
Predicted label: 0
Correct prediction
Energy consumption = 138.406824 pJ
sum error= 323
Actual label: 1
Output voltages: [0.040827, 0.79871, 0.035924, 0.030921, 0.27182, 0.001163, 0.023362, 0.0011242, 0.46838, 0.24126]
Predicted label: 1
Correct prediction
Energy consumption = 157.144503 pJ
sum error= 323
Actual label: 2
Output voltages: [0.33054, 0.0020917, 0.78568, 0.63981, 0.03656, 0.0011591, 0.023233, 0.024339, 0.76947, 0.044765]
Predicted label: 2
Correct prediction
Energy consumption = 144.587991 pJ
sum error= 323
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 775 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 775 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 775 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34806, 0.022593, 0.048398, 0.79867, 0.0064543, 0.023444, 0.0082656, 0.017727, 0.51019, 0.021622]
Predicted label: 3
Correct prediction
Energy consumption = 159.607978 pJ
sum error= 323
Actual label: 4
Output voltages: [0.012598, 0.016229, 0.11621, 0.0051961, 0.79878, 0.022058, 0.08735, 0.09167, 0.25891, 0.002763]
Predicted label: 4
Correct prediction
Energy consumption = 146.939103 pJ
sum error= 323
Actual label: 5
Output voltages: [0.052867, 0.0011445, 0.0011871, 0.29625, 0.026574, 0.79751, 0.1576, 0.043743, 0.77349, 0.045478]
Predicted label: 5
Correct prediction
Energy consumption = 148.097275 pJ
sum error= 323
Actual label: 6
Output voltages: [0.13712, 0.017753, 0.12421, 0.017982, 0.3539, 0.56342, 0.79878, 0.001083, 0.56918, 0.051982]
Predicted label: 6
Correct prediction
Energy consumption = 145.594248 pJ
sum error= 323
Actual label: 7
Output voltages: [0.14175, 0.039591, 0.066315, 0.031819, 0.0101, 0.0088472, 0.0010723, 0.79855, 0.036841, 0.36514]
Predicted label: 7
Correct prediction
Energy consumption = 153.648811 pJ
sum error= 323
Actual label: 8
Output voltages: [0.046146, 0.036797, 0.59339, 0.033233, 0.025071, 0.0011722, 0.027994, 0.0019179, 0.79879, 0.051559]
Predicted label: 8
Correct prediction
Energy consumption = 151.398825 pJ
sum error= 323
Actual label: 9
Output voltages: [0.12229, 0.003263, 0.04359, 0.01734, 0.036159, 0.0018891, 0.0038746, 0.023038, 0.75766, 0.77819]
Predicted label: 9
Correct prediction
Energy consumption = 156.056161 pJ
sum error= 323
Actual label: 7
Output voltages: [0.095265, 0.25041, 0.44137, 0.068116, 0.0052722, 0.0011346, 0.0010761, 0.79879, 0.069185, 0.069134]
Predicted label: 7
Correct prediction
Energy consumption = 153.925904 pJ
sum error= 323
Actual label: 6
Output voltages: [0.039719, 0.29743, 0.24995, 0.0054274, 0.19017, 0.086444, 0.79869, 0.0013891, 0.31112, 0.017553]
Predicted label: 6
Correct prediction
Energy consumption = 151.567436 pJ
sum error= 323
Actual label: 4
Output voltages: [0.0013056, 0.012565, 0.020212, 0.033668, 0.79878, 0.001431, 0.21255, 0.27206, 0.043552, 0.0023771]
Predicted label: 4
Correct prediction
Energy consumption = 146.313754 pJ
sum error= 323
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 776 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 776 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 776 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25028, 0.012788, 0.030661, 0.16544, 0.0057728, 0.00365, 0.0012086, 0.79872, 0.39162, 0.42187]
Predicted label: 7
Correct prediction
Energy consumption = 173.046195 pJ
sum error= 323
Actual label: 6
Output voltages: [0.081532, 0.097417, 0.26176, 0.0035473, 0.2275, 0.21739, 0.79872, 0.0015483, 0.43805, 0.0046107]
Predicted label: 6
Correct prediction
Energy consumption = 150.692671 pJ
sum error= 323
Actual label: 2
Output voltages: [0.29374, 0.026079, 0.79868, 0.030674, 0.0060154, 0.0011661, 0.043267, 0.057027, 0.65569, 0.012749]
Predicted label: 2
Correct prediction
Energy consumption = 141.850409 pJ
sum error= 323
Actual label: 3
Output voltages: [0.2153, 0.043571, 0.012488, 0.79859, 0.0033646, 0.012556, 0.019006, 0.03027, 0.32286, 0.10285]
Predicted label: 3
Correct prediction
Energy consumption = 145.234951 pJ
sum error= 323
Actual label: 4
Output voltages: [0.012445, 0.011198, 0.03312, 0.020505, 0.79864, 0.0013877, 0.062835, 0.10789, 0.054193, 0.0042494]
Predicted label: 4
Correct prediction
Energy consumption = 149.976245 pJ
sum error= 323
Actual label: 8
Output voltages: [0.0071524, 0.040596, 0.10505, 0.18953, 0.01549, 0.017483, 0.019193, 0.011286, 0.79876, 0.35278]
Predicted label: 8
Correct prediction
Energy consumption = 152.235085 pJ
sum error= 323
Actual label: 7
Output voltages: [0.52589, 0.027642, 0.031641, 0.059715, 0.0015088, 0.004738, 0.0011054, 0.7987, 0.31736, 0.053846]
Predicted label: 7
Correct prediction
Energy consumption = 149.275279 pJ
sum error= 323
Actual label: 8
Output voltages: [0.034309, 0.051442, 0.2894, 0.12504, 0.017632, 0.011913, 0.033784, 0.0046275, 0.79871, 0.041172]
Predicted label: 8
Correct prediction
Energy consumption = 144.912353 pJ
sum error= 323
Actual label: 6
Output voltages: [0.023211, 0.032454, 0.24901, 0.013789, 0.032894, 0.52112, 0.79871, 0.0081505, 0.29003, 0.003224]
Predicted label: 6
Correct prediction
Energy consumption = 153.909904 pJ
sum error= 323
Actual label: 9
Output voltages: [0.044794, 0.017925, 0.035074, 0.039433, 0.015406, 0.0089022, 0.004546, 0.042634, 0.71925, 0.79263]
Predicted label: 9
Correct prediction
Energy consumption = 150.358330 pJ
sum error= 323
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 777 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 777 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 777 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.26605, 0.023661, 0.19783, 0.3374, 0.006453, 0.0095708, 0.018004, 0.0019191, 0.79878, 0.10236]
Predicted label: 8
Correct prediction
Energy consumption = 167.207462 pJ
sum error= 323
Actual label: 3
Output voltages: [0.62089, 0.013218, 0.020488, 0.79869, 0.0079571, 0.041565, 0.0025302, 0.013536, 0.55899, 0.020664]
Predicted label: 3
Correct prediction
Energy consumption = 146.460446 pJ
sum error= 323
Actual label: 2
Output voltages: [0.52594, 0.0058977, 0.79879, 0.10119, 0.0032926, 0.0010666, 0.016031, 0.040027, 0.70428, 0.0016609]
Predicted label: 2
Correct prediction
Energy consumption = 139.309524 pJ
sum error= 323
Actual label: 2
Output voltages: [0.60746, 0.048632, 0.79874, 0.065374, 0.016148, 0.0012272, 0.082442, 0.045463, 0.45322, 0.01174]
Predicted label: 2
Correct prediction
Energy consumption = 139.464574 pJ
sum error= 323
Actual label: 8
Output voltages: [0.0076375, 0.020327, 0.02454, 0.011649, 0.091478, 0.013376, 0.26398, 0.024644, 0.79876, 0.045045]
Predicted label: 8
Correct prediction
Energy consumption = 144.530804 pJ
sum error= 323
Actual label: 4
Output voltages: [0.0077915, 0.01749, 0.028265, 0.014201, 0.79869, 0.0013035, 0.13542, 0.18724, 0.034426, 0.019577]
Predicted label: 4
Correct prediction
Energy consumption = 147.862343 pJ
sum error= 323
Actual label: 8
Output voltages: [0.021967, 0.01153, 0.040043, 0.17222, 0.0067299, 0.14821, 0.041581, 0.0043664, 0.79864, 0.010209]
Predicted label: 8
Correct prediction
Energy consumption = 150.204015 pJ
sum error= 323
Actual label: 5
Output voltages: [0.05134, 0.0010929, 0.0025055, 0.20106, 0.017131, 0.79879, 0.2145, 0.015601, 0.76533, 0.036548]
Predicted label: 5
Correct prediction
Energy consumption = 141.867856 pJ
sum error= 323
Actual label: 6
Output voltages: [0.14748, 0.033477, 0.24373, 0.0012841, 0.43974, 0.30264, 0.79876, 0.0019941, 0.18645, 0.010942]
Predicted label: 6
Correct prediction
Energy consumption = 143.174737 pJ
sum error= 323
Actual label: 5
Output voltages: [0.13602, 0.0011207, 0.036401, 0.26914, 0.015539, 0.78986, 0.4774, 0.0022041, 0.7755, 0.0019241]
Predicted label: 5
Correct prediction
Energy consumption = 135.709980 pJ
sum error= 323
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 778 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 778 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 778 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.073152, 0.024359, 0.013775, 0.011976, 0.02392, 0.64672, 0.031315, 0.058327, 0.017215]
Predicted label: 0
Correct prediction
Energy consumption = 167.173083 pJ
sum error= 323
Actual label: 2
Output voltages: [0.46179, 0.0028246, 0.79879, 0.5049, 0.0084077, 0.0012488, 0.0082982, 0.14143, 0.34381, 0.017328]
Predicted label: 2
Correct prediction
Energy consumption = 151.110728 pJ
sum error= 323
Actual label: 0
Output voltages: [0.79879, 0.085312, 0.026001, 0.015165, 0.0043993, 0.014034, 0.59134, 0.051173, 0.17702, 0.022891]
Predicted label: 0
Correct prediction
Energy consumption = 143.155405 pJ
sum error= 323
Actual label: 1
Output voltages: [0.086758, 0.79879, 0.37839, 0.54343, 0.0047648, 0.0012238, 0.1995, 0.001066, 0.43785, 0.41181]
Predicted label: 1
Correct prediction
Energy consumption = 156.316364 pJ
sum error= 323
Actual label: 1
Output voltages: [0.08908, 0.79869, 0.19103, 0.031623, 0.16907, 0.0013055, 0.10287, 0.0043675, 0.29784, 0.052421]
Predicted label: 1
Correct prediction
Energy consumption = 150.358304 pJ
sum error= 323
Actual label: 2
Output voltages: [0.51024, 0.0049788, 0.79876, 0.16637, 0.014929, 0.0011846, 0.015491, 0.23543, 0.64155, 0.0055118]
Predicted label: 2
Correct prediction
Energy consumption = 148.155983 pJ
sum error= 323
Actual label: 9
Output voltages: [0.1549, 0.0087136, 0.017803, 0.046465, 0.014737, 0.025916, 0.0049801, 0.41502, 0.60655, 0.79108]
Predicted label: 9
Correct prediction
Energy consumption = 152.582559 pJ
sum error= 323
Actual label: 6
Output voltages: [0.24218, 0.029268, 0.095765, 0.014331, 0.31565, 0.15024, 0.79879, 0.001066, 0.614, 0.013477]
Predicted label: 6
Correct prediction
Energy consumption = 149.451984 pJ
sum error= 323
Actual label: 8
Output voltages: [0.30031, 0.024199, 0.69389, 0.10143, 0.067192, 0.001091, 0.14673, 0.0011339, 0.79369, 0.10544]
Predicted label: 8
Correct prediction
Energy consumption = 152.629306 pJ
sum error= 323
Actual label: 2
Output voltages: [0.49032, 0.16058, 0.79876, 0.03088, 0.0059954, 0.0012761, 0.034058, 0.040332, 0.33488, 0.014059]
Predicted label: 2
Correct prediction
Energy consumption = 142.518841 pJ
sum error= 323
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 779 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 779 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 779 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.014999, 0.79839, 0.2155, 0.75855, 0.024799, 0.0011353, 0.31986, 0.0018713, 0.70872, 0.14891]
Predicted label: 1
Correct prediction
Energy consumption = 178.607667 pJ
sum error= 323
Actual label: 0
Output voltages: [0.79538, 0.018598, 0.045683, 0.0045977, 0.020556, 0.0059632, 0.72078, 0.029486, 0.02499, 0.3197]
Predicted label: 0
Correct prediction
Energy consumption = 143.775979 pJ
sum error= 323
Actual label: 6
Output voltages: [0.16807, 0.041895, 0.32216, 0.0017079, 0.40411, 0.21562, 0.79869, 0.0018427, 0.40539, 0.024754]
Predicted label: 6
Correct prediction
Energy consumption = 140.860964 pJ
sum error= 323
Actual label: 5
Output voltages: [0.034566, 0.0010742, 0.0033993, 0.24999, 0.017687, 0.79866, 0.14094, 0.011137, 0.79202, 0.00883]
Predicted label: 5
Correct prediction
Energy consumption = 143.245925 pJ
sum error= 323
Actual label: 2
Output voltages: [0.48007, 0.0059261, 0.79879, 0.043094, 0.016513, 0.0010762, 0.048762, 0.029293, 0.73002, 0.037094]
Predicted label: 2
Correct prediction
Energy consumption = 145.933053 pJ
sum error= 323
Actual label: 9
Output voltages: [0.51869, 0.027858, 0.020774, 0.19171, 0.26787, 0.085233, 0.013649, 0.03587, 0.23155, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 157.209402 pJ
sum error= 323
Actual label: 7
Output voltages: [0.060944, 0.14598, 0.091978, 0.036517, 0.01285, 0.0067909, 0.0010851, 0.79864, 0.11932, 0.5188]
Predicted label: 7
Correct prediction
Energy consumption = 147.838214 pJ
sum error= 323
Actual label: 5
Output voltages: [0.0095058, 0.0011762, 0.0068486, 0.042533, 0.028224, 0.79818, 0.62264, 0.015973, 0.75914, 0.0063992]
Predicted label: 5
Correct prediction
Energy consumption = 143.346092 pJ
sum error= 323
Actual label: 3
Output voltages: [0.48159, 0.0025682, 0.32476, 0.79879, 0.025778, 0.051204, 0.0042541, 0.0064587, 0.59994, 0.041709]
Predicted label: 3
Correct prediction
Energy consumption = 142.115889 pJ
sum error= 323
Actual label: 9
Output voltages: [0.089526, 0.019889, 0.01431, 0.044729, 0.0378, 0.0047841, 0.0016197, 0.017365, 0.71004, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 144.054996 pJ
sum error= 323
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 780 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 780 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 780 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.78589, 0.001578, 0.45759, 0.79877, 0.02475, 0.08688, 0.017717, 0.011402, 0.45619, 0.016708]
Predicted label: 3
Correct prediction
Energy consumption = 164.731326 pJ
sum error= 323
Actual label: 7
Output voltages: [0.12798, 0.019136, 0.040767, 0.082473, 0.0084008, 0.023773, 0.001136, 0.79849, 0.06714, 0.2147]
Predicted label: 7
Correct prediction
Energy consumption = 154.335028 pJ
sum error= 323
Actual label: 1
Output voltages: [0.02661, 0.79877, 0.037297, 0.038661, 0.33006, 0.0011268, 0.14471, 0.0010678, 0.35019, 0.38597]
Predicted label: 1
Correct prediction
Energy consumption = 161.533754 pJ
sum error= 323
Actual label: 8
Output voltages: [0.046455, 0.043102, 0.12238, 0.20136, 0.0061817, 0.037968, 0.01312, 0.0016519, 0.79865, 0.13781]
Predicted label: 8
Correct prediction
Energy consumption = 146.061995 pJ
sum error= 323
Actual label: 3
Output voltages: [0.73078, 0.0043607, 0.11544, 0.79877, 0.016974, 0.014502, 0.0069866, 0.0058575, 0.6215, 0.047512]
Predicted label: 3
Correct prediction
Energy consumption = 146.873758 pJ
sum error= 323
Actual label: 8
Output voltages: [0.030183, 0.034951, 0.22647, 0.024528, 0.02347, 0.021732, 0.19902, 0.011533, 0.79869, 0.04749]
Predicted label: 8
Correct prediction
Energy consumption = 142.870906 pJ
sum error= 323
Actual label: 1
Output voltages: [0.029952, 0.79876, 0.0079203, 0.016653, 0.049901, 0.0010668, 0.26065, 0.0017646, 0.52409, 0.28126]
Predicted label: 1
Correct prediction
Energy consumption = 152.197741 pJ
sum error= 323
Actual label: 9
Output voltages: [0.4299, 0.021477, 0.060294, 0.069932, 0.013881, 0.0029574, 0.0044692, 0.04904, 0.73587, 0.79793]
Predicted label: 9
Correct prediction
Energy consumption = 151.621996 pJ
sum error= 323
Actual label: 5
Output voltages: [0.0060081, 0.0011093, 0.0021369, 0.23219, 0.024012, 0.79751, 0.29519, 0.0050028, 0.70665, 0.037419]
Predicted label: 5
Correct prediction
Energy consumption = 139.355496 pJ
sum error= 323
Actual label: 5
Output voltages: [0.026219, 0.0011542, 0.0096365, 0.060051, 0.014403, 0.79428, 0.2745, 0.010379, 0.79159, 0.019373]
Predicted label: 5
Correct prediction
Energy consumption = 130.163210 pJ
sum error= 323
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 781 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 781 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 781 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.033806, 0.031015, 0.01428, 0.033201, 0.0069855, 0.71183, 0.012986, 0.065433, 0.059049]
Predicted label: 0
Correct prediction
Energy consumption = 168.793182 pJ
sum error= 323
Actual label: 1
Output voltages: [0.0075489, 0.79875, 0.0051028, 0.20271, 0.15029, 0.0010729, 0.25274, 0.0011878, 0.73712, 0.25049]
Predicted label: 1
Correct prediction
Energy consumption = 160.154800 pJ
sum error= 323
Actual label: 1
Output voltages: [0.044003, 0.79775, 0.015037, 0.21247, 0.015918, 0.0029299, 0.053389, 0.003347, 0.78473, 0.046878]
Predicted label: 1
Correct prediction
Energy consumption = 151.836754 pJ
sum error= 323
Actual label: 9
Output voltages: [0.2055, 0.0023017, 0.030355, 0.015438, 0.041825, 0.0073505, 0.0022886, 0.038663, 0.75618, 0.79821]
Predicted label: 9
Correct prediction
Energy consumption = 145.796174 pJ
sum error= 323
Actual label: 8
Output voltages: [0.055453, 0.043005, 0.14585, 0.041469, 0.0077352, 0.03704, 0.0043131, 0.0011077, 0.79878, 0.32257]
Predicted label: 8
Correct prediction
Energy consumption = 143.508616 pJ
sum error= 323
Actual label: 2
Output voltages: [0.40943, 0.0028528, 0.79879, 0.061082, 0.017431, 0.0010984, 0.10896, 0.19001, 0.69107, 0.0024788]
Predicted label: 2
Correct prediction
Energy consumption = 150.803052 pJ
sum error= 323
Actual label: 6
Output voltages: [0.028142, 0.051786, 0.23129, 0.0025881, 0.14213, 0.25472, 0.79877, 0.001747, 0.69457, 0.0019798]
Predicted label: 6
Correct prediction
Energy consumption = 145.426085 pJ
sum error= 323
Actual label: 0
Output voltages: [0.79865, 0.027482, 0.15133, 0.01638, 0.01128, 0.032159, 0.27867, 0.046176, 0.10345, 0.018167]
Predicted label: 0
Correct prediction
Energy consumption = 140.205745 pJ
sum error= 323
Actual label: 4
Output voltages: [0.0024651, 0.0081192, 0.027566, 0.0018578, 0.79869, 0.014462, 0.44957, 0.43411, 0.22466, 0.016853]
Predicted label: 4
Correct prediction
Energy consumption = 149.400785 pJ
sum error= 323
Actual label: 5
Output voltages: [0.13166, 0.0010664, 0.0037161, 0.15984, 0.0023696, 0.79869, 0.15817, 0.0023814, 0.77753, 0.0011316]
Predicted label: 5
Correct prediction
Energy consumption = 141.936600 pJ
sum error= 323
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 782 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 782 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 782 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.010025, 0.10444, 0.0079969, 0.025334, 0.0059436, 0.64642, 0.048155, 0.035339, 0.24336]
Predicted label: 0
Correct prediction
Energy consumption = 161.333066 pJ
sum error= 323
Actual label: 3
Output voltages: [0.49731, 0.0043648, 0.67467, 0.79872, 0.02482, 0.032806, 0.012814, 0.0020338, 0.77033, 0.02305]
Predicted label: 3
Correct prediction
Energy consumption = 142.341898 pJ
sum error= 323
Actual label: 1
Output voltages: [0.15345, 0.79877, 0.013961, 0.029687, 0.10295, 0.0016591, 0.42953, 0.0011691, 0.33926, 0.12063]
Predicted label: 1
Correct prediction
Energy consumption = 156.308486 pJ
sum error= 323
Actual label: 8
Output voltages: [0.049576, 0.001765, 0.18845, 0.41467, 0.017033, 0.022977, 0.069539, 0.015537, 0.79878, 0.27424]
Predicted label: 8
Correct prediction
Energy consumption = 148.056955 pJ
sum error= 323
Actual label: 6
Output voltages: [0.095837, 0.014186, 0.24357, 0.019816, 0.30106, 0.52386, 0.79878, 0.0011277, 0.66658, 0.10583]
Predicted label: 6
Correct prediction
Energy consumption = 140.176016 pJ
sum error= 323
Actual label: 7
Output voltages: [0.59025, 0.038478, 0.42941, 0.099869, 0.010083, 0.0012461, 0.001833, 0.79863, 0.5879, 0.02224]
Predicted label: 7
Correct prediction
Energy consumption = 156.247269 pJ
sum error= 323
Actual label: 5
Output voltages: [0.052789, 0.0011885, 0.0030218, 0.35638, 0.029346, 0.79878, 0.23681, 0.052596, 0.77708, 0.0013681]
Predicted label: 5
Correct prediction
Energy consumption = 134.987834 pJ
sum error= 323
Actual label: 9
Output voltages: [0.20945, 0.02049, 0.028536, 0.033163, 0.085162, 0.014429, 0.0062819, 0.02618, 0.56682, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 150.187056 pJ
sum error= 323
Actual label: 9
Output voltages: [0.23567, 0.023544, 0.032696, 0.034957, 0.050177, 0.02994, 0.0039332, 0.010487, 0.30814, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 142.314940 pJ
sum error= 323
Actual label: 3
Output voltages: [0.37998, 0.013538, 0.10184, 0.79866, 0.036435, 0.0039568, 0.012227, 0.012831, 0.47563, 0.10255]
Predicted label: 3
Correct prediction
Energy consumption = 141.325869 pJ
sum error= 323
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 783 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 783 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 783 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.034119, 0.014776, 0.0079889, 0.0034632, 0.0022528, 0.68487, 0.024149, 0.31696, 0.045506]
Predicted label: 0
Correct prediction
Energy consumption = 161.877244 pJ
sum error= 323
Actual label: 3
Output voltages: [0.64108, 0.0015513, 0.29319, 0.79879, 0.0065244, 0.0045633, 0.0082906, 0.01327, 0.44078, 0.044009]
Predicted label: 3
Correct prediction
Energy consumption = 150.238535 pJ
sum error= 323
Actual label: 1
Output voltages: [0.02171, 0.79874, 0.38779, 0.014035, 0.1766, 0.0010792, 0.24429, 0.0047281, 0.042606, 0.020872]
Predicted label: 1
Correct prediction
Energy consumption = 154.456074 pJ
sum error= 323
Actual label: 4
Output voltages: [0.010182, 0.016272, 0.0082572, 0.029374, 0.79877, 0.0010674, 0.033531, 0.16566, 0.10965, 0.0038204]
Predicted label: 4
Correct prediction
Energy consumption = 149.857767 pJ
sum error= 323
Actual label: 4
Output voltages: [0.0018099, 0.0070637, 0.032418, 0.022786, 0.79869, 0.0014259, 0.07476, 0.21731, 0.10681, 0.0033268]
Predicted label: 4
Correct prediction
Energy consumption = 135.579610 pJ
sum error= 323
Actual label: 0
Output voltages: [0.79879, 0.044696, 0.014328, 0.011219, 0.013792, 0.011248, 0.547, 0.025005, 0.23988, 0.036747]
Predicted label: 0
Correct prediction
Energy consumption = 149.696393 pJ
sum error= 323
Actual label: 4
Output voltages: [0.012053, 0.013304, 0.025369, 0.00267, 0.79878, 0.0011833, 0.28747, 0.24269, 0.037855, 0.0033648]
Predicted label: 4
Correct prediction
Energy consumption = 152.267371 pJ
sum error= 323
Actual label: 9
Output voltages: [0.19366, 0.018101, 0.057344, 0.0085158, 0.043431, 0.0178, 0.0011269, 0.029033, 0.73875, 0.78259]
Predicted label: 9
Correct prediction
Energy consumption = 152.457578 pJ
sum error= 323
Actual label: 0
Output voltages: [0.79878, 0.051374, 0.02341, 0.014436, 0.01581, 0.0024384, 0.71887, 0.023373, 0.14976, 0.12516]
Predicted label: 0
Correct prediction
Energy consumption = 148.714952 pJ
sum error= 323
Actual label: 1
Output voltages: [0.29082, 0.79556, 0.021677, 0.26153, 0.19153, 0.0010735, 0.40661, 0.0011238, 0.55165, 0.073789]
Predicted label: 1
Correct prediction
Energy consumption = 155.219023 pJ
sum error= 323
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 784 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 784 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 784 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.35695, 0.020509, 0.79866, 0.026007, 0.017384, 0.0010748, 0.038887, 0.14157, 0.38202, 0.01138]
Predicted label: 2
Correct prediction
Energy consumption = 161.518578 pJ
sum error= 323
Actual label: 3
Output voltages: [0.089124, 0.017568, 0.038997, 0.79874, 0.037435, 0.045479, 0.010128, 0.012409, 0.76065, 0.14087]
Predicted label: 3
Correct prediction
Energy consumption = 152.669787 pJ
sum error= 323
Actual label: 5
Output voltages: [0.42798, 0.0014932, 0.014895, 0.41453, 0.017703, 0.35967, 0.44902, 0.0032209, 0.78736, 0.0011338]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.317643 pJ
sum error= 324
Actual label: 6
Output voltages: [0.12052, 0.032785, 0.074406, 0.0021905, 0.26076, 0.18566, 0.79877, 0.0016518, 0.50887, 0.0040148]
Predicted label: 6
Correct prediction
Energy consumption = 142.751621 pJ
sum error= 324
Actual label: 7
Output voltages: [0.30608, 0.14639, 0.0059353, 0.003049, 0.0031825, 0.0089715, 0.0033809, 0.79875, 0.52704, 0.012882]
Predicted label: 7
Correct prediction
Energy consumption = 152.320766 pJ
sum error= 324
Actual label: 8
Output voltages: [0.21607, 0.00724, 0.26888, 0.038393, 0.010552, 0.016661, 0.10077, 0.0021508, 0.79879, 0.025896]
Predicted label: 8
Correct prediction
Energy consumption = 148.938407 pJ
sum error= 324
Actual label: 0
Output voltages: [0.79762, 0.041872, 0.41397, 0.0052505, 0.002697, 0.0014637, 0.18924, 0.0030487, 0.54063, 0.03144]
Predicted label: 0
Correct prediction
Energy consumption = 136.005549 pJ
sum error= 324
Actual label: 1
Output voltages: [0.10569, 0.64459, 0.046638, 0.24739, 0.75923, 0.0052533, 0.2401, 0.001086, 0.30989, 0.0065756]
Predicted label: 4
Wrong prediction!
Energy consumption = 148.971924 pJ
sum error= 325
Actual label: 2
Output voltages: [0.055597, 0.0017122, 0.79872, 0.050666, 0.1275, 0.0011008, 0.029424, 0.028334, 0.60433, 0.027876]
Predicted label: 2
Correct prediction
Energy consumption = 137.931640 pJ
sum error= 325
Actual label: 3
Output voltages: [0.28318, 0.001066, 0.74228, 0.72386, 0.25557, 0.013432, 0.092516, 0.0011028, 0.35419, 0.055987]
Predicted label: 2
Wrong prediction!
Energy consumption = 135.529027 pJ
sum error= 326
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 785 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 785 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 785 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.4922, 0.0011275, 0.0088451, 0.22265, 0.0049011, 0.79706, 0.43417, 0.0043553, 0.76584, 0.0011535]
Predicted label: 5
Correct prediction
Energy consumption = 160.173887 pJ
sum error= 326
Actual label: 6
Output voltages: [0.06552, 0.042422, 0.57137, 0.0016721, 0.24323, 0.019725, 0.79876, 0.0011119, 0.55513, 0.025914]
Predicted label: 6
Correct prediction
Energy consumption = 143.207997 pJ
sum error= 326
Actual label: 7
Output voltages: [0.28715, 0.12663, 0.040261, 0.073744, 0.0017481, 0.0010945, 0.001066, 0.79868, 0.22858, 0.043581]
Predicted label: 7
Correct prediction
Energy consumption = 156.864284 pJ
sum error= 326
Actual label: 8
Output voltages: [0.64944, 0.039341, 0.57641, 0.021457, 0.012523, 0.0011406, 0.53372, 0.0034747, 0.78672, 0.011939]
Predicted label: 8
Correct prediction
Energy consumption = 148.021151 pJ
sum error= 326
Actual label: 9
Output voltages: [0.71679, 0.021134, 0.014702, 0.28033, 0.071626, 0.0036558, 0.0042028, 0.014527, 0.05555, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 149.564154 pJ
sum error= 326
Actual label: 0
Output voltages: [0.79872, 0.27629, 0.039655, 0.022004, 0.0064757, 0.0067466, 0.19402, 0.011187, 0.1125, 0.14502]
Predicted label: 0
Correct prediction
Energy consumption = 144.762185 pJ
sum error= 326
Actual label: 1
Output voltages: [0.021953, 0.78443, 0.072678, 0.0017404, 0.73433, 0.0017799, 0.20655, 0.0030852, 0.29967, 0.21388]
Predicted label: 1
Correct prediction
Energy consumption = 148.986523 pJ
sum error= 326
Actual label: 2
Output voltages: [0.029008, 0.013775, 0.79879, 0.17155, 0.017709, 0.0011301, 0.061557, 0.013966, 0.77158, 0.038688]
Predicted label: 2
Correct prediction
Energy consumption = 133.500543 pJ
sum error= 326
Actual label: 3
Output voltages: [0.54633, 0.0014098, 0.60972, 0.79878, 0.024783, 0.032526, 0.013774, 0.0012873, 0.6306, 0.027287]
Predicted label: 3
Correct prediction
Energy consumption = 145.261791 pJ
sum error= 326
Actual label: 5
Output voltages: [0.10523, 0.0016608, 0.0013169, 0.37311, 0.014447, 0.79879, 0.26075, 0.0043166, 0.75782, 0.0033082]
Predicted label: 5
Correct prediction
Energy consumption = 130.364143 pJ
sum error= 326
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 786 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 786 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 786 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.13319, 0.0051224, 0.058199, 0.0016786, 0.24722, 0.046774, 0.79827, 0.001066, 0.56799, 0.0023857]
Predicted label: 6
Correct prediction
Energy consumption = 161.535918 pJ
sum error= 326
Actual label: 7
Output voltages: [0.35439, 0.051602, 0.016439, 0.027235, 0.025867, 0.00163, 0.0011619, 0.79875, 0.1353, 0.036134]
Predicted label: 7
Correct prediction
Energy consumption = 153.237813 pJ
sum error= 326
Actual label: 8
Output voltages: [0.22198, 0.066295, 0.30759, 0.16939, 0.0030697, 0.011837, 0.4624, 0.0020713, 0.79875, 0.043149]
Predicted label: 8
Correct prediction
Energy consumption = 149.155321 pJ
sum error= 326
Actual label: 9
Output voltages: [0.15485, 0.012941, 0.013329, 0.012714, 0.20796, 0.005162, 0.0012031, 0.017143, 0.49835, 0.79775]
Predicted label: 9
Correct prediction
Energy consumption = 143.702591 pJ
sum error= 326
Actual label: 9
Output voltages: [0.25771, 0.0047739, 0.012208, 0.051377, 0.3395, 0.048256, 0.056344, 0.054268, 0.097932, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 151.406040 pJ
sum error= 326
Actual label: 7
Output voltages: [0.24272, 0.02971, 0.066371, 0.03524, 0.0044206, 0.0068916, 0.0012049, 0.79872, 0.67052, 0.37443]
Predicted label: 7
Correct prediction
Energy consumption = 154.175983 pJ
sum error= 326
Actual label: 0
Output voltages: [0.79876, 0.029777, 0.053229, 0.0084526, 0.025499, 0.0028378, 0.65728, 0.04277, 0.10339, 0.26665]
Predicted label: 0
Correct prediction
Energy consumption = 142.344903 pJ
sum error= 326
Actual label: 9
Output voltages: [0.28935, 0.0032347, 0.031519, 0.18304, 0.45085, 0.017797, 0.010095, 0.052043, 0.5567, 0.79714]
Predicted label: 9
Correct prediction
Energy consumption = 147.376526 pJ
sum error= 326
Actual label: 0
Output voltages: [0.79877, 0.021587, 0.02887, 0.017797, 0.032028, 0.013437, 0.19653, 0.089263, 0.45117, 0.026412]
Predicted label: 0
Correct prediction
Energy consumption = 146.812297 pJ
sum error= 326
Actual label: 1
Output voltages: [0.025213, 0.79033, 0.00225, 0.015203, 0.50405, 0.0014528, 0.062419, 0.0010865, 0.56687, 0.16687]
Predicted label: 1
Correct prediction
Energy consumption = 147.591590 pJ
sum error= 326
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 787 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 787 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 787 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.033088, 0.0011157, 0.0010812, 0.2599, 0.064902, 0.7985, 0.16086, 0.037262, 0.38486, 0.018116]
Predicted label: 5
Correct prediction
Energy consumption = 155.666494 pJ
sum error= 326
Actual label: 8
Output voltages: [0.044377, 0.0069259, 0.31101, 0.070996, 0.010294, 0.038014, 0.044141, 0.014768, 0.7987, 0.042149]
Predicted label: 8
Correct prediction
Energy consumption = 146.026466 pJ
sum error= 326
Actual label: 8
Output voltages: [0.26824, 0.047407, 0.037138, 0.15621, 0.0044978, 0.043733, 0.047358, 0.0013551, 0.79879, 0.047935]
Predicted label: 8
Correct prediction
Energy consumption = 146.641373 pJ
sum error= 326
Actual label: 0
Output voltages: [0.79879, 0.20447, 0.043366, 0.018797, 0.0060305, 0.01001, 0.50285, 0.030517, 0.22985, 0.043252]
Predicted label: 0
Correct prediction
Energy consumption = 140.238156 pJ
sum error= 326
Actual label: 9
Output voltages: [0.65599, 0.021837, 0.017077, 0.031158, 0.048769, 0.024878, 0.050563, 0.011444, 0.48844, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 141.632207 pJ
sum error= 326
Actual label: 3
Output voltages: [0.25586, 0.014374, 0.070001, 0.79879, 0.029803, 0.023993, 0.0042392, 0.0010894, 0.39495, 0.1905]
Predicted label: 3
Correct prediction
Energy consumption = 137.936399 pJ
sum error= 326
Actual label: 2
Output voltages: [0.19041, 0.0033613, 0.79876, 0.03477, 0.5344, 0.0010719, 0.039647, 0.0018736, 0.58482, 0.23486]
Predicted label: 2
Correct prediction
Energy consumption = 133.222850 pJ
sum error= 326
Actual label: 7
Output voltages: [0.16655, 0.03417, 0.56587, 0.0031783, 0.10683, 0.0010924, 0.0011595, 0.79879, 0.46426, 0.05368]
Predicted label: 7
Correct prediction
Energy consumption = 153.314681 pJ
sum error= 326
Actual label: 8
Output voltages: [0.15103, 0.025851, 0.64796, 0.11408, 0.010117, 0.024471, 0.030245, 0.014313, 0.79874, 0.043751]
Predicted label: 8
Correct prediction
Energy consumption = 141.710665 pJ
sum error= 326
Actual label: 4
Output voltages: [0.013447, 0.13835, 0.033233, 0.0063384, 0.79876, 0.014792, 0.054945, 0.52377, 0.03734, 0.010392]
Predicted label: 4
Correct prediction
Energy consumption = 144.639566 pJ
sum error= 326
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 788 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 788 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 788 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.020181, 0.017277, 0.49376, 0.0010679, 0.39556, 0.041773, 0.79878, 0.0013809, 0.44643, 0.0025379]
Predicted label: 6
Correct prediction
Energy consumption = 162.740879 pJ
sum error= 326
Actual label: 1
Output voltages: [0.026426, 0.79868, 0.15901, 0.0060472, 0.098183, 0.0012513, 0.17602, 0.0012783, 0.058219, 0.035549]
Predicted label: 1
Correct prediction
Energy consumption = 149.984390 pJ
sum error= 326
Actual label: 0
Output voltages: [0.79876, 0.058387, 0.045313, 0.015366, 0.017723, 0.0082503, 0.47829, 0.009063, 0.070396, 0.22581]
Predicted label: 0
Correct prediction
Energy consumption = 145.435777 pJ
sum error= 326
Actual label: 4
Output voltages: [0.0051429, 0.0051453, 0.54744, 0.029939, 0.79865, 0.0021587, 0.46813, 0.13518, 0.012287, 0.019858]
Predicted label: 4
Correct prediction
Energy consumption = 149.618706 pJ
sum error= 326
Actual label: 9
Output voltages: [0.083214, 0.0050769, 0.042253, 0.023258, 0.21744, 0.0097834, 0.0042938, 0.045477, 0.56907, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 147.874107 pJ
sum error= 326
Actual label: 4
Output voltages: [0.039971, 0.0021475, 0.43926, 0.0032634, 0.79875, 0.0010751, 0.69991, 0.32714, 0.035768, 0.016633]
Predicted label: 4
Correct prediction
Energy consumption = 143.470118 pJ
sum error= 326
Actual label: 2
Output voltages: [0.04215, 0.001679, 0.79879, 0.020067, 0.62413, 0.0010931, 0.049735, 0.0046049, 0.50076, 0.18617]
Predicted label: 2
Correct prediction
Energy consumption = 135.396485 pJ
sum error= 326
Actual label: 0
Output voltages: [0.79879, 0.11222, 0.049468, 0.01191, 0.020549, 0.0025591, 0.53699, 0.011223, 0.073058, 0.16933]
Predicted label: 0
Correct prediction
Energy consumption = 143.432990 pJ
sum error= 326
Actual label: 5
Output voltages: [0.0059211, 0.0011216, 0.0010664, 0.070184, 0.39356, 0.79694, 0.4691, 0.0021561, 0.42305, 0.041612]
Predicted label: 5
Correct prediction
Energy consumption = 130.855210 pJ
sum error= 326
Actual label: 0
Output voltages: [0.79878, 0.072419, 0.025365, 0.018968, 0.032392, 0.018476, 0.47435, 0.031314, 0.12056, 0.05145]
Predicted label: 0
Correct prediction
Energy consumption = 139.457433 pJ
sum error= 326
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 789 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 789 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 789 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.039483, 0.79873, 0.15441, 0.012118, 0.053559, 0.0010881, 0.21559, 0.0015992, 0.2338, 0.028115]
Predicted label: 1
Correct prediction
Energy consumption = 176.659961 pJ
sum error= 326
Actual label: 6
Output voltages: [0.047162, 0.046304, 0.1918, 0.0040161, 0.14074, 0.053746, 0.79879, 0.0010817, 0.62264, 0.0031997]
Predicted label: 6
Correct prediction
Energy consumption = 144.328673 pJ
sum error= 326
Actual label: 9
Output voltages: [0.19954, 0.0045246, 0.018331, 0.0089997, 0.10573, 0.0057891, 0.0030533, 0.016277, 0.68511, 0.79753]
Predicted label: 9
Correct prediction
Energy consumption = 152.505570 pJ
sum error= 326
Actual label: 3
Output voltages: [0.71555, 0.0011102, 0.52142, 0.79504, 0.049552, 0.0043591, 0.0020724, 0.039624, 0.67002, 0.01523]
Predicted label: 3
Correct prediction
Energy consumption = 152.575331 pJ
sum error= 326
Actual label: 2
Output voltages: [0.61258, 0.0011028, 0.79703, 0.15341, 0.089747, 0.0010662, 0.01828, 0.033376, 0.77597, 0.022089]
Predicted label: 2
Correct prediction
Energy consumption = 131.507293 pJ
sum error= 326
Actual label: 9
Output voltages: [0.40841, 0.0060519, 0.032962, 0.073647, 0.34098, 0.0029516, 0.013145, 0.0028092, 0.37081, 0.79773]
Predicted label: 9
Correct prediction
Energy consumption = 155.898767 pJ
sum error= 326
Actual label: 1
Output voltages: [0.053975, 0.79858, 0.011024, 0.058578, 0.47901, 0.0010817, 0.22135, 0.0011121, 0.26988, 0.1685]
Predicted label: 1
Correct prediction
Energy consumption = 156.996628 pJ
sum error= 326
Actual label: 6
Output voltages: [0.32483, 0.048705, 0.22068, 0.0021047, 0.26697, 0.048351, 0.79877, 0.0010826, 0.4466, 0.025234]
Predicted label: 6
Correct prediction
Energy consumption = 151.139668 pJ
sum error= 326
Actual label: 0
Output voltages: [0.79636, 0.031789, 0.016826, 0.0059243, 0.0023975, 0.068773, 0.76776, 0.0029934, 0.074297, 0.0994]
Predicted label: 0
Correct prediction
Energy consumption = 141.649769 pJ
sum error= 326
Actual label: 1
Output voltages: [0.070794, 0.79607, 0.001986, 0.27515, 0.24772, 0.0014215, 0.29441, 0.00209, 0.74927, 0.056123]
Predicted label: 1
Correct prediction
Energy consumption = 152.520453 pJ
sum error= 326
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 790 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 790 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 790 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.030245, 0.79878, 0.19773, 0.010684, 0.12984, 0.0011194, 0.72937, 0.0015444, 0.091933, 0.027237]
Predicted label: 1
Correct prediction
Energy consumption = 169.595066 pJ
sum error= 326
Actual label: 8
Output voltages: [0.17028, 0.023839, 0.088522, 0.032294, 0.057678, 0.015906, 0.56144, 0.0011373, 0.79877, 0.047585]
Predicted label: 8
Correct prediction
Energy consumption = 145.563122 pJ
sum error= 326
Actual label: 7
Output voltages: [0.07846, 0.0060436, 0.023761, 0.057565, 0.010328, 0.0059854, 0.0011078, 0.77539, 0.78551, 0.59164]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.373428 pJ
sum error= 327
Actual label: 7
Output voltages: [0.20792, 0.16368, 0.58842, 0.047685, 0.0060989, 0.0011048, 0.0016388, 0.79874, 0.60342, 0.0054842]
Predicted label: 7
Correct prediction
Energy consumption = 136.030296 pJ
sum error= 327
Actual label: 6
Output voltages: [0.42432, 0.017892, 0.12316, 0.0014032, 0.4865, 0.022588, 0.79879, 0.0010922, 0.64321, 0.018273]
Predicted label: 6
Correct prediction
Energy consumption = 142.420404 pJ
sum error= 327
Actual label: 3
Output voltages: [0.30226, 0.0065157, 0.472, 0.79775, 0.0062388, 0.016915, 0.018337, 0.0010661, 0.45416, 0.33972]
Predicted label: 3
Correct prediction
Energy consumption = 148.191285 pJ
sum error= 327
Actual label: 6
Output voltages: [0.11235, 0.012968, 0.19338, 0.0010749, 0.57789, 0.050383, 0.79879, 0.0010866, 0.15687, 0.0027356]
Predicted label: 6
Correct prediction
Energy consumption = 143.413158 pJ
sum error= 327
Actual label: 0
Output voltages: [0.79875, 0.038035, 0.0079822, 0.023841, 0.034127, 0.0065668, 0.329, 0.026009, 0.27583, 0.043541]
Predicted label: 0
Correct prediction
Energy consumption = 139.214996 pJ
sum error= 327
Actual label: 7
Output voltages: [0.2326, 0.031902, 0.15051, 0.0023141, 0.031977, 0.004053, 0.0010887, 0.79852, 0.52945, 0.14947]
Predicted label: 7
Correct prediction
Energy consumption = 151.993637 pJ
sum error= 327
Actual label: 2
Output voltages: [0.14154, 0.11587, 0.79879, 0.047982, 0.24135, 0.001185, 0.060208, 0.42654, 0.11441, 0.025785]
Predicted label: 2
Correct prediction
Energy consumption = 141.526746 pJ
sum error= 327
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 791 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 791 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 791 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.086959, 0.0041118, 0.23771, 0.0030146, 0.79868, 0.0012223, 0.17394, 0.018537, 0.020521, 0.020977]
Predicted label: 4
Correct prediction
Energy consumption = 165.547178 pJ
sum error= 327
Actual label: 1
Output voltages: [0.024461, 0.79868, 0.024844, 0.013399, 0.33861, 0.0010659, 0.43892, 0.0023423, 0.059316, 0.076926]
Predicted label: 1
Correct prediction
Energy consumption = 148.950521 pJ
sum error= 327
Actual label: 7
Output voltages: [0.11686, 0.018936, 0.061999, 0.039634, 0.035594, 0.0015221, 0.0012354, 0.79877, 0.74722, 0.075379]
Predicted label: 7
Correct prediction
Energy consumption = 155.802286 pJ
sum error= 327
Actual label: 0
Output voltages: [0.79879, 0.088978, 0.05927, 0.025563, 0.032354, 0.0019372, 0.62881, 0.010557, 0.18236, 0.207]
Predicted label: 0
Correct prediction
Energy consumption = 147.913765 pJ
sum error= 327
Actual label: 6
Output voltages: [0.11694, 0.041387, 0.52798, 0.00114, 0.19155, 0.10209, 0.79879, 0.0017354, 0.62841, 0.011403]
Predicted label: 6
Correct prediction
Energy consumption = 141.562976 pJ
sum error= 327
Actual label: 7
Output voltages: [0.035893, 0.31389, 0.006416, 0.0017513, 0.021908, 0.0023899, 0.0011696, 0.66065, 0.79805, 0.18568]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.842862 pJ
sum error= 328
Actual label: 1
Output voltages: [0.011802, 0.79875, 0.1031, 0.37299, 0.55344, 0.001571, 0.18487, 0.0033586, 0.47291, 0.064918]
Predicted label: 1
Correct prediction
Energy consumption = 143.459309 pJ
sum error= 328
Actual label: 2
Output voltages: [0.16577, 0.0059857, 0.79879, 0.043753, 0.38581, 0.0011172, 0.039309, 0.0017113, 0.50374, 0.31771]
Predicted label: 2
Correct prediction
Energy consumption = 138.705897 pJ
sum error= 328
Actual label: 5
Output voltages: [0.36008, 0.029336, 0.002681, 0.11905, 0.037537, 0.7924, 0.77034, 0.0010697, 0.428, 0.0019056]
Predicted label: 5
Correct prediction
Energy consumption = 134.636964 pJ
sum error= 328
Actual label: 8
Output voltages: [0.39449, 0.0061289, 0.58421, 0.032002, 0.048081, 0.010658, 0.012053, 0.0058982, 0.79879, 0.039568]
Predicted label: 8
Correct prediction
Energy consumption = 138.904291 pJ
sum error= 328
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 792 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 792 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 792 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.033828, 0.79852, 0.17396, 0.11806, 0.28408, 0.0011099, 0.37319, 0.0010859, 0.54604, 0.39612]
Predicted label: 1
Correct prediction
Energy consumption = 170.771202 pJ
sum error= 328
Actual label: 8
Output voltages: [0.1318, 0.0012056, 0.35478, 0.53262, 0.0034485, 0.23143, 0.021692, 0.0089067, 0.79877, 0.0179]
Predicted label: 8
Correct prediction
Energy consumption = 136.906675 pJ
sum error= 328
Actual label: 2
Output voltages: [0.36622, 0.014024, 0.79875, 0.077875, 0.21339, 0.00107, 0.079585, 0.089231, 0.17071, 0.012672]
Predicted label: 2
Correct prediction
Energy consumption = 137.168419 pJ
sum error= 328
Actual label: 8
Output voltages: [0.15414, 0.017723, 0.4556, 0.022307, 0.049411, 0.0079562, 0.033781, 0.002201, 0.79872, 0.04544]
Predicted label: 8
Correct prediction
Energy consumption = 141.939291 pJ
sum error= 328
Actual label: 7
Output voltages: [0.21107, 0.051684, 0.0097028, 0.17616, 0.0051837, 0.0067749, 0.0011104, 0.79697, 0.63988, 0.1067]
Predicted label: 7
Correct prediction
Energy consumption = 148.577952 pJ
sum error= 328
Actual label: 6
Output voltages: [0.074189, 0.01924, 0.31544, 0.0010931, 0.40684, 0.040963, 0.79878, 0.0012727, 0.46024, 0.001466]
Predicted label: 6
Correct prediction
Energy consumption = 142.626520 pJ
sum error= 328
Actual label: 8
Output voltages: [0.35814, 0.0094132, 0.69951, 0.032453, 0.019959, 0.0021322, 0.050904, 0.0017492, 0.79874, 0.15029]
Predicted label: 8
Correct prediction
Energy consumption = 142.219427 pJ
sum error= 328
Actual label: 7
Output voltages: [0.16709, 0.024909, 0.092308, 0.010093, 0.042748, 0.0011155, 0.0011564, 0.79861, 0.23392, 0.56712]
Predicted label: 7
Correct prediction
Energy consumption = 148.924904 pJ
sum error= 328
Actual label: 1
Output voltages: [0.12991, 0.67317, 0.0025687, 0.052153, 0.1305, 0.0013698, 0.44433, 0.0010859, 0.7205, 0.097115]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.544656 pJ
sum error= 329
Actual label: 6
Output voltages: [0.05088, 0.021541, 0.39542, 0.001066, 0.18679, 0.056617, 0.79879, 0.0015942, 0.53365, 0.0020475]
Predicted label: 6
Correct prediction
Energy consumption = 142.283486 pJ
sum error= 329
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 793 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 793 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 793 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.067756, 0.0046513, 0.7987, 0.046356, 0.20753, 0.001067, 0.028895, 0.013172, 0.709, 0.023349]
Predicted label: 2
Correct prediction
Energy consumption = 155.781136 pJ
sum error= 329
Actual label: 9
Output voltages: [0.18601, 0.025007, 0.046817, 0.036148, 0.021165, 0.0092802, 0.0039645, 0.020939, 0.71967, 0.79721]
Predicted label: 9
Correct prediction
Energy consumption = 151.697707 pJ
sum error= 329
Actual label: 3
Output voltages: [0.51619, 0.0013896, 0.74465, 0.79857, 0.024327, 0.0046038, 0.0047846, 0.010683, 0.72645, 0.01125]
Predicted label: 3
Correct prediction
Energy consumption = 145.597336 pJ
sum error= 329
Actual label: 0
Output voltages: [0.79858, 0.067838, 0.2129, 0.01197, 0.0020656, 0.0014207, 0.34149, 0.023974, 0.17704, 0.11593]
Predicted label: 0
Correct prediction
Energy consumption = 144.404882 pJ
sum error= 329
Actual label: 1
Output voltages: [0.029293, 0.79876, 0.024263, 0.14489, 0.028183, 0.0011049, 0.32574, 0.0011113, 0.53933, 0.36403]
Predicted label: 1
Correct prediction
Energy consumption = 158.154890 pJ
sum error= 329
Actual label: 2
Output voltages: [0.31513, 0.017385, 0.79878, 0.40488, 0.014716, 0.0010792, 0.013586, 0.34969, 0.53543, 0.014716]
Predicted label: 2
Correct prediction
Energy consumption = 151.757316 pJ
sum error= 329
Actual label: 3
Output voltages: [0.30208, 0.039293, 0.039676, 0.79868, 0.016799, 0.00161, 0.016936, 0.011508, 0.43571, 0.040488]
Predicted label: 3
Correct prediction
Energy consumption = 140.126814 pJ
sum error= 329
Actual label: 4
Output voltages: [0.047689, 0.0028785, 0.01395, 0.0060122, 0.79876, 0.0011521, 0.18218, 0.0087975, 0.06186, 0.0019204]
Predicted label: 4
Correct prediction
Energy consumption = 151.674942 pJ
sum error= 329
Actual label: 5
Output voltages: [0.21417, 0.0011375, 0.006801, 0.36037, 0.10409, 0.79859, 0.38734, 0.017093, 0.786, 0.022057]
Predicted label: 5
Correct prediction
Energy consumption = 145.565739 pJ
sum error= 329
Actual label: 6
Output voltages: [0.20852, 0.022653, 0.26702, 0.0051195, 0.27023, 0.28816, 0.79875, 0.0014814, 0.32398, 0.0055995]
Predicted label: 6
Correct prediction
Energy consumption = 140.201051 pJ
sum error= 329
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 794 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 794 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 794 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.34211, 0.028312, 0.11484, 0.12649, 0.0043102, 0.0011544, 0.0011247, 0.79859, 0.26098, 0.13416]
Predicted label: 7
Correct prediction
Energy consumption = 172.455338 pJ
sum error= 329
Actual label: 8
Output voltages: [0.13205, 0.035826, 0.51555, 0.032775, 0.030256, 0.0021961, 0.045017, 0.0033586, 0.79879, 0.080374]
Predicted label: 8
Correct prediction
Energy consumption = 146.443559 pJ
sum error= 329
Actual label: 9
Output voltages: [0.078507, 0.0042492, 0.0081621, 0.037652, 0.097417, 0.0028027, 0.0013526, 0.022913, 0.6364, 0.79686]
Predicted label: 9
Correct prediction
Energy consumption = 143.920869 pJ
sum error= 329
Actual label: 0
Output voltages: [0.79849, 0.030067, 0.19141, 0.01327, 0.0010676, 0.026762, 0.61268, 0.02184, 0.3848, 0.0043407]
Predicted label: 0
Correct prediction
Energy consumption = 143.688474 pJ
sum error= 329
Actual label: 1
Output voltages: [0.031746, 0.79865, 0.10485, 0.026874, 0.11104, 0.0017589, 0.43646, 0.0073278, 0.28543, 0.013458]
Predicted label: 1
Correct prediction
Energy consumption = 160.147230 pJ
sum error= 329
Actual label: 2
Output voltages: [0.75774, 0.0091301, 0.78442, 0.76468, 0.023155, 0.001066, 0.020518, 0.015876, 0.037185, 0.010368]
Predicted label: 2
Correct prediction
Energy consumption = 149.903068 pJ
sum error= 329
Actual label: 3
Output voltages: [0.19659, 0.0026707, 0.39428, 0.79866, 0.031737, 0.0027241, 0.033181, 0.0010812, 0.77985, 0.051875]
Predicted label: 3
Correct prediction
Energy consumption = 141.165827 pJ
sum error= 329
Actual label: 4
Output voltages: [0.023508, 0.10569, 0.043237, 0.024544, 0.79878, 0.0013477, 0.29198, 0.24745, 0.018037, 0.02785]
Predicted label: 4
Correct prediction
Energy consumption = 153.628522 pJ
sum error= 329
Actual label: 5
Output voltages: [0.023039, 0.0010786, 0.010259, 0.039541, 0.0059244, 0.7986, 0.29716, 0.010868, 0.78066, 0.0036831]
Predicted label: 5
Correct prediction
Energy consumption = 153.033366 pJ
sum error= 329
Actual label: 6
Output voltages: [0.14854, 0.13747, 0.1236, 0.010152, 0.37396, 0.29695, 0.79872, 0.0012387, 0.36534, 0.019651]
Predicted label: 6
Correct prediction
Energy consumption = 144.974168 pJ
sum error= 329
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 795 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 795 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 795 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.51485, 0.030662, 0.46333, 0.11632, 0.0018517, 0.0012708, 0.0011348, 0.79835, 0.50316, 0.0052138]
Predicted label: 7
Correct prediction
Energy consumption = 172.239182 pJ
sum error= 329
Actual label: 8
Output voltages: [0.026261, 0.19651, 0.13298, 0.016385, 0.023065, 0.0017908, 0.023848, 0.0041978, 0.79879, 0.66736]
Predicted label: 8
Correct prediction
Energy consumption = 144.613824 pJ
sum error= 329
Actual label: 9
Output voltages: [0.40234, 0.0026276, 0.024589, 0.014265, 0.16041, 0.0030773, 0.0010665, 0.031255, 0.50088, 0.79731]
Predicted label: 9
Correct prediction
Energy consumption = 147.765761 pJ
sum error= 329
Actual label: 0
Output voltages: [0.79879, 0.14349, 0.049788, 0.017631, 0.0051639, 0.003718, 0.51863, 0.0088617, 0.056445, 0.12348]
Predicted label: 0
Correct prediction
Energy consumption = 147.931953 pJ
sum error= 329
Actual label: 1
Output voltages: [0.026362, 0.79878, 0.01168, 0.025165, 0.37078, 0.0010941, 0.12166, 0.0011617, 0.43189, 0.3431]
Predicted label: 1
Correct prediction
Energy consumption = 156.719632 pJ
sum error= 329
Actual label: 2
Output voltages: [0.57354, 0.0033031, 0.79869, 0.064899, 0.017512, 0.0010682, 0.0076059, 0.10466, 0.52114, 0.0091082]
Predicted label: 2
Correct prediction
Energy consumption = 144.970936 pJ
sum error= 329
Actual label: 3
Output voltages: [0.26614, 0.010103, 0.085174, 0.79872, 0.078278, 0.003286, 0.032154, 0.0083973, 0.74081, 0.045265]
Predicted label: 3
Correct prediction
Energy consumption = 142.591560 pJ
sum error= 329
Actual label: 4
Output voltages: [0.0010751, 0.012859, 0.019335, 0.019593, 0.79879, 0.009348, 0.32696, 0.14534, 0.22702, 0.0021071]
Predicted label: 4
Correct prediction
Energy consumption = 145.175143 pJ
sum error= 329
Actual label: 5
Output voltages: [0.020078, 0.001204, 0.0042413, 0.36332, 0.041259, 0.79848, 0.17947, 0.064542, 0.76757, 0.029332]
Predicted label: 5
Correct prediction
Energy consumption = 145.543998 pJ
sum error= 329
Actual label: 6
Output voltages: [0.049329, 0.15574, 0.48357, 0.015133, 0.18643, 0.087583, 0.79873, 0.0010947, 0.57133, 0.03914]
Predicted label: 6
Correct prediction
Energy consumption = 142.216531 pJ
sum error= 329
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 796 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 796 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 796 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.024816, 0.057037, 0.76969, 0.013887, 0.0028732, 0.0010742, 0.001577, 0.79866, 0.44684, 0.39262]
Predicted label: 7
Correct prediction
Energy consumption = 166.865445 pJ
sum error= 329
Actual label: 8
Output voltages: [0.036196, 0.075947, 0.057666, 0.037954, 0.055166, 0.0079872, 0.046611, 0.0014247, 0.79874, 0.42813]
Predicted label: 8
Correct prediction
Energy consumption = 144.886916 pJ
sum error= 329
Actual label: 9
Output voltages: [0.36486, 0.0069238, 0.03022, 0.016859, 0.053299, 0.040068, 0.0020731, 0.16127, 0.66991, 0.79057]
Predicted label: 9
Correct prediction
Energy consumption = 148.101587 pJ
sum error= 329
Actual label: 8
Output voltages: [0.0067781, 0.058025, 0.20402, 0.039625, 0.0085488, 0.0040948, 0.039746, 0.029056, 0.79874, 0.15414]
Predicted label: 8
Correct prediction
Energy consumption = 144.413108 pJ
sum error= 329
Actual label: 9
Output voltages: [0.053916, 0.031762, 0.021314, 0.022629, 0.012776, 0.0020762, 0.0014992, 0.011383, 0.7173, 0.79644]
Predicted label: 9
Correct prediction
Energy consumption = 146.430112 pJ
sum error= 329
Actual label: 5
Output voltages: [0.040569, 0.0012939, 0.012151, 0.34236, 0.02453, 0.79879, 0.096959, 0.20311, 0.78816, 0.05573]
Predicted label: 5
Correct prediction
Energy consumption = 146.771338 pJ
sum error= 329
Actual label: 7
Output voltages: [0.57847, 0.0039333, 0.31055, 0.54535, 0.0010981, 0.0010665, 0.0010692, 0.79862, 0.3839, 0.22249]
Predicted label: 7
Correct prediction
Energy consumption = 154.111678 pJ
sum error= 329
Actual label: 0
Output voltages: [0.79873, 0.046174, 0.02176, 0.02097, 0.046634, 0.019717, 0.54287, 0.016559, 0.076476, 0.042935]
Predicted label: 0
Correct prediction
Energy consumption = 144.482387 pJ
sum error= 329
Actual label: 3
Output voltages: [0.39002, 0.010399, 0.13073, 0.79868, 0.04183, 0.006749, 0.011304, 0.0067368, 0.67565, 0.037701]
Predicted label: 3
Correct prediction
Energy consumption = 149.382951 pJ
sum error= 329
Actual label: 1
Output voltages: [0.024052, 0.79857, 0.037089, 0.0203, 0.12661, 0.001473, 0.72066, 0.020349, 0.047086, 0.034173]
Predicted label: 1
Correct prediction
Energy consumption = 154.790977 pJ
sum error= 329
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 797 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 797 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 797 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.03877, 0.0044542, 0.14247, 0.0039923, 0.26669, 0.37302, 0.79877, 0.001116, 0.6639, 0.0058157]
Predicted label: 6
Correct prediction
Energy consumption = 162.150057 pJ
sum error= 329
Actual label: 8
Output voltages: [0.43827, 0.034641, 0.20252, 0.017272, 0.042304, 0.0012023, 0.02327, 0.012103, 0.7957, 0.21524]
Predicted label: 8
Correct prediction
Energy consumption = 152.510817 pJ
sum error= 329
Actual label: 4
Output voltages: [0.0038649, 0.00993, 0.039583, 0.021412, 0.79879, 0.0016065, 0.1922, 0.18599, 0.036323, 0.0028071]
Predicted label: 4
Correct prediction
Energy consumption = 147.645916 pJ
sum error= 329
Actual label: 1
Output voltages: [0.020181, 0.79876, 0.17843, 0.0042892, 0.36671, 0.0010666, 0.064897, 0.0042836, 0.073461, 0.021951]
Predicted label: 1
Correct prediction
Energy consumption = 154.150803 pJ
sum error= 329
Actual label: 5
Output voltages: [0.048309, 0.0010931, 0.0010933, 0.39052, 0.033575, 0.79873, 0.14648, 0.062827, 0.76771, 0.0068285]
Predicted label: 5
Correct prediction
Energy consumption = 140.869331 pJ
sum error= 329
Actual label: 6
Output voltages: [0.064284, 0.0078303, 0.50965, 0.0040792, 0.3121, 0.1898, 0.79872, 0.0011066, 0.61633, 0.040254]
Predicted label: 6
Correct prediction
Energy consumption = 148.634146 pJ
sum error= 329
Actual label: 4
Output voltages: [0.0042059, 0.0040204, 0.41754, 0.027309, 0.79866, 0.0012335, 0.51401, 0.33651, 0.005446, 0.013016]
Predicted label: 4
Correct prediction
Energy consumption = 143.733435 pJ
sum error= 329
Actual label: 2
Output voltages: [0.57828, 0.0032546, 0.79733, 0.24086, 0.019587, 0.0012258, 0.030824, 0.11244, 0.6586, 0.012932]
Predicted label: 2
Correct prediction
Energy consumption = 146.083639 pJ
sum error= 329
Actual label: 7
Output voltages: [0.73965, 0.0089653, 0.61508, 0.33991, 0.0036451, 0.0014513, 0.0010678, 0.7867, 0.77411, 0.024205]
Predicted label: 7
Correct prediction
Energy consumption = 142.872530 pJ
sum error= 329
Actual label: 8
Output voltages: [0.038134, 0.014652, 0.49144, 0.010914, 0.020391, 0.0094825, 0.015932, 0.0049715, 0.79874, 0.22068]
Predicted label: 8
Correct prediction
Energy consumption = 135.541041 pJ
sum error= 329
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 798 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 798 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 798 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.062684, 0.79878, 0.52941, 0.045306, 0.19706, 0.0011666, 0.6547, 0.011619, 0.070875, 0.023934]
Predicted label: 1
Correct prediction
Energy consumption = 179.981867 pJ
sum error= 329
Actual label: 3
Output voltages: [0.43617, 0.024128, 0.090583, 0.79863, 0.030772, 0.011059, 0.013065, 0.01135, 0.67214, 0.043567]
Predicted label: 3
Correct prediction
Energy consumption = 145.272620 pJ
sum error= 329
Actual label: 4
Output voltages: [0.0134, 0.032019, 0.028385, 0.019857, 0.79876, 0.0010937, 0.10937, 0.011899, 0.42714, 0.013356]
Predicted label: 4
Correct prediction
Energy consumption = 150.998498 pJ
sum error= 329
Actual label: 3
Output voltages: [0.17471, 0.014671, 0.027578, 0.79867, 0.03956, 0.028728, 0.033714, 0.0041005, 0.63895, 0.14625]
Predicted label: 3
Correct prediction
Energy consumption = 149.480961 pJ
sum error= 329
Actual label: 4
Output voltages: [0.020743, 0.027297, 0.024226, 0.026312, 0.79877, 0.0010663, 0.11346, 0.072496, 0.035087, 0.0042587]
Predicted label: 4
Correct prediction
Energy consumption = 151.675528 pJ
sum error= 329
Actual label: 7
Output voltages: [0.040417, 0.060677, 0.6967, 0.033765, 0.0035304, 0.001156, 0.0011112, 0.79875, 0.66755, 0.093889]
Predicted label: 7
Correct prediction
Energy consumption = 151.750172 pJ
sum error= 329
Actual label: 2
Output voltages: [0.47972, 0.0030744, 0.79777, 0.34398, 0.0041208, 0.0011503, 0.024107, 0.079188, 0.71108, 0.022326]
Predicted label: 2
Correct prediction
Energy consumption = 136.199210 pJ
sum error= 329
Actual label: 0
Output voltages: [0.79879, 0.0345, 0.18023, 0.017161, 0.0044826, 0.0074495, 0.38027, 0.028437, 0.45595, 0.012276]
Predicted label: 0
Correct prediction
Energy consumption = 147.711147 pJ
sum error= 329
Actual label: 5
Output voltages: [0.027172, 0.0011514, 0.0011672, 0.097381, 0.038861, 0.79865, 0.43224, 0.11125, 0.74898, 0.009601]
Predicted label: 5
Correct prediction
Energy consumption = 140.158906 pJ
sum error= 329
Actual label: 0
Output voltages: [0.79844, 0.052549, 0.02442, 0.016948, 0.0028661, 0.0018361, 0.73402, 0.012442, 0.3132, 0.054318]
Predicted label: 0
Correct prediction
Energy consumption = 134.926754 pJ
sum error= 329
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 799 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 799 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 799 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.054514, 0.77573, 0.0082008, 0.029837, 0.068967, 0.0099697, 0.067088, 0.0053154, 0.78378, 0.047919]
Predicted label: 8
Wrong prediction!
Energy consumption = 171.107645 pJ
sum error= 330
Actual label: 9
Output voltages: [0.34922, 0.0016292, 0.055018, 0.0055872, 0.027025, 0.0134, 0.001142, 0.066487, 0.79151, 0.78869]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.457694 pJ
sum error= 331
Actual label: 2
Output voltages: [0.23879, 0.015896, 0.79866, 0.079459, 0.021943, 0.0010683, 0.028633, 0.16743, 0.35106, 0.029868]
Predicted label: 2
Correct prediction
Energy consumption = 141.895838 pJ
sum error= 331
Actual label: 3
Output voltages: [0.60934, 0.0047426, 0.040154, 0.79869, 0.020037, 0.28635, 0.011442, 0.012157, 0.52081, 0.028701]
Predicted label: 3
Correct prediction
Energy consumption = 143.638114 pJ
sum error= 331
Actual label: 2
Output voltages: [0.54047, 0.0042298, 0.79871, 0.058717, 0.0081586, 0.0011411, 0.022045, 0.091039, 0.68772, 0.0021148]
Predicted label: 2
Correct prediction
Energy consumption = 137.017045 pJ
sum error= 331
Actual label: 3
Output voltages: [0.37818, 0.038253, 0.07712, 0.79857, 0.033275, 0.014993, 0.015891, 0.029559, 0.63468, 0.04824]
Predicted label: 3
Correct prediction
Energy consumption = 145.912344 pJ
sum error= 331
Actual label: 5
Output voltages: [0.03138, 0.0010659, 0.0011034, 0.31817, 0.33767, 0.79874, 0.44251, 0.0029419, 0.74987, 0.0019191]
Predicted label: 5
Correct prediction
Energy consumption = 132.684024 pJ
sum error= 331
Actual label: 5
Output voltages: [0.17708, 0.0012111, 0.0010739, 0.37644, 0.012646, 0.79878, 0.36521, 0.019742, 0.75457, 0.0049419]
Predicted label: 5
Correct prediction
Energy consumption = 131.711427 pJ
sum error= 331
Actual label: 7
Output voltages: [0.38946, 0.002079, 0.032484, 0.16039, 0.0011338, 0.011321, 0.001119, 0.79667, 0.75311, 0.51888]
Predicted label: 7
Correct prediction
Energy consumption = 149.825942 pJ
sum error= 331
Actual label: 8
Output voltages: [0.61586, 0.018482, 0.75136, 0.006811, 0.012033, 0.0018118, 0.026615, 0.014203, 0.79818, 0.20775]
Predicted label: 8
Correct prediction
Energy consumption = 139.348327 pJ
sum error= 331
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 800 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 800 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 800 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.030111, 0.0080858, 0.6098, 0.0095476, 0.79879, 0.001066, 0.65991, 0.046344, 0.03483, 0.036231]
Predicted label: 4
Correct prediction
Energy consumption = 160.107356 pJ
sum error= 331
Actual label: 9
Output voltages: [0.27906, 0.0015682, 0.012485, 0.051594, 0.37198, 0.003437, 0.0034951, 0.032941, 0.52723, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 154.529660 pJ
sum error= 331
Actual label: 9
Output voltages: [0.052519, 0.0079419, 0.013507, 0.034036, 0.034102, 0.0062548, 0.0011533, 0.029069, 0.74634, 0.79243]
Predicted label: 9
Correct prediction
Energy consumption = 140.505650 pJ
sum error= 331
Actual label: 7
Output voltages: [0.099576, 0.050217, 0.2438, 0.38701, 0.0054375, 0.0011236, 0.0011962, 0.79879, 0.69692, 0.4538]
Predicted label: 7
Correct prediction
Energy consumption = 147.319430 pJ
sum error= 331
Actual label: 1
Output voltages: [0.53233, 0.78876, 0.3276, 0.028882, 0.052472, 0.010681, 0.77098, 0.0010697, 0.035068, 0.032884]
Predicted label: 1
Correct prediction
Energy consumption = 160.930671 pJ
sum error= 331
Actual label: 1
Output voltages: [0.010273, 0.79855, 0.054004, 0.012809, 0.040942, 0.0035376, 0.70673, 0.019471, 0.33723, 0.034002]
Predicted label: 1
Correct prediction
Energy consumption = 150.673818 pJ
sum error= 331
Actual label: 9
Output voltages: [0.38717, 0.014234, 0.029563, 0.019469, 0.035892, 0.029686, 0.0083674, 0.037879, 0.74315, 0.79815]
Predicted label: 9
Correct prediction
Energy consumption = 154.939552 pJ
sum error= 331
Actual label: 0
Output voltages: [0.79879, 0.031699, 0.10952, 0.004788, 0.004317, 0.0024636, 0.50453, 0.080064, 0.29196, 0.023887]
Predicted label: 0
Correct prediction
Energy consumption = 142.430594 pJ
sum error= 331
Actual label: 7
Output voltages: [0.12615, 0.032295, 0.74708, 0.033173, 0.0017882, 0.001072, 0.0010731, 0.79872, 0.61078, 0.30524]
Predicted label: 7
Correct prediction
Energy consumption = 144.993889 pJ
sum error= 331
Actual label: 8
Output voltages: [0.086041, 0.010829, 0.59703, 0.0066992, 0.035955, 0.0071678, 0.010596, 0.0041544, 0.79876, 0.18967]
Predicted label: 8
Correct prediction
Energy consumption = 139.878365 pJ
sum error= 331
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 801 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 801 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 801 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.73466, 0.0010677, 0.29367, 0.79856, 0.018742, 0.010673, 0.012201, 0.0053803, 0.76515, 0.0054492]
Predicted label: 3
Correct prediction
Energy consumption = 171.616769 pJ
sum error= 331
Actual label: 4
Output voltages: [0.021659, 0.028691, 0.0088304, 0.012681, 0.79861, 0.0014486, 0.11023, 0.056271, 0.21563, 0.0089577]
Predicted label: 4
Correct prediction
Energy consumption = 151.473942 pJ
sum error= 331
Actual label: 8
Output voltages: [0.059518, 0.029976, 0.36065, 0.020077, 0.026917, 0.0054333, 0.036849, 0.01647, 0.79874, 0.13884]
Predicted label: 8
Correct prediction
Energy consumption = 144.521461 pJ
sum error= 331
Actual label: 6
Output voltages: [0.048548, 0.079556, 0.5074, 0.0021992, 0.41472, 0.10141, 0.79864, 0.0028631, 0.4218, 0.020165]
Predicted label: 6
Correct prediction
Energy consumption = 146.188531 pJ
sum error= 331
Actual label: 3
Output voltages: [0.53304, 0.0038034, 0.29919, 0.79876, 0.027598, 0.013385, 0.029213, 0.019808, 0.68557, 0.046834]
Predicted label: 3
Correct prediction
Energy consumption = 155.425058 pJ
sum error= 331
Actual label: 8
Output voltages: [0.023428, 0.052514, 0.16022, 0.018467, 0.014492, 0.03836, 0.030699, 0.0030676, 0.79874, 0.10279]
Predicted label: 8
Correct prediction
Energy consumption = 146.862114 pJ
sum error= 331
Actual label: 0
Output voltages: [0.79866, 0.038496, 0.061361, 0.023716, 0.0086732, 0.0012076, 0.66862, 0.015183, 0.27325, 0.23468]
Predicted label: 0
Correct prediction
Energy consumption = 136.682766 pJ
sum error= 331
Actual label: 9
Output voltages: [0.28727, 0.01187, 0.023467, 0.030145, 0.12126, 0.011144, 0.002164, 0.043348, 0.61435, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 147.223003 pJ
sum error= 331
Actual label: 6
Output voltages: [0.10435, 0.045395, 0.42991, 0.0011274, 0.29823, 0.2045, 0.79871, 0.0018752, 0.59168, 0.0050761]
Predicted label: 6
Correct prediction
Energy consumption = 153.501056 pJ
sum error= 331
Actual label: 2
Output voltages: [0.29982, 0.016947, 0.79759, 0.39651, 0.011182, 0.0011306, 0.19349, 0.016198, 0.7896, 0.1108]
Predicted label: 2
Correct prediction
Energy consumption = 149.391851 pJ
sum error= 331
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 802 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 802 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 802 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.27895, 0.7964, 0.11561, 0.023703, 0.0026099, 0.0011037, 0.75489, 0.0013639, 0.65946, 0.033514]
Predicted label: 1
Correct prediction
Energy consumption = 183.148883 pJ
sum error= 331
Actual label: 0
Output voltages: [0.79879, 0.10375, 0.022202, 0.0088353, 0.049667, 0.010964, 0.61525, 0.010102, 0.056717, 0.12895]
Predicted label: 0
Correct prediction
Energy consumption = 142.991645 pJ
sum error= 331
Actual label: 1
Output voltages: [0.059921, 0.79872, 0.024666, 0.029049, 0.30089, 0.0010752, 0.17777, 0.001066, 0.52556, 0.1733]
Predicted label: 1
Correct prediction
Energy consumption = 157.102545 pJ
sum error= 331
Actual label: 0
Output voltages: [0.79681, 0.062964, 0.012602, 0.015055, 0.0090409, 0.0012083, 0.43185, 0.025809, 0.36646, 0.029935]
Predicted label: 0
Correct prediction
Energy consumption = 143.828093 pJ
sum error= 331
Actual label: 6
Output voltages: [0.078971, 0.024129, 0.35943, 0.0010659, 0.36446, 0.026122, 0.79878, 0.0010838, 0.20478, 0.006192]
Predicted label: 6
Correct prediction
Energy consumption = 146.019120 pJ
sum error= 331
Actual label: 2
Output voltages: [0.21598, 0.0086869, 0.79863, 0.025891, 0.051456, 0.0011593, 0.076568, 0.072192, 0.34796, 0.0066537]
Predicted label: 2
Correct prediction
Energy consumption = 139.068436 pJ
sum error= 331
Actual label: 3
Output voltages: [0.50297, 0.015405, 0.18952, 0.79873, 0.31852, 0.0054767, 0.012624, 0.0021705, 0.63214, 0.029181]
Predicted label: 3
Correct prediction
Energy consumption = 137.489136 pJ
sum error= 331
Actual label: 8
Output voltages: [0.041429, 0.024211, 0.43378, 0.016904, 0.039093, 0.0074045, 0.023985, 0.0049838, 0.79873, 0.1276]
Predicted label: 8
Correct prediction
Energy consumption = 139.560466 pJ
sum error= 331
Actual label: 9
Output voltages: [0.32041, 0.014769, 0.10033, 0.0059901, 0.04278, 0.0093865, 0.0019176, 0.039677, 0.67243, 0.79792]
Predicted label: 9
Correct prediction
Energy consumption = 153.084297 pJ
sum error= 331
Actual label: 0
Output voltages: [0.79713, 0.021892, 0.26367, 0.01037, 0.018241, 0.0012326, 0.67502, 0.047688, 0.2842, 0.037283]
Predicted label: 0
Correct prediction
Energy consumption = 144.931812 pJ
sum error= 331
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 803 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 803 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 803 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.60506, 0.0035852, 0.74034, 0.26015, 0.0010795, 0.0018179, 0.0010726, 0.79504, 0.58919, 0.25768]
Predicted label: 7
Correct prediction
Energy consumption = 170.523117 pJ
sum error= 331
Actual label: 2
Output voltages: [0.13169, 0.054949, 0.79878, 0.50226, 0.026612, 0.0012741, 0.031577, 0.33956, 0.096435, 0.01393]
Predicted label: 2
Correct prediction
Energy consumption = 134.207276 pJ
sum error= 331
Actual label: 3
Output voltages: [0.064913, 0.0055254, 0.078807, 0.79877, 0.024591, 0.0037671, 0.0053313, 0.033012, 0.60112, 0.13198]
Predicted label: 3
Correct prediction
Energy consumption = 144.974636 pJ
sum error= 331
Actual label: 4
Output voltages: [0.0026286, 0.0093239, 0.013113, 0.0060654, 0.79869, 0.0011081, 0.041401, 0.18082, 0.24371, 0.0079657]
Predicted label: 4
Correct prediction
Energy consumption = 146.257266 pJ
sum error= 331
Actual label: 5
Output voltages: [0.0044205, 0.0011419, 0.0040184, 0.34988, 0.015209, 0.7833, 0.025534, 0.0050263, 0.77063, 0.037891]
Predicted label: 5
Correct prediction
Energy consumption = 149.427623 pJ
sum error= 331
Actual label: 5
Output voltages: [0.015597, 0.0010941, 0.0012797, 0.64178, 0.02054, 0.76773, 0.016761, 0.010525, 0.75098, 0.020645]
Predicted label: 5
Correct prediction
Energy consumption = 133.523559 pJ
sum error= 331
Actual label: 2
Output voltages: [0.5724, 0.025555, 0.79874, 0.2053, 0.052118, 0.0032574, 0.047021, 0.042381, 0.19184, 0.018091]
Predicted label: 2
Correct prediction
Energy consumption = 145.641808 pJ
sum error= 331
Actual label: 8
Output voltages: [0.020593, 0.14338, 0.15792, 0.026049, 0.027782, 0.016192, 0.034508, 0.0019111, 0.79877, 0.41532]
Predicted label: 8
Correct prediction
Energy consumption = 142.791369 pJ
sum error= 331
Actual label: 5
Output voltages: [0.029252, 0.0084068, 0.0032863, 0.28343, 0.016496, 0.79878, 0.21725, 0.0319, 0.6368, 0.022488]
Predicted label: 5
Correct prediction
Energy consumption = 146.029120 pJ
sum error= 331
Actual label: 4
Output voltages: [0.0038623, 0.027202, 0.041018, 0.02313, 0.79862, 0.0041805, 0.033507, 0.064876, 0.023433, 0.024882]
Predicted label: 4
Correct prediction
Energy consumption = 154.970156 pJ
sum error= 331
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 804 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 804 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 804 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.2098, 0.022312, 0.32081, 0.0012225, 0.5002, 0.22881, 0.79879, 0.0010689, 0.40112, 0.0052882]
Predicted label: 6
Correct prediction
Energy consumption = 167.743216 pJ
sum error= 331
Actual label: 6
Output voltages: [0.21745, 0.044952, 0.052034, 0.020247, 0.21414, 0.26181, 0.79879, 0.0011044, 0.62374, 0.0055718]
Predicted label: 6
Correct prediction
Energy consumption = 139.893700 pJ
sum error= 331
Actual label: 6
Output voltages: [0.1858, 0.071979, 0.19574, 0.011703, 0.31475, 0.2691, 0.7987, 0.0015672, 0.44175, 0.012284]
Predicted label: 6
Correct prediction
Energy consumption = 141.298279 pJ
sum error= 331
Actual label: 7
Output voltages: [0.44278, 0.2198, 0.79766, 0.019533, 0.0014682, 0.00113, 0.021221, 0.78392, 0.61181, 0.054983]
Predicted label: 2
Wrong prediction!
Energy consumption = 153.498616 pJ
sum error= 332
Actual label: 9
Output voltages: [0.39947, 0.0024713, 0.0093744, 0.033682, 0.042154, 0.0035923, 0.0019525, 0.059805, 0.56791, 0.78897]
Predicted label: 9
Correct prediction
Energy consumption = 154.121408 pJ
sum error= 332
Actual label: 1
Output voltages: [0.041164, 0.79859, 0.020833, 0.017724, 0.50853, 0.001066, 0.1327, 0.0010838, 0.31937, 0.249]
Predicted label: 1
Correct prediction
Energy consumption = 160.845203 pJ
sum error= 332
Actual label: 8
Output voltages: [0.024948, 0.037784, 0.19427, 0.010303, 0.011636, 0.0031813, 0.0272, 0.025886, 0.79877, 0.3136]
Predicted label: 8
Correct prediction
Energy consumption = 141.054651 pJ
sum error= 332
Actual label: 2
Output voltages: [0.75271, 0.023494, 0.79879, 0.58051, 0.0085138, 0.0091873, 0.11897, 0.055674, 0.70511, 0.0095992]
Predicted label: 2
Correct prediction
Energy consumption = 143.571494 pJ
sum error= 332
Actual label: 1
Output voltages: [0.011672, 0.79861, 0.036326, 0.012563, 0.020975, 0.0023953, 0.28809, 0.010674, 0.54005, 0.0068874]
Predicted label: 1
Correct prediction
Energy consumption = 164.111261 pJ
sum error= 332
Actual label: 5
Output voltages: [0.033682, 0.0010704, 0.0043939, 0.11012, 0.031704, 0.79857, 0.32232, 0.035579, 0.78067, 0.010029]
Predicted label: 5
Correct prediction
Energy consumption = 146.121283 pJ
sum error= 332
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 805 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 805 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 805 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.62665, 0.0078182, 0.11276, 0.79878, 0.036883, 0.0068737, 0.001588, 0.0023222, 0.49509, 0.0076379]
Predicted label: 3
Correct prediction
Energy consumption = 167.052491 pJ
sum error= 332
Actual label: 4
Output voltages: [0.023041, 0.010889, 0.038681, 0.037888, 0.79874, 0.0011761, 0.0085751, 0.011205, 0.11146, 0.013258]
Predicted label: 4
Correct prediction
Energy consumption = 148.037038 pJ
sum error= 332
Actual label: 7
Output voltages: [0.15513, 0.022549, 0.53522, 0.011302, 0.0017622, 0.0010692, 0.0010664, 0.79865, 0.34285, 0.15665]
Predicted label: 7
Correct prediction
Energy consumption = 152.338674 pJ
sum error= 332
Actual label: 9
Output voltages: [0.33133, 0.0064987, 0.014183, 0.021739, 0.10099, 0.0048752, 0.0021984, 0.032188, 0.64494, 0.79863]
Predicted label: 9
Correct prediction
Energy consumption = 144.407247 pJ
sum error= 332
Actual label: 4
Output voltages: [0.0095994, 0.01195, 0.018605, 0.0076176, 0.79869, 0.0011418, 0.12902, 0.21254, 0.035751, 0.0042172]
Predicted label: 4
Correct prediction
Energy consumption = 150.598374 pJ
sum error= 332
Actual label: 0
Output voltages: [0.79873, 0.026259, 0.042535, 0.017722, 0.078257, 0.00257, 0.36264, 0.018246, 0.2695, 0.020803]
Predicted label: 0
Correct prediction
Energy consumption = 154.290271 pJ
sum error= 332
Actual label: 0
Output voltages: [0.79874, 0.24073, 0.028768, 0.034066, 0.0096311, 0.021122, 0.21596, 0.051677, 0.12943, 0.067436]
Predicted label: 0
Correct prediction
Energy consumption = 140.473687 pJ
sum error= 332
Actual label: 0
Output voltages: [0.79795, 0.040154, 0.032761, 0.0037532, 0.032905, 0.0014794, 0.60677, 0.017683, 0.034144, 0.13788]
Predicted label: 0
Correct prediction
Energy consumption = 140.597157 pJ
sum error= 332
Actual label: 1
Output voltages: [0.0089793, 0.79859, 0.031974, 0.10636, 0.12077, 0.0033476, 0.69842, 0.001295, 0.34385, 0.059611]
Predicted label: 1
Correct prediction
Energy consumption = 163.514250 pJ
sum error= 332
Actual label: 2
Output voltages: [0.050043, 0.75536, 0.79561, 0.58402, 0.0018714, 0.001111, 0.41026, 0.0025814, 0.41371, 0.068904]
Predicted label: 2
Correct prediction
Energy consumption = 150.565264 pJ
sum error= 332
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 806 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 806 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 806 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34073, 0.065926, 0.056804, 0.79868, 0.01228, 0.0075489, 0.0017044, 0.0074118, 0.63898, 0.22347]
Predicted label: 3
Correct prediction
Energy consumption = 171.958684 pJ
sum error= 332
Actual label: 4
Output voltages: [0.22277, 0.01888, 0.099786, 0.01574, 0.79879, 0.0011996, 0.020805, 0.011158, 0.023517, 0.11533]
Predicted label: 4
Correct prediction
Energy consumption = 153.906431 pJ
sum error= 332
Actual label: 5
Output voltages: [0.073054, 0.046902, 0.0034668, 0.40611, 0.001083, 0.77248, 0.028292, 0.001405, 0.79784, 0.023159]
Predicted label: 8
Wrong prediction!
Energy consumption = 155.155503 pJ
sum error= 333
Actual label: 6
Output voltages: [0.27503, 0.060839, 0.091859, 0.046427, 0.15488, 0.4456, 0.79878, 0.0011686, 0.43823, 0.0049265]
Predicted label: 6
Correct prediction
Energy consumption = 150.197744 pJ
sum error= 333
Actual label: 7
Output voltages: [0.45879, 0.087933, 0.058785, 0.59253, 0.0030952, 0.0059861, 0.0011726, 0.79704, 0.72622, 0.26563]
Predicted label: 7
Correct prediction
Energy consumption = 161.355157 pJ
sum error= 333
Actual label: 8
Output voltages: [0.11613, 0.36594, 0.039141, 0.62335, 0.017274, 0.0037356, 0.046452, 0.0021792, 0.79875, 0.2225]
Predicted label: 8
Correct prediction
Energy consumption = 158.294670 pJ
sum error= 333
Actual label: 9
Output voltages: [0.048349, 0.019587, 0.0097329, 0.02939, 0.02723, 0.0020342, 0.0010978, 0.011945, 0.72475, 0.7979]
Predicted label: 9
Correct prediction
Energy consumption = 144.783678 pJ
sum error= 333
Actual label: 0
Output voltages: [0.79869, 0.033781, 0.20426, 0.0042426, 0.011869, 0.014418, 0.072471, 0.02077, 0.22764, 0.03918]
Predicted label: 0
Correct prediction
Energy consumption = 151.949776 pJ
sum error= 333
Actual label: 1
Output voltages: [0.011722, 0.79853, 0.038475, 0.046811, 0.0977, 0.0033373, 0.72009, 0.0016104, 0.29026, 0.24942]
Predicted label: 1
Correct prediction
Energy consumption = 166.645717 pJ
sum error= 333
Actual label: 2
Output voltages: [0.017414, 0.79295, 0.66459, 0.14784, 0.022722, 0.0012933, 0.2876, 0.0040914, 0.23528, 0.008515]
Predicted label: 1
Wrong prediction!
Energy consumption = 144.349826 pJ
sum error= 334
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 807 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 807 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 807 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.48233, 0.023558, 0.12333, 0.79869, 0.025173, 0.015237, 0.005707, 0.020619, 0.62098, 0.044045]
Predicted label: 3
Correct prediction
Energy consumption = 167.178774 pJ
sum error= 334
Actual label: 4
Output voltages: [0.089616, 0.20188, 0.0012163, 0.29802, 0.79764, 0.0071144, 0.079436, 0.010006, 0.027643, 0.3044]
Predicted label: 4
Correct prediction
Energy consumption = 150.454655 pJ
sum error= 334
Actual label: 5
Output voltages: [0.023879, 0.0067997, 0.0034773, 0.55984, 0.030055, 0.79872, 0.13406, 0.038661, 0.75022, 0.028848]
Predicted label: 5
Correct prediction
Energy consumption = 148.974857 pJ
sum error= 334
Actual label: 6
Output voltages: [0.032531, 0.087584, 0.21236, 0.0072695, 0.035959, 0.35642, 0.79877, 0.019027, 0.53223, 0.0042152]
Predicted label: 6
Correct prediction
Energy consumption = 147.863300 pJ
sum error= 334
Actual label: 7
Output voltages: [0.03902, 0.051451, 0.055794, 0.064188, 0.0067303, 0.0010678, 0.001195, 0.79879, 0.62388, 0.20933]
Predicted label: 7
Correct prediction
Energy consumption = 159.589621 pJ
sum error= 334
Actual label: 8
Output voltages: [0.37921, 0.68901, 0.015964, 0.4451, 0.0014403, 0.0014737, 0.019542, 0.0011283, 0.79876, 0.56864]
Predicted label: 8
Correct prediction
Energy consumption = 153.458673 pJ
sum error= 334
Actual label: 9
Output voltages: [0.34471, 0.0080627, 0.027321, 0.025376, 0.13465, 0.004827, 0.0012653, 0.037658, 0.45423, 0.79756]
Predicted label: 9
Correct prediction
Energy consumption = 150.804871 pJ
sum error= 334
Actual label: 0
Output voltages: [0.79878, 0.040764, 0.18984, 0.027616, 0.10291, 0.0022788, 0.40757, 0.022013, 0.28164, 0.063416]
Predicted label: 0
Correct prediction
Energy consumption = 155.657076 pJ
sum error= 334
Actual label: 1
Output voltages: [0.04146, 0.79863, 0.046851, 0.1669, 0.036768, 0.0015042, 0.64594, 0.001068, 0.24595, 0.081974]
Predicted label: 1
Correct prediction
Energy consumption = 160.092750 pJ
sum error= 334
Actual label: 2
Output voltages: [0.15934, 0.42656, 0.79836, 0.26147, 0.0073832, 0.0011178, 0.21669, 0.0026829, 0.56099, 0.25908]
Predicted label: 2
Correct prediction
Energy consumption = 147.357390 pJ
sum error= 334
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 808 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 808 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 808 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.65059, 0.041992, 0.13595, 0.79865, 0.055674, 0.015117, 0.012916, 0.014945, 0.74558, 0.04454]
Predicted label: 3
Correct prediction
Energy consumption = 165.534503 pJ
sum error= 334
Actual label: 4
Output voltages: [0.20346, 0.12459, 0.016537, 0.031945, 0.79596, 0.0018785, 0.78349, 0.0024207, 0.0052318, 0.054977]
Predicted label: 4
Correct prediction
Energy consumption = 147.736816 pJ
sum error= 334
Actual label: 5
Output voltages: [0.045066, 0.002093, 0.0018264, 0.12728, 0.093145, 0.79875, 0.6468, 0.024556, 0.76204, 0.30448]
Predicted label: 5
Correct prediction
Energy consumption = 143.997781 pJ
sum error= 334
Actual label: 6
Output voltages: [0.13482, 0.24137, 0.16752, 0.0054082, 0.18913, 0.35541, 0.79871, 0.0053069, 0.40433, 0.014696]
Predicted label: 6
Correct prediction
Energy consumption = 148.137562 pJ
sum error= 334
Actual label: 9
Output voltages: [0.31176, 0.024275, 0.037721, 0.03311, 0.24375, 0.0047498, 0.0026445, 0.0070459, 0.32812, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 158.764266 pJ
sum error= 334
Actual label: 0
Output voltages: [0.79861, 0.037086, 0.15665, 0.0064815, 0.031241, 0.0024177, 0.76185, 0.0023976, 0.43685, 0.041919]
Predicted label: 0
Correct prediction
Energy consumption = 154.427696 pJ
sum error= 334
Actual label: 1
Output voltages: [0.014664, 0.79872, 0.16801, 0.11207, 0.18158, 0.0012453, 0.65825, 0.0016425, 0.049581, 0.020889]
Predicted label: 1
Correct prediction
Energy consumption = 167.179800 pJ
sum error= 334
Actual label: 3
Output voltages: [0.16676, 0.03324, 0.091425, 0.79877, 0.0041841, 0.0025953, 0.010384, 0.017574, 0.76881, 0.018712]
Predicted label: 3
Correct prediction
Energy consumption = 142.189568 pJ
sum error= 334
Actual label: 1
Output voltages: [0.24357, 0.79879, 0.06176, 0.50568, 0.0065238, 0.0016031, 0.28644, 0.0010796, 0.7372, 0.15293]
Predicted label: 1
Correct prediction
Energy consumption = 161.819150 pJ
sum error= 334
Actual label: 5
Output voltages: [0.011294, 0.0016452, 0.0061573, 0.24771, 0.016023, 0.79867, 0.045786, 0.025242, 0.77801, 0.043542]
Predicted label: 5
Correct prediction
Energy consumption = 153.363950 pJ
sum error= 334
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 809 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 809 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 809 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.028087, 0.79869, 0.040351, 0.062254, 0.0058591, 0.0038506, 0.73337, 0.0053122, 0.2597, 0.0095454]
Predicted label: 1
Correct prediction
Energy consumption = 179.343704 pJ
sum error= 334
Actual label: 2
Output voltages: [0.38497, 0.4568, 0.77871, 0.54638, 0.0070118, 0.0012502, 0.29226, 0.072594, 0.41539, 0.0017072]
Predicted label: 2
Correct prediction
Energy consumption = 152.288492 pJ
sum error= 334
Actual label: 4
Output voltages: [0.016252, 0.0020071, 0.051383, 0.0025494, 0.79862, 0.0041573, 0.40567, 0.033131, 0.13849, 0.011332]
Predicted label: 4
Correct prediction
Energy consumption = 150.971255 pJ
sum error= 334
Actual label: 9
Output voltages: [0.12316, 0.0085568, 0.022979, 0.04409, 0.06729, 0.010349, 0.0020171, 0.044216, 0.66634, 0.79458]
Predicted label: 9
Correct prediction
Energy consumption = 147.035597 pJ
sum error= 334
Actual label: 2
Output voltages: [0.032473, 0.21034, 0.74262, 0.34403, 0.048399, 0.0010933, 0.013133, 0.019261, 0.75398, 0.019282]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.950665 pJ
sum error= 335
Actual label: 4
Output voltages: [0.029984, 0.041882, 0.0030543, 0.15433, 0.79426, 0.0017527, 0.47923, 0.0055331, 0.15286, 0.001887]
Predicted label: 4
Correct prediction
Energy consumption = 157.089192 pJ
sum error= 335
Actual label: 6
Output voltages: [0.053473, 0.054441, 0.34774, 0.0043283, 0.19879, 0.22273, 0.79875, 0.0015625, 0.51257, 0.0024571]
Predicted label: 6
Correct prediction
Energy consumption = 143.286027 pJ
sum error= 335
Actual label: 8
Output voltages: [0.67665, 0.0040532, 0.31582, 0.60289, 0.0052677, 0.014328, 0.015971, 0.0012287, 0.79808, 0.24647]
Predicted label: 8
Correct prediction
Energy consumption = 151.358678 pJ
sum error= 335
Actual label: 0
Output voltages: [0.79875, 0.044798, 0.25945, 0.012127, 0.018344, 0.0037313, 0.51031, 0.070493, 0.086279, 0.025012]
Predicted label: 0
Correct prediction
Energy consumption = 141.559843 pJ
sum error= 335
Actual label: 1
Output voltages: [0.0060668, 0.79856, 0.2302, 0.010894, 0.018031, 0.0013823, 0.36658, 0.0037465, 0.3269, 0.0066992]
Predicted label: 1
Correct prediction
Energy consumption = 153.441253 pJ
sum error= 335
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 810 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 810 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 810 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.013216, 0.7986, 0.04803, 0.026804, 0.038106, 0.0022121, 0.62237, 0.00129, 0.26715, 0.033592]
Predicted label: 1
Correct prediction
Energy consumption = 177.337736 pJ
sum error= 335
Actual label: 9
Output voltages: [0.2648, 0.023578, 0.023572, 0.046549, 0.34573, 0.023623, 0.011925, 0.0086753, 0.26192, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 153.175510 pJ
sum error= 335
Actual label: 2
Output voltages: [0.052794, 0.39528, 0.79421, 0.49123, 0.0017842, 0.0010696, 0.039075, 0.018683, 0.62702, 0.0036814]
Predicted label: 2
Correct prediction
Energy consumption = 157.868687 pJ
sum error= 335
Actual label: 6
Output voltages: [0.11514, 0.026316, 0.17859, 0.0044894, 0.42842, 0.18749, 0.79876, 0.0013645, 0.70911, 0.0049398]
Predicted label: 6
Correct prediction
Energy consumption = 149.382963 pJ
sum error= 335
Actual label: 6
Output voltages: [0.059508, 0.009926, 0.081221, 0.0014483, 0.47123, 0.027535, 0.79879, 0.001087, 0.75984, 0.0043778]
Predicted label: 6
Correct prediction
Energy consumption = 140.392226 pJ
sum error= 335
Actual label: 8
Output voltages: [0.20277, 0.05853, 0.02406, 0.45798, 0.0014683, 0.081434, 0.016001, 0.0016756, 0.79878, 0.26811]
Predicted label: 8
Correct prediction
Energy consumption = 151.154867 pJ
sum error= 335
Actual label: 7
Output voltages: [0.29978, 0.21576, 0.25018, 0.023163, 0.0010662, 0.0013673, 0.0015596, 0.76458, 0.79248, 0.085331]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.713234 pJ
sum error= 336
Actual label: 4
Output voltages: [0.15791, 0.024485, 0.15567, 0.0019549, 0.79873, 0.0013984, 0.14283, 0.0083122, 0.038332, 0.33794]
Predicted label: 4
Correct prediction
Energy consumption = 152.695515 pJ
sum error= 336
Actual label: 2
Output voltages: [0.55909, 0.25961, 0.79871, 0.0311, 0.0053728, 0.0012396, 0.0382, 0.15663, 0.32066, 0.0045815]
Predicted label: 2
Correct prediction
Energy consumption = 154.965753 pJ
sum error= 336
Actual label: 9
Output voltages: [0.27801, 0.0060999, 0.02639, 0.025399, 0.32768, 0.0075825, 0.0053038, 0.045602, 0.46973, 0.79786]
Predicted label: 9
Correct prediction
Energy consumption = 154.285260 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 811 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 811 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 811 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.041955, 0.24857, 0.25771, 0.0044235, 0.019534, 0.0011873, 0.0010745, 0.79879, 0.41887, 0.070851]
Predicted label: 7
Correct prediction
Energy consumption = 171.968712 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79879, 0.041484, 0.048714, 0.019886, 0.012882, 0.0031806, 0.46351, 0.040544, 0.088214, 0.16633]
Predicted label: 0
Correct prediction
Energy consumption = 147.590394 pJ
sum error= 336
Actual label: 2
Output voltages: [0.3904, 0.097149, 0.79877, 0.44922, 0.011843, 0.0012306, 0.24463, 0.044389, 0.47021, 0.024283]
Predicted label: 2
Correct prediction
Energy consumption = 151.249075 pJ
sum error= 336
Actual label: 1
Output voltages: [0.010712, 0.79861, 0.075077, 0.44966, 0.028123, 0.001154, 0.77366, 0.016616, 0.063726, 0.031745]
Predicted label: 1
Correct prediction
Energy consumption = 159.572229 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79877, 0.14219, 0.024004, 0.014557, 0.011667, 0.013201, 0.48248, 0.03041, 0.090458, 0.027177]
Predicted label: 0
Correct prediction
Energy consumption = 146.195803 pJ
sum error= 336
Actual label: 3
Output voltages: [0.26827, 0.012629, 0.052414, 0.79875, 0.0030112, 0.037935, 0.0056635, 0.030866, 0.76035, 0.079582]
Predicted label: 3
Correct prediction
Energy consumption = 148.813268 pJ
sum error= 336
Actual label: 6
Output voltages: [0.035845, 0.017478, 0.25138, 0.0011223, 0.27844, 0.02864, 0.79879, 0.0011633, 0.705, 0.0028662]
Predicted label: 6
Correct prediction
Energy consumption = 144.487693 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79875, 0.032818, 0.06199, 0.039204, 0.0038474, 0.0072809, 0.31536, 0.015039, 0.033772, 0.063095]
Predicted label: 0
Correct prediction
Energy consumption = 142.763325 pJ
sum error= 336
Actual label: 1
Output voltages: [0.033925, 0.79869, 0.29143, 0.0038295, 0.14275, 0.001066, 0.19328, 0.0010679, 0.06076, 0.049127]
Predicted label: 1
Correct prediction
Energy consumption = 152.483649 pJ
sum error= 336
Actual label: 2
Output voltages: [0.097213, 0.040134, 0.79865, 0.031449, 0.0098748, 0.0011226, 0.050106, 0.20455, 0.46541, 0.029957]
Predicted label: 2
Correct prediction
Energy consumption = 132.843305 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 812 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 812 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 812 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.22912, 0.0017057, 0.39251, 0.79856, 0.0042513, 0.01602, 0.0026677, 0.022341, 0.7692, 0.031187]
Predicted label: 3
Correct prediction
Energy consumption = 159.429122 pJ
sum error= 336
Actual label: 4
Output voltages: [0.01378, 0.0069149, 0.40154, 0.028686, 0.79862, 0.0018672, 0.2991, 0.22476, 0.013057, 0.020452]
Predicted label: 4
Correct prediction
Energy consumption = 148.134669 pJ
sum error= 336
Actual label: 5
Output voltages: [0.010314, 0.0011018, 0.0015926, 0.41019, 0.021516, 0.79871, 0.38029, 0.07271, 0.74906, 0.022222]
Predicted label: 5
Correct prediction
Energy consumption = 154.218895 pJ
sum error= 336
Actual label: 6
Output voltages: [0.031984, 0.013101, 0.37689, 0.0010706, 0.4632, 0.076587, 0.79878, 0.001067, 0.31495, 0.016618]
Predicted label: 6
Correct prediction
Energy consumption = 138.411163 pJ
sum error= 336
Actual label: 7
Output voltages: [0.21088, 0.034296, 0.08464, 0.19778, 0.045368, 0.0010849, 0.0011603, 0.79871, 0.041975, 0.11426]
Predicted label: 7
Correct prediction
Energy consumption = 159.643876 pJ
sum error= 336
Actual label: 8
Output voltages: [0.050861, 0.015502, 0.73111, 0.0022153, 0.092562, 0.0017585, 0.040765, 0.0025652, 0.79879, 0.28219]
Predicted label: 8
Correct prediction
Energy consumption = 143.380220 pJ
sum error= 336
Actual label: 9
Output voltages: [0.22899, 0.0055207, 0.0036422, 0.11818, 0.18624, 0.50897, 0.0059227, 0.025838, 0.28935, 0.78706]
Predicted label: 9
Correct prediction
Energy consumption = 147.178616 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79879, 0.14264, 0.019576, 0.021689, 0.022767, 0.032052, 0.74024, 0.011579, 0.18058, 0.020973]
Predicted label: 0
Correct prediction
Energy consumption = 149.992683 pJ
sum error= 336
Actual label: 1
Output voltages: [0.054428, 0.79546, 0.12527, 0.15363, 0.1035, 0.0073578, 0.79286, 0.001148, 0.56855, 0.019893]
Predicted label: 1
Correct prediction
Energy consumption = 154.049532 pJ
sum error= 336
Actual label: 2
Output voltages: [0.3607, 0.12614, 0.79877, 0.41674, 0.023279, 0.0010659, 0.024108, 0.13416, 0.25106, 0.052246]
Predicted label: 2
Correct prediction
Energy consumption = 133.849101 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 813 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 813 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 813 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.26857, 0.018983, 0.060578, 0.79865, 0.016397, 0.025608, 0.0078179, 0.02377, 0.71783, 0.051394]
Predicted label: 3
Correct prediction
Energy consumption = 162.826813 pJ
sum error= 336
Actual label: 4
Output voltages: [0.003253, 0.0012117, 0.033115, 0.019877, 0.79861, 0.010857, 0.04049, 0.022012, 0.16527, 0.023286]
Predicted label: 4
Correct prediction
Energy consumption = 151.370544 pJ
sum error= 336
Actual label: 5
Output voltages: [0.16799, 0.0011372, 0.0015465, 0.45365, 0.087533, 0.79878, 0.39033, 0.034525, 0.67426, 0.0018294]
Predicted label: 5
Correct prediction
Energy consumption = 140.837322 pJ
sum error= 336
Actual label: 6
Output voltages: [0.064672, 0.1843, 0.42955, 0.001503, 0.36742, 0.01878, 0.79875, 0.001066, 0.494, 0.017905]
Predicted label: 6
Correct prediction
Energy consumption = 140.487266 pJ
sum error= 336
Actual label: 7
Output voltages: [0.052379, 0.036908, 0.39209, 0.015866, 0.024261, 0.0010703, 0.0017957, 0.79852, 0.14958, 0.058099]
Predicted label: 7
Correct prediction
Energy consumption = 158.616898 pJ
sum error= 336
Actual label: 8
Output voltages: [0.019647, 0.013336, 0.34854, 0.022335, 0.029969, 0.015112, 0.045811, 0.0095608, 0.79879, 0.20407]
Predicted label: 8
Correct prediction
Energy consumption = 150.946889 pJ
sum error= 336
Actual label: 9
Output voltages: [0.49634, 0.007147, 0.016334, 0.046281, 0.43977, 0.036334, 0.010633, 0.070671, 0.54635, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 144.806079 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79876, 0.22331, 0.030861, 0.042497, 0.0084651, 0.022734, 0.30252, 0.009463, 0.13122, 0.23812]
Predicted label: 0
Correct prediction
Energy consumption = 142.391856 pJ
sum error= 336
Actual label: 1
Output voltages: [0.021464, 0.79863, 0.048629, 0.036478, 0.051013, 0.001475, 0.69144, 0.0010974, 0.2872, 0.073267]
Predicted label: 1
Correct prediction
Energy consumption = 153.225217 pJ
sum error= 336
Actual label: 2
Output voltages: [0.17028, 0.0097614, 0.79872, 0.2028, 0.0060765, 0.00112, 0.019755, 0.26377, 0.60775, 0.0081345]
Predicted label: 2
Correct prediction
Energy consumption = 137.854989 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 814 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 814 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 814 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.54801, 0.001074, 0.52984, 0.79818, 0.0045947, 0.079056, 0.0018262, 0.027671, 0.77168, 0.0024412]
Predicted label: 3
Correct prediction
Energy consumption = 158.112258 pJ
sum error= 336
Actual label: 4
Output voltages: [0.033523, 0.0011679, 0.31659, 0.020039, 0.7987, 0.0011113, 0.0070211, 0.0056982, 0.23704, 0.042962]
Predicted label: 4
Correct prediction
Energy consumption = 142.578169 pJ
sum error= 336
Actual label: 5
Output voltages: [0.20614, 0.0010665, 0.0011436, 0.38182, 0.046394, 0.79879, 0.17362, 0.0087657, 0.60407, 0.020072]
Predicted label: 5
Correct prediction
Energy consumption = 139.884159 pJ
sum error= 336
Actual label: 6
Output voltages: [0.15431, 0.0054719, 0.0022376, 0.01961, 0.068681, 0.7059, 0.79791, 0.0010678, 0.54199, 0.0084253]
Predicted label: 6
Correct prediction
Energy consumption = 133.150716 pJ
sum error= 336
Actual label: 7
Output voltages: [0.021591, 0.042568, 0.76111, 0.13434, 0.0070271, 0.0010769, 0.0010807, 0.79879, 0.27926, 0.23438]
Predicted label: 7
Correct prediction
Energy consumption = 155.780839 pJ
sum error= 336
Actual label: 8
Output voltages: [0.0072393, 0.011709, 0.042123, 0.32195, 0.0015569, 0.52529, 0.048621, 0.011929, 0.79876, 0.030154]
Predicted label: 8
Correct prediction
Energy consumption = 147.660049 pJ
sum error= 336
Actual label: 9
Output voltages: [0.33468, 0.016641, 0.011402, 0.040926, 0.1061, 0.0090983, 0.0010866, 0.013447, 0.4549, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 147.056073 pJ
sum error= 336
Actual label: 8
Output voltages: [0.020989, 0.036149, 0.3585, 0.087768, 0.031573, 0.010121, 0.024912, 0.012083, 0.79873, 0.043055]
Predicted label: 8
Correct prediction
Energy consumption = 139.380560 pJ
sum error= 336
Actual label: 6
Output voltages: [0.064036, 0.049943, 0.05158, 0.02148, 0.15565, 0.39828, 0.79878, 0.0010708, 0.59076, 0.036464]
Predicted label: 6
Correct prediction
Energy consumption = 143.593695 pJ
sum error= 336
Actual label: 5
Output voltages: [0.062908, 0.0011415, 0.0089262, 0.072366, 0.11884, 0.79879, 0.030838, 0.027271, 0.77199, 0.058937]
Predicted label: 5
Correct prediction
Energy consumption = 144.895052 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 815 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 815 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 815 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.061858, 0.0058106, 0.019769, 0.037836, 0.064532, 0.03375, 0.0028353, 0.23244, 0.7343, 0.78704]
Predicted label: 9
Correct prediction
Energy consumption = 168.064463 pJ
sum error= 336
Actual label: 7
Output voltages: [0.09761, 0.050355, 0.74555, 0.047909, 0.0020779, 0.0010731, 0.0010858, 0.79878, 0.43145, 0.31122]
Predicted label: 7
Correct prediction
Energy consumption = 150.509970 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79879, 0.069233, 0.04704, 0.013505, 0.0066604, 0.0029003, 0.44333, 0.007525, 0.051461, 0.031095]
Predicted label: 0
Correct prediction
Energy consumption = 148.499658 pJ
sum error= 336
Actual label: 2
Output voltages: [0.28908, 0.014123, 0.7987, 0.092205, 0.012925, 0.0011169, 0.018585, 0.031852, 0.65879, 0.010915]
Predicted label: 2
Correct prediction
Energy consumption = 140.456734 pJ
sum error= 336
Actual label: 3
Output voltages: [0.38327, 0.021906, 0.11757, 0.79862, 0.025276, 0.036767, 0.012271, 0.038205, 0.65144, 0.16406]
Predicted label: 3
Correct prediction
Energy consumption = 139.253639 pJ
sum error= 336
Actual label: 4
Output voltages: [0.0073934, 0.020165, 0.2521, 0.029224, 0.79862, 0.0026337, 0.23726, 0.14794, 0.0091532, 0.024845]
Predicted label: 4
Correct prediction
Energy consumption = 153.621410 pJ
sum error= 336
Actual label: 3
Output voltages: [0.009702, 0.16311, 0.066518, 0.79223, 0.0073597, 0.039048, 0.011572, 0.0042665, 0.73819, 0.62983]
Predicted label: 3
Correct prediction
Energy consumption = 140.300272 pJ
sum error= 336
Actual label: 8
Output voltages: [0.0042696, 0.040154, 0.038104, 0.028414, 0.018516, 0.027649, 0.035209, 0.0035979, 0.79879, 0.30915]
Predicted label: 8
Correct prediction
Energy consumption = 141.510233 pJ
sum error= 336
Actual label: 5
Output voltages: [0.32294, 0.0011111, 0.0014671, 0.17983, 0.043114, 0.79877, 0.2619, 0.01295, 0.49733, 0.0043458]
Predicted label: 5
Correct prediction
Energy consumption = 139.630594 pJ
sum error= 336
Actual label: 1
Output voltages: [0.013021, 0.79879, 0.16856, 0.043646, 0.074506, 0.0011084, 0.60272, 0.064526, 0.034693, 0.042241]
Predicted label: 1
Correct prediction
Energy consumption = 157.394083 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 816 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 816 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 816 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.34917, 0.0022224, 0.0011065, 0.43558, 0.044539, 0.7976, 0.036791, 0.010161, 0.49022, 0.066025]
Predicted label: 5
Correct prediction
Energy consumption = 160.532895 pJ
sum error= 336
Actual label: 2
Output voltages: [0.20112, 0.02665, 0.79869, 0.23039, 0.040096, 0.0011258, 0.027685, 0.12592, 0.48326, 0.055818]
Predicted label: 2
Correct prediction
Energy consumption = 149.049365 pJ
sum error= 336
Actual label: 3
Output voltages: [0.13244, 0.0095181, 0.20689, 0.79867, 0.010802, 0.0072225, 0.012206, 0.037329, 0.65509, 0.038253]
Predicted label: 3
Correct prediction
Energy consumption = 139.920185 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79865, 0.046933, 0.030846, 0.0088616, 0.0086626, 0.0033341, 0.71102, 0.014632, 0.166, 0.037386]
Predicted label: 0
Correct prediction
Energy consumption = 140.591879 pJ
sum error= 336
Actual label: 1
Output voltages: [0.056421, 0.79747, 0.29591, 0.03737, 0.37357, 0.0010717, 0.49207, 0.0022205, 0.042098, 0.0032673]
Predicted label: 1
Correct prediction
Energy consumption = 154.425174 pJ
sum error= 336
Actual label: 2
Output voltages: [0.058587, 0.26983, 0.79866, 0.12018, 0.034169, 0.0011857, 0.053318, 0.25184, 0.027104, 0.025231]
Predicted label: 2
Correct prediction
Energy consumption = 134.294081 pJ
sum error= 336
Actual label: 1
Output voltages: [0.065348, 0.79864, 0.045498, 0.014566, 0.22001, 0.0014188, 0.30371, 0.0010792, 0.16956, 0.077742]
Predicted label: 1
Correct prediction
Energy consumption = 154.364040 pJ
sum error= 336
Actual label: 3
Output voltages: [0.11599, 0.023464, 0.14122, 0.79862, 0.050707, 0.01358, 0.017153, 0.028339, 0.66059, 0.069023]
Predicted label: 3
Correct prediction
Energy consumption = 148.658692 pJ
sum error= 336
Actual label: 2
Output voltages: [0.29767, 0.15699, 0.7987, 0.33214, 0.01194, 0.0012511, 0.16383, 0.023349, 0.20165, 0.028815]
Predicted label: 2
Correct prediction
Energy consumption = 133.674034 pJ
sum error= 336
Actual label: 6
Output voltages: [0.19772, 0.022507, 0.21371, 0.0041939, 0.31873, 0.15998, 0.79873, 0.0017506, 0.72149, 0.03048]
Predicted label: 6
Correct prediction
Energy consumption = 139.326486 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 817 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 817 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 817 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.046897, 0.0013018, 0.0010948, 0.23234, 0.038449, 0.79871, 0.44925, 0.047792, 0.63239, 0.0025459]
Predicted label: 5
Correct prediction
Energy consumption = 148.700482 pJ
sum error= 336
Actual label: 3
Output voltages: [0.050983, 0.0024019, 0.041597, 0.79878, 0.040044, 0.013254, 0.0016314, 0.028555, 0.72512, 0.05141]
Predicted label: 3
Correct prediction
Energy consumption = 145.275765 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79878, 0.080386, 0.10732, 0.0095931, 0.0072497, 0.0029455, 0.43508, 0.027736, 0.062973, 0.061891]
Predicted label: 0
Correct prediction
Energy consumption = 148.225541 pJ
sum error= 336
Actual label: 7
Output voltages: [0.2233, 0.0437, 0.72416, 0.032037, 0.0076964, 0.0010679, 0.0010852, 0.79867, 0.35554, 0.2185]
Predicted label: 7
Correct prediction
Energy consumption = 144.654831 pJ
sum error= 336
Actual label: 2
Output voltages: [0.7192, 0.0010804, 0.79341, 0.52464, 0.03236, 0.0010775, 0.011579, 0.10273, 0.77912, 0.049122]
Predicted label: 2
Correct prediction
Energy consumption = 136.590032 pJ
sum error= 336
Actual label: 7
Output voltages: [0.051064, 0.20849, 0.59923, 0.12175, 0.0050986, 0.0010801, 0.0010766, 0.79875, 0.18248, 0.35767]
Predicted label: 7
Correct prediction
Energy consumption = 146.883781 pJ
sum error= 336
Actual label: 4
Output voltages: [0.017732, 0.011887, 0.05805, 0.0013282, 0.79871, 0.0027459, 0.18761, 0.35269, 0.11256, 0.0090988]
Predicted label: 4
Correct prediction
Energy consumption = 145.881152 pJ
sum error= 336
Actual label: 6
Output voltages: [0.062769, 0.013401, 0.16907, 0.0027832, 0.41973, 0.11083, 0.79875, 0.0013789, 0.55379, 0.01717]
Predicted label: 6
Correct prediction
Energy consumption = 140.599713 pJ
sum error= 336
Actual label: 4
Output voltages: [0.024684, 0.0076493, 0.20523, 0.0055474, 0.79859, 0.01076, 0.055303, 0.09105, 0.045747, 0.01154]
Predicted label: 4
Correct prediction
Energy consumption = 142.225070 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79866, 0.034587, 0.27983, 0.020093, 0.0053866, 0.0034628, 0.29833, 0.022178, 0.03323, 0.034305]
Predicted label: 0
Correct prediction
Energy consumption = 147.676312 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 818 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 818 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 818 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.026498, 0.00109, 0.0010682, 0.15993, 0.037902, 0.79875, 0.4269, 0.061529, 0.76421, 0.0064906]
Predicted label: 5
Correct prediction
Energy consumption = 157.871121 pJ
sum error= 336
Actual label: 9
Output voltages: [0.24976, 0.00211, 0.022801, 0.021386, 0.04298, 0.17937, 0.0035372, 0.0040357, 0.56594, 0.78822]
Predicted label: 9
Correct prediction
Energy consumption = 143.777902 pJ
sum error= 336
Actual label: 9
Output voltages: [0.78937, 0.0012564, 0.016446, 0.030802, 0.44265, 0.011075, 0.014325, 0.0011474, 0.33633, 0.78668]
Predicted label: 0
Wrong prediction!
Energy consumption = 135.956167 pJ
sum error= 337
Actual label: 8
Output voltages: [0.047242, 0.00125, 0.0011423, 0.57206, 0.014411, 0.73718, 0.19543, 0.00134, 0.78501, 0.013681]
Predicted label: 8
Correct prediction
Energy consumption = 142.350242 pJ
sum error= 337
Actual label: 9
Output voltages: [0.21012, 0.010096, 0.012065, 0.02531, 0.10971, 0.013501, 0.0017801, 0.012444, 0.61541, 0.79579]
Predicted label: 9
Correct prediction
Energy consumption = 140.600738 pJ
sum error= 337
Actual label: 5
Output voltages: [0.020364, 0.0010659, 0.012548, 0.48516, 0.010436, 0.77588, 0.049736, 0.0055385, 0.76342, 0.20992]
Predicted label: 5
Correct prediction
Energy consumption = 148.665556 pJ
sum error= 337
Actual label: 3
Output voltages: [0.148, 0.0041839, 0.013217, 0.79871, 0.040273, 0.03697, 0.0017886, 0.063687, 0.70405, 0.048978]
Predicted label: 3
Correct prediction
Energy consumption = 130.907749 pJ
sum error= 337
Actual label: 1
Output voltages: [0.013267, 0.79879, 0.034802, 0.014976, 0.48617, 0.0010736, 0.065031, 0.027922, 0.04137, 0.0094737]
Predicted label: 1
Correct prediction
Energy consumption = 150.349559 pJ
sum error= 337
Actual label: 7
Output voltages: [0.045004, 0.18319, 0.28019, 0.019705, 0.0017607, 0.0016318, 0.0012786, 0.79866, 0.41533, 0.061669]
Predicted label: 7
Correct prediction
Energy consumption = 152.346806 pJ
sum error= 337
Actual label: 4
Output voltages: [0.0020519, 0.015447, 0.078049, 0.018343, 0.79866, 0.0033686, 0.25052, 0.4524, 0.013849, 0.026318]
Predicted label: 4
Correct prediction
Energy consumption = 144.177583 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 819 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 819 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 819 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.10497, 0.14371, 0.60716, 0.055299, 0.008527, 0.0010665, 0.0018106, 0.79879, 0.2685, 0.47313]
Predicted label: 7
Correct prediction
Energy consumption = 166.054862 pJ
sum error= 337
Actual label: 6
Output voltages: [0.14827, 0.058338, 0.3766, 0.0010757, 0.41126, 0.082205, 0.79876, 0.0010721, 0.55548, 0.0053561]
Predicted label: 6
Correct prediction
Energy consumption = 149.600724 pJ
sum error= 337
Actual label: 5
Output voltages: [0.045748, 0.0011176, 0.0015046, 0.25406, 0.048961, 0.79877, 0.30288, 0.24829, 0.77164, 0.0062414]
Predicted label: 5
Correct prediction
Energy consumption = 139.915323 pJ
sum error= 337
Actual label: 4
Output voltages: [0.012409, 0.010445, 0.37799, 0.0023945, 0.7986, 0.015618, 0.15226, 0.13662, 0.040657, 0.02938]
Predicted label: 4
Correct prediction
Energy consumption = 143.713110 pJ
sum error= 337
Actual label: 0
Output voltages: [0.79877, 0.018672, 0.4666, 0.022012, 0.037035, 0.0012095, 0.37547, 0.21764, 0.16589, 0.032434]
Predicted label: 0
Correct prediction
Energy consumption = 146.397180 pJ
sum error= 337
Actual label: 0
Output voltages: [0.79878, 0.13911, 0.02043, 0.012721, 0.011828, 0.0035635, 0.64461, 0.017504, 0.21232, 0.050222]
Predicted label: 0
Correct prediction
Energy consumption = 133.395258 pJ
sum error= 337
Actual label: 6
Output voltages: [0.28476, 0.023685, 0.29261, 0.0011422, 0.12207, 0.059749, 0.79834, 0.0010934, 0.26526, 0.0038658]
Predicted label: 6
Correct prediction
Energy consumption = 130.030373 pJ
sum error= 337
Actual label: 6
Output voltages: [0.20397, 0.0027377, 0.047101, 0.0019089, 0.16115, 0.6773, 0.79699, 0.0010868, 0.60948, 0.013974]
Predicted label: 6
Correct prediction
Energy consumption = 129.995932 pJ
sum error= 337
Actual label: 2
Output voltages: [0.026301, 0.019402, 0.79864, 0.17504, 0.038202, 0.0010661, 0.020364, 0.26699, 0.25469, 0.028258]
Predicted label: 2
Correct prediction
Energy consumption = 134.687816 pJ
sum error= 337
Actual label: 0
Output voltages: [0.79876, 0.12136, 0.03941, 0.014255, 0.0029587, 0.0083884, 0.63919, 0.05827, 0.14215, 0.049665]
Predicted label: 0
Correct prediction
Energy consumption = 137.286256 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 820 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 820 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 820 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.10586, 0.01956, 0.49098, 0.0010661, 0.33117, 0.17166, 0.79879, 0.0010698, 0.69289, 0.01244]
Predicted label: 6
Correct prediction
Energy consumption = 159.489499 pJ
sum error= 337
Actual label: 3
Output voltages: [0.42089, 0.0058426, 0.17066, 0.79879, 0.025006, 0.18781, 0.0027825, 0.015236, 0.73945, 0.20241]
Predicted label: 3
Correct prediction
Energy consumption = 142.909938 pJ
sum error= 337
Actual label: 7
Output voltages: [0.054807, 0.47994, 0.52199, 0.1401, 0.034495, 0.0011192, 0.0011429, 0.79879, 0.032654, 0.10729]
Predicted label: 7
Correct prediction
Energy consumption = 151.495070 pJ
sum error= 337
Actual label: 7
Output voltages: [0.76456, 0.019368, 0.015624, 0.030746, 0.18404, 0.0045621, 0.0011214, 0.79876, 0.32891, 0.0137]
Predicted label: 7
Correct prediction
Energy consumption = 138.263369 pJ
sum error= 337
Actual label: 4
Output voltages: [0.072374, 0.0042315, 0.40265, 0.065504, 0.79879, 0.0011756, 0.024699, 0.027596, 0.013925, 0.038248]
Predicted label: 4
Correct prediction
Energy consumption = 148.493647 pJ
sum error= 337
Actual label: 4
Output voltages: [0.0011567, 0.11571, 0.18378, 0.028723, 0.79873, 0.001564, 0.054277, 0.58193, 0.010865, 0.034603]
Predicted label: 4
Correct prediction
Energy consumption = 140.161991 pJ
sum error= 337
Actual label: 3
Output voltages: [0.23723, 0.014006, 0.11038, 0.79866, 0.034875, 0.017079, 0.011869, 0.030987, 0.6542, 0.057216]
Predicted label: 3
Correct prediction
Energy consumption = 142.186775 pJ
sum error= 337
Actual label: 9
Output voltages: [0.32238, 0.0095245, 0.023206, 0.13116, 0.081425, 0.01911, 0.002126, 0.039451, 0.69164, 0.79747]
Predicted label: 9
Correct prediction
Energy consumption = 143.360213 pJ
sum error= 337
Actual label: 2
Output voltages: [0.37664, 0.0085389, 0.79863, 0.032081, 0.0080262, 0.0010876, 0.035896, 0.070123, 0.64163, 0.0026978]
Predicted label: 2
Correct prediction
Energy consumption = 137.673968 pJ
sum error= 337
Actual label: 8
Output voltages: [0.098236, 0.0049371, 0.40631, 0.024612, 0.069062, 0.015479, 0.14424, 0.0019488, 0.79879, 0.021015]
Predicted label: 8
Correct prediction
Energy consumption = 149.541732 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 821 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 821 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 821 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.099271, 0.024724, 0.0073702, 0.21926, 0.74549, 0.35625, 0.27963, 0.004182, 0.070412, 0.79703]
Predicted label: 9
Correct prediction
Energy consumption = 169.829334 pJ
sum error= 337
Actual label: 6
Output voltages: [0.076176, 0.1845, 0.23871, 0.0046275, 0.25647, 0.18644, 0.79871, 0.0010869, 0.46292, 0.012407]
Predicted label: 6
Correct prediction
Energy consumption = 145.057288 pJ
sum error= 337
Actual label: 0
Output voltages: [0.78861, 0.025107, 0.11897, 0.0021429, 0.0021398, 0.0014131, 0.72707, 0.44662, 0.062251, 0.22142]
Predicted label: 0
Correct prediction
Energy consumption = 135.929109 pJ
sum error= 337
Actual label: 9
Output voltages: [0.63619, 0.010541, 0.040328, 0.025006, 0.64944, 0.0091617, 0.011811, 0.0018532, 0.053598, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 139.980856 pJ
sum error= 337
Actual label: 5
Output voltages: [0.045242, 0.0012259, 0.0010678, 0.077018, 0.1526, 0.79878, 0.23506, 0.035782, 0.77153, 0.019174]
Predicted label: 5
Correct prediction
Energy consumption = 144.527315 pJ
sum error= 337
Actual label: 3
Output voltages: [0.19027, 0.0045318, 0.063774, 0.79876, 0.013609, 0.031849, 0.0037805, 0.042351, 0.74133, 0.062894]
Predicted label: 3
Correct prediction
Energy consumption = 139.672986 pJ
sum error= 337
Actual label: 8
Output voltages: [0.036441, 0.025828, 0.22048, 0.37599, 0.014263, 0.012071, 0.07028, 0.0014069, 0.79873, 0.048722]
Predicted label: 8
Correct prediction
Energy consumption = 148.141030 pJ
sum error= 337
Actual label: 8
Output voltages: [0.081507, 0.027084, 0.1664, 0.21035, 0.0043201, 0.03013, 0.021572, 0.0016044, 0.79874, 0.58097]
Predicted label: 8
Correct prediction
Energy consumption = 141.222032 pJ
sum error= 337
Actual label: 7
Output voltages: [0.10376, 0.24643, 0.71654, 0.054322, 0.0071309, 0.00128, 0.005435, 0.79871, 0.055943, 0.26267]
Predicted label: 7
Correct prediction
Energy consumption = 154.173501 pJ
sum error= 337
Actual label: 1
Output voltages: [0.028447, 0.79863, 0.45882, 0.0082289, 0.27122, 0.0010939, 0.34216, 0.006909, 0.038841, 0.041134]
Predicted label: 1
Correct prediction
Energy consumption = 147.125398 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 822 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 822 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 822 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.017737, 0.011471, 0.11894, 0.0099409, 0.79873, 0.0015973, 0.038829, 0.07363, 0.021702, 0.005343]
Predicted label: 4
Correct prediction
Energy consumption = 165.772757 pJ
sum error= 337
Actual label: 0
Output voltages: [0.79873, 0.1305, 0.033081, 0.014567, 0.016218, 0.0068726, 0.56787, 0.027031, 0.19415, 0.026392]
Predicted label: 0
Correct prediction
Energy consumption = 149.820343 pJ
sum error= 337
Actual label: 4
Output voltages: [0.022792, 0.015094, 0.3576, 0.10254, 0.79878, 0.0021691, 0.10551, 0.048501, 0.010204, 0.055316]
Predicted label: 4
Correct prediction
Energy consumption = 153.978528 pJ
sum error= 337
Actual label: 8
Output voltages: [0.018355, 0.0084751, 0.46737, 0.039789, 0.029535, 0.011915, 0.26214, 0.00382, 0.79879, 0.016851]
Predicted label: 8
Correct prediction
Energy consumption = 144.056057 pJ
sum error= 337
Actual label: 5
Output voltages: [0.24799, 0.0010775, 0.0021067, 0.41316, 0.010137, 0.79871, 0.27664, 0.027524, 0.76769, 0.0041935]
Predicted label: 5
Correct prediction
Energy consumption = 141.106142 pJ
sum error= 337
Actual label: 2
Output voltages: [0.14483, 0.026625, 0.79866, 0.12154, 0.0027503, 0.0010968, 0.025771, 0.22064, 0.52243, 0.0040569]
Predicted label: 2
Correct prediction
Energy consumption = 134.859853 pJ
sum error= 337
Actual label: 3
Output voltages: [0.43142, 0.0025506, 0.36613, 0.79878, 0.010254, 0.0013168, 0.012853, 0.0037824, 0.71619, 0.0089009]
Predicted label: 3
Correct prediction
Energy consumption = 141.117987 pJ
sum error= 337
Actual label: 9
Output voltages: [0.6043, 0.0097981, 0.023228, 0.052706, 0.3059, 0.033162, 0.0034477, 0.022467, 0.29209, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 137.612324 pJ
sum error= 337
Actual label: 0
Output voltages: [0.77846, 0.014896, 0.27221, 0.036862, 0.73093, 0.0013246, 0.63766, 0.014225, 0.20273, 0.040717]
Predicted label: 0
Correct prediction
Energy consumption = 152.832582 pJ
sum error= 337
Actual label: 1
Output voltages: [0.2328, 0.79599, 0.050492, 0.0048502, 0.61232, 0.0077152, 0.27695, 0.0010886, 0.53863, 0.020628]
Predicted label: 1
Correct prediction
Energy consumption = 143.719086 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 823 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 823 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 823 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.65869, 0.014921, 0.0046415, 0.04052, 0.080981, 0.030158, 0.011243, 0.022377, 0.37761, 0.79667]
Predicted label: 9
Correct prediction
Energy consumption = 161.890243 pJ
sum error= 337
Actual label: 1
Output voltages: [0.0080808, 0.79878, 0.30781, 0.012057, 0.040662, 0.001304, 0.57409, 0.0010671, 0.23324, 0.022545]
Predicted label: 1
Correct prediction
Energy consumption = 150.881465 pJ
sum error= 337
Actual label: 5
Output voltages: [0.16639, 0.0011769, 0.0010804, 0.56331, 0.043505, 0.79877, 0.13485, 0.0066428, 0.52212, 0.041027]
Predicted label: 5
Correct prediction
Energy consumption = 146.545754 pJ
sum error= 337
Actual label: 1
Output voltages: [0.036946, 0.79879, 0.14527, 0.028421, 0.42611, 0.010352, 0.74932, 0.0013367, 0.29169, 0.013717]
Predicted label: 1
Correct prediction
Energy consumption = 156.066208 pJ
sum error= 337
Actual label: 7
Output voltages: [0.040276, 0.23449, 0.65387, 0.044369, 0.013186, 0.0010665, 0.0011238, 0.7987, 0.27275, 0.098144]
Predicted label: 7
Correct prediction
Energy consumption = 152.944342 pJ
sum error= 337
Actual label: 4
Output voltages: [0.021158, 0.0057878, 0.43351, 0.0012952, 0.79874, 0.0019358, 0.11422, 0.26356, 0.022854, 0.04552]
Predicted label: 4
Correct prediction
Energy consumption = 143.071561 pJ
sum error= 337
Actual label: 8
Output voltages: [0.0045524, 0.058871, 0.14855, 0.010141, 0.31024, 0.045957, 0.69953, 0.018937, 0.79488, 0.031982]
Predicted label: 8
Correct prediction
Energy consumption = 138.809207 pJ
sum error= 337
Actual label: 6
Output voltages: [0.1488, 0.12898, 0.30516, 0.019681, 0.22207, 0.063198, 0.79879, 0.0010993, 0.55051, 0.050346]
Predicted label: 6
Correct prediction
Energy consumption = 142.199213 pJ
sum error= 337
Actual label: 2
Output voltages: [0.27358, 0.016604, 0.79866, 0.067704, 0.012808, 0.0010977, 0.049658, 0.17377, 0.46849, 0.018711]
Predicted label: 2
Correct prediction
Energy consumption = 135.840451 pJ
sum error= 337
Actual label: 1
Output voltages: [0.076315, 0.79773, 0.011095, 0.046733, 0.7422, 0.003943, 0.70145, 0.0011165, 0.54406, 0.14253]
Predicted label: 1
Correct prediction
Energy consumption = 151.334985 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 824 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 824 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 824 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.068136, 0.0034191, 0.082991, 0.0069615, 0.45703, 0.39693, 0.79858, 0.0010723, 0.75124, 0.0091775]
Predicted label: 6
Correct prediction
Energy consumption = 159.642673 pJ
sum error= 337
Actual label: 8
Output voltages: [0.28325, 0.17461, 0.59313, 0.016504, 0.25977, 0.0024851, 0.13134, 0.0012232, 0.79852, 0.21513]
Predicted label: 8
Correct prediction
Energy consumption = 151.512911 pJ
sum error= 337
Actual label: 8
Output voltages: [0.055276, 0.014573, 0.060319, 0.026276, 0.038014, 0.18837, 0.045106, 0.017219, 0.79879, 0.02337]
Predicted label: 8
Correct prediction
Energy consumption = 144.945848 pJ
sum error= 337
Actual label: 0
Output voltages: [0.79723, 0.001235, 0.13359, 0.001068, 0.25117, 0.0082166, 0.72087, 0.25899, 0.042505, 0.006794]
Predicted label: 0
Correct prediction
Energy consumption = 149.140397 pJ
sum error= 337
Actual label: 1
Output voltages: [0.0070328, 0.79808, 0.045911, 0.0098006, 0.72729, 0.0058876, 0.24867, 0.0010667, 0.19475, 0.20845]
Predicted label: 1
Correct prediction
Energy consumption = 146.615216 pJ
sum error= 337
Actual label: 2
Output voltages: [0.12619, 0.031521, 0.79863, 0.039614, 0.029225, 0.0011566, 0.035879, 0.27705, 0.21631, 0.025965]
Predicted label: 2
Correct prediction
Energy consumption = 134.503647 pJ
sum error= 337
Actual label: 3
Output voltages: [0.06139, 0.006019, 0.032672, 0.79708, 0.050178, 0.58037, 0.0042119, 0.0037301, 0.74588, 0.39651]
Predicted label: 3
Correct prediction
Energy consumption = 140.898722 pJ
sum error= 337
Actual label: 4
Output voltages: [0.010585, 0.0085276, 0.14386, 0.0014334, 0.79878, 0.0052286, 0.24076, 0.28836, 0.44725, 0.0015559]
Predicted label: 4
Correct prediction
Energy consumption = 139.142223 pJ
sum error= 337
Actual label: 7
Output voltages: [0.097859, 0.12009, 0.2733, 0.080503, 0.0016866, 0.0011951, 0.0010693, 0.79874, 0.62365, 0.029573]
Predicted label: 7
Correct prediction
Energy consumption = 149.625650 pJ
sum error= 337
Actual label: 8
Output voltages: [0.11791, 0.042795, 0.37946, 0.016187, 0.008925, 0.012071, 0.017147, 0.0067974, 0.79876, 0.20321]
Predicted label: 8
Correct prediction
Energy consumption = 136.173581 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 825 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 825 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 825 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.47386, 0.012059, 0.029916, 0.041694, 0.26133, 0.027328, 0.007268, 0.010157, 0.28157, 0.79867]
Predicted label: 9
Correct prediction
Energy consumption = 160.583296 pJ
sum error= 337
Actual label: 0
Output voltages: [0.79871, 0.19022, 0.027238, 0.03002, 0.03036, 0.0070415, 0.51661, 0.0064717, 0.069328, 0.029951]
Predicted label: 0
Correct prediction
Energy consumption = 147.998115 pJ
sum error= 337
Actual label: 1
Output voltages: [0.014898, 0.79866, 0.20595, 0.014999, 0.46168, 0.0024141, 0.063521, 0.0157, 0.015536, 0.0488]
Predicted label: 1
Correct prediction
Energy consumption = 154.516066 pJ
sum error= 337
Actual label: 2
Output voltages: [0.038826, 0.034665, 0.79861, 0.06535, 0.03644, 0.0011015, 0.031019, 0.040481, 0.36093, 0.19049]
Predicted label: 2
Correct prediction
Energy consumption = 132.262321 pJ
sum error= 337
Actual label: 3
Output voltages: [0.181, 0.022817, 0.31449, 0.79877, 0.0042136, 0.017299, 0.032447, 0.030821, 0.7823, 0.00252]
Predicted label: 3
Correct prediction
Energy consumption = 141.945074 pJ
sum error= 337
Actual label: 4
Output voltages: [0.015927, 0.0013291, 0.41597, 0.018472, 0.79729, 0.0040826, 0.25255, 0.01695, 0.59063, 0.0012053]
Predicted label: 4
Correct prediction
Energy consumption = 141.652042 pJ
sum error= 337
Actual label: 6
Output voltages: [0.041573, 0.019036, 0.29252, 0.0071666, 0.74293, 0.13144, 0.79877, 0.0016515, 0.44097, 0.0056455]
Predicted label: 6
Correct prediction
Energy consumption = 132.267495 pJ
sum error= 337
Actual label: 7
Output voltages: [0.033269, 0.021657, 0.76853, 0.022805, 0.0025362, 0.001066, 0.0010735, 0.79864, 0.58836, 0.059602]
Predicted label: 7
Correct prediction
Energy consumption = 156.041530 pJ
sum error= 337
Actual label: 8
Output voltages: [0.023825, 0.0039877, 0.02755, 0.047149, 0.011385, 0.097387, 0.015058, 0.018174, 0.7987, 0.011975]
Predicted label: 8
Correct prediction
Energy consumption = 138.194288 pJ
sum error= 337
Actual label: 9
Output voltages: [0.18551, 0.0010938, 0.021482, 0.026636, 0.088352, 0.12536, 0.0055006, 0.49025, 0.75311, 0.79641]
Predicted label: 9
Correct prediction
Energy consumption = 140.646042 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 826 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 826 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 826 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79845, 0.013465, 0.23223, 0.0067193, 0.05835, 0.0027208, 0.45307, 0.031203, 0.0193, 0.51465]
Predicted label: 0
Correct prediction
Energy consumption = 156.317039 pJ
sum error= 337
Actual label: 1
Output voltages: [0.06193, 0.79879, 0.31564, 0.016565, 0.038369, 0.0041197, 0.75019, 0.0010743, 0.22116, 0.0030993]
Predicted label: 1
Correct prediction
Energy consumption = 152.888719 pJ
sum error= 337
Actual label: 2
Output voltages: [0.14756, 0.14412, 0.79879, 0.43278, 0.020663, 0.0011555, 0.0087073, 0.18944, 0.047827, 0.0074363]
Predicted label: 2
Correct prediction
Energy consumption = 134.362956 pJ
sum error= 337
Actual label: 3
Output voltages: [0.19838, 0.018075, 0.11757, 0.7987, 0.027763, 0.0021957, 0.006654, 0.026741, 0.53975, 0.072956]
Predicted label: 3
Correct prediction
Energy consumption = 140.904805 pJ
sum error= 337
Actual label: 4
Output voltages: [0.042244, 0.008801, 0.58979, 0.048058, 0.79805, 0.0011221, 0.024735, 0.0301, 0.25541, 0.009199]
Predicted label: 4
Correct prediction
Energy consumption = 141.173815 pJ
sum error= 337
Actual label: 7
Output voltages: [0.42432, 0.0014507, 0.12443, 0.38489, 0.0010956, 0.010284, 0.0011872, 0.79795, 0.65143, 0.29478]
Predicted label: 7
Correct prediction
Energy consumption = 145.361280 pJ
sum error= 337
Actual label: 8
Output voltages: [0.018833, 0.019045, 0.043766, 0.017378, 0.015393, 0.054974, 0.022826, 0.017688, 0.7987, 0.050771]
Predicted label: 8
Correct prediction
Energy consumption = 141.540834 pJ
sum error= 337
Actual label: 9
Output voltages: [0.39911, 0.0013249, 0.029941, 0.0121, 0.45892, 0.054865, 0.0095032, 0.14388, 0.43259, 0.78936]
Predicted label: 9
Correct prediction
Energy consumption = 144.426443 pJ
sum error= 337
Actual label: 1
Output voltages: [0.0018529, 0.79872, 0.15992, 0.022184, 0.048546, 0.0010659, 0.35117, 0.0024587, 0.058075, 0.015682]
Predicted label: 1
Correct prediction
Energy consumption = 150.864376 pJ
sum error= 337
Actual label: 4
Output voltages: [0.0019135, 0.022521, 0.073182, 0.049616, 0.79865, 0.0020469, 0.016248, 0.050041, 0.028173, 0.021313]
Predicted label: 4
Correct prediction
Energy consumption = 147.719620 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 827 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 827 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 827 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.35284, 0.0031153, 0.0011139, 0.034267, 0.10976, 0.79877, 0.54767, 0.033828, 0.52566, 0.01791]
Predicted label: 5
Correct prediction
Energy consumption = 163.274370 pJ
sum error= 337
Actual label: 3
Output voltages: [0.03399, 0.0085634, 0.05112, 0.79879, 0.011346, 0.02518, 0.0030411, 0.075804, 0.69959, 0.052281]
Predicted label: 3
Correct prediction
Energy consumption = 145.105745 pJ
sum error= 337
Actual label: 3
Output voltages: [0.035165, 0.030995, 0.15786, 0.79879, 0.0052837, 0.0079208, 0.0020329, 0.0076316, 0.7496, 0.017167]
Predicted label: 3
Correct prediction
Energy consumption = 135.258678 pJ
sum error= 337
Actual label: 0
Output voltages: [0.79854, 0.0037348, 0.29312, 0.0021501, 0.011353, 0.0010698, 0.16309, 0.4358, 0.029695, 0.22171]
Predicted label: 0
Correct prediction
Energy consumption = 142.777123 pJ
sum error= 337
Actual label: 9
Output voltages: [0.32185, 0.005431, 0.018314, 0.02952, 0.063886, 0.013898, 0.0091968, 0.01327, 0.73574, 0.79544]
Predicted label: 9
Correct prediction
Energy consumption = 133.995534 pJ
sum error= 337
Actual label: 5
Output voltages: [0.6382, 0.0012739, 0.0011355, 0.12743, 0.0037101, 0.79841, 0.51318, 0.014547, 0.58649, 0.0019328]
Predicted label: 5
Correct prediction
Energy consumption = 146.324672 pJ
sum error= 337
Actual label: 4
Output voltages: [0.011389, 0.010749, 0.54644, 0.0024474, 0.7986, 0.001594, 0.052787, 0.031427, 0.31506, 0.022486]
Predicted label: 4
Correct prediction
Energy consumption = 146.771394 pJ
sum error= 337
Actual label: 3
Output voltages: [0.028217, 0.0097332, 0.034752, 0.79877, 0.070901, 0.21152, 0.011719, 0.024577, 0.52857, 0.045801]
Predicted label: 3
Correct prediction
Energy consumption = 141.852622 pJ
sum error= 337
Actual label: 0
Output voltages: [0.79871, 0.0091524, 0.50958, 0.098789, 0.011879, 0.0018652, 0.027623, 0.011351, 0.028416, 0.367]
Predicted label: 0
Correct prediction
Energy consumption = 134.723499 pJ
sum error= 337
Actual label: 8
Output voltages: [0.023667, 0.0028559, 0.15629, 0.017677, 0.0018103, 0.006522, 0.048437, 0.52052, 0.79787, 0.024543]
Predicted label: 8
Correct prediction
Energy consumption = 140.238571 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 828 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 828 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 828 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.012475, 0.027374, 0.22569, 0.015109, 0.79875, 0.020332, 0.036273, 0.026058, 0.19125, 0.0058256]
Predicted label: 4
Correct prediction
Energy consumption = 164.513341 pJ
sum error= 337
Actual label: 6
Output voltages: [0.093503, 0.056532, 0.16784, 0.048982, 0.09383, 0.16958, 0.79603, 0.014332, 0.68899, 0.0010661]
Predicted label: 6
Correct prediction
Energy consumption = 143.861692 pJ
sum error= 337
Actual label: 7
Output voltages: [0.11061, 0.045539, 0.67159, 0.037806, 0.0028304, 0.0010872, 0.0010728, 0.79879, 0.59219, 0.21172]
Predicted label: 7
Correct prediction
Energy consumption = 144.688058 pJ
sum error= 337
Actual label: 0
Output voltages: [0.79877, 0.019969, 0.1953, 0.01693, 0.035788, 0.0018818, 0.64791, 0.06296, 0.035185, 0.039045]
Predicted label: 0
Correct prediction
Energy consumption = 139.636218 pJ
sum error= 337
Actual label: 7
Output voltages: [0.65107, 0.0061761, 0.0071504, 0.35475, 0.0010739, 0.26629, 0.0010665, 0.7986, 0.77809, 0.19578]
Predicted label: 7
Correct prediction
Energy consumption = 144.878333 pJ
sum error= 337
Actual label: 7
Output voltages: [0.026765, 0.24945, 0.66244, 0.049253, 0.003895, 0.0010665, 0.0010685, 0.79874, 0.38097, 0.29145]
Predicted label: 7
Correct prediction
Energy consumption = 144.688124 pJ
sum error= 337
Actual label: 1
Output voltages: [0.021611, 0.79754, 0.079161, 0.026829, 0.19323, 0.0010931, 0.0060938, 0.1073, 0.44578, 0.064516]
Predicted label: 1
Correct prediction
Energy consumption = 147.793722 pJ
sum error= 337
Actual label: 6
Output voltages: [0.26877, 0.011248, 0.025531, 0.023096, 0.045464, 0.39417, 0.78617, 0.019117, 0.7519, 0.0010684]
Predicted label: 6
Correct prediction
Energy consumption = 147.733887 pJ
sum error= 337
Actual label: 9
Output voltages: [0.024336, 0.018791, 0.016629, 0.035445, 0.11584, 0.35205, 0.047233, 0.28569, 0.53349, 0.79471]
Predicted label: 9
Correct prediction
Energy consumption = 147.123464 pJ
sum error= 337
Actual label: 1
Output voltages: [0.0080973, 0.79879, 0.026067, 0.038859, 0.48515, 0.0010711, 0.056788, 0.012732, 0.06268, 0.16342]
Predicted label: 1
Correct prediction
Energy consumption = 155.287291 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 829 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 829 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 829 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.46115, 0.039171, 0.066155, 0.79869, 0.0048304, 0.058144, 0.01999, 0.0052765, 0.62171, 0.017226]
Predicted label: 3
Correct prediction
Energy consumption = 168.055485 pJ
sum error= 337
Actual label: 6
Output voltages: [0.042102, 0.019218, 0.3992, 0.0012027, 0.33121, 0.047516, 0.79878, 0.001371, 0.73933, 0.0012869]
Predicted label: 6
Correct prediction
Energy consumption = 147.098863 pJ
sum error= 337
Actual label: 2
Output voltages: [0.42426, 0.041873, 0.79879, 0.091765, 0.011498, 0.0012682, 0.20697, 0.26556, 0.32688, 0.0018333]
Predicted label: 2
Correct prediction
Energy consumption = 144.661194 pJ
sum error= 337
Actual label: 3
Output voltages: [0.026351, 0.07709, 0.11411, 0.79879, 0.012727, 0.0049458, 0.0048457, 0.014088, 0.72396, 0.18563]
Predicted label: 3
Correct prediction
Energy consumption = 143.307729 pJ
sum error= 337
Actual label: 8
Output voltages: [0.03546, 0.008165, 0.21641, 0.029636, 0.024554, 0.026171, 0.013508, 0.02124, 0.79874, 0.071671]
Predicted label: 8
Correct prediction
Energy consumption = 146.684969 pJ
sum error= 337
Actual label: 2
Output voltages: [0.49834, 0.0013427, 0.79861, 0.18077, 0.024803, 0.0010768, 0.054614, 0.37348, 0.77386, 0.010717]
Predicted label: 2
Correct prediction
Energy consumption = 138.259798 pJ
sum error= 337
Actual label: 3
Output voltages: [0.13036, 0.0018507, 0.40408, 0.79872, 0.035724, 0.19615, 0.0063322, 0.031196, 0.761, 0.038429]
Predicted label: 3
Correct prediction
Energy consumption = 137.752879 pJ
sum error= 337
Actual label: 8
Output voltages: [0.010291, 0.028986, 0.215, 0.031144, 0.028474, 0.017244, 0.046941, 0.017576, 0.79879, 0.093734]
Predicted label: 8
Correct prediction
Energy consumption = 138.128610 pJ
sum error= 337
Actual label: 9
Output voltages: [0.12712, 0.0086802, 0.010616, 0.022791, 0.33269, 0.039783, 0.019961, 0.014148, 0.45998, 0.79769]
Predicted label: 9
Correct prediction
Energy consumption = 136.182856 pJ
sum error= 337
Actual label: 5
Output voltages: [0.40833, 0.0010748, 0.0018118, 0.052829, 0.019657, 0.79878, 0.63135, 0.049301, 0.77901, 0.0020351]
Predicted label: 5
Correct prediction
Energy consumption = 140.316796 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 830 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 830 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 830 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.026046, 0.0017118, 0.033944, 0.27883, 0.0094797, 0.029616, 0.016208, 0.0076751, 0.79874, 0.061493]
Predicted label: 8
Correct prediction
Energy consumption = 165.162564 pJ
sum error= 337
Actual label: 8
Output voltages: [0.031133, 0.0055753, 0.035745, 0.0891, 0.015954, 0.11143, 0.01338, 0.0064881, 0.79875, 0.1324]
Predicted label: 8
Correct prediction
Energy consumption = 136.550672 pJ
sum error= 337
Actual label: 7
Output voltages: [0.73988, 0.012168, 0.093927, 0.542, 0.014844, 0.0014909, 0.0010771, 0.79877, 0.32883, 0.37751]
Predicted label: 7
Correct prediction
Energy consumption = 148.400720 pJ
sum error= 337
Actual label: 1
Output voltages: [0.01659, 0.79875, 0.040051, 0.0062768, 0.40544, 0.0010989, 0.21824, 0.0012462, 0.035162, 0.21778]
Predicted label: 1
Correct prediction
Energy consumption = 143.479760 pJ
sum error= 337
Actual label: 7
Output voltages: [0.78739, 0.020394, 0.41961, 0.39301, 0.0012716, 0.16349, 0.0038085, 0.74287, 0.77627, 0.046174]
Predicted label: 0
Wrong prediction!
Energy consumption = 147.336022 pJ
sum error= 338
Actual label: 1
Output voltages: [0.011678, 0.7987, 0.078364, 0.0047985, 0.028862, 0.0021083, 0.30888, 0.0038483, 0.34867, 0.010251]
Predicted label: 1
Correct prediction
Energy consumption = 143.664804 pJ
sum error= 338
Actual label: 1
Output voltages: [0.35482, 0.79795, 0.19275, 0.0011191, 0.51729, 0.0020992, 0.18092, 0.0010745, 0.22694, 0.022142]
Predicted label: 1
Correct prediction
Energy consumption = 135.124443 pJ
sum error= 338
Actual label: 0
Output voltages: [0.79867, 0.089407, 0.040437, 0.014662, 0.012843, 0.012545, 0.49363, 0.022495, 0.12166, 0.031948]
Predicted label: 0
Correct prediction
Energy consumption = 142.956477 pJ
sum error= 338
Actual label: 3
Output voltages: [0.20829, 0.016868, 0.091366, 0.79869, 0.029084, 0.0054431, 0.023234, 0.049001, 0.71249, 0.038937]
Predicted label: 3
Correct prediction
Energy consumption = 143.850293 pJ
sum error= 338
Actual label: 4
Output voltages: [0.008821, 0.010136, 0.6549, 0.016346, 0.79655, 0.0012618, 0.080632, 0.0062745, 0.67491, 0.0083332]
Predicted label: 4
Correct prediction
Energy consumption = 141.256688 pJ
sum error= 338
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 831 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 831 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 831 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.030717, 0.0343, 0.79872, 0.30607, 0.01529, 0.0012026, 0.11811, 0.037141, 0.2687, 0.014579]
Predicted label: 2
Correct prediction
Energy consumption = 150.570291 pJ
sum error= 338
Actual label: 6
Output voltages: [0.050257, 0.023076, 0.68872, 0.0010917, 0.65441, 0.045328, 0.79828, 0.0023956, 0.24159, 0.0012382]
Predicted label: 6
Correct prediction
Energy consumption = 135.604669 pJ
sum error= 338
Actual label: 4
Output voltages: [0.0075532, 0.023579, 0.04387, 0.00147, 0.79866, 0.013173, 0.033108, 0.45757, 0.057439, 0.021888]
Predicted label: 4
Correct prediction
Energy consumption = 144.010189 pJ
sum error= 338
Actual label: 7
Output voltages: [0.048751, 0.014045, 0.13904, 0.12263, 0.0044825, 0.0020008, 0.0010918, 0.7986, 0.057779, 0.29668]
Predicted label: 7
Correct prediction
Energy consumption = 149.517429 pJ
sum error= 338
Actual label: 4
Output voltages: [0.016528, 0.039298, 0.04687, 0.040056, 0.7987, 0.0014963, 0.041582, 0.028027, 0.03417, 0.02373]
Predicted label: 4
Correct prediction
Energy consumption = 150.195578 pJ
sum error= 338
Actual label: 2
Output voltages: [0.091826, 0.0034754, 0.79879, 0.032199, 0.018667, 0.0010844, 0.022001, 0.23208, 0.7274, 0.009341]
Predicted label: 2
Correct prediction
Energy consumption = 140.112866 pJ
sum error= 338
Actual label: 7
Output voltages: [0.57612, 0.079379, 0.76327, 0.031986, 0.0011096, 0.0023899, 0.0026474, 0.77676, 0.58993, 0.02519]
Predicted label: 7
Correct prediction
Energy consumption = 141.480928 pJ
sum error= 338
Actual label: 4
Output voltages: [0.023312, 0.0042258, 0.46503, 0.043637, 0.79879, 0.0030711, 0.0047921, 0.0030294, 0.29746, 0.038032]
Predicted label: 4
Correct prediction
Energy consumption = 143.078229 pJ
sum error= 338
Actual label: 2
Output voltages: [0.44038, 0.0034009, 0.79855, 0.13966, 0.0029537, 0.001179, 0.012908, 0.27094, 0.7615, 0.0054581]
Predicted label: 2
Correct prediction
Energy consumption = 143.015219 pJ
sum error= 338
Actual label: 9
Output voltages: [0.17363, 0.003619, 0.0011931, 0.065584, 0.048936, 0.18574, 0.028722, 0.011648, 0.54622, 0.78398]
Predicted label: 9
Correct prediction
Energy consumption = 146.734634 pJ
sum error= 338
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 832 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 832 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 832 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.39355, 0.001221, 0.7972, 0.29821, 0.0032994, 0.0011676, 0.014398, 0.53026, 0.73012, 0.0088832]
Predicted label: 2
Correct prediction
Energy consumption = 157.245115 pJ
sum error= 338
Actual label: 7
Output voltages: [0.60379, 0.0091327, 0.063863, 0.74116, 0.0040164, 0.024537, 0.0011504, 0.79867, 0.74888, 0.22218]
Predicted label: 7
Correct prediction
Energy consumption = 149.203659 pJ
sum error= 338
Actual label: 9
Output voltages: [0.26471, 0.0013414, 0.0055501, 0.021298, 0.34254, 0.26762, 0.1427, 0.047849, 0.049329, 0.7938]
Predicted label: 9
Correct prediction
Energy consumption = 141.222753 pJ
sum error= 338
Actual label: 2
Output voltages: [0.6743, 0.059231, 0.7986, 0.42703, 0.0038878, 0.0011539, 0.093096, 0.0031046, 0.77229, 0.19148]
Predicted label: 2
Correct prediction
Energy consumption = 145.874430 pJ
sum error= 338
Actual label: 1
Output voltages: [0.0028599, 0.79877, 0.22586, 0.052373, 0.36893, 0.0010696, 0.41887, 0.011958, 0.048966, 0.031985]
Predicted label: 1
Correct prediction
Energy consumption = 148.970704 pJ
sum error= 338
Actual label: 0
Output voltages: [0.68936, 0.13909, 0.1575, 0.023842, 0.036075, 0.0044325, 0.79595, 0.010722, 0.055114, 0.003588]
Predicted label: 6
Wrong prediction!
Energy consumption = 153.198265 pJ
sum error= 339
Actual label: 6
Output voltages: [0.14506, 0.081944, 0.66539, 0.0010866, 0.4852, 0.46597, 0.77336, 0.032467, 0.11292, 0.0011981]
Predicted label: 6
Correct prediction
Energy consumption = 136.519529 pJ
sum error= 339
Actual label: 5
Output voltages: [0.040899, 0.0013711, 0.0012752, 0.58402, 0.052296, 0.79872, 0.31303, 0.010484, 0.78314, 0.041133]
Predicted label: 5
Correct prediction
Energy consumption = 137.075093 pJ
sum error= 339
Actual label: 3
Output voltages: [0.5103, 0.013064, 0.072605, 0.79868, 0.012025, 0.004636, 0.017591, 0.0076931, 0.4266, 0.037671]
Predicted label: 3
Correct prediction
Energy consumption = 142.346063 pJ
sum error= 339
Actual label: 4
Output voltages: [0.054569, 0.012581, 0.11835, 0.0026355, 0.79876, 0.0022028, 0.061372, 0.01022, 0.090415, 0.0030731]
Predicted label: 4
Correct prediction
Energy consumption = 143.283927 pJ
sum error= 339
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 833 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 833 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 833 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.094114, 0.001275, 0.23973, 0.019476, 0.0010688, 0.13191, 0.013717, 0.019465, 0.79878, 0.054945]
Predicted label: 8
Correct prediction
Energy consumption = 165.097844 pJ
sum error= 339
Actual label: 5
Output voltages: [0.025549, 0.0010672, 0.0010764, 0.37131, 0.042851, 0.79872, 0.26319, 0.031397, 0.66736, 0.0087442]
Predicted label: 5
Correct prediction
Energy consumption = 142.957889 pJ
sum error= 339
Actual label: 9
Output voltages: [0.28656, 0.0013069, 0.018823, 0.31376, 0.021277, 0.01082, 0.0010723, 0.47034, 0.74245, 0.76451]
Predicted label: 9
Correct prediction
Energy consumption = 148.599489 pJ
sum error= 339
Actual label: 6
Output voltages: [0.084222, 0.046371, 0.1927, 0.0016418, 0.22383, 0.18773, 0.79876, 0.0019206, 0.47836, 0.0047936]
Predicted label: 6
Correct prediction
Energy consumption = 144.131034 pJ
sum error= 339
Actual label: 9
Output voltages: [0.045516, 0.002686, 0.0068099, 0.023936, 0.43667, 0.025388, 0.025686, 0.0067409, 0.43527, 0.79234]
Predicted label: 9
Correct prediction
Energy consumption = 146.665823 pJ
sum error= 339
Actual label: 0
Output voltages: [0.79483, 0.020757, 0.0096411, 0.0024038, 0.15996, 0.10278, 0.78628, 0.04549, 0.12102, 0.012703]
Predicted label: 0
Correct prediction
Energy consumption = 147.004589 pJ
sum error= 339
Actual label: 6
Output voltages: [0.20355, 0.0051874, 0.25371, 0.0018015, 0.54883, 0.03177, 0.79879, 0.0010701, 0.40608, 0.022372]
Predicted label: 6
Correct prediction
Energy consumption = 130.700991 pJ
sum error= 339
Actual label: 3
Output voltages: [0.019413, 0.013768, 0.061333, 0.79879, 0.016768, 0.0045773, 0.0057208, 0.026756, 0.76213, 0.042075]
Predicted label: 3
Correct prediction
Energy consumption = 144.443389 pJ
sum error= 339
Actual label: 0
Output voltages: [0.79878, 0.12396, 0.022973, 0.012884, 0.016075, 0.0021415, 0.72804, 0.0060658, 0.17823, 0.064539]
Predicted label: 0
Correct prediction
Energy consumption = 151.222199 pJ
sum error= 339
Actual label: 8
Output voltages: [0.016806, 0.026758, 0.63851, 0.0024272, 0.4004, 0.0068049, 0.75916, 0.0019337, 0.60073, 0.0041539]
Predicted label: 6
Wrong prediction!
Energy consumption = 128.433897 pJ
sum error= 340
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 834 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 834 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 834 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.015313, 0.79869, 0.43183, 0.066401, 0.022201, 0.0010737, 0.4723, 0.00375, 0.21901, 0.053083]
Predicted label: 1
Correct prediction
Energy consumption = 174.527213 pJ
sum error= 340
Actual label: 6
Output voltages: [0.044807, 0.10319, 0.43556, 0.0054989, 0.075367, 0.13458, 0.79877, 0.0014128, 0.62822, 0.013832]
Predicted label: 6
Correct prediction
Energy consumption = 141.191755 pJ
sum error= 340
Actual label: 0
Output voltages: [0.79676, 0.030973, 0.45232, 0.0047752, 0.036301, 0.0010982, 0.63991, 0.022659, 0.031113, 0.039457]
Predicted label: 0
Correct prediction
Energy consumption = 137.386345 pJ
sum error= 340
Actual label: 0
Output voltages: [0.79877, 0.043397, 0.02945, 0.019099, 0.011632, 0.0071852, 0.40032, 0.015895, 0.085461, 0.043838]
Predicted label: 0
Correct prediction
Energy consumption = 138.952999 pJ
sum error= 340
Actual label: 1
Output voltages: [0.0096412, 0.79878, 0.05224, 0.017205, 0.35156, 0.0010971, 0.41058, 0.0064752, 0.21015, 0.048901]
Predicted label: 1
Correct prediction
Energy consumption = 161.967979 pJ
sum error= 340
Actual label: 2
Output voltages: [0.31278, 0.0088138, 0.79875, 0.36294, 0.065471, 0.0011512, 0.02273, 0.39418, 0.20024, 0.0095206]
Predicted label: 2
Correct prediction
Energy consumption = 143.027713 pJ
sum error= 340
Actual label: 3
Output voltages: [0.044029, 0.0024288, 0.21645, 0.79879, 0.049806, 0.04496, 0.0023144, 0.06198, 0.70358, 0.28816]
Predicted label: 3
Correct prediction
Energy consumption = 145.019927 pJ
sum error= 340
Actual label: 4
Output voltages: [0.0035253, 0.012328, 0.10903, 0.02117, 0.79863, 0.0027236, 0.05258, 0.026416, 0.03611, 0.031045]
Predicted label: 4
Correct prediction
Energy consumption = 149.844442 pJ
sum error= 340
Actual label: 5
Output voltages: [0.036419, 0.0011363, 0.016938, 0.2464, 0.019947, 0.79674, 0.42044, 0.01694, 0.78613, 0.0024047]
Predicted label: 5
Correct prediction
Energy consumption = 145.475328 pJ
sum error= 340
Actual label: 6
Output voltages: [0.046192, 0.030834, 0.48323, 0.0011199, 0.5688, 0.012553, 0.79879, 0.0010887, 0.078522, 0.008341]
Predicted label: 6
Correct prediction
Energy consumption = 137.120250 pJ
sum error= 340
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 835 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 835 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 835 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.054989, 0.071492, 0.04133, 0.022194, 0.0057782, 0.0028608, 0.0010691, 0.79868, 0.21451, 0.33895]
Predicted label: 7
Correct prediction
Energy consumption = 170.683861 pJ
sum error= 340
Actual label: 0
Output voltages: [0.79797, 0.054583, 0.094703, 0.011328, 0.0012095, 0.0012202, 0.49655, 0.033181, 0.1491, 0.10484]
Predicted label: 0
Correct prediction
Energy consumption = 140.349864 pJ
sum error= 340
Actual label: 1
Output voltages: [0.0096176, 0.79857, 0.040828, 0.03283, 0.0073415, 0.0011388, 0.43765, 0.005127, 0.45953, 0.030432]
Predicted label: 1
Correct prediction
Energy consumption = 158.644956 pJ
sum error= 340
Actual label: 2
Output voltages: [0.22857, 0.019625, 0.79081, 0.010881, 0.78547, 0.0013825, 0.05692, 0.03632, 0.11395, 0.13603]
Predicted label: 2
Correct prediction
Energy consumption = 134.011423 pJ
sum error= 340
Actual label: 3
Output voltages: [0.24096, 0.0041458, 0.012454, 0.79868, 0.015129, 0.54905, 0.011808, 0.058737, 0.49895, 0.0019636]
Predicted label: 3
Correct prediction
Energy consumption = 148.434533 pJ
sum error= 340
Actual label: 4
Output voltages: [0.011053, 0.0066943, 0.43014, 0.0027014, 0.79869, 0.0018794, 0.049769, 0.025581, 0.019361, 0.12389]
Predicted label: 4
Correct prediction
Energy consumption = 152.840494 pJ
sum error= 340
Actual label: 7
Output voltages: [0.10288, 0.04008, 0.04295, 0.20606, 0.011233, 0.0077562, 0.0010675, 0.79852, 0.052897, 0.065849]
Predicted label: 7
Correct prediction
Energy consumption = 149.831173 pJ
sum error= 340
Actual label: 8
Output voltages: [0.039594, 0.0055566, 0.059294, 0.29221, 0.0012258, 0.090558, 0.092474, 0.0030283, 0.79854, 0.026544]
Predicted label: 8
Correct prediction
Energy consumption = 141.433624 pJ
sum error= 340
Actual label: 9
Output voltages: [0.37334, 0.0086623, 0.010164, 0.055899, 0.32225, 0.015211, 0.0016747, 0.012134, 0.49708, 0.79802]
Predicted label: 9
Correct prediction
Energy consumption = 141.847065 pJ
sum error= 340
Actual label: 0
Output voltages: [0.79874, 0.013161, 0.027035, 0.0058619, 0.031729, 0.017882, 0.64038, 0.034467, 0.037259, 0.19154]
Predicted label: 0
Correct prediction
Energy consumption = 135.819539 pJ
sum error= 340
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 836 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 836 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 836 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.038801, 0.79879, 0.040558, 0.00932, 0.24599, 0.00108, 0.54709, 0.0014392, 0.18191, 0.040488]
Predicted label: 1
Correct prediction
Energy consumption = 172.555986 pJ
sum error= 340
Actual label: 2
Output voltages: [0.22228, 0.0082429, 0.7987, 0.075996, 0.044142, 0.0010844, 0.027504, 0.067067, 0.5278, 0.020401]
Predicted label: 2
Correct prediction
Energy consumption = 136.057005 pJ
sum error= 340
Actual label: 3
Output voltages: [0.25182, 0.0025107, 0.026983, 0.79879, 0.049352, 0.06463, 0.029659, 0.01265, 0.65618, 0.0080641]
Predicted label: 3
Correct prediction
Energy consumption = 140.459716 pJ
sum error= 340
Actual label: 4
Output voltages: [0.006305, 0.001365, 0.37717, 0.032105, 0.79879, 0.0012213, 0.08816, 0.020888, 0.051383, 0.01795]
Predicted label: 4
Correct prediction
Energy consumption = 151.852085 pJ
sum error= 340
Actual label: 7
Output voltages: [0.08592, 0.038826, 0.76783, 0.068527, 0.0058848, 0.0010736, 0.0010914, 0.79872, 0.1988, 0.19316]
Predicted label: 7
Correct prediction
Energy consumption = 150.022888 pJ
sum error= 340
Actual label: 2
Output voltages: [0.26504, 0.026552, 0.79862, 0.044685, 0.017291, 0.0012297, 0.021195, 0.025418, 0.60824, 0.0065494]
Predicted label: 2
Correct prediction
Energy consumption = 142.578056 pJ
sum error= 340
Actual label: 5
Output voltages: [0.048425, 0.0011853, 0.0013002, 0.26177, 0.031596, 0.79878, 0.3335, 0.027171, 0.73863, 0.016634]
Predicted label: 5
Correct prediction
Energy consumption = 150.936300 pJ
sum error= 340
Actual label: 1
Output voltages: [0.0084263, 0.79863, 0.27058, 0.038026, 0.044599, 0.0011425, 0.37185, 0.01801, 0.16803, 0.0021873]
Predicted label: 1
Correct prediction
Energy consumption = 155.713105 pJ
sum error= 340
Actual label: 6
Output voltages: [0.25572, 0.012617, 0.23249, 0.0010963, 0.40884, 0.10056, 0.79879, 0.0032555, 0.24554, 0.0022992]
Predicted label: 6
Correct prediction
Energy consumption = 145.830514 pJ
sum error= 340
Actual label: 4
Output voltages: [0.014055, 0.005927, 0.030667, 0.0010989, 0.79872, 0.0047363, 0.19019, 0.032791, 0.28222, 0.0064927]
Predicted label: 4
Correct prediction
Energy consumption = 147.143565 pJ
sum error= 340
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 837 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 837 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 837 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.46117, 0.0070175, 0.049192, 0.79871, 0.018596, 0.012421, 0.025257, 0.011181, 0.40231, 0.040406]
Predicted label: 3
Correct prediction
Energy consumption = 164.959975 pJ
sum error= 340
Actual label: 9
Output voltages: [0.38432, 0.0051457, 0.03799, 0.034346, 0.03009, 0.01682, 0.0040675, 0.012601, 0.75347, 0.79388]
Predicted label: 9
Correct prediction
Energy consumption = 149.280936 pJ
sum error= 340
Actual label: 9
Output voltages: [0.43028, 0.0055526, 0.12208, 0.02912, 0.049612, 0.0058205, 0.0028801, 0.036923, 0.57609, 0.79495]
Predicted label: 9
Correct prediction
Energy consumption = 131.487769 pJ
sum error= 340
Actual label: 0
Output voltages: [0.79872, 0.016248, 0.046538, 0.0097232, 0.022245, 0.0046844, 0.74915, 0.054582, 0.17748, 0.11422]
Predicted label: 0
Correct prediction
Energy consumption = 139.273075 pJ
sum error= 340
Actual label: 9
Output voltages: [0.16231, 0.015999, 0.031638, 0.025288, 0.013713, 0.033499, 0.0027119, 0.08848, 0.79341, 0.75952]
Predicted label: 8
Wrong prediction!
Energy consumption = 139.440429 pJ
sum error= 341
Actual label: 7
Output voltages: [0.11326, 0.037085, 0.029038, 0.042969, 0.031015, 0.0045493, 0.0010698, 0.7987, 0.12005, 0.02876]
Predicted label: 7
Correct prediction
Energy consumption = 148.091223 pJ
sum error= 341
Actual label: 1
Output voltages: [0.050752, 0.79879, 0.01662, 0.34489, 0.21923, 0.0041957, 0.50887, 0.056495, 0.10501, 0.037985]
Predicted label: 1
Correct prediction
Energy consumption = 162.327274 pJ
sum error= 341
Actual label: 6
Output voltages: [0.033141, 0.014948, 0.37309, 0.0010989, 0.61395, 0.11118, 0.79878, 0.0040494, 0.28745, 0.0035112]
Predicted label: 6
Correct prediction
Energy consumption = 140.712160 pJ
sum error= 341
Actual label: 4
Output voltages: [0.0030995, 0.015343, 0.11937, 0.0087094, 0.79875, 0.0016279, 0.023401, 0.04714, 0.029486, 0.017924]
Predicted label: 4
Correct prediction
Energy consumption = 153.543381 pJ
sum error= 341
Actual label: 3
Output voltages: [0.12906, 0.010114, 0.20825, 0.79879, 0.034793, 0.035822, 0.011832, 0.030199, 0.6515, 0.27461]
Predicted label: 3
Correct prediction
Energy consumption = 141.640803 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 838 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 838 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 838 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.02132, 0.013182, 0.28754, 0.0013288, 0.65031, 0.16245, 0.79878, 0.0012055, 0.59994, 0.0062431]
Predicted label: 6
Correct prediction
Energy consumption = 162.418801 pJ
sum error= 341
Actual label: 2
Output voltages: [0.041951, 0.019113, 0.79861, 0.039859, 0.019258, 0.0010885, 0.038506, 0.10335, 0.44454, 0.032289]
Predicted label: 2
Correct prediction
Energy consumption = 134.365835 pJ
sum error= 341
Actual label: 0
Output voltages: [0.79714, 0.0010919, 0.75253, 0.34397, 0.0011092, 0.024443, 0.051861, 0.20285, 0.43013, 0.0071051]
Predicted label: 0
Correct prediction
Energy consumption = 136.919468 pJ
sum error= 341
Actual label: 9
Output voltages: [0.013322, 0.0097778, 0.11952, 0.033217, 0.018837, 0.24046, 0.0067112, 0.0074154, 0.79432, 0.63803]
Predicted label: 8
Wrong prediction!
Energy consumption = 145.345678 pJ
sum error= 342
Actual label: 8
Output voltages: [0.069999, 0.0097139, 0.22694, 0.12326, 0.025818, 0.29542, 0.016826, 0.027583, 0.79871, 0.013242]
Predicted label: 8
Correct prediction
Energy consumption = 141.951700 pJ
sum error= 342
Actual label: 6
Output voltages: [0.03703, 0.033371, 0.54232, 0.0010878, 0.35396, 0.10277, 0.79877, 0.0041409, 0.46879, 0.0040607]
Predicted label: 6
Correct prediction
Energy consumption = 145.038063 pJ
sum error= 342
Actual label: 5
Output voltages: [0.054163, 0.0011023, 0.011323, 0.056702, 0.21943, 0.79827, 0.44149, 0.0014692, 0.78492, 0.028385]
Predicted label: 5
Correct prediction
Energy consumption = 139.038031 pJ
sum error= 342
Actual label: 7
Output voltages: [0.16837, 0.062494, 0.023899, 0.097825, 0.036197, 0.0011675, 0.0012045, 0.79779, 0.2, 0.34486]
Predicted label: 7
Correct prediction
Energy consumption = 145.631098 pJ
sum error= 342
Actual label: 0
Output voltages: [0.79871, 0.0056623, 0.15721, 0.0055038, 0.012578, 0.0028345, 0.55147, 0.15392, 0.047995, 0.17144]
Predicted label: 0
Correct prediction
Energy consumption = 145.000276 pJ
sum error= 342
Actual label: 0
Output voltages: [0.78964, 0.029895, 0.19584, 0.019798, 0.032059, 0.0012375, 0.774, 0.0068111, 0.4457, 0.052894]
Predicted label: 0
Correct prediction
Energy consumption = 127.792873 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 839 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 839 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 839 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.4023, 0.79875, 0.0071595, 0.038499, 0.47935, 0.017206, 0.43755, 0.0018247, 0.048389, 0.049729]
Predicted label: 1
Correct prediction
Energy consumption = 174.005337 pJ
sum error= 342
Actual label: 7
Output voltages: [0.51826, 0.039209, 0.015194, 0.044273, 0.019714, 0.02365, 0.0038137, 0.79871, 0.43866, 0.009332]
Predicted label: 7
Correct prediction
Energy consumption = 147.114884 pJ
sum error= 342
Actual label: 4
Output voltages: [0.0072228, 0.019444, 0.27109, 0.0011091, 0.79878, 0.0060122, 0.53831, 0.036115, 0.31103, 0.0024817]
Predicted label: 4
Correct prediction
Energy consumption = 150.211865 pJ
sum error= 342
Actual label: 3
Output voltages: [0.30866, 0.007284, 0.11973, 0.79874, 0.012476, 0.0050784, 0.0048978, 0.037944, 0.66035, 0.048277]
Predicted label: 3
Correct prediction
Energy consumption = 145.884220 pJ
sum error= 342
Actual label: 2
Output voltages: [0.58739, 0.0061746, 0.7987, 0.032905, 0.0030347, 0.0010972, 0.021569, 0.12374, 0.60485, 0.0023071]
Predicted label: 2
Correct prediction
Energy consumption = 137.031739 pJ
sum error= 342
Actual label: 4
Output voltages: [0.017121, 0.010357, 0.082118, 0.098988, 0.79875, 0.0025134, 0.037542, 0.025787, 0.016375, 0.012105]
Predicted label: 4
Correct prediction
Energy consumption = 152.963659 pJ
sum error= 342
Actual label: 1
Output voltages: [0.030781, 0.79879, 0.082301, 0.025324, 0.17893, 0.003232, 0.75743, 0.0010661, 0.41816, 0.034501]
Predicted label: 1
Correct prediction
Energy consumption = 158.568095 pJ
sum error= 342
Actual label: 3
Output voltages: [0.77211, 0.037947, 0.75437, 0.79818, 0.0013703, 0.3825, 0.012537, 0.0013276, 0.62048, 0.0013708]
Predicted label: 3
Correct prediction
Energy consumption = 145.298684 pJ
sum error= 342
Actual label: 7
Output voltages: [0.025492, 0.061621, 0.16154, 0.16721, 0.0072045, 0.0015477, 0.001066, 0.79865, 0.28934, 0.12353]
Predicted label: 7
Correct prediction
Energy consumption = 148.018407 pJ
sum error= 342
Actual label: 6
Output voltages: [0.027013, 0.0046459, 0.17304, 0.0012846, 0.46351, 0.067355, 0.79879, 0.0033273, 0.66818, 0.0047461]
Predicted label: 6
Correct prediction
Energy consumption = 148.012702 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 840 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 840 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 840 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.010334, 0.0079109, 0.19535, 0.020693, 0.79868, 0.0024257, 0.11596, 0.030114, 0.02922, 0.036838]
Predicted label: 4
Correct prediction
Energy consumption = 169.261597 pJ
sum error= 342
Actual label: 7
Output voltages: [0.07401, 0.071222, 0.0094705, 0.010169, 0.021451, 0.0020568, 0.0018784, 0.79867, 0.31181, 0.28399]
Predicted label: 7
Correct prediction
Energy consumption = 152.649698 pJ
sum error= 342
Actual label: 7
Output voltages: [0.28626, 0.032439, 0.1007, 0.0051129, 0.024099, 0.022979, 0.0010659, 0.79857, 0.27319, 0.0085114]
Predicted label: 7
Correct prediction
Energy consumption = 140.623043 pJ
sum error= 342
Actual label: 7
Output voltages: [0.19627, 0.039012, 0.041919, 0.026433, 0.022053, 0.010253, 0.0010836, 0.7986, 0.053093, 0.033278]
Predicted label: 7
Correct prediction
Energy consumption = 136.973510 pJ
sum error= 342
Actual label: 9
Output voltages: [0.52419, 0.012927, 0.022459, 0.024262, 0.21301, 0.024903, 0.009886, 0.022811, 0.64224, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 149.065445 pJ
sum error= 342
Actual label: 8
Output voltages: [0.023728, 0.042358, 0.055589, 0.048367, 0.016102, 0.054944, 0.025753, 0.0032558, 0.79879, 0.38391]
Predicted label: 8
Correct prediction
Energy consumption = 137.930996 pJ
sum error= 342
Actual label: 4
Output voltages: [0.0049643, 0.0017002, 0.39598, 0.020874, 0.79879, 0.0010903, 0.023765, 0.0072957, 0.14903, 0.1911]
Predicted label: 4
Correct prediction
Energy consumption = 153.032002 pJ
sum error= 342
Actual label: 3
Output voltages: [0.13801, 0.0072621, 0.095174, 0.79874, 0.023184, 0.019218, 0.0068675, 0.010726, 0.73681, 0.039979]
Predicted label: 3
Correct prediction
Energy consumption = 142.599018 pJ
sum error= 342
Actual label: 8
Output voltages: [0.11612, 0.0026307, 0.021593, 0.042478, 0.0095389, 0.50433, 0.76501, 0.0012313, 0.78136, 0.013053]
Predicted label: 8
Correct prediction
Energy consumption = 133.947067 pJ
sum error= 342
Actual label: 2
Output voltages: [0.049505, 0.019031, 0.79859, 0.053666, 0.016881, 0.0010848, 0.025072, 0.093359, 0.47761, 0.016142]
Predicted label: 2
Correct prediction
Energy consumption = 134.614185 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 841 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 841 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 841 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18908, 0.0018362, 0.030517, 0.29052, 0.0010662, 0.4246, 0.096483, 0.0010957, 0.79128, 0.11129]
Predicted label: 8
Correct prediction
Energy consumption = 168.408450 pJ
sum error= 342
Actual label: 3
Output voltages: [0.089181, 0.022181, 0.037802, 0.79868, 0.0050135, 0.004555, 0.0066896, 0.032616, 0.60641, 0.029117]
Predicted label: 3
Correct prediction
Energy consumption = 146.999503 pJ
sum error= 342
Actual label: 5
Output voltages: [0.17274, 0.0010661, 0.0010746, 0.54848, 0.035513, 0.79869, 0.075756, 0.17403, 0.54323, 0.0094336]
Predicted label: 5
Correct prediction
Energy consumption = 134.206041 pJ
sum error= 342
Actual label: 8
Output voltages: [0.25638, 0.023443, 0.025732, 0.21914, 0.024501, 0.048372, 0.49359, 0.0019486, 0.79865, 0.0019707]
Predicted label: 8
Correct prediction
Energy consumption = 144.825099 pJ
sum error= 342
Actual label: 0
Output voltages: [0.79871, 0.022673, 0.16723, 0.010838, 0.01493, 0.0024109, 0.57543, 0.045741, 0.23977, 0.021712]
Predicted label: 0
Correct prediction
Energy consumption = 145.530781 pJ
sum error= 342
Actual label: 5
Output voltages: [0.063003, 0.0011707, 0.0010699, 0.078047, 0.1687, 0.79857, 0.38664, 0.01451, 0.45218, 0.037099]
Predicted label: 5
Correct prediction
Energy consumption = 139.423070 pJ
sum error= 342
Actual label: 4
Output voltages: [0.0057962, 0.031259, 0.024747, 0.0012884, 0.79873, 0.016349, 0.037433, 0.027662, 0.53064, 0.012342]
Predicted label: 4
Correct prediction
Energy consumption = 156.220950 pJ
sum error= 342
Actual label: 7
Output voltages: [0.66381, 0.01146, 0.0053245, 0.010409, 0.023559, 0.3376, 0.0018999, 0.79861, 0.31583, 0.084608]
Predicted label: 7
Correct prediction
Energy consumption = 147.015613 pJ
sum error= 342
Actual label: 1
Output voltages: [0.019346, 0.7986, 0.015094, 0.037324, 0.044787, 0.0046479, 0.60264, 0.0050603, 0.18133, 0.034528]
Predicted label: 1
Correct prediction
Energy consumption = 165.321033 pJ
sum error= 342
Actual label: 3
Output voltages: [0.048119, 0.0030905, 0.027415, 0.79874, 0.1309, 0.021828, 0.011105, 0.016817, 0.38775, 0.56479]
Predicted label: 3
Correct prediction
Energy consumption = 150.315380 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 842 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 842 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 842 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0023903, 0.79858, 0.024349, 0.02775, 0.017222, 0.0011881, 0.75111, 0.0029307, 0.41508, 0.032106]
Predicted label: 1
Correct prediction
Energy consumption = 176.820063 pJ
sum error= 342
Actual label: 7
Output voltages: [0.044559, 0.48055, 0.10058, 0.025366, 0.0066486, 0.0011228, 0.0013789, 0.79874, 0.53644, 0.3985]
Predicted label: 7
Correct prediction
Energy consumption = 151.319418 pJ
sum error= 342
Actual label: 9
Output voltages: [0.072325, 0.0024137, 0.013138, 0.050877, 0.078336, 0.084231, 0.00208, 0.23187, 0.75806, 0.79594]
Predicted label: 9
Correct prediction
Energy consumption = 137.803491 pJ
sum error= 342
Actual label: 6
Output voltages: [0.026804, 0.032743, 0.49492, 0.0010675, 0.30463, 0.044499, 0.79878, 0.0028265, 0.45053, 0.001632]
Predicted label: 6
Correct prediction
Energy consumption = 144.022694 pJ
sum error= 342
Actual label: 2
Output voltages: [0.16319, 0.039086, 0.79858, 0.058636, 0.028789, 0.0011686, 0.05508, 0.035742, 0.22972, 0.04206]
Predicted label: 2
Correct prediction
Energy consumption = 141.254611 pJ
sum error= 342
Actual label: 0
Output voltages: [0.79876, 0.03534, 0.04831, 0.0096894, 0.028153, 0.005305, 0.5198, 0.022741, 0.037922, 0.081872]
Predicted label: 0
Correct prediction
Energy consumption = 146.262517 pJ
sum error= 342
Actual label: 9
Output voltages: [0.76467, 0.003843, 0.0066625, 0.086829, 0.052815, 0.34589, 0.0062279, 0.048219, 0.2267, 0.78882]
Predicted label: 9
Correct prediction
Energy consumption = 143.377558 pJ
sum error= 342
Actual label: 1
Output voltages: [0.016392, 0.79877, 0.03951, 0.11741, 0.13967, 0.0011402, 0.7476, 0.0017865, 0.23396, 0.019059]
Predicted label: 1
Correct prediction
Energy consumption = 162.015836 pJ
sum error= 342
Actual label: 7
Output voltages: [0.74711, 0.013548, 0.0086995, 0.046135, 0.14025, 0.024844, 0.0011675, 0.79869, 0.29427, 0.15983]
Predicted label: 7
Correct prediction
Energy consumption = 158.722787 pJ
sum error= 342
Actual label: 3
Output voltages: [0.030757, 0.014709, 0.035482, 0.79875, 0.036203, 0.14044, 0.0026464, 0.026511, 0.7677, 0.039234]
Predicted label: 3
Correct prediction
Energy consumption = 141.144825 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 843 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 843 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 843 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.029647, 0.0069413, 0.080275, 0.79879, 0.031994, 0.029469, 0.0044235, 0.11682, 0.74066, 0.10675]
Predicted label: 3
Correct prediction
Energy consumption = 165.305102 pJ
sum error= 342
Actual label: 9
Output voltages: [0.20306, 0.0010712, 0.0016657, 0.0088723, 0.39956, 0.23097, 0.0035765, 0.067899, 0.75908, 0.7796]
Predicted label: 9
Correct prediction
Energy consumption = 144.764352 pJ
sum error= 342
Actual label: 1
Output voltages: [0.0026265, 0.79866, 0.0532, 0.018105, 0.28105, 0.0013072, 0.32098, 0.013007, 0.16211, 0.042565]
Predicted label: 1
Correct prediction
Energy consumption = 161.179408 pJ
sum error= 342
Actual label: 6
Output voltages: [0.039696, 0.013568, 0.48848, 0.0010662, 0.68606, 0.046695, 0.79878, 0.0034545, 0.17278, 0.0035581]
Predicted label: 6
Correct prediction
Energy consumption = 141.605776 pJ
sum error= 342
Actual label: 4
Output voltages: [0.0072297, 0.001184, 0.19423, 0.0019076, 0.79861, 0.0010665, 0.18213, 0.026355, 0.051269, 0.015142]
Predicted label: 4
Correct prediction
Energy consumption = 145.836451 pJ
sum error= 342
Actual label: 3
Output voltages: [0.42053, 0.0011216, 0.042242, 0.79879, 0.015448, 0.34926, 0.014579, 0.0056397, 0.062571, 0.0098358]
Predicted label: 3
Correct prediction
Energy consumption = 141.282312 pJ
sum error= 342
Actual label: 9
Output voltages: [0.067261, 0.026969, 0.038403, 0.045677, 0.042244, 0.014249, 0.0020402, 0.087396, 0.45843, 0.7981]
Predicted label: 9
Correct prediction
Energy consumption = 150.130354 pJ
sum error= 342
Actual label: 8
Output voltages: [0.0066637, 0.0085508, 0.031904, 0.09387, 0.0089302, 0.17032, 0.074471, 0.020753, 0.7987, 0.043251]
Predicted label: 8
Correct prediction
Energy consumption = 139.287768 pJ
sum error= 342
Actual label: 2
Output voltages: [0.53313, 0.0077121, 0.79868, 0.11379, 0.0094541, 0.0015899, 0.057719, 0.045104, 0.42608, 0.004774]
Predicted label: 2
Correct prediction
Energy consumption = 141.162278 pJ
sum error= 342
Actual label: 1
Output voltages: [0.0044747, 0.79879, 0.35612, 0.035106, 0.067006, 0.0013638, 0.48748, 0.019823, 0.34208, 0.0012707]
Predicted label: 1
Correct prediction
Energy consumption = 155.705090 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 844 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 844 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 844 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0035739, 0.095223, 0.089368, 0.015625, 0.021311, 0.0061724, 0.023422, 0.030465, 0.79877, 0.36201]
Predicted label: 8
Correct prediction
Energy consumption = 163.668903 pJ
sum error= 342
Actual label: 6
Output voltages: [0.071309, 0.16076, 0.25682, 0.0015005, 0.34537, 0.15497, 0.7987, 0.0033316, 0.28811, 0.011465]
Predicted label: 6
Correct prediction
Energy consumption = 141.662662 pJ
sum error= 342
Actual label: 4
Output voltages: [0.038482, 0.014624, 0.081527, 0.0029274, 0.79658, 0.0017837, 0.7923, 0.0031929, 0.043628, 0.027786]
Predicted label: 4
Correct prediction
Energy consumption = 141.975397 pJ
sum error= 342
Actual label: 1
Output voltages: [0.050088, 0.79869, 0.22853, 0.063771, 0.036941, 0.0011083, 0.62645, 0.006869, 0.066447, 0.011265]
Predicted label: 1
Correct prediction
Energy consumption = 157.557569 pJ
sum error= 342
Actual label: 5
Output voltages: [0.046059, 0.0010659, 0.0011412, 0.26101, 0.20595, 0.79878, 0.1329, 0.033434, 0.55271, 0.027072]
Predicted label: 5
Correct prediction
Energy consumption = 138.212846 pJ
sum error= 342
Actual label: 5
Output voltages: [0.04403, 0.0010772, 0.0010758, 0.35228, 0.068089, 0.79865, 0.27998, 0.23069, 0.76807, 0.003264]
Predicted label: 5
Correct prediction
Energy consumption = 132.623821 pJ
sum error= 342
Actual label: 6
Output voltages: [0.044795, 0.022583, 0.34807, 0.0039243, 0.21013, 0.083135, 0.79878, 0.0011262, 0.75423, 0.010309]
Predicted label: 6
Correct prediction
Energy consumption = 140.679764 pJ
sum error= 342
Actual label: 5
Output voltages: [0.033247, 0.0020827, 0.0024877, 0.30161, 0.023642, 0.79807, 0.19595, 0.024449, 0.7519, 0.15263]
Predicted label: 5
Correct prediction
Energy consumption = 142.927111 pJ
sum error= 342
Actual label: 0
Output voltages: [0.79878, 0.12104, 0.0036812, 0.018442, 0.017056, 0.019287, 0.42691, 0.025776, 0.11303, 0.074973]
Predicted label: 0
Correct prediction
Energy consumption = 154.182187 pJ
sum error= 342
Actual label: 1
Output voltages: [0.013088, 0.79877, 0.0014563, 0.043965, 0.19887, 0.25971, 0.48938, 0.014463, 0.45409, 0.04386]
Predicted label: 1
Correct prediction
Energy consumption = 160.970219 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 845 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 845 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 845 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36017, 0.17302, 0.79876, 0.033591, 0.043404, 0.00132, 0.28034, 0.039177, 0.21507, 0.024926]
Predicted label: 2
Correct prediction
Energy consumption = 169.735845 pJ
sum error= 342
Actual label: 3
Output voltages: [0.37755, 0.025981, 0.036488, 0.79869, 0.039365, 0.0095569, 0.017361, 0.0041013, 0.55323, 0.11366]
Predicted label: 3
Correct prediction
Energy consumption = 147.070028 pJ
sum error= 342
Actual label: 4
Output voltages: [0.027694, 0.012135, 0.17496, 0.019463, 0.79856, 0.0025008, 0.049915, 0.18857, 0.011165, 0.038343]
Predicted label: 4
Correct prediction
Energy consumption = 157.635341 pJ
sum error= 342
Actual label: 5
Output voltages: [0.022515, 0.00119, 0.002012, 0.46412, 0.025645, 0.79799, 0.27545, 0.0028524, 0.76619, 0.013369]
Predicted label: 5
Correct prediction
Energy consumption = 144.006696 pJ
sum error= 342
Actual label: 6
Output voltages: [0.15381, 0.04601, 0.25803, 0.0039422, 0.36001, 0.39377, 0.79866, 0.0024456, 0.45894, 0.0082553]
Predicted label: 6
Correct prediction
Energy consumption = 137.208287 pJ
sum error= 342
Actual label: 7
Output voltages: [0.12746, 0.10562, 0.50639, 0.0208, 0.001154, 0.0011026, 0.0010678, 0.7986, 0.41518, 0.055219]
Predicted label: 7
Correct prediction
Energy consumption = 161.559176 pJ
sum error= 342
Actual label: 8
Output voltages: [0.50267, 0.0037328, 0.32208, 0.20161, 0.04566, 0.017218, 0.21036, 0.001602, 0.79879, 0.014546]
Predicted label: 8
Correct prediction
Energy consumption = 150.342391 pJ
sum error= 342
Actual label: 9
Output voltages: [0.32052, 0.0086869, 0.014504, 0.041611, 0.022044, 0.011863, 0.0015189, 0.016644, 0.75695, 0.79726]
Predicted label: 9
Correct prediction
Energy consumption = 141.524467 pJ
sum error= 342
Actual label: 0
Output voltages: [0.79869, 0.097354, 0.010274, 0.019926, 0.0042986, 0.018851, 0.61429, 0.026847, 0.10219, 0.0226]
Predicted label: 0
Correct prediction
Energy consumption = 145.627496 pJ
sum error= 342
Actual label: 1
Output voltages: [0.019824, 0.79855, 0.040698, 0.22772, 0.048848, 0.0050389, 0.39589, 0.0031991, 0.36836, 0.046845]
Predicted label: 1
Correct prediction
Energy consumption = 157.949988 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 846 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 846 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 846 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.59955, 0.0037075, 0.79824, 0.26586, 0.05538, 0.0011401, 0.019608, 0.054584, 0.47702, 0.025025]
Predicted label: 2
Correct prediction
Energy consumption = 164.031086 pJ
sum error= 342
Actual label: 3
Output voltages: [0.56357, 0.014219, 0.044544, 0.79862, 0.034545, 0.024488, 0.0078599, 0.01364, 0.51541, 0.091265]
Predicted label: 3
Correct prediction
Energy consumption = 147.665525 pJ
sum error= 342
Actual label: 4
Output voltages: [0.0015679, 0.048796, 0.010898, 0.0010685, 0.79866, 0.026862, 0.044852, 0.21832, 0.45201, 0.027702]
Predicted label: 4
Correct prediction
Energy consumption = 164.184789 pJ
sum error= 342
Actual label: 5
Output voltages: [0.057678, 0.0012285, 0.0010713, 0.53082, 0.025834, 0.79872, 0.30028, 0.032731, 0.73733, 0.011217]
Predicted label: 5
Correct prediction
Energy consumption = 141.227191 pJ
sum error= 342
Actual label: 6
Output voltages: [0.071423, 0.053622, 0.40925, 0.0011261, 0.40568, 0.049082, 0.79868, 0.0016354, 0.34954, 0.0063491]
Predicted label: 6
Correct prediction
Energy consumption = 145.904383 pJ
sum error= 342
Actual label: 7
Output voltages: [0.12319, 0.031062, 0.53873, 0.15832, 0.0011557, 0.0025805, 0.0010923, 0.79879, 0.77764, 0.042507]
Predicted label: 7
Correct prediction
Energy consumption = 160.159976 pJ
sum error= 342
Actual label: 8
Output voltages: [0.04278, 0.042145, 0.48947, 0.03343, 0.010896, 0.0040296, 0.017425, 0.0021983, 0.7987, 0.12954]
Predicted label: 8
Correct prediction
Energy consumption = 143.948398 pJ
sum error= 342
Actual label: 9
Output voltages: [0.18171, 0.0048699, 0.024257, 0.068588, 0.14632, 0.31238, 0.10772, 0.14159, 0.39628, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 150.941968 pJ
sum error= 342
Actual label: 0
Output voltages: [0.79866, 0.063768, 0.057707, 0.011637, 0.0018099, 0.0054583, 0.58216, 0.023316, 0.2504, 0.042063]
Predicted label: 0
Correct prediction
Energy consumption = 146.496759 pJ
sum error= 342
Actual label: 1
Output voltages: [0.0078621, 0.79865, 0.073802, 0.11505, 0.020371, 0.0016489, 0.34091, 0.002617, 0.38952, 0.038288]
Predicted label: 1
Correct prediction
Energy consumption = 155.334622 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 847 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 847 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 847 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36985, 0.10467, 0.79849, 0.29464, 0.079447, 0.0010921, 0.031647, 0.028342, 0.29777, 0.012509]
Predicted label: 2
Correct prediction
Energy consumption = 164.110408 pJ
sum error= 342
Actual label: 3
Output voltages: [0.23849, 0.013394, 0.091135, 0.79873, 0.072122, 0.0051359, 0.012597, 0.010056, 0.64937, 0.069068]
Predicted label: 3
Correct prediction
Energy consumption = 143.461391 pJ
sum error= 342
Actual label: 4
Output voltages: [0.053604, 0.0024308, 0.39439, 0.0014313, 0.79806, 0.0010801, 0.071688, 0.0019503, 0.34159, 0.49902]
Predicted label: 4
Correct prediction
Energy consumption = 154.335776 pJ
sum error= 342
Actual label: 5
Output voltages: [0.037704, 0.0012189, 0.0032154, 0.74, 0.038134, 0.79867, 0.072876, 0.013882, 0.74881, 0.033645]
Predicted label: 5
Correct prediction
Energy consumption = 146.360352 pJ
sum error= 342
Actual label: 6
Output voltages: [0.15924, 0.11398, 0.13186, 0.0052023, 0.10874, 0.35165, 0.79875, 0.0029936, 0.26856, 0.0037415]
Predicted label: 6
Correct prediction
Energy consumption = 143.583784 pJ
sum error= 342
Actual label: 7
Output voltages: [0.24976, 0.043082, 0.23837, 0.020308, 0.001079, 0.0014561, 0.0010929, 0.79879, 0.69488, 0.2557]
Predicted label: 7
Correct prediction
Energy consumption = 162.350399 pJ
sum error= 342
Actual label: 8
Output voltages: [0.19905, 0.0032824, 0.051674, 0.2206, 0.026243, 0.10545, 0.038996, 0.0010679, 0.79821, 0.078698]
Predicted label: 8
Correct prediction
Energy consumption = 145.142850 pJ
sum error= 342
Actual label: 9
Output voltages: [0.26402, 0.001625, 0.039812, 0.028365, 0.03238, 0.0047326, 0.0015704, 0.16674, 0.73324, 0.77655]
Predicted label: 9
Correct prediction
Energy consumption = 144.825983 pJ
sum error= 342
Actual label: 6
Output voltages: [0.4329, 0.063583, 0.036826, 0.012447, 0.23769, 0.70542, 0.79879, 0.0022079, 0.43135, 0.0094844]
Predicted label: 6
Correct prediction
Energy consumption = 148.930271 pJ
sum error= 342
Actual label: 9
Output voltages: [0.48853, 0.0017132, 0.019579, 0.016392, 0.067583, 0.0032233, 0.0025144, 0.31488, 0.42147, 0.79397]
Predicted label: 9
Correct prediction
Energy consumption = 153.876034 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 848 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 848 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 848 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.052837, 0.059425, 0.10682, 0.0077006, 0.0052704, 0.0034724, 0.0011033, 0.79865, 0.51446, 0.091422]
Predicted label: 7
Correct prediction
Energy consumption = 174.555883 pJ
sum error= 342
Actual label: 0
Output voltages: [0.79879, 0.099307, 0.022145, 0.033145, 0.006302, 0.022744, 0.35853, 0.013842, 0.035464, 0.055694]
Predicted label: 0
Correct prediction
Energy consumption = 158.180252 pJ
sum error= 342
Actual label: 2
Output voltages: [0.47916, 0.039686, 0.79878, 0.28191, 0.034176, 0.0011879, 0.044017, 0.022089, 0.52253, 0.022689]
Predicted label: 2
Correct prediction
Energy consumption = 147.254224 pJ
sum error= 342
Actual label: 3
Output voltages: [0.6646, 0.018342, 0.07704, 0.79866, 0.01942, 0.0056132, 0.02415, 0.0056144, 0.44786, 0.043157]
Predicted label: 3
Correct prediction
Energy consumption = 142.947076 pJ
sum error= 342
Actual label: 4
Output voltages: [0.0033931, 0.02469, 0.067138, 0.0010918, 0.79855, 0.0063655, 0.17586, 0.03909, 0.053097, 0.059665]
Predicted label: 4
Correct prediction
Energy consumption = 158.276989 pJ
sum error= 342
Actual label: 3
Output voltages: [0.18852, 0.018231, 0.12233, 0.79878, 0.033249, 0.0024608, 0.03096, 0.0054628, 0.70899, 0.10493]
Predicted label: 3
Correct prediction
Energy consumption = 154.778445 pJ
sum error= 342
Actual label: 8
Output voltages: [0.45681, 0.018084, 0.3827, 0.024913, 0.016734, 0.0033481, 0.0062233, 0.0015762, 0.79879, 0.37726]
Predicted label: 8
Correct prediction
Energy consumption = 149.901621 pJ
sum error= 342
Actual label: 5
Output voltages: [0.065245, 0.0011093, 0.0011093, 0.27072, 0.031808, 0.79801, 0.14597, 0.022221, 0.7658, 0.022148]
Predicted label: 5
Correct prediction
Energy consumption = 139.640518 pJ
sum error= 342
Actual label: 1
Output voltages: [0.015985, 0.79868, 0.0044338, 0.12028, 0.097819, 0.013822, 0.59403, 0.0034128, 0.39065, 0.047635]
Predicted label: 1
Correct prediction
Energy consumption = 162.571308 pJ
sum error= 342
Actual label: 3
Output voltages: [0.39661, 0.0095708, 0.20742, 0.79874, 0.023198, 0.031838, 0.019253, 0.0062148, 0.64464, 0.13325]
Predicted label: 3
Correct prediction
Energy consumption = 151.730934 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 849 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 849 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 849 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.026441, 0.044466, 0.014717, 0.0043222, 0.007912, 0.53534, 0.056543, 0.14404, 0.025996]
Predicted label: 0
Correct prediction
Energy consumption = 162.234915 pJ
sum error= 342
Actual label: 1
Output voltages: [0.033395, 0.79863, 0.1603, 0.29411, 0.0012269, 0.0037045, 0.50474, 0.014853, 0.31175, 0.0085742]
Predicted label: 1
Correct prediction
Energy consumption = 164.266260 pJ
sum error= 342
Actual label: 2
Output voltages: [0.13641, 0.021123, 0.79866, 0.096095, 0.02957, 0.0011349, 0.28076, 0.19673, 0.049099, 0.27766]
Predicted label: 2
Correct prediction
Energy consumption = 139.552764 pJ
sum error= 342
Actual label: 1
Output voltages: [0.028067, 0.79866, 0.028783, 0.11511, 0.030079, 0.0018005, 0.1292, 0.0012081, 0.48806, 0.042999]
Predicted label: 1
Correct prediction
Energy consumption = 159.042158 pJ
sum error= 342
Actual label: 3
Output voltages: [0.45708, 0.0084231, 0.039586, 0.79864, 0.02265, 0.028463, 0.02355, 0.0071161, 0.56772, 0.058726]
Predicted label: 3
Correct prediction
Energy consumption = 147.278892 pJ
sum error= 342
Actual label: 2
Output voltages: [0.35175, 0.18899, 0.79702, 0.67654, 0.012094, 0.0012071, 0.37879, 0.0021107, 0.4225, 0.0057041]
Predicted label: 2
Correct prediction
Energy consumption = 140.715715 pJ
sum error= 342
Actual label: 0
Output voltages: [0.79812, 0.019119, 0.024717, 0.0014385, 0.0059394, 0.017089, 0.74957, 0.0013376, 0.050865, 0.056262]
Predicted label: 0
Correct prediction
Energy consumption = 145.904814 pJ
sum error= 342
Actual label: 7
Output voltages: [0.085233, 0.54446, 0.20571, 0.45484, 0.0022128, 0.0011419, 0.0012185, 0.79806, 0.5575, 0.081768]
Predicted label: 7
Correct prediction
Energy consumption = 160.647684 pJ
sum error= 342
Actual label: 2
Output voltages: [0.29809, 0.17092, 0.78905, 0.57683, 0.015914, 0.0012461, 0.34772, 0.018583, 0.65098, 0.053148]
Predicted label: 2
Correct prediction
Energy consumption = 145.573809 pJ
sum error= 342
Actual label: 6
Output voltages: [0.10227, 0.034918, 0.17502, 0.0027384, 0.35706, 0.34825, 0.79876, 0.002657, 0.49171, 0.0023897]
Predicted label: 6
Correct prediction
Energy consumption = 146.314712 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 850 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 850 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 850 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0077959, 0.017861, 0.088776, 0.01872, 0.79853, 0.0037924, 0.12017, 0.52783, 0.033067, 0.036215]
Predicted label: 4
Correct prediction
Energy consumption = 165.881878 pJ
sum error= 342
Actual label: 0
Output voltages: [0.79875, 0.043672, 0.015969, 0.027557, 0.03392, 0.011099, 0.55542, 0.032442, 0.19773, 0.11528]
Predicted label: 0
Correct prediction
Energy consumption = 153.894231 pJ
sum error= 342
Actual label: 5
Output voltages: [0.022301, 0.0014476, 0.0045492, 0.76106, 0.0027567, 0.7227, 0.016458, 0.0050331, 0.70077, 0.14194]
Predicted label: 3
Wrong prediction!
Energy consumption = 148.388606 pJ
sum error= 343
Actual label: 9
Output voltages: [0.39874, 0.0097734, 0.0068568, 0.024214, 0.037251, 0.22625, 0.0037759, 0.04062, 0.34511, 0.79421]
Predicted label: 9
Correct prediction
Energy consumption = 149.725206 pJ
sum error= 343
Actual label: 9
Output voltages: [0.059937, 0.001143, 0.022263, 0.045258, 0.030183, 0.68007, 0.0061333, 0.31652, 0.74503, 0.76838]
Predicted label: 9
Correct prediction
Energy consumption = 147.520661 pJ
sum error= 343
Actual label: 8
Output voltages: [0.39609, 0.0091986, 0.20878, 0.18321, 0.0041336, 0.12666, 0.023736, 0.0037773, 0.79849, 0.086471]
Predicted label: 8
Correct prediction
Energy consumption = 149.418453 pJ
sum error= 343
Actual label: 9
Output voltages: [0.30954, 0.010833, 0.016363, 0.013355, 0.11246, 0.011024, 0.0022749, 0.02661, 0.60658, 0.79804]
Predicted label: 9
Correct prediction
Energy consumption = 152.207975 pJ
sum error= 343
Actual label: 5
Output voltages: [0.20414, 0.0011163, 0.0017516, 0.093917, 0.022207, 0.79865, 0.46024, 0.0045492, 0.78105, 0.0013644]
Predicted label: 5
Correct prediction
Energy consumption = 135.601573 pJ
sum error= 343
Actual label: 3
Output voltages: [0.54837, 0.0092753, 0.027335, 0.79865, 0.022334, 0.084318, 0.01418, 0.018699, 0.45262, 0.022604]
Predicted label: 3
Correct prediction
Energy consumption = 148.351877 pJ
sum error= 343
Actual label: 1
Output voltages: [0.040551, 0.79879, 0.038339, 0.29098, 0.049834, 0.0014497, 0.47314, 0.0010661, 0.42502, 0.0076144]
Predicted label: 1
Correct prediction
Energy consumption = 160.103200 pJ
sum error= 343
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 851 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 851 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 851 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.041708, 0.44111, 0.30358, 0.32101, 0.0017598, 0.0011043, 0.0012013, 0.79871, 0.70571, 0.15414]
Predicted label: 7
Correct prediction
Energy consumption = 179.422362 pJ
sum error= 343
Actual label: 4
Output voltages: [0.033694, 0.0029295, 0.13397, 0.001987, 0.79867, 0.0021196, 0.16843, 0.21831, 0.040386, 0.018039]
Predicted label: 4
Correct prediction
Energy consumption = 156.939619 pJ
sum error= 343
Actual label: 7
Output voltages: [0.052001, 0.081494, 0.23102, 0.37886, 0.0065536, 0.0010786, 0.0011388, 0.79879, 0.43522, 0.11351]
Predicted label: 7
Correct prediction
Energy consumption = 158.688654 pJ
sum error= 343
Actual label: 0
Output voltages: [0.79875, 0.010916, 0.031033, 0.080669, 0.0021629, 0.017828, 0.37399, 0.036686, 0.14535, 0.068965]
Predicted label: 0
Correct prediction
Energy consumption = 141.694725 pJ
sum error= 343
Actual label: 0
Output voltages: [0.79872, 0.071473, 0.047437, 0.018859, 0.008733, 0.0022271, 0.7545, 0.02047, 0.29261, 0.12076]
Predicted label: 0
Correct prediction
Energy consumption = 139.176650 pJ
sum error= 343
Actual label: 6
Output voltages: [0.02672, 0.10721, 0.43365, 0.0014139, 0.16336, 0.18743, 0.79871, 0.0047251, 0.3352, 0.0099992]
Predicted label: 6
Correct prediction
Energy consumption = 146.335162 pJ
sum error= 343
Actual label: 6
Output voltages: [0.22349, 0.11898, 0.20294, 0.0041997, 0.32892, 0.16856, 0.79871, 0.0011055, 0.41346, 0.013948]
Predicted label: 6
Correct prediction
Energy consumption = 138.577315 pJ
sum error= 343
Actual label: 6
Output voltages: [0.055043, 0.014681, 0.27337, 0.0011485, 0.57292, 0.47781, 0.79873, 0.0013314, 0.60942, 0.0013141]
Predicted label: 6
Correct prediction
Energy consumption = 139.406498 pJ
sum error= 343
Actual label: 3
Output voltages: [0.34439, 0.022581, 0.030374, 0.79867, 0.012533, 0.0057605, 0.0086175, 0.016008, 0.48089, 0.044461]
Predicted label: 3
Correct prediction
Energy consumption = 158.931352 pJ
sum error= 343
Actual label: 7
Output voltages: [0.24887, 0.61578, 0.4329, 0.23817, 0.0010807, 0.001218, 0.0029515, 0.7987, 0.068241, 0.050773]
Predicted label: 7
Correct prediction
Energy consumption = 149.189147 pJ
sum error= 343
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 852 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 852 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 852 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0051167, 0.027244, 0.026861, 0.028077, 0.77086, 0.0010837, 0.0012925, 0.014292, 0.35804, 0.78038]
Predicted label: 9
Wrong prediction!
Energy consumption = 172.199921 pJ
sum error= 344
Actual label: 2
Output voltages: [0.41777, 0.3644, 0.79878, 0.50637, 0.0063902, 0.001321, 0.047001, 0.056735, 0.12277, 0.04404]
Predicted label: 2
Correct prediction
Energy consumption = 150.069360 pJ
sum error= 344
Actual label: 8
Output voltages: [0.027065, 0.001174, 0.34864, 0.094101, 0.029205, 0.022873, 0.66259, 0.0032559, 0.79872, 0.014323]
Predicted label: 8
Correct prediction
Energy consumption = 148.037469 pJ
sum error= 344
Actual label: 9
Output voltages: [0.18487, 0.001094, 0.060512, 0.17344, 0.34813, 0.0081277, 0.0012312, 0.452, 0.045183, 0.79351]
Predicted label: 9
Correct prediction
Energy consumption = 157.107080 pJ
sum error= 344
Actual label: 8
Output voltages: [0.027017, 0.0267, 0.68776, 0.062487, 0.016287, 0.0011229, 0.29012, 0.003868, 0.79872, 0.050189]
Predicted label: 8
Correct prediction
Energy consumption = 155.194040 pJ
sum error= 344
Actual label: 7
Output voltages: [0.17225, 0.19554, 0.11342, 0.52477, 0.014406, 0.001159, 0.0011088, 0.79848, 0.44643, 0.16141]
Predicted label: 7
Correct prediction
Energy consumption = 162.811488 pJ
sum error= 344
Actual label: 1
Output voltages: [0.035168, 0.79849, 0.2062, 0.2296, 0.0023482, 0.0010667, 0.50222, 0.0039155, 0.079209, 0.035264]
Predicted label: 1
Correct prediction
Energy consumption = 159.237864 pJ
sum error= 344
Actual label: 4
Output voltages: [0.27524, 0.0027398, 0.028627, 0.014178, 0.71611, 0.03399, 0.044156, 0.24027, 0.047342, 0.79508]
Predicted label: 9
Wrong prediction!
Energy consumption = 159.225818 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79876, 0.027037, 0.03295, 0.0079395, 0.009015, 0.23881, 0.32907, 0.0047216, 0.014012, 0.026374]
Predicted label: 0
Correct prediction
Energy consumption = 157.179650 pJ
sum error= 345
Actual label: 4
Output voltages: [0.057668, 0.015413, 0.064501, 0.0010699, 0.79866, 0.032232, 0.27012, 0.024488, 0.094105, 0.10982]
Predicted label: 4
Correct prediction
Energy consumption = 150.898094 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 853 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 853 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 853 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.42683, 0.0018401, 0.13008, 0.1586, 0.025991, 0.011072, 0.048108, 0.0020014, 0.79852, 0.049531]
Predicted label: 8
Correct prediction
Energy consumption = 163.000411 pJ
sum error= 345
Actual label: 5
Output voltages: [0.010805, 0.0010754, 0.0027284, 0.30173, 0.15882, 0.79873, 0.42482, 0.013791, 0.75321, 0.04483]
Predicted label: 5
Correct prediction
Energy consumption = 150.791053 pJ
sum error= 345
Actual label: 2
Output voltages: [0.46012, 0.1375, 0.79879, 0.28428, 0.013549, 0.0012413, 0.37898, 0.013506, 0.56116, 0.015653]
Predicted label: 2
Correct prediction
Energy consumption = 148.674123 pJ
sum error= 345
Actual label: 3
Output voltages: [0.52784, 0.015222, 0.44994, 0.79879, 0.0091097, 0.0012857, 0.0058523, 0.0030572, 0.58412, 0.025532]
Predicted label: 3
Correct prediction
Energy consumption = 146.834379 pJ
sum error= 345
Actual label: 9
Output voltages: [0.25391, 0.001104, 0.038517, 0.45308, 0.062679, 0.02286, 0.041977, 0.49848, 0.037447, 0.78776]
Predicted label: 9
Correct prediction
Energy consumption = 155.287816 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79856, 0.16447, 0.021145, 0.0022721, 0.011709, 0.004579, 0.59695, 0.018921, 0.14737, 0.22394]
Predicted label: 0
Correct prediction
Energy consumption = 151.383183 pJ
sum error= 345
Actual label: 1
Output voltages: [0.015794, 0.79867, 0.16923, 0.061968, 0.094302, 0.024672, 0.044918, 0.28457, 0.053079, 0.0164]
Predicted label: 1
Correct prediction
Energy consumption = 166.098062 pJ
sum error= 345
Actual label: 9
Output voltages: [0.31221, 0.0054796, 0.024628, 0.013882, 0.11809, 0.05604, 0.023664, 0.39818, 0.26843, 0.79657]
Predicted label: 9
Correct prediction
Energy consumption = 156.846086 pJ
sum error= 345
Actual label: 1
Output voltages: [0.061171, 0.79878, 0.046647, 0.33629, 0.040812, 0.00277, 0.051721, 0.078032, 0.28356, 0.093791]
Predicted label: 1
Correct prediction
Energy consumption = 167.055114 pJ
sum error= 345
Actual label: 5
Output voltages: [0.30797, 0.0013576, 0.0010665, 0.21797, 0.014923, 0.79877, 0.2266, 0.29665, 0.62, 0.01017]
Predicted label: 5
Correct prediction
Energy consumption = 153.938805 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 854 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 854 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 854 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.01125, 0.79853, 0.31937, 0.57435, 0.03612, 0.0015544, 0.10812, 0.055204, 0.014185, 0.048327]
Predicted label: 1
Correct prediction
Energy consumption = 183.360774 pJ
sum error= 345
Actual label: 7
Output voltages: [0.090296, 0.14579, 0.10396, 0.28578, 0.001068, 0.0010661, 0.0012002, 0.79879, 0.52599, 0.4613]
Predicted label: 7
Correct prediction
Energy consumption = 154.277619 pJ
sum error= 345
Actual label: 6
Output voltages: [0.044667, 0.11662, 0.11226, 0.021708, 0.2588, 0.34315, 0.79878, 0.012766, 0.73587, 0.011752]
Predicted label: 6
Correct prediction
Energy consumption = 164.527513 pJ
sum error= 345
Actual label: 1
Output voltages: [0.048189, 0.79847, 0.30749, 0.46991, 0.020874, 0.021887, 0.056333, 0.065649, 0.0075287, 0.1121]
Predicted label: 1
Correct prediction
Energy consumption = 163.215336 pJ
sum error= 345
Actual label: 2
Output voltages: [0.70803, 0.018918, 0.79833, 0.30396, 0.0012363, 0.0010691, 0.057108, 0.014336, 0.45071, 0.0029427]
Predicted label: 2
Correct prediction
Energy consumption = 147.301037 pJ
sum error= 345
Actual label: 1
Output voltages: [0.01768, 0.79857, 0.30707, 0.17012, 0.11258, 0.011912, 0.34927, 0.51577, 0.014496, 0.038247]
Predicted label: 1
Correct prediction
Energy consumption = 165.188557 pJ
sum error= 345
Actual label: 6
Output voltages: [0.13388, 0.13077, 0.040045, 0.021943, 0.60734, 0.5949, 0.79869, 0.020671, 0.73131, 0.0024598]
Predicted label: 6
Correct prediction
Energy consumption = 154.922807 pJ
sum error= 345
Actual label: 8
Output voltages: [0.31383, 0.012298, 0.057363, 0.071201, 0.050252, 0.033587, 0.026373, 0.0021039, 0.79875, 0.088093]
Predicted label: 8
Correct prediction
Energy consumption = 145.420902 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79872, 0.088007, 0.0068328, 0.015806, 0.0076, 0.13808, 0.45357, 0.0059384, 0.094583, 0.25316]
Predicted label: 0
Correct prediction
Energy consumption = 153.617389 pJ
sum error= 345
Actual label: 1
Output voltages: [0.0085788, 0.79841, 0.055638, 0.066552, 0.011553, 0.0016551, 0.606, 0.0035377, 0.1449, 0.058691]
Predicted label: 1
Correct prediction
Energy consumption = 155.080071 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 855 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 855 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 855 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.044567, 0.037742, 0.79875, 0.2215, 0.020451, 0.0012351, 0.021204, 0.17899, 0.061157, 0.032937]
Predicted label: 2
Correct prediction
Energy consumption = 162.586699 pJ
sum error= 345
Actual label: 3
Output voltages: [0.20404, 0.0054666, 0.22664, 0.79872, 0.024613, 0.010844, 0.030942, 0.0042057, 0.53526, 0.064724]
Predicted label: 3
Correct prediction
Energy consumption = 141.553902 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0014528, 0.0018969, 0.36026, 0.010245, 0.79859, 0.0014895, 0.098428, 0.094896, 0.036388, 0.048301]
Predicted label: 4
Correct prediction
Energy consumption = 157.335282 pJ
sum error= 345
Actual label: 5
Output voltages: [0.074659, 0.017466, 0.010627, 0.13063, 0.0032769, 0.79872, 0.10782, 0.24503, 0.51421, 0.016305]
Predicted label: 5
Correct prediction
Energy consumption = 151.647875 pJ
sum error= 345
Actual label: 6
Output voltages: [0.23405, 0.16522, 0.32276, 0.0055187, 0.25522, 0.063575, 0.79873, 0.0015471, 0.26985, 0.015465]
Predicted label: 6
Correct prediction
Energy consumption = 151.798343 pJ
sum error= 345
Actual label: 7
Output voltages: [0.056544, 0.010499, 0.039986, 0.19322, 0.0037933, 0.010646, 0.0010855, 0.79861, 0.059912, 0.32401]
Predicted label: 7
Correct prediction
Energy consumption = 159.780632 pJ
sum error= 345
Actual label: 8
Output voltages: [0.028428, 0.011208, 0.064242, 0.15559, 0.0042395, 0.18456, 0.017884, 0.0027164, 0.79871, 0.21631]
Predicted label: 8
Correct prediction
Energy consumption = 149.599605 pJ
sum error= 345
Actual label: 9
Output voltages: [0.054522, 0.017794, 0.026574, 0.40262, 0.060791, 0.19582, 0.03013, 0.060048, 0.43955, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 146.937553 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79874, 0.12938, 0.0040803, 0.01796, 0.0099713, 0.30155, 0.75471, 0.028444, 0.26647, 0.010452]
Predicted label: 0
Correct prediction
Energy consumption = 161.673461 pJ
sum error= 345
Actual label: 1
Output voltages: [0.011946, 0.79842, 0.0014846, 0.035015, 0.018285, 0.0199, 0.43541, 0.019646, 0.43026, 0.028663]
Predicted label: 1
Correct prediction
Energy consumption = 159.122732 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 856 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 856 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 856 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.64564, 0.017272, 0.79832, 0.58809, 0.01409, 0.0012182, 0.0090932, 0.03647, 0.50329, 0.003506]
Predicted label: 2
Correct prediction
Energy consumption = 170.479092 pJ
sum error= 345
Actual label: 3
Output voltages: [0.014171, 0.022503, 0.044931, 0.79829, 0.022738, 0.045942, 0.0013528, 0.033905, 0.77242, 0.12837]
Predicted label: 3
Correct prediction
Energy consumption = 139.366793 pJ
sum error= 345
Actual label: 4
Output voltages: [0.011513, 0.018788, 0.2118, 0.004787, 0.79858, 0.0035968, 0.081135, 0.22631, 0.023933, 0.026446]
Predicted label: 4
Correct prediction
Energy consumption = 151.496376 pJ
sum error= 345
Actual label: 5
Output voltages: [0.028444, 0.0011834, 0.0030105, 0.60539, 0.0315, 0.79879, 0.10488, 0.14921, 0.70998, 0.19919]
Predicted label: 5
Correct prediction
Energy consumption = 142.959223 pJ
sum error= 345
Actual label: 6
Output voltages: [0.08932, 0.25399, 0.24526, 0.0012841, 0.22817, 0.13868, 0.79866, 0.002178, 0.31692, 0.0086367]
Predicted label: 6
Correct prediction
Energy consumption = 155.833331 pJ
sum error= 345
Actual label: 7
Output voltages: [0.12918, 0.39541, 0.30028, 0.48559, 0.0010712, 0.0010939, 0.005644, 0.79559, 0.24343, 0.40035]
Predicted label: 7
Correct prediction
Energy consumption = 166.552607 pJ
sum error= 345
Actual label: 8
Output voltages: [0.020661, 0.023221, 0.048726, 0.044047, 0.035624, 0.10974, 0.034787, 0.0072303, 0.79866, 0.039186]
Predicted label: 8
Correct prediction
Energy consumption = 152.645528 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79824, 0.036783, 0.033187, 0.024511, 0.0013319, 0.088184, 0.29794, 0.0018057, 0.061305, 0.047376]
Predicted label: 0
Correct prediction
Energy consumption = 153.970672 pJ
sum error= 345
Actual label: 1
Output voltages: [0.016037, 0.79844, 0.048095, 0.078128, 0.047738, 0.0026355, 0.6687, 0.0025311, 0.17483, 0.13104]
Predicted label: 1
Correct prediction
Energy consumption = 161.626959 pJ
sum error= 345
Actual label: 2
Output voltages: [0.50779, 0.001727, 0.79877, 0.4403, 0.0094895, 0.001412, 0.025205, 0.057363, 0.47828, 0.0059698]
Predicted label: 2
Correct prediction
Energy consumption = 144.716786 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 857 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 857 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 857 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.0651, 0.017318, 0.057453, 0.79875, 0.028607, 0.030999, 0.0036553, 0.005168, 0.73726, 0.040884]
Predicted label: 3
Correct prediction
Energy consumption = 168.072922 pJ
sum error= 345
Actual label: 5
Output voltages: [0.13956, 0.0014264, 0.0024806, 0.32447, 0.011075, 0.79874, 0.19013, 0.045822, 0.70218, 0.031693]
Predicted label: 5
Correct prediction
Energy consumption = 144.383295 pJ
sum error= 345
Actual label: 6
Output voltages: [0.042739, 0.20809, 0.18138, 0.0020101, 0.15942, 0.15021, 0.7987, 0.0015495, 0.33262, 0.0043745]
Predicted label: 6
Correct prediction
Energy consumption = 151.991703 pJ
sum error= 345
Actual label: 7
Output voltages: [0.48639, 0.19843, 0.030753, 0.40365, 0.010322, 0.038968, 0.0010695, 0.7986, 0.02099, 0.29601]
Predicted label: 7
Correct prediction
Energy consumption = 159.484137 pJ
sum error= 345
Actual label: 8
Output voltages: [0.074118, 0.010698, 0.21986, 0.035063, 0.016825, 0.023123, 0.020795, 0.0070594, 0.79865, 0.040726]
Predicted label: 8
Correct prediction
Energy consumption = 147.159065 pJ
sum error= 345
Actual label: 1
Output voltages: [0.0027258, 0.7986, 0.13329, 0.19895, 0.011947, 0.0040097, 0.44002, 0.013096, 0.55511, 0.20352]
Predicted label: 1
Correct prediction
Energy consumption = 163.572137 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.071146, 0.010611, 0.010638, 0.11651, 0.047527, 0.76281, 0.0076586, 0.038208, 0.054297]
Predicted label: 0
Correct prediction
Energy consumption = 162.761595 pJ
sum error= 345
Actual label: 4
Output voltages: [0.011092, 0.0030711, 0.23848, 0.026592, 0.79862, 0.0010674, 0.024055, 0.14069, 0.013205, 0.057138]
Predicted label: 4
Correct prediction
Energy consumption = 156.099680 pJ
sum error= 345
Actual label: 5
Output voltages: [0.49086, 0.0021222, 0.0019561, 0.60034, 0.035302, 0.79878, 0.36229, 0.020254, 0.53411, 0.054177]
Predicted label: 5
Correct prediction
Energy consumption = 151.216008 pJ
sum error= 345
Actual label: 6
Output voltages: [0.15964, 0.25298, 0.3344, 0.0059763, 0.28999, 0.11567, 0.79869, 0.0012987, 0.26583, 0.022759]
Predicted label: 6
Correct prediction
Energy consumption = 143.793554 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 858 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 858 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 858 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.35748, 0.049147, 0.36099, 0.001397, 0.35565, 0.28231, 0.79877, 0.0017036, 0.16847, 0.015643]
Predicted label: 6
Correct prediction
Energy consumption = 167.080667 pJ
sum error= 345
Actual label: 3
Output voltages: [0.16969, 0.022115, 0.084453, 0.79875, 0.017163, 0.0013535, 0.0066753, 0.0042978, 0.64888, 0.034663]
Predicted label: 3
Correct prediction
Energy consumption = 148.057614 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0040398, 0.013765, 0.205, 0.027096, 0.79863, 0.0064052, 0.20169, 0.042534, 0.019541, 0.039886]
Predicted label: 4
Correct prediction
Energy consumption = 150.488544 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0043082, 0.001189, 0.47306, 0.007688, 0.79857, 0.0014358, 0.046673, 0.0099978, 0.053568, 0.12539]
Predicted label: 4
Correct prediction
Energy consumption = 144.456201 pJ
sum error= 345
Actual label: 2
Output voltages: [0.67641, 0.080979, 0.79879, 0.30101, 0.0021408, 0.00108, 0.22905, 0.0030634, 0.28001, 0.061651]
Predicted label: 2
Correct prediction
Energy consumption = 151.481498 pJ
sum error= 345
Actual label: 8
Output voltages: [0.024338, 0.031562, 0.1039, 0.090089, 0.0040784, 0.027426, 0.037135, 0.016949, 0.79869, 0.18403]
Predicted label: 8
Correct prediction
Energy consumption = 152.402193 pJ
sum error= 345
Actual label: 1
Output voltages: [0.0071404, 0.79847, 0.1785, 0.24591, 0.038237, 0.0021032, 0.74085, 0.016384, 0.18301, 0.050277]
Predicted label: 1
Correct prediction
Energy consumption = 164.598913 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79812, 0.089801, 0.011555, 0.0082397, 0.058377, 0.027106, 0.77398, 0.0043284, 0.055675, 0.020047]
Predicted label: 0
Correct prediction
Energy consumption = 157.106160 pJ
sum error= 345
Actual label: 6
Output voltages: [0.056809, 0.11621, 0.16352, 0.0059446, 0.42362, 0.22388, 0.79868, 0.0013205, 0.36695, 0.020301]
Predicted label: 6
Correct prediction
Energy consumption = 142.811637 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0047108, 0.0084378, 0.18867, 0.01657, 0.79865, 0.0038399, 0.10266, 0.039392, 0.12873, 0.011129]
Predicted label: 4
Correct prediction
Energy consumption = 154.006804 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 859 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 859 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 859 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.041885, 0.016276, 0.14786, 0.17555, 0.07995, 0.071446, 0.05941, 0.11484, 0.22575, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 173.915122 pJ
sum error= 345
Actual label: 7
Output voltages: [0.14811, 0.56589, 0.025547, 0.54239, 0.0040255, 0.0011244, 0.0033052, 0.79765, 0.019053, 0.30137]
Predicted label: 7
Correct prediction
Energy consumption = 164.794116 pJ
sum error= 345
Actual label: 2
Output voltages: [0.39637, 0.033308, 0.79867, 0.041406, 0.0093628, 0.0010816, 0.03045, 0.018798, 0.36509, 0.0033545]
Predicted label: 2
Correct prediction
Energy consumption = 146.333367 pJ
sum error= 345
Actual label: 9
Output voltages: [0.25412, 0.0026311, 0.046871, 0.002968, 0.69834, 0.020737, 0.02041, 0.047837, 0.057987, 0.79854]
Predicted label: 9
Correct prediction
Energy consumption = 158.129484 pJ
sum error= 345
Actual label: 2
Output voltages: [0.52739, 0.013006, 0.79879, 0.13404, 0.017553, 0.0011049, 0.02176, 0.043942, 0.56453, 0.0053119]
Predicted label: 2
Correct prediction
Energy consumption = 157.857746 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.091042, 0.026673, 0.01207, 0.021456, 0.022466, 0.63648, 0.015162, 0.049121, 0.018634]
Predicted label: 0
Correct prediction
Energy consumption = 152.181460 pJ
sum error= 345
Actual label: 9
Output voltages: [0.32419, 0.03074, 0.018227, 0.39535, 0.43054, 0.064657, 0.23872, 0.035937, 0.032591, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 157.174212 pJ
sum error= 345
Actual label: 3
Output voltages: [0.031313, 0.022526, 0.32806, 0.79879, 0.012793, 0.031192, 0.0024431, 0.02379, 0.70638, 0.041115]
Predicted label: 3
Correct prediction
Energy consumption = 148.309222 pJ
sum error= 345
Actual label: 3
Output voltages: [0.29679, 0.0053275, 0.17006, 0.79873, 0.029056, 0.0027847, 0.017094, 0.0019008, 0.39384, 0.070161]
Predicted label: 3
Correct prediction
Energy consumption = 141.085031 pJ
sum error= 345
Actual label: 9
Output voltages: [0.19005, 0.014335, 0.046893, 0.29249, 0.40338, 0.0047216, 0.019293, 0.0025927, 0.10654, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 143.842611 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 860 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 860 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 860 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0098816, 0.79867, 0.60648, 0.11169, 0.029865, 0.001066, 0.39984, 0.0042429, 0.11527, 0.032127]
Predicted label: 1
Correct prediction
Energy consumption = 178.939604 pJ
sum error= 345
Actual label: 5
Output voltages: [0.017138, 0.0012356, 0.0015722, 0.51362, 0.037082, 0.79758, 0.069809, 0.019746, 0.68851, 0.31994]
Predicted label: 5
Correct prediction
Energy consumption = 151.623037 pJ
sum error= 345
Actual label: 2
Output voltages: [0.61953, 0.0041108, 0.79855, 0.42433, 0.0037127, 0.0010799, 0.034685, 0.0086861, 0.49191, 0.0069003]
Predicted label: 2
Correct prediction
Energy consumption = 153.750025 pJ
sum error= 345
Actual label: 3
Output voltages: [0.75543, 0.0030613, 0.26353, 0.79878, 0.055379, 0.018218, 0.014611, 0.0059201, 0.69962, 0.0080163]
Predicted label: 3
Correct prediction
Energy consumption = 137.585026 pJ
sum error= 345
Actual label: 1
Output voltages: [0.004712, 0.79851, 0.028522, 0.11806, 0.034575, 0.004872, 0.22024, 0.01382, 0.7212, 0.047772]
Predicted label: 1
Correct prediction
Energy consumption = 167.058616 pJ
sum error= 345
Actual label: 6
Output voltages: [0.14066, 0.27198, 0.20944, 0.0058097, 0.25591, 0.14, 0.7987, 0.001771, 0.22279, 0.010264]
Predicted label: 6
Correct prediction
Energy consumption = 152.866010 pJ
sum error= 345
Actual label: 7
Output voltages: [0.38606, 0.4375, 0.34603, 0.45245, 0.0022766, 0.0011341, 0.0010903, 0.79872, 0.0554, 0.33848]
Predicted label: 7
Correct prediction
Energy consumption = 164.170670 pJ
sum error= 345
Actual label: 3
Output voltages: [0.069295, 0.031039, 0.072793, 0.79789, 0.0020015, 0.036159, 0.010495, 0.018127, 0.78602, 0.096374]
Predicted label: 3
Correct prediction
Energy consumption = 144.636011 pJ
sum error= 345
Actual label: 7
Output voltages: [0.085043, 0.046986, 0.034577, 0.40839, 0.0038282, 0.0025941, 0.001069, 0.79869, 0.12703, 0.69098]
Predicted label: 7
Correct prediction
Energy consumption = 156.761767 pJ
sum error= 345
Actual label: 8
Output voltages: [0.0048992, 0.039353, 0.1106, 0.030891, 0.030365, 0.017212, 0.0045773, 0.013506, 0.79874, 0.15798]
Predicted label: 8
Correct prediction
Energy consumption = 141.695866 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 861 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 861 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 861 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0062221, 0.0021579, 0.060972, 0.0067117, 0.79866, 0.0018106, 0.092437, 0.25811, 0.39076, 0.0063823]
Predicted label: 4
Correct prediction
Energy consumption = 172.619248 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79878, 0.089177, 0.018949, 0.037723, 0.034618, 0.0051326, 0.56357, 0.012372, 0.045209, 0.28965]
Predicted label: 0
Correct prediction
Energy consumption = 160.729964 pJ
sum error= 345
Actual label: 2
Output voltages: [0.37277, 0.030122, 0.79858, 0.042362, 0.014044, 0.0010679, 0.044191, 0.14807, 0.4008, 0.0070048]
Predicted label: 2
Correct prediction
Energy consumption = 142.782294 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0025267, 0.0045019, 0.19984, 0.15756, 0.7987, 0.001197, 0.03601, 0.076502, 0.042954, 0.039439]
Predicted label: 4
Correct prediction
Energy consumption = 157.593380 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79872, 0.017192, 0.041079, 0.010483, 0.027446, 0.0035875, 0.27103, 0.014639, 0.10847, 0.017798]
Predicted label: 0
Correct prediction
Energy consumption = 159.079333 pJ
sum error= 345
Actual label: 2
Output voltages: [0.49069, 0.012677, 0.77939, 0.76597, 0.020008, 0.0011647, 0.0054733, 0.011574, 0.61716, 0.0074573]
Predicted label: 2
Correct prediction
Energy consumption = 153.010229 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0076388, 0.046582, 0.0052816, 0.012475, 0.79877, 0.0042853, 0.074608, 0.14851, 0.072615, 0.06099]
Predicted label: 4
Correct prediction
Energy consumption = 162.684495 pJ
sum error= 345
Actual label: 7
Output voltages: [0.21136, 0.035889, 0.0079841, 0.047931, 0.021767, 0.0051081, 0.0011699, 0.79874, 0.035757, 0.43374]
Predicted label: 7
Correct prediction
Energy consumption = 148.733037 pJ
sum error= 345
Actual label: 8
Output voltages: [0.012716, 0.058611, 0.15543, 0.1703, 0.0069684, 0.021727, 0.032482, 0.029399, 0.79876, 0.30276]
Predicted label: 8
Correct prediction
Energy consumption = 148.130412 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79878, 0.17169, 0.054595, 0.02639, 0.0088423, 0.016854, 0.43905, 0.024186, 0.047095, 0.023902]
Predicted label: 0
Correct prediction
Energy consumption = 145.928508 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 862 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 862 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 862 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.063294, 0.039648, 0.044736, 0.14374, 0.014347, 0.012459, 0.0010664, 0.79855, 0.028494, 0.2307]
Predicted label: 7
Correct prediction
Energy consumption = 175.374064 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79878, 0.14349, 0.020806, 0.017585, 0.022565, 0.0090387, 0.75881, 0.0098212, 0.22659, 0.018284]
Predicted label: 0
Correct prediction
Energy consumption = 155.457811 pJ
sum error= 345
Actual label: 6
Output voltages: [0.060387, 0.16958, 0.22916, 0.0030486, 0.090078, 0.20913, 0.7987, 0.0035778, 0.35258, 0.010101]
Predicted label: 6
Correct prediction
Energy consumption = 146.930311 pJ
sum error= 345
Actual label: 9
Output voltages: [0.5697, 0.017849, 0.0035416, 0.049454, 0.75411, 0.040673, 0.092816, 0.033279, 0.029516, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 164.819216 pJ
sum error= 345
Actual label: 3
Output voltages: [0.57438, 0.0064706, 0.032086, 0.79868, 0.020869, 0.045261, 0.0094993, 0.0092926, 0.34917, 0.030432]
Predicted label: 3
Correct prediction
Energy consumption = 147.490757 pJ
sum error= 345
Actual label: 2
Output voltages: [0.57889, 0.0082349, 0.79878, 0.13433, 0.23714, 0.001078, 0.022996, 0.014623, 0.61907, 0.035244]
Predicted label: 2
Correct prediction
Energy consumption = 145.373795 pJ
sum error= 345
Actual label: 4
Output voltages: [0.012489, 0.0019248, 0.33971, 0.011762, 0.79854, 0.001106, 0.025822, 0.047367, 0.01557, 0.055289]
Predicted label: 4
Correct prediction
Energy consumption = 149.331593 pJ
sum error= 345
Actual label: 8
Output voltages: [0.015248, 0.046846, 0.032797, 0.051088, 0.037479, 0.055843, 0.010236, 0.014066, 0.79873, 0.17111]
Predicted label: 8
Correct prediction
Energy consumption = 152.261620 pJ
sum error= 345
Actual label: 6
Output voltages: [0.19406, 0.22105, 0.068603, 0.0013304, 0.27857, 0.35704, 0.79865, 0.0027995, 0.15133, 0.012926]
Predicted label: 6
Correct prediction
Energy consumption = 154.590215 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79873, 0.058399, 0.036695, 0.013518, 0.020672, 0.0056123, 0.76244, 0.011504, 0.18887, 0.082572]
Predicted label: 0
Correct prediction
Energy consumption = 146.052981 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 863 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 863 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 863 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.099763, 0.0017525, 0.01253, 0.69117, 0.012381, 0.79878, 0.042639, 0.10679, 0.75666, 0.074803]
Predicted label: 5
Correct prediction
Energy consumption = 164.519495 pJ
sum error= 345
Actual label: 7
Output voltages: [0.061028, 0.036369, 0.025291, 0.2452, 0.021894, 0.0020537, 0.0011233, 0.79858, 0.053106, 0.17215]
Predicted label: 7
Correct prediction
Energy consumption = 151.511771 pJ
sum error= 345
Actual label: 5
Output voltages: [0.085563, 0.035199, 0.0023643, 0.54865, 0.0064703, 0.79763, 0.73843, 0.021479, 0.37155, 0.0058653]
Predicted label: 5
Correct prediction
Energy consumption = 146.675480 pJ
sum error= 345
Actual label: 1
Output voltages: [0.0071137, 0.79871, 0.21661, 0.44255, 0.0060532, 0.0011232, 0.20869, 0.046506, 0.060034, 0.14629]
Predicted label: 1
Correct prediction
Energy consumption = 169.487344 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.027421, 0.036758, 0.021996, 0.023776, 0.0026909, 0.5802, 0.021797, 0.085408, 0.22175]
Predicted label: 0
Correct prediction
Energy consumption = 159.390745 pJ
sum error= 345
Actual label: 8
Output voltages: [0.0059021, 0.061686, 0.047744, 0.005444, 0.026474, 0.0027338, 0.11377, 0.037879, 0.79877, 0.38807]
Predicted label: 8
Correct prediction
Energy consumption = 155.567862 pJ
sum error= 345
Actual label: 1
Output voltages: [0.011355, 0.79858, 0.023251, 0.042253, 0.032195, 0.0026323, 0.43214, 0.0015668, 0.28799, 0.025164]
Predicted label: 1
Correct prediction
Energy consumption = 154.366982 pJ
sum error= 345
Actual label: 6
Output voltages: [0.22364, 0.0042423, 0.10601, 0.0010694, 0.23702, 0.044547, 0.79848, 0.0033236, 0.48723, 0.0077639]
Predicted label: 6
Correct prediction
Energy consumption = 147.111984 pJ
sum error= 345
Actual label: 7
Output voltages: [0.1302, 0.024086, 0.033007, 0.059629, 0.0075512, 0.0062545, 0.001074, 0.79848, 0.058127, 0.16786]
Predicted label: 7
Correct prediction
Energy consumption = 154.154390 pJ
sum error= 345
Actual label: 2
Output voltages: [0.74639, 0.0039603, 0.79872, 0.10686, 0.0014292, 0.0010932, 0.025521, 0.059487, 0.49724, 0.0060709]
Predicted label: 2
Correct prediction
Energy consumption = 140.724885 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 864 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 864 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 864 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.17378, 0.019906, 0.095038, 0.043609, 0.037594, 0.0058129, 0.021041, 0.016651, 0.34745, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 171.703306 pJ
sum error= 345
Actual label: 7
Output voltages: [0.073515, 0.053032, 0.039129, 0.068617, 0.010609, 0.0044672, 0.001066, 0.79862, 0.1734, 0.41136]
Predicted label: 7
Correct prediction
Energy consumption = 150.596338 pJ
sum error= 345
Actual label: 9
Output voltages: [0.29321, 0.033245, 0.027141, 0.18766, 0.2885, 0.067312, 0.045443, 0.011303, 0.081263, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 150.961002 pJ
sum error= 345
Actual label: 5
Output voltages: [0.059434, 0.0030915, 0.0082007, 0.66407, 0.024503, 0.79875, 0.098906, 0.034595, 0.65296, 0.15646]
Predicted label: 5
Correct prediction
Energy consumption = 144.899055 pJ
sum error= 345
Actual label: 6
Output voltages: [0.11899, 0.17045, 0.27186, 0.0099718, 0.22645, 0.26702, 0.79872, 0.0026903, 0.5309, 0.020592]
Predicted label: 6
Correct prediction
Energy consumption = 151.290682 pJ
sum error= 345
Actual label: 5
Output voltages: [0.068351, 0.0031285, 0.0067058, 0.51529, 0.012435, 0.79788, 0.047063, 0.029675, 0.74839, 0.39305]
Predicted label: 5
Correct prediction
Energy consumption = 148.043361 pJ
sum error= 345
Actual label: 2
Output voltages: [0.64432, 0.027977, 0.79877, 0.022603, 0.020251, 0.0012052, 0.085717, 0.035589, 0.29237, 0.021824]
Predicted label: 2
Correct prediction
Energy consumption = 148.832370 pJ
sum error= 345
Actual label: 6
Output voltages: [0.050795, 0.21633, 0.038539, 0.010465, 0.1611, 0.50138, 0.79868, 0.004049, 0.19766, 0.014464]
Predicted label: 6
Correct prediction
Energy consumption = 154.882046 pJ
sum error= 345
Actual label: 2
Output voltages: [0.48409, 0.008201, 0.79845, 0.36207, 0.0069927, 0.0011814, 0.044481, 0.033175, 0.4569, 0.0074449]
Predicted label: 2
Correct prediction
Energy consumption = 149.714393 pJ
sum error= 345
Actual label: 8
Output voltages: [0.023385, 0.043282, 0.1548, 0.12388, 0.0017774, 0.045243, 0.0094023, 0.014465, 0.79867, 0.17781]
Predicted label: 8
Correct prediction
Energy consumption = 147.440004 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 865 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 865 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 865 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.020677, 0.79842, 0.01884, 0.056996, 0.099955, 0.016582, 0.70834, 0.0024841, 0.049527, 0.20553]
Predicted label: 1
Correct prediction
Energy consumption = 178.087331 pJ
sum error= 345
Actual label: 7
Output voltages: [0.2381, 0.034664, 0.030359, 0.38531, 0.019428, 0.0062355, 0.0010879, 0.79859, 0.019013, 0.37764]
Predicted label: 7
Correct prediction
Energy consumption = 154.593900 pJ
sum error= 345
Actual label: 5
Output voltages: [0.028742, 0.0026369, 0.0033371, 0.53972, 0.030167, 0.79879, 0.18293, 0.084368, 0.7176, 0.27361]
Predicted label: 5
Correct prediction
Energy consumption = 144.767320 pJ
sum error= 345
Actual label: 5
Output voltages: [0.041975, 0.019931, 0.036511, 0.43595, 0.001218, 0.79879, 0.038581, 0.18793, 0.67918, 0.0017928]
Predicted label: 5
Correct prediction
Energy consumption = 133.908444 pJ
sum error= 345
Actual label: 7
Output voltages: [0.1421, 0.021157, 0.063752, 0.27078, 0.015482, 0.0014972, 0.0013043, 0.79864, 0.020983, 0.48652]
Predicted label: 7
Correct prediction
Energy consumption = 154.081915 pJ
sum error= 345
Actual label: 3
Output voltages: [0.70893, 0.04085, 0.028545, 0.79861, 0.0061253, 0.069218, 0.0066366, 0.017655, 0.39632, 0.031028]
Predicted label: 3
Correct prediction
Energy consumption = 147.738511 pJ
sum error= 345
Actual label: 5
Output voltages: [0.1099, 0.0015299, 0.0019482, 0.29738, 0.0058886, 0.79879, 0.022181, 0.1068, 0.76513, 0.060284]
Predicted label: 5
Correct prediction
Energy consumption = 137.091177 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.23097, 0.029236, 0.034081, 0.004137, 0.024639, 0.4759, 0.024164, 0.048001, 0.028992]
Predicted label: 0
Correct prediction
Energy consumption = 140.887396 pJ
sum error= 345
Actual label: 1
Output voltages: [0.018943, 0.79871, 0.40183, 0.051834, 0.037319, 0.0010667, 0.69672, 0.0023564, 0.14738, 0.020346]
Predicted label: 1
Correct prediction
Energy consumption = 163.792584 pJ
sum error= 345
Actual label: 1
Output voltages: [0.0087395, 0.79848, 0.094282, 0.083462, 0.050756, 0.0054913, 0.48622, 0.010357, 0.19825, 0.0328]
Predicted label: 1
Correct prediction
Energy consumption = 150.426710 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 866 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 866 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 866 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.095168, 0.021358, 0.064297, 0.79861, 0.01718, 0.016551, 0.0090722, 0.051127, 0.47074, 0.048747]
Predicted label: 3
Correct prediction
Energy consumption = 162.903643 pJ
sum error= 345
Actual label: 8
Output voltages: [0.024423, 0.011215, 0.060324, 0.13197, 0.012773, 0.12547, 0.014304, 0.0018366, 0.79879, 0.37396]
Predicted label: 8
Correct prediction
Energy consumption = 147.549257 pJ
sum error= 345
Actual label: 4
Output voltages: [0.00254, 0.0058913, 0.30705, 0.016425, 0.79858, 0.002197, 0.16697, 0.032674, 0.029344, 0.030147]
Predicted label: 4
Correct prediction
Energy consumption = 155.297859 pJ
sum error= 345
Actual label: 9
Output voltages: [0.19381, 0.023278, 0.037067, 0.038346, 0.079594, 0.0371, 0.012259, 0.04277, 0.47226, 0.79817]
Predicted label: 9
Correct prediction
Energy consumption = 150.267704 pJ
sum error= 345
Actual label: 4
Output voltages: [0.028348, 0.0026891, 0.26348, 0.0063647, 0.7987, 0.0010664, 0.1173, 0.068688, 0.1386, 0.027315]
Predicted label: 4
Correct prediction
Energy consumption = 151.188977 pJ
sum error= 345
Actual label: 5
Output voltages: [0.073573, 0.0024523, 0.0014569, 0.29932, 0.063811, 0.79874, 0.055121, 0.063594, 0.70366, 0.1187]
Predicted label: 5
Correct prediction
Energy consumption = 150.952319 pJ
sum error= 345
Actual label: 1
Output voltages: [0.0087002, 0.7985, 0.017227, 0.16902, 0.2159, 0.0027257, 0.25628, 0.025892, 0.27959, 0.061554]
Predicted label: 1
Correct prediction
Energy consumption = 170.190973 pJ
sum error= 345
Actual label: 8
Output voltages: [0.016804, 0.016479, 0.064047, 0.46549, 0.0013423, 0.32968, 0.015072, 0.0080029, 0.79876, 0.1047]
Predicted label: 8
Correct prediction
Energy consumption = 153.381964 pJ
sum error= 345
Actual label: 6
Output voltages: [0.052436, 0.26431, 0.27971, 0.0077606, 0.21449, 0.066112, 0.79867, 0.0018752, 0.41818, 0.023054]
Predicted label: 6
Correct prediction
Energy consumption = 152.105584 pJ
sum error= 345
Actual label: 8
Output voltages: [0.022965, 0.044669, 0.17756, 0.017078, 0.010543, 0.01141, 0.009722, 0.029622, 0.79879, 0.30136]
Predicted label: 8
Correct prediction
Energy consumption = 147.736419 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 867 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 867 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 867 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.43189, 0.032145, 0.048089, 0.13256, 0.14127, 0.076297, 0.016683, 0.02977, 0.33303, 0.79808]
Predicted label: 9
Correct prediction
Energy consumption = 170.262663 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.11262, 0.14117, 0.016974, 0.0061368, 0.0016769, 0.36417, 0.010172, 0.034773, 0.18926]
Predicted label: 0
Correct prediction
Energy consumption = 151.132331 pJ
sum error= 345
Actual label: 1
Output voltages: [0.023999, 0.79863, 0.22227, 0.13769, 0.074768, 0.0011185, 0.3918, 0.0053297, 0.0388, 0.052301]
Predicted label: 1
Correct prediction
Energy consumption = 159.158587 pJ
sum error= 345
Actual label: 2
Output voltages: [0.53606, 0.028737, 0.79872, 0.22181, 0.0049524, 0.0011288, 0.036579, 0.1652, 0.48093, 0.01617]
Predicted label: 2
Correct prediction
Energy consumption = 149.281941 pJ
sum error= 345
Actual label: 3
Output voltages: [0.27208, 0.0071672, 0.24317, 0.79875, 0.041755, 0.0016276, 0.027249, 0.004204, 0.51243, 0.033411]
Predicted label: 3
Correct prediction
Energy consumption = 150.566773 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0021902, 0.0086398, 0.055734, 0.014347, 0.79866, 0.0010659, 0.042236, 0.058617, 0.021507, 0.031801]
Predicted label: 4
Correct prediction
Energy consumption = 150.685843 pJ
sum error= 345
Actual label: 5
Output voltages: [0.020812, 0.0011521, 0.0075075, 0.18494, 0.0081234, 0.79354, 0.18163, 0.010875, 0.77329, 0.010711]
Predicted label: 5
Correct prediction
Energy consumption = 150.626286 pJ
sum error= 345
Actual label: 6
Output voltages: [0.067419, 0.059885, 0.32575, 0.0020561, 0.39595, 0.20553, 0.7987, 0.0015518, 0.295, 0.0041518]
Predicted label: 6
Correct prediction
Energy consumption = 145.119024 pJ
sum error= 345
Actual label: 7
Output voltages: [0.074283, 0.06915, 0.0331, 0.2968, 0.0027002, 0.013082, 0.0010829, 0.79877, 0.14876, 0.37758]
Predicted label: 7
Correct prediction
Energy consumption = 155.791837 pJ
sum error= 345
Actual label: 8
Output voltages: [0.010935, 0.04987, 0.03924, 0.44785, 0.0017481, 0.021148, 0.009039, 0.0047411, 0.79877, 0.26502]
Predicted label: 8
Correct prediction
Energy consumption = 140.531398 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 868 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 868 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 868 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.25507, 0.016799, 0.11001, 0.048301, 0.075389, 0.0095825, 0.0017115, 0.058363, 0.43329, 0.79791]
Predicted label: 9
Correct prediction
Energy consumption = 173.098691 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79855, 0.19751, 0.085528, 0.0020868, 0.0074433, 0.0015806, 0.49845, 0.041608, 0.074991, 0.45562]
Predicted label: 0
Correct prediction
Energy consumption = 144.530415 pJ
sum error= 345
Actual label: 1
Output voltages: [0.0085968, 0.79858, 0.013023, 0.026923, 0.22823, 0.004729, 0.58038, 0.002602, 0.33331, 0.22403]
Predicted label: 1
Correct prediction
Energy consumption = 162.582386 pJ
sum error= 345
Actual label: 2
Output voltages: [0.58695, 0.012917, 0.79874, 0.066558, 0.010975, 0.0010982, 0.025894, 0.18692, 0.50505, 0.010026]
Predicted label: 2
Correct prediction
Energy consumption = 151.586504 pJ
sum error= 345
Actual label: 3
Output voltages: [0.2088, 0.015931, 0.57914, 0.79875, 0.01233, 0.0020535, 0.0089873, 0.0011885, 0.77169, 0.045212]
Predicted label: 3
Correct prediction
Energy consumption = 146.931302 pJ
sum error= 345
Actual label: 4
Output voltages: [0.013684, 0.011139, 0.34689, 0.0013879, 0.79873, 0.0011082, 0.25542, 0.13083, 0.0063568, 0.02898]
Predicted label: 4
Correct prediction
Energy consumption = 153.275588 pJ
sum error= 345
Actual label: 5
Output voltages: [0.037246, 0.0011017, 0.0011066, 0.58926, 0.39908, 0.79871, 0.43536, 0.0055431, 0.75381, 0.0065135]
Predicted label: 5
Correct prediction
Energy consumption = 143.612961 pJ
sum error= 345
Actual label: 6
Output voltages: [0.17703, 0.02817, 0.22829, 0.0010965, 0.43992, 0.056359, 0.79879, 0.0014475, 0.11005, 0.0035249]
Predicted label: 6
Correct prediction
Energy consumption = 141.709011 pJ
sum error= 345
Actual label: 7
Output voltages: [0.037861, 0.096307, 0.14046, 0.20306, 0.0048587, 0.0010665, 0.0011157, 0.79872, 0.51267, 0.13093]
Predicted label: 7
Correct prediction
Energy consumption = 162.697580 pJ
sum error= 345
Actual label: 8
Output voltages: [0.0094004, 0.063238, 0.22516, 0.18593, 0.0040429, 0.022432, 0.01929, 0.011217, 0.79871, 0.13854]
Predicted label: 8
Correct prediction
Energy consumption = 144.305499 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 869 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 869 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 869 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3329, 0.015427, 0.02182, 0.023729, 0.061408, 0.0058032, 0.0015014, 0.097689, 0.45908, 0.79817]
Predicted label: 9
Correct prediction
Energy consumption = 170.850112 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79878, 0.038131, 0.14594, 0.0046602, 0.022466, 0.0021476, 0.23097, 0.099051, 0.43634, 0.060552]
Predicted label: 0
Correct prediction
Energy consumption = 148.571090 pJ
sum error= 345
Actual label: 1
Output voltages: [0.049872, 0.79864, 0.026206, 0.024121, 0.11437, 0.0023786, 0.72408, 0.0013924, 0.19886, 0.020888]
Predicted label: 1
Correct prediction
Energy consumption = 161.295543 pJ
sum error= 345
Actual label: 2
Output voltages: [0.53728, 0.010004, 0.79879, 0.04765, 0.062858, 0.0010688, 0.042506, 0.048189, 0.42363, 0.015174]
Predicted label: 2
Correct prediction
Energy consumption = 147.344807 pJ
sum error= 345
Actual label: 3
Output voltages: [0.15187, 0.020111, 0.055004, 0.79873, 0.047245, 0.0065068, 0.011684, 0.0051914, 0.5544, 0.16265]
Predicted label: 3
Correct prediction
Energy consumption = 145.579420 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0027418, 0.0054506, 0.033259, 0.013306, 0.79863, 0.0010724, 0.035679, 0.045583, 0.05245, 0.023974]
Predicted label: 4
Correct prediction
Energy consumption = 149.151328 pJ
sum error= 345
Actual label: 5
Output voltages: [0.029454, 0.0068339, 0.0012071, 0.066418, 0.023451, 0.79864, 0.11355, 0.02692, 0.75392, 0.01937]
Predicted label: 5
Correct prediction
Energy consumption = 153.931754 pJ
sum error= 345
Actual label: 6
Output voltages: [0.07654, 0.22171, 0.54329, 0.0032346, 0.2562, 0.20474, 0.79867, 0.0019911, 0.2448, 0.019741]
Predicted label: 6
Correct prediction
Energy consumption = 146.926901 pJ
sum error= 345
Actual label: 7
Output voltages: [0.1111, 0.039417, 0.057434, 0.010031, 0.03719, 0.0011296, 0.001199, 0.79865, 0.055701, 0.014159]
Predicted label: 7
Correct prediction
Energy consumption = 152.103053 pJ
sum error= 345
Actual label: 8
Output voltages: [0.028128, 0.028899, 0.059324, 0.46828, 0.011827, 0.0097857, 0.0074011, 0.031824, 0.79877, 0.063595]
Predicted label: 8
Correct prediction
Energy consumption = 144.501432 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 870 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 870 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 870 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.1994, 0.0046343, 0.017759, 0.013059, 0.041849, 0.014642, 0.0017531, 0.014093, 0.74486, 0.79447]
Predicted label: 9
Correct prediction
Energy consumption = 163.931330 pJ
sum error= 345
Actual label: 3
Output voltages: [0.54272, 0.026472, 0.12452, 0.79869, 0.016725, 0.015663, 0.0049792, 0.025863, 0.48018, 0.044784]
Predicted label: 3
Correct prediction
Energy consumption = 149.489235 pJ
sum error= 345
Actual label: 5
Output voltages: [0.045851, 0.0081699, 0.0043675, 0.39907, 0.0044471, 0.79879, 0.23673, 0.012778, 0.63266, 0.013422]
Predicted label: 5
Correct prediction
Energy consumption = 146.974466 pJ
sum error= 345
Actual label: 3
Output voltages: [0.74176, 0.010345, 0.692, 0.79862, 0.0028617, 0.0015263, 0.024302, 0.0063567, 0.39827, 0.057734]
Predicted label: 3
Correct prediction
Energy consumption = 153.946629 pJ
sum error= 345
Actual label: 2
Output voltages: [0.41262, 0.052459, 0.79872, 0.18082, 0.024361, 0.0012123, 0.20296, 0.10214, 0.51749, 0.078158]
Predicted label: 2
Correct prediction
Energy consumption = 140.951163 pJ
sum error= 345
Actual label: 9
Output voltages: [0.27429, 0.0021575, 0.049704, 0.080297, 0.28958, 0.0088946, 0.0016419, 0.15295, 0.57713, 0.7981]
Predicted label: 9
Correct prediction
Energy consumption = 154.249637 pJ
sum error= 345
Actual label: 3
Output voltages: [0.45192, 0.0213, 0.14083, 0.79867, 0.059328, 0.0030468, 0.010918, 0.013914, 0.59657, 0.020733]
Predicted label: 3
Correct prediction
Energy consumption = 144.599556 pJ
sum error= 345
Actual label: 2
Output voltages: [0.44367, 0.0073087, 0.79869, 0.031321, 0.017551, 0.0010733, 0.038507, 0.068737, 0.70344, 0.0026914]
Predicted label: 2
Correct prediction
Energy consumption = 135.588592 pJ
sum error= 345
Actual label: 1
Output voltages: [0.011646, 0.79877, 0.1509, 0.037609, 0.20358, 0.0010707, 0.53512, 0.022853, 0.32865, 0.010387]
Predicted label: 1
Correct prediction
Energy consumption = 154.878946 pJ
sum error= 345
Actual label: 4
Output voltages: [0.020765, 0.0083288, 0.11706, 0.0083291, 0.79851, 0.011272, 0.033291, 0.038458, 0.10441, 0.0050916]
Predicted label: 4
Correct prediction
Energy consumption = 151.725665 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 871 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 871 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 871 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.013719, 0.0010659, 0.0023684, 0.21225, 0.17487, 0.79858, 0.46948, 0.0023423, 0.78045, 0.088225]
Predicted label: 5
Correct prediction
Energy consumption = 162.054251 pJ
sum error= 345
Actual label: 5
Output voltages: [0.011362, 0.0010985, 0.0023502, 0.27628, 0.036001, 0.79754, 0.451, 0.003449, 0.76535, 0.029728]
Predicted label: 5
Correct prediction
Energy consumption = 136.863052 pJ
sum error= 345
Actual label: 2
Output voltages: [0.50518, 0.019013, 0.79869, 0.14105, 0.021128, 0.0010704, 0.029244, 0.045823, 0.56597, 0.0054175]
Predicted label: 2
Correct prediction
Energy consumption = 145.424375 pJ
sum error= 345
Actual label: 3
Output voltages: [0.41595, 0.017821, 0.14653, 0.79874, 0.012187, 0.0063419, 0.039282, 0.026841, 0.63601, 0.0276]
Predicted label: 3
Correct prediction
Energy consumption = 143.050161 pJ
sum error= 345
Actual label: 2
Output voltages: [0.4998, 0.069898, 0.79878, 0.089015, 0.029719, 0.0012807, 0.062684, 0.099665, 0.34613, 0.03582]
Predicted label: 2
Correct prediction
Energy consumption = 144.371087 pJ
sum error= 345
Actual label: 1
Output voltages: [0.031224, 0.79871, 0.02252, 0.03089, 0.029017, 0.001142, 0.69665, 0.0011548, 0.51415, 0.020243]
Predicted label: 1
Correct prediction
Energy consumption = 163.249808 pJ
sum error= 345
Actual label: 3
Output voltages: [0.71931, 0.0081025, 0.16878, 0.79879, 0.0018216, 0.0026754, 0.0077103, 0.014189, 0.27748, 0.031982]
Predicted label: 3
Correct prediction
Energy consumption = 146.141267 pJ
sum error= 345
Actual label: 9
Output voltages: [0.37272, 0.0084469, 0.027356, 0.041813, 0.20387, 0.0059569, 0.0029708, 0.15184, 0.22835, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 146.025822 pJ
sum error= 345
Actual label: 7
Output voltages: [0.022684, 0.16777, 0.75126, 0.023031, 0.014946, 0.0011139, 0.0012095, 0.79873, 0.41644, 0.21357]
Predicted label: 7
Correct prediction
Energy consumption = 144.399000 pJ
sum error= 345
Actual label: 2
Output voltages: [0.45303, 0.054346, 0.79862, 0.052807, 0.014737, 0.0010768, 0.055085, 0.071498, 0.29459, 0.025347]
Predicted label: 2
Correct prediction
Energy consumption = 138.017064 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 872 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 872 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 872 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.021651, 0.79866, 0.25648, 0.10869, 0.11195, 0.0012434, 0.55102, 0.0051273, 0.073248, 0.0098846]
Predicted label: 1
Correct prediction
Energy consumption = 176.859363 pJ
sum error= 345
Actual label: 2
Output voltages: [0.60183, 0.067335, 0.79877, 0.22361, 0.0142, 0.0012211, 0.046459, 0.043471, 0.55289, 0.011659]
Predicted label: 2
Correct prediction
Energy consumption = 143.850910 pJ
sum error= 345
Actual label: 8
Output voltages: [0.055448, 0.015785, 0.03964, 0.7136, 0.0011568, 0.032034, 0.012313, 0.0054852, 0.79868, 0.090392]
Predicted label: 8
Correct prediction
Energy consumption = 147.835762 pJ
sum error= 345
Actual label: 9
Output voltages: [0.046333, 0.016619, 0.012705, 0.033361, 0.028557, 0.0063225, 0.0011053, 0.0367, 0.74728, 0.79803]
Predicted label: 9
Correct prediction
Energy consumption = 148.417021 pJ
sum error= 345
Actual label: 1
Output voltages: [0.018998, 0.79868, 0.2276, 0.021986, 0.030579, 0.0010682, 0.68909, 0.013706, 0.29527, 0.0070505]
Predicted label: 1
Correct prediction
Energy consumption = 160.543667 pJ
sum error= 345
Actual label: 8
Output voltages: [0.026453, 0.03185, 0.043776, 0.39716, 0.0029491, 0.042815, 0.0065714, 0.0042784, 0.79878, 0.34032]
Predicted label: 8
Correct prediction
Energy consumption = 154.174495 pJ
sum error= 345
Actual label: 8
Output voltages: [0.018433, 0.017644, 0.073855, 0.10309, 0.010387, 0.15001, 0.083252, 0.0083229, 0.79877, 0.16727]
Predicted label: 8
Correct prediction
Energy consumption = 145.859189 pJ
sum error= 345
Actual label: 7
Output voltages: [0.074353, 0.1071, 0.079709, 0.057759, 0.0026625, 0.0012483, 0.0010837, 0.79864, 0.067085, 0.24292]
Predicted label: 7
Correct prediction
Energy consumption = 153.849661 pJ
sum error= 345
Actual label: 8
Output voltages: [0.013591, 0.024308, 0.086113, 0.44199, 0.0025478, 0.070655, 0.029011, 0.010434, 0.79877, 0.16125]
Predicted label: 8
Correct prediction
Energy consumption = 151.994775 pJ
sum error= 345
Actual label: 1
Output voltages: [0.036163, 0.7987, 0.065467, 0.034194, 0.037364, 0.0010685, 0.74519, 0.0012907, 0.16755, 0.021922]
Predicted label: 1
Correct prediction
Energy consumption = 153.469561 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 873 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 873 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 873 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.052468, 0.029246, 0.15933, 0.020555, 0.016533, 0.58395, 0.063064, 0.23744, 0.046915]
Predicted label: 0
Correct prediction
Energy consumption = 170.484724 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79878, 0.056227, 0.17463, 0.023369, 0.010892, 0.0018261, 0.50725, 0.0076505, 0.062746, 0.31077]
Predicted label: 0
Correct prediction
Energy consumption = 140.707935 pJ
sum error= 345
Actual label: 6
Output voltages: [0.052813, 0.04281, 0.51137, 0.0010782, 0.19523, 0.061798, 0.79879, 0.0017908, 0.41557, 0.0012699]
Predicted label: 6
Correct prediction
Energy consumption = 140.527735 pJ
sum error= 345
Actual label: 7
Output voltages: [0.16763, 0.15631, 0.041085, 0.27315, 0.0016063, 0.0014011, 0.0011157, 0.7987, 0.039552, 0.62433]
Predicted label: 7
Correct prediction
Energy consumption = 160.089448 pJ
sum error= 345
Actual label: 7
Output voltages: [0.22218, 0.068317, 0.29514, 0.06418, 0.0033593, 0.0010676, 0.0011142, 0.79856, 0.4831, 0.039572]
Predicted label: 7
Correct prediction
Energy consumption = 147.872501 pJ
sum error= 345
Actual label: 8
Output voltages: [0.01228, 0.028491, 0.014579, 0.19272, 0.0020088, 0.026424, 0.006676, 0.0038021, 0.79859, 0.33806]
Predicted label: 8
Correct prediction
Energy consumption = 146.009752 pJ
sum error= 345
Actual label: 7
Output voltages: [0.081608, 0.011051, 0.010679, 0.082011, 0.030428, 0.0014887, 0.0010966, 0.79861, 0.44982, 0.61809]
Predicted label: 7
Correct prediction
Energy consumption = 148.145732 pJ
sum error= 345
Actual label: 5
Output voltages: [0.03426, 0.0042996, 0.0098148, 0.4964, 0.017335, 0.79877, 0.53521, 0.015828, 0.75312, 0.040931]
Predicted label: 5
Correct prediction
Energy consumption = 145.087785 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.010577, 0.073408, 0.0031005, 0.14965, 0.0060686, 0.48469, 0.016196, 0.055512, 0.038869]
Predicted label: 0
Correct prediction
Energy consumption = 150.410911 pJ
sum error= 345
Actual label: 6
Output voltages: [0.078074, 0.063988, 0.19775, 0.01715, 0.39679, 0.28794, 0.79863, 0.0023534, 0.64604, 0.024039]
Predicted label: 6
Correct prediction
Energy consumption = 143.700281 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 874 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 874 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 874 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0040976, 0.79854, 0.021382, 0.012966, 0.011994, 0.0041497, 0.46535, 0.0080447, 0.67688, 0.011746]
Predicted label: 1
Correct prediction
Energy consumption = 177.911343 pJ
sum error= 345
Actual label: 5
Output voltages: [0.022152, 0.0010744, 0.0018641, 0.33486, 0.072395, 0.79828, 0.32311, 0.0060674, 0.70542, 0.056502]
Predicted label: 5
Correct prediction
Energy consumption = 151.704635 pJ
sum error= 345
Actual label: 7
Output voltages: [0.19282, 0.25676, 0.75298, 0.021339, 0.0010773, 0.0011354, 0.001468, 0.79875, 0.38517, 0.019668]
Predicted label: 7
Correct prediction
Energy consumption = 158.508566 pJ
sum error= 345
Actual label: 4
Output voltages: [0.017908, 0.0085353, 0.030384, 0.0049508, 0.79879, 0.004651, 0.22587, 0.15685, 0.18634, 0.0012012]
Predicted label: 4
Correct prediction
Energy consumption = 150.100385 pJ
sum error= 345
Actual label: 6
Output voltages: [0.25372, 0.034799, 0.13353, 0.012079, 0.24121, 0.42067, 0.79879, 0.0033008, 0.73135, 0.018108]
Predicted label: 6
Correct prediction
Energy consumption = 150.484238 pJ
sum error= 345
Actual label: 1
Output voltages: [0.055154, 0.79862, 0.12502, 0.045923, 0.046504, 0.0010676, 0.75953, 0.0012528, 0.0362, 0.043692]
Predicted label: 1
Correct prediction
Energy consumption = 157.457155 pJ
sum error= 345
Actual label: 2
Output voltages: [0.33538, 0.0020271, 0.79878, 0.29677, 0.027584, 0.0010671, 0.03896, 0.074253, 0.49519, 0.0031277]
Predicted label: 2
Correct prediction
Energy consumption = 144.606620 pJ
sum error= 345
Actual label: 5
Output voltages: [0.015514, 0.0010731, 0.0045763, 0.2167, 0.17791, 0.79878, 0.21231, 0.027601, 0.77791, 0.042737]
Predicted label: 5
Correct prediction
Energy consumption = 142.484275 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79875, 0.10618, 0.0097512, 0.025621, 0.031126, 0.014269, 0.52568, 0.0049038, 0.44262, 0.031656]
Predicted label: 0
Correct prediction
Energy consumption = 149.835944 pJ
sum error= 345
Actual label: 7
Output voltages: [0.15932, 0.041358, 0.038249, 0.043114, 0.002034, 0.01382, 0.0010962, 0.79872, 0.11102, 0.62073]
Predicted label: 7
Correct prediction
Energy consumption = 149.734468 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 875 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 875 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 875 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.59088, 0.0016696, 0.024139, 0.0089091, 0.3323, 0.013208, 0.0018534, 0.033597, 0.56741, 0.79795]
Predicted label: 9
Correct prediction
Energy consumption = 172.516532 pJ
sum error= 345
Actual label: 9
Output voltages: [0.44974, 0.0085809, 0.036468, 0.030582, 0.13144, 0.0093715, 0.0011657, 0.097216, 0.60502, 0.79657]
Predicted label: 9
Correct prediction
Energy consumption = 141.156317 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.055607, 0.28611, 0.01577, 0.0028392, 0.0024737, 0.40499, 0.010577, 0.083335, 0.14947]
Predicted label: 0
Correct prediction
Energy consumption = 153.754607 pJ
sum error= 345
Actual label: 3
Output voltages: [0.7276, 0.0051908, 0.21273, 0.79879, 0.02053, 0.011988, 0.0019987, 0.011749, 0.48986, 0.009711]
Predicted label: 3
Correct prediction
Energy consumption = 149.535816 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0023154, 0.0016326, 0.10275, 0.013561, 0.79863, 0.0010702, 0.27326, 0.077604, 0.029969, 0.028409]
Predicted label: 4
Correct prediction
Energy consumption = 149.474014 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0041818, 0.004731, 0.045452, 0.021044, 0.79867, 0.0048817, 0.10314, 0.2932, 0.2869, 0.0020963]
Predicted label: 4
Correct prediction
Energy consumption = 141.986930 pJ
sum error= 345
Actual label: 8
Output voltages: [0.022812, 0.01027, 0.12678, 0.026539, 0.020372, 0.013657, 0.029408, 0.011673, 0.79877, 0.21829]
Predicted label: 8
Correct prediction
Energy consumption = 148.274253 pJ
sum error= 345
Actual label: 4
Output voltages: [0.015933, 0.0054843, 0.26977, 0.0018198, 0.79869, 0.0021071, 0.2793, 0.047678, 0.043124, 0.0079169]
Predicted label: 4
Correct prediction
Energy consumption = 150.367089 pJ
sum error= 345
Actual label: 1
Output voltages: [0.013047, 0.79859, 0.028813, 0.27282, 0.0083752, 0.0015079, 0.76222, 0.040894, 0.13095, 0.019063]
Predicted label: 1
Correct prediction
Energy consumption = 156.043582 pJ
sum error= 345
Actual label: 8
Output voltages: [0.24284, 0.014708, 0.28479, 0.043607, 0.018408, 0.0020406, 0.049316, 0.021905, 0.79879, 0.061173]
Predicted label: 8
Correct prediction
Energy consumption = 155.041864 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 876 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 876 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 876 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.05846, 0.041813, 0.24686, 0.0061184, 0.28531, 0.12519, 0.79876, 0.0015249, 0.54107, 0.0059278]
Predicted label: 6
Correct prediction
Energy consumption = 167.683184 pJ
sum error= 345
Actual label: 5
Output voltages: [0.13726, 0.0023065, 0.0012641, 0.26666, 0.0054751, 0.79879, 0.19096, 0.030032, 0.76284, 0.0070229]
Predicted label: 5
Correct prediction
Energy consumption = 148.543911 pJ
sum error= 345
Actual label: 9
Output voltages: [0.32999, 0.026525, 0.019524, 0.040306, 0.22442, 0.015961, 0.0017498, 0.012719, 0.37373, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 153.162256 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79875, 0.080872, 0.11868, 0.030146, 0.01771, 0.0011953, 0.53597, 0.01243, 0.11243, 0.09965]
Predicted label: 0
Correct prediction
Energy consumption = 153.864004 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.14476, 0.076627, 0.0076923, 0.0039396, 0.0033969, 0.50356, 0.028396, 0.044291, 0.19672]
Predicted label: 0
Correct prediction
Energy consumption = 139.666416 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.082414, 0.044276, 0.010037, 0.0051663, 0.0045156, 0.39974, 0.032837, 0.11913, 0.062735]
Predicted label: 0
Correct prediction
Energy consumption = 137.645683 pJ
sum error= 345
Actual label: 3
Output voltages: [0.74649, 0.0021086, 0.39596, 0.79879, 0.033767, 0.1556, 0.0012153, 0.018057, 0.54143, 0.0063098]
Predicted label: 3
Correct prediction
Energy consumption = 148.283474 pJ
sum error= 345
Actual label: 7
Output voltages: [0.23499, 0.013112, 0.025452, 0.082962, 0.016257, 0.043689, 0.001162, 0.79862, 0.31689, 0.30791]
Predicted label: 7
Correct prediction
Energy consumption = 148.681489 pJ
sum error= 345
Actual label: 1
Output voltages: [0.0060105, 0.79859, 0.39601, 0.048112, 0.23614, 0.0011921, 0.45522, 0.0056502, 0.012611, 0.034826]
Predicted label: 1
Correct prediction
Energy consumption = 156.592821 pJ
sum error= 345
Actual label: 6
Output voltages: [0.12714, 0.017177, 0.13966, 0.0011471, 0.42079, 0.098534, 0.79877, 0.0014189, 0.4958, 0.0034838]
Predicted label: 6
Correct prediction
Energy consumption = 141.832415 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 877 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 877 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 877 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0011695, 0.0028621, 0.049389, 0.02652, 0.7987, 0.0010768, 0.38314, 0.27008, 0.028135, 0.047249]
Predicted label: 4
Correct prediction
Energy consumption = 170.209034 pJ
sum error= 345
Actual label: 6
Output voltages: [0.25867, 0.05124, 0.27052, 0.0016635, 0.37439, 0.28225, 0.79871, 0.0018403, 0.39631, 0.005261]
Predicted label: 6
Correct prediction
Energy consumption = 147.285125 pJ
sum error= 345
Actual label: 0
Output voltages: [0.7987, 0.064186, 0.038244, 0.016327, 0.025261, 0.012712, 0.38069, 0.011217, 0.29544, 0.13736]
Predicted label: 0
Correct prediction
Energy consumption = 148.053167 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0074725, 0.0054526, 0.024163, 0.020618, 0.79872, 0.0024542, 0.15677, 0.13287, 0.029603, 0.0023428]
Predicted label: 4
Correct prediction
Energy consumption = 152.201729 pJ
sum error= 345
Actual label: 5
Output voltages: [0.0049521, 0.001143, 0.010596, 0.3854, 0.027331, 0.79419, 0.28113, 0.0045949, 0.76874, 0.017472]
Predicted label: 5
Correct prediction
Energy consumption = 149.049375 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0081312, 0.0025648, 0.034869, 0.0055714, 0.79877, 0.006229, 0.21388, 0.23137, 0.22851, 0.0011503]
Predicted label: 4
Correct prediction
Energy consumption = 154.909320 pJ
sum error= 345
Actual label: 1
Output voltages: [0.026542, 0.79859, 0.038676, 0.009685, 0.1126, 0.0014129, 0.44998, 0.010382, 0.09201, 0.025318]
Predicted label: 1
Correct prediction
Energy consumption = 155.538271 pJ
sum error= 345
Actual label: 3
Output voltages: [0.1537, 0.033268, 0.031448, 0.79861, 0.013217, 0.0085179, 0.010234, 0.01857, 0.45857, 0.058169]
Predicted label: 3
Correct prediction
Energy consumption = 145.374972 pJ
sum error= 345
Actual label: 8
Output voltages: [0.02536, 0.042484, 0.039835, 0.42919, 0.0070705, 0.066135, 0.0090971, 0.039615, 0.79879, 0.48686]
Predicted label: 8
Correct prediction
Energy consumption = 147.865498 pJ
sum error= 345
Actual label: 6
Output voltages: [0.067196, 0.063299, 0.43715, 0.0014066, 0.41333, 0.23063, 0.79872, 0.0028921, 0.33468, 0.0044505]
Predicted label: 6
Correct prediction
Energy consumption = 147.729340 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 878 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 878 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 878 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.2137, 0.025237, 0.044582, 0.79864, 0.030628, 0.0065833, 0.013762, 0.014843, 0.64544, 0.081582]
Predicted label: 3
Correct prediction
Energy consumption = 168.280363 pJ
sum error= 345
Actual label: 9
Output voltages: [0.23038, 0.026765, 0.0546, 0.10899, 0.049608, 0.087651, 0.010748, 0.042465, 0.2977, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 148.485799 pJ
sum error= 345
Actual label: 9
Output voltages: [0.056349, 0.020358, 0.067642, 0.01545, 0.021865, 0.030661, 0.0062088, 0.041401, 0.77582, 0.7898]
Predicted label: 9
Correct prediction
Energy consumption = 141.210106 pJ
sum error= 345
Actual label: 5
Output voltages: [0.0065445, 0.0036502, 0.0078067, 0.3454, 0.029443, 0.79704, 0.19101, 0.0071841, 0.69942, 0.14621]
Predicted label: 5
Correct prediction
Energy consumption = 133.387828 pJ
sum error= 345
Actual label: 9
Output voltages: [0.36734, 0.0098611, 0.085678, 0.017151, 0.048247, 0.013211, 0.0054355, 0.049291, 0.59822, 0.7941]
Predicted label: 9
Correct prediction
Energy consumption = 154.024105 pJ
sum error= 345
Actual label: 3
Output voltages: [0.76562, 0.0017063, 0.32448, 0.79879, 0.014568, 0.0051313, 0.0014864, 0.028744, 0.31686, 0.0092079]
Predicted label: 3
Correct prediction
Energy consumption = 151.863721 pJ
sum error= 345
Actual label: 7
Output voltages: [0.3389, 0.011145, 0.014714, 0.12972, 0.0044187, 0.014777, 0.0011557, 0.79873, 0.57228, 0.55802]
Predicted label: 7
Correct prediction
Energy consumption = 148.786058 pJ
sum error= 345
Actual label: 8
Output voltages: [0.071897, 0.0052173, 0.037189, 0.55482, 0.0099951, 0.015027, 0.0016871, 0.001981, 0.79866, 0.095842]
Predicted label: 8
Correct prediction
Energy consumption = 149.773227 pJ
sum error= 345
Actual label: 5
Output voltages: [0.032556, 0.0010771, 0.0014911, 0.47174, 0.036573, 0.79879, 0.11645, 0.036135, 0.73094, 0.25547]
Predicted label: 5
Correct prediction
Energy consumption = 146.450817 pJ
sum error= 345
Actual label: 6
Output voltages: [0.16562, 0.15273, 0.11056, 0.0021718, 0.16151, 0.29517, 0.7987, 0.0012665, 0.22091, 0.02178]
Predicted label: 6
Correct prediction
Energy consumption = 144.872522 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 879 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 879 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 879 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0061011, 0.0026796, 0.042259, 0.013035, 0.7987, 0.0016822, 0.2229, 0.080875, 0.023356, 0.008269]
Predicted label: 4
Correct prediction
Energy consumption = 167.176945 pJ
sum error= 345
Actual label: 7
Output voltages: [0.25908, 0.0029013, 0.019883, 0.34893, 0.0050214, 0.0073483, 0.0011634, 0.7986, 0.71371, 0.74108]
Predicted label: 7
Correct prediction
Energy consumption = 155.969678 pJ
sum error= 345
Actual label: 6
Output voltages: [0.087712, 0.032817, 0.24159, 0.0050881, 0.57014, 0.076149, 0.79877, 0.0010796, 0.33435, 0.018414]
Predicted label: 6
Correct prediction
Energy consumption = 150.972503 pJ
sum error= 345
Actual label: 2
Output voltages: [0.73478, 0.025238, 0.79879, 0.13491, 0.02488, 0.0010928, 0.060142, 0.039544, 0.5456, 0.020721]
Predicted label: 2
Correct prediction
Energy consumption = 146.530528 pJ
sum error= 345
Actual label: 2
Output voltages: [0.35633, 0.030453, 0.79878, 0.17149, 0.024701, 0.0012653, 0.050248, 0.18696, 0.3436, 0.060838]
Predicted label: 2
Correct prediction
Energy consumption = 139.430526 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79861, 0.062078, 0.20976, 0.011074, 0.036967, 0.0011076, 0.4997, 0.0027169, 0.34651, 0.19157]
Predicted label: 0
Correct prediction
Energy consumption = 149.774041 pJ
sum error= 345
Actual label: 9
Output voltages: [0.48948, 0.0042547, 0.031881, 0.020142, 0.41865, 0.027578, 0.0018377, 0.03622, 0.25965, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 152.557079 pJ
sum error= 345
Actual label: 4
Output voltages: [0.01783, 0.0071944, 0.047395, 0.016116, 0.79868, 0.0030962, 0.049196, 0.038154, 0.032845, 0.0036952]
Predicted label: 4
Correct prediction
Energy consumption = 143.896372 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79878, 0.13155, 0.23685, 0.011197, 0.0030396, 0.0019427, 0.42942, 0.0097623, 0.082745, 0.16787]
Predicted label: 0
Correct prediction
Energy consumption = 154.682416 pJ
sum error= 345
Actual label: 1
Output voltages: [0.041518, 0.7987, 0.20564, 0.062345, 0.31287, 0.0018666, 0.77443, 0.0010729, 0.044226, 0.032381]
Predicted label: 1
Correct prediction
Energy consumption = 154.359216 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 880 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 880 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 880 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.62612, 0.0034336, 0.79877, 0.058451, 0.040971, 0.0011606, 0.038603, 0.051545, 0.62746, 0.004074]
Predicted label: 2
Correct prediction
Energy consumption = 164.008279 pJ
sum error= 345
Actual label: 3
Output voltages: [0.31019, 0.026407, 0.079796, 0.79863, 0.03582, 0.011969, 0.0098926, 0.020794, 0.58264, 0.11589]
Predicted label: 3
Correct prediction
Energy consumption = 141.321696 pJ
sum error= 345
Actual label: 4
Output voltages: [0.025897, 0.0048542, 0.30062, 0.0015092, 0.7987, 0.0011938, 0.28892, 0.04973, 0.019756, 0.017674]
Predicted label: 4
Correct prediction
Energy consumption = 153.038217 pJ
sum error= 345
Actual label: 5
Output voltages: [0.028761, 0.0010762, 0.012093, 0.11322, 0.0083594, 0.79872, 0.31166, 0.0063932, 0.79378, 0.0013404]
Predicted label: 5
Correct prediction
Energy consumption = 148.710485 pJ
sum error= 345
Actual label: 6
Output voltages: [0.059904, 0.047816, 0.28341, 0.0045876, 0.40855, 0.29902, 0.79867, 0.0033095, 0.40933, 0.0070473]
Predicted label: 6
Correct prediction
Energy consumption = 144.876348 pJ
sum error= 345
Actual label: 7
Output voltages: [0.017175, 0.19559, 0.6604, 0.013464, 0.015178, 0.0010754, 0.0017382, 0.79863, 0.18362, 0.10936]
Predicted label: 7
Correct prediction
Energy consumption = 155.967090 pJ
sum error= 345
Actual label: 8
Output voltages: [0.025229, 0.16417, 0.01518, 0.037869, 0.010367, 0.034564, 0.043203, 0.034965, 0.79878, 0.043485]
Predicted label: 8
Correct prediction
Energy consumption = 145.268804 pJ
sum error= 345
Actual label: 9
Output voltages: [0.24927, 0.0090088, 0.0074802, 0.03268, 0.065336, 0.011996, 0.0045024, 0.022121, 0.45377, 0.79808]
Predicted label: 9
Correct prediction
Energy consumption = 149.223027 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.066938, 0.011287, 0.024541, 0.0086839, 0.014264, 0.49587, 0.034556, 0.174, 0.025159]
Predicted label: 0
Correct prediction
Energy consumption = 143.388175 pJ
sum error= 345
Actual label: 1
Output voltages: [0.17848, 0.79787, 0.18883, 0.026354, 0.57882, 0.0010675, 0.021507, 0.0027891, 0.028447, 0.037877]
Predicted label: 1
Correct prediction
Energy consumption = 151.544403 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 881 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 881 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 881 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36468, 0.14182, 0.79862, 0.086026, 0.013242, 0.0011304, 0.064576, 0.12252, 0.34936, 0.013517]
Predicted label: 2
Correct prediction
Energy consumption = 161.901539 pJ
sum error= 345
Actual label: 3
Output voltages: [0.25574, 0.016486, 0.27623, 0.79864, 0.18939, 0.0105, 0.024607, 0.017829, 0.61211, 0.087212]
Predicted label: 3
Correct prediction
Energy consumption = 143.908660 pJ
sum error= 345
Actual label: 4
Output voltages: [0.043942, 0.0037368, 0.4283, 0.001317, 0.79869, 0.0053758, 0.11804, 0.059741, 0.029741, 0.010747]
Predicted label: 4
Correct prediction
Energy consumption = 148.239689 pJ
sum error= 345
Actual label: 5
Output voltages: [0.044161, 0.0010953, 0.0020014, 0.27253, 0.15907, 0.79875, 0.12691, 0.020562, 0.77742, 0.028759]
Predicted label: 5
Correct prediction
Energy consumption = 148.688199 pJ
sum error= 345
Actual label: 6
Output voltages: [0.034875, 0.063162, 0.043625, 0.37967, 0.40359, 0.041271, 0.79634, 0.011462, 0.15168, 0.001094]
Predicted label: 6
Correct prediction
Energy consumption = 152.908662 pJ
sum error= 345
Actual label: 7
Output voltages: [0.52055, 0.023667, 0.27411, 0.1228, 0.013122, 0.0020715, 0.0011886, 0.79867, 0.39975, 0.11617]
Predicted label: 7
Correct prediction
Energy consumption = 158.070683 pJ
sum error= 345
Actual label: 8
Output voltages: [0.029608, 0.37779, 0.016221, 0.20074, 0.017919, 0.04186, 0.60559, 0.0025637, 0.79358, 0.03903]
Predicted label: 8
Correct prediction
Energy consumption = 148.684088 pJ
sum error= 345
Actual label: 9
Output voltages: [0.085259, 0.0098017, 0.036901, 0.053165, 0.040007, 0.0034982, 0.0017612, 0.051019, 0.61438, 0.79792]
Predicted label: 9
Correct prediction
Energy consumption = 146.087913 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79865, 0.038826, 0.055749, 0.016512, 0.014719, 0.011965, 0.27865, 0.043818, 0.032822, 0.044501]
Predicted label: 0
Correct prediction
Energy consumption = 143.883498 pJ
sum error= 345
Actual label: 1
Output voltages: [0.036128, 0.79877, 0.43666, 0.022712, 0.48977, 0.0011898, 0.42714, 0.020514, 0.092078, 0.016302]
Predicted label: 1
Correct prediction
Energy consumption = 148.225183 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 882 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 882 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 882 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.32303, 0.0012653, 0.79879, 0.10255, 0.0035614, 0.0010772, 0.005209, 0.34336, 0.75558, 0.0059124]
Predicted label: 2
Correct prediction
Energy consumption = 154.607397 pJ
sum error= 345
Actual label: 3
Output voltages: [0.70404, 0.014661, 0.06726, 0.79871, 0.0065891, 0.046358, 0.014212, 0.031535, 0.49249, 0.049177]
Predicted label: 3
Correct prediction
Energy consumption = 143.915559 pJ
sum error= 345
Actual label: 4
Output voltages: [0.031327, 0.17225, 0.047695, 0.0091809, 0.79877, 0.028014, 0.080018, 0.02595, 0.013504, 0.028166]
Predicted label: 4
Correct prediction
Energy consumption = 147.598737 pJ
sum error= 345
Actual label: 5
Output voltages: [0.1225, 0.0013867, 0.0013384, 0.27158, 0.0033685, 0.79859, 0.10731, 0.26615, 0.76869, 0.0023844]
Predicted label: 5
Correct prediction
Energy consumption = 148.738125 pJ
sum error= 345
Actual label: 6
Output voltages: [0.05327, 0.061862, 0.29317, 0.0010902, 0.22389, 0.14543, 0.79876, 0.0021861, 0.39427, 0.0022337]
Predicted label: 6
Correct prediction
Energy consumption = 143.276083 pJ
sum error= 345
Actual label: 7
Output voltages: [0.12719, 0.11722, 0.74992, 0.045742, 0.0094261, 0.0010665, 0.001122, 0.79863, 0.23952, 0.091632]
Predicted label: 7
Correct prediction
Energy consumption = 155.439534 pJ
sum error= 345
Actual label: 8
Output voltages: [0.36338, 0.043458, 0.36007, 0.035247, 0.023648, 0.0011975, 0.14819, 0.0018588, 0.79842, 0.26068]
Predicted label: 8
Correct prediction
Energy consumption = 147.566353 pJ
sum error= 345
Actual label: 9
Output voltages: [0.11104, 0.018853, 0.043202, 0.032179, 0.023428, 0.013949, 0.0055681, 0.031214, 0.76458, 0.79752]
Predicted label: 9
Correct prediction
Energy consumption = 141.367129 pJ
sum error= 345
Actual label: 6
Output voltages: [0.21434, 0.030312, 0.14551, 0.01177, 0.37551, 0.22842, 0.79878, 0.0024383, 0.54066, 0.020087]
Predicted label: 6
Correct prediction
Energy consumption = 148.076679 pJ
sum error= 345
Actual label: 4
Output voltages: [0.007813, 0.010725, 0.24322, 0.020213, 0.7986, 0.0051487, 0.089113, 0.024719, 0.028801, 0.051577]
Predicted label: 4
Correct prediction
Energy consumption = 158.863184 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 883 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 883 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 883 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36474, 0.013152, 0.79864, 0.028003, 0.034169, 0.0011263, 0.032456, 0.021823, 0.53758, 0.0048187]
Predicted label: 2
Correct prediction
Energy consumption = 155.952773 pJ
sum error= 345
Actual label: 6
Output voltages: [0.056271, 0.045912, 0.037327, 0.020654, 0.48422, 0.31765, 0.79875, 0.002439, 0.70495, 0.0050872]
Predicted label: 6
Correct prediction
Energy consumption = 152.630793 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0044581, 0.0087354, 0.033267, 0.023643, 0.79866, 0.001066, 0.25692, 0.23285, 0.03033, 0.014718]
Predicted label: 4
Correct prediction
Energy consumption = 158.989151 pJ
sum error= 345
Actual label: 7
Output voltages: [0.17489, 0.079312, 0.017748, 0.15341, 0.020649, 0.021978, 0.0011398, 0.79867, 0.080451, 0.53903]
Predicted label: 7
Correct prediction
Energy consumption = 142.740386 pJ
sum error= 345
Actual label: 5
Output voltages: [0.076952, 0.0010785, 0.0014732, 0.34632, 0.039715, 0.7987, 0.61936, 0.002594, 0.79083, 0.023735]
Predicted label: 5
Correct prediction
Energy consumption = 147.057826 pJ
sum error= 345
Actual label: 5
Output voltages: [0.024959, 0.001092, 0.0015561, 0.24136, 0.014184, 0.7926, 0.42209, 0.0083174, 0.77548, 0.01813]
Predicted label: 5
Correct prediction
Energy consumption = 133.325832 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0032367, 0.0030138, 0.20314, 0.024914, 0.7986, 0.0045304, 0.32106, 0.3089, 0.022826, 0.0069475]
Predicted label: 4
Correct prediction
Energy consumption = 155.283496 pJ
sum error= 345
Actual label: 7
Output voltages: [0.28046, 0.012978, 0.014413, 0.039352, 0.027072, 0.006099, 0.0011125, 0.79868, 0.053587, 0.48146]
Predicted label: 7
Correct prediction
Energy consumption = 150.872012 pJ
sum error= 345
Actual label: 2
Output voltages: [0.072637, 0.06287, 0.79859, 0.039598, 0.016201, 0.0011017, 0.032264, 0.16304, 0.26989, 0.021807]
Predicted label: 2
Correct prediction
Energy consumption = 137.327552 pJ
sum error= 345
Actual label: 9
Output voltages: [0.33091, 0.013647, 0.032679, 0.035939, 0.084081, 0.022854, 0.0031637, 0.22501, 0.41504, 0.79786]
Predicted label: 9
Correct prediction
Energy consumption = 159.220826 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 884 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 884 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 884 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33498, 0.025143, 0.083752, 0.79862, 0.028453, 0.01222, 0.015021, 0.016702, 0.66952, 0.031742]
Predicted label: 3
Correct prediction
Energy consumption = 162.031376 pJ
sum error= 345
Actual label: 9
Output voltages: [0.20943, 0.014136, 0.029148, 0.020402, 0.05304, 0.019823, 0.0052417, 0.034402, 0.71673, 0.7979]
Predicted label: 9
Correct prediction
Energy consumption = 146.006561 pJ
sum error= 345
Actual label: 3
Output voltages: [0.18699, 0.0024106, 0.1187, 0.79877, 0.15551, 0.026849, 0.016593, 0.0040545, 0.35934, 0.067959]
Predicted label: 3
Correct prediction
Energy consumption = 146.816130 pJ
sum error= 345
Actual label: 8
Output voltages: [0.026483, 0.10531, 0.22446, 0.029166, 0.0028615, 0.042719, 0.034341, 0.02779, 0.79875, 0.054196]
Predicted label: 8
Correct prediction
Energy consumption = 146.077871 pJ
sum error= 345
Actual label: 2
Output voltages: [0.34, 0.017459, 0.79877, 0.048581, 0.034522, 0.001071, 0.034677, 0.0087566, 0.4825, 0.03447]
Predicted label: 2
Correct prediction
Energy consumption = 145.684866 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79874, 0.070745, 0.2103, 0.020455, 0.021928, 0.001261, 0.4437, 0.034485, 0.25717, 0.02968]
Predicted label: 0
Correct prediction
Energy consumption = 155.682033 pJ
sum error= 345
Actual label: 9
Output voltages: [0.17131, 0.010581, 0.025017, 0.018159, 0.4189, 0.0029651, 0.0054728, 0.0055869, 0.45937, 0.79867]
Predicted label: 9
Correct prediction
Energy consumption = 156.008519 pJ
sum error= 345
Actual label: 5
Output voltages: [0.051384, 0.001132, 0.0010959, 0.35764, 0.19895, 0.79878, 0.66593, 0.033668, 0.67461, 0.075527]
Predicted label: 5
Correct prediction
Energy consumption = 145.852132 pJ
sum error= 345
Actual label: 6
Output voltages: [0.03015, 0.017887, 0.24099, 0.0020435, 0.28139, 0.1729, 0.79876, 0.002245, 0.66387, 0.0020304]
Predicted label: 6
Correct prediction
Energy consumption = 142.740280 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79866, 0.039035, 0.27877, 0.0032707, 0.015515, 0.0012805, 0.66421, 0.013606, 0.045567, 0.18937]
Predicted label: 0
Correct prediction
Energy consumption = 152.265272 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 885 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 885 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 885 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0071854, 0.79873, 0.17899, 0.061336, 0.071968, 0.0011416, 0.63063, 0.0059384, 0.27387, 0.029918]
Predicted label: 1
Correct prediction
Energy consumption = 175.106652 pJ
sum error= 345
Actual label: 0
Output voltages: [0.7987, 0.066278, 0.054645, 0.016757, 0.035543, 0.0091969, 0.15756, 0.077295, 0.057675, 0.19526]
Predicted label: 0
Correct prediction
Energy consumption = 149.989087 pJ
sum error= 345
Actual label: 6
Output voltages: [0.13922, 0.028651, 0.17595, 0.0035458, 0.40428, 0.23928, 0.79871, 0.001215, 0.55329, 0.0059292]
Predicted label: 6
Correct prediction
Energy consumption = 146.224309 pJ
sum error= 345
Actual label: 5
Output voltages: [0.25662, 0.0010797, 0.0014653, 0.21456, 0.051446, 0.79869, 0.52443, 0.020959, 0.77935, 0.0020909]
Predicted label: 5
Correct prediction
Energy consumption = 144.513414 pJ
sum error= 345
Actual label: 3
Output voltages: [0.51856, 0.010567, 0.063064, 0.79867, 0.015679, 0.038478, 0.011614, 0.021419, 0.61552, 0.064193]
Predicted label: 3
Correct prediction
Energy consumption = 145.126286 pJ
sum error= 345
Actual label: 5
Output voltages: [0.08694, 0.0011755, 0.0011448, 0.25426, 0.081453, 0.79875, 0.27898, 0.02138, 0.75888, 0.023406]
Predicted label: 5
Correct prediction
Energy consumption = 140.211816 pJ
sum error= 345
Actual label: 3
Output voltages: [0.43423, 0.0127, 0.054186, 0.79863, 0.038735, 0.020165, 0.019404, 0.015011, 0.55885, 0.14893]
Predicted label: 3
Correct prediction
Energy consumption = 141.515210 pJ
sum error= 345
Actual label: 8
Output voltages: [0.019551, 0.055743, 0.5143, 0.018071, 0.015048, 0.0041891, 0.024109, 0.019994, 0.79878, 0.1249]
Predicted label: 8
Correct prediction
Energy consumption = 148.399488 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79878, 0.042702, 0.083539, 0.032263, 0.033097, 0.0022222, 0.55046, 0.026561, 0.080317, 0.14541]
Predicted label: 0
Correct prediction
Energy consumption = 150.497264 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79872, 0.014057, 0.0063286, 0.025941, 0.085839, 0.032415, 0.7185, 0.043894, 0.19694, 0.023255]
Predicted label: 0
Correct prediction
Energy consumption = 139.351705 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 886 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 886 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 886 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.61712, 0.033122, 0.040335, 0.79862, 0.031679, 0.014447, 0.016154, 0.011732, 0.58741, 0.10907]
Predicted label: 3
Correct prediction
Energy consumption = 165.683454 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0040652, 0.0053086, 0.25584, 0.008308, 0.79872, 0.0021852, 0.15313, 0.13083, 0.038289, 0.016769]
Predicted label: 4
Correct prediction
Energy consumption = 155.718575 pJ
sum error= 345
Actual label: 1
Output voltages: [0.0065814, 0.79859, 0.075863, 0.019398, 0.30354, 0.0014327, 0.2436, 0.018995, 0.034058, 0.038297]
Predicted label: 1
Correct prediction
Energy consumption = 155.329981 pJ
sum error= 345
Actual label: 5
Output voltages: [0.035018, 0.0011757, 0.0011719, 0.067251, 0.057085, 0.79879, 0.64965, 0.01067, 0.78579, 0.020154]
Predicted label: 5
Correct prediction
Energy consumption = 152.655593 pJ
sum error= 345
Actual label: 3
Output voltages: [0.71827, 0.031284, 0.036863, 0.7987, 0.0065292, 0.016584, 0.018634, 0.011001, 0.38146, 0.03051]
Predicted label: 3
Correct prediction
Energy consumption = 148.508288 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79878, 0.04462, 0.15252, 0.0062381, 0.013542, 0.0022271, 0.51351, 0.0040131, 0.062854, 0.19276]
Predicted label: 0
Correct prediction
Energy consumption = 155.058528 pJ
sum error= 345
Actual label: 8
Output voltages: [0.020655, 0.077272, 0.11057, 0.12878, 0.03673, 0.0047139, 0.034492, 0.021219, 0.79879, 0.23351]
Predicted label: 8
Correct prediction
Energy consumption = 151.763391 pJ
sum error= 345
Actual label: 3
Output voltages: [0.76221, 0.014021, 0.20728, 0.79879, 0.019573, 0.020024, 0.0098625, 0.0092414, 0.29611, 0.0047624]
Predicted label: 3
Correct prediction
Energy consumption = 141.635673 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79878, 0.049453, 0.032165, 0.0055292, 0.0054685, 0.0098269, 0.63905, 0.010665, 0.21276, 0.042633]
Predicted label: 0
Correct prediction
Energy consumption = 148.476794 pJ
sum error= 345
Actual label: 6
Output voltages: [0.037417, 0.19912, 0.28917, 0.0011849, 0.30323, 0.058932, 0.79872, 0.0012417, 0.37742, 0.0023969]
Predicted label: 6
Correct prediction
Energy consumption = 135.900458 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 887 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 887 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 887 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.45027, 0.032263, 0.79878, 0.11966, 0.16283, 0.0011166, 0.033294, 0.012547, 0.40057, 0.020705]
Predicted label: 2
Correct prediction
Energy consumption = 160.321417 pJ
sum error= 345
Actual label: 7
Output voltages: [0.049487, 0.13838, 0.16366, 0.10358, 0.0043536, 0.0013873, 0.0010969, 0.79854, 0.17693, 0.20806]
Predicted label: 7
Correct prediction
Energy consumption = 150.785906 pJ
sum error= 345
Actual label: 8
Output voltages: [0.2365, 0.026099, 0.41854, 0.058535, 0.0076129, 0.015496, 0.25279, 0.0045611, 0.79871, 0.021089]
Predicted label: 8
Correct prediction
Energy consumption = 152.175923 pJ
sum error= 345
Actual label: 1
Output voltages: [0.010861, 0.79878, 0.059013, 0.03757, 0.20335, 0.0012031, 0.27849, 0.014766, 0.034899, 0.046305]
Predicted label: 1
Correct prediction
Energy consumption = 154.953407 pJ
sum error= 345
Actual label: 7
Output voltages: [0.04026, 0.034102, 0.045186, 0.24224, 0.0017538, 0.0015229, 0.001122, 0.79866, 0.31633, 0.25594]
Predicted label: 7
Correct prediction
Energy consumption = 151.126368 pJ
sum error= 345
Actual label: 1
Output voltages: [0.033508, 0.79879, 0.39091, 0.037567, 0.12851, 0.0011413, 0.77537, 0.0010665, 0.021799, 0.038697]
Predicted label: 1
Correct prediction
Energy consumption = 155.133377 pJ
sum error= 345
Actual label: 3
Output voltages: [0.3677, 0.015327, 0.028879, 0.79868, 0.028153, 0.01418, 0.012915, 0.010369, 0.53273, 0.041405]
Predicted label: 3
Correct prediction
Energy consumption = 144.641196 pJ
sum error= 345
Actual label: 8
Output voltages: [0.032503, 0.024672, 0.25332, 0.03618, 0.017072, 0.02167, 0.014547, 0.0094192, 0.79871, 0.13149]
Predicted label: 8
Correct prediction
Energy consumption = 150.408281 pJ
sum error= 345
Actual label: 5
Output voltages: [0.021991, 0.0014749, 0.0016911, 0.14546, 0.026763, 0.79878, 0.55845, 0.022982, 0.72579, 0.020985]
Predicted label: 5
Correct prediction
Energy consumption = 144.365463 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0016968, 0.018651, 0.021535, 0.03258, 0.79868, 0.0010794, 0.096392, 0.41469, 0.023599, 0.017456]
Predicted label: 4
Correct prediction
Energy consumption = 150.838355 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 888 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 888 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 888 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.61557, 0.08513, 0.79877, 0.33984, 0.015365, 0.0011657, 0.029719, 0.023846, 0.35108, 0.011178]
Predicted label: 2
Correct prediction
Energy consumption = 165.036928 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79873, 0.047677, 0.28285, 0.0074496, 0.036171, 0.0012992, 0.22099, 0.036187, 0.19251, 0.026777]
Predicted label: 0
Correct prediction
Energy consumption = 157.898226 pJ
sum error= 345
Actual label: 9
Output voltages: [0.19406, 0.006404, 0.095438, 0.046872, 0.52264, 0.01556, 0.014063, 0.0039782, 0.31746, 0.79839]
Predicted label: 9
Correct prediction
Energy consumption = 158.131373 pJ
sum error= 345
Actual label: 7
Output voltages: [0.16716, 0.022998, 0.17825, 0.23367, 0.011997, 0.0018536, 0.001183, 0.79867, 0.58205, 0.21662]
Predicted label: 7
Correct prediction
Energy consumption = 150.564849 pJ
sum error= 345
Actual label: 6
Output voltages: [0.051011, 0.047415, 0.15948, 0.0010762, 0.33475, 0.15146, 0.79875, 0.001422, 0.098059, 0.0092035]
Predicted label: 6
Correct prediction
Energy consumption = 155.872415 pJ
sum error= 345
Actual label: 7
Output voltages: [0.021237, 0.08961, 0.54231, 0.1292, 0.0018043, 0.0010667, 0.0011239, 0.79879, 0.4217, 0.32314]
Predicted label: 7
Correct prediction
Energy consumption = 154.110125 pJ
sum error= 345
Actual label: 4
Output voltages: [0.013012, 0.0023272, 0.43991, 0.020702, 0.79866, 0.001357, 0.019334, 0.011431, 0.07632, 0.040755]
Predicted label: 4
Correct prediction
Energy consumption = 151.724709 pJ
sum error= 345
Actual label: 1
Output voltages: [0.02574, 0.79798, 0.060024, 0.010487, 0.55647, 0.0010962, 0.042806, 0.02582, 0.04512, 0.023424]
Predicted label: 1
Correct prediction
Energy consumption = 151.258684 pJ
sum error= 345
Actual label: 6
Output voltages: [0.03441, 0.034977, 0.39235, 0.0021609, 0.48498, 0.19207, 0.79871, 0.0051498, 0.26, 0.0048538]
Predicted label: 6
Correct prediction
Energy consumption = 147.863140 pJ
sum error= 345
Actual label: 2
Output voltages: [0.63099, 0.027011, 0.79879, 0.45854, 0.0059445, 0.0011857, 0.050371, 0.04144, 0.50619, 0.041642]
Predicted label: 2
Correct prediction
Energy consumption = 141.193285 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 889 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 889 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 889 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.045721, 0.040177, 0.10947, 0.0027663, 0.33321, 0.19359, 0.79872, 0.0019555, 0.67029, 0.0071467]
Predicted label: 6
Correct prediction
Energy consumption = 158.892937 pJ
sum error= 345
Actual label: 7
Output voltages: [0.049136, 0.066277, 0.22341, 0.076851, 0.0052967, 0.003351, 0.0011118, 0.79858, 0.28805, 0.44668]
Predicted label: 7
Correct prediction
Energy consumption = 158.413786 pJ
sum error= 345
Actual label: 1
Output voltages: [0.47343, 0.79875, 0.21767, 0.021948, 0.28085, 0.004504, 0.026632, 0.016656, 0.0072605, 0.04645]
Predicted label: 1
Correct prediction
Energy consumption = 158.889156 pJ
sum error= 345
Actual label: 9
Output voltages: [0.39175, 0.026536, 0.023181, 0.072357, 0.19606, 0.030905, 0.0082594, 0.012522, 0.35949, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 144.974621 pJ
sum error= 345
Actual label: 8
Output voltages: [0.011948, 0.055629, 0.20359, 0.042179, 0.009279, 0.012277, 0.032103, 0.011211, 0.79866, 0.2604]
Predicted label: 8
Correct prediction
Energy consumption = 147.385187 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79876, 0.090002, 0.043186, 0.010168, 0.013477, 0.010259, 0.18076, 0.10913, 0.045142, 0.04681]
Predicted label: 0
Correct prediction
Energy consumption = 150.801681 pJ
sum error= 345
Actual label: 6
Output voltages: [0.14276, 0.049943, 0.43723, 0.0017826, 0.27315, 0.2314, 0.7987, 0.0034305, 0.17341, 0.012535]
Predicted label: 6
Correct prediction
Energy consumption = 145.191094 pJ
sum error= 345
Actual label: 9
Output voltages: [0.39616, 0.0031212, 0.036694, 0.01201, 0.048338, 0.018009, 0.002299, 0.02511, 0.53446, 0.79688]
Predicted label: 9
Correct prediction
Energy consumption = 148.299741 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0077341, 0.010232, 0.13408, 0.0066732, 0.79866, 0.0014213, 0.028362, 0.030148, 0.037006, 0.034918]
Predicted label: 4
Correct prediction
Energy consumption = 153.748245 pJ
sum error= 345
Actual label: 9
Output voltages: [0.33408, 0.0051025, 0.027983, 0.011695, 0.2355, 0.0057728, 0.0021596, 0.0075983, 0.5035, 0.79581]
Predicted label: 9
Correct prediction
Energy consumption = 139.278306 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 890 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 890 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 890 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.062017, 0.011414, 0.023406, 0.047773, 0.063208, 0.018191, 0.0035257, 0.047368, 0.69832, 0.79667]
Predicted label: 9
Correct prediction
Energy consumption = 165.696362 pJ
sum error= 345
Actual label: 6
Output voltages: [0.3028, 0.18536, 0.2302, 0.0037018, 0.11363, 0.38894, 0.79876, 0.017853, 0.36678, 0.0050503]
Predicted label: 6
Correct prediction
Energy consumption = 153.238137 pJ
sum error= 345
Actual label: 2
Output voltages: [0.60393, 0.035003, 0.79875, 0.02324, 0.0085806, 0.0011925, 0.036878, 0.046291, 0.40156, 0.014611]
Predicted label: 2
Correct prediction
Energy consumption = 152.567468 pJ
sum error= 345
Actual label: 3
Output voltages: [0.38139, 0.026467, 0.20341, 0.79875, 0.019221, 0.031274, 0.019962, 0.010895, 0.53084, 0.15705]
Predicted label: 3
Correct prediction
Energy consumption = 143.226813 pJ
sum error= 345
Actual label: 7
Output voltages: [0.62864, 0.02397, 0.001852, 0.044913, 0.03631, 0.028712, 0.0016017, 0.79879, 0.036297, 0.39326]
Predicted label: 7
Correct prediction
Energy consumption = 146.637458 pJ
sum error= 345
Actual label: 1
Output voltages: [0.22483, 0.79877, 0.035349, 0.0065107, 0.64445, 0.0051341, 0.018854, 0.0069315, 0.28726, 0.026214]
Predicted label: 1
Correct prediction
Energy consumption = 155.555608 pJ
sum error= 345
Actual label: 9
Output voltages: [0.2629, 0.012073, 0.0061018, 0.034978, 0.14748, 0.071307, 0.0060378, 0.0051625, 0.69753, 0.79772]
Predicted label: 9
Correct prediction
Energy consumption = 149.476452 pJ
sum error= 345
Actual label: 2
Output voltages: [0.65249, 0.002432, 0.79879, 0.10423, 0.014735, 0.0010784, 0.017572, 0.031506, 0.48712, 0.003205]
Predicted label: 2
Correct prediction
Energy consumption = 147.279588 pJ
sum error= 345
Actual label: 2
Output voltages: [0.21136, 0.015086, 0.79728, 0.052978, 0.33276, 0.0010852, 0.31324, 0.010831, 0.51317, 0.025893]
Predicted label: 2
Correct prediction
Energy consumption = 141.323269 pJ
sum error= 345
Actual label: 5
Output voltages: [0.033685, 0.0011262, 0.0037855, 0.44778, 0.016917, 0.79661, 0.25, 0.029761, 0.77967, 0.030919]
Predicted label: 5
Correct prediction
Energy consumption = 145.037871 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 891 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 891 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 891 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.37808, 0.0021006, 0.043404, 0.79876, 0.1677, 0.036113, 0.011145, 0.0053965, 0.64331, 0.036628]
Predicted label: 3
Correct prediction
Energy consumption = 168.694059 pJ
sum error= 345
Actual label: 7
Output voltages: [0.14075, 0.17178, 0.60185, 0.14754, 0.0016061, 0.0010764, 0.0011204, 0.79879, 0.16784, 0.44213]
Predicted label: 7
Correct prediction
Energy consumption = 150.456690 pJ
sum error= 345
Actual label: 8
Output voltages: [0.01648, 0.11912, 0.033235, 0.15795, 0.014379, 0.040874, 0.059083, 0.027744, 0.79879, 0.23557]
Predicted label: 8
Correct prediction
Energy consumption = 144.331106 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79873, 0.045253, 0.03137, 0.016452, 0.10396, 0.0062765, 0.56667, 0.025659, 0.059964, 0.073984]
Predicted label: 0
Correct prediction
Energy consumption = 152.537259 pJ
sum error= 345
Actual label: 1
Output voltages: [0.015222, 0.79859, 0.037236, 0.040963, 0.053345, 0.0025267, 0.51179, 0.0052885, 0.059569, 0.034941]
Predicted label: 1
Correct prediction
Energy consumption = 153.307014 pJ
sum error= 345
Actual label: 2
Output voltages: [0.43299, 0.0078719, 0.79862, 0.36711, 0.027948, 0.0010694, 0.016301, 0.038402, 0.63218, 0.0021184]
Predicted label: 2
Correct prediction
Energy consumption = 144.374586 pJ
sum error= 345
Actual label: 3
Output voltages: [0.10578, 0.012399, 0.18487, 0.79877, 0.014797, 0.0043556, 0.0037969, 0.02421, 0.53729, 0.042677]
Predicted label: 3
Correct prediction
Energy consumption = 139.056422 pJ
sum error= 345
Actual label: 4
Output voltages: [0.010651, 0.0067796, 0.11743, 0.0098882, 0.79857, 0.0045175, 0.035065, 0.0187, 0.061916, 0.011988]
Predicted label: 4
Correct prediction
Energy consumption = 145.946011 pJ
sum error= 345
Actual label: 7
Output voltages: [0.38234, 0.025975, 0.015087, 0.56747, 0.023907, 0.10392, 0.0011371, 0.79878, 0.40292, 0.36853]
Predicted label: 7
Correct prediction
Energy consumption = 148.277085 pJ
sum error= 345
Actual label: 8
Output voltages: [0.013222, 0.031625, 0.04569, 0.047502, 0.042497, 0.020299, 0.01613, 0.024692, 0.79867, 0.12045]
Predicted label: 8
Correct prediction
Energy consumption = 140.061691 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 892 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 892 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 892 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.47598, 0.020769, 0.056759, 0.044437, 0.16264, 0.059994, 0.0060637, 0.039513, 0.41723, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 166.345694 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79875, 0.027265, 0.060912, 0.01919, 0.021483, 0.0037421, 0.35539, 0.029024, 0.1294, 0.044232]
Predicted label: 0
Correct prediction
Energy consumption = 146.255849 pJ
sum error= 345
Actual label: 1
Output voltages: [0.054642, 0.7985, 0.39959, 0.0013123, 0.018687, 0.0045617, 0.40023, 0.0011926, 0.73567, 0.1418]
Predicted label: 1
Correct prediction
Energy consumption = 144.935424 pJ
sum error= 345
Actual label: 2
Output voltages: [0.49245, 0.0032129, 0.79878, 0.24413, 0.005419, 0.0010741, 0.027118, 0.030371, 0.42781, 0.0043254]
Predicted label: 2
Correct prediction
Energy consumption = 147.839157 pJ
sum error= 345
Actual label: 3
Output voltages: [0.35802, 0.017521, 0.14022, 0.79863, 0.039384, 0.01461, 0.011193, 0.039498, 0.70426, 0.073616]
Predicted label: 3
Correct prediction
Energy consumption = 142.797807 pJ
sum error= 345
Actual label: 4
Output voltages: [0.031693, 0.01148, 0.39907, 0.019096, 0.79866, 0.0013887, 0.065028, 0.40173, 0.010668, 0.011238]
Predicted label: 4
Correct prediction
Energy consumption = 152.627109 pJ
sum error= 345
Actual label: 7
Output voltages: [0.21194, 0.014612, 0.1335, 0.01441, 0.05781, 0.017952, 0.0011699, 0.79863, 0.057102, 0.49988]
Predicted label: 7
Correct prediction
Energy consumption = 150.799662 pJ
sum error= 345
Actual label: 8
Output voltages: [0.04959, 0.047847, 0.29678, 0.038959, 0.0074294, 0.090927, 0.013465, 0.005017, 0.79869, 0.033954]
Predicted label: 8
Correct prediction
Energy consumption = 147.409292 pJ
sum error= 345
Actual label: 9
Output voltages: [0.33413, 0.0082395, 0.02496, 0.021268, 0.034885, 0.03041, 0.006363, 0.050569, 0.67664, 0.79798]
Predicted label: 9
Correct prediction
Energy consumption = 139.874569 pJ
sum error= 345
Actual label: 0
Output voltages: [0.7987, 0.052794, 0.025923, 0.011569, 0.021338, 0.014645, 0.39182, 0.030178, 0.069368, 0.027234]
Predicted label: 0
Correct prediction
Energy consumption = 136.642245 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 893 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 893 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 893 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.023713, 0.79865, 0.13814, 0.036606, 0.54171, 0.0013565, 0.065646, 0.010431, 0.08581, 0.030921]
Predicted label: 1
Correct prediction
Energy consumption = 167.435797 pJ
sum error= 345
Actual label: 7
Output voltages: [0.47703, 0.0221, 0.047078, 0.023907, 0.062819, 0.0018422, 0.0011208, 0.79856, 0.045106, 0.02684]
Predicted label: 7
Correct prediction
Energy consumption = 146.576438 pJ
sum error= 345
Actual label: 8
Output voltages: [0.023139, 0.065972, 0.31174, 0.013684, 0.0061016, 0.0035017, 0.030098, 0.0085337, 0.79879, 0.36708]
Predicted label: 8
Correct prediction
Energy consumption = 142.026727 pJ
sum error= 345
Actual label: 9
Output voltages: [0.14431, 0.012816, 0.040923, 0.012616, 0.034212, 0.022156, 0.001943, 0.028469, 0.75973, 0.79702]
Predicted label: 9
Correct prediction
Energy consumption = 136.256883 pJ
sum error= 345
Actual label: 8
Output voltages: [0.0033112, 0.15169, 0.22334, 0.042297, 0.021536, 0.010753, 0.014587, 0.023901, 0.79875, 0.20984]
Predicted label: 8
Correct prediction
Energy consumption = 144.451056 pJ
sum error= 345
Actual label: 9
Output voltages: [0.25782, 0.022929, 0.031541, 0.046549, 0.16566, 0.014226, 0.010118, 0.020447, 0.39455, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 148.597122 pJ
sum error= 345
Actual label: 2
Output voltages: [0.50106, 0.017896, 0.79863, 0.029183, 0.0084322, 0.0010868, 0.078199, 0.030618, 0.42821, 0.009642]
Predicted label: 2
Correct prediction
Energy consumption = 146.871304 pJ
sum error= 345
Actual label: 6
Output voltages: [0.035516, 0.034954, 0.396, 0.0010678, 0.59021, 0.047288, 0.79878, 0.0011592, 0.2718, 0.0023148]
Predicted label: 6
Correct prediction
Energy consumption = 146.469885 pJ
sum error= 345
Actual label: 1
Output voltages: [0.058181, 0.79879, 0.006715, 0.0085312, 0.18506, 0.0027166, 0.25533, 0.0051049, 0.25841, 0.039951]
Predicted label: 1
Correct prediction
Energy consumption = 153.906396 pJ
sum error= 345
Actual label: 3
Output voltages: [0.25458, 0.030928, 0.24568, 0.79874, 0.0093371, 0.0025546, 0.0068992, 0.011549, 0.44546, 0.020029]
Predicted label: 3
Correct prediction
Energy consumption = 145.489351 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 894 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 894 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 894 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.2007, 0.0011952, 0.016846, 0.39825, 0.1963, 0.79879, 0.29472, 0.010406, 0.77287, 0.0073548]
Predicted label: 5
Correct prediction
Energy consumption = 159.041276 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0036813, 0.011975, 0.031392, 0.18473, 0.79879, 0.020505, 0.027812, 0.034527, 0.038786, 0.012611]
Predicted label: 4
Correct prediction
Energy consumption = 142.436538 pJ
sum error= 345
Actual label: 8
Output voltages: [0.030039, 0.35366, 0.28715, 0.042432, 0.031177, 0.0013539, 0.0032515, 0.0012988, 0.79848, 0.061918]
Predicted label: 8
Correct prediction
Energy consumption = 147.000321 pJ
sum error= 345
Actual label: 2
Output voltages: [0.31628, 0.074288, 0.79872, 0.37156, 0.0046777, 0.0011434, 0.077323, 0.032701, 0.3126, 0.0070087]
Predicted label: 2
Correct prediction
Energy consumption = 144.199432 pJ
sum error= 345
Actual label: 6
Output voltages: [0.1218, 0.012382, 0.080385, 0.0015174, 0.33032, 0.15191, 0.79879, 0.0010851, 0.69309, 0.0060973]
Predicted label: 6
Correct prediction
Energy consumption = 148.663338 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0053345, 0.006457, 0.021808, 0.030575, 0.7986, 0.0045666, 0.051185, 0.032613, 0.10936, 0.015206]
Predicted label: 4
Correct prediction
Energy consumption = 146.021021 pJ
sum error= 345
Actual label: 3
Output voltages: [0.353, 0.011456, 0.019811, 0.79865, 0.035141, 0.035928, 0.024478, 0.0020654, 0.4013, 0.074879]
Predicted label: 3
Correct prediction
Energy consumption = 146.433800 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0031175, 0.027146, 0.063637, 0.031967, 0.79871, 0.0013328, 0.022995, 0.040013, 0.048625, 0.015005]
Predicted label: 4
Correct prediction
Energy consumption = 142.819358 pJ
sum error= 345
Actual label: 5
Output voltages: [0.16876, 0.0033052, 0.0011099, 0.57121, 0.14143, 0.79873, 0.18854, 0.011629, 0.35728, 0.0088879]
Predicted label: 5
Correct prediction
Energy consumption = 136.417587 pJ
sum error= 345
Actual label: 9
Output voltages: [0.59134, 0.018565, 0.012809, 0.20393, 0.24178, 0.098494, 0.014872, 0.038703, 0.58784, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 138.239004 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 895 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 895 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 895 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.58968, 0.018115, 0.79873, 0.047691, 0.015324, 0.0011649, 0.029043, 0.024177, 0.48908, 0.0053471]
Predicted label: 2
Correct prediction
Energy consumption = 160.386497 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79861, 0.03523, 0.034908, 0.014208, 0.023182, 0.025014, 0.058376, 0.046435, 0.078455, 0.02071]
Predicted label: 0
Correct prediction
Energy consumption = 153.465290 pJ
sum error= 345
Actual label: 3
Output voltages: [0.20719, 0.024869, 0.60604, 0.7921, 0.0015072, 0.0069274, 0.0015381, 0.0036803, 0.4043, 0.12961]
Predicted label: 3
Correct prediction
Energy consumption = 152.097153 pJ
sum error= 345
Actual label: 9
Output voltages: [0.11763, 0.0059603, 0.028291, 0.014645, 0.043635, 0.0031785, 0.0032825, 0.01271, 0.65645, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 139.355758 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0081137, 0.013546, 0.046336, 0.025711, 0.79865, 0.031272, 0.38668, 0.062321, 0.11286, 0.0060637]
Predicted label: 4
Correct prediction
Energy consumption = 142.882949 pJ
sum error= 345
Actual label: 9
Output voltages: [0.27097, 0.018698, 0.018522, 0.044282, 0.028449, 0.0094032, 0.0020431, 0.025783, 0.54984, 0.79856]
Predicted label: 9
Correct prediction
Energy consumption = 141.846660 pJ
sum error= 345
Actual label: 7
Output voltages: [0.032492, 0.14052, 0.38946, 0.062308, 0.0020229, 0.0031801, 0.0012036, 0.79835, 0.50724, 0.23635]
Predicted label: 7
Correct prediction
Energy consumption = 147.216525 pJ
sum error= 345
Actual label: 3
Output voltages: [0.30763, 0.013809, 0.063831, 0.79865, 0.016984, 0.15349, 0.020616, 0.078901, 0.73658, 0.040038]
Predicted label: 3
Correct prediction
Energy consumption = 142.978996 pJ
sum error= 345
Actual label: 8
Output voltages: [0.0023772, 0.11283, 0.021037, 0.28306, 0.0017564, 0.099824, 0.0023233, 0.068671, 0.79868, 0.044997]
Predicted label: 8
Correct prediction
Energy consumption = 144.384188 pJ
sum error= 345
Actual label: 7
Output voltages: [0.097449, 0.19183, 0.10603, 0.097368, 0.032071, 0.0059334, 0.0010673, 0.79861, 0.036652, 0.2324]
Predicted label: 7
Correct prediction
Energy consumption = 142.697952 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 896 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 896 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 896 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0039525, 0.0052175, 0.090865, 0.019103, 0.7986, 0.0026499, 0.038052, 0.02652, 0.15189, 0.011456]
Predicted label: 4
Correct prediction
Energy consumption = 163.382851 pJ
sum error= 345
Actual label: 4
Output voltages: [0.030831, 0.010257, 0.44828, 0.0070998, 0.79868, 0.0097663, 0.33408, 0.11649, 0.051465, 0.0041536]
Predicted label: 4
Correct prediction
Energy consumption = 134.524353 pJ
sum error= 345
Actual label: 9
Output voltages: [0.079277, 0.028139, 0.035405, 0.18398, 0.10073, 0.025795, 0.0013989, 0.026929, 0.41428, 0.7982]
Predicted label: 9
Correct prediction
Energy consumption = 151.059452 pJ
sum error= 345
Actual label: 8
Output voltages: [0.0025411, 0.046406, 0.068951, 0.027908, 0.026556, 0.021376, 0.0070291, 0.041848, 0.79874, 0.22783]
Predicted label: 8
Correct prediction
Energy consumption = 136.049701 pJ
sum error= 345
Actual label: 5
Output voltages: [0.015781, 0.0011055, 0.0014544, 0.41631, 0.058327, 0.79879, 0.2278, 0.019125, 0.72954, 0.11236]
Predicted label: 5
Correct prediction
Energy consumption = 141.962020 pJ
sum error= 345
Actual label: 8
Output voltages: [0.0083336, 0.061302, 0.15625, 0.17493, 0.0038074, 0.036423, 0.023601, 0.23793, 0.79867, 0.025]
Predicted label: 8
Correct prediction
Energy consumption = 147.166977 pJ
sum error= 345
Actual label: 2
Output voltages: [0.38422, 0.21323, 0.79862, 0.31168, 0.023395, 0.0010983, 0.21928, 0.040126, 0.26111, 0.024676]
Predicted label: 2
Correct prediction
Energy consumption = 142.268331 pJ
sum error= 345
Actual label: 6
Output voltages: [0.014275, 0.0043931, 0.051123, 0.0068947, 0.057095, 0.5437, 0.7986, 0.0026178, 0.79152, 0.014376]
Predicted label: 6
Correct prediction
Energy consumption = 151.485697 pJ
sum error= 345
Actual label: 6
Output voltages: [0.058885, 0.02119, 0.056105, 0.019973, 0.41121, 0.44514, 0.79879, 0.0039717, 0.71019, 0.012055]
Predicted label: 6
Correct prediction
Energy consumption = 138.254764 pJ
sum error= 345
Actual label: 2
Output voltages: [0.39366, 0.019901, 0.79869, 0.058758, 0.066766, 0.0010697, 0.042568, 0.032277, 0.43658, 0.02331]
Predicted label: 2
Correct prediction
Energy consumption = 141.475072 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 897 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 897 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 897 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.17791, 0.0062419, 0.39979, 0.79879, 0.0088755, 0.0011971, 0.003429, 0.031822, 0.639, 0.030382]
Predicted label: 3
Correct prediction
Energy consumption = 161.362057 pJ
sum error= 345
Actual label: 1
Output voltages: [0.10414, 0.79879, 0.035264, 0.0050003, 0.19065, 0.0022471, 0.36685, 0.0039556, 0.094802, 0.0018635]
Predicted label: 1
Correct prediction
Energy consumption = 148.486663 pJ
sum error= 345
Actual label: 3
Output voltages: [0.4252, 0.0017693, 0.55785, 0.79878, 0.015441, 0.020332, 0.030789, 0.038908, 0.78504, 0.017122]
Predicted label: 3
Correct prediction
Energy consumption = 149.726014 pJ
sum error= 345
Actual label: 2
Output voltages: [0.019353, 0.098269, 0.79878, 0.077441, 0.021151, 0.001071, 0.16833, 0.026241, 0.73865, 0.031796]
Predicted label: 2
Correct prediction
Energy consumption = 135.800208 pJ
sum error= 345
Actual label: 7
Output voltages: [0.75882, 0.013238, 0.032495, 0.024619, 0.040773, 0.0024059, 0.001067, 0.79875, 0.15452, 0.036929]
Predicted label: 7
Correct prediction
Energy consumption = 146.836048 pJ
sum error= 345
Actual label: 3
Output voltages: [0.53785, 0.017818, 0.048041, 0.79875, 0.048926, 0.082904, 0.0061293, 0.0013126, 0.46494, 0.050395]
Predicted label: 3
Correct prediction
Energy consumption = 140.259314 pJ
sum error= 345
Actual label: 1
Output voltages: [0.046336, 0.79877, 0.16761, 0.017744, 0.42743, 0.0026253, 0.12217, 0.028398, 0.12303, 0.0014369]
Predicted label: 1
Correct prediction
Energy consumption = 149.334144 pJ
sum error= 345
Actual label: 9
Output voltages: [0.49757, 0.020032, 0.021923, 0.041542, 0.064391, 0.0049094, 0.0023351, 0.031415, 0.60798, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 151.387113 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79858, 0.038958, 0.044409, 0.012086, 0.021414, 0.018684, 0.31573, 0.020146, 0.11563, 0.033845]
Predicted label: 0
Correct prediction
Energy consumption = 139.261533 pJ
sum error= 345
Actual label: 1
Output voltages: [0.011504, 0.7987, 0.099856, 0.011209, 0.035384, 0.009656, 0.65044, 0.001544, 0.4951, 0.011393]
Predicted label: 1
Correct prediction
Energy consumption = 143.815726 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 898 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 898 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 898 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.040102, 0.79875, 0.58445, 0.017944, 0.44151, 0.0010926, 0.10139, 0.0065437, 0.021682, 0.02841]
Predicted label: 1
Correct prediction
Energy consumption = 168.178044 pJ
sum error= 345
Actual label: 3
Output voltages: [0.16112, 0.011513, 0.036041, 0.79877, 0.0073505, 0.10052, 0.0046491, 0.0097288, 0.77923, 0.019694]
Predicted label: 3
Correct prediction
Energy consumption = 138.933239 pJ
sum error= 345
Actual label: 5
Output voltages: [0.23853, 0.0012625, 0.0011037, 0.25992, 0.32334, 0.79872, 0.038461, 0.019943, 0.69643, 0.0106]
Predicted label: 5
Correct prediction
Energy consumption = 135.241434 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.03705, 0.056101, 0.013565, 0.0047928, 0.00147, 0.7274, 0.032135, 0.19892, 0.24475]
Predicted label: 0
Correct prediction
Energy consumption = 133.483711 pJ
sum error= 345
Actual label: 7
Output voltages: [0.051254, 0.36602, 0.13718, 0.040462, 0.04414, 0.0010905, 0.0010967, 0.79869, 0.030852, 0.039681]
Predicted label: 7
Correct prediction
Energy consumption = 156.799840 pJ
sum error= 345
Actual label: 8
Output voltages: [0.0025223, 0.087341, 0.18348, 0.052033, 0.0038434, 0.024849, 0.0099637, 0.029032, 0.79869, 0.13676]
Predicted label: 8
Correct prediction
Energy consumption = 147.690265 pJ
sum error= 345
Actual label: 1
Output voltages: [0.045302, 0.79878, 0.041755, 0.10502, 0.74897, 0.0013538, 0.15515, 0.0017671, 0.26802, 0.095127]
Predicted label: 1
Correct prediction
Energy consumption = 150.773716 pJ
sum error= 345
Actual label: 5
Output voltages: [0.12182, 0.0011148, 0.0010736, 0.22031, 0.038826, 0.79878, 0.046949, 0.04942, 0.7617, 0.017693]
Predicted label: 5
Correct prediction
Energy consumption = 148.941874 pJ
sum error= 345
Actual label: 1
Output voltages: [0.029628, 0.79879, 0.058379, 0.001138, 0.13488, 0.0017508, 0.31124, 0.0022565, 0.48576, 0.010525]
Predicted label: 1
Correct prediction
Energy consumption = 154.945878 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0056623, 0.0065664, 0.10297, 0.032825, 0.79871, 0.0030129, 0.04424, 0.10401, 0.13796, 0.013336]
Predicted label: 4
Correct prediction
Energy consumption = 138.294867 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 899 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 899 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 899 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.075281, 0.020255, 0.24238, 0.0095545, 0.54531, 0.13259, 0.79874, 0.0010858, 0.63312, 0.050631]
Predicted label: 6
Correct prediction
Energy consumption = 166.184536 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79873, 0.085172, 0.059185, 0.016725, 0.0069039, 0.01393, 0.44719, 0.021588, 0.048095, 0.038494]
Predicted label: 0
Correct prediction
Energy consumption = 148.732935 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79874, 0.047482, 0.12444, 0.0089634, 0.01087, 0.0039155, 0.40818, 0.016604, 0.044591, 0.022921]
Predicted label: 0
Correct prediction
Energy consumption = 133.163119 pJ
sum error= 345
Actual label: 4
Output voltages: [0.0050019, 0.025502, 0.18906, 0.019524, 0.79858, 0.0059963, 0.14528, 0.17266, 0.035373, 0.02892]
Predicted label: 4
Correct prediction
Energy consumption = 149.122507 pJ
sum error= 345
Actual label: 9
Output voltages: [0.32046, 0.0020028, 0.030826, 0.026186, 0.48758, 0.002651, 0.003899, 0.0093974, 0.43394, 0.79801]
Predicted label: 9
Correct prediction
Energy consumption = 137.821471 pJ
sum error= 345
Actual label: 1
Output voltages: [0.023092, 0.79879, 0.050553, 0.058698, 0.35828, 0.00114, 0.3842, 0.025201, 0.12172, 0.0068442]
Predicted label: 1
Correct prediction
Energy consumption = 153.294663 pJ
sum error= 345
Actual label: 6
Output voltages: [0.21194, 0.027658, 0.075462, 0.0012708, 0.46566, 0.042833, 0.79877, 0.001111, 0.57933, 0.0023199]
Predicted label: 6
Correct prediction
Energy consumption = 139.576636 pJ
sum error= 345
Actual label: 6
Output voltages: [0.15798, 0.024666, 0.16229, 0.0055579, 0.48964, 0.37431, 0.79876, 0.0010673, 0.40594, 0.025223]
Predicted label: 6
Correct prediction
Energy consumption = 139.440737 pJ
sum error= 345
Actual label: 9
Output voltages: [0.21106, 0.0023944, 0.059795, 0.011848, 0.038288, 0.0031231, 0.0012121, 0.013686, 0.77063, 0.78556]
Predicted label: 9
Correct prediction
Energy consumption = 140.403225 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79874, 0.050208, 0.011528, 0.01283, 0.0033377, 0.021906, 0.52356, 0.017043, 0.25697, 0.023713]
Predicted label: 0
Correct prediction
Energy consumption = 139.675618 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 900 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 900 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 900 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.50757, 0.012594, 0.12229, 0.051334, 0.028769, 0.0010704, 0.001066, 0.79878, 0.14589, 0.096866]
Predicted label: 7
Correct prediction
Energy consumption = 167.043437 pJ
sum error= 345
Actual label: 6
Output voltages: [0.042469, 0.022669, 0.1906, 0.010971, 0.45774, 0.26763, 0.79873, 0.0010881, 0.74712, 0.039495]
Predicted label: 6
Correct prediction
Energy consumption = 140.642010 pJ
sum error= 345
Actual label: 1
Output voltages: [0.017165, 0.79874, 0.050344, 0.0065932, 0.031777, 0.0090043, 0.52391, 0.015577, 0.69257, 0.019365]
Predicted label: 1
Correct prediction
Energy consumption = 147.820416 pJ
sum error= 345
Actual label: 1
Output voltages: [0.014127, 0.79879, 0.059985, 0.0016433, 0.13079, 0.0010696, 0.22447, 0.0012611, 0.34115, 0.11228]
Predicted label: 1
Correct prediction
Energy consumption = 132.281625 pJ
sum error= 345
Actual label: 0
Output voltages: [0.79879, 0.020258, 0.094866, 0.014565, 0.0088708, 0.0026101, 0.53942, 0.18559, 0.060368, 0.039878]
Predicted label: 0
Correct prediction
Energy consumption = 143.564793 pJ
sum error= 345
Actual label: 1
Output voltages: [0.020197, 0.79644, 0.051141, 0.002559, 0.18224, 0.0012296, 0.075853, 0.0013889, 0.74925, 0.22724]
Predicted label: 1
Correct prediction
Energy consumption = 149.726118 pJ
sum error= 345
Actual label: 2
Output voltages: [0.42328, 0.011188, 0.79879, 0.19211, 0.003543, 0.001196, 0.014983, 0.22666, 0.73696, 0.0019311]
Predicted label: 2
Correct prediction
Energy consumption = 139.045067 pJ
sum error= 345
Actual label: 3
Output voltages: [0.084208, 0.0063034, 0.25566, 0.79878, 0.0015251, 0.017378, 0.0020062, 0.028256, 0.787, 0.0022752]
Predicted label: 3
Correct prediction
Energy consumption = 131.376018 pJ
sum error= 345
Actual label: 4
Output voltages: [0.036874, 0.0021207, 0.039695, 0.005035, 0.79873, 0.0096682, 0.2965, 0.012725, 0.085138, 0.0023819]
Predicted label: 4
Correct prediction
Energy consumption = 143.174618 pJ
sum error= 345
Actual label: 7
Output voltages: [0.070672, 0.012318, 0.79757, 0.28168, 0.011001, 0.0010993, 0.0034677, 0.52041, 0.77738, 0.0011849]
Predicted label: 2
Wrong prediction!
Energy consumption = 142.701215 pJ
sum error= 346
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 901 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 901 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 901 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.23363, 0.028271, 0.79704, 0.4219, 0.0010749, 0.0010701, 0.070791, 0.020772, 0.76162, 0.0010962]
Predicted label: 2
Correct prediction
Energy consumption = 163.363560 pJ
sum error= 346
Actual label: 3
Output voltages: [0.58526, 0.0010666, 0.28524, 0.79876, 0.020271, 0.1161, 0.0015283, 0.020768, 0.77286, 0.0012197]
Predicted label: 3
Correct prediction
Energy consumption = 132.691133 pJ
sum error= 346
Actual label: 4
Output voltages: [0.056512, 0.0073699, 0.1945, 0.0018813, 0.79876, 0.0010766, 0.044298, 0.22447, 0.042296, 0.018774]
Predicted label: 4
Correct prediction
Energy consumption = 141.743044 pJ
sum error= 346
Actual label: 5
Output voltages: [0.23062, 0.0011462, 0.012247, 0.11989, 0.02206, 0.79879, 0.46021, 0.0084839, 0.75914, 0.0011799]
Predicted label: 5
Correct prediction
Energy consumption = 132.299320 pJ
sum error= 346
Actual label: 6
Output voltages: [0.20265, 0.0020847, 0.048942, 0.0022184, 0.31707, 0.17636, 0.79723, 0.0010661, 0.74776, 0.0064872]
Predicted label: 6
Correct prediction
Energy consumption = 131.613775 pJ
sum error= 346
Actual label: 7
Output voltages: [0.043068, 0.024787, 0.78692, 0.38454, 0.013383, 0.001195, 0.0031175, 0.74908, 0.54798, 0.018191]
Predicted label: 2
Wrong prediction!
Energy consumption = 147.580711 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79706, 0.010716, 0.062095, 0.0014595, 0.067585, 0.013206, 0.77238, 0.10564, 0.034308, 0.0017039]
Predicted label: 0
Correct prediction
Energy consumption = 136.059856 pJ
sum error= 347
Actual label: 1
Output voltages: [0.0010675, 0.79877, 0.038536, 0.031191, 0.25134, 0.0011538, 0.155, 0.021954, 0.26086, 0.028443]
Predicted label: 1
Correct prediction
Energy consumption = 141.195744 pJ
sum error= 347
Actual label: 2
Output voltages: [0.11135, 0.0076414, 0.79878, 0.38877, 0.0058943, 0.0012123, 0.019148, 0.15506, 0.51078, 0.0048737]
Predicted label: 2
Correct prediction
Energy consumption = 136.674820 pJ
sum error= 347
Actual label: 7
Output voltages: [0.028892, 0.0038341, 0.75895, 0.058037, 0.0063077, 0.0011473, 0.0018147, 0.79752, 0.71808, 0.0031683]
Predicted label: 7
Correct prediction
Energy consumption = 132.980719 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 902 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 902 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 902 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.019304, 0.012938, 0.012934, 0.31192, 0.0035305, 0.21935, 0.015383, 0.0012247, 0.79879, 0.18852]
Predicted label: 8
Correct prediction
Energy consumption = 166.092100 pJ
sum error= 347
Actual label: 6
Output voltages: [0.066777, 0.040078, 0.43282, 0.0011284, 0.40277, 0.0053538, 0.79874, 0.0011422, 0.27129, 0.0058594]
Predicted label: 6
Correct prediction
Energy consumption = 138.154006 pJ
sum error= 347
Actual label: 3
Output voltages: [0.070895, 0.001066, 0.75614, 0.79857, 0.0011352, 0.016816, 0.0091051, 0.072687, 0.60974, 0.0027035]
Predicted label: 3
Correct prediction
Energy consumption = 140.285444 pJ
sum error= 347
Actual label: 9
Output voltages: [0.43468, 0.0018747, 0.033613, 0.042823, 0.30132, 0.019531, 0.0011088, 0.16468, 0.4051, 0.79489]
Predicted label: 9
Correct prediction
Energy consumption = 142.289308 pJ
sum error= 347
Actual label: 7
Output voltages: [0.038199, 0.013797, 0.79299, 0.20022, 0.0039758, 0.0011882, 0.0023923, 0.79866, 0.74251, 0.025598]
Predicted label: 7
Correct prediction
Energy consumption = 138.168104 pJ
sum error= 347
Actual label: 1
Output voltages: [0.019032, 0.7987, 0.028385, 0.021183, 0.05882, 0.0020583, 0.73857, 0.0025177, 0.41912, 0.021723]
Predicted label: 1
Correct prediction
Energy consumption = 149.523802 pJ
sum error= 347
Actual label: 9
Output voltages: [0.28238, 0.01206, 0.0038424, 0.222, 0.28583, 0.093453, 0.052465, 0.02171, 0.19126, 0.79761]
Predicted label: 9
Correct prediction
Energy consumption = 139.711902 pJ
sum error= 347
Actual label: 3
Output voltages: [0.050991, 0.0090682, 0.38853, 0.79878, 0.019873, 0.02485, 0.0026313, 0.02066, 0.7431, 0.013208]
Predicted label: 3
Correct prediction
Energy consumption = 138.482030 pJ
sum error= 347
Actual label: 9
Output voltages: [0.44348, 0.0025335, 0.0080961, 0.018546, 0.015783, 0.047296, 0.0017458, 0.080594, 0.69421, 0.78291]
Predicted label: 9
Correct prediction
Energy consumption = 141.474314 pJ
sum error= 347
Actual label: 6
Output voltages: [0.059906, 0.0018936, 0.29248, 0.0018783, 0.5598, 0.31816, 0.7987, 0.0010673, 0.64698, 0.019899]
Predicted label: 6
Correct prediction
Energy consumption = 142.547393 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 903 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 903 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 903 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.45477, 0.79878, 0.2205, 0.027449, 0.31677, 0.0010689, 0.11585, 0.051445, 0.0013831, 0.099704]
Predicted label: 1
Correct prediction
Energy consumption = 177.794445 pJ
sum error= 347
Actual label: 7
Output voltages: [0.040501, 0.019628, 0.6002, 0.12972, 0.12297, 0.0011655, 0.002663, 0.79879, 0.074449, 0.1807]
Predicted label: 7
Correct prediction
Energy consumption = 147.089564 pJ
sum error= 347
Actual label: 2
Output voltages: [0.25052, 0.010797, 0.79879, 0.062837, 0.0038762, 0.0012087, 0.2022, 0.025309, 0.6601, 0.0094978]
Predicted label: 2
Correct prediction
Energy consumption = 137.797485 pJ
sum error= 347
Actual label: 4
Output voltages: [0.0067274, 0.0055505, 0.048542, 0.0037101, 0.79866, 0.011025, 0.19087, 0.31531, 0.18129, 0.0087151]
Predicted label: 4
Correct prediction
Energy consumption = 148.709722 pJ
sum error= 347
Actual label: 4
Output voltages: [0.0015763, 0.021519, 0.032221, 0.016104, 0.79874, 0.0022066, 0.11719, 0.48456, 0.04318, 0.0022345]
Predicted label: 4
Correct prediction
Energy consumption = 138.184560 pJ
sum error= 347
Actual label: 5
Output voltages: [0.044679, 0.022278, 0.0010706, 0.17426, 0.16918, 0.79868, 0.090408, 0.020995, 0.77919, 0.0017648]
Predicted label: 5
Correct prediction
Energy consumption = 143.250543 pJ
sum error= 347
Actual label: 7
Output voltages: [0.024476, 0.51729, 0.78445, 0.22351, 0.0069072, 0.0011669, 0.0012392, 0.77885, 0.21915, 0.027009]
Predicted label: 2
Wrong prediction!
Energy consumption = 148.757686 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79875, 0.011051, 0.028577, 0.0061659, 0.071328, 0.024336, 0.64994, 0.029379, 0.027129, 0.25984]
Predicted label: 0
Correct prediction
Energy consumption = 141.830861 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79878, 0.024401, 0.15921, 0.0023338, 0.030743, 0.021295, 0.74902, 0.29954, 0.021575, 0.027717]
Predicted label: 0
Correct prediction
Energy consumption = 127.009565 pJ
sum error= 348
Actual label: 1
Output voltages: [0.014706, 0.79877, 0.27972, 0.0089186, 0.25196, 0.0092819, 0.67388, 0.0016013, 0.41685, 0.028647]
Predicted label: 1
Correct prediction
Energy consumption = 152.746254 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 904 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 904 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 904 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.32109, 0.0028848, 0.025227, 0.026811, 0.20824, 0.76934, 0.79813, 0.0010911, 0.6109, 0.036806]
Predicted label: 6
Correct prediction
Energy consumption = 162.138671 pJ
sum error= 348
Actual label: 6
Output voltages: [0.39827, 0.037556, 0.039621, 0.0022225, 0.15192, 0.30086, 0.79868, 0.0011835, 0.18898, 0.011871]
Predicted label: 6
Correct prediction
Energy consumption = 131.927113 pJ
sum error= 348
Actual label: 8
Output voltages: [0.010433, 0.026774, 0.065132, 0.012185, 0.024503, 0.017708, 0.020708, 0.0018229, 0.79869, 0.25049]
Predicted label: 8
Correct prediction
Energy consumption = 143.814406 pJ
sum error= 348
Actual label: 2
Output voltages: [0.31047, 0.091645, 0.79873, 0.1699, 0.0069728, 0.0012771, 0.10106, 0.025992, 0.39122, 0.023511]
Predicted label: 2
Correct prediction
Energy consumption = 140.681722 pJ
sum error= 348
Actual label: 7
Output voltages: [0.036375, 0.0034426, 0.78208, 0.015682, 0.011373, 0.0011972, 0.0073999, 0.79877, 0.36509, 0.034897]
Predicted label: 7
Correct prediction
Energy consumption = 141.566001 pJ
sum error= 348
Actual label: 7
Output voltages: [0.011766, 0.025904, 0.77277, 0.04025, 0.040596, 0.0011296, 0.0021451, 0.79878, 0.24229, 0.031287]
Predicted label: 7
Correct prediction
Energy consumption = 133.982439 pJ
sum error= 348
Actual label: 2
Output voltages: [0.065239, 0.0040874, 0.79868, 0.34426, 0.0015562, 0.0011119, 0.014235, 0.3043, 0.77728, 0.0018538]
Predicted label: 2
Correct prediction
Energy consumption = 129.349317 pJ
sum error= 348
Actual label: 4
Output voltages: [0.010945, 0.020204, 0.022813, 0.0016353, 0.79878, 0.0011896, 0.25968, 0.59462, 0.059114, 0.0070752]
Predicted label: 4
Correct prediction
Energy consumption = 148.345230 pJ
sum error= 348
Actual label: 2
Output voltages: [0.3123, 0.04547, 0.79874, 0.043703, 0.015721, 0.0012379, 0.32856, 0.042623, 0.72749, 0.032102]
Predicted label: 2
Correct prediction
Energy consumption = 151.195541 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0096234, 0.79874, 0.16582, 0.0057131, 0.12863, 0.0077716, 0.67326, 0.0047136, 0.63645, 0.034447]
Predicted label: 1
Correct prediction
Energy consumption = 147.039213 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 905 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 905 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 905 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.13983, 0.0050292, 0.17046, 0.001701, 0.23017, 0.063267, 0.79869, 0.0011021, 0.62753, 0.0098597]
Predicted label: 6
Correct prediction
Energy consumption = 164.361198 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0133, 0.79844, 0.0025131, 0.30445, 0.17124, 0.0010712, 0.24908, 0.0031941, 0.56716, 0.021647]
Predicted label: 1
Correct prediction
Energy consumption = 162.868936 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79875, 0.13841, 0.016944, 0.013062, 0.01402, 0.012069, 0.46755, 0.019493, 0.15062, 0.029878]
Predicted label: 0
Correct prediction
Energy consumption = 147.136335 pJ
sum error= 348
Actual label: 6
Output voltages: [0.082966, 0.055809, 0.2834, 0.0012153, 0.44748, 0.0325, 0.79872, 0.0010817, 0.18337, 0.011244]
Predicted label: 6
Correct prediction
Energy consumption = 140.856517 pJ
sum error= 348
Actual label: 9
Output voltages: [0.53691, 0.005641, 0.023626, 0.046889, 0.10339, 0.025117, 0.0010889, 0.49212, 0.41147, 0.79501]
Predicted label: 9
Correct prediction
Energy consumption = 152.878957 pJ
sum error= 348
Actual label: 8
Output voltages: [0.015917, 0.01212, 0.053802, 0.21859, 0.0013174, 0.15768, 0.026764, 0.030406, 0.79874, 0.030866]
Predicted label: 8
Correct prediction
Energy consumption = 151.742080 pJ
sum error= 348
Actual label: 3
Output voltages: [0.26655, 0.004947, 0.10935, 0.79873, 0.011297, 0.27756, 0.0048278, 0.024158, 0.63263, 0.0094817]
Predicted label: 3
Correct prediction
Energy consumption = 144.039909 pJ
sum error= 348
Actual label: 9
Output voltages: [0.11331, 0.0093391, 0.011709, 0.11734, 0.024666, 0.0086053, 0.0011362, 0.037899, 0.73996, 0.79806]
Predicted label: 9
Correct prediction
Energy consumption = 143.143790 pJ
sum error= 348
Actual label: 6
Output voltages: [0.10813, 0.022377, 0.23541, 0.0010692, 0.30464, 0.062178, 0.79879, 0.0017446, 0.30916, 0.0023105]
Predicted label: 6
Correct prediction
Energy consumption = 146.581087 pJ
sum error= 348
Actual label: 3
Output voltages: [0.14014, 0.0034166, 0.10561, 0.79871, 0.019475, 0.34621, 0.0096223, 0.020542, 0.76192, 0.0085899]
Predicted label: 3
Correct prediction
Energy consumption = 141.003030 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 906 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 906 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 906 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79873, 0.040711, 0.36187, 0.01129, 0.0020735, 0.0091461, 0.2217, 0.0099178, 0.039463, 0.088032]
Predicted label: 0
Correct prediction
Energy consumption = 168.726507 pJ
sum error= 348
Actual label: 1
Output voltages: [0.033205, 0.7985, 0.079529, 0.083533, 0.0013059, 0.0019735, 0.4818, 0.0099734, 0.19552, 0.038076]
Predicted label: 1
Correct prediction
Energy consumption = 159.298200 pJ
sum error= 348
Actual label: 2
Output voltages: [0.061474, 0.091574, 0.79832, 0.018992, 0.017239, 0.0013915, 0.3989, 0.043968, 0.53151, 0.039237]
Predicted label: 2
Correct prediction
Energy consumption = 152.895386 pJ
sum error= 348
Actual label: 3
Output voltages: [0.16144, 0.44736, 0.37421, 0.79877, 0.017822, 0.0011639, 0.0089335, 0.014976, 0.17034, 0.044977]
Predicted label: 3
Correct prediction
Energy consumption = 144.159661 pJ
sum error= 348
Actual label: 4
Output voltages: [0.020367, 0.023354, 0.034806, 0.001227, 0.79863, 0.017754, 0.070844, 0.081746, 0.10525, 0.031696]
Predicted label: 4
Correct prediction
Energy consumption = 156.525426 pJ
sum error= 348
Actual label: 5
Output voltages: [0.038268, 0.0010853, 0.0037578, 0.41533, 0.029363, 0.79874, 0.071311, 0.087806, 0.76045, 0.17162]
Predicted label: 5
Correct prediction
Energy consumption = 152.233700 pJ
sum error= 348
Actual label: 6
Output voltages: [0.03856, 0.044387, 0.30391, 0.0033767, 0.15277, 0.44467, 0.79871, 0.014776, 0.70704, 0.008543]
Predicted label: 6
Correct prediction
Energy consumption = 142.829704 pJ
sum error= 348
Actual label: 7
Output voltages: [0.095719, 0.031062, 0.045108, 0.0058642, 0.13838, 0.024495, 0.0010941, 0.7985, 0.1227, 0.056439]
Predicted label: 7
Correct prediction
Energy consumption = 160.424579 pJ
sum error= 348
Actual label: 8
Output voltages: [0.016083, 0.019396, 0.13135, 0.057895, 0.0085594, 0.037792, 0.018747, 0.02584, 0.79866, 0.06089]
Predicted label: 8
Correct prediction
Energy consumption = 148.444020 pJ
sum error= 348
Actual label: 9
Output voltages: [0.5436, 0.0055666, 0.01656, 0.013552, 0.38519, 0.0097228, 0.0067733, 0.010094, 0.17468, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 143.695120 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 907 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 907 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 907 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.13195, 0.036222, 0.014391, 0.0043005, 0.012527, 0.59952, 0.026644, 0.086717, 0.047825]
Predicted label: 0
Correct prediction
Energy consumption = 163.765802 pJ
sum error= 348
Actual label: 1
Output voltages: [0.070767, 0.79749, 0.19136, 0.033862, 0.027283, 0.0011401, 0.47803, 0.001468, 0.43619, 0.045061]
Predicted label: 1
Correct prediction
Energy consumption = 158.173186 pJ
sum error= 348
Actual label: 2
Output voltages: [0.26843, 0.22223, 0.79878, 0.4483, 0.036661, 0.001167, 0.40498, 0.0041239, 0.52265, 0.16866]
Predicted label: 2
Correct prediction
Energy consumption = 152.917485 pJ
sum error= 348
Actual label: 3
Output voltages: [0.37304, 0.0055148, 0.13151, 0.79879, 0.0013429, 0.041897, 0.0058058, 0.33288, 0.76721, 0.023323]
Predicted label: 3
Correct prediction
Energy consumption = 137.582351 pJ
sum error= 348
Actual label: 4
Output voltages: [0.022642, 0.0083677, 0.037449, 0.0010957, 0.79874, 0.024941, 0.70993, 0.027634, 0.35396, 0.0083227]
Predicted label: 4
Correct prediction
Energy consumption = 162.313053 pJ
sum error= 348
Actual label: 5
Output voltages: [0.14765, 0.0010663, 0.0012115, 0.29603, 0.15791, 0.79873, 0.24532, 0.038652, 0.77993, 0.061995]
Predicted label: 5
Correct prediction
Energy consumption = 145.447160 pJ
sum error= 348
Actual label: 6
Output voltages: [0.089246, 0.017656, 0.40264, 0.021315, 0.23345, 0.4565, 0.7987, 0.0010749, 0.54233, 0.016923]
Predicted label: 6
Correct prediction
Energy consumption = 144.772166 pJ
sum error= 348
Actual label: 7
Output voltages: [0.17919, 0.15738, 0.052699, 0.076055, 0.014144, 0.0013391, 0.001098, 0.79868, 0.45327, 0.49423]
Predicted label: 7
Correct prediction
Energy consumption = 159.933326 pJ
sum error= 348
Actual label: 8
Output voltages: [0.031017, 0.015313, 0.098752, 0.046114, 0.0073926, 0.036686, 0.061761, 0.01365, 0.79877, 0.13968]
Predicted label: 8
Correct prediction
Energy consumption = 147.087218 pJ
sum error= 348
Actual label: 9
Output voltages: [0.17502, 0.0046775, 0.036887, 0.093481, 0.62465, 0.043925, 0.041242, 0.0012589, 0.10204, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 148.560077 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 908 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 908 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 908 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.061605, 0.042402, 0.003957, 0.0039241, 0.0088663, 0.49444, 0.0096013, 0.27343, 0.085769]
Predicted label: 0
Correct prediction
Energy consumption = 163.826191 pJ
sum error= 348
Actual label: 1
Output voltages: [0.013662, 0.79858, 0.028703, 0.057528, 0.051644, 0.0024936, 0.39035, 0.0015477, 0.46704, 0.040704]
Predicted label: 1
Correct prediction
Energy consumption = 161.450166 pJ
sum error= 348
Actual label: 2
Output voltages: [0.028294, 0.13579, 0.79805, 0.11473, 0.0055626, 0.0012723, 0.4229, 0.0021834, 0.70809, 0.022165]
Predicted label: 2
Correct prediction
Energy consumption = 148.910301 pJ
sum error= 348
Actual label: 3
Output voltages: [0.42385, 0.030877, 0.057156, 0.79866, 0.050566, 0.0031594, 0.020926, 0.0077442, 0.73764, 0.044203]
Predicted label: 3
Correct prediction
Energy consumption = 141.467883 pJ
sum error= 348
Actual label: 4
Output voltages: [0.20011, 0.0013965, 0.17584, 0.0011112, 0.79879, 0.0011879, 0.24533, 0.020167, 0.31474, 0.0026642]
Predicted label: 4
Correct prediction
Energy consumption = 154.329582 pJ
sum error= 348
Actual label: 5
Output voltages: [0.021231, 0.0011013, 0.017178, 0.06908, 0.033642, 0.79834, 0.038933, 0.046427, 0.78647, 0.16544]
Predicted label: 5
Correct prediction
Energy consumption = 146.773433 pJ
sum error= 348
Actual label: 6
Output voltages: [0.057618, 0.073832, 0.1454, 0.0035246, 0.2598, 0.20215, 0.79874, 0.0010709, 0.3259, 0.017396]
Predicted label: 6
Correct prediction
Energy consumption = 141.155715 pJ
sum error= 348
Actual label: 7
Output voltages: [0.063644, 0.043829, 0.038218, 0.015898, 0.026185, 0.0019568, 0.0010828, 0.7986, 0.29581, 0.072444]
Predicted label: 7
Correct prediction
Energy consumption = 156.682439 pJ
sum error= 348
Actual label: 8
Output voltages: [0.034549, 0.030207, 0.032106, 0.29484, 0.012119, 0.21485, 0.29639, 0.0018499, 0.79878, 0.27719]
Predicted label: 8
Correct prediction
Energy consumption = 154.757255 pJ
sum error= 348
Actual label: 9
Output voltages: [0.16272, 0.030097, 0.012932, 0.10857, 0.15269, 0.016195, 0.011043, 0.021953, 0.24497, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 143.950217 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 909 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 909 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 909 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0017971, 0.79864, 0.040149, 0.2405, 0.10392, 0.001307, 0.062489, 0.015302, 0.27745, 0.16271]
Predicted label: 1
Correct prediction
Energy consumption = 183.135189 pJ
sum error= 348
Actual label: 6
Output voltages: [0.24898, 0.035522, 0.34895, 0.0031753, 0.35996, 0.41959, 0.79871, 0.0025006, 0.44591, 0.01229]
Predicted label: 6
Correct prediction
Energy consumption = 156.245115 pJ
sum error= 348
Actual label: 8
Output voltages: [0.051896, 0.0085739, 0.010224, 0.40847, 0.0024794, 0.069658, 0.0031755, 0.0020396, 0.79877, 0.29258]
Predicted label: 8
Correct prediction
Energy consumption = 158.443889 pJ
sum error= 348
Actual label: 9
Output voltages: [0.55034, 0.0085317, 0.036509, 0.074844, 0.12553, 0.010676, 0.006089, 0.05284, 0.10951, 0.79312]
Predicted label: 9
Correct prediction
Energy consumption = 150.323153 pJ
sum error= 348
Actual label: 9
Output voltages: [0.24756, 0.015745, 0.41261, 0.048078, 0.070622, 0.016131, 0.0096391, 0.061264, 0.20237, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 147.220919 pJ
sum error= 348
Actual label: 0
Output voltages: [0.7984, 0.025153, 0.026961, 0.0028842, 0.0013875, 0.0087349, 0.69531, 0.0046408, 0.20601, 0.04994]
Predicted label: 0
Correct prediction
Energy consumption = 152.940194 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0062941, 0.79858, 0.046197, 0.035862, 0.018601, 0.0021683, 0.66312, 0.0048557, 0.15724, 0.041901]
Predicted label: 1
Correct prediction
Energy consumption = 158.529656 pJ
sum error= 348
Actual label: 2
Output voltages: [0.29783, 0.18472, 0.79813, 0.28047, 0.033531, 0.0012353, 0.4109, 0.0034827, 0.61167, 0.052005]
Predicted label: 2
Correct prediction
Energy consumption = 146.272549 pJ
sum error= 348
Actual label: 4
Output voltages: [0.011311, 0.0098779, 0.21217, 0.0059188, 0.79861, 0.01142, 0.15661, 0.2101, 0.039103, 0.0235]
Predicted label: 4
Correct prediction
Energy consumption = 157.778176 pJ
sum error= 348
Actual label: 4
Output voltages: [0.005446, 0.0023555, 0.040573, 0.0066918, 0.79852, 0.0089669, 0.24738, 0.096936, 0.15397, 0.031048]
Predicted label: 4
Correct prediction
Energy consumption = 137.897630 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 910 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 910 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 910 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.17025, 0.029388, 0.2471, 0.79878, 0.013513, 0.0011444, 0.0094719, 0.0016556, 0.56187, 0.10491]
Predicted label: 3
Correct prediction
Energy consumption = 164.633897 pJ
sum error= 348
Actual label: 7
Output voltages: [0.050721, 0.047302, 0.21783, 0.22946, 0.0037028, 0.0015053, 0.0026456, 0.79856, 0.034451, 0.34395]
Predicted label: 7
Correct prediction
Energy consumption = 151.496813 pJ
sum error= 348
Actual label: 4
Output voltages: [0.0077704, 0.0067428, 0.036978, 0.0058463, 0.79867, 0.003169, 0.27347, 0.34735, 0.043634, 0.0060594]
Predicted label: 4
Correct prediction
Energy consumption = 154.126257 pJ
sum error= 348
Actual label: 4
Output voltages: [0.038275, 0.0099236, 0.18119, 0.01001, 0.79864, 0.0021778, 0.53748, 0.042016, 0.015877, 0.0081042]
Predicted label: 4
Correct prediction
Energy consumption = 147.145684 pJ
sum error= 348
Actual label: 4
Output voltages: [0.0014205, 0.0045859, 0.021898, 0.0046766, 0.79861, 0.0016003, 0.1407, 0.45422, 0.078707, 0.030445]
Predicted label: 4
Correct prediction
Energy consumption = 144.685473 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79865, 0.078852, 0.034088, 0.0066515, 0.0077602, 0.0020861, 0.74999, 0.017006, 0.13215, 0.10083]
Predicted label: 0
Correct prediction
Energy consumption = 151.829551 pJ
sum error= 348
Actual label: 3
Output voltages: [0.38315, 0.021776, 0.088092, 0.79871, 0.043844, 0.0015025, 0.0060539, 0.013483, 0.61738, 0.017597]
Predicted label: 3
Correct prediction
Energy consumption = 148.850893 pJ
sum error= 348
Actual label: 8
Output voltages: [0.027793, 0.026452, 0.047157, 0.043326, 0.011406, 0.039867, 0.014936, 0.018198, 0.79875, 0.17719]
Predicted label: 8
Correct prediction
Energy consumption = 148.341171 pJ
sum error= 348
Actual label: 7
Output voltages: [0.55917, 0.011926, 0.0034682, 0.032071, 0.15066, 0.22526, 0.0010923, 0.79864, 0.11747, 0.38236]
Predicted label: 7
Correct prediction
Energy consumption = 151.178477 pJ
sum error= 348
Actual label: 5
Output voltages: [0.019073, 0.0010735, 0.0022141, 0.046829, 0.034397, 0.79758, 0.054349, 0.014705, 0.78633, 0.099134]
Predicted label: 5
Correct prediction
Energy consumption = 139.735565 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 911 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 911 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 911 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.005473, 0.02643, 0.40792, 0.32306, 0.020029, 0.0052271, 0.021921, 0.020682, 0.79806, 0.189]
Predicted label: 8
Correct prediction
Energy consumption = 167.781734 pJ
sum error= 348
Actual label: 2
Output voltages: [0.54424, 0.038261, 0.79874, 0.35558, 0.020281, 0.0012092, 0.19153, 0.009704, 0.66034, 0.013736]
Predicted label: 2
Correct prediction
Energy consumption = 150.744507 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0084721, 0.79873, 0.023306, 0.019163, 0.62495, 0.17999, 0.76306, 0.0016745, 0.064953, 0.027157]
Predicted label: 1
Correct prediction
Energy consumption = 160.470567 pJ
sum error= 348
Actual label: 7
Output voltages: [0.023487, 0.073022, 0.032285, 0.0012151, 0.048567, 0.0020999, 0.0058214, 0.79857, 0.30514, 0.13994]
Predicted label: 7
Correct prediction
Energy consumption = 156.615811 pJ
sum error= 348
Actual label: 5
Output voltages: [0.10263, 0.0010748, 0.001197, 0.37027, 0.025439, 0.7985, 0.14094, 0.044921, 0.77572, 0.034384]
Predicted label: 5
Correct prediction
Energy consumption = 145.353111 pJ
sum error= 348
Actual label: 3
Output voltages: [0.32331, 0.017784, 0.029757, 0.79868, 0.014956, 0.013079, 0.013316, 0.0064965, 0.67253, 0.051908]
Predicted label: 3
Correct prediction
Energy consumption = 146.354614 pJ
sum error= 348
Actual label: 8
Output voltages: [0.29232, 0.022317, 0.40449, 0.019952, 0.0039752, 0.012428, 0.10545, 0.0022447, 0.79868, 0.16018]
Predicted label: 8
Correct prediction
Energy consumption = 150.311328 pJ
sum error= 348
Actual label: 5
Output voltages: [0.076263, 0.0010685, 0.0011197, 0.71263, 0.0039159, 0.7982, 0.13042, 0.0555, 0.66123, 0.0037512]
Predicted label: 5
Correct prediction
Energy consumption = 150.660641 pJ
sum error= 348
Actual label: 2
Output voltages: [0.32373, 0.040668, 0.79877, 0.10209, 0.023201, 0.0012767, 0.30034, 0.022335, 0.51305, 0.026842]
Predicted label: 2
Correct prediction
Energy consumption = 148.844512 pJ
sum error= 348
Actual label: 5
Output voltages: [0.020499, 0.0010679, 0.013026, 0.1979, 0.018419, 0.79834, 0.065497, 0.025131, 0.78775, 0.040038]
Predicted label: 5
Correct prediction
Energy consumption = 140.550773 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 912 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 912 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 912 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0061817, 0.79872, 0.10753, 0.045674, 0.11925, 0.0010995, 0.44474, 0.0024087, 0.32966, 0.034184]
Predicted label: 1
Correct prediction
Energy consumption = 187.665253 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0058256, 0.79867, 0.22672, 0.033252, 0.018316, 0.0010667, 0.74511, 0.0017387, 0.18538, 0.0078083]
Predicted label: 1
Correct prediction
Energy consumption = 147.660634 pJ
sum error= 348
Actual label: 6
Output voltages: [0.04127, 0.040654, 0.085251, 0.0016044, 0.30505, 0.30152, 0.79879, 0.001294, 0.33673, 0.0022608]
Predicted label: 6
Correct prediction
Energy consumption = 144.935602 pJ
sum error= 348
Actual label: 2
Output voltages: [0.20091, 0.021179, 0.7978, 0.47681, 0.0082037, 0.0012925, 0.16075, 0.019377, 0.63667, 0.011982]
Predicted label: 2
Correct prediction
Energy consumption = 140.533465 pJ
sum error= 348
Actual label: 1
Output voltages: [0.072481, 0.79857, 0.36494, 0.10723, 0.04138, 0.0012761, 0.73255, 0.0018685, 0.036511, 0.025788]
Predicted label: 1
Correct prediction
Energy consumption = 163.498463 pJ
sum error= 348
Actual label: 3
Output voltages: [0.27315, 0.029489, 0.14212, 0.79858, 0.038593, 0.012716, 0.010389, 0.022288, 0.69527, 0.036448]
Predicted label: 3
Correct prediction
Energy consumption = 147.461699 pJ
sum error= 348
Actual label: 8
Output voltages: [0.24749, 0.01383, 0.062142, 0.19878, 0.049406, 0.013302, 0.62755, 0.0042864, 0.79879, 0.041621]
Predicted label: 8
Correct prediction
Energy consumption = 149.011618 pJ
sum error= 348
Actual label: 6
Output voltages: [0.035527, 0.024127, 0.34888, 0.0044686, 0.25981, 0.2013, 0.79878, 0.0047368, 0.47194, 0.0015168]
Predicted label: 6
Correct prediction
Energy consumption = 149.795678 pJ
sum error= 348
Actual label: 4
Output voltages: [0.0073386, 0.059865, 0.10982, 0.007829, 0.79859, 0.015761, 0.39864, 0.26804, 0.061969, 0.021138]
Predicted label: 4
Correct prediction
Energy consumption = 154.095545 pJ
sum error= 348
Actual label: 2
Output voltages: [0.17845, 0.52873, 0.79831, 0.59198, 0.012362, 0.0012506, 0.36349, 0.0021287, 0.58563, 0.057467]
Predicted label: 2
Correct prediction
Energy consumption = 150.134166 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 913 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 913 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 913 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.39194, 0.46416, 0.41007, 0.0034096, 0.027924, 0.025815, 0.79879, 0.0013578, 0.57209, 0.011768]
Predicted label: 6
Correct prediction
Energy consumption = 170.074330 pJ
sum error= 348
Actual label: 2
Output voltages: [0.20589, 0.068643, 0.7987, 0.027742, 0.0050328, 0.0013086, 0.14, 0.24142, 0.42963, 0.028392]
Predicted label: 2
Correct prediction
Energy consumption = 148.264479 pJ
sum error= 348
Actual label: 5
Output voltages: [0.045533, 0.0010825, 0.0090583, 0.35168, 0.046135, 0.79877, 0.34071, 0.02993, 0.77843, 0.069522]
Predicted label: 5
Correct prediction
Energy consumption = 151.290383 pJ
sum error= 348
Actual label: 5
Output voltages: [0.043211, 0.0011087, 0.0017961, 0.30883, 0.021743, 0.79839, 0.071957, 0.024173, 0.78511, 0.01434]
Predicted label: 5
Correct prediction
Energy consumption = 136.190145 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79875, 0.057478, 0.35844, 0.012752, 0.0021378, 0.0072566, 0.26705, 0.025225, 0.14029, 0.048118]
Predicted label: 0
Correct prediction
Energy consumption = 146.782684 pJ
sum error= 348
Actual label: 2
Output voltages: [0.36942, 0.095321, 0.79878, 0.061942, 0.025931, 0.0011574, 0.31905, 0.0028112, 0.48816, 0.046509]
Predicted label: 2
Correct prediction
Energy consumption = 142.774484 pJ
sum error= 348
Actual label: 8
Output voltages: [0.030156, 0.0066938, 0.040171, 0.045813, 0.026425, 0.043271, 0.010995, 0.009681, 0.79877, 0.18735]
Predicted label: 8
Correct prediction
Energy consumption = 149.594514 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79876, 0.070399, 0.036224, 0.02559, 0.0016147, 0.011467, 0.66424, 0.027951, 0.23214, 0.023774]
Predicted label: 0
Correct prediction
Energy consumption = 153.981940 pJ
sum error= 348
Actual label: 6
Output voltages: [0.086331, 0.13917, 0.15327, 0.0021086, 0.21725, 0.41457, 0.79869, 0.0015784, 0.12278, 0.025057]
Predicted label: 6
Correct prediction
Energy consumption = 142.228599 pJ
sum error= 348
Actual label: 8
Output voltages: [0.0024541, 0.054108, 0.033622, 0.42755, 0.55434, 0.015076, 0.43353, 0.0010944, 0.76752, 0.050157]
Predicted label: 8
Correct prediction
Energy consumption = 157.140441 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 914 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 914 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 914 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.029277, 0.79855, 0.052903, 0.14142, 0.26442, 0.0051316, 0.35096, 0.0015243, 0.21221, 0.037842]
Predicted label: 1
Correct prediction
Energy consumption = 180.529337 pJ
sum error= 348
Actual label: 7
Output voltages: [0.35555, 0.0030409, 0.0047943, 0.02043, 0.26207, 0.024891, 0.0010713, 0.79862, 0.36423, 0.099936]
Predicted label: 7
Correct prediction
Energy consumption = 155.790810 pJ
sum error= 348
Actual label: 9
Output voltages: [0.56052, 0.014133, 0.034058, 0.046372, 0.39599, 0.010686, 0.0079262, 0.022437, 0.043885, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 153.770829 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0057076, 0.79858, 0.014568, 0.19146, 0.28027, 0.0017346, 0.49717, 0.0089704, 0.26216, 0.28603]
Predicted label: 1
Correct prediction
Energy consumption = 166.294245 pJ
sum error= 348
Actual label: 9
Output voltages: [0.3768, 0.03276, 0.032502, 0.20859, 0.17953, 0.041353, 0.017761, 0.03324, 0.28023, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 158.939289 pJ
sum error= 348
Actual label: 2
Output voltages: [0.39904, 0.10232, 0.79879, 0.048125, 0.021039, 0.0013094, 0.36588, 0.019612, 0.50118, 0.028543]
Predicted label: 2
Correct prediction
Energy consumption = 150.683839 pJ
sum error= 348
Actual label: 6
Output voltages: [0.28386, 0.027044, 0.19499, 0.019978, 0.10768, 0.34652, 0.79876, 0.0011786, 0.55879, 0.14954]
Predicted label: 6
Correct prediction
Energy consumption = 149.534930 pJ
sum error= 348
Actual label: 7
Output voltages: [0.19124, 0.013623, 0.032495, 0.021612, 0.039392, 0.012626, 0.0010728, 0.79844, 0.21789, 0.19666]
Predicted label: 7
Correct prediction
Energy consumption = 158.091090 pJ
sum error= 348
Actual label: 6
Output voltages: [0.32873, 0.0254, 0.051901, 0.0020782, 0.35146, 0.32121, 0.79871, 0.020232, 0.71293, 0.0038312]
Predicted label: 6
Correct prediction
Energy consumption = 156.257665 pJ
sum error= 348
Actual label: 6
Output voltages: [0.049009, 0.073382, 0.12982, 0.0024382, 0.17616, 0.17724, 0.79876, 0.010174, 0.73266, 0.015017]
Predicted label: 6
Correct prediction
Energy consumption = 136.732387 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 915 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 915 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 915 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.03801, 0.012453, 0.034951, 0.041126, 0.047283, 0.11511, 0.33983, 0.0042762, 0.79879, 0.1594]
Predicted label: 8
Correct prediction
Energy consumption = 169.726588 pJ
sum error= 348
Actual label: 7
Output voltages: [0.34865, 0.002197, 0.013035, 0.032842, 0.043452, 0.15057, 0.0010813, 0.79857, 0.2935, 0.30183]
Predicted label: 7
Correct prediction
Energy consumption = 159.423331 pJ
sum error= 348
Actual label: 4
Output voltages: [0.019013, 0.0045635, 0.26143, 0.0046913, 0.79859, 0.0017781, 0.29261, 0.055181, 0.020747, 0.012979]
Predicted label: 4
Correct prediction
Energy consumption = 154.265872 pJ
sum error= 348
Actual label: 9
Output voltages: [0.25111, 0.0056127, 0.011979, 0.019086, 0.065167, 0.011222, 0.0026704, 0.032083, 0.52103, 0.79502]
Predicted label: 9
Correct prediction
Energy consumption = 152.406445 pJ
sum error= 348
Actual label: 2
Output voltages: [0.34399, 0.068297, 0.79871, 0.12942, 0.035693, 0.0012262, 0.52455, 0.023059, 0.57786, 0.060574]
Predicted label: 2
Correct prediction
Energy consumption = 148.488597 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0061452, 0.79846, 0.03184, 0.04842, 0.02446, 0.0058744, 0.74249, 0.0067102, 0.45503, 0.031179]
Predicted label: 1
Correct prediction
Energy consumption = 153.845234 pJ
sum error= 348
Actual label: 3
Output voltages: [0.6819, 0.037081, 0.017269, 0.79861, 0.014735, 0.063353, 0.026974, 0.034301, 0.23127, 0.04538]
Predicted label: 3
Correct prediction
Energy consumption = 151.954290 pJ
sum error= 348
Actual label: 3
Output voltages: [0.29762, 0.017219, 0.063928, 0.79868, 0.020549, 0.002976, 0.0090434, 0.0097317, 0.51323, 0.033974]
Predicted label: 3
Correct prediction
Energy consumption = 132.401792 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79798, 0.0049939, 0.10457, 0.0035652, 0.015268, 0.0011269, 0.056561, 0.077133, 0.035477, 0.66838]
Predicted label: 0
Correct prediction
Energy consumption = 138.991784 pJ
sum error= 348
Actual label: 5
Output voltages: [0.044952, 0.0010807, 0.0085448, 0.42287, 0.026978, 0.79879, 0.13378, 0.15553, 0.77328, 0.074751]
Predicted label: 5
Correct prediction
Energy consumption = 137.942616 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 916 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 916 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 916 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.23264, 0.0019969, 0.0031629, 0.26839, 0.013315, 0.79874, 0.30951, 0.016914, 0.76192, 0.003221]
Predicted label: 5
Correct prediction
Energy consumption = 166.523973 pJ
sum error= 348
Actual label: 8
Output voltages: [0.24879, 0.0038913, 0.031711, 0.31178, 0.0090254, 0.49781, 0.33691, 0.0013008, 0.79879, 0.21419]
Predicted label: 8
Correct prediction
Energy consumption = 145.795555 pJ
sum error= 348
Actual label: 0
Output voltages: [0.7983, 0.0082162, 0.033029, 0.0050039, 0.042155, 0.0017132, 0.5959, 0.046298, 0.29869, 0.032749]
Predicted label: 0
Correct prediction
Energy consumption = 156.338819 pJ
sum error= 348
Actual label: 3
Output voltages: [0.21573, 0.016648, 0.70616, 0.78759, 0.0037407, 0.0011277, 0.042275, 0.010908, 0.7659, 0.043878]
Predicted label: 3
Correct prediction
Energy consumption = 151.927528 pJ
sum error= 348
Actual label: 7
Output voltages: [0.12388, 0.022825, 0.011911, 0.051963, 0.012381, 0.039525, 0.0010664, 0.79867, 0.12948, 0.55294]
Predicted label: 7
Correct prediction
Energy consumption = 156.413991 pJ
sum error= 348
Actual label: 9
Output voltages: [0.19778, 0.030005, 0.0073198, 0.13204, 0.62292, 0.14588, 0.063961, 0.016655, 0.031928, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 146.212662 pJ
sum error= 348
Actual label: 7
Output voltages: [0.21629, 0.0011532, 0.0027696, 0.071823, 0.039274, 0.039538, 0.0010662, 0.79857, 0.29831, 0.17453]
Predicted label: 7
Correct prediction
Energy consumption = 153.372670 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79874, 0.045053, 0.030403, 0.015587, 0.0017506, 0.035024, 0.32151, 0.033758, 0.14754, 0.020532]
Predicted label: 0
Correct prediction
Energy consumption = 154.684067 pJ
sum error= 348
Actual label: 2
Output voltages: [0.026742, 0.23538, 0.79614, 0.19381, 0.023319, 0.0010892, 0.28318, 0.001828, 0.77873, 0.01925]
Predicted label: 2
Correct prediction
Energy consumption = 153.326848 pJ
sum error= 348
Actual label: 7
Output voltages: [0.020049, 0.0035894, 0.057867, 0.03788, 0.066165, 0.0066227, 0.0014232, 0.79854, 0.62445, 0.137]
Predicted label: 7
Correct prediction
Energy consumption = 160.926746 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 917 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 917 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 917 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.1759, 0.040647, 0.026539, 0.22779, 0.49166, 0.037571, 0.013638, 0.0070934, 0.16589, 0.79864]
Predicted label: 9
Correct prediction
Energy consumption = 169.711451 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0056457, 0.79855, 0.03019, 0.022457, 0.016927, 0.0014697, 0.50126, 0.0023611, 0.33035, 0.018603]
Predicted label: 1
Correct prediction
Energy consumption = 162.535351 pJ
sum error= 348
Actual label: 7
Output voltages: [0.24507, 0.0013898, 0.0011362, 0.020464, 0.62592, 0.12685, 0.0035637, 0.79878, 0.32607, 0.052575]
Predicted label: 7
Correct prediction
Energy consumption = 166.627715 pJ
sum error= 348
Actual label: 8
Output voltages: [0.0046976, 0.098511, 0.11674, 0.038854, 0.021922, 0.0057489, 0.022558, 0.11321, 0.79877, 0.11776]
Predicted label: 8
Correct prediction
Energy consumption = 144.277759 pJ
sum error= 348
Actual label: 0
Output voltages: [0.7987, 0.10504, 0.034917, 0.012774, 0.0059022, 0.015406, 0.43694, 0.039331, 0.12612, 0.015079]
Predicted label: 0
Correct prediction
Energy consumption = 147.772531 pJ
sum error= 348
Actual label: 3
Output voltages: [0.55623, 0.010712, 0.29535, 0.79877, 0.020227, 0.0011301, 0.0072075, 0.0027325, 0.42025, 0.032866]
Predicted label: 3
Correct prediction
Energy consumption = 151.149465 pJ
sum error= 348
Actual label: 5
Output voltages: [0.043238, 0.0011613, 0.0022046, 0.12989, 0.017283, 0.79207, 0.15905, 0.038462, 0.7745, 0.044429]
Predicted label: 5
Correct prediction
Energy consumption = 139.138202 pJ
sum error= 348
Actual label: 3
Output voltages: [0.45295, 0.013445, 0.10093, 0.79869, 0.11839, 0.0044634, 0.016066, 0.0037688, 0.70737, 0.027712]
Predicted label: 3
Correct prediction
Energy consumption = 142.664731 pJ
sum error= 348
Actual label: 6
Output voltages: [0.17937, 0.047321, 0.11764, 0.0016164, 0.33869, 0.26695, 0.79872, 0.0012314, 0.55887, 0.007536]
Predicted label: 6
Correct prediction
Energy consumption = 149.650156 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79838, 0.16859, 0.039993, 0.0077563, 0.0061153, 0.0018615, 0.53755, 0.04551, 0.32328, 0.53855]
Predicted label: 0
Correct prediction
Energy consumption = 139.718096 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 918 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 918 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 918 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.042982, 0.79847, 0.32724, 0.001079, 0.027684, 0.0064467, 0.062356, 0.0030821, 0.73706, 0.035186]
Predicted label: 1
Correct prediction
Energy consumption = 168.319882 pJ
sum error= 348
Actual label: 2
Output voltages: [0.030522, 0.060186, 0.79878, 0.11671, 0.0029052, 0.001145, 0.027043, 0.028071, 0.67907, 0.024852]
Predicted label: 2
Correct prediction
Energy consumption = 146.076283 pJ
sum error= 348
Actual label: 3
Output voltages: [0.38231, 0.022526, 0.092565, 0.79876, 0.0061989, 0.0021122, 0.003314, 0.021087, 0.44802, 0.021707]
Predicted label: 3
Correct prediction
Energy consumption = 140.813407 pJ
sum error= 348
Actual label: 4
Output voltages: [0.0061267, 0.0023745, 0.033874, 0.098053, 0.79867, 0.010754, 0.065977, 0.042243, 0.22015, 0.26542]
Predicted label: 4
Correct prediction
Energy consumption = 137.688218 pJ
sum error= 348
Actual label: 5
Output voltages: [0.0083783, 0.0064411, 0.0041718, 0.36123, 0.016147, 0.79879, 0.44342, 0.0087272, 0.70143, 0.012875]
Predicted label: 5
Correct prediction
Energy consumption = 145.628810 pJ
sum error= 348
Actual label: 6
Output voltages: [0.134, 0.037659, 0.022552, 0.0044299, 0.0653, 0.175, 0.79851, 0.037072, 0.78021, 0.0073059]
Predicted label: 6
Correct prediction
Energy consumption = 142.887725 pJ
sum error= 348
Actual label: 7
Output voltages: [0.36385, 0.026958, 0.049676, 0.024704, 0.22025, 0.0011379, 0.0010937, 0.79863, 0.40738, 0.017022]
Predicted label: 7
Correct prediction
Energy consumption = 148.170001 pJ
sum error= 348
Actual label: 8
Output voltages: [0.0041233, 0.14128, 0.097676, 0.022406, 0.02482, 0.012747, 0.015337, 0.020838, 0.79879, 0.45942]
Predicted label: 8
Correct prediction
Energy consumption = 142.557728 pJ
sum error= 348
Actual label: 9
Output voltages: [0.36086, 0.01218, 0.047694, 0.14505, 0.47233, 0.0017384, 0.0011889, 0.0079594, 0.21669, 0.79677]
Predicted label: 9
Correct prediction
Energy consumption = 147.339967 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79865, 0.0907, 0.018088, 0.01946, 0.020786, 0.016924, 0.69173, 0.018238, 0.14813, 0.0096911]
Predicted label: 0
Correct prediction
Energy consumption = 142.440427 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 919 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 919 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 919 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0074622, 0.79878, 0.035515, 0.0064871, 0.011914, 0.0020323, 0.44791, 0.0031681, 0.68563, 0.029894]
Predicted label: 1
Correct prediction
Energy consumption = 166.418213 pJ
sum error= 348
Actual label: 2
Output voltages: [0.26645, 0.094014, 0.79878, 0.24204, 0.0019069, 0.0012611, 0.20463, 0.009068, 0.36717, 0.0090957]
Predicted label: 2
Correct prediction
Energy consumption = 143.230335 pJ
sum error= 348
Actual label: 3
Output voltages: [0.087728, 0.004164, 0.036559, 0.79874, 0.0379, 0.023517, 0.0090876, 0.02082, 0.73656, 0.040592]
Predicted label: 3
Correct prediction
Energy consumption = 140.706374 pJ
sum error= 348
Actual label: 4
Output voltages: [0.04818, 0.023332, 0.0089815, 0.0042889, 0.79872, 0.026698, 0.014404, 0.12866, 0.2367, 0.0039755]
Predicted label: 4
Correct prediction
Energy consumption = 140.833023 pJ
sum error= 348
Actual label: 5
Output voltages: [0.25081, 0.0017833, 0.0013312, 0.15598, 0.025852, 0.79878, 0.4771, 0.01811, 0.44552, 0.0022856]
Predicted label: 5
Correct prediction
Energy consumption = 140.521721 pJ
sum error= 348
Actual label: 6
Output voltages: [0.25583, 0.027541, 0.034341, 0.0026766, 0.29136, 0.31862, 0.79877, 0.0076363, 0.70955, 0.0075518]
Predicted label: 6
Correct prediction
Energy consumption = 141.872444 pJ
sum error= 348
Actual label: 7
Output voltages: [0.075431, 0.033872, 0.097489, 0.15674, 0.090475, 0.030254, 0.0011619, 0.79879, 0.13909, 0.61083]
Predicted label: 7
Correct prediction
Energy consumption = 145.982097 pJ
sum error= 348
Actual label: 8
Output voltages: [0.10616, 0.048162, 0.10749, 0.03485, 0.046821, 0.046583, 0.007199, 0.021549, 0.79879, 0.028599]
Predicted label: 8
Correct prediction
Energy consumption = 139.276464 pJ
sum error= 348
Actual label: 9
Output voltages: [0.37193, 0.0021793, 0.025862, 0.023018, 0.066675, 0.028331, 0.0010867, 0.013897, 0.69584, 0.79574]
Predicted label: 9
Correct prediction
Energy consumption = 134.390388 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79862, 0.046596, 0.043568, 0.0056177, 0.015734, 0.0092712, 0.4494, 0.033711, 0.1779, 0.024101]
Predicted label: 0
Correct prediction
Energy consumption = 135.952107 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 920 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 920 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 920 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0016629, 0.79875, 0.25306, 0.016196, 0.37115, 0.0039965, 0.43514, 0.001066, 0.092186, 0.058892]
Predicted label: 1
Correct prediction
Energy consumption = 168.290319 pJ
sum error= 348
Actual label: 2
Output voltages: [0.17052, 0.010521, 0.79879, 0.22374, 0.0055906, 0.001119, 0.22109, 0.033961, 0.73717, 0.012395]
Predicted label: 2
Correct prediction
Energy consumption = 145.864651 pJ
sum error= 348
Actual label: 3
Output voltages: [0.028519, 0.024288, 0.44069, 0.79732, 0.02034, 0.0021364, 0.0010824, 0.01061, 0.5303, 0.20424]
Predicted label: 3
Correct prediction
Energy consumption = 142.208470 pJ
sum error= 348
Actual label: 4
Output voltages: [0.012399, 0.010364, 0.030012, 0.0029096, 0.79855, 0.014058, 0.051187, 0.037709, 0.085572, 0.033637]
Predicted label: 4
Correct prediction
Energy consumption = 137.643611 pJ
sum error= 348
Actual label: 7
Output voltages: [0.30076, 0.042033, 0.033961, 0.074467, 0.001246, 0.0036059, 0.0012465, 0.79879, 0.063007, 0.30067]
Predicted label: 7
Correct prediction
Energy consumption = 148.974483 pJ
sum error= 348
Actual label: 8
Output voltages: [0.1229, 0.11406, 0.22145, 0.010279, 0.039188, 0.0012169, 0.24732, 0.0015858, 0.79717, 0.40046]
Predicted label: 8
Correct prediction
Energy consumption = 142.586893 pJ
sum error= 348
Actual label: 9
Output voltages: [0.29208, 0.011075, 0.0052106, 0.21229, 0.30545, 0.011816, 0.0053314, 0.0051356, 0.46513, 0.79817]
Predicted label: 9
Correct prediction
Energy consumption = 133.398187 pJ
sum error= 348
Actual label: 6
Output voltages: [0.46245, 0.036299, 0.14891, 0.0029625, 0.22106, 0.026372, 0.79825, 0.004463, 0.73118, 0.0067532]
Predicted label: 6
Correct prediction
Energy consumption = 148.640986 pJ
sum error= 348
Actual label: 4
Output voltages: [0.0037225, 0.011861, 0.082103, 0.20913, 0.79879, 0.0017281, 0.0072078, 0.02401, 0.032753, 0.054642]
Predicted label: 4
Correct prediction
Energy consumption = 151.225251 pJ
sum error= 348
Actual label: 2
Output voltages: [0.57296, 0.02878, 0.79877, 0.16467, 0.019573, 0.0012255, 0.034177, 0.16069, 0.54586, 0.0086916]
Predicted label: 2
Correct prediction
Energy consumption = 140.533771 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 921 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 921 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 921 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.28362, 0.15474, 0.29636, 0.0021164, 0.16174, 0.014273, 0.7987, 0.0066897, 0.27309, 0.032741]
Predicted label: 6
Correct prediction
Energy consumption = 166.075170 pJ
sum error= 348
Actual label: 4
Output voltages: [0.010329, 0.02359, 0.038949, 0.07044, 0.78646, 0.0010678, 0.0013122, 0.0074586, 0.32263, 0.67511]
Predicted label: 4
Correct prediction
Energy consumption = 151.655807 pJ
sum error= 348
Actual label: 7
Output voltages: [0.54565, 0.046493, 0.044337, 0.013313, 0.061626, 0.024552, 0.0010891, 0.79876, 0.23483, 0.2357]
Predicted label: 7
Correct prediction
Energy consumption = 145.096907 pJ
sum error= 348
Actual label: 8
Output voltages: [0.047924, 0.017604, 0.032329, 0.13168, 0.0041992, 0.039875, 0.025806, 0.0036929, 0.79874, 0.081748]
Predicted label: 8
Correct prediction
Energy consumption = 148.141198 pJ
sum error= 348
Actual label: 9
Output voltages: [0.51897, 0.011467, 0.024059, 0.041794, 0.40614, 0.0019502, 0.0013255, 0.02322, 0.5089, 0.79737]
Predicted label: 9
Correct prediction
Energy consumption = 138.940890 pJ
sum error= 348
Actual label: 2
Output voltages: [0.21672, 0.041191, 0.7986, 0.039135, 0.003159, 0.0010683, 0.042791, 0.09646, 0.48666, 0.0058647]
Predicted label: 2
Correct prediction
Energy consumption = 139.996511 pJ
sum error= 348
Actual label: 9
Output voltages: [0.021903, 0.0076969, 0.024298, 0.035557, 0.20539, 0.0081045, 0.0013064, 0.031469, 0.75867, 0.79517]
Predicted label: 9
Correct prediction
Energy consumption = 145.364552 pJ
sum error= 348
Actual label: 3
Output voltages: [0.20436, 0.0020181, 0.22201, 0.79878, 0.0018504, 0.0044922, 0.023499, 0.029103, 0.72887, 0.0017703]
Predicted label: 3
Correct prediction
Energy consumption = 140.277599 pJ
sum error= 348
Actual label: 9
Output voltages: [0.58605, 0.011025, 0.042246, 0.025426, 0.34608, 0.012086, 0.0023044, 0.0095791, 0.44494, 0.79757]
Predicted label: 9
Correct prediction
Energy consumption = 145.400859 pJ
sum error= 348
Actual label: 3
Output voltages: [0.14015, 0.011733, 0.028131, 0.79865, 0.015502, 0.094548, 0.0021917, 0.0078966, 0.47298, 0.024985]
Predicted label: 3
Correct prediction
Energy consumption = 137.976670 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 922 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 922 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 922 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79875, 0.040817, 0.064325, 0.007564, 0.0081606, 0.0097314, 0.38018, 0.024524, 0.056788, 0.011071]
Predicted label: 0
Correct prediction
Energy consumption = 162.849932 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79585, 0.015544, 0.092586, 0.092991, 0.04972, 0.0010867, 0.026051, 0.0055702, 0.65968, 0.2342]
Predicted label: 0
Correct prediction
Energy consumption = 139.245919 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0025955, 0.79867, 0.034548, 0.0017117, 0.015735, 0.0038137, 0.36261, 0.0064982, 0.64077, 0.02439]
Predicted label: 1
Correct prediction
Energy consumption = 140.671690 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79853, 0.079188, 0.19151, 0.013399, 0.0019661, 0.0013965, 0.48429, 0.019757, 0.060654, 0.31971]
Predicted label: 0
Correct prediction
Energy consumption = 137.425461 pJ
sum error= 348
Actual label: 4
Output voltages: [0.024465, 0.036032, 0.10669, 0.026151, 0.7986, 0.0019238, 0.038923, 0.044754, 0.030605, 0.023509]
Predicted label: 4
Correct prediction
Energy consumption = 150.627480 pJ
sum error= 348
Actual label: 2
Output voltages: [0.035147, 0.51914, 0.79878, 0.045559, 0.0011083, 0.0010928, 0.018746, 0.25336, 0.69741, 0.023185]
Predicted label: 2
Correct prediction
Energy consumption = 144.888518 pJ
sum error= 348
Actual label: 6
Output voltages: [0.064757, 0.024715, 0.20706, 0.0010913, 0.35573, 0.02569, 0.79879, 0.0013045, 0.62646, 0.0033315]
Predicted label: 6
Correct prediction
Energy consumption = 138.673697 pJ
sum error= 348
Actual label: 3
Output voltages: [0.18495, 0.019846, 0.35641, 0.79878, 0.0028188, 0.0075943, 0.0054812, 0.0030784, 0.76054, 0.0063902]
Predicted label: 3
Correct prediction
Energy consumption = 137.547697 pJ
sum error= 348
Actual label: 5
Output voltages: [0.12814, 0.001066, 0.0010673, 0.40975, 0.036915, 0.79879, 0.27888, 0.017446, 0.55123, 0.039606]
Predicted label: 5
Correct prediction
Energy consumption = 140.604959 pJ
sum error= 348
Actual label: 3
Output voltages: [0.081756, 0.03439, 0.053025, 0.7987, 0.0096863, 0.025182, 0.0013862, 0.0044591, 0.65163, 0.032971]
Predicted label: 3
Correct prediction
Energy consumption = 136.309702 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 923 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 923 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 923 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79869, 0.069829, 0.030013, 0.013093, 0.016775, 0.017368, 0.4776, 0.019886, 0.17496, 0.044554]
Predicted label: 0
Correct prediction
Energy consumption = 164.726053 pJ
sum error= 348
Actual label: 3
Output voltages: [0.20406, 0.011041, 0.039186, 0.79877, 0.045817, 0.0072898, 0.011456, 0.020761, 0.55127, 0.038571]
Predicted label: 3
Correct prediction
Energy consumption = 147.362819 pJ
sum error= 348
Actual label: 4
Output voltages: [0.025261, 0.0020875, 0.13513, 0.0041304, 0.79859, 0.018081, 0.15058, 0.32737, 0.053166, 0.0043265]
Predicted label: 4
Correct prediction
Energy consumption = 140.191596 pJ
sum error= 348
Actual label: 1
Output voltages: [0.013299, 0.79869, 0.71038, 0.034738, 0.30992, 0.0011027, 0.42133, 0.0083021, 0.022842, 0.011619]
Predicted label: 1
Correct prediction
Energy consumption = 145.156239 pJ
sum error= 348
Actual label: 5
Output voltages: [0.017062, 0.00107, 0.0010843, 0.35215, 0.2178, 0.79876, 0.48309, 0.044825, 0.54709, 0.02225]
Predicted label: 5
Correct prediction
Energy consumption = 144.650511 pJ
sum error= 348
Actual label: 3
Output voltages: [0.36801, 0.024191, 0.058543, 0.79866, 0.01185, 0.031749, 0.0051057, 0.00573, 0.73164, 0.015954]
Predicted label: 3
Correct prediction
Energy consumption = 140.030366 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79861, 0.054772, 0.12656, 0.02774, 0.033994, 0.0067979, 0.22315, 0.011518, 0.73657, 0.072957]
Predicted label: 0
Correct prediction
Energy consumption = 145.152622 pJ
sum error= 348
Actual label: 8
Output voltages: [0.025267, 0.0033401, 0.17558, 0.024166, 0.028865, 0.015043, 0.0076693, 0.0067452, 0.79879, 0.061708]
Predicted label: 8
Correct prediction
Energy consumption = 140.989491 pJ
sum error= 348
Actual label: 3
Output voltages: [0.16349, 0.0028703, 0.44622, 0.79879, 0.014972, 0.0017293, 0.012165, 0.0011196, 0.68895, 0.0247]
Predicted label: 3
Correct prediction
Energy consumption = 135.478194 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79869, 0.17004, 0.018769, 0.018878, 0.025904, 0.025215, 0.4704, 0.010691, 0.14359, 0.040166]
Predicted label: 0
Correct prediction
Energy consumption = 141.383493 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 924 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 924 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 924 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.067141, 0.035197, 0.2525, 0.0011736, 0.2745, 0.10479, 0.79876, 0.0038047, 0.51736, 0.013537]
Predicted label: 6
Correct prediction
Energy consumption = 164.084312 pJ
sum error= 348
Actual label: 1
Output voltages: [0.12247, 0.7977, 0.39867, 0.010406, 0.68502, 0.0010943, 0.039481, 0.018961, 0.035014, 0.027639]
Predicted label: 1
Correct prediction
Energy consumption = 149.810318 pJ
sum error= 348
Actual label: 7
Output voltages: [0.44906, 0.011679, 0.03013, 0.022862, 0.15233, 0.021082, 0.0010684, 0.79865, 0.042675, 0.091234]
Predicted label: 7
Correct prediction
Energy consumption = 151.717084 pJ
sum error= 348
Actual label: 8
Output voltages: [0.35756, 0.026975, 0.40417, 0.0068298, 0.048553, 0.0011487, 0.0071725, 0.014751, 0.79869, 0.42209]
Predicted label: 8
Correct prediction
Energy consumption = 148.822442 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79867, 0.12443, 0.028298, 0.011075, 0.011618, 0.010239, 0.49545, 0.066415, 0.20512, 0.03042]
Predicted label: 0
Correct prediction
Energy consumption = 138.837865 pJ
sum error= 348
Actual label: 9
Output voltages: [0.76844, 0.0017759, 0.019406, 0.041894, 0.62683, 0.015728, 0.0025838, 0.0078453, 0.16622, 0.78271]
Predicted label: 9
Correct prediction
Energy consumption = 142.640159 pJ
sum error= 348
Actual label: 2
Output voltages: [0.23436, 0.044986, 0.79871, 0.10895, 0.0074421, 0.0012658, 0.20989, 0.16261, 0.57602, 0.038946]
Predicted label: 2
Correct prediction
Energy consumption = 144.744960 pJ
sum error= 348
Actual label: 6
Output voltages: [0.066628, 0.029305, 0.27406, 0.0012185, 0.42456, 0.048714, 0.79875, 0.0025159, 0.44886, 0.0061702]
Predicted label: 6
Correct prediction
Energy consumption = 141.730428 pJ
sum error= 348
Actual label: 7
Output voltages: [0.22331, 0.33049, 0.003896, 0.2141, 0.14197, 0.0010734, 0.0039558, 0.79877, 0.111, 0.14507]
Predicted label: 7
Correct prediction
Energy consumption = 154.424950 pJ
sum error= 348
Actual label: 1
Output voltages: [0.003051, 0.79871, 0.0057475, 0.0020892, 0.15153, 0.014439, 0.30224, 0.0020364, 0.49794, 0.046212]
Predicted label: 1
Correct prediction
Energy consumption = 149.231898 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 925 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 925 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 925 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.51526, 0.021584, 0.018143, 0.12487, 0.20258, 0.007078, 0.0071665, 0.03205, 0.50821, 0.79814]
Predicted label: 9
Correct prediction
Energy consumption = 158.383873 pJ
sum error= 348
Actual label: 6
Output voltages: [0.053566, 0.035779, 0.15245, 0.0019277, 0.14133, 0.18177, 0.79876, 0.0075581, 0.60421, 0.009732]
Predicted label: 6
Correct prediction
Energy consumption = 147.102144 pJ
sum error= 348
Actual label: 9
Output voltages: [0.70422, 0.0026465, 0.027585, 0.32012, 0.75694, 0.011086, 0.0012868, 0.011923, 0.12287, 0.7946]
Predicted label: 9
Correct prediction
Energy consumption = 148.615727 pJ
sum error= 348
Actual label: 4
Output voltages: [0.031045, 0.0041786, 0.042386, 0.11033, 0.76628, 0.2442, 0.24066, 0.0055791, 0.78023, 0.023667]
Predicted label: 8
Wrong prediction!
Energy consumption = 141.619939 pJ
sum error= 349
Actual label: 9
Output voltages: [0.065098, 0.0020468, 0.0063574, 0.027958, 0.26964, 0.0071877, 0.0010927, 0.018459, 0.73204, 0.79777]
Predicted label: 9
Correct prediction
Energy consumption = 147.002281 pJ
sum error= 349
Actual label: 9
Output voltages: [0.3147, 0.014428, 0.013321, 0.097657, 0.28273, 0.014324, 0.0022866, 0.018156, 0.51747, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 133.859423 pJ
sum error= 349
Actual label: 6
Output voltages: [0.043266, 0.033055, 0.40289, 0.00107, 0.30275, 0.03411, 0.79879, 0.0017835, 0.54813, 0.0019444]
Predicted label: 6
Correct prediction
Energy consumption = 146.388002 pJ
sum error= 349
Actual label: 7
Output voltages: [0.043979, 0.31906, 0.25382, 0.031993, 0.025661, 0.0011397, 0.0010926, 0.79867, 0.063276, 0.23966]
Predicted label: 7
Correct prediction
Energy consumption = 145.041277 pJ
sum error= 349
Actual label: 1
Output voltages: [0.010123, 0.79877, 0.33188, 0.0094593, 0.030959, 0.0012032, 0.5976, 0.0010758, 0.24611, 0.037783]
Predicted label: 1
Correct prediction
Energy consumption = 145.201950 pJ
sum error= 349
Actual label: 2
Output voltages: [0.12239, 0.010647, 0.78145, 0.5172, 0.0011759, 0.0010764, 0.039299, 0.011341, 0.68817, 0.0015073]
Predicted label: 2
Correct prediction
Energy consumption = 138.441074 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 926 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 926 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 926 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.10148, 0.0011088, 0.001066, 0.33546, 0.019042, 0.79877, 0.18896, 0.016594, 0.74185, 0.0053665]
Predicted label: 5
Correct prediction
Energy consumption = 157.534326 pJ
sum error= 349
Actual label: 3
Output voltages: [0.24853, 0.0082192, 0.18703, 0.79877, 0.011509, 0.0082549, 0.0042584, 0.10805, 0.61952, 0.055105]
Predicted label: 3
Correct prediction
Energy consumption = 143.198684 pJ
sum error= 349
Actual label: 7
Output voltages: [0.048392, 0.084936, 0.035131, 0.2709, 0.029691, 0.013363, 0.0011646, 0.79876, 0.11859, 0.39914]
Predicted label: 7
Correct prediction
Energy consumption = 145.054652 pJ
sum error= 349
Actual label: 8
Output voltages: [0.0017326, 0.08462, 0.19438, 0.086495, 0.0050339, 0.0030029, 0.035262, 0.017947, 0.79876, 0.057913]
Predicted label: 8
Correct prediction
Energy consumption = 141.713861 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79874, 0.13862, 0.019068, 0.020814, 0.0061606, 0.026271, 0.56778, 0.02536, 0.047109, 0.020049]
Predicted label: 0
Correct prediction
Energy consumption = 146.636438 pJ
sum error= 349
Actual label: 1
Output voltages: [0.0064626, 0.79849, 0.58805, 0.52956, 0.031547, 0.0077291, 0.4819, 0.024929, 0.01639, 0.37702]
Predicted label: 1
Correct prediction
Energy consumption = 168.472205 pJ
sum error= 349
Actual label: 2
Output voltages: [0.49716, 0.009499, 0.79875, 0.041382, 0.0067374, 0.0010956, 0.026242, 0.055906, 0.56172, 0.007543]
Predicted label: 2
Correct prediction
Energy consumption = 147.627134 pJ
sum error= 349
Actual label: 4
Output voltages: [0.0067866, 0.033868, 0.052365, 0.0026775, 0.79877, 0.057421, 0.023833, 0.27987, 0.087339, 0.15883]
Predicted label: 4
Correct prediction
Energy consumption = 159.868997 pJ
sum error= 349
Actual label: 5
Output voltages: [0.017227, 0.0016802, 0.012104, 0.15676, 0.014751, 0.77377, 0.040951, 0.002718, 0.765, 0.28119]
Predicted label: 5
Correct prediction
Energy consumption = 145.767834 pJ
sum error= 349
Actual label: 6
Output voltages: [0.19569, 0.023201, 0.33362, 0.0025213, 0.19791, 0.30601, 0.79879, 0.0026537, 0.356, 0.0046864]
Predicted label: 6
Correct prediction
Energy consumption = 145.149217 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 927 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 927 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 927 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.035946, 0.29362, 0.25017, 0.051235, 0.0031297, 0.0010664, 0.0013858, 0.79861, 0.21035, 0.22345]
Predicted label: 7
Correct prediction
Energy consumption = 172.803814 pJ
sum error= 349
Actual label: 8
Output voltages: [0.0086321, 0.017929, 0.04774, 0.090991, 0.012597, 0.02025, 0.05192, 0.0034553, 0.79876, 0.18031]
Predicted label: 8
Correct prediction
Energy consumption = 149.346941 pJ
sum error= 349
Actual label: 9
Output voltages: [0.40186, 0.033085, 0.01606, 0.057325, 0.089842, 0.014436, 0.0023949, 0.025049, 0.31721, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 153.245220 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79877, 0.069825, 0.05527, 0.019781, 0.0058682, 0.0064639, 0.40746, 0.012889, 0.059666, 0.030393]
Predicted label: 0
Correct prediction
Energy consumption = 148.622042 pJ
sum error= 349
Actual label: 1
Output voltages: [0.023252, 0.79834, 0.039713, 0.04937, 0.0079494, 0.0042633, 0.73236, 0.012921, 0.21652, 0.1088]
Predicted label: 1
Correct prediction
Energy consumption = 160.181325 pJ
sum error= 349
Actual label: 3
Output voltages: [0.35391, 0.014732, 0.057364, 0.79869, 0.021577, 0.0083976, 0.033137, 0.010759, 0.41959, 0.04696]
Predicted label: 3
Correct prediction
Energy consumption = 153.352158 pJ
sum error= 349
Actual label: 4
Output voltages: [0.011351, 0.021532, 0.20163, 0.010484, 0.79858, 0.011116, 0.14198, 0.035776, 0.035098, 0.032803]
Predicted label: 4
Correct prediction
Energy consumption = 153.985509 pJ
sum error= 349
Actual label: 5
Output voltages: [0.017883, 0.0029338, 0.00417, 0.3767, 0.049806, 0.79684, 0.14586, 0.0039395, 0.6379, 0.10926]
Predicted label: 5
Correct prediction
Energy consumption = 145.983749 pJ
sum error= 349
Actual label: 6
Output voltages: [0.05564, 0.1815, 0.32091, 0.0038941, 0.22442, 0.22183, 0.79866, 0.0025697, 0.35771, 0.01372]
Predicted label: 6
Correct prediction
Energy consumption = 143.254688 pJ
sum error= 349
Actual label: 7
Output voltages: [0.21592, 0.024295, 0.026542, 0.030173, 0.01723, 0.0025275, 0.001089, 0.79859, 0.31119, 0.23108]
Predicted label: 7
Correct prediction
Energy consumption = 160.283431 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 928 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 928 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 928 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.049849, 0.0014282, 0.19364, 0.027408, 0.0015225, 0.78206, 0.17946, 0.0016631, 0.79811, 0.013273]
Predicted label: 8
Correct prediction
Energy consumption = 167.150851 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79872, 0.123, 0.031857, 0.018575, 0.024513, 0.023243, 0.48688, 0.044906, 0.22828, 0.042565]
Predicted label: 0
Correct prediction
Energy consumption = 144.577131 pJ
sum error= 349
Actual label: 1
Output voltages: [0.0034711, 0.79846, 0.043949, 0.055189, 0.025685, 0.0046165, 0.65298, 0.0038229, 0.50094, 0.041463]
Predicted label: 1
Correct prediction
Energy consumption = 167.594346 pJ
sum error= 349
Actual label: 3
Output voltages: [0.045505, 0.026383, 0.050514, 0.79862, 0.021575, 0.0017052, 0.020659, 0.013258, 0.43618, 0.18206]
Predicted label: 3
Correct prediction
Energy consumption = 149.518814 pJ
sum error= 349
Actual label: 4
Output voltages: [0.0040185, 0.036555, 0.31303, 0.020912, 0.79863, 0.017259, 0.25463, 0.36773, 0.022055, 0.075056]
Predicted label: 4
Correct prediction
Energy consumption = 159.735004 pJ
sum error= 349
Actual label: 7
Output voltages: [0.12629, 0.0033628, 0.044856, 0.76409, 0.0012179, 0.030186, 0.0012246, 0.79875, 0.52741, 0.41461]
Predicted label: 7
Correct prediction
Energy consumption = 149.460509 pJ
sum error= 349
Actual label: 8
Output voltages: [0.024696, 0.0029645, 0.027677, 0.070681, 0.0084437, 0.56274, 0.049526, 0.0038745, 0.79877, 0.054308]
Predicted label: 8
Correct prediction
Energy consumption = 143.660740 pJ
sum error= 349
Actual label: 9
Output voltages: [0.028684, 0.020783, 0.04678, 0.19716, 0.038002, 0.018677, 0.017202, 0.16487, 0.64208, 0.79839]
Predicted label: 9
Correct prediction
Energy consumption = 148.338139 pJ
sum error= 349
Actual label: 7
Output voltages: [0.16344, 0.015052, 0.31455, 0.37772, 0.0079397, 0.0025441, 0.0010976, 0.79863, 0.43036, 0.26031]
Predicted label: 7
Correct prediction
Energy consumption = 150.642773 pJ
sum error= 349
Actual label: 5
Output voltages: [0.034902, 0.0044034, 0.027229, 0.40249, 0.018937, 0.79594, 0.016538, 0.0034659, 0.78127, 0.23132]
Predicted label: 5
Correct prediction
Energy consumption = 141.959880 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 929 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 929 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 929 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.098387, 0.020769, 0.0021182, 0.12886, 0.24967, 0.79877, 0.37809, 0.0052402, 0.17021, 0.1409]
Predicted label: 5
Correct prediction
Energy consumption = 160.579632 pJ
sum error= 349
Actual label: 1
Output voltages: [0.24855, 0.79879, 0.59082, 0.17476, 0.21671, 0.0011999, 0.022114, 0.0083513, 0.027495, 0.035367]
Predicted label: 1
Correct prediction
Energy consumption = 174.399431 pJ
sum error= 349
Actual label: 9
Output voltages: [0.509, 0.021636, 0.019944, 0.027911, 0.058189, 0.015187, 0.0018676, 0.0248, 0.4057, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 159.380726 pJ
sum error= 349
Actual label: 9
Output voltages: [0.029464, 0.0060835, 0.013087, 0.31856, 0.05158, 0.0023363, 0.0033332, 0.24317, 0.66673, 0.78566]
Predicted label: 9
Correct prediction
Energy consumption = 147.259491 pJ
sum error= 349
Actual label: 7
Output voltages: [0.17767, 0.030462, 0.034832, 0.037607, 0.035692, 0.010276, 0.0010806, 0.7985, 0.32917, 0.28159]
Predicted label: 7
Correct prediction
Energy consumption = 150.284411 pJ
sum error= 349
Actual label: 1
Output voltages: [0.11235, 0.79867, 0.32987, 0.03403, 0.41149, 0.0012067, 0.6962, 0.0069305, 0.013407, 0.032122]
Predicted label: 1
Correct prediction
Energy consumption = 164.781707 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79814, 0.046421, 0.049615, 0.0035093, 0.0051104, 0.0038862, 0.70981, 0.15283, 0.016537, 0.14837]
Predicted label: 0
Correct prediction
Energy consumption = 135.832389 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79816, 0.15525, 0.31371, 0.022415, 0.0012418, 0.0011725, 0.4305, 0.055107, 0.26424, 0.13096]
Predicted label: 0
Correct prediction
Energy consumption = 133.869163 pJ
sum error= 349
Actual label: 5
Output voltages: [0.017886, 0.0010794, 0.0011227, 0.31521, 0.031713, 0.79871, 0.10112, 0.10601, 0.7111, 0.050588]
Predicted label: 5
Correct prediction
Energy consumption = 154.561807 pJ
sum error= 349
Actual label: 9
Output voltages: [0.19665, 0.024176, 0.027235, 0.035392, 0.060775, 0.024531, 0.0027382, 0.070662, 0.41517, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 142.773137 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 930 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 930 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 930 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.32746, 0.014994, 0.014492, 0.25151, 0.025003, 0.031074, 0.001084, 0.79862, 0.069779, 0.41744]
Predicted label: 7
Correct prediction
Energy consumption = 169.276646 pJ
sum error= 349
Actual label: 1
Output voltages: [0.01862, 0.79838, 0.10109, 0.043267, 0.022628, 0.00895, 0.44165, 0.0062103, 0.34919, 0.040401]
Predicted label: 1
Correct prediction
Energy consumption = 168.046745 pJ
sum error= 349
Actual label: 7
Output voltages: [0.38903, 0.047586, 0.084239, 0.11244, 0.017436, 0.0017555, 0.0010694, 0.79871, 0.14367, 0.38183]
Predicted label: 7
Correct prediction
Energy consumption = 157.286180 pJ
sum error= 349
Actual label: 2
Output voltages: [0.58631, 0.013649, 0.79494, 0.75702, 0.0016499, 0.0011195, 0.037859, 0.036389, 0.73303, 0.064484]
Predicted label: 2
Correct prediction
Energy consumption = 149.333901 pJ
sum error= 349
Actual label: 2
Output voltages: [0.65972, 0.016742, 0.79821, 0.42118, 0.0075587, 0.0011014, 0.1222, 0.038897, 0.70534, 0.03407]
Predicted label: 2
Correct prediction
Energy consumption = 141.682915 pJ
sum error= 349
Actual label: 3
Output voltages: [0.49308, 0.080103, 0.063376, 0.79865, 0.010056, 0.0018389, 0.028479, 0.010517, 0.33054, 0.033473]
Predicted label: 3
Correct prediction
Energy consumption = 144.373711 pJ
sum error= 349
Actual label: 6
Output voltages: [0.23777, 0.032638, 0.31937, 0.0024628, 0.27488, 0.21096, 0.7987, 0.0044507, 0.45644, 0.033124]
Predicted label: 6
Correct prediction
Energy consumption = 137.317427 pJ
sum error= 349
Actual label: 8
Output voltages: [0.029079, 0.017133, 0.057908, 0.2305, 0.0047205, 0.016615, 0.039589, 0.012202, 0.79874, 0.30626]
Predicted label: 8
Correct prediction
Energy consumption = 152.360209 pJ
sum error= 349
Actual label: 3
Output voltages: [0.74254, 0.023931, 0.047942, 0.79866, 0.0096542, 0.14781, 0.013554, 0.017131, 0.38739, 0.12626]
Predicted label: 3
Correct prediction
Energy consumption = 153.254007 pJ
sum error= 349
Actual label: 2
Output voltages: [0.2706, 0.0099548, 0.79829, 0.48951, 0.0077317, 0.0011894, 0.031209, 0.22704, 0.40261, 0.029687]
Predicted label: 2
Correct prediction
Energy consumption = 144.211984 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 931 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 931 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 931 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.097275, 0.16063, 0.0091104, 0.0018516, 0.0035018, 0.34215, 0.023068, 0.30151, 0.059706]
Predicted label: 0
Correct prediction
Energy consumption = 163.407924 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79335, 0.028992, 0.32885, 0.018451, 0.017031, 0.0011536, 0.71709, 0.010528, 0.32883, 0.035323]
Predicted label: 0
Correct prediction
Energy consumption = 140.300689 pJ
sum error= 349
Actual label: 6
Output voltages: [0.064763, 0.036494, 0.056328, 0.0096467, 0.24562, 0.28418, 0.79869, 0.0016442, 0.52144, 0.018713]
Predicted label: 6
Correct prediction
Energy consumption = 138.969411 pJ
sum error= 349
Actual label: 1
Output voltages: [0.053971, 0.79864, 0.19859, 0.021984, 0.022313, 0.001066, 0.75362, 0.0011768, 0.22141, 0.047963]
Predicted label: 1
Correct prediction
Energy consumption = 161.113326 pJ
sum error= 349
Actual label: 7
Output voltages: [0.11917, 0.18066, 0.14619, 0.43481, 0.0038167, 0.0030905, 0.0010682, 0.79864, 0.42931, 0.59863]
Predicted label: 7
Correct prediction
Energy consumption = 161.510608 pJ
sum error= 349
Actual label: 5
Output voltages: [0.025883, 0.011016, 0.0021598, 0.080283, 0.033448, 0.79868, 0.018352, 0.0010824, 0.75448, 0.09759]
Predicted label: 5
Correct prediction
Energy consumption = 150.679559 pJ
sum error= 349
Actual label: 8
Output voltages: [0.052911, 0.019576, 0.074859, 0.37705, 0.0017886, 0.14925, 0.0093802, 0.0084334, 0.79878, 0.26874]
Predicted label: 8
Correct prediction
Energy consumption = 138.338418 pJ
sum error= 349
Actual label: 6
Output voltages: [0.10861, 0.046709, 0.16474, 0.022657, 0.12477, 0.25242, 0.79877, 0.0032196, 0.43809, 0.16569]
Predicted label: 6
Correct prediction
Energy consumption = 143.245082 pJ
sum error= 349
Actual label: 2
Output voltages: [0.73442, 0.0098749, 0.79872, 0.6555, 0.012283, 0.0011142, 0.021155, 0.27197, 0.63621, 0.052218]
Predicted label: 2
Correct prediction
Energy consumption = 154.875359 pJ
sum error= 349
Actual label: 9
Output voltages: [0.4333, 0.0082684, 0.016314, 0.018263, 0.19108, 0.010932, 0.0017808, 0.10575, 0.42437, 0.79783]
Predicted label: 9
Correct prediction
Energy consumption = 154.733628 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 932 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 932 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 932 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.050793, 0.0079257, 0.039664, 0.014521, 0.79869, 0.0010732, 0.032293, 0.044623, 0.21458, 0.20495]
Predicted label: 4
Correct prediction
Energy consumption = 176.494972 pJ
sum error= 349
Actual label: 8
Output voltages: [0.039132, 0.044489, 0.047737, 0.40135, 0.001327, 0.031072, 0.006608, 0.0030905, 0.79871, 0.22607]
Predicted label: 8
Correct prediction
Energy consumption = 152.984722 pJ
sum error= 349
Actual label: 8
Output voltages: [0.022918, 0.03851, 0.39817, 0.039427, 0.031472, 0.021251, 0.027613, 0.0066893, 0.79876, 0.11678]
Predicted label: 8
Correct prediction
Energy consumption = 145.531718 pJ
sum error= 349
Actual label: 7
Output voltages: [0.3177, 0.022801, 0.0061938, 0.16045, 0.035658, 0.0143, 0.0010662, 0.79867, 0.19412, 0.61618]
Predicted label: 7
Correct prediction
Energy consumption = 157.396927 pJ
sum error= 349
Actual label: 1
Output voltages: [0.0017986, 0.79854, 0.022007, 0.0097364, 0.029296, 0.010519, 0.651, 0.0056188, 0.5032, 0.023742]
Predicted label: 1
Correct prediction
Energy consumption = 164.873687 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79674, 0.060537, 0.2671, 0.0040393, 0.0014691, 0.001066, 0.43804, 0.014303, 0.16283, 0.11085]
Predicted label: 0
Correct prediction
Energy consumption = 153.043095 pJ
sum error= 349
Actual label: 8
Output voltages: [0.018235, 0.015057, 0.1102, 0.40087, 0.0012206, 0.27639, 0.01762, 0.0044731, 0.79874, 0.062856]
Predicted label: 8
Correct prediction
Energy consumption = 146.697977 pJ
sum error= 349
Actual label: 7
Output voltages: [0.15439, 0.024907, 0.0060787, 0.1223, 0.025193, 0.015473, 0.0012806, 0.79878, 0.28908, 0.76007]
Predicted label: 7
Correct prediction
Energy consumption = 155.889575 pJ
sum error= 349
Actual label: 7
Output voltages: [0.060982, 0.0062381, 0.021303, 0.28655, 0.0064965, 0.017711, 0.0011668, 0.79866, 0.43194, 0.39932]
Predicted label: 7
Correct prediction
Energy consumption = 141.198536 pJ
sum error= 349
Actual label: 5
Output voltages: [0.14462, 0.0014925, 0.0016598, 0.27285, 0.03315, 0.79879, 0.033041, 0.014641, 0.78572, 0.040182]
Predicted label: 5
Correct prediction
Energy consumption = 141.250342 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 933 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 933 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 933 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.011561, 0.021878, 0.061364, 0.32906, 0.0054423, 0.21498, 0.061134, 0.010854, 0.79877, 0.040885]
Predicted label: 8
Correct prediction
Energy consumption = 168.776910 pJ
sum error= 349
Actual label: 5
Output voltages: [0.010673, 0.001067, 0.0010762, 0.46744, 0.13284, 0.79586, 0.17001, 0.021892, 0.53709, 0.42393]
Predicted label: 5
Correct prediction
Energy consumption = 146.902671 pJ
sum error= 349
Actual label: 3
Output voltages: [0.57172, 0.016165, 0.13271, 0.7986, 0.021756, 0.010703, 0.018019, 0.015497, 0.48606, 0.036859]
Predicted label: 3
Correct prediction
Energy consumption = 150.013597 pJ
sum error= 349
Actual label: 4
Output voltages: [0.0040626, 0.013086, 0.2246, 0.0036621, 0.79872, 0.001067, 0.031401, 0.036371, 0.035701, 0.3408]
Predicted label: 4
Correct prediction
Energy consumption = 161.123267 pJ
sum error= 349
Actual label: 6
Output voltages: [0.050853, 0.017256, 0.1423, 0.0026802, 0.44053, 0.19783, 0.79879, 0.0030502, 0.49607, 0.0016194]
Predicted label: 6
Correct prediction
Energy consumption = 148.836074 pJ
sum error= 349
Actual label: 1
Output voltages: [0.0079774, 0.79865, 0.3364, 0.77341, 0.0090303, 0.0015062, 0.025167, 0.047934, 0.010245, 0.3805]
Predicted label: 1
Correct prediction
Energy consumption = 162.624383 pJ
sum error= 349
Actual label: 1
Output voltages: [0.060756, 0.79834, 0.05233, 0.21246, 0.0048187, 0.0027757, 0.73736, 0.0033271, 0.03874, 0.30011]
Predicted label: 1
Correct prediction
Energy consumption = 151.721355 pJ
sum error= 349
Actual label: 5
Output voltages: [0.0027098, 0.0076343, 0.0052604, 0.39704, 0.040382, 0.7975, 0.046202, 0.031162, 0.71158, 0.23186]
Predicted label: 5
Correct prediction
Energy consumption = 155.658657 pJ
sum error= 349
Actual label: 5
Output voltages: [0.032164, 0.0083386, 0.023197, 0.57799, 0.0018234, 0.76997, 0.001581, 0.0072866, 0.79618, 0.046496]
Predicted label: 8
Wrong prediction!
Energy consumption = 138.101187 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79878, 0.14543, 0.33602, 0.041656, 0.001072, 0.029134, 0.20453, 0.023006, 0.37373, 0.013637]
Predicted label: 0
Correct prediction
Energy consumption = 146.610539 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 934 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 934 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 934 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25907, 0.32212, 0.049198, 0.28396, 0.0013365, 0.001142, 0.0010712, 0.7987, 0.2272, 0.48245]
Predicted label: 7
Correct prediction
Energy consumption = 180.141841 pJ
sum error= 350
Actual label: 2
Output voltages: [0.35995, 0.002655, 0.79782, 0.48314, 0.0070271, 0.0011415, 0.026653, 0.041438, 0.60958, 0.044953]
Predicted label: 2
Correct prediction
Energy consumption = 150.948447 pJ
sum error= 350
Actual label: 3
Output voltages: [0.75917, 0.13604, 0.36937, 0.79879, 0.0011122, 0.26582, 0.0034575, 0.025505, 0.021632, 0.028921]
Predicted label: 3
Correct prediction
Energy consumption = 143.656411 pJ
sum error= 350
Actual label: 6
Output voltages: [0.23675, 0.096477, 0.22514, 0.009402, 0.22788, 0.38927, 0.79875, 0.0017548, 0.37951, 0.027732]
Predicted label: 6
Correct prediction
Energy consumption = 149.407045 pJ
sum error= 350
Actual label: 4
Output voltages: [0.0041981, 0.011958, 0.33516, 0.019422, 0.79868, 0.0042201, 0.14509, 0.017092, 0.018178, 0.20936]
Predicted label: 4
Correct prediction
Energy consumption = 157.965319 pJ
sum error= 350
Actual label: 1
Output voltages: [0.0090836, 0.79856, 0.17805, 0.051886, 0.28738, 0.002139, 0.5105, 0.020917, 0.34614, 0.057727]
Predicted label: 1
Correct prediction
Energy consumption = 168.899667 pJ
sum error= 350
Actual label: 2
Output voltages: [0.61508, 0.013721, 0.79878, 0.47428, 0.025425, 0.0011007, 0.056475, 0.092602, 0.75772, 0.03788]
Predicted label: 2
Correct prediction
Energy consumption = 148.827773 pJ
sum error= 350
Actual label: 4
Output voltages: [0.0070715, 0.0044922, 0.2012, 0.012871, 0.79861, 0.0016784, 0.083544, 0.030763, 0.028737, 0.040148]
Predicted label: 4
Correct prediction
Energy consumption = 154.833042 pJ
sum error= 350
Actual label: 1
Output voltages: [0.1718, 0.79868, 0.27983, 0.14831, 0.051179, 0.001141, 0.39473, 0.0039788, 0.17037, 0.027776]
Predicted label: 1
Correct prediction
Energy consumption = 166.589554 pJ
sum error= 350
Actual label: 5
Output voltages: [0.041352, 0.0017553, 0.011792, 0.21893, 0.017834, 0.79876, 0.41921, 0.032269, 0.74179, 0.017482]
Predicted label: 5
Correct prediction
Energy consumption = 155.443320 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 935 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 935 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 935 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.012728, 0.0059842, 0.35931, 0.0096785, 0.79874, 0.0010845, 0.038913, 0.22513, 0.027388, 0.22767]
Predicted label: 4
Correct prediction
Energy consumption = 169.963496 pJ
sum error= 350
Actual label: 2
Output voltages: [0.37641, 0.011399, 0.7957, 0.46657, 0.011695, 0.0012251, 0.11345, 0.082482, 0.60276, 0.091707]
Predicted label: 2
Correct prediction
Energy consumption = 156.148018 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79874, 0.17243, 0.094113, 0.0098744, 0.010451, 0.016014, 0.45559, 0.019363, 0.034413, 0.057623]
Predicted label: 0
Correct prediction
Energy consumption = 149.103944 pJ
sum error= 350
Actual label: 4
Output voltages: [0.025109, 0.005755, 0.26856, 0.026729, 0.79875, 0.0011765, 0.049832, 0.23287, 0.048624, 0.1512]
Predicted label: 4
Correct prediction
Energy consumption = 161.138582 pJ
sum error= 350
Actual label: 8
Output voltages: [0.014496, 0.014922, 0.30621, 0.04301, 0.01919, 0.015202, 0.040524, 0.012896, 0.7987, 0.059217]
Predicted label: 8
Correct prediction
Energy consumption = 151.774476 pJ
sum error= 350
Actual label: 6
Output voltages: [0.062548, 0.083364, 0.32926, 0.011033, 0.34467, 0.23493, 0.79865, 0.010498, 0.35438, 0.016992]
Predicted label: 6
Correct prediction
Energy consumption = 147.735050 pJ
sum error= 350
Actual label: 1
Output voltages: [0.012877, 0.79836, 0.059546, 0.019887, 0.0063481, 0.010179, 0.61098, 0.02285, 0.47096, 0.019932]
Predicted label: 1
Correct prediction
Energy consumption = 163.271931 pJ
sum error= 350
Actual label: 9
Output voltages: [0.04274, 0.0064529, 0.015029, 0.020009, 0.31045, 0.0064474, 0.0025303, 0.010546, 0.50937, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 153.030922 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79879, 0.14741, 0.039654, 0.015308, 0.0046816, 0.0082414, 0.53974, 0.017204, 0.11555, 0.064123]
Predicted label: 0
Correct prediction
Energy consumption = 152.185409 pJ
sum error= 350
Actual label: 2
Output voltages: [0.73123, 0.0053999, 0.79859, 0.29023, 0.0059471, 0.0010689, 0.034422, 0.22679, 0.73587, 0.0032778]
Predicted label: 2
Correct prediction
Energy consumption = 143.568721 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 936 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 936 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 936 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.035756, 0.0012338, 0.0022442, 0.44564, 0.011353, 0.79879, 0.14013, 0.028893, 0.64302, 0.060936]
Predicted label: 5
Correct prediction
Energy consumption = 165.352638 pJ
sum error= 350
Actual label: 6
Output voltages: [0.047647, 0.094765, 0.29313, 0.0045806, 0.15997, 0.37432, 0.79868, 0.0050503, 0.44191, 0.017246]
Predicted label: 6
Correct prediction
Energy consumption = 145.431500 pJ
sum error= 350
Actual label: 9
Output voltages: [0.34043, 0.018173, 0.034609, 0.031746, 0.065539, 0.024404, 0.0040496, 0.092537, 0.47644, 0.79775]
Predicted label: 9
Correct prediction
Energy consumption = 155.977027 pJ
sum error= 350
Actual label: 3
Output voltages: [0.28579, 0.025074, 0.052759, 0.79869, 0.027803, 0.012566, 0.019498, 0.0081413, 0.48912, 0.17229]
Predicted label: 3
Correct prediction
Energy consumption = 150.739164 pJ
sum error= 350
Actual label: 6
Output voltages: [0.18165, 0.032517, 0.27775, 0.0013872, 0.45513, 0.011224, 0.79878, 0.001075, 0.20684, 0.021515]
Predicted label: 6
Correct prediction
Energy consumption = 146.596581 pJ
sum error= 350
Actual label: 3
Output voltages: [0.31, 0.021621, 0.034199, 0.79871, 0.014684, 0.028413, 0.0068273, 0.01765, 0.53584, 0.043857]
Predicted label: 3
Correct prediction
Energy consumption = 158.430253 pJ
sum error= 350
Actual label: 6
Output voltages: [0.025146, 0.014023, 0.20292, 0.0030382, 0.41945, 0.022351, 0.79879, 0.0013382, 0.36041, 0.026147]
Predicted label: 6
Correct prediction
Energy consumption = 144.666411 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79879, 0.096256, 0.034219, 0.011513, 0.003563, 0.0044843, 0.55197, 0.020284, 0.093742, 0.043585]
Predicted label: 0
Correct prediction
Energy consumption = 144.627693 pJ
sum error= 350
Actual label: 1
Output voltages: [0.010678, 0.79852, 0.056403, 0.026653, 0.17103, 0.0070641, 0.21726, 0.0079107, 0.1569, 0.19045]
Predicted label: 1
Correct prediction
Energy consumption = 165.838656 pJ
sum error= 350
Actual label: 2
Output voltages: [0.47198, 0.0026794, 0.79737, 0.38406, 0.016357, 0.0012008, 0.014075, 0.023802, 0.32826, 0.025973]
Predicted label: 2
Correct prediction
Energy consumption = 145.108161 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 937 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 937 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 937 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.35826, 0.057559, 0.25601, 0.79877, 0.0019463, 0.0013726, 0.020765, 0.0057823, 0.59792, 0.02414]
Predicted label: 3
Correct prediction
Energy consumption = 162.052793 pJ
sum error= 350
Actual label: 4
Output voltages: [0.0028051, 0.020932, 0.13361, 0.0045004, 0.79868, 0.0084582, 0.052582, 0.032609, 0.03011, 0.3731]
Predicted label: 4
Correct prediction
Energy consumption = 157.898464 pJ
sum error= 350
Actual label: 5
Output voltages: [0.037606, 0.0010728, 0.0023159, 0.37004, 0.056752, 0.79879, 0.32949, 0.048822, 0.78563, 0.035065]
Predicted label: 5
Correct prediction
Energy consumption = 149.385971 pJ
sum error= 350
Actual label: 6
Output voltages: [0.046689, 0.049702, 0.24136, 0.0022656, 0.3467, 0.29185, 0.79867, 0.0067671, 0.41387, 0.0080259]
Predicted label: 6
Correct prediction
Energy consumption = 140.768083 pJ
sum error= 350
Actual label: 7
Output voltages: [0.070033, 0.0088928, 0.03252, 0.051304, 0.040124, 0.025439, 0.0010686, 0.79848, 0.025224, 0.087387]
Predicted label: 7
Correct prediction
Energy consumption = 157.807199 pJ
sum error= 350
Actual label: 8
Output voltages: [0.17732, 0.017969, 0.13209, 0.29, 0.0024624, 0.0025873, 0.31051, 0.0012699, 0.79861, 0.040972]
Predicted label: 8
Correct prediction
Energy consumption = 151.088111 pJ
sum error= 350
Actual label: 9
Output voltages: [0.29333, 0.028907, 0.025592, 0.17797, 0.1464, 0.17963, 0.018424, 0.022182, 0.13475, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 153.109605 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79876, 0.018641, 0.14697, 0.019892, 0.0014093, 0.019324, 0.3121, 0.060341, 0.17349, 0.024696]
Predicted label: 0
Correct prediction
Energy consumption = 140.290885 pJ
sum error= 350
Actual label: 1
Output voltages: [0.02028, 0.79867, 0.15781, 0.11246, 0.30671, 0.0038244, 0.17762, 0.0020877, 0.067056, 0.041313]
Predicted label: 1
Correct prediction
Energy consumption = 165.389014 pJ
sum error= 350
Actual label: 2
Output voltages: [0.37196, 0.0054169, 0.79875, 0.056296, 0.0030902, 0.0010778, 0.070802, 0.053643, 0.74603, 0.0028632]
Predicted label: 2
Correct prediction
Energy consumption = 147.018482 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 938 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 938 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 938 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23324, 0.0072117, 0.22101, 0.79866, 0.015301, 0.0012789, 0.039235, 0.23688, 0.33585, 0.024038]
Predicted label: 3
Correct prediction
Energy consumption = 160.169314 pJ
sum error= 350
Actual label: 4
Output voltages: [0.0046683, 0.044063, 0.050882, 0.0033616, 0.79865, 0.0099669, 0.022112, 0.25383, 0.04363, 0.11494]
Predicted label: 4
Correct prediction
Energy consumption = 158.637987 pJ
sum error= 350
Actual label: 5
Output voltages: [0.0088043, 0.0015341, 0.0011016, 0.28401, 0.60726, 0.7179, 0.15466, 0.0011198, 0.56334, 0.22457]
Predicted label: 5
Correct prediction
Energy consumption = 144.088334 pJ
sum error= 350
Actual label: 6
Output voltages: [0.041875, 0.10016, 0.57286, 0.0010788, 0.42059, 0.26636, 0.79873, 0.0013042, 0.50371, 0.0056246]
Predicted label: 6
Correct prediction
Energy consumption = 140.159426 pJ
sum error= 350
Actual label: 7
Output voltages: [0.045618, 0.02994, 0.035137, 0.01676, 0.020494, 0.0028358, 0.0010793, 0.79856, 0.18821, 0.2725]
Predicted label: 7
Correct prediction
Energy consumption = 151.181162 pJ
sum error= 350
Actual label: 8
Output voltages: [0.057091, 0.034177, 0.25124, 0.55205, 0.0011221, 0.26206, 0.75486, 0.0010785, 0.79788, 0.036495]
Predicted label: 8
Correct prediction
Energy consumption = 156.241698 pJ
sum error= 350
Actual label: 9
Output voltages: [0.051275, 0.01835, 0.035577, 0.029214, 0.044405, 0.0057461, 0.0054061, 0.051431, 0.57913, 0.79348]
Predicted label: 9
Correct prediction
Energy consumption = 147.938539 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79877, 0.067458, 0.047545, 0.019425, 0.003259, 0.008383, 0.5956, 0.034119, 0.29233, 0.026569]
Predicted label: 0
Correct prediction
Energy consumption = 144.541068 pJ
sum error= 350
Actual label: 1
Output voltages: [0.016, 0.79835, 0.048404, 0.067413, 0.028095, 0.0077882, 0.68956, 0.018965, 0.094404, 0.20691]
Predicted label: 1
Correct prediction
Energy consumption = 162.595068 pJ
sum error= 350
Actual label: 2
Output voltages: [0.68751, 0.0076102, 0.79875, 0.17751, 0.016898, 0.0011138, 0.20995, 0.0445, 0.71689, 0.028988]
Predicted label: 2
Correct prediction
Energy consumption = 148.283077 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 939 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 939 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 939 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.25288, 0.024545, 0.064217, 0.79869, 0.028249, 0.0012895, 0.016448, 0.052786, 0.65184, 0.033217]
Predicted label: 3
Correct prediction
Energy consumption = 160.628755 pJ
sum error= 350
Actual label: 5
Output voltages: [0.1252, 0.0010992, 0.0010767, 0.38657, 0.51183, 0.79876, 0.24871, 0.02065, 0.76729, 0.028139]
Predicted label: 5
Correct prediction
Energy consumption = 143.972382 pJ
sum error= 350
Actual label: 6
Output voltages: [0.040659, 0.044388, 0.42639, 0.0041552, 0.046081, 0.067379, 0.79877, 0.01283, 0.066704, 0.027379]
Predicted label: 6
Correct prediction
Energy consumption = 139.476321 pJ
sum error= 350
Actual label: 7
Output voltages: [0.062052, 0.06197, 0.18112, 0.033402, 0.0058372, 0.0075957, 0.0057196, 0.79837, 0.061084, 0.10084]
Predicted label: 7
Correct prediction
Energy consumption = 155.485500 pJ
sum error= 350
Actual label: 8
Output voltages: [0.015908, 0.010071, 0.057812, 0.029628, 0.0022262, 0.037936, 0.11426, 0.0044853, 0.79879, 0.14714]
Predicted label: 8
Correct prediction
Energy consumption = 145.997877 pJ
sum error= 350
Actual label: 1
Output voltages: [0.05095, 0.79858, 0.14051, 0.1379, 0.04971, 0.0013782, 0.23531, 0.0027727, 0.036836, 0.2157]
Predicted label: 1
Correct prediction
Energy consumption = 166.536462 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79875, 0.033524, 0.057016, 0.0079393, 0.019879, 0.0020424, 0.67726, 0.021643, 0.11003, 0.077714]
Predicted label: 0
Correct prediction
Energy consumption = 141.481370 pJ
sum error= 350
Actual label: 9
Output voltages: [0.053535, 0.031789, 0.06192, 0.15075, 0.020529, 0.0079929, 0.011381, 0.16703, 0.56001, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 154.489770 pJ
sum error= 350
Actual label: 5
Output voltages: [0.15552, 0.0010734, 0.0022357, 0.45037, 0.081138, 0.79878, 0.10881, 0.047282, 0.76994, 0.036487]
Predicted label: 5
Correct prediction
Energy consumption = 144.731432 pJ
sum error= 350
Actual label: 7
Output voltages: [0.50566, 0.041476, 0.0029086, 0.020101, 0.038265, 0.026597, 0.0015275, 0.79878, 0.038765, 0.59551]
Predicted label: 7
Correct prediction
Energy consumption = 153.098422 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 940 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 940 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 940 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.02319, 0.0010794, 0.0012721, 0.35255, 0.039543, 0.79357, 0.14871, 0.019771, 0.78474, 0.013559]
Predicted label: 5
Correct prediction
Energy consumption = 168.874731 pJ
sum error= 350
Actual label: 1
Output voltages: [0.017621, 0.79847, 0.020882, 0.14113, 0.038955, 0.0039828, 0.22509, 0.025307, 0.036517, 0.10416]
Predicted label: 1
Correct prediction
Energy consumption = 169.920366 pJ
sum error= 350
Actual label: 8
Output voltages: [0.020901, 0.018925, 0.32199, 0.1604, 0.0077949, 0.36999, 0.028303, 0.019971, 0.79875, 0.0162]
Predicted label: 8
Correct prediction
Energy consumption = 158.279119 pJ
sum error= 350
Actual label: 6
Output voltages: [0.21308, 0.14918, 0.033821, 0.010056, 0.2564, 0.34354, 0.79872, 0.0019108, 0.48968, 0.011805]
Predicted label: 6
Correct prediction
Energy consumption = 148.168095 pJ
sum error= 350
Actual label: 9
Output voltages: [0.19045, 0.0051894, 0.01562, 0.022746, 0.19238, 0.04852, 0.0078544, 0.079109, 0.36829, 0.79833]
Predicted label: 9
Correct prediction
Energy consumption = 154.867102 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79879, 0.059136, 0.022388, 0.0056715, 0.037351, 0.018138, 0.68992, 0.0028625, 0.03695, 0.052861]
Predicted label: 0
Correct prediction
Energy consumption = 152.659763 pJ
sum error= 350
Actual label: 4
Output voltages: [0.024254, 0.031707, 0.28807, 0.0046047, 0.79879, 0.0011631, 0.015812, 0.068172, 0.018043, 0.49733]
Predicted label: 4
Correct prediction
Energy consumption = 158.571207 pJ
sum error= 350
Actual label: 1
Output voltages: [0.021515, 0.79862, 0.041781, 0.1342, 0.28472, 0.02061, 0.61425, 0.0011417, 0.061151, 0.18783]
Predicted label: 1
Correct prediction
Energy consumption = 162.012563 pJ
sum error= 350
Actual label: 9
Output voltages: [0.3208, 0.002341, 0.020389, 0.18395, 0.52786, 0.13162, 0.042239, 0.013566, 0.056398, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 153.016281 pJ
sum error= 350
Actual label: 3
Output voltages: [0.34287, 0.026346, 0.28414, 0.79868, 0.011413, 0.014081, 0.010682, 0.0038617, 0.72872, 0.025017]
Predicted label: 3
Correct prediction
Energy consumption = 139.879098 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 941 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 941 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 941 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18373, 0.0066376, 0.01577, 0.61087, 0.001066, 0.4895, 0.02059, 0.0036401, 0.79878, 0.43625]
Predicted label: 8
Correct prediction
Energy consumption = 167.136110 pJ
sum error= 350
Actual label: 4
Output voltages: [0.010605, 0.0075629, 0.092803, 0.012804, 0.7987, 0.0011808, 0.12402, 0.028112, 0.056281, 0.030845]
Predicted label: 4
Correct prediction
Energy consumption = 157.042560 pJ
sum error= 350
Actual label: 4
Output voltages: [0.010904, 0.002905, 0.036957, 0.011578, 0.79874, 0.0018797, 0.12565, 0.38344, 0.2263, 0.0037112]
Predicted label: 4
Correct prediction
Energy consumption = 147.085834 pJ
sum error= 350
Actual label: 7
Output voltages: [0.19193, 0.2248, 0.59149, 0.044037, 0.0071974, 0.0012235, 0.0024733, 0.79879, 0.30314, 0.083826]
Predicted label: 7
Correct prediction
Energy consumption = 156.216978 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79879, 0.0026395, 0.10477, 0.0091563, 0.02877, 0.010901, 0.2549, 0.020131, 0.045767, 0.032278]
Predicted label: 0
Correct prediction
Energy consumption = 156.836509 pJ
sum error= 350
Actual label: 1
Output voltages: [0.022613, 0.79847, 0.065592, 0.022783, 0.015139, 0.0017217, 0.3932, 0.017191, 0.48859, 0.03434]
Predicted label: 1
Correct prediction
Energy consumption = 163.219796 pJ
sum error= 350
Actual label: 9
Output voltages: [0.30203, 0.0074482, 0.01834, 0.43598, 0.045122, 0.30329, 0.016758, 0.1038, 0.14427, 0.7985]
Predicted label: 9
Correct prediction
Energy consumption = 156.493853 pJ
sum error= 350
Actual label: 2
Output voltages: [0.44305, 0.023521, 0.79868, 0.026223, 0.010412, 0.0010729, 0.038016, 0.027665, 0.58953, 0.0013872]
Predicted label: 2
Correct prediction
Energy consumption = 152.535926 pJ
sum error= 350
Actual label: 8
Output voltages: [0.03556, 0.041398, 0.27831, 0.061899, 0.012921, 0.0030073, 0.041883, 0.0013525, 0.79879, 0.30273]
Predicted label: 8
Correct prediction
Energy consumption = 149.559860 pJ
sum error= 350
Actual label: 7
Output voltages: [0.45152, 0.11761, 0.0068572, 0.39353, 0.015627, 0.059457, 0.0011154, 0.79869, 0.046633, 0.24418]
Predicted label: 7
Correct prediction
Energy consumption = 155.762812 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 942 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 942 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 942 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.024529, 0.052648, 0.19701, 0.063417, 0.0073465, 0.0049955, 0.014461, 0.0095583, 0.79874, 0.32407]
Predicted label: 8
Correct prediction
Energy consumption = 163.837609 pJ
sum error= 350
Actual label: 2
Output voltages: [0.69705, 0.036616, 0.79879, 0.25487, 0.0011023, 0.0010659, 0.013373, 0.16143, 0.3888, 0.020048]
Predicted label: 2
Correct prediction
Energy consumption = 144.921200 pJ
sum error= 350
Actual label: 5
Output voltages: [0.0024793, 0.0011172, 0.0062526, 0.77901, 0.43523, 0.32832, 0.49244, 0.012793, 0.52047, 0.018325]
Predicted label: 3
Wrong prediction!
Energy consumption = 150.798260 pJ
sum error= 351
Actual label: 9
Output voltages: [0.22859, 0.018535, 0.037369, 0.073126, 0.21946, 0.025586, 0.014032, 0.31203, 0.072386, 0.79832]
Predicted label: 9
Correct prediction
Energy consumption = 147.727967 pJ
sum error= 351
Actual label: 6
Output voltages: [0.054861, 0.040966, 0.11923, 0.0039368, 0.3368, 0.36999, 0.79872, 0.0047797, 0.45368, 0.0039022]
Predicted label: 6
Correct prediction
Energy consumption = 149.367341 pJ
sum error= 351
Actual label: 0
Output voltages: [0.78948, 0.0063787, 0.078874, 0.0012104, 0.0070416, 0.017119, 0.70515, 0.0021226, 0.28924, 0.022853]
Predicted label: 0
Correct prediction
Energy consumption = 147.631842 pJ
sum error= 351
Actual label: 6
Output voltages: [0.086146, 0.015314, 0.078973, 0.0016325, 0.29175, 0.03545, 0.79828, 0.0092819, 0.046966, 0.042275]
Predicted label: 6
Correct prediction
Energy consumption = 136.723857 pJ
sum error= 351
Actual label: 5
Output voltages: [0.031039, 0.0010661, 0.0010789, 0.36062, 0.30181, 0.79873, 0.59901, 0.0036927, 0.7708, 0.045372]
Predicted label: 5
Correct prediction
Energy consumption = 143.671407 pJ
sum error= 351
Actual label: 5
Output voltages: [0.013495, 0.0011095, 0.0014222, 0.41847, 0.18427, 0.79439, 0.24069, 0.011639, 0.74797, 0.047578]
Predicted label: 5
Correct prediction
Energy consumption = 138.418546 pJ
sum error= 351
Actual label: 3
Output voltages: [0.20619, 0.030471, 0.070919, 0.79871, 0.019652, 0.0026131, 0.005318, 0.0084363, 0.708, 0.025463]
Predicted label: 3
Correct prediction
Energy consumption = 136.242374 pJ
sum error= 351
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 943 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 943 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 943 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.64127, 0.016365, 0.50832, 0.79879, 0.0048639, 0.015291, 0.0097562, 0.013781, 0.35425, 0.016831]
Predicted label: 3
Correct prediction
Energy consumption = 161.553222 pJ
sum error= 351
Actual label: 3
Output voltages: [0.42229, 0.0085967, 0.19889, 0.79877, 0.0051121, 0.0083574, 0.0076219, 0.0031548, 0.70642, 0.017458]
Predicted label: 3
Correct prediction
Energy consumption = 137.570759 pJ
sum error= 351
Actual label: 9
Output voltages: [0.38759, 0.048437, 0.0090867, 0.58855, 0.3222, 0.014003, 0.029166, 0.017634, 0.070568, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 149.654352 pJ
sum error= 351
Actual label: 8
Output voltages: [0.055095, 0.0273, 0.20887, 0.0081601, 0.0032282, 0.021965, 0.28001, 0.012855, 0.79879, 0.30055]
Predicted label: 8
Correct prediction
Energy consumption = 152.292347 pJ
sum error= 351
Actual label: 1
Output voltages: [0.015171, 0.79862, 0.29185, 0.079563, 0.037098, 0.0010663, 0.60194, 0.0010919, 0.13524, 0.42813]
Predicted label: 1
Correct prediction
Energy consumption = 167.432662 pJ
sum error= 351
Actual label: 1
Output voltages: [0.017775, 0.79835, 0.023088, 0.2311, 0.0055857, 0.011981, 0.61743, 0.0048457, 0.040321, 0.063633]
Predicted label: 1
Correct prediction
Energy consumption = 156.668347 pJ
sum error= 351
Actual label: 0
Output voltages: [0.79879, 0.26963, 0.1263, 0.026265, 0.0043008, 0.021853, 0.35916, 0.01297, 0.15364, 0.13267]
Predicted label: 0
Correct prediction
Energy consumption = 158.820117 pJ
sum error= 351
Actual label: 6
Output voltages: [0.029934, 0.10318, 0.25419, 0.0020749, 0.10968, 0.13872, 0.79873, 0.0097354, 0.31907, 0.0032572]
Predicted label: 6
Correct prediction
Energy consumption = 142.746302 pJ
sum error= 351
Actual label: 1
Output voltages: [0.014778, 0.79846, 0.10295, 0.056554, 0.0282, 0.0038235, 0.4942, 0.0078437, 0.20291, 0.027899]
Predicted label: 1
Correct prediction
Energy consumption = 160.391767 pJ
sum error= 351
Actual label: 0
Output voltages: [0.79712, 0.016149, 0.047384, 0.0028147, 0.0063005, 0.001609, 0.67663, 0.024069, 0.10224, 0.045484]
Predicted label: 0
Correct prediction
Energy consumption = 151.707227 pJ
sum error= 351
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 944 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 944 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 944 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79858, 0.041784, 0.025134, 0.010686, 0.0012149, 0.015423, 0.61249, 0.0068391, 0.28415, 0.017789]
Predicted label: 0
Correct prediction
Energy consumption = 162.679073 pJ
sum error= 351
Actual label: 6
Output voltages: [0.16171, 0.21203, 0.31447, 0.006419, 0.22553, 0.23667, 0.79869, 0.0035991, 0.21242, 0.021515]
Predicted label: 6
Correct prediction
Energy consumption = 145.598373 pJ
sum error= 351
Actual label: 2
Output voltages: [0.3097, 0.0010923, 0.79862, 0.43722, 0.02044, 0.0010668, 0.037315, 0.1956, 0.72937, 0.041372]
Predicted label: 2
Correct prediction
Energy consumption = 143.986585 pJ
sum error= 351
Actual label: 1
Output voltages: [0.019209, 0.7985, 0.017783, 0.15688, 0.038357, 0.025306, 0.33385, 0.0059907, 0.29424, 0.16863]
Predicted label: 1
Correct prediction
Energy consumption = 169.061201 pJ
sum error= 351
Actual label: 1
Output voltages: [0.026915, 0.79857, 0.12599, 0.029957, 0.29347, 0.011036, 0.23466, 0.0069653, 0.011684, 0.17745]
Predicted label: 1
Correct prediction
Energy consumption = 157.344148 pJ
sum error= 351
Actual label: 3
Output voltages: [0.37434, 0.031847, 0.048684, 0.79861, 0.017399, 0.0045428, 0.02676, 0.036634, 0.54068, 0.029709]
Predicted label: 3
Correct prediction
Energy consumption = 142.087791 pJ
sum error= 351
Actual label: 2
Output voltages: [0.022202, 0.0043421, 0.79878, 0.39885, 0.073172, 0.0011319, 0.060653, 0.2964, 0.3524, 0.0191]
Predicted label: 2
Correct prediction
Energy consumption = 132.549919 pJ
sum error= 351
Actual label: 7
Output voltages: [0.26076, 0.032032, 0.039418, 0.018406, 0.048686, 0.0086735, 0.0017753, 0.79847, 0.16532, 0.043946]
Predicted label: 7
Correct prediction
Energy consumption = 156.129437 pJ
sum error= 351
Actual label: 7
Output voltages: [0.011719, 0.34149, 0.047036, 0.020025, 0.041613, 0.0011305, 0.002268, 0.79869, 0.029685, 0.31245]
Predicted label: 7
Correct prediction
Energy consumption = 146.276375 pJ
sum error= 351
Actual label: 8
Output voltages: [0.02308, 0.0071098, 0.047821, 0.059767, 0.0064233, 0.023429, 0.0049601, 0.027649, 0.79879, 0.44322]
Predicted label: 8
Correct prediction
Energy consumption = 141.236825 pJ
sum error= 351
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 945 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 945 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 945 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.15967, 0.0096707, 0.20746, 0.36256, 0.0039359, 0.040266, 0.41714, 0.002652, 0.79874, 0.020597]
Predicted label: 8
Correct prediction
Energy consumption = 170.087687 pJ
sum error= 351
Actual label: 7
Output voltages: [0.13665, 0.01861, 0.012687, 0.069406, 0.021664, 0.012346, 0.0010865, 0.79862, 0.084723, 0.30566]
Predicted label: 7
Correct prediction
Energy consumption = 156.626714 pJ
sum error= 351
Actual label: 8
Output voltages: [0.011722, 0.014567, 0.23917, 0.09749, 0.0026493, 0.20851, 0.16917, 0.015056, 0.79877, 0.039559]
Predicted label: 8
Correct prediction
Energy consumption = 150.057963 pJ
sum error= 351
Actual label: 4
Output voltages: [0.019869, 0.02437, 0.2452, 0.0079058, 0.79865, 0.0048702, 0.03465, 0.034433, 0.038286, 0.044563]
Predicted label: 4
Correct prediction
Energy consumption = 153.814615 pJ
sum error= 351
Actual label: 6
Output voltages: [0.02598, 0.078485, 0.46564, 0.0010733, 0.45193, 0.054797, 0.79873, 0.0012685, 0.17773, 0.003965]
Predicted label: 6
Correct prediction
Energy consumption = 141.369171 pJ
sum error= 351
Actual label: 0
Output voltages: [0.79792, 0.0805, 0.28306, 0.0027816, 0.0040586, 0.011429, 0.30969, 0.0092742, 0.0076936, 0.071937]
Predicted label: 0
Correct prediction
Energy consumption = 150.330502 pJ
sum error= 351
Actual label: 2
Output voltages: [0.18481, 0.015037, 0.79879, 0.32509, 0.0018301, 0.0011885, 0.062243, 0.74795, 0.44431, 0.060123]
Predicted label: 2
Correct prediction
Energy consumption = 138.151405 pJ
sum error= 351
Actual label: 0
Output voltages: [0.79819, 0.043335, 0.027475, 0.014431, 0.0088854, 0.012381, 0.74528, 0.0057323, 0.20516, 0.035884]
Predicted label: 0
Correct prediction
Energy consumption = 154.912913 pJ
sum error= 351
Actual label: 7
Output voltages: [0.45494, 0.01241, 0.20627, 0.0037991, 0.032686, 0.0041269, 0.0010681, 0.79865, 0.040546, 0.045692]
Predicted label: 7
Correct prediction
Energy consumption = 150.062260 pJ
sum error= 351
Actual label: 0
Output voltages: [0.79879, 0.091953, 0.029118, 0.0047896, 0.015677, 0.006185, 0.48444, 0.0054558, 0.043078, 0.33084]
Predicted label: 0
Correct prediction
Energy consumption = 148.258031 pJ
sum error= 351
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 946 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 946 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 946 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.051027, 0.023545, 0.11419, 0.79874, 0.0068025, 0.001113, 0.01158, 0.011712, 0.74143, 0.022136]
Predicted label: 3
Correct prediction
Energy consumption = 158.004082 pJ
sum error= 351
Actual label: 6
Output voltages: [0.069271, 0.031114, 0.067294, 0.0087131, 0.55414, 0.40219, 0.79873, 0.0014999, 0.68234, 0.014219]
Predicted label: 6
Correct prediction
Energy consumption = 146.416178 pJ
sum error= 351
Actual label: 8
Output voltages: [0.01743, 0.020013, 0.0625, 0.014982, 0.022982, 0.021763, 0.034129, 0.012187, 0.7987, 0.12209]
Predicted label: 8
Correct prediction
Energy consumption = 154.534203 pJ
sum error= 351
Actual label: 7
Output voltages: [0.26008, 0.0018812, 0.0095768, 0.037021, 0.03014, 0.013714, 0.0011187, 0.79878, 0.6126, 0.19954]
Predicted label: 7
Correct prediction
Energy consumption = 153.728733 pJ
sum error= 351
Actual label: 1
Output voltages: [0.0035074, 0.79849, 0.022515, 0.036978, 0.011416, 0.0055069, 0.51937, 0.0092384, 0.4557, 0.038937]
Predicted label: 1
Correct prediction
Energy consumption = 165.621984 pJ
sum error= 351
Actual label: 5
Output voltages: [0.068048, 0.002941, 0.0038335, 0.53597, 0.019833, 0.79878, 0.21647, 0.010177, 0.38872, 0.012999]
Predicted label: 5
Correct prediction
Energy consumption = 155.657166 pJ
sum error= 351
Actual label: 9
Output voltages: [0.20337, 0.0075343, 0.0033489, 0.13791, 0.23784, 0.0013133, 0.001209, 0.010001, 0.4618, 0.79802]
Predicted label: 9
Correct prediction
Energy consumption = 152.348429 pJ
sum error= 351
Actual label: 9
Output voltages: [0.25415, 0.0086441, 0.051799, 0.013087, 0.14975, 0.0081239, 0.0072488, 0.0069098, 0.54745, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 141.099216 pJ
sum error= 351
Actual label: 3
Output voltages: [0.29761, 0.012425, 0.41953, 0.79875, 0.0078293, 0.0036964, 0.0020107, 0.0049359, 0.7749, 0.0060623]
Predicted label: 3
Correct prediction
Energy consumption = 143.973587 pJ
sum error= 351
Actual label: 7
Output voltages: [0.15913, 0.028172, 0.0016773, 0.45965, 0.012127, 0.021022, 0.0010933, 0.79877, 0.049266, 0.2568]
Predicted label: 7
Correct prediction
Energy consumption = 152.846065 pJ
sum error= 351
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 947 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 947 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 947 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.50271, 0.0019614, 0.79878, 0.052722, 0.0066016, 0.0011241, 0.043117, 0.038154, 0.66151, 0.0042464]
Predicted label: 2
Correct prediction
Energy consumption = 163.241227 pJ
sum error= 351
Actual label: 4
Output voltages: [0.0081496, 0.031484, 0.049094, 0.013341, 0.79866, 0.002647, 0.22943, 0.028321, 0.031775, 0.04408]
Predicted label: 4
Correct prediction
Energy consumption = 152.075501 pJ
sum error= 351
Actual label: 9
Output voltages: [0.24589, 0.0025015, 0.014423, 0.019798, 0.53477, 0.073617, 0.088711, 0.28192, 0.15493, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 148.300824 pJ
sum error= 351
Actual label: 4
Output voltages: [0.0092638, 0.0081744, 0.24006, 0.0080029, 0.79862, 0.0011577, 0.038369, 0.012668, 0.027675, 0.24834]
Predicted label: 4
Correct prediction
Energy consumption = 149.188142 pJ
sum error= 351
Actual label: 3
Output voltages: [0.40641, 0.0056655, 0.18441, 0.79874, 0.019422, 0.04943, 0.0075952, 0.024118, 0.59521, 0.11789]
Predicted label: 3
Correct prediction
Energy consumption = 155.828821 pJ
sum error= 351
Actual label: 6
Output voltages: [0.14911, 0.032046, 0.1678, 0.0010722, 0.38597, 0.39946, 0.79876, 0.0014338, 0.41606, 0.029788]
Predicted label: 6
Correct prediction
Energy consumption = 147.447603 pJ
sum error= 351
Actual label: 2
Output voltages: [0.24429, 0.048259, 0.79865, 0.04193, 0.0089146, 0.0010669, 0.14529, 0.022261, 0.67466, 0.020739]
Predicted label: 2
Correct prediction
Energy consumption = 138.847301 pJ
sum error= 351
Actual label: 2
Output voltages: [0.099317, 0.0011228, 0.79877, 0.18641, 0.049585, 0.0010711, 0.0051292, 0.19707, 0.72003, 0.0076952]
Predicted label: 2
Correct prediction
Energy consumption = 125.562003 pJ
sum error= 351
Actual label: 5
Output voltages: [0.030285, 0.013787, 0.0016553, 0.36894, 0.048833, 0.79872, 0.1529, 0.0014364, 0.76423, 0.0035423]
Predicted label: 5
Correct prediction
Energy consumption = 153.964632 pJ
sum error= 351
Actual label: 3
Output voltages: [0.33163, 0.048343, 0.16254, 0.79866, 0.011603, 0.011168, 0.002808, 0.018318, 0.75524, 0.020466]
Predicted label: 3
Correct prediction
Energy consumption = 141.199086 pJ
sum error= 351
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 948 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 948 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 948 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36979, 0.034016, 0.79863, 0.034601, 0.018973, 0.0011346, 0.1395, 0.016175, 0.38226, 0.013041]
Predicted label: 2
Correct prediction
Energy consumption = 163.307899 pJ
sum error= 351
Actual label: 5
Output voltages: [0.030055, 0.0016227, 0.0030643, 0.36176, 0.034105, 0.79865, 0.038795, 0.030463, 0.76459, 0.0038777]
Predicted label: 5
Correct prediction
Energy consumption = 147.634425 pJ
sum error= 351
Actual label: 5
Output voltages: [0.050328, 0.0030307, 0.0050388, 0.77494, 0.057572, 0.79866, 0.012087, 0.012289, 0.73093, 0.016579]
Predicted label: 5
Correct prediction
Energy consumption = 141.958055 pJ
sum error= 351
Actual label: 9
Output voltages: [0.083372, 0.019534, 0.026517, 0.041881, 0.044628, 0.017553, 0.0017018, 0.023725, 0.69897, 0.79739]
Predicted label: 9
Correct prediction
Energy consumption = 150.310607 pJ
sum error= 351
Actual label: 4
Output voltages: [0.011025, 0.013078, 0.044915, 0.0093938, 0.79874, 0.0020692, 0.10826, 0.073232, 0.16881, 0.0099437]
Predicted label: 4
Correct prediction
Energy consumption = 148.883214 pJ
sum error= 351
Actual label: 1
Output voltages: [0.016088, 0.79878, 0.016208, 0.010875, 0.35928, 0.002291, 0.12167, 0.0032023, 0.37765, 0.21151]
Predicted label: 1
Correct prediction
Energy consumption = 157.865437 pJ
sum error= 351
Actual label: 7
Output voltages: [0.14049, 0.056504, 0.21428, 0.33716, 0.019018, 0.085146, 0.0012156, 0.79854, 0.047521, 0.37512]
Predicted label: 7
Correct prediction
Energy consumption = 149.975908 pJ
sum error= 351
Actual label: 2
Output voltages: [0.38206, 0.021755, 0.79874, 0.18844, 0.012808, 0.001066, 0.055902, 0.036258, 0.30647, 0.013886]
Predicted label: 2
Correct prediction
Energy consumption = 141.526639 pJ
sum error= 351
Actual label: 0
Output voltages: [0.79878, 0.035751, 0.034279, 0.011535, 0.0033799, 0.0045054, 0.61651, 0.043466, 0.10369, 0.051409]
Predicted label: 0
Correct prediction
Energy consumption = 139.781269 pJ
sum error= 351
Actual label: 1
Output voltages: [0.0089248, 0.79864, 0.36032, 0.030447, 0.12388, 0.0010719, 0.32206, 0.0050373, 0.19195, 0.010538]
Predicted label: 1
Correct prediction
Energy consumption = 166.367520 pJ
sum error= 351
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 949 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 949 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 949 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.039791, 0.20774, 0.79852, 0.035354, 0.0029344, 0.0011223, 0.022487, 0.040736, 0.59326, 0.031117]
Predicted label: 2
Correct prediction
Energy consumption = 166.005243 pJ
sum error= 351
Actual label: 3
Output voltages: [0.26899, 0.023182, 0.047734, 0.79871, 0.018997, 0.01394, 0.008845, 0.37602, 0.57256, 0.14845]
Predicted label: 3
Correct prediction
Energy consumption = 149.199631 pJ
sum error= 351
Actual label: 4
Output voltages: [0.038461, 0.0020687, 0.73206, 0.060937, 0.79877, 0.021137, 0.053836, 0.0023202, 0.3006, 0.64713]
Predicted label: 4
Correct prediction
Energy consumption = 151.811364 pJ
sum error= 351
Actual label: 5
Output voltages: [0.022015, 0.0010704, 0.0017295, 0.037698, 0.19655, 0.79685, 0.031348, 0.010556, 0.78996, 0.1441]
Predicted label: 5
Correct prediction
Energy consumption = 143.344506 pJ
sum error= 351
Actual label: 6
Output voltages: [0.048765, 0.080011, 0.65008, 0.0010699, 0.22152, 0.033961, 0.79877, 0.003359, 0.041261, 0.021949]
Predicted label: 6
Correct prediction
Energy consumption = 147.387372 pJ
sum error= 351
Actual label: 7
Output voltages: [0.22046, 0.062989, 0.015056, 0.018023, 0.0070005, 0.0014489, 0.0010659, 0.79878, 0.040412, 0.76568]
Predicted label: 7
Correct prediction
Energy consumption = 158.888263 pJ
sum error= 351
Actual label: 8
Output voltages: [0.0095929, 0.18181, 0.16175, 0.049327, 0.0081728, 0.023634, 0.015498, 0.3484, 0.79867, 0.043209]
Predicted label: 8
Correct prediction
Energy consumption = 144.009657 pJ
sum error= 351
Actual label: 9
Output voltages: [0.043656, 0.0208, 0.01706, 0.037515, 0.0065444, 0.0083518, 0.0016073, 0.065877, 0.76383, 0.78874]
Predicted label: 9
Correct prediction
Energy consumption = 144.339843 pJ
sum error= 351
Actual label: 0
Output voltages: [0.79879, 0.10813, 0.025048, 0.0040229, 0.01129, 0.0063922, 0.57552, 0.0085318, 0.06386, 0.059543]
Predicted label: 0
Correct prediction
Energy consumption = 146.808452 pJ
sum error= 351
Actual label: 1
Output voltages: [0.017324, 0.79852, 0.17288, 0.37638, 0.021339, 0.0011146, 0.74268, 0.018943, 0.03863, 0.019205]
Predicted label: 1
Correct prediction
Energy consumption = 161.795608 pJ
sum error= 351
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 950 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 950 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 950 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.14782, 0.014039, 0.79879, 0.03347, 0.015726, 0.0010704, 0.013919, 0.58643, 0.54568, 0.0098077]
Predicted label: 2
Correct prediction
Energy consumption = 163.369106 pJ
sum error= 351
Actual label: 3
Output voltages: [0.03706, 0.026096, 0.044264, 0.79872, 0.015698, 0.0016691, 0.010313, 0.045252, 0.6446, 0.034993]
Predicted label: 3
Correct prediction
Energy consumption = 143.602879 pJ
sum error= 351
Actual label: 4
Output voltages: [0.013015, 0.0042006, 0.026963, 0.0012589, 0.79874, 0.0026695, 0.11957, 0.18542, 0.59073, 0.0031912]
Predicted label: 4
Correct prediction
Energy consumption = 155.801775 pJ
sum error= 351
Actual label: 5
Output voltages: [0.012088, 0.001066, 0.0018612, 0.11725, 0.050663, 0.78986, 0.26172, 0.014655, 0.75881, 0.068153]
Predicted label: 5
Correct prediction
Energy consumption = 142.738799 pJ
sum error= 351
Actual label: 6
Output voltages: [0.035489, 0.1181, 0.11549, 0.0081414, 0.19282, 0.44174, 0.79869, 0.0015423, 0.42045, 0.020521]
Predicted label: 6
Correct prediction
Energy consumption = 140.865378 pJ
sum error= 351
Actual label: 7
Output voltages: [0.47512, 0.024606, 0.75195, 0.55119, 0.0010737, 0.001158, 0.0048305, 0.70822, 0.58338, 0.14929]
Predicted label: 2
Wrong prediction!
Energy consumption = 153.609887 pJ
sum error= 352
Actual label: 8
Output voltages: [0.015825, 0.030787, 0.16033, 0.039799, 0.011252, 0.0044403, 0.023789, 0.22169, 0.79873, 0.11717]
Predicted label: 8
Correct prediction
Energy consumption = 139.613671 pJ
sum error= 352
Actual label: 9
Output voltages: [0.067354, 0.024851, 0.017013, 0.026666, 0.017014, 0.011433, 0.0012988, 0.019645, 0.75101, 0.79651]
Predicted label: 9
Correct prediction
Energy consumption = 143.950198 pJ
sum error= 352
Actual label: 0
Output voltages: [0.79842, 0.012126, 0.015526, 0.0092738, 0.022258, 0.0014345, 0.065766, 0.0037509, 0.56449, 0.0098094]
Predicted label: 0
Correct prediction
Energy consumption = 142.694649 pJ
sum error= 352
Actual label: 1
Output voltages: [0.066064, 0.79674, 0.052767, 0.022356, 0.23075, 0.0010773, 0.54128, 0.0011299, 0.042193, 0.069739]
Predicted label: 1
Correct prediction
Energy consumption = 156.888763 pJ
sum error= 352
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 951 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 951 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 951 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.52038, 0.0073062, 0.79874, 0.15574, 0.0041627, 0.0010955, 0.016588, 0.29277, 0.74499, 0.0013247]
Predicted label: 2
Correct prediction
Energy consumption = 166.354408 pJ
sum error= 352
Actual label: 3
Output voltages: [0.32884, 0.017122, 0.04731, 0.79859, 0.0043846, 0.15498, 0.0081614, 0.03941, 0.52708, 0.017743]
Predicted label: 3
Correct prediction
Energy consumption = 152.228811 pJ
sum error= 352
Actual label: 4
Output voltages: [0.0048705, 0.013274, 0.13662, 0.015692, 0.79876, 0.0022459, 0.057975, 0.10873, 0.044542, 0.024963]
Predicted label: 4
Correct prediction
Energy consumption = 150.964444 pJ
sum error= 352
Actual label: 5
Output voltages: [0.006515, 0.0011016, 0.0011468, 0.047534, 0.50592, 0.75967, 0.49463, 0.12703, 0.78621, 0.0041228]
Predicted label: 8
Wrong prediction!
Energy consumption = 140.670567 pJ
sum error= 353
Actual label: 6
Output voltages: [0.11247, 0.20019, 0.20743, 0.0053254, 0.22045, 0.15425, 0.79871, 0.0011127, 0.36531, 0.010339]
Predicted label: 6
Correct prediction
Energy consumption = 140.696782 pJ
sum error= 353
Actual label: 7
Output voltages: [0.077177, 0.14308, 0.41227, 0.078174, 0.002144, 0.0011559, 0.0010932, 0.79864, 0.74728, 0.054077]
Predicted label: 7
Correct prediction
Energy consumption = 155.569234 pJ
sum error= 353
Actual label: 8
Output voltages: [0.022906, 0.013404, 0.1977, 0.038331, 0.019547, 0.02889, 0.010555, 0.023793, 0.79862, 0.033041]
Predicted label: 8
Correct prediction
Energy consumption = 141.546832 pJ
sum error= 353
Actual label: 9
Output voltages: [0.039592, 0.01086, 0.031508, 0.0081102, 0.59208, 0.0011201, 0.0011182, 0.018615, 0.52631, 0.76402]
Predicted label: 9
Correct prediction
Energy consumption = 148.631904 pJ
sum error= 353
Actual label: 1
Output voltages: [0.035334, 0.79861, 0.21968, 0.27954, 0.22396, 0.002008, 0.66484, 0.010471, 0.093272, 0.080684]
Predicted label: 1
Correct prediction
Energy consumption = 159.487271 pJ
sum error= 353
Actual label: 0
Output voltages: [0.79865, 0.041521, 0.16453, 0.004026, 0.014835, 0.0012533, 0.57131, 0.011368, 0.25012, 0.14475]
Predicted label: 0
Correct prediction
Energy consumption = 148.131248 pJ
sum error= 353
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 952 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 952 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 952 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.010402, 0.79868, 0.0022315, 0.043019, 0.30811, 0.0012481, 0.27839, 0.0016392, 0.29421, 0.41361]
Predicted label: 1
Correct prediction
Energy consumption = 180.099320 pJ
sum error= 353
Actual label: 2
Output voltages: [0.34778, 0.0061983, 0.79805, 0.23248, 0.024544, 0.0012311, 0.033158, 0.040649, 0.70818, 0.027202]
Predicted label: 2
Correct prediction
Energy consumption = 145.079918 pJ
sum error= 353
Actual label: 7
Output voltages: [0.084959, 0.056423, 0.036078, 0.022032, 0.0032119, 0.014872, 0.0010989, 0.7985, 0.15401, 0.054108]
Predicted label: 7
Correct prediction
Energy consumption = 151.819326 pJ
sum error= 353
Actual label: 5
Output voltages: [0.026688, 0.0010674, 0.0047149, 0.11052, 0.023194, 0.79663, 0.057857, 0.026228, 0.72766, 0.04918]
Predicted label: 5
Correct prediction
Energy consumption = 141.584393 pJ
sum error= 353
Actual label: 3
Output voltages: [0.56019, 0.021665, 0.058605, 0.79868, 0.0028072, 0.027147, 0.0040297, 0.027286, 0.36286, 0.016473]
Predicted label: 3
Correct prediction
Energy consumption = 145.788735 pJ
sum error= 353
Actual label: 4
Output voltages: [0.0019304, 0.0091149, 0.008355, 0.0017001, 0.79867, 0.0014379, 0.37012, 0.51098, 0.046889, 0.0056893]
Predicted label: 4
Correct prediction
Energy consumption = 143.529798 pJ
sum error= 353
Actual label: 4
Output voltages: [0.007614, 0.016457, 0.12497, 0.0059669, 0.79871, 0.020353, 0.4235, 0.4019, 0.13763, 0.0045039]
Predicted label: 4
Correct prediction
Energy consumption = 137.605945 pJ
sum error= 353
Actual label: 0
Output voltages: [0.7925, 0.017996, 0.15564, 0.0028989, 0.016183, 0.0010961, 0.76868, 0.011489, 0.36386, 0.043172]
Predicted label: 0
Correct prediction
Energy consumption = 149.345007 pJ
sum error= 353
Actual label: 0
Output voltages: [0.79871, 0.054291, 0.093661, 0.0097755, 0.013916, 0.0039365, 0.5004, 0.025983, 0.12363, 0.022606]
Predicted label: 0
Correct prediction
Energy consumption = 136.980506 pJ
sum error= 353
Actual label: 6
Output voltages: [0.1615, 0.050557, 0.20098, 0.0041978, 0.37928, 0.42244, 0.79871, 0.0063832, 0.50533, 0.0066764]
Predicted label: 6
Correct prediction
Energy consumption = 144.338045 pJ
sum error= 353
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 953 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 953 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 953 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.033431, 0.01067, 0.0098733, 0.013905, 0.024717, 0.0078533, 0.019314, 0.017535, 0.75898, 0.78097]
Predicted label: 9
Correct prediction
Energy consumption = 174.080730 pJ
sum error= 353
Actual label: 6
Output voltages: [0.055901, 0.039186, 0.38571, 0.0016984, 0.3164, 0.22703, 0.79869, 0.0038158, 0.31055, 0.0034936]
Predicted label: 6
Correct prediction
Energy consumption = 149.443694 pJ
sum error= 353
Actual label: 6
Output voltages: [0.29758, 0.064263, 0.14051, 0.0015502, 0.29486, 0.17807, 0.79878, 0.001436, 0.25946, 0.018147]
Predicted label: 6
Correct prediction
Energy consumption = 137.606142 pJ
sum error= 353
Actual label: 5
Output voltages: [0.025889, 0.0010884, 0.0010928, 0.24529, 0.31237, 0.79874, 0.46054, 0.013172, 0.77236, 0.010774]
Predicted label: 5
Correct prediction
Energy consumption = 134.265581 pJ
sum error= 353
Actual label: 7
Output voltages: [0.53888, 0.0093577, 0.043259, 0.62701, 0.0055992, 0.0088582, 0.0011586, 0.79874, 0.055254, 0.45044]
Predicted label: 7
Correct prediction
Energy consumption = 154.463761 pJ
sum error= 353
Actual label: 2
Output voltages: [0.39502, 0.024717, 0.79745, 0.0031244, 0.054615, 0.0013124, 0.038805, 0.0069983, 0.7909, 0.11548]
Predicted label: 2
Correct prediction
Energy consumption = 145.117581 pJ
sum error= 353
Actual label: 3
Output voltages: [0.041043, 0.069394, 0.052808, 0.79878, 0.004872, 0.0016007, 0.010779, 0.033175, 0.60776, 0.13231]
Predicted label: 3
Correct prediction
Energy consumption = 143.298912 pJ
sum error= 353
Actual label: 4
Output voltages: [0.003073, 0.023909, 0.013006, 0.013791, 0.79868, 0.0020047, 0.029518, 0.039548, 0.095985, 0.015265]
Predicted label: 4
Correct prediction
Energy consumption = 150.385868 pJ
sum error= 353
Actual label: 4
Output voltages: [0.0010675, 0.21756, 0.020541, 0.0010665, 0.79664, 0.014739, 0.030313, 0.27042, 0.4304, 0.078583]
Predicted label: 4
Correct prediction
Energy consumption = 144.389413 pJ
sum error= 353
Actual label: 9
Output voltages: [0.034783, 0.015261, 0.010576, 0.020012, 0.017627, 0.0016395, 0.0018245, 0.05263, 0.78642, 0.79684]
Predicted label: 9
Correct prediction
Energy consumption = 136.605123 pJ
sum error= 353
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 954 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 954 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 954 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0045217, 0.75982, 0.0099808, 0.31671, 0.046036, 0.0011336, 0.025731, 0.0011655, 0.60875, 0.55092]
Predicted label: 1
Correct prediction
Energy consumption = 172.240135 pJ
sum error= 353
Actual label: 4
Output voltages: [0.0027323, 0.16508, 0.027335, 0.0018921, 0.79171, 0.03966, 0.18298, 0.010755, 0.41017, 0.023519]
Predicted label: 4
Correct prediction
Energy consumption = 150.574682 pJ
sum error= 353
Actual label: 0
Output voltages: [0.79143, 0.024295, 0.38103, 0.31342, 0.0011324, 0.0057456, 0.018882, 0.031795, 0.77901, 0.027043]
Predicted label: 0
Correct prediction
Energy consumption = 156.951807 pJ
sum error= 353
Actual label: 7
Output voltages: [0.22514, 0.021365, 0.028029, 0.11382, 0.0018132, 0.010046, 0.0012448, 0.79871, 0.27437, 0.43945]
Predicted label: 7
Correct prediction
Energy consumption = 149.486086 pJ
sum error= 353
Actual label: 9
Output voltages: [0.21297, 0.0054647, 0.054971, 0.10085, 0.21599, 0.016189, 0.0060429, 0.29972, 0.46493, 0.78852]
Predicted label: 9
Correct prediction
Energy consumption = 144.341730 pJ
sum error= 353
Actual label: 5
Output voltages: [0.021536, 0.0010806, 0.0010775, 0.55933, 0.033742, 0.79879, 0.061296, 0.025376, 0.72628, 0.0042113]
Predicted label: 5
Correct prediction
Energy consumption = 139.964946 pJ
sum error= 353
Actual label: 7
Output voltages: [0.51548, 0.013716, 0.020371, 0.035369, 0.015485, 0.013227, 0.0010682, 0.79874, 0.52817, 0.016035]
Predicted label: 7
Correct prediction
Energy consumption = 147.064388 pJ
sum error= 353
Actual label: 2
Output voltages: [0.60135, 0.0012646, 0.79876, 0.16666, 0.012309, 0.0010673, 0.02294, 0.065871, 0.68923, 0.0024855]
Predicted label: 2
Correct prediction
Energy consumption = 145.484413 pJ
sum error= 353
Actual label: 3
Output voltages: [0.3357, 0.0087894, 0.28474, 0.7987, 0.047826, 0.0062553, 0.011887, 0.047939, 0.65624, 0.050062]
Predicted label: 3
Correct prediction
Energy consumption = 142.004239 pJ
sum error= 353
Actual label: 1
Output voltages: [0.06378, 0.79864, 0.20964, 0.020448, 0.29843, 0.0010901, 0.35486, 0.013695, 0.040653, 0.056221]
Predicted label: 1
Correct prediction
Energy consumption = 163.703347 pJ
sum error= 353
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 955 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 955 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 955 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.02354, 0.037374, 0.125, 0.0038916, 0.79878, 0.0015935, 0.48456, 0.2013, 0.032244, 0.024726]
Predicted label: 4
Correct prediction
Energy consumption = 172.943820 pJ
sum error= 353
Actual label: 4
Output voltages: [0.0020208, 0.013318, 0.029566, 0.027789, 0.7987, 0.0010662, 0.092877, 0.24211, 0.018919, 0.025324]
Predicted label: 4
Correct prediction
Energy consumption = 152.257419 pJ
sum error= 353
Actual label: 0
Output voltages: [0.79829, 0.091076, 0.1562, 0.025006, 0.0037943, 0.0038005, 0.60725, 0.12697, 0.50017, 0.10382]
Predicted label: 0
Correct prediction
Energy consumption = 163.668527 pJ
sum error= 353
Actual label: 9
Output voltages: [0.43931, 0.0074926, 0.030776, 0.021852, 0.35004, 0.0084562, 0.0078257, 0.0070278, 0.62467, 0.79829]
Predicted label: 9
Correct prediction
Energy consumption = 148.385175 pJ
sum error= 353
Actual label: 9
Output voltages: [0.061013, 0.0017645, 0.043202, 0.0089161, 0.19386, 0.0017055, 0.0011183, 0.050137, 0.75887, 0.78348]
Predicted label: 9
Correct prediction
Energy consumption = 143.478077 pJ
sum error= 353
Actual label: 6
Output voltages: [0.06601, 0.028678, 0.29428, 0.0085728, 0.13756, 0.59065, 0.79872, 0.0091138, 0.43443, 0.019011]
Predicted label: 6
Correct prediction
Energy consumption = 149.771197 pJ
sum error= 353
Actual label: 1
Output voltages: [0.13385, 0.79574, 0.12644, 0.025197, 0.047868, 0.0011315, 0.44392, 0.0010663, 0.13475, 0.023616]
Predicted label: 1
Correct prediction
Energy consumption = 157.948156 pJ
sum error= 353
Actual label: 8
Output voltages: [0.026108, 0.011445, 0.18459, 0.044342, 0.01348, 0.018985, 0.010793, 0.076119, 0.79867, 0.016519]
Predicted label: 8
Correct prediction
Energy consumption = 144.069069 pJ
sum error= 353
Actual label: 3
Output voltages: [0.036897, 0.11669, 0.21572, 0.79866, 0.017055, 0.021628, 0.0027375, 0.022783, 0.52995, 0.1633]
Predicted label: 3
Correct prediction
Energy consumption = 141.953171 pJ
sum error= 353
Actual label: 3
Output voltages: [0.66636, 0.020537, 0.64105, 0.79856, 0.0045964, 0.0010834, 0.0010726, 0.022568, 0.52291, 0.018715]
Predicted label: 3
Correct prediction
Energy consumption = 140.245414 pJ
sum error= 353
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 956 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 956 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 956 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.069738, 0.19673, 0.53522, 0.11689, 0.0010917, 0.0011277, 0.0010781, 0.79875, 0.7701, 0.28612]
Predicted label: 7
Correct prediction
Energy consumption = 169.930487 pJ
sum error= 353
Actual label: 3
Output voltages: [0.12311, 0.017994, 0.080446, 0.79867, 0.020612, 0.0041735, 0.0077267, 0.028901, 0.48912, 0.054701]
Predicted label: 3
Correct prediction
Energy consumption = 139.864776 pJ
sum error= 353
Actual label: 9
Output voltages: [0.10458, 0.0065681, 0.029526, 0.011554, 0.26551, 0.00342, 0.0026357, 0.032906, 0.52934, 0.79229]
Predicted label: 9
Correct prediction
Energy consumption = 151.409795 pJ
sum error= 353
Actual label: 8
Output voltages: [0.055327, 0.021825, 0.29949, 0.085637, 0.01936, 0.13455, 0.061245, 0.022621, 0.79871, 0.015489]
Predicted label: 8
Correct prediction
Energy consumption = 142.198661 pJ
sum error= 353
Actual label: 8
Output voltages: [0.028761, 0.032698, 0.32173, 0.2178, 0.002744, 0.018931, 0.21469, 0.060495, 0.7987, 0.0062614]
Predicted label: 8
Correct prediction
Energy consumption = 139.430911 pJ
sum error= 353
Actual label: 4
Output voltages: [0.0077047, 0.054265, 0.018761, 0.0018078, 0.79878, 0.013559, 0.67745, 0.35701, 0.080964, 0.029574]
Predicted label: 4
Correct prediction
Energy consumption = 159.071129 pJ
sum error= 353
Actual label: 7
Output voltages: [0.053057, 0.15851, 0.14507, 0.3917, 0.0012498, 0.0011879, 0.0012606, 0.79879, 0.40166, 0.41856]
Predicted label: 7
Correct prediction
Energy consumption = 148.308901 pJ
sum error= 353
Actual label: 7
Output voltages: [0.045728, 0.15097, 0.031952, 0.15629, 0.0025978, 0.001506, 0.0010953, 0.79863, 0.03627, 0.18154]
Predicted label: 7
Correct prediction
Energy consumption = 137.343669 pJ
sum error= 353
Actual label: 6
Output voltages: [0.24197, 0.058131, 0.35574, 0.013895, 0.20948, 0.33144, 0.79867, 0.0047656, 0.25915, 0.045731]
Predicted label: 6
Correct prediction
Energy consumption = 152.796029 pJ
sum error= 353
Actual label: 2
Output voltages: [0.19041, 0.40806, 0.7987, 0.22218, 0.01082, 0.0012222, 0.17853, 0.01746, 0.27058, 0.079322]
Predicted label: 2
Correct prediction
Energy consumption = 150.787256 pJ
sum error= 353
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 957 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 957 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 957 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.032069, 0.79865, 0.16896, 0.016961, 0.15096, 0.001194, 0.69845, 0.0049913, 0.1859, 0.019919]
Predicted label: 1
Correct prediction
Energy consumption = 178.580682 pJ
sum error= 353
Actual label: 9
Output voltages: [0.24754, 0.008037, 0.015402, 0.0085659, 0.048881, 0.01734, 0.001234, 0.013345, 0.74117, 0.79257]
Predicted label: 9
Correct prediction
Energy consumption = 149.073735 pJ
sum error= 353
Actual label: 8
Output voltages: [0.011474, 0.0073859, 0.038473, 0.14901, 0.029643, 0.056476, 0.084669, 0.0023918, 0.79876, 0.26171]
Predicted label: 8
Correct prediction
Energy consumption = 146.140231 pJ
sum error= 353
Actual label: 7
Output voltages: [0.046539, 0.15885, 0.59293, 0.04322, 0.0019505, 0.0011393, 0.0010984, 0.79874, 0.76072, 0.028367]
Predicted label: 7
Correct prediction
Energy consumption = 145.240489 pJ
sum error= 353
Actual label: 8
Output voltages: [0.031456, 0.021553, 0.14898, 0.040308, 0.019642, 0.032846, 0.028755, 0.01307, 0.79864, 0.060749]
Predicted label: 8
Correct prediction
Energy consumption = 144.345401 pJ
sum error= 353
Actual label: 8
Output voltages: [0.042561, 0.05192, 0.11772, 0.40967, 0.0021986, 0.044502, 0.015589, 0.0026072, 0.79873, 0.38952]
Predicted label: 8
Correct prediction
Energy consumption = 140.080279 pJ
sum error= 353
Actual label: 7
Output voltages: [0.0701, 0.026913, 0.020225, 0.12581, 0.033146, 0.0010756, 0.001305, 0.79707, 0.30214, 0.2777]
Predicted label: 7
Correct prediction
Energy consumption = 158.816275 pJ
sum error= 353
Actual label: 2
Output voltages: [0.081465, 0.2035, 0.79835, 0.025626, 0.013591, 0.0013832, 0.040284, 0.48319, 0.39313, 0.0065843]
Predicted label: 2
Correct prediction
Energy consumption = 147.090303 pJ
sum error= 353
Actual label: 2
Output voltages: [0.2746, 0.030594, 0.7986, 0.010506, 0.0044414, 0.0011156, 0.080078, 0.29793, 0.72988, 0.0043234]
Predicted label: 2
Correct prediction
Energy consumption = 133.443096 pJ
sum error= 353
Actual label: 3
Output voltages: [0.31174, 0.016952, 0.12226, 0.79874, 0.038219, 0.033796, 0.031141, 0.0032802, 0.48311, 0.055285]
Predicted label: 3
Correct prediction
Energy consumption = 141.791613 pJ
sum error= 353
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 958 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 958 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 958 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.44354, 0.0065954, 0.0094836, 0.041758, 0.19076, 0.0030892, 0.0014117, 0.0059416, 0.44386, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 171.445302 pJ
sum error= 353
Actual label: 3
Output voltages: [0.15804, 0.018669, 0.35612, 0.79871, 0.018793, 0.010508, 0.0065983, 0.05424, 0.47244, 0.041004]
Predicted label: 3
Correct prediction
Energy consumption = 145.752750 pJ
sum error= 353
Actual label: 3
Output voltages: [0.44849, 0.013261, 0.044635, 0.79868, 0.011178, 0.029405, 0.0074481, 0.013996, 0.60422, 0.032288]
Predicted label: 3
Correct prediction
Energy consumption = 137.353021 pJ
sum error= 353
Actual label: 5
Output voltages: [0.055067, 0.0010668, 0.0011026, 0.65749, 0.055229, 0.7985, 0.035328, 0.018892, 0.65623, 0.021991]
Predicted label: 5
Correct prediction
Energy consumption = 138.982048 pJ
sum error= 353
Actual label: 5
Output voltages: [0.20745, 0.0011535, 0.0021077, 0.039435, 0.018547, 0.79869, 0.046988, 0.042107, 0.7805, 0.0029884]
Predicted label: 5
Correct prediction
Energy consumption = 135.429976 pJ
sum error= 353
Actual label: 0
Output voltages: [0.7982, 0.16595, 0.033292, 0.022295, 0.0050636, 0.0040566, 0.73713, 0.04058, 0.15216, 0.049283]
Predicted label: 0
Correct prediction
Energy consumption = 152.202539 pJ
sum error= 353
Actual label: 7
Output voltages: [0.43386, 0.011936, 0.22383, 0.46264, 0.0044184, 0.0012326, 0.0011216, 0.79877, 0.12826, 0.021827]
Predicted label: 7
Correct prediction
Energy consumption = 153.055222 pJ
sum error= 353
Actual label: 9
Output voltages: [0.34916, 0.0080383, 0.04108, 0.41152, 0.78713, 0.0012584, 0.0020958, 0.043487, 0.040182, 0.79305]
Predicted label: 9
Correct prediction
Energy consumption = 147.886345 pJ
sum error= 353
Actual label: 5
Output voltages: [0.017668, 0.0010676, 0.013223, 0.044284, 0.014275, 0.79499, 0.068315, 0.0030838, 0.78325, 0.029612]
Predicted label: 5
Correct prediction
Energy consumption = 148.967882 pJ
sum error= 353
Actual label: 6
Output voltages: [0.012723, 0.026725, 0.40282, 0.0021617, 0.17478, 0.25284, 0.79874, 0.0072125, 0.41727, 0.0023815]
Predicted label: 6
Correct prediction
Energy consumption = 145.727766 pJ
sum error= 353
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 959 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 959 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 959 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.035014, 0.0012291, 0.004978, 0.22625, 0.027265, 0.79841, 0.11894, 0.003038, 0.77459, 0.0062349]
Predicted label: 5
Correct prediction
Energy consumption = 161.443473 pJ
sum error= 353
Actual label: 1
Output voltages: [0.31843, 0.79442, 0.02594, 0.032334, 0.62842, 0.0011871, 0.51234, 0.0011324, 0.33911, 0.18732]
Predicted label: 1
Correct prediction
Energy consumption = 158.630809 pJ
sum error= 353
Actual label: 4
Output voltages: [0.01224, 0.0018613, 0.038065, 0.0010748, 0.79879, 0.003054, 0.32778, 0.30036, 0.64447, 0.0022608]
Predicted label: 4
Correct prediction
Energy consumption = 146.647189 pJ
sum error= 353
Actual label: 1
Output voltages: [0.019943, 0.79875, 0.03083, 0.013144, 0.25073, 0.0010712, 0.56624, 0.0011803, 0.044771, 0.048969]
Predicted label: 1
Correct prediction
Energy consumption = 158.425573 pJ
sum error= 353
Actual label: 1
Output voltages: [0.035271, 0.79218, 0.0038619, 0.015313, 0.63702, 0.0036905, 0.73051, 0.0010867, 0.73087, 0.093585]
Predicted label: 1
Correct prediction
Energy consumption = 148.771107 pJ
sum error= 353
Actual label: 2
Output voltages: [0.18678, 0.0042084, 0.79846, 0.068524, 0.021192, 0.0010659, 0.080564, 0.71572, 0.77142, 0.00129]
Predicted label: 2
Correct prediction
Energy consumption = 139.525317 pJ
sum error= 353
Actual label: 8
Output voltages: [0.18805, 0.0047028, 0.022622, 0.22575, 0.0010691, 0.031114, 0.0011387, 0.023693, 0.79856, 0.40396]
Predicted label: 8
Correct prediction
Energy consumption = 139.262843 pJ
sum error= 353
Actual label: 2
Output voltages: [0.58335, 0.02019, 0.79877, 0.062239, 0.025787, 0.0010867, 0.012517, 0.015988, 0.45871, 0.013974]
Predicted label: 2
Correct prediction
Energy consumption = 140.743393 pJ
sum error= 353
Actual label: 6
Output voltages: [0.055903, 0.027144, 0.31662, 0.0011954, 0.27358, 0.24066, 0.79877, 0.0036344, 0.40669, 0.0029216]
Predicted label: 6
Correct prediction
Energy consumption = 148.352059 pJ
sum error= 353
Actual label: 1
Output voltages: [0.025095, 0.79873, 0.012946, 0.2825, 0.03191, 0.0018102, 0.71528, 0.0083797, 0.055458, 0.023552]
Predicted label: 1
Correct prediction
Energy consumption = 156.923307 pJ
sum error= 353
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 960 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 960 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 960 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.052516, 0.0012041, 0.0012106, 0.19781, 0.23814, 0.76595, 0.26812, 0.001922, 0.7813, 0.012137]
Predicted label: 8
Wrong prediction!
Energy consumption = 156.704980 pJ
sum error= 354
Actual label: 0
Output voltages: [0.79876, 0.036522, 0.10715, 0.016369, 0.0114, 0.0044886, 0.49108, 0.048946, 0.089846, 0.047459]
Predicted label: 0
Correct prediction
Energy consumption = 149.919356 pJ
sum error= 354
Actual label: 1
Output voltages: [0.036288, 0.7987, 0.16722, 0.19483, 0.45633, 0.0011173, 0.33586, 0.011649, 0.023128, 0.042047]
Predicted label: 1
Correct prediction
Energy consumption = 161.685593 pJ
sum error= 354
Actual label: 2
Output voltages: [0.32614, 0.083341, 0.7987, 0.21665, 0.024914, 0.0011483, 0.26071, 0.038492, 0.37139, 0.16218]
Predicted label: 2
Correct prediction
Energy consumption = 136.808988 pJ
sum error= 354
Actual label: 3
Output voltages: [0.16521, 0.016097, 0.2864, 0.79878, 0.050821, 0.019652, 0.12716, 0.014429, 0.38453, 0.017892]
Predicted label: 3
Correct prediction
Energy consumption = 146.660478 pJ
sum error= 354
Actual label: 4
Output voltages: [0.08039, 0.0054883, 0.54593, 0.046326, 0.79877, 0.0012904, 0.0029731, 0.20089, 0.036189, 0.046819]
Predicted label: 4
Correct prediction
Energy consumption = 144.351219 pJ
sum error= 354
Actual label: 5
Output voltages: [0.31038, 0.01493, 0.0012063, 0.59019, 0.033559, 0.79867, 0.14316, 0.012636, 0.42159, 0.011793]
Predicted label: 5
Correct prediction
Energy consumption = 140.834601 pJ
sum error= 354
Actual label: 6
Output voltages: [0.21844, 0.39933, 0.17019, 0.031811, 0.029872, 0.18025, 0.79837, 0.011849, 0.41294, 0.0021575]
Predicted label: 6
Correct prediction
Energy consumption = 142.025197 pJ
sum error= 354
Actual label: 7
Output voltages: [0.43732, 0.008759, 0.23487, 0.46117, 0.0019347, 0.0010973, 0.001094, 0.79874, 0.050536, 0.51414]
Predicted label: 7
Correct prediction
Energy consumption = 155.480758 pJ
sum error= 354
Actual label: 8
Output voltages: [0.016345, 0.082135, 0.22217, 0.071667, 0.022819, 0.011653, 0.029413, 0.0082756, 0.79874, 0.28835]
Predicted label: 8
Correct prediction
Energy consumption = 133.179909 pJ
sum error= 354
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 961 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 961 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 961 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.054101, 0.01407, 0.020209, 0.3116, 0.0047405, 0.013421, 0.0010973, 0.19074, 0.75064, 0.78686]
Predicted label: 9
Correct prediction
Energy consumption = 166.984392 pJ
sum error= 354
Actual label: 0
Output voltages: [0.79879, 0.027133, 0.02916, 0.0054806, 0.012448, 0.010067, 0.53292, 0.012916, 0.055143, 0.032246]
Predicted label: 0
Correct prediction
Energy consumption = 144.326155 pJ
sum error= 354
Actual label: 1
Output voltages: [0.0020077, 0.78761, 0.5978, 0.67681, 0.58272, 0.0012505, 0.0084547, 0.047801, 0.024923, 0.71604]
Predicted label: 1
Correct prediction
Energy consumption = 155.347732 pJ
sum error= 354
Actual label: 2
Output voltages: [0.14459, 0.13338, 0.79871, 0.35348, 0.039904, 0.0012528, 0.17363, 0.019676, 0.62106, 0.28428]
Predicted label: 2
Correct prediction
Energy consumption = 138.149201 pJ
sum error= 354
Actual label: 3
Output voltages: [0.72795, 0.0012128, 0.15742, 0.79877, 0.032527, 0.29392, 0.0016149, 0.026276, 0.49261, 0.001335]
Predicted label: 3
Correct prediction
Energy consumption = 138.071513 pJ
sum error= 354
Actual label: 4
Output voltages: [0.013019, 0.001834, 0.19216, 0.0031939, 0.79873, 0.0016679, 0.075706, 0.24964, 0.13272, 0.015367]
Predicted label: 4
Correct prediction
Energy consumption = 147.588007 pJ
sum error= 354
Actual label: 5
Output voltages: [0.013377, 0.0011745, 0.0018384, 0.56057, 0.018182, 0.79879, 0.23713, 0.033683, 0.76448, 0.0097696]
Predicted label: 5
Correct prediction
Energy consumption = 142.838355 pJ
sum error= 354
Actual label: 6
Output voltages: [0.1282, 0.034428, 0.22072, 0.0060253, 0.62239, 0.033443, 0.79878, 0.0064278, 0.39855, 0.0030582]
Predicted label: 6
Correct prediction
Energy consumption = 142.478374 pJ
sum error= 354
Actual label: 7
Output voltages: [0.51457, 0.1055, 0.79734, 0.029482, 0.0010834, 0.0011507, 0.01352, 0.7944, 0.13981, 0.026519]
Predicted label: 2
Wrong prediction!
Energy consumption = 150.621295 pJ
sum error= 355
Actual label: 8
Output voltages: [0.16165, 0.018304, 0.3499, 0.032219, 0.0062086, 0.028927, 0.010811, 0.0094158, 0.79871, 0.093704]
Predicted label: 8
Correct prediction
Energy consumption = 137.782936 pJ
sum error= 355
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 962 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 962 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 962 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.05339, 0.0021534, 0.0011423, 0.045688, 0.39402, 0.022335, 0.001887, 0.64468, 0.36975, 0.75977]
Predicted label: 9
Correct prediction
Energy consumption = 171.198915 pJ
sum error= 355
Actual label: 0
Output voltages: [0.79877, 0.060155, 0.0076486, 0.017353, 0.021914, 0.034892, 0.64754, 0.028319, 0.1858, 0.029745]
Predicted label: 0
Correct prediction
Energy consumption = 146.518596 pJ
sum error= 355
Actual label: 1
Output voltages: [0.0023878, 0.79877, 0.34556, 0.056881, 0.61547, 0.0010926, 0.41291, 0.025252, 0.38218, 0.29419]
Predicted label: 1
Correct prediction
Energy consumption = 161.004411 pJ
sum error= 355
Actual label: 2
Output voltages: [0.24903, 0.12964, 0.79879, 0.29227, 0.024252, 0.0011919, 0.021637, 0.12816, 0.43945, 0.0076161]
Predicted label: 2
Correct prediction
Energy consumption = 142.463679 pJ
sum error= 355
Actual label: 3
Output voltages: [0.021346, 0.007828, 0.32121, 0.79876, 0.0060963, 0.0024986, 0.014021, 0.0026749, 0.79047, 0.021779]
Predicted label: 3
Correct prediction
Energy consumption = 133.556532 pJ
sum error= 355
Actual label: 4
Output voltages: [0.048393, 0.0010804, 0.28257, 0.020454, 0.79812, 0.0010674, 0.0012686, 0.0095186, 0.08164, 0.65809]
Predicted label: 4
Correct prediction
Energy consumption = 148.891530 pJ
sum error= 355
Actual label: 5
Output voltages: [0.12061, 0.0030093, 0.001066, 0.61191, 0.049204, 0.7987, 0.1171, 0.0039273, 0.43461, 0.0033784]
Predicted label: 5
Correct prediction
Energy consumption = 141.277261 pJ
sum error= 355
Actual label: 6
Output voltages: [0.073388, 0.017123, 0.32501, 0.015842, 0.73067, 0.035703, 0.79811, 0.0031614, 0.57371, 0.0010739]
Predicted label: 6
Correct prediction
Energy consumption = 137.278168 pJ
sum error= 355
Actual label: 7
Output voltages: [0.70447, 0.011558, 0.66592, 0.05232, 0.0016331, 0.0010858, 0.0019426, 0.79861, 0.55665, 0.032367]
Predicted label: 7
Correct prediction
Energy consumption = 147.678746 pJ
sum error= 355
Actual label: 8
Output voltages: [0.025003, 0.0026473, 0.12897, 0.008487, 0.084068, 0.095886, 0.040834, 0.0020431, 0.79873, 0.011531]
Predicted label: 8
Correct prediction
Energy consumption = 132.331480 pJ
sum error= 355
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 963 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 963 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 963 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.014556, 0.024361, 0.22503, 0.047165, 0.0050263, 0.018058, 0.02673, 0.030781, 0.79865, 0.045672]
Predicted label: 8
Correct prediction
Energy consumption = 165.800471 pJ
sum error= 355
Actual label: 0
Output voltages: [0.79804, 0.086602, 0.21313, 0.033389, 0.016708, 0.0017556, 0.49619, 0.0079405, 0.34791, 0.0473]
Predicted label: 0
Correct prediction
Energy consumption = 151.855978 pJ
sum error= 355
Actual label: 6
Output voltages: [0.09214, 0.046581, 0.19638, 0.012331, 0.21584, 0.32381, 0.79879, 0.0017763, 0.53448, 0.0045551]
Predicted label: 6
Correct prediction
Energy consumption = 138.605682 pJ
sum error= 355
Actual label: 0
Output voltages: [0.79879, 0.028323, 0.038354, 0.021916, 0.054625, 0.0011911, 0.058589, 0.030917, 0.49298, 0.034801]
Predicted label: 0
Correct prediction
Energy consumption = 142.791585 pJ
sum error= 355
Actual label: 0
Output voltages: [0.6543, 0.18412, 0.066456, 0.18896, 0.0013225, 0.0011885, 0.50296, 0.0010689, 0.79074, 0.030132]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.125056 pJ
sum error= 356
Actual label: 2
Output voltages: [0.35464, 0.13093, 0.79864, 0.1976, 0.021143, 0.001111, 0.25558, 0.14243, 0.18726, 0.13676]
Predicted label: 2
Correct prediction
Energy consumption = 142.295268 pJ
sum error= 356
Actual label: 3
Output voltages: [0.46314, 0.016865, 0.054745, 0.79879, 0.012563, 0.40164, 0.024734, 0.040991, 0.39846, 0.0038483]
Predicted label: 3
Correct prediction
Energy consumption = 142.464856 pJ
sum error= 356
Actual label: 7
Output voltages: [0.57943, 0.010575, 0.10426, 0.29384, 0.001199, 0.0011022, 0.0010795, 0.79879, 0.4253, 0.14254]
Predicted label: 7
Correct prediction
Energy consumption = 140.286024 pJ
sum error= 356
Actual label: 9
Output voltages: [0.60784, 0.021662, 0.017507, 0.021778, 0.01525, 0.023269, 0.0015188, 0.23954, 0.51134, 0.79786]
Predicted label: 9
Correct prediction
Energy consumption = 143.117286 pJ
sum error= 356
Actual label: 4
Output voltages: [0.004173, 0.010785, 0.022738, 0.0056004, 0.79854, 0.0012943, 0.04306, 0.27521, 0.10428, 0.0078084]
Predicted label: 4
Correct prediction
Energy consumption = 148.128061 pJ
sum error= 356
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 964 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 964 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 964 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.040822, 0.22764, 0.7496, 0.15718, 0.0016197, 0.0010852, 0.0010872, 0.79871, 0.44757, 0.33806]
Predicted label: 7
Correct prediction
Energy consumption = 167.602649 pJ
sum error= 356
Actual label: 1
Output voltages: [0.10084, 0.79875, 0.022681, 0.080572, 0.76504, 0.0010751, 0.24408, 0.0010736, 0.031287, 0.35624]
Predicted label: 1
Correct prediction
Energy consumption = 156.433856 pJ
sum error= 356
Actual label: 9
Output voltages: [0.63734, 0.0021179, 0.04951, 0.033959, 0.28936, 0.022795, 0.0031563, 0.33753, 0.11068, 0.79593]
Predicted label: 9
Correct prediction
Energy consumption = 149.448446 pJ
sum error= 356
Actual label: 1
Output voltages: [0.051996, 0.79741, 0.040007, 0.22524, 0.51605, 0.0011504, 0.0010703, 0.02502, 0.056042, 0.16815]
Predicted label: 1
Correct prediction
Energy consumption = 151.774322 pJ
sum error= 356
Actual label: 7
Output voltages: [0.39278, 0.040984, 0.17559, 0.38276, 0.005065, 0.0011712, 0.0010698, 0.79866, 0.04023, 0.30202]
Predicted label: 7
Correct prediction
Energy consumption = 146.147431 pJ
sum error= 356
Actual label: 1
Output voltages: [0.014605, 0.79878, 0.029776, 0.0097753, 0.74272, 0.0010661, 0.014333, 0.046028, 0.013183, 0.15572]
Predicted label: 1
Correct prediction
Energy consumption = 155.141337 pJ
sum error= 356
Actual label: 4
Output voltages: [0.014224, 0.010968, 0.019307, 0.025183, 0.79879, 0.0011404, 0.019713, 0.53692, 0.39686, 0.014221]
Predicted label: 4
Correct prediction
Energy consumption = 140.087301 pJ
sum error= 356
Actual label: 0
Output voltages: [0.79877, 0.061812, 0.036507, 0.021367, 0.0085213, 0.012938, 0.42328, 0.15899, 0.05441, 0.027439]
Predicted label: 0
Correct prediction
Energy consumption = 147.723894 pJ
sum error= 356
Actual label: 0
Output voltages: [0.79875, 0.045629, 0.14001, 0.0090058, 0.012761, 0.0017856, 0.321, 0.054349, 0.18802, 0.019536]
Predicted label: 0
Correct prediction
Energy consumption = 133.631236 pJ
sum error= 356
Actual label: 1
Output voltages: [0.0031147, 0.79878, 0.17839, 0.064719, 0.12667, 0.0010659, 0.051839, 0.0066809, 0.16686, 0.15907]
Predicted label: 1
Correct prediction
Energy consumption = 139.598733 pJ
sum error= 356
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 965 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 965 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 965 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.68625, 0.032801, 0.0070142, 0.072603, 0.1366, 0.076427, 0.0020082, 0.79859, 0.021863, 0.050862]
Predicted label: 7
Correct prediction
Energy consumption = 166.563511 pJ
sum error= 356
Actual label: 5
Output voltages: [0.018948, 0.012909, 0.0011191, 0.68566, 0.029505, 0.79871, 0.031332, 0.013861, 0.39664, 0.0067778]
Predicted label: 5
Correct prediction
Energy consumption = 140.153985 pJ
sum error= 356
Actual label: 7
Output voltages: [0.1893, 0.047092, 0.43669, 0.12974, 0.023802, 0.0036808, 0.0018938, 0.7974, 0.034838, 0.73891]
Predicted label: 7
Correct prediction
Energy consumption = 151.188681 pJ
sum error= 356
Actual label: 1
Output voltages: [0.013831, 0.79771, 0.082497, 0.024745, 0.28237, 0.0011155, 0.021896, 0.0070033, 0.23093, 0.22596]
Predicted label: 1
Correct prediction
Energy consumption = 155.194332 pJ
sum error= 356
Actual label: 3
Output voltages: [0.56334, 0.00963, 0.047034, 0.79867, 0.0065325, 0.040981, 0.0024072, 0.022717, 0.64523, 0.0078583]
Predicted label: 3
Correct prediction
Energy consumption = 138.991656 pJ
sum error= 356
Actual label: 3
Output voltages: [0.017076, 0.0015036, 0.058224, 0.79879, 0.013531, 0.40813, 0.014946, 0.012143, 0.75425, 0.02562]
Predicted label: 3
Correct prediction
Energy consumption = 131.597676 pJ
sum error= 356
Actual label: 3
Output voltages: [0.58023, 0.0010689, 0.68315, 0.79737, 0.014541, 0.2964, 0.0011471, 0.0091137, 0.6844, 0.0017231]
Predicted label: 3
Correct prediction
Energy consumption = 124.753803 pJ
sum error= 356
Actual label: 1
Output voltages: [0.026608, 0.79878, 0.54008, 0.0049491, 0.39881, 0.001097, 0.40716, 0.001899, 0.1139, 0.10869]
Predicted label: 1
Correct prediction
Energy consumption = 157.958739 pJ
sum error= 356
Actual label: 6
Output voltages: [0.043694, 0.015926, 0.49354, 0.0013022, 0.29903, 0.22936, 0.79878, 0.0078604, 0.69164, 0.0017701]
Predicted label: 6
Correct prediction
Energy consumption = 139.777022 pJ
sum error= 356
Actual label: 9
Output voltages: [0.23877, 0.023716, 0.022573, 0.098345, 0.15233, 0.010692, 0.0077078, 0.024169, 0.48682, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 153.845794 pJ
sum error= 356
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 966 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 966 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 966 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.3787, 0.039029, 0.30546, 0.018647, 0.015743, 0.0010731, 0.0013932, 0.79869, 0.052828, 0.015388]
Predicted label: 7
Correct prediction
Energy consumption = 167.319901 pJ
sum error= 356
Actual label: 1
Output voltages: [0.015699, 0.79873, 0.0296, 0.0328, 0.4918, 0.001084, 0.22402, 0.0017046, 0.32204, 0.14863]
Predicted label: 1
Correct prediction
Energy consumption = 158.070356 pJ
sum error= 356
Actual label: 3
Output voltages: [0.075374, 0.0055483, 0.68397, 0.79854, 0.0163, 0.0017541, 0.013086, 0.0058399, 0.78828, 0.010372]
Predicted label: 3
Correct prediction
Energy consumption = 141.858942 pJ
sum error= 356
Actual label: 0
Output voltages: [0.79818, 0.016743, 0.1554, 0.0049209, 0.041407, 0.0028384, 0.47818, 0.10628, 0.30966, 0.012142]
Predicted label: 0
Correct prediction
Energy consumption = 145.519817 pJ
sum error= 356
Actual label: 2
Output voltages: [0.40002, 0.02328, 0.79861, 0.04613, 0.0075182, 0.001162, 0.0041641, 0.77549, 0.58125, 0.046465]
Predicted label: 2
Correct prediction
Energy consumption = 135.196229 pJ
sum error= 356
Actual label: 6
Output voltages: [0.13459, 0.013741, 0.06972, 0.0028399, 0.48585, 0.14601, 0.79875, 0.0019702, 0.68947, 0.0097863]
Predicted label: 6
Correct prediction
Energy consumption = 142.146501 pJ
sum error= 356
Actual label: 0
Output voltages: [0.79852, 0.011972, 0.17734, 0.016755, 0.039883, 0.0011006, 0.27764, 0.010705, 0.37026, 0.040248]
Predicted label: 0
Correct prediction
Energy consumption = 148.123081 pJ
sum error= 356
Actual label: 8
Output voltages: [0.0085549, 0.061982, 0.28841, 0.033788, 0.0074037, 0.022414, 0.0070734, 0.036974, 0.7987, 0.12065]
Predicted label: 8
Correct prediction
Energy consumption = 148.097338 pJ
sum error= 356
Actual label: 9
Output voltages: [0.34878, 0.028498, 0.023022, 0.040045, 0.14297, 0.0099998, 0.0032253, 0.0042605, 0.45248, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.287887 pJ
sum error= 356
Actual label: 4
Output voltages: [0.0023475, 0.055342, 0.013711, 0.32701, 0.79835, 0.0057538, 0.0011888, 0.027869, 0.010344, 0.37931]
Predicted label: 4
Correct prediction
Energy consumption = 141.206992 pJ
sum error= 356
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 967 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 967 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 967 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.054174, 0.026821, 0.046853, 0.79877, 0.0066664, 0.04213, 0.0021052, 0.0041471, 0.70518, 0.019876]
Predicted label: 3
Correct prediction
Energy consumption = 157.981053 pJ
sum error= 356
Actual label: 5
Output voltages: [0.048726, 0.013336, 0.0011305, 0.31506, 0.041566, 0.79877, 0.096038, 0.001922, 0.5511, 0.027476]
Predicted label: 5
Correct prediction
Energy consumption = 141.164105 pJ
sum error= 356
Actual label: 4
Output voltages: [0.011859, 0.0059288, 0.02392, 0.019694, 0.79868, 0.0064048, 0.26964, 0.18084, 0.18419, 0.011001]
Predicted label: 4
Correct prediction
Energy consumption = 155.136780 pJ
sum error= 356
Actual label: 8
Output voltages: [0.037035, 0.0060651, 0.043946, 0.057911, 0.011493, 0.031564, 0.0094172, 0.0091958, 0.79876, 0.054606]
Predicted label: 8
Correct prediction
Energy consumption = 140.315397 pJ
sum error= 356
Actual label: 1
Output voltages: [0.021069, 0.79879, 0.4342, 0.0025133, 0.57122, 0.0014317, 0.28935, 0.022056, 0.27719, 0.067826]
Predicted label: 1
Correct prediction
Energy consumption = 158.532795 pJ
sum error= 356
Actual label: 5
Output voltages: [0.38732, 0.0013458, 0.0011212, 0.39016, 0.036598, 0.79871, 0.22604, 0.014291, 0.54461, 0.043663]
Predicted label: 5
Correct prediction
Energy consumption = 143.923344 pJ
sum error= 356
Actual label: 9
Output voltages: [0.24494, 0.014225, 0.01312, 0.27346, 0.3586, 0.011516, 0.0030215, 0.0087168, 0.41354, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 139.897173 pJ
sum error= 356
Actual label: 0
Output voltages: [0.79876, 0.019439, 0.5165, 0.0626, 0.032646, 0.0011042, 0.11677, 0.036756, 0.28877, 0.032598]
Predicted label: 0
Correct prediction
Energy consumption = 143.937277 pJ
sum error= 356
Actual label: 6
Output voltages: [0.1954, 0.018441, 0.63059, 0.0013045, 0.58096, 0.18043, 0.7979, 0.0055492, 0.065023, 0.0011021]
Predicted label: 6
Correct prediction
Energy consumption = 140.180329 pJ
sum error= 356
Actual label: 6
Output voltages: [0.0043201, 0.68513, 0.077253, 0.71194, 0.036579, 0.60257, 0.59066, 0.022384, 0.001665, 0.0010975]
Predicted label: 3
Wrong prediction!
Energy consumption = 137.683161 pJ
sum error= 357
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 968 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 968 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 968 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.051572, 0.0097585, 0.04747, 0.79874, 0.0092254, 0.0017848, 0.00728, 0.013116, 0.73633, 0.041917]
Predicted label: 3
Correct prediction
Energy consumption = 163.266235 pJ
sum error= 357
Actual label: 8
Output voltages: [0.040032, 0.023174, 0.076481, 0.46535, 0.0011902, 0.31971, 0.0051926, 0.0074213, 0.79869, 0.12459]
Predicted label: 8
Correct prediction
Energy consumption = 145.319585 pJ
sum error= 357
Actual label: 1
Output voltages: [0.017989, 0.79879, 0.44752, 0.22965, 0.089037, 0.0010803, 0.049537, 0.001689, 0.2281, 0.14515]
Predicted label: 1
Correct prediction
Energy consumption = 163.993899 pJ
sum error= 357
Actual label: 4
Output voltages: [0.0087362, 0.0067023, 0.024952, 0.056933, 0.79871, 0.0010715, 0.01146, 0.024934, 0.23305, 0.13374]
Predicted label: 4
Correct prediction
Energy consumption = 151.860781 pJ
sum error= 357
Actual label: 7
Output voltages: [0.74166, 0.017512, 0.0057573, 0.03994, 0.27765, 0.024824, 0.0010872, 0.79865, 0.041241, 0.021704]
Predicted label: 7
Correct prediction
Energy consumption = 146.815910 pJ
sum error= 357
Actual label: 5
Output voltages: [0.19897, 0.0010917, 0.0010661, 0.51692, 0.49828, 0.79873, 0.23501, 0.02168, 0.14033, 0.072984]
Predicted label: 5
Correct prediction
Energy consumption = 142.732642 pJ
sum error= 357
Actual label: 2
Output voltages: [0.41453, 0.3829, 0.79879, 0.64433, 0.018712, 0.0012538, 0.03075, 0.053338, 0.06345, 0.04301]
Predicted label: 2
Correct prediction
Energy consumption = 146.388713 pJ
sum error= 357
Actual label: 0
Output voltages: [0.79682, 0.38128, 0.068907, 0.22234, 0.0010785, 0.003668, 0.57489, 0.0037657, 0.46105, 0.033858]
Predicted label: 0
Correct prediction
Energy consumption = 156.653707 pJ
sum error= 357
Actual label: 0
Output voltages: [0.7987, 0.024392, 0.01336, 0.013428, 0.021314, 0.027336, 0.25245, 0.075504, 0.25446, 0.02566]
Predicted label: 0
Correct prediction
Energy consumption = 138.264525 pJ
sum error= 357
Actual label: 1
Output voltages: [0.013798, 0.79873, 0.16386, 0.021801, 0.74593, 0.0011489, 0.089957, 0.0088012, 0.023104, 0.33128]
Predicted label: 1
Correct prediction
Energy consumption = 154.397041 pJ
sum error= 357
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 969 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 969 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 969 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.62157, 0.017275, 0.023318, 0.068557, 0.01672, 0.0018512, 0.0010662, 0.79872, 0.11544, 0.13729]
Predicted label: 7
Correct prediction
Energy consumption = 169.923625 pJ
sum error= 357
Actual label: 8
Output voltages: [0.023709, 0.023155, 0.059829, 0.28456, 0.0015542, 0.11942, 0.0095263, 0.015298, 0.79868, 0.040487]
Predicted label: 8
Correct prediction
Energy consumption = 142.365902 pJ
sum error= 357
Actual label: 9
Output voltages: [0.25267, 0.041499, 0.035365, 0.46455, 0.027092, 0.0045359, 0.0011026, 0.7986, 0.59748, 0.57724]
Predicted label: 7
Wrong prediction!
Energy consumption = 160.104247 pJ
sum error= 358
Actual label: 6
Output voltages: [0.082512, 0.025043, 0.042857, 0.0062919, 0.012269, 0.32962, 0.79879, 0.011905, 0.76915, 0.011528]
Predicted label: 6
Correct prediction
Energy consumption = 142.632200 pJ
sum error= 358
Actual label: 8
Output voltages: [0.024742, 0.0029039, 0.34464, 0.34705, 0.0040794, 0.017312, 0.0011396, 0.013227, 0.79878, 0.023333]
Predicted label: 8
Correct prediction
Energy consumption = 143.380554 pJ
sum error= 358
Actual label: 8
Output voltages: [0.020953, 0.022335, 0.021176, 0.58196, 0.0012582, 0.041156, 0.0078997, 0.003567, 0.79879, 0.18212]
Predicted label: 8
Correct prediction
Energy consumption = 136.382232 pJ
sum error= 358
Actual label: 2
Output voltages: [0.14085, 0.2058, 0.79878, 0.15069, 0.0066356, 0.0012086, 0.021622, 0.040361, 0.34708, 0.041413]
Predicted label: 2
Correct prediction
Energy consumption = 146.716035 pJ
sum error= 358
Actual label: 3
Output voltages: [0.15703, 0.0081345, 0.035226, 0.79862, 0.047835, 0.018354, 0.036695, 0.06056, 0.7654, 0.022963]
Predicted label: 3
Correct prediction
Energy consumption = 132.068808 pJ
sum error= 358
Actual label: 6
Output voltages: [0.081213, 0.2415, 0.022909, 0.067161, 0.051399, 0.54535, 0.60039, 0.22636, 0.15008, 0.0014995]
Predicted label: 6
Correct prediction
Energy consumption = 142.839409 pJ
sum error= 358
Actual label: 1
Output voltages: [0.051744, 0.77065, 0.36688, 0.0012816, 0.72427, 0.0010788, 0.023121, 0.0054455, 0.28139, 0.054041]
Predicted label: 1
Correct prediction
Energy consumption = 160.803629 pJ
sum error= 358
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 970 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 970 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 970 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.0038499, 0.010214, 0.79836, 0.2234, 0.021315, 0.0011413, 0.10998, 0.56261, 0.60044, 0.040434]
Predicted label: 2
Correct prediction
Energy consumption = 156.423634 pJ
sum error= 358
Actual label: 9
Output voltages: [0.35254, 0.07622, 0.022911, 0.040093, 0.038454, 0.20304, 0.042257, 0.13679, 0.078034, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 161.291489 pJ
sum error= 358
Actual label: 5
Output voltages: [0.34072, 0.0010775, 0.0012201, 0.46988, 0.016293, 0.79864, 0.22836, 0.28313, 0.50533, 0.0050658]
Predicted label: 5
Correct prediction
Energy consumption = 142.428272 pJ
sum error= 358
Actual label: 2
Output voltages: [0.42392, 0.1582, 0.79873, 0.062166, 0.050928, 0.001172, 0.33706, 0.022753, 0.23691, 0.10529]
Predicted label: 2
Correct prediction
Energy consumption = 146.447923 pJ
sum error= 358
Actual label: 0
Output voltages: [0.79877, 0.047043, 0.023101, 0.017643, 0.095517, 0.0082589, 0.38776, 0.017436, 0.39443, 0.2595]
Predicted label: 0
Correct prediction
Energy consumption = 153.294145 pJ
sum error= 358
Actual label: 1
Output voltages: [0.0078192, 0.79857, 0.057757, 0.063088, 0.0099697, 0.0010849, 0.71195, 0.016303, 0.041836, 0.020113]
Predicted label: 1
Correct prediction
Energy consumption = 155.141809 pJ
sum error= 358
Actual label: 2
Output voltages: [0.19607, 0.12839, 0.79879, 0.59603, 0.0027218, 0.0011208, 0.29441, 0.043466, 0.038539, 0.0075672]
Predicted label: 2
Correct prediction
Energy consumption = 146.584893 pJ
sum error= 358
Actual label: 3
Output voltages: [0.37067, 0.0072006, 0.056416, 0.79865, 0.024712, 0.0052263, 0.018132, 0.01533, 0.64571, 0.023273]
Predicted label: 3
Correct prediction
Energy consumption = 137.883637 pJ
sum error= 358
Actual label: 4
Output voltages: [0.01818, 0.0082707, 0.06388, 0.0082863, 0.79872, 0.0039023, 0.2432, 0.02189, 0.10319, 0.0065533]
Predicted label: 4
Correct prediction
Energy consumption = 150.219811 pJ
sum error= 358
Actual label: 5
Output voltages: [0.24651, 0.011515, 0.0016772, 0.30665, 0.042908, 0.79879, 0.74663, 0.0041605, 0.68169, 0.0029888]
Predicted label: 5
Correct prediction
Energy consumption = 139.573751 pJ
sum error= 358
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 971 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 971 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 971 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.69468, 0.023622, 0.042174, 0.0010977, 0.51328, 0.12898, 0.79877, 0.0011338, 0.4162, 0.024591]
Predicted label: 6
Correct prediction
Energy consumption = 162.118110 pJ
sum error= 358
Actual label: 7
Output voltages: [0.26349, 0.0020809, 0.0094422, 0.020181, 0.7562, 0.0049649, 0.0012223, 0.79879, 0.12548, 0.047741]
Predicted label: 7
Correct prediction
Energy consumption = 159.773040 pJ
sum error= 358
Actual label: 8
Output voltages: [0.052257, 0.048645, 0.19333, 0.059466, 0.007713, 0.29445, 0.058428, 0.0045363, 0.79873, 0.019811]
Predicted label: 8
Correct prediction
Energy consumption = 150.161409 pJ
sum error= 358
Actual label: 9
Output voltages: [0.18104, 0.015195, 0.028892, 0.027891, 0.047798, 0.009178, 0.011751, 0.030499, 0.7129, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 134.899487 pJ
sum error= 358
Actual label: 0
Output voltages: [0.79706, 0.080796, 0.0037116, 0.024218, 0.0050755, 0.024495, 0.73714, 0.022926, 0.22362, 0.054033]
Predicted label: 0
Correct prediction
Energy consumption = 146.578646 pJ
sum error= 358
Actual label: 1
Output voltages: [0.01643, 0.79822, 0.1312, 0.1315, 0.34113, 0.0011842, 0.12189, 0.029872, 0.053252, 0.17741]
Predicted label: 1
Correct prediction
Energy consumption = 157.125317 pJ
sum error= 358
Actual label: 2
Output voltages: [0.79837, 0.28561, 0.78282, 0.60916, 0.0046208, 0.015006, 0.071941, 0.037481, 0.0032941, 0.020979]
Predicted label: 0
Wrong prediction!
Energy consumption = 155.974802 pJ
sum error= 359
Actual label: 3
Output voltages: [0.151, 0.020205, 0.059, 0.79862, 0.01289, 0.031685, 0.01566, 0.009783, 0.74455, 0.032075]
Predicted label: 3
Correct prediction
Energy consumption = 147.149044 pJ
sum error= 359
Actual label: 4
Output voltages: [0.0024598, 0.0030084, 0.044516, 0.0091612, 0.79867, 0.0015051, 0.60694, 0.28917, 0.27635, 0.016678]
Predicted label: 4
Correct prediction
Energy consumption = 152.011327 pJ
sum error= 359
Actual label: 5
Output voltages: [0.68359, 0.020645, 0.0015478, 0.6468, 0.0014921, 0.78311, 0.4646, 0.0018323, 0.47834, 0.0023182]
Predicted label: 5
Correct prediction
Energy consumption = 150.628695 pJ
sum error= 359
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 972 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 972 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 972 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.054237, 0.0013045, 0.011231, 0.037351, 0.10735, 0.72423, 0.78583, 0.0010675, 0.75094, 0.039674]
Predicted label: 6
Correct prediction
Energy consumption = 158.113684 pJ
sum error= 359
Actual label: 7
Output voltages: [0.040709, 0.039727, 0.028934, 0.29734, 0.0037942, 0.016859, 0.0011433, 0.79874, 0.24564, 0.64625]
Predicted label: 7
Correct prediction
Energy consumption = 152.930065 pJ
sum error= 359
Actual label: 8
Output voltages: [0.038375, 0.038549, 0.017693, 0.14307, 0.015664, 0.21238, 0.27019, 0.0035741, 0.79875, 0.017289]
Predicted label: 8
Correct prediction
Energy consumption = 151.207696 pJ
sum error= 359
Actual label: 9
Output voltages: [0.55369, 0.0033608, 0.027265, 0.01574, 0.2758, 0.012543, 0.0027117, 0.032334, 0.5513, 0.79854]
Predicted label: 9
Correct prediction
Energy consumption = 139.883217 pJ
sum error= 359
Actual label: 0
Output voltages: [0.79866, 0.051221, 0.037719, 0.018896, 0.021241, 0.033333, 0.42075, 0.060058, 0.062899, 0.022164]
Predicted label: 0
Correct prediction
Energy consumption = 136.063151 pJ
sum error= 359
Actual label: 1
Output voltages: [0.059194, 0.79879, 0.036202, 0.0016516, 0.24632, 0.0011503, 0.20418, 0.032287, 0.15825, 0.001299]
Predicted label: 1
Correct prediction
Energy consumption = 151.695849 pJ
sum error= 359
Actual label: 2
Output voltages: [0.48007, 0.32813, 0.79879, 0.17022, 0.0016271, 0.0012304, 0.39988, 0.016731, 0.13277, 0.023319]
Predicted label: 2
Correct prediction
Energy consumption = 141.382471 pJ
sum error= 359
Actual label: 3
Output voltages: [0.23124, 0.0097944, 0.032381, 0.79871, 0.023964, 0.17889, 0.0022619, 0.019659, 0.71695, 0.021046]
Predicted label: 3
Correct prediction
Energy consumption = 140.479600 pJ
sum error= 359
Actual label: 4
Output voltages: [0.01807, 0.035589, 0.065812, 0.0046251, 0.79865, 0.0018415, 0.1009, 0.031613, 0.022431, 0.03121]
Predicted label: 4
Correct prediction
Energy consumption = 147.835772 pJ
sum error= 359
Actual label: 5
Output voltages: [0.68758, 0.024144, 0.0027692, 0.018008, 0.37112, 0.79114, 0.79632, 0.0017825, 0.03488, 0.023034]
Predicted label: 6
Wrong prediction!
Energy consumption = 139.396533 pJ
sum error= 360
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 973 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 973 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 973 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.15534, 0.003467, 0.027428, 0.011374, 0.27803, 0.47704, 0.79858, 0.0011159, 0.76241, 0.015508]
Predicted label: 6
Correct prediction
Energy consumption = 160.206490 pJ
sum error= 360
Actual label: 7
Output voltages: [0.066351, 0.054727, 0.311, 0.0090043, 0.24732, 0.001148, 0.0012016, 0.79879, 0.29397, 0.11451]
Predicted label: 7
Correct prediction
Energy consumption = 146.105267 pJ
sum error= 360
Actual label: 8
Output voltages: [0.034327, 0.0036295, 0.024085, 0.3286, 0.0010847, 0.51002, 0.082524, 0.0095694, 0.79876, 0.048596]
Predicted label: 8
Correct prediction
Energy consumption = 147.530951 pJ
sum error= 360
Actual label: 9
Output voltages: [0.26654, 0.0012881, 0.025477, 0.0075449, 0.011657, 0.0091679, 0.0010967, 0.04559, 0.79547, 0.77876]
Predicted label: 8
Wrong prediction!
Energy consumption = 139.851482 pJ
sum error= 361
Actual label: 7
Output voltages: [0.44762, 0.073486, 0.016818, 0.085176, 0.18916, 0.017252, 0.00152, 0.79879, 0.059345, 0.44063]
Predicted label: 7
Correct prediction
Energy consumption = 151.876601 pJ
sum error= 361
Actual label: 4
Output voltages: [0.0077708, 0.11052, 0.027926, 0.084269, 0.79879, 0.0010669, 0.049942, 0.052233, 0.036179, 0.12577]
Predicted label: 4
Correct prediction
Energy consumption = 142.353324 pJ
sum error= 361
Actual label: 6
Output voltages: [0.23779, 0.0016168, 0.0090812, 0.053796, 0.11417, 0.77869, 0.78332, 0.0011099, 0.65003, 0.057148]
Predicted label: 6
Correct prediction
Energy consumption = 140.197448 pJ
sum error= 361
Actual label: 1
Output voltages: [0.0091509, 0.79862, 0.16404, 0.030681, 0.23196, 0.012017, 0.61146, 0.02721, 0.077923, 0.07021]
Predicted label: 1
Correct prediction
Energy consumption = 158.308312 pJ
sum error= 361
Actual label: 4
Output voltages: [0.11378, 0.10901, 0.02828, 0.056255, 0.79466, 0.0011918, 0.0062718, 0.022012, 0.19764, 0.043115]
Predicted label: 4
Correct prediction
Energy consumption = 145.758527 pJ
sum error= 361
Actual label: 0
Output voltages: [0.79878, 0.01679, 0.079331, 0.0063088, 0.011721, 0.0028983, 0.060948, 0.02685, 0.43011, 0.03076]
Predicted label: 0
Correct prediction
Energy consumption = 148.170698 pJ
sum error= 361
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 974 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 974 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 974 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.32271, 0.021821, 0.021319, 0.030299, 0.16585, 0.028388, 0.0036171, 0.016687, 0.59445, 0.79805]
Predicted label: 9
Correct prediction
Energy consumption = 158.186989 pJ
sum error= 361
Actual label: 9
Output voltages: [0.71945, 0.01937, 0.0015663, 0.039543, 0.46216, 0.0038216, 0.0058133, 0.031317, 0.046922, 0.78429]
Predicted label: 9
Correct prediction
Energy consumption = 139.019637 pJ
sum error= 361
Actual label: 3
Output voltages: [0.20754, 0.012639, 0.19973, 0.79873, 0.00464, 0.049872, 0.0031928, 0.017567, 0.69173, 0.026493]
Predicted label: 3
Correct prediction
Energy consumption = 145.989488 pJ
sum error= 361
Actual label: 7
Output voltages: [0.015181, 0.083394, 0.074916, 0.038095, 0.19847, 0.0011195, 0.0010916, 0.79866, 0.18793, 0.027398]
Predicted label: 7
Correct prediction
Energy consumption = 144.949876 pJ
sum error= 361
Actual label: 8
Output voltages: [0.0061283, 0.29724, 0.080642, 0.033547, 0.042946, 0.021904, 0.62152, 0.010508, 0.79618, 0.096673]
Predicted label: 8
Correct prediction
Energy consumption = 148.735511 pJ
sum error= 361
Actual label: 4
Output voltages: [0.29915, 0.029224, 0.75041, 0.0070711, 0.78502, 0.0014647, 0.12404, 0.01671, 0.079512, 0.050545]
Predicted label: 4
Correct prediction
Energy consumption = 145.508742 pJ
sum error= 361
Actual label: 7
Output voltages: [0.25231, 0.044815, 0.15318, 0.051331, 0.065289, 0.013306, 0.0010753, 0.79861, 0.031936, 0.40265]
Predicted label: 7
Correct prediction
Energy consumption = 148.148200 pJ
sum error= 361
Actual label: 5
Output voltages: [0.42141, 0.023938, 0.0072141, 0.38544, 0.0084061, 0.79568, 0.74284, 0.0069636, 0.03946, 0.16691]
Predicted label: 5
Correct prediction
Energy consumption = 139.524239 pJ
sum error= 361
Actual label: 8
Output voltages: [0.45775, 0.0019177, 0.031141, 0.17065, 0.045836, 0.28396, 0.27287, 0.0048666, 0.7987, 0.002856]
Predicted label: 8
Correct prediction
Energy consumption = 143.545879 pJ
sum error= 361
Actual label: 5
Output voltages: [0.2471, 0.0017963, 0.0027584, 0.34591, 0.047942, 0.79875, 0.76451, 0.0050606, 0.50138, 0.013584]
Predicted label: 5
Correct prediction
Energy consumption = 138.183507 pJ
sum error= 361
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 975 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 975 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 975 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.050382, 0.014681, 0.17538, 0.79867, 0.015838, 0.036593, 0.0076558, 0.0182, 0.61518, 0.041864]
Predicted label: 3
Correct prediction
Energy consumption = 167.018857 pJ
sum error= 361
Actual label: 2
Output voltages: [0.62203, 0.16568, 0.79879, 0.2649, 0.012357, 0.001101, 0.31698, 0.018641, 0.2927, 0.13035]
Predicted label: 2
Correct prediction
Energy consumption = 148.897077 pJ
sum error= 361
Actual label: 2
Output voltages: [0.30974, 0.042647, 0.79879, 0.22908, 0.042696, 0.001085, 0.29775, 0.0027401, 0.21583, 0.054803]
Predicted label: 2
Correct prediction
Energy consumption = 140.546296 pJ
sum error= 361
Actual label: 0
Output voltages: [0.7987, 0.043532, 0.016223, 0.010051, 0.013811, 0.018842, 0.42116, 0.060413, 0.27963, 0.036491]
Predicted label: 0
Correct prediction
Energy consumption = 139.647995 pJ
sum error= 361
Actual label: 5
Output voltages: [0.47224, 0.032339, 0.0030842, 0.051536, 0.06692, 0.76113, 0.79165, 0.0010659, 0.042622, 0.0055395]
Predicted label: 6
Wrong prediction!
Energy consumption = 142.205395 pJ
sum error= 362
Actual label: 8
Output voltages: [0.184, 0.011331, 0.028578, 0.03236, 0.0050806, 0.74907, 0.28826, 0.017853, 0.79857, 0.0010695]
Predicted label: 8
Correct prediction
Energy consumption = 144.806934 pJ
sum error= 362
Actual label: 6
Output voltages: [0.10632, 0.013372, 0.47733, 0.0025067, 0.084061, 0.063237, 0.79866, 0.0011621, 0.7118, 0.037798]
Predicted label: 6
Correct prediction
Energy consumption = 133.795160 pJ
sum error= 362
Actual label: 0
Output voltages: [0.79879, 0.024001, 0.074303, 0.015239, 0.047217, 0.0027386, 0.10525, 0.011137, 0.46666, 0.034513]
Predicted label: 0
Correct prediction
Energy consumption = 148.703525 pJ
sum error= 362
Actual label: 3
Output voltages: [0.66664, 0.0053917, 0.052461, 0.79868, 0.033651, 0.43852, 0.0017206, 0.022088, 0.49423, 0.030128]
Predicted label: 3
Correct prediction
Energy consumption = 145.888294 pJ
sum error= 362
Actual label: 8
Output voltages: [0.011685, 0.023096, 0.095558, 0.33009, 0.0017781, 0.19827, 0.013486, 0.0069652, 0.79872, 0.16613]
Predicted label: 8
Correct prediction
Energy consumption = 146.355568 pJ
sum error= 362
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 976 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 976 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 976 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.010407, 0.79859, 0.0022994, 0.019796, 0.46355, 0.0095864, 0.69363, 0.020935, 0.024013, 0.1568]
Predicted label: 1
Correct prediction
Energy consumption = 171.578374 pJ
sum error= 362
Actual label: 0
Output voltages: [0.79879, 0.067616, 0.082105, 0.010927, 0.012236, 0.0059869, 0.56174, 0.16613, 0.38881, 0.031702]
Predicted label: 0
Correct prediction
Energy consumption = 147.842264 pJ
sum error= 362
Actual label: 3
Output voltages: [0.36784, 0.0016564, 0.36791, 0.79829, 0.045364, 0.027016, 0.010977, 0.0098241, 0.79148, 0.056931]
Predicted label: 3
Correct prediction
Energy consumption = 156.259257 pJ
sum error= 362
Actual label: 0
Output voltages: [0.79879, 0.061222, 0.023395, 0.049716, 0.026094, 0.0097105, 0.57687, 0.051379, 0.28136, 0.023789]
Predicted label: 0
Correct prediction
Energy consumption = 144.535520 pJ
sum error= 362
Actual label: 4
Output voltages: [0.062999, 0.048333, 0.028749, 0.03584, 0.79879, 0.0011273, 0.019038, 0.0048356, 0.050828, 0.043203]
Predicted label: 4
Correct prediction
Energy consumption = 149.113825 pJ
sum error= 362
Actual label: 7
Output voltages: [0.2197, 0.056971, 0.0184, 0.16905, 0.053863, 0.0094016, 0.00141, 0.79877, 0.11399, 0.527]
Predicted label: 7
Correct prediction
Energy consumption = 152.540021 pJ
sum error= 362
Actual label: 4
Output voltages: [0.033898, 0.021258, 0.034285, 0.02102, 0.79868, 0.0011254, 0.037166, 0.030183, 0.086883, 0.084817]
Predicted label: 4
Correct prediction
Energy consumption = 140.211017 pJ
sum error= 362
Actual label: 9
Output voltages: [0.16396, 0.011398, 0.031783, 0.031874, 0.14477, 0.0076916, 0.010148, 0.011185, 0.49247, 0.79703]
Predicted label: 9
Correct prediction
Energy consumption = 139.241800 pJ
sum error= 362
Actual label: 2
Output voltages: [0.78852, 0.0017436, 0.61312, 0.027079, 0.016495, 0.001117, 0.0068449, 0.046678, 0.75888, 0.036431]
Predicted label: 0
Wrong prediction!
Energy consumption = 142.530154 pJ
sum error= 363
Actual label: 9
Output voltages: [0.25997, 0.0097903, 0.0034635, 0.013227, 0.050299, 0.0069702, 0.0015398, 0.0065536, 0.56451, 0.79859]
Predicted label: 9
Correct prediction
Energy consumption = 144.081526 pJ
sum error= 363
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 977 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 977 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 977 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.79508, 0.022907, 0.017248, 0.018111, 0.025463, 0.3497, 0.7667, 0.19651, 0.022925, 0.0075256]
Predicted label: 0
Wrong prediction!
Energy consumption = 162.231814 pJ
sum error= 364
Actual label: 7
Output voltages: [0.31591, 0.023793, 0.012843, 0.27394, 0.11304, 0.018403, 0.0014465, 0.79875, 0.06091, 0.43699]
Predicted label: 7
Correct prediction
Energy consumption = 150.336494 pJ
sum error= 364
Actual label: 1
Output voltages: [0.01095, 0.79868, 0.27489, 0.0099012, 0.039278, 0.0026776, 0.62659, 0.0013121, 0.43122, 0.016522]
Predicted label: 1
Correct prediction
Energy consumption = 152.417709 pJ
sum error= 364
Actual label: 7
Output voltages: [0.20659, 0.12438, 0.16642, 0.025074, 0.37778, 0.00107, 0.0010689, 0.79871, 0.048251, 0.034085]
Predicted label: 7
Correct prediction
Energy consumption = 145.251553 pJ
sum error= 364
Actual label: 1
Output voltages: [0.019894, 0.79875, 0.33613, 0.019724, 0.6675, 0.0011098, 0.316, 0.012805, 0.029278, 0.0070621]
Predicted label: 1
Correct prediction
Energy consumption = 150.229457 pJ
sum error= 364
Actual label: 6
Output voltages: [0.31518, 0.027235, 0.071272, 0.0030495, 0.47583, 0.059861, 0.79877, 0.0010717, 0.75305, 0.0064996]
Predicted label: 6
Correct prediction
Energy consumption = 140.161199 pJ
sum error= 364
Actual label: 6
Output voltages: [0.094203, 0.0058293, 0.1325, 0.03235, 0.055069, 0.47251, 0.79879, 0.0011552, 0.36404, 0.10565]
Predicted label: 6
Correct prediction
Energy consumption = 127.552388 pJ
sum error= 364
Actual label: 5
Output voltages: [0.76586, 0.0033126, 0.0010696, 0.071029, 0.12082, 0.79708, 0.52755, 0.0064176, 0.056648, 0.0044573]
Predicted label: 5
Correct prediction
Energy consumption = 130.785867 pJ
sum error= 364
Actual label: 6
Output voltages: [0.44976, 0.009172, 0.038815, 0.065475, 0.050402, 0.7565, 0.79816, 0.0013246, 0.62069, 0.043242]
Predicted label: 6
Correct prediction
Energy consumption = 142.862012 pJ
sum error= 364
Actual label: 2
Output voltages: [0.78942, 0.0010795, 0.69872, 0.35669, 0.0010736, 0.0027548, 0.0031126, 0.30715, 0.65672, 0.02563]
Predicted label: 0
Wrong prediction!
Energy consumption = 147.842513 pJ
sum error= 365
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 978 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 978 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 978 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.50305, 0.0084748, 0.11714, 0.024009, 0.0030459, 0.26176, 0.0012586, 0.053333, 0.79876, 0.0028521]
Predicted label: 8
Correct prediction
Energy consumption = 163.752434 pJ
sum error= 365
Actual label: 7
Output voltages: [0.15488, 0.0075658, 0.063176, 0.0010659, 0.33028, 0.011266, 0.0010817, 0.79184, 0.38078, 0.24941]
Predicted label: 7
Correct prediction
Energy consumption = 138.780818 pJ
sum error= 365
Actual label: 6
Output voltages: [0.26688, 0.0011346, 0.11351, 0.01413, 0.22639, 0.58211, 0.79628, 0.0010668, 0.64038, 0.041325]
Predicted label: 6
Correct prediction
Energy consumption = 143.707636 pJ
sum error= 365
Actual label: 4
Output voltages: [0.019017, 0.10481, 0.096761, 0.12648, 0.79879, 0.0011141, 0.026938, 0.096102, 0.00811, 0.040869]
Predicted label: 4
Correct prediction
Energy consumption = 148.901895 pJ
sum error= 365
Actual label: 9
Output voltages: [0.34838, 0.01253, 0.012065, 0.071075, 0.37943, 0.0052365, 0.003612, 0.0099694, 0.28601, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 146.585490 pJ
sum error= 365
Actual label: 9
Output voltages: [0.23444, 0.028221, 0.01506, 0.07443, 0.33456, 0.0096522, 0.0022329, 0.0028454, 0.34374, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 140.359019 pJ
sum error= 365
Actual label: 5
Output voltages: [0.2462, 0.025903, 0.0010675, 0.28023, 0.024571, 0.7987, 0.41774, 0.0024288, 0.32542, 0.02339]
Predicted label: 5
Correct prediction
Energy consumption = 145.438909 pJ
sum error= 365
Actual label: 3
Output voltages: [0.23575, 0.014648, 0.040052, 0.79866, 0.01, 0.031132, 0.0038966, 0.0070073, 0.65798, 0.03373]
Predicted label: 3
Correct prediction
Energy consumption = 144.989213 pJ
sum error= 365
Actual label: 7
Output voltages: [0.063965, 0.058097, 0.19813, 0.0155, 0.017201, 0.0010761, 0.0011354, 0.79863, 0.042369, 0.21552]
Predicted label: 7
Correct prediction
Energy consumption = 138.429851 pJ
sum error= 365
Actual label: 4
Output voltages: [0.048666, 0.03656, 0.29254, 0.029597, 0.79867, 0.001103, 0.048321, 0.011567, 0.027138, 0.044971]
Predicted label: 4
Correct prediction
Energy consumption = 142.647008 pJ
sum error= 365
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 979 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 979 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 979 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.77916, 0.045264, 0.023825, 0.79872, 0.006822, 0.038017, 0.0016094, 0.37241, 0.26406, 0.019401]
Predicted label: 3
Correct prediction
Energy consumption = 167.771983 pJ
sum error= 365
Actual label: 0
Output voltages: [0.79879, 0.37621, 0.12876, 0.0031851, 0.016764, 0.0030803, 0.21545, 0.02783, 0.19575, 0.03979]
Predicted label: 0
Correct prediction
Energy consumption = 151.430277 pJ
sum error= 365
Actual label: 4
Output voltages: [0.43652, 0.31415, 0.038621, 0.09699, 0.77344, 0.0012472, 0.0071594, 0.048049, 0.0028039, 0.73407]
Predicted label: 4
Correct prediction
Energy consumption = 149.876627 pJ
sum error= 365
Actual label: 6
Output voltages: [0.029813, 0.0041002, 0.021463, 0.016241, 0.14612, 0.69928, 0.79815, 0.0046895, 0.78379, 0.0046766]
Predicted label: 6
Correct prediction
Energy consumption = 146.980326 pJ
sum error= 365
Actual label: 6
Output voltages: [0.10329, 0.021663, 0.41363, 0.0011354, 0.26183, 0.21526, 0.79874, 0.0011129, 0.52389, 0.030356]
Predicted label: 6
Correct prediction
Energy consumption = 134.805986 pJ
sum error= 365
Actual label: 1
Output voltages: [0.022828, 0.79878, 0.37164, 0.019419, 0.13614, 0.0052735, 0.55909, 0.0013588, 0.42168, 0.0021908]
Predicted label: 1
Correct prediction
Energy consumption = 148.612351 pJ
sum error= 365
Actual label: 1
Output voltages: [0.083888, 0.79862, 0.32736, 0.0026492, 0.67193, 0.0017987, 0.49764, 0.0010678, 0.12576, 0.031745]
Predicted label: 1
Correct prediction
Energy consumption = 136.831788 pJ
sum error= 365
Actual label: 3
Output voltages: [0.41656, 0.026803, 0.041438, 0.79875, 0.0069606, 0.041977, 0.011231, 0.0058744, 0.76412, 0.022778]
Predicted label: 3
Correct prediction
Energy consumption = 153.278729 pJ
sum error= 365
Actual label: 2
Output voltages: [0.13979, 0.048936, 0.79868, 0.072048, 0.030226, 0.0011262, 0.065114, 0.043417, 0.40246, 0.034766]
Predicted label: 2
Correct prediction
Energy consumption = 141.522676 pJ
sum error= 365
Actual label: 1
Output voltages: [0.042472, 0.79876, 0.20682, 0.0017625, 0.076812, 0.0027542, 0.31039, 0.001105, 0.0885, 0.010424]
Predicted label: 1
Correct prediction
Energy consumption = 140.932819 pJ
sum error= 365
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 980 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 980 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 980 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7769, 0.028516, 0.041267, 0.004707, 0.014197, 0.0091676, 0.73276, 0.34174, 0.032416, 0.59844]
Predicted label: 0
Correct prediction
Energy consumption = 161.928747 pJ
sum error= 365
Actual label: 0
Output voltages: [0.79879, 0.060726, 0.031049, 0.020526, 0.040889, 0.014169, 0.49747, 0.0034712, 0.095211, 0.27441]
Predicted label: 0
Correct prediction
Energy consumption = 143.427450 pJ
sum error= 365
Actual label: 1
Output voltages: [0.009312, 0.79855, 0.31586, 0.010284, 0.1052, 0.017217, 0.6391, 0.0015614, 0.27895, 0.016029]
Predicted label: 1
Correct prediction
Energy consumption = 158.935339 pJ
sum error= 365
Actual label: 2
Output voltages: [0.25092, 0.0011134, 0.79835, 0.079608, 0.012082, 0.0011902, 0.041586, 0.14214, 0.77454, 0.0053333]
Predicted label: 2
Correct prediction
Energy consumption = 147.736787 pJ
sum error= 365
Actual label: 3
Output voltages: [0.042948, 0.0023178, 0.064821, 0.79876, 0.029943, 0.065842, 0.024066, 0.0053311, 0.48974, 0.047173]
Predicted label: 3
Correct prediction
Energy consumption = 146.675724 pJ
sum error= 365
Actual label: 4
Output voltages: [0.0094918, 0.029584, 0.051543, 0.014729, 0.79875, 0.0018192, 0.26216, 0.087403, 0.019358, 0.0062828]
Predicted label: 4
Correct prediction
Energy consumption = 154.437176 pJ
sum error= 365
Actual label: 7
Output voltages: [0.051819, 0.0098001, 0.02508, 0.019428, 0.024985, 0.004635, 0.0010664, 0.79866, 0.29765, 0.48344]
Predicted label: 7
Correct prediction
Energy consumption = 154.953591 pJ
sum error= 365
Actual label: 8
Output voltages: [0.03346, 0.15227, 0.099166, 0.25663, 0.01775, 0.006885, 0.026541, 0.0019855, 0.79868, 0.23551]
Predicted label: 8
Correct prediction
Energy consumption = 145.066813 pJ
sum error= 365
Actual label: 9
Output voltages: [0.33675, 0.022112, 0.0047036, 0.0291, 0.75798, 0.0067209, 0.0025582, 0.57627, 0.13988, 0.74961]
Predicted label: 4
Wrong prediction!
Energy consumption = 152.021895 pJ
sum error= 366
Actual label: 0
Output voltages: [0.79873, 0.092063, 0.025134, 0.026675, 0.017721, 0.019906, 0.19934, 0.011278, 0.36586, 0.081895]
Predicted label: 0
Correct prediction
Energy consumption = 150.516485 pJ
sum error= 366
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 981 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 981 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 981 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23055, 0.79867, 0.16215, 0.010016, 0.19784, 0.0056647, 0.27239, 0.0020435, 0.043138, 0.03378]
Predicted label: 1
Correct prediction
Energy consumption = 180.599030 pJ
sum error= 366
Actual label: 2
Output voltages: [0.032319, 0.019851, 0.79867, 0.086535, 0.0010874, 0.0011158, 0.010976, 0.58721, 0.73911, 0.0083228]
Predicted label: 2
Correct prediction
Energy consumption = 143.623987 pJ
sum error= 366
Actual label: 3
Output voltages: [0.071861, 0.022566, 0.059215, 0.79874, 0.040138, 0.36562, 0.038197, 0.017052, 0.49029, 0.018206]
Predicted label: 3
Correct prediction
Energy consumption = 149.487367 pJ
sum error= 366
Actual label: 4
Output voltages: [0.0029185, 0.037374, 0.037283, 0.0056657, 0.79877, 0.0011435, 0.49474, 0.095991, 0.0042855, 0.023518]
Predicted label: 4
Correct prediction
Energy consumption = 151.532048 pJ
sum error= 366
Actual label: 5
Output voltages: [0.063419, 0.062639, 0.011581, 0.038943, 0.0021907, 0.79873, 0.11528, 0.015285, 0.7985, 0.014092]
Predicted label: 5
Correct prediction
Energy consumption = 164.238615 pJ
sum error= 366
Actual label: 6
Output voltages: [0.25079, 0.0056959, 0.0052542, 0.038163, 0.041175, 0.78477, 0.79784, 0.0015844, 0.47535, 0.046995]
Predicted label: 6
Correct prediction
Energy consumption = 145.765796 pJ
sum error= 366
Actual label: 7
Output voltages: [0.42342, 0.025674, 0.37639, 0.044932, 0.012098, 0.0011615, 0.0011432, 0.79861, 0.044856, 0.039306]
Predicted label: 7
Correct prediction
Energy consumption = 156.596110 pJ
sum error= 366
Actual label: 8
Output voltages: [0.19874, 0.047045, 0.10036, 0.37231, 0.018964, 0.017588, 0.027659, 0.0010907, 0.79761, 0.067624]
Predicted label: 8
Correct prediction
Energy consumption = 154.011813 pJ
sum error= 366
Actual label: 0
Output voltages: [0.79879, 0.016507, 0.027495, 0.0057655, 0.016343, 0.010133, 0.10635, 0.030366, 0.57631, 0.030449]
Predicted label: 0
Correct prediction
Energy consumption = 143.585547 pJ
sum error= 366
Actual label: 1
Output voltages: [0.0019197, 0.79879, 0.025093, 0.0085363, 0.17738, 0.0012166, 0.086033, 0.0099657, 0.52891, 0.052889]
Predicted label: 1
Correct prediction
Energy consumption = 150.182670 pJ
sum error= 366
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 982 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 982 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 982 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.43634, 0.042148, 0.79878, 0.25795, 0.021668, 0.0011824, 0.45088, 0.015448, 0.72907, 0.096302]
Predicted label: 2
Correct prediction
Energy consumption = 166.914949 pJ
sum error= 366
Actual label: 3
Output voltages: [0.73981, 0.020155, 0.10916, 0.79876, 0.011479, 0.021451, 0.0032177, 0.0086974, 0.50474, 0.010307]
Predicted label: 3
Correct prediction
Energy consumption = 139.063824 pJ
sum error= 366
Actual label: 4
Output voltages: [0.0046515, 0.057831, 0.025765, 0.038154, 0.79875, 0.0019614, 0.26828, 0.44913, 0.023641, 0.0032102]
Predicted label: 4
Correct prediction
Energy consumption = 154.891521 pJ
sum error= 366
Actual label: 7
Output voltages: [0.28246, 0.15639, 0.46943, 0.47429, 0.0014688, 0.0010868, 0.0010723, 0.7976, 0.080724, 0.37829]
Predicted label: 7
Correct prediction
Energy consumption = 152.395109 pJ
sum error= 366
Actual label: 8
Output voltages: [0.058318, 0.016808, 0.026247, 0.68449, 0.0015369, 0.10952, 0.22998, 0.0025532, 0.79878, 0.082106]
Predicted label: 8
Correct prediction
Energy consumption = 155.484262 pJ
sum error= 366
Actual label: 9
Output voltages: [0.078126, 0.013994, 0.028091, 0.3457, 0.049212, 0.00274, 0.0015738, 0.14435, 0.46308, 0.79796]
Predicted label: 9
Correct prediction
Energy consumption = 148.393620 pJ
sum error= 366
Actual label: 0
Output voltages: [0.78902, 0.036778, 0.14689, 0.032431, 0.0064702, 0.0011071, 0.67153, 0.015413, 0.28501, 0.069995]
Predicted label: 0
Correct prediction
Energy consumption = 157.076442 pJ
sum error= 366
Actual label: 8
Output voltages: [0.012676, 0.12518, 0.032652, 0.28824, 0.0065283, 0.004084, 0.3253, 0.012045, 0.79878, 0.20552]
Predicted label: 8
Correct prediction
Energy consumption = 153.831370 pJ
sum error= 366
Actual label: 3
Output voltages: [0.050436, 0.022908, 0.36452, 0.7986, 0.013318, 0.044049, 0.0088459, 0.001798, 0.59889, 0.046213]
Predicted label: 3
Correct prediction
Energy consumption = 158.385392 pJ
sum error= 366
Actual label: 9
Output voltages: [0.51092, 0.011044, 0.019074, 0.040008, 0.50105, 0.0081764, 0.009518, 0.004044, 0.22248, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 145.111047 pJ
sum error= 366
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 983 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 983 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 983 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.02959, 0.023966, 0.001563, 0.047166, 0.01343, 0.79869, 0.22778, 0.023529, 0.75428, 0.022417]
Predicted label: 5
Correct prediction
Energy consumption = 172.835189 pJ
sum error= 366
Actual label: 5
Output voltages: [0.026409, 0.48996, 0.0010835, 0.74119, 0.0092142, 0.79871, 0.20745, 0.02986, 0.7255, 0.0064617]
Predicted label: 5
Correct prediction
Energy consumption = 148.370506 pJ
sum error= 366
Actual label: 2
Output voltages: [0.37832, 0.10021, 0.79861, 0.12715, 0.0088065, 0.0013899, 0.29955, 0.23525, 0.59455, 0.014395]
Predicted label: 2
Correct prediction
Energy consumption = 150.213571 pJ
sum error= 366
Actual label: 6
Output voltages: [0.034166, 0.051027, 0.11094, 0.0027267, 0.2642, 0.19121, 0.79879, 0.0019748, 0.76175, 0.004843]
Predicted label: 6
Correct prediction
Energy consumption = 146.966219 pJ
sum error= 366
Actual label: 8
Output voltages: [0.049205, 0.032082, 0.17233, 0.19455, 0.001147, 0.1197, 0.50108, 0.0051496, 0.79865, 0.040023]
Predicted label: 8
Correct prediction
Energy consumption = 148.537448 pJ
sum error= 366
Actual label: 4
Output voltages: [0.017214, 0.027053, 0.099676, 0.0026269, 0.79876, 0.0011398, 0.28985, 0.033166, 0.29828, 0.0092137]
Predicted label: 4
Correct prediction
Energy consumption = 150.117879 pJ
sum error= 366
Actual label: 1
Output voltages: [0.016345, 0.79874, 0.013405, 0.0078982, 0.667, 0.017388, 0.44972, 0.002088, 0.24394, 0.18132]
Predicted label: 1
Correct prediction
Energy consumption = 155.911044 pJ
sum error= 366
Actual label: 7
Output voltages: [0.11415, 0.029849, 0.27046, 0.046625, 0.0043895, 0.0012432, 0.001191, 0.79876, 0.34187, 0.23928]
Predicted label: 7
Correct prediction
Energy consumption = 158.809889 pJ
sum error= 366
Actual label: 1
Output voltages: [0.14061, 0.79876, 0.0011081, 0.027542, 0.72118, 0.0078893, 0.065087, 0.0010847, 0.2564, 0.51118]
Predicted label: 1
Correct prediction
Energy consumption = 161.215865 pJ
sum error= 366
Actual label: 2
Output voltages: [0.36755, 0.15312, 0.79145, 0.28322, 0.0011608, 0.001168, 0.023245, 0.65134, 0.6157, 0.037514]
Predicted label: 2
Correct prediction
Energy consumption = 148.051621 pJ
sum error= 366
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 984 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 984 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 984 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.45894, 0.0050753, 0.19469, 0.79878, 0.039318, 0.065875, 0.010018, 0.0052854, 0.53282, 0.029128]
Predicted label: 3
Correct prediction
Energy consumption = 167.443300 pJ
sum error= 366
Actual label: 5
Output voltages: [0.15265, 0.066089, 0.001071, 0.34958, 0.021993, 0.79859, 0.6614, 0.0095973, 0.34841, 0.0047474]
Predicted label: 5
Correct prediction
Energy consumption = 153.133542 pJ
sum error= 366
Actual label: 6
Output voltages: [0.17196, 0.011376, 0.047259, 0.0034124, 0.31024, 0.063927, 0.79855, 0.0010755, 0.6344, 0.002739]
Predicted label: 6
Correct prediction
Energy consumption = 137.128410 pJ
sum error= 366
Actual label: 9
Output voltages: [0.19249, 0.0075189, 0.015607, 0.30765, 0.20253, 0.0012706, 0.010959, 0.0362, 0.32032, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 144.353770 pJ
sum error= 366
Actual label: 1
Output voltages: [0.036458, 0.7984, 0.027346, 0.051545, 0.049506, 0.0030957, 0.62813, 0.010777, 0.025045, 0.041713]
Predicted label: 1
Correct prediction
Energy consumption = 161.729183 pJ
sum error= 366
Actual label: 1
Output voltages: [0.055501, 0.7987, 0.016631, 0.0071802, 0.31121, 0.002509, 0.29337, 0.024324, 0.18484, 0.15822]
Predicted label: 1
Correct prediction
Energy consumption = 152.550183 pJ
sum error= 366
Actual label: 1
Output voltages: [0.036751, 0.79878, 0.022822, 0.017936, 0.50515, 0.0011409, 0.06278, 0.14796, 0.019103, 0.33584]
Predicted label: 1
Correct prediction
Energy consumption = 146.599639 pJ
sum error= 366
Actual label: 2
Output voltages: [0.037204, 0.48624, 0.79879, 0.033001, 0.0028808, 0.0012658, 0.031791, 0.57366, 0.40417, 0.03463]
Predicted label: 2
Correct prediction
Energy consumption = 145.821709 pJ
sum error= 366
Actual label: 1
Output voltages: [0.0074074, 0.79864, 0.023405, 0.0075924, 0.23639, 0.0027871, 0.54513, 0.0038486, 0.35182, 0.045009]
Predicted label: 1
Correct prediction
Energy consumption = 150.628090 pJ
sum error= 366
Actual label: 2
Output voltages: [0.36788, 0.26705, 0.79875, 0.31434, 0.0038619, 0.0012468, 0.081254, 0.0070016, 0.48877, 0.0094287]
Predicted label: 2
Correct prediction
Energy consumption = 142.783231 pJ
sum error= 366
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 985 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 985 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 985 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79574, 0.026036, 0.1243, 0.014946, 0.0088815, 0.0041597, 0.71862, 0.014308, 0.56854, 0.28744]
Predicted label: 0
Correct prediction
Energy consumption = 160.650188 pJ
sum error= 366
Actual label: 7
Output voltages: [0.11548, 0.014668, 0.040158, 0.29694, 0.0038969, 0.0033931, 0.0011721, 0.79867, 0.32617, 0.39315]
Predicted label: 7
Correct prediction
Energy consumption = 152.322945 pJ
sum error= 366
Actual label: 7
Output voltages: [0.044843, 0.32831, 0.062077, 0.26551, 0.0018093, 0.0017619, 0.0010676, 0.79867, 0.078778, 0.57336]
Predicted label: 7
Correct prediction
Energy consumption = 138.471197 pJ
sum error= 366
Actual label: 5
Output voltages: [0.017149, 0.017683, 0.026467, 0.04649, 0.0021355, 0.79874, 0.020271, 0.002377, 0.79869, 0.0023229]
Predicted label: 5
Correct prediction
Energy consumption = 154.754129 pJ
sum error= 366
Actual label: 8
Output voltages: [0.056554, 0.029427, 0.01541, 0.21041, 0.018304, 0.2259, 0.36633, 0.001833, 0.79873, 0.086363]
Predicted label: 8
Correct prediction
Energy consumption = 144.443377 pJ
sum error= 366
Actual label: 2
Output voltages: [0.1724, 0.22049, 0.79843, 0.47787, 0.0011517, 0.0011523, 0.26008, 0.016646, 0.65331, 0.0066001]
Predicted label: 2
Correct prediction
Energy consumption = 151.211364 pJ
sum error= 366
Actual label: 9
Output voltages: [0.046338, 0.0010664, 0.0010661, 0.013405, 0.097298, 0.79602, 0.030594, 0.19892, 0.19256, 0.35765]
Predicted label: 5
Wrong prediction!
Energy consumption = 150.748044 pJ
sum error= 367
Actual label: 8
Output voltages: [0.013884, 0.15918, 0.018343, 0.36495, 0.001172, 0.043661, 0.047807, 0.0044986, 0.79879, 0.29876]
Predicted label: 8
Correct prediction
Energy consumption = 143.815028 pJ
sum error= 367
Actual label: 6
Output voltages: [0.44443, 0.23847, 0.0022163, 0.31005, 0.015934, 0.37149, 0.79696, 0.038636, 0.7253, 0.0012573]
Predicted label: 6
Correct prediction
Energy consumption = 152.111464 pJ
sum error= 367
Actual label: 7
Output voltages: [0.07993, 0.01701, 0.029519, 0.034101, 0.018695, 0.0064258, 0.001071, 0.79856, 0.075737, 0.39243]
Predicted label: 7
Correct prediction
Energy consumption = 151.842789 pJ
sum error= 367
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 986 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 986 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 986 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36908, 0.0027464, 0.14495, 0.79879, 0.015626, 0.31824, 0.0030857, 0.004755, 0.65049, 0.0048798]
Predicted label: 3
Correct prediction
Energy consumption = 167.008241 pJ
sum error= 367
Actual label: 4
Output voltages: [0.016615, 0.010133, 0.3683, 0.0042625, 0.79876, 0.0011606, 0.57477, 0.046258, 0.013854, 0.020137]
Predicted label: 4
Correct prediction
Energy consumption = 147.433044 pJ
sum error= 367
Actual label: 6
Output voltages: [0.11174, 0.026786, 0.015292, 0.046492, 0.044332, 0.30188, 0.72752, 0.011573, 0.79875, 0.0010717]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.530292 pJ
sum error= 368
Actual label: 8
Output voltages: [0.26517, 0.026824, 0.039729, 0.71667, 0.0010661, 0.039419, 0.23175, 0.0083713, 0.79811, 0.094576]
Predicted label: 8
Correct prediction
Energy consumption = 151.006004 pJ
sum error= 368
Actual label: 7
Output voltages: [0.11193, 0.23037, 0.17915, 0.018482, 0.023874, 0.0011003, 0.0010802, 0.79875, 0.05483, 0.21055]
Predicted label: 7
Correct prediction
Energy consumption = 149.134791 pJ
sum error= 368
Actual label: 0
Output voltages: [0.79874, 0.029343, 0.30178, 0.015747, 0.016589, 0.0034525, 0.041617, 0.033641, 0.19236, 0.14088]
Predicted label: 0
Correct prediction
Energy consumption = 151.226649 pJ
sum error= 368
Actual label: 4
Output voltages: [0.018616, 0.0019794, 0.67261, 0.0095601, 0.79872, 0.003145, 0.54872, 0.37524, 0.014237, 0.0075626]
Predicted label: 4
Correct prediction
Energy consumption = 144.087530 pJ
sum error= 368
Actual label: 2
Output voltages: [0.19651, 0.039101, 0.79875, 0.022919, 0.0010845, 0.0011512, 0.013563, 0.7745, 0.74409, 0.0019765]
Predicted label: 2
Correct prediction
Energy consumption = 140.267368 pJ
sum error= 368
Actual label: 7
Output voltages: [0.019283, 0.28692, 0.57405, 0.024329, 0.0063281, 0.0010752, 0.0011072, 0.79873, 0.1986, 0.23671]
Predicted label: 7
Correct prediction
Energy consumption = 142.403726 pJ
sum error= 368
Actual label: 7
Output voltages: [0.036382, 0.12372, 0.18508, 0.0053316, 0.0016946, 0.0011145, 0.0011209, 0.79879, 0.73981, 0.37027]
Predicted label: 7
Correct prediction
Energy consumption = 134.203439 pJ
sum error= 368
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 987 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 987 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 987 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.010037, 0.0080887, 0.0012737, 0.2931, 0.027085, 0.79869, 0.44208, 0.012245, 0.7012, 0.0052177]
Predicted label: 5
Correct prediction
Energy consumption = 172.633035 pJ
sum error= 368
Actual label: 4
Output voltages: [0.004533, 0.0085534, 0.09544, 0.0019201, 0.79867, 0.0014723, 0.36998, 0.050286, 0.02611, 0.013114]
Predicted label: 4
Correct prediction
Energy consumption = 152.480110 pJ
sum error= 368
Actual label: 3
Output voltages: [0.5914, 0.043673, 0.038538, 0.7987, 0.0066398, 0.0066945, 0.095543, 0.015054, 0.51983, 0.022886]
Predicted label: 3
Correct prediction
Energy consumption = 151.234797 pJ
sum error= 368
Actual label: 4
Output voltages: [0.046878, 0.0018127, 0.26393, 0.0041878, 0.79871, 0.0018565, 0.77312, 0.024821, 0.043803, 0.012823]
Predicted label: 4
Correct prediction
Energy consumption = 143.910978 pJ
sum error= 368
Actual label: 2
Output voltages: [0.24064, 0.075965, 0.79587, 0.39471, 0.0010872, 0.001377, 0.032456, 0.3511, 0.66848, 0.027799]
Predicted label: 2
Correct prediction
Energy consumption = 155.665654 pJ
sum error= 368
Actual label: 8
Output voltages: [0.0097359, 0.023551, 0.093875, 0.12849, 0.019103, 0.026721, 0.02636, 0.01289, 0.79877, 0.21363]
Predicted label: 8
Correct prediction
Energy consumption = 146.209878 pJ
sum error= 368
Actual label: 1
Output voltages: [0.0082827, 0.7986, 0.042264, 0.027179, 0.27864, 0.0013158, 0.24075, 0.0025475, 0.089283, 0.094972]
Predicted label: 1
Correct prediction
Energy consumption = 151.265635 pJ
sum error= 368
Actual label: 5
Output voltages: [0.27967, 0.016335, 0.0010784, 0.19529, 0.0015959, 0.79865, 0.41425, 0.03651, 0.46554, 0.0021677]
Predicted label: 5
Correct prediction
Energy consumption = 152.809854 pJ
sum error= 368
Actual label: 1
Output voltages: [0.12103, 0.79866, 0.05075, 0.1924, 0.21017, 0.0017083, 0.42422, 0.0024014, 0.0075904, 0.026319]
Predicted label: 1
Correct prediction
Energy consumption = 158.351848 pJ
sum error= 368
Actual label: 0
Output voltages: [0.77864, 0.038454, 0.23396, 0.009005, 0.51767, 0.0011201, 0.5138, 0.0011976, 0.75238, 0.32375]
Predicted label: 0
Correct prediction
Energy consumption = 152.300416 pJ
sum error= 368
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 988 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 988 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 988 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.02389, 0.039615, 0.79663, 0.32712, 0.0015895, 0.0010669, 0.033657, 0.031357, 0.78351, 0.026503]
Predicted label: 2
Correct prediction
Energy consumption = 170.615394 pJ
sum error= 368
Actual label: 3
Output voltages: [0.18809, 0.017587, 0.090978, 0.79878, 0.01959, 0.26809, 0.041709, 0.0019402, 0.26925, 0.058702]
Predicted label: 3
Correct prediction
Energy consumption = 150.732724 pJ
sum error= 368
Actual label: 3
Output voltages: [0.11295, 0.0083636, 0.0275, 0.79872, 0.021362, 0.02336, 0.0392, 0.0014902, 0.43008, 0.18177]
Predicted label: 3
Correct prediction
Energy consumption = 139.148437 pJ
sum error= 368
Actual label: 5
Output voltages: [0.025274, 0.050873, 0.058582, 0.46307, 0.0014634, 0.76366, 0.72412, 0.001066, 0.65629, 0.0027485]
Predicted label: 5
Correct prediction
Energy consumption = 149.897216 pJ
sum error= 368
Actual label: 7
Output voltages: [0.034129, 0.098726, 0.032232, 0.0090663, 0.044714, 0.0012655, 0.0010872, 0.79863, 0.087146, 0.04178]
Predicted label: 7
Correct prediction
Energy consumption = 148.888250 pJ
sum error= 368
Actual label: 0
Output voltages: [0.7986, 0.046967, 0.030574, 0.018199, 0.010805, 0.0058212, 0.31315, 0.010303, 0.63753, 0.027606]
Predicted label: 0
Correct prediction
Energy consumption = 153.381850 pJ
sum error= 368
Actual label: 6
Output voltages: [0.18725, 0.034958, 0.10076, 0.0028893, 0.7349, 0.086996, 0.79879, 0.001267, 0.29297, 0.0012791]
Predicted label: 6
Correct prediction
Energy consumption = 143.143598 pJ
sum error= 368
Actual label: 8
Output voltages: [0.020629, 0.1503, 0.008694, 0.19763, 0.031535, 0.031699, 0.74948, 0.010831, 0.79879, 0.011903]
Predicted label: 8
Correct prediction
Energy consumption = 146.360012 pJ
sum error= 368
Actual label: 6
Output voltages: [0.49645, 0.051389, 0.021402, 0.038145, 0.22695, 0.018602, 0.79105, 0.016099, 0.74379, 0.0041393]
Predicted label: 6
Correct prediction
Energy consumption = 150.248584 pJ
sum error= 368
Actual label: 3
Output voltages: [0.37607, 0.024657, 0.13645, 0.79868, 0.029049, 0.0047819, 0.0039438, 0.23274, 0.57782, 0.020413]
Predicted label: 3
Correct prediction
Energy consumption = 151.189628 pJ
sum error= 368
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 989 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 989 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 989 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.34777, 0.0010667, 0.0010736, 0.029859, 0.17634, 0.49197, 0.33291, 0.079348, 0.28294, 0.75355]
Predicted label: 9
Correct prediction
Energy consumption = 161.824769 pJ
sum error= 368
Actual label: 9
Output voltages: [0.053436, 0.014257, 0.014026, 0.707, 0.041729, 0.12453, 0.014266, 0.76329, 0.021923, 0.7855]
Predicted label: 9
Correct prediction
Energy consumption = 142.142627 pJ
sum error= 368
Actual label: 8
Output voltages: [0.032233, 0.0017328, 0.24405, 0.018213, 0.0062086, 0.15782, 0.015241, 0.0047404, 0.79621, 0.35127]
Predicted label: 8
Correct prediction
Energy consumption = 141.128131 pJ
sum error= 368
Actual label: 2
Output voltages: [0.27241, 0.017355, 0.79876, 0.28667, 0.0025369, 0.0012532, 0.042954, 0.50131, 0.74639, 0.0018298]
Predicted label: 2
Correct prediction
Energy consumption = 138.935020 pJ
sum error= 368
Actual label: 7
Output voltages: [0.026662, 0.50736, 0.63234, 0.02559, 0.0091459, 0.0010962, 0.0011399, 0.79877, 0.05532, 0.039166]
Predicted label: 7
Correct prediction
Energy consumption = 141.882229 pJ
sum error= 368
Actual label: 7
Output voltages: [0.13707, 0.061058, 0.77531, 0.0079045, 0.013858, 0.0012061, 0.0020327, 0.79873, 0.15346, 0.037002]
Predicted label: 7
Correct prediction
Energy consumption = 136.015007 pJ
sum error= 368
Actual label: 1
Output voltages: [0.18866, 0.79875, 0.013777, 0.13422, 0.51261, 0.0018636, 0.26404, 0.0076692, 0.019488, 0.04689]
Predicted label: 1
Correct prediction
Energy consumption = 150.450136 pJ
sum error= 368
Actual label: 0
Output voltages: [0.79879, 0.17344, 0.04727, 0.019512, 0.2234, 0.0028319, 0.46027, 0.0023354, 0.19426, 0.028647]
Predicted label: 0
Correct prediction
Energy consumption = 144.542913 pJ
sum error= 368
Actual label: 1
Output voltages: [0.010233, 0.79865, 0.19203, 0.0083051, 0.029043, 0.0048566, 0.74786, 0.024783, 0.35215, 0.017146]
Predicted label: 1
Correct prediction
Energy consumption = 150.127629 pJ
sum error= 368
Actual label: 7
Output voltages: [0.028355, 0.025427, 0.060227, 0.042072, 0.007174, 0.0080238, 0.0010695, 0.79861, 0.31173, 0.3517]
Predicted label: 7
Correct prediction
Energy consumption = 150.948720 pJ
sum error= 368
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 990 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 990 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 990 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0091794, 0.033165, 0.042929, 0.30104, 0.0017531, 0.173, 0.022745, 0.033074, 0.79874, 0.026336]
Predicted label: 8
Correct prediction
Energy consumption = 163.347243 pJ
sum error= 368
Actual label: 9
Output voltages: [0.41114, 0.0058399, 0.01844, 0.022325, 0.064826, 0.033235, 0.0021197, 0.015267, 0.66364, 0.79829]
Predicted label: 9
Correct prediction
Energy consumption = 144.537036 pJ
sum error= 368
Actual label: 0
Output voltages: [0.79879, 0.0078688, 0.044136, 0.012488, 0.057338, 0.010718, 0.57694, 0.2886, 0.22626, 0.019]
Predicted label: 0
Correct prediction
Energy consumption = 149.017431 pJ
sum error= 368
Actual label: 1
Output voltages: [0.078757, 0.79878, 0.13327, 0.0088835, 0.37206, 0.0010799, 0.51199, 0.014593, 0.16204, 0.0086331]
Predicted label: 1
Correct prediction
Energy consumption = 148.724848 pJ
sum error= 368
Actual label: 2
Output voltages: [0.78946, 0.001561, 0.56917, 0.012076, 0.0038576, 0.014167, 0.54924, 0.027428, 0.72513, 0.054584]
Predicted label: 0
Wrong prediction!
Energy consumption = 142.171728 pJ
sum error= 369
Actual label: 3
Output voltages: [0.036933, 0.013976, 0.55096, 0.78429, 0.0038763, 0.0011072, 0.0010779, 0.51896, 0.68908, 0.16187]
Predicted label: 3
Correct prediction
Energy consumption = 144.364897 pJ
sum error= 369
Actual label: 4
Output voltages: [0.0014001, 0.02295, 0.42125, 0.14892, 0.79879, 0.0035756, 0.33353, 0.061209, 0.026079, 0.013601]
Predicted label: 4
Correct prediction
Energy consumption = 141.334438 pJ
sum error= 369
Actual label: 5
Output voltages: [0.35209, 0.0012596, 0.0011184, 0.097005, 0.20209, 0.79869, 0.38616, 0.0032339, 0.65592, 0.0073497]
Predicted label: 5
Correct prediction
Energy consumption = 141.243514 pJ
sum error= 369
Actual label: 6
Output voltages: [0.026453, 0.048292, 0.31663, 0.0035926, 0.29612, 0.070839, 0.79871, 0.0040512, 0.59774, 0.0045199]
Predicted label: 6
Correct prediction
Energy consumption = 137.599718 pJ
sum error= 369
Actual label: 7
Output voltages: [0.27515, 0.030413, 0.02138, 0.031356, 0.11378, 0.0017522, 0.0010806, 0.79879, 0.088779, 0.33846]
Predicted label: 7
Correct prediction
Energy consumption = 152.623040 pJ
sum error= 369
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 991 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 991 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 991 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.046802, 0.15305, 0.021543, 0.032917, 0.013836, 0.22469, 0.32847, 0.0055607, 0.79879, 0.009706]
Predicted label: 8
Correct prediction
Energy consumption = 174.156349 pJ
sum error= 369
Actual label: 0
Output voltages: [0.79863, 0.023368, 0.21401, 0.032757, 0.0065727, 0.00115, 0.33514, 0.031858, 0.075612, 0.11074]
Predicted label: 0
Correct prediction
Energy consumption = 141.963641 pJ
sum error= 369
Actual label: 1
Output voltages: [0.022382, 0.79821, 0.25278, 0.01831, 0.33814, 0.0010986, 0.31808, 0.0014335, 0.1552, 0.041068]
Predicted label: 1
Correct prediction
Energy consumption = 146.225608 pJ
sum error= 369
Actual label: 2
Output voltages: [0.19216, 0.0029667, 0.79865, 0.04756, 0.00426, 0.0011553, 0.012352, 0.2011, 0.78019, 0.0080325]
Predicted label: 2
Correct prediction
Energy consumption = 140.226369 pJ
sum error= 369
Actual label: 3
Output voltages: [0.056828, 0.083978, 0.4154, 0.79873, 0.0034223, 0.0031015, 0.0012369, 0.0323, 0.73358, 0.076864]
Predicted label: 3
Correct prediction
Energy consumption = 140.451117 pJ
sum error= 369
Actual label: 4
Output voltages: [0.0012288, 0.042376, 0.0087371, 0.0023794, 0.79874, 0.044228, 0.23872, 0.21504, 0.087758, 0.0094238]
Predicted label: 4
Correct prediction
Energy consumption = 147.952799 pJ
sum error= 369
Actual label: 7
Output voltages: [0.46771, 0.011368, 0.17456, 0.039009, 0.025576, 0.0011371, 0.0010715, 0.79872, 0.049807, 0.010841]
Predicted label: 7
Correct prediction
Energy consumption = 149.314285 pJ
sum error= 369
Actual label: 8
Output voltages: [0.056736, 0.040812, 0.13356, 0.07823, 0.023586, 0.028138, 0.0093404, 0.018904, 0.79872, 0.31084]
Predicted label: 8
Correct prediction
Energy consumption = 139.974091 pJ
sum error= 369
Actual label: 9
Output voltages: [0.24004, 0.010218, 0.024188, 0.040351, 0.051427, 0.059735, 0.021208, 0.02971, 0.27631, 0.79728]
Predicted label: 9
Correct prediction
Energy consumption = 150.676112 pJ
sum error= 369
Actual label: 7
Output voltages: [0.26136, 0.02423, 0.38701, 0.001102, 0.27054, 0.0010788, 0.0010807, 0.79878, 0.041011, 0.02317]
Predicted label: 7
Correct prediction
Energy consumption = 144.377968 pJ
sum error= 369
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 992 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 992 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 992 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.023395, 0.055797, 0.29036, 0.18955, 0.0052997, 0.012521, 0.015736, 0.0072187, 0.79867, 0.025362]
Predicted label: 8
Correct prediction
Energy consumption = 166.662118 pJ
sum error= 369
Actual label: 6
Output voltages: [0.041434, 0.0080764, 0.34352, 0.0011138, 0.24764, 0.34093, 0.79871, 0.0011072, 0.44735, 0.0021121]
Predicted label: 6
Correct prediction
Energy consumption = 151.463637 pJ
sum error= 369
Actual label: 4
Output voltages: [0.0027216, 0.025021, 0.024667, 0.0090301, 0.79879, 0.0010733, 0.0050673, 0.0057773, 0.18391, 0.36655]
Predicted label: 4
Correct prediction
Energy consumption = 147.922361 pJ
sum error= 369
Actual label: 1
Output voltages: [0.012143, 0.79878, 0.43192, 0.0067591, 0.3608, 0.0015906, 0.25093, 0.0022206, 0.14428, 0.025482]
Predicted label: 1
Correct prediction
Energy consumption = 149.558981 pJ
sum error= 369
Actual label: 9
Output voltages: [0.56578, 0.0017405, 0.01679, 0.12241, 0.18439, 0.051056, 0.0016566, 0.20549, 0.55872, 0.79356]
Predicted label: 9
Correct prediction
Energy consumption = 142.983220 pJ
sum error= 369
Actual label: 3
Output voltages: [0.058917, 0.0013431, 0.116, 0.79879, 0.0059295, 0.031941, 0.0035969, 0.018434, 0.68523, 0.020419]
Predicted label: 3
Correct prediction
Energy consumption = 138.286934 pJ
sum error= 369
Actual label: 8
Output voltages: [0.076088, 0.048, 0.045985, 0.44074, 0.0027213, 0.074279, 0.098093, 0.052172, 0.79877, 0.0042611]
Predicted label: 8
Correct prediction
Energy consumption = 146.128668 pJ
sum error= 369
Actual label: 4
Output voltages: [0.0048791, 0.024876, 0.44049, 0.089237, 0.7987, 0.0011706, 0.049769, 0.049027, 0.0015732, 0.066028]
Predicted label: 4
Correct prediction
Energy consumption = 145.969508 pJ
sum error= 369
Actual label: 4
Output voltages: [0.0034912, 0.064906, 0.14767, 0.098302, 0.79872, 0.0043909, 0.043852, 0.18097, 0.021449, 0.039229]
Predicted label: 4
Correct prediction
Energy consumption = 140.249514 pJ
sum error= 369
Actual label: 7
Output voltages: [0.027082, 0.09459, 0.098296, 0.034482, 0.013733, 0.00127, 0.0010952, 0.79864, 0.038622, 0.13773]
Predicted label: 7
Correct prediction
Energy consumption = 141.995936 pJ
sum error= 369
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 993 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 993 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 993 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79864, 0.20837, 0.12651, 0.041658, 0.0034217, 0.011907, 0.36539, 0.02037, 0.14486, 0.006547]
Predicted label: 0
Correct prediction
Energy consumption = 173.645132 pJ
sum error= 369
Actual label: 1
Output voltages: [0.0064869, 0.79867, 0.21872, 0.12532, 0.46696, 0.0010873, 0.1233, 0.011179, 0.051407, 0.067513]
Predicted label: 1
Correct prediction
Energy consumption = 162.520469 pJ
sum error= 369
Actual label: 9
Output voltages: [0.42813, 0.02824, 0.062312, 0.18328, 0.052815, 0.014391, 0.11508, 0.030436, 0.042108, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 154.610881 pJ
sum error= 369
Actual label: 2
Output voltages: [0.29387, 0.033334, 0.79858, 0.027362, 0.0092979, 0.0010691, 0.054819, 0.022781, 0.44764, 0.010754]
Predicted label: 2
Correct prediction
Energy consumption = 145.808847 pJ
sum error= 369
Actual label: 8
Output voltages: [0.013228, 0.11734, 0.031223, 0.58713, 0.0012704, 0.043661, 0.0014462, 0.024528, 0.79879, 0.3575]
Predicted label: 8
Correct prediction
Energy consumption = 152.772436 pJ
sum error= 369
Actual label: 7
Output voltages: [0.055694, 0.060324, 0.042647, 0.10697, 0.01037, 0.0011663, 0.0012919, 0.79879, 0.040856, 0.57576]
Predicted label: 7
Correct prediction
Energy consumption = 153.777506 pJ
sum error= 369
Actual label: 8
Output voltages: [0.031334, 0.012645, 0.018757, 0.17874, 0.0017839, 0.16296, 0.018532, 0.0082122, 0.79878, 0.16863]
Predicted label: 8
Correct prediction
Energy consumption = 147.293804 pJ
sum error= 369
Actual label: 2
Output voltages: [0.42711, 0.0045768, 0.79872, 0.025223, 0.013266, 0.0010849, 0.049054, 0.04258, 0.62655, 0.0028256]
Predicted label: 2
Correct prediction
Energy consumption = 140.351257 pJ
sum error= 369
Actual label: 6
Output voltages: [0.2751, 0.077753, 0.24663, 0.0099972, 0.35648, 0.03863, 0.79878, 0.0016965, 0.56093, 0.0067744]
Predicted label: 6
Correct prediction
Energy consumption = 145.051443 pJ
sum error= 369
Actual label: 0
Output voltages: [0.79879, 0.030854, 0.024038, 0.012146, 0.010493, 0.0048482, 0.74464, 0.019364, 0.30106, 0.061462]
Predicted label: 0
Correct prediction
Energy consumption = 129.748886 pJ
sum error= 369
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 994 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 994 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 994 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.098321, 0.07531, 0.42105, 0.0010662, 0.18501, 0.04496, 0.79879, 0.0028909, 0.53628, 0.0013925]
Predicted label: 6
Correct prediction
Energy consumption = 162.363099 pJ
sum error= 369
Actual label: 5
Output voltages: [0.33625, 0.0010839, 0.040477, 0.74565, 0.0054592, 0.76348, 0.38653, 0.014622, 0.78217, 0.020179]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.676103 pJ
sum error= 370
Actual label: 3
Output voltages: [0.082599, 0.016714, 0.029637, 0.79879, 0.014557, 0.010288, 0.0058167, 0.0138, 0.74335, 0.025758]
Predicted label: 3
Correct prediction
Energy consumption = 137.785402 pJ
sum error= 370
Actual label: 3
Output voltages: [0.039768, 0.020632, 0.29882, 0.79864, 0.0013398, 0.0019739, 0.0089363, 0.027765, 0.76272, 0.0076866]
Predicted label: 3
Correct prediction
Energy consumption = 131.353873 pJ
sum error= 370
Actual label: 3
Output voltages: [0.024795, 0.015633, 0.073561, 0.52165, 0.11416, 0.002253, 0.0046814, 0.0026375, 0.79839, 0.027893]
Predicted label: 8
Wrong prediction!
Energy consumption = 134.544280 pJ
sum error= 371
Actual label: 9
Output voltages: [0.22037, 0.0078362, 0.0022604, 0.056106, 0.7442, 0.0079209, 0.0012715, 0.0043197, 0.092504, 0.79483]
Predicted label: 9
Correct prediction
Energy consumption = 146.130182 pJ
sum error= 371
Actual label: 1
Output voltages: [0.0039874, 0.79861, 0.032557, 0.018309, 0.030184, 0.0017991, 0.59004, 0.035404, 0.24416, 0.02599]
Predicted label: 1
Correct prediction
Energy consumption = 154.911436 pJ
sum error= 371
Actual label: 4
Output voltages: [0.051347, 0.026974, 0.21623, 0.0075199, 0.79877, 0.0016978, 0.78891, 0.19295, 0.0076933, 0.016504]
Predicted label: 4
Correct prediction
Energy consumption = 145.041640 pJ
sum error= 371
Actual label: 0
Output voltages: [0.79871, 0.094363, 0.012653, 0.014558, 0.0028176, 0.0084984, 0.46563, 0.032918, 0.24899, 0.033686]
Predicted label: 0
Correct prediction
Energy consumption = 150.082214 pJ
sum error= 371
Actual label: 6
Output voltages: [0.042598, 0.038791, 0.25885, 0.0022226, 0.36228, 0.32664, 0.79869, 0.004678, 0.63763, 0.0068936]
Predicted label: 6
Correct prediction
Energy consumption = 143.040480 pJ
sum error= 371
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 995 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 995 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 995 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23963, 0.79879, 0.041005, 0.0012525, 0.054749, 0.0027671, 0.071777, 0.0018744, 0.054436, 0.048098]
Predicted label: 1
Correct prediction
Energy consumption = 172.991346 pJ
sum error= 371
Actual label: 0
Output voltages: [0.79879, 0.0065636, 0.085708, 0.25021, 0.018912, 0.0067626, 0.015626, 0.14087, 0.42058, 0.017617]
Predicted label: 0
Correct prediction
Energy consumption = 149.951520 pJ
sum error= 371
Actual label: 0
Output voltages: [0.79875, 0.02403, 0.12694, 0.026629, 0.026359, 0.0037151, 0.2743, 0.02506, 0.15233, 0.29013]
Predicted label: 0
Correct prediction
Energy consumption = 141.728900 pJ
sum error= 371
Actual label: 6
Output voltages: [0.20942, 0.083916, 0.27722, 0.0012542, 0.19044, 0.09424, 0.79879, 0.0015139, 0.64332, 0.001956]
Predicted label: 6
Correct prediction
Energy consumption = 139.246857 pJ
sum error= 371
Actual label: 2
Output voltages: [0.13577, 0.001397, 0.79549, 0.63991, 0.0015531, 0.0011654, 0.026062, 0.17044, 0.75766, 0.0024091]
Predicted label: 2
Correct prediction
Energy consumption = 146.969023 pJ
sum error= 371
Actual label: 1
Output voltages: [0.0042711, 0.79879, 0.35545, 0.01588, 0.017293, 0.001079, 0.52141, 0.0017669, 0.27897, 0.017214]
Predicted label: 1
Correct prediction
Energy consumption = 147.222676 pJ
sum error= 371
Actual label: 1
Output voltages: [0.19015, 0.79775, 0.42605, 0.0098333, 0.79318, 0.0024064, 0.26807, 0.0015229, 0.20609, 0.035684]
Predicted label: 1
Correct prediction
Energy consumption = 140.827283 pJ
sum error= 371
Actual label: 7
Output voltages: [0.03488, 0.056502, 0.085763, 0.13093, 0.018362, 0.0014321, 0.0010675, 0.79867, 0.016106, 0.049828]
Predicted label: 7
Correct prediction
Energy consumption = 145.122303 pJ
sum error= 371
Actual label: 7
Output voltages: [0.027652, 0.24666, 0.40913, 0.03154, 0.005238, 0.0011863, 0.0011705, 0.79879, 0.28959, 0.1702]
Predicted label: 7
Correct prediction
Energy consumption = 140.790127 pJ
sum error= 371
Actual label: 8
Output voltages: [0.018068, 0.38652, 0.21363, 0.080546, 0.0067846, 0.0097801, 0.027968, 0.088716, 0.79868, 0.12901]
Predicted label: 8
Correct prediction
Energy consumption = 146.587379 pJ
sum error= 371
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 996 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 996 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 996 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0073717, 0.0066628, 0.0779, 0.01272, 0.79861, 0.0029672, 0.10288, 0.045191, 0.048525, 0.011713]
Predicted label: 4
Correct prediction
Energy consumption = 169.816404 pJ
sum error= 371
Actual label: 6
Output voltages: [0.031463, 0.030533, 0.18358, 0.0035438, 0.29975, 0.28484, 0.79872, 0.0035441, 0.71848, 0.0047186]
Predicted label: 6
Correct prediction
Energy consumption = 147.053883 pJ
sum error= 371
Actual label: 0
Output voltages: [0.79698, 0.041552, 0.034241, 0.030662, 0.63937, 0.0016733, 0.05174, 0.0211, 0.43683, 0.032959]
Predicted label: 0
Correct prediction
Energy consumption = 147.468909 pJ
sum error= 371
Actual label: 7
Output voltages: [0.31321, 0.010211, 0.012833, 0.41232, 0.0025423, 0.044332, 0.0011534, 0.79875, 0.39682, 0.32827]
Predicted label: 7
Correct prediction
Energy consumption = 148.715487 pJ
sum error= 371
Actual label: 0
Output voltages: [0.79868, 0.017182, 0.25432, 0.013808, 0.020878, 0.0010871, 0.31893, 0.017185, 0.39205, 0.02358]
Predicted label: 0
Correct prediction
Energy consumption = 144.992997 pJ
sum error= 371
Actual label: 3
Output voltages: [0.21915, 0.0019108, 0.034526, 0.79875, 0.028845, 0.27186, 0.007678, 0.014836, 0.76933, 0.029487]
Predicted label: 3
Correct prediction
Energy consumption = 149.348364 pJ
sum error= 371
Actual label: 6
Output voltages: [0.14523, 0.010302, 0.42023, 0.0010881, 0.34043, 0.073587, 0.79873, 0.0020327, 0.24809, 0.0021928]
Predicted label: 6
Correct prediction
Energy consumption = 141.331066 pJ
sum error= 371
Actual label: 8
Output voltages: [0.034294, 0.063467, 0.15895, 0.32004, 0.0022446, 0.021499, 0.015858, 0.0032042, 0.79876, 0.034395]
Predicted label: 8
Correct prediction
Energy consumption = 149.749293 pJ
sum error= 371
Actual label: 7
Output voltages: [0.059075, 0.073431, 0.64162, 0.01411, 0.0093338, 0.0010876, 0.0010855, 0.79866, 0.050071, 0.05646]
Predicted label: 7
Correct prediction
Energy consumption = 152.646765 pJ
sum error= 371
Actual label: 1
Output voltages: [0.17302, 0.79867, 0.028454, 0.046636, 0.64195, 0.0016017, 0.35218, 0.022261, 0.0055758, 0.055577]
Predicted label: 1
Correct prediction
Energy consumption = 152.409870 pJ
sum error= 371
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 997 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 997 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 997 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.18833, 0.010572, 0.0082802, 0.42783, 0.0028624, 0.77446, 0.75431, 0.0010681, 0.40383, 0.0082422]
Predicted label: 5
Correct prediction
Energy consumption = 164.342952 pJ
sum error= 371
Actual label: 2
Output voltages: [0.4188, 0.0098029, 0.79874, 0.041087, 0.014635, 0.0011569, 0.043113, 0.059504, 0.66961, 0.024957]
Predicted label: 2
Correct prediction
Energy consumption = 140.331862 pJ
sum error= 371
Actual label: 4
Output voltages: [0.0079068, 0.026643, 0.029343, 0.011469, 0.79873, 0.0013307, 0.14506, 0.015282, 0.063, 0.019265]
Predicted label: 4
Correct prediction
Energy consumption = 154.098242 pJ
sum error= 371
Actual label: 9
Output voltages: [0.35428, 0.031749, 0.030156, 0.052028, 0.29599, 0.013825, 0.0031499, 0.0024084, 0.30546, 0.79798]
Predicted label: 9
Correct prediction
Energy consumption = 138.335621 pJ
sum error= 371
Actual label: 4
Output voltages: [0.0058528, 0.02857, 0.19165, 0.0369, 0.79878, 0.0014271, 0.058462, 0.045413, 0.019913, 0.0031604]
Predicted label: 4
Correct prediction
Energy consumption = 146.308548 pJ
sum error= 371
Actual label: 3
Output voltages: [0.065516, 0.0027866, 0.71274, 0.79678, 0.0021209, 0.0070072, 0.010083, 0.015805, 0.79152, 0.0058497]
Predicted label: 3
Correct prediction
Energy consumption = 141.396835 pJ
sum error= 371
Actual label: 6
Output voltages: [0.081194, 0.025956, 0.062406, 0.0073997, 0.44515, 0.21634, 0.79879, 0.0017659, 0.71216, 0.0090819]
Predicted label: 6
Correct prediction
Energy consumption = 146.887377 pJ
sum error= 371
Actual label: 4
Output voltages: [0.15373, 0.0064206, 0.098283, 0.017886, 0.79876, 0.0010851, 0.11004, 0.024086, 0.045336, 0.0019515]
Predicted label: 4
Correct prediction
Energy consumption = 142.534762 pJ
sum error= 371
Actual label: 1
Output voltages: [0.16763, 0.79848, 0.63248, 0.001975, 0.52944, 0.001092, 0.094597, 0.098939, 0.048875, 0.098918]
Predicted label: 1
Correct prediction
Energy consumption = 153.399458 pJ
sum error= 371
Actual label: 7
Output voltages: [0.42598, 0.050472, 0.013335, 0.28649, 0.029043, 0.024413, 0.0020535, 0.79865, 0.16383, 0.20065]
Predicted label: 7
Correct prediction
Energy consumption = 146.067482 pJ
sum error= 371
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 998 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 998 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 998 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33339, 0.0036224, 0.79879, 0.048668, 0.0011707, 0.0010732, 0.025503, 0.074718, 0.74936, 0.0031768]
Predicted label: 2
Correct prediction
Energy consumption = 164.021598 pJ
sum error= 371
Actual label: 6
Output voltages: [0.13494, 0.084211, 0.19123, 0.011276, 0.048519, 0.18033, 0.79879, 0.0022261, 0.62711, 0.0024852]
Predicted label: 6
Correct prediction
Energy consumption = 140.596362 pJ
sum error= 371
Actual label: 5
Output voltages: [0.051736, 0.01561, 0.15132, 0.014012, 0.029314, 0.55084, 0.79766, 0.0010785, 0.044145, 0.015088]
Predicted label: 6
Wrong prediction!
Energy consumption = 148.824724 pJ
sum error= 372
Actual label: 0
Output voltages: [0.79878, 0.12936, 0.032306, 0.032315, 0.012989, 0.025472, 0.60185, 0.026246, 0.15474, 0.023523]
Predicted label: 0
Correct prediction
Energy consumption = 149.481393 pJ
sum error= 372
Actual label: 1
Output voltages: [0.040863, 0.79864, 0.26389, 0.20614, 0.39963, 0.0021888, 0.65733, 0.011894, 0.033261, 0.024891]
Predicted label: 1
Correct prediction
Energy consumption = 167.364117 pJ
sum error= 372
Actual label: 2
Output voltages: [0.52592, 0.24979, 0.79875, 0.022596, 0.0044865, 0.0012882, 0.121, 0.3704, 0.46168, 0.0079255]
Predicted label: 2
Correct prediction
Energy consumption = 148.587162 pJ
sum error= 372
Actual label: 3
Output voltages: [0.1491, 0.034581, 0.060158, 0.79869, 0.023162, 0.0057794, 0.0060306, 0.01676, 0.64925, 0.10549]
Predicted label: 3
Correct prediction
Energy consumption = 144.572575 pJ
sum error= 372
Actual label: 4
Output voltages: [0.0015283, 0.0033813, 0.023892, 0.047083, 0.79878, 0.0010949, 0.068134, 0.045349, 0.080558, 0.0071674]
Predicted label: 4
Correct prediction
Energy consumption = 151.116657 pJ
sum error= 372
Actual label: 5
Output voltages: [0.033433, 0.0012398, 0.0014042, 0.55362, 0.012968, 0.79876, 0.17857, 0.019861, 0.79471, 0.0060788]
Predicted label: 5
Correct prediction
Energy consumption = 147.026520 pJ
sum error= 372
Actual label: 6
Output voltages: [0.14731, 0.039042, 0.03126, 0.0038911, 0.1859, 0.2564, 0.79879, 0.013503, 0.74043, 0.010066]
Predicted label: 6
Correct prediction
Energy consumption = 141.222232 pJ
sum error= 372
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 999 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 999 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 999 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.035495, 0.39855, 0.51038, 0.016128, 0.011345, 0.0012017, 0.0011127, 0.79879, 0.48849, 0.15442]
Predicted label: 7
Correct prediction
Energy consumption = 177.122422 pJ
sum error= 372
Actual label: 8
Output voltages: [0.026193, 0.010499, 0.32967, 0.20886, 0.010412, 0.61871, 0.052142, 0.010241, 0.79865, 0.040686]
Predicted label: 8
Correct prediction
Energy consumption = 151.158382 pJ
sum error= 372
Actual label: 9
Output voltages: [0.11416, 0.0073626, 0.0052374, 0.013169, 0.59282, 0.029277, 0.025831, 0.010647, 0.34245, 0.79803]
Predicted label: 9
Correct prediction
Energy consumption = 152.784084 pJ
sum error= 372
Actual label: 0
Output voltages: [0.78818, 0.032807, 0.056784, 0.019037, 0.023357, 0.0010836, 0.60309, 0.014513, 0.50218, 0.025514]
Predicted label: 0
Correct prediction
Energy consumption = 143.423637 pJ
sum error= 372
Actual label: 1
Output voltages: [0.018853, 0.79875, 0.58249, 0.059897, 0.16013, 0.001123, 0.42988, 0.0042344, 0.19228, 0.045054]
Predicted label: 1
Correct prediction
Energy consumption = 162.189495 pJ
sum error= 372
Actual label: 2
Output voltages: [0.059471, 0.10856, 0.79878, 0.04463, 0.0061157, 0.001254, 0.049219, 0.046652, 0.30973, 0.042545]
Predicted label: 2
Correct prediction
Energy consumption = 147.792853 pJ
sum error= 372
Actual label: 3
Output voltages: [0.31745, 0.023147, 0.13384, 0.79871, 0.015328, 0.0084275, 0.023283, 0.0024809, 0.46966, 0.057157]
Predicted label: 3
Correct prediction
Energy consumption = 147.942931 pJ
sum error= 372
Actual label: 4
Output voltages: [0.0021423, 0.0061078, 0.032257, 0.022377, 0.79866, 0.0037138, 0.2262, 0.27884, 0.17038, 0.0024485]
Predicted label: 4
Correct prediction
Energy consumption = 150.659853 pJ
sum error= 372
Actual label: 5
Output voltages: [0.28689, 0.0011314, 0.0015702, 0.21822, 0.079912, 0.79878, 0.53284, 0.01368, 0.78406, 0.0038236]
Predicted label: 5
Correct prediction
Energy consumption = 146.521201 pJ
sum error= 372
Actual label: 6
Output voltages: [0.22745, 0.011115, 0.35989, 0.0018303, 0.43487, 0.037947, 0.79874, 0.0013399, 0.35807, 0.013929]
Predicted label: 6
Correct prediction
Energy consumption = 135.621195 pJ
sum error= 372
End-to-End CSV Created: 5_5_2025_full_run.csv
Total area = 3401.58464 µm^2
Task completed!
Total error= 372
error rate = 0.037200
accuracy = 96.280000%
Program Execution Time = 8 hours 7 minutes 44 seconds
real	487m45.200s
user	507m46.344s
sys	19m15.496s
