Soft limit: 1024
Hard limit: 1048576
Soft limit: 20000
Hard limit: 1048576
Rlow=78000.000000
Rhigh=202000.000000
Horizontal partitions = [13, 4, 3]
Vertical partitions = [4, 3, 1]
Created folder: separated_csvs_5_10_25
Folder already exists: pwl_files
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 0 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 0 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 0 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.32394, 0.0044768, 0.054202, 0.18914, 0.0049443, 0.0029593, 0.0011568, 0.79868, 0.75749, 0.25661]
Predicted label: 7
Correct prediction
Energy consumption = 151.814938 pJ
sum error= 0
Actual label: 2
Output voltages: [0.47194, 0.3898, 0.79754, 0.26678, 0.0047988, 0.0012837, 0.38597, 0.0021071, 0.10902, 0.0060613]
Predicted label: 2
Correct prediction
Energy consumption = 149.799930 pJ
sum error= 0
Actual label: 1
Output voltages: [0.014643, 0.79849, 0.021692, 0.02397, 0.01863, 0.0030739, 0.71961, 0.012719, 0.31398, 0.046303]
Predicted label: 1
Correct prediction
Energy consumption = 151.965163 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79877, 0.03969, 0.0074899, 0.014214, 0.099546, 0.024545, 0.57059, 0.014994, 0.041716, 0.036526]
Predicted label: 0
Correct prediction
Energy consumption = 154.645368 pJ
sum error= 0
Actual label: 4
Output voltages: [0.016171, 0.0073495, 0.15016, 0.011999, 0.79867, 0.0011042, 0.036953, 0.051331, 0.037681, 0.094351]
Predicted label: 4
Correct prediction
Energy consumption = 156.380932 pJ
sum error= 0
Actual label: 1
Output voltages: [0.022164, 0.79857, 0.021632, 0.016578, 0.19866, 0.003706, 0.72924, 0.019046, 0.15472, 0.037667]
Predicted label: 1
Correct prediction
Energy consumption = 160.315697 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0010718, 0.025026, 0.023623, 0.0011931, 0.78144, 0.014809, 0.007456, 0.0027105, 0.75038, 0.1213]
Predicted label: 4
Correct prediction
Energy consumption = 144.300062 pJ
sum error= 0
Actual label: 9
Output voltages: [0.45426, 0.0031459, 0.66091, 0.022136, 0.17101, 0.0040566, 0.014524, 0.043458, 0.33468, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 154.535937 pJ
sum error= 0
Actual label: 5
Output voltages: [0.21916, 0.0011098, 0.0063818, 0.036631, 0.33232, 0.79879, 0.73962, 0.0058759, 0.75608, 0.031883]
Predicted label: 5
Correct prediction
Energy consumption = 148.770987 pJ
sum error= 0
Actual label: 9
Output voltages: [0.43809, 0.0074784, 0.038503, 0.019491, 0.16014, 0.032167, 0.0022969, 0.035436, 0.55299, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 136.481604 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 1 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 1 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 1 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79876, 0.042066, 0.16697, 0.0084904, 0.0074511, 0.0059929, 0.3019, 0.009571, 0.11563, 0.19043]
Predicted label: 0
Correct prediction
Energy consumption = 157.937678 pJ
sum error= 0
Actual label: 6
Output voltages: [0.16644, 0.1695, 0.29757, 0.0024702, 0.31999, 0.097008, 0.79869, 0.0015097, 0.44016, 0.022982]
Predicted label: 6
Correct prediction
Energy consumption = 141.022191 pJ
sum error= 0
Actual label: 9
Output voltages: [0.27754, 0.0042105, 0.010255, 0.030078, 0.44964, 0.0048219, 0.0049686, 0.016946, 0.43587, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 152.118303 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79879, 0.15505, 0.0088823, 0.01666, 0.016748, 0.026108, 0.72263, 0.017142, 0.1645, 0.047202]
Predicted label: 0
Correct prediction
Energy consumption = 158.244662 pJ
sum error= 0
Actual label: 1
Output voltages: [0.020138, 0.79847, 0.13566, 0.070167, 0.008706, 0.0013382, 0.53055, 0.0042072, 0.13572, 0.037173]
Predicted label: 1
Correct prediction
Energy consumption = 159.281278 pJ
sum error= 0
Actual label: 5
Output voltages: [0.19683, 0.0010769, 0.010478, 0.23149, 0.0024774, 0.79861, 0.039306, 0.19694, 0.7741, 0.0039497]
Predicted label: 5
Correct prediction
Energy consumption = 147.449801 pJ
sum error= 0
Actual label: 9
Output voltages: [0.38382, 0.0046731, 0.05995, 0.032395, 0.47331, 0.010315, 0.016492, 0.0073668, 0.16158, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 154.260760 pJ
sum error= 0
Actual label: 7
Output voltages: [0.30911, 0.0058294, 0.13859, 0.36219, 0.0014905, 0.015797, 0.0010659, 0.79865, 0.29142, 0.28354]
Predicted label: 7
Correct prediction
Energy consumption = 148.350506 pJ
sum error= 0
Actual label: 3
Output voltages: [0.033615, 0.0032619, 0.74033, 0.79673, 0.0063833, 0.0011059, 0.029324, 0.14379, 0.62629, 0.015099]
Predicted label: 3
Correct prediction
Energy consumption = 147.596071 pJ
sum error= 0
Actual label: 4
Output voltages: [0.024647, 0.012967, 0.40954, 0.026942, 0.7986, 0.0015134, 0.093548, 0.05735, 0.017885, 0.061478]
Predicted label: 4
Correct prediction
Energy consumption = 156.974896 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 2 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 2 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 2 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.19105, 0.016793, 0.027628, 0.061886, 0.43696, 0.004467, 0.0020663, 0.017672, 0.35237, 0.79758]
Predicted label: 9
Correct prediction
Energy consumption = 153.470308 pJ
sum error= 0
Actual label: 6
Output voltages: [0.20681, 0.15657, 0.17368, 0.0029388, 0.22208, 0.46411, 0.79878, 0.0011092, 0.31841, 0.0082488]
Predicted label: 6
Correct prediction
Energy consumption = 152.492680 pJ
sum error= 0
Actual label: 6
Output voltages: [0.47166, 0.059983, 0.17586, 0.015907, 0.4067, 0.33233, 0.79876, 0.0050867, 0.26348, 0.021693]
Predicted label: 6
Correct prediction
Energy consumption = 140.378134 pJ
sum error= 0
Actual label: 5
Output voltages: [0.40875, 0.0011434, 0.001913, 0.13188, 0.028711, 0.79876, 0.57261, 0.01618, 0.74281, 0.0085389]
Predicted label: 5
Correct prediction
Energy consumption = 140.979865 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0084444, 0.0019202, 0.52882, 0.014247, 0.79874, 0.0011217, 0.24991, 0.46993, 0.010797, 0.12399]
Predicted label: 4
Correct prediction
Energy consumption = 148.922415 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79852, 0.065305, 0.050115, 0.0060039, 0.0061063, 0.0012346, 0.73904, 0.019547, 0.13601, 0.094869]
Predicted label: 0
Correct prediction
Energy consumption = 150.060733 pJ
sum error= 0
Actual label: 7
Output voltages: [0.662, 0.2069, 0.028932, 0.33673, 0.0047698, 0.012766, 0.0011266, 0.79878, 0.014292, 0.39953]
Predicted label: 7
Correct prediction
Energy consumption = 155.503126 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0092715, 0.012486, 0.19077, 0.021434, 0.79867, 0.0012022, 0.13281, 0.076199, 0.018806, 0.060798]
Predicted label: 4
Correct prediction
Energy consumption = 152.214184 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79879, 0.036347, 0.46999, 0.19067, 0.025806, 0.0023179, 0.33364, 0.023223, 0.074949, 0.054514]
Predicted label: 0
Correct prediction
Energy consumption = 159.726799 pJ
sum error= 0
Actual label: 1
Output voltages: [0.05287, 0.79857, 0.035648, 0.36586, 0.0098262, 0.002369, 0.26922, 0.0013773, 0.47724, 0.048712]
Predicted label: 1
Correct prediction
Energy consumption = 163.535496 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 3 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 3 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 3 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.15105, 0.010356, 0.10405, 0.79868, 0.034198, 0.0062553, 0.0076523, 0.079175, 0.3659, 0.16529]
Predicted label: 3
Correct prediction
Energy consumption = 147.083904 pJ
sum error= 0
Actual label: 1
Output voltages: [0.004004, 0.79844, 0.048181, 0.1213, 0.048032, 0.01462, 0.11648, 0.0094, 0.010499, 0.19272]
Predicted label: 1
Correct prediction
Energy consumption = 160.069070 pJ
sum error= 0
Actual label: 3
Output voltages: [0.27973, 0.013868, 0.11101, 0.79866, 0.027894, 0.0041276, 0.022992, 0.03884, 0.75237, 0.012505]
Predicted label: 3
Correct prediction
Energy consumption = 145.668787 pJ
sum error= 0
Actual label: 4
Output voltages: [0.44935, 0.018303, 0.41182, 0.001078, 0.7978, 0.0021515, 0.733, 0.022211, 0.15335, 0.0038135]
Predicted label: 4
Correct prediction
Energy consumption = 156.262097 pJ
sum error= 0
Actual label: 7
Output voltages: [0.028253, 0.17749, 0.74473, 0.03475, 0.0026978, 0.0012129, 0.0010659, 0.79872, 0.23762, 0.4204]
Predicted label: 7
Correct prediction
Energy consumption = 152.046282 pJ
sum error= 0
Actual label: 2
Output voltages: [0.3509, 0.018769, 0.79869, 0.040013, 0.0067591, 0.0010674, 0.1891, 0.0093835, 0.36695, 0.015585]
Predicted label: 2
Correct prediction
Energy consumption = 136.206687 pJ
sum error= 0
Actual label: 7
Output voltages: [0.065299, 0.039911, 0.61948, 0.042283, 0.0026395, 0.0012274, 0.0030644, 0.79875, 0.29978, 0.038737]
Predicted label: 7
Correct prediction
Energy consumption = 143.192134 pJ
sum error= 0
Actual label: 1
Output voltages: [0.057085, 0.79847, 0.061794, 0.049596, 0.039482, 0.011823, 0.36453, 0.0074436, 0.23388, 0.048771]
Predicted label: 1
Correct prediction
Energy consumption = 162.483948 pJ
sum error= 0
Actual label: 2
Output voltages: [0.27164, 0.32632, 0.78235, 0.36392, 0.0016487, 0.0011739, 0.31809, 0.19825, 0.31065, 0.017221]
Predicted label: 2
Correct prediction
Energy consumption = 153.077213 pJ
sum error= 0
Actual label: 1
Output voltages: [0.01749, 0.79846, 0.0098634, 0.13909, 0.0119, 0.0017515, 0.7697, 0.0033757, 0.32523, 0.082697]
Predicted label: 1
Correct prediction
Energy consumption = 155.194302 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 4 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 4 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 4 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23869, 0.79836, 0.072321, 0.20923, 0.041346, 0.0024129, 0.4503, 0.19281, 0.012808, 0.19459]
Predicted label: 1
Correct prediction
Energy consumption = 164.624220 pJ
sum error= 0
Actual label: 7
Output voltages: [0.1892, 0.26523, 0.74459, 0.022832, 0.011389, 0.0012783, 0.0012647, 0.79879, 0.020851, 0.21542]
Predicted label: 7
Correct prediction
Energy consumption = 147.808036 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0038943, 0.013553, 0.18504, 0.00563, 0.79869, 0.0013518, 0.059841, 0.031441, 0.049231, 0.041936]
Predicted label: 4
Correct prediction
Energy consumption = 160.313371 pJ
sum error= 0
Actual label: 2
Output voltages: [0.020486, 0.031534, 0.79634, 0.22975, 0.39638, 0.0011296, 0.089129, 0.24762, 0.045001, 0.0072482]
Predicted label: 2
Correct prediction
Energy consumption = 142.502002 pJ
sum error= 0
Actual label: 3
Output voltages: [0.041059, 0.051853, 0.069566, 0.79858, 0.21437, 0.015145, 0.04613, 0.2408, 0.45604, 0.036482]
Predicted label: 3
Correct prediction
Energy consumption = 153.738856 pJ
sum error= 0
Actual label: 5
Output voltages: [0.21896, 0.0010707, 0.0028414, 0.41972, 0.0073867, 0.79871, 0.12879, 0.029273, 0.75845, 0.040542]
Predicted label: 5
Correct prediction
Energy consumption = 151.657799 pJ
sum error= 0
Actual label: 1
Output voltages: [0.010501, 0.79829, 0.0088141, 0.76026, 0.016279, 0.010169, 0.0037786, 0.036814, 0.35717, 0.12273]
Predicted label: 1
Correct prediction
Energy consumption = 158.213112 pJ
sum error= 0
Actual label: 2
Output voltages: [0.55999, 0.29559, 0.7987, 0.070233, 0.02334, 0.0011914, 0.26079, 0.038607, 0.39201, 0.050329]
Predicted label: 2
Correct prediction
Energy consumption = 143.088151 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0038944, 0.020783, 0.058452, 0.0053679, 0.79879, 0.011534, 0.20562, 0.086193, 0.28123, 0.046789]
Predicted label: 4
Correct prediction
Energy consumption = 152.881237 pJ
sum error= 0
Actual label: 4
Output voltages: [0.016051, 0.0034055, 0.14223, 0.0093826, 0.79851, 0.015115, 0.11091, 0.055221, 0.026296, 0.033041]
Predicted label: 4
Correct prediction
Energy consumption = 146.454400 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 5 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 5 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 5 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.040556, 0.039522, 0.076468, 0.0026967, 0.033502, 0.081853, 0.79879, 0.020323, 0.76607, 0.0040816]
Predicted label: 6
Correct prediction
Energy consumption = 154.210338 pJ
sum error= 0
Actual label: 3
Output voltages: [0.62983, 0.0076909, 0.10102, 0.79871, 0.011958, 0.1557, 0.013821, 0.041245, 0.76711, 0.049482]
Predicted label: 3
Correct prediction
Energy consumption = 140.977458 pJ
sum error= 0
Actual label: 5
Output voltages: [0.053021, 0.0010956, 0.0017221, 0.29711, 0.21716, 0.7987, 0.74823, 0.010837, 0.71298, 0.01759]
Predicted label: 5
Correct prediction
Energy consumption = 134.711173 pJ
sum error= 0
Actual label: 5
Output voltages: [0.1574, 0.0011128, 0.013009, 0.32637, 0.0019326, 0.79876, 0.043073, 0.15175, 0.76733, 0.019216]
Predicted label: 5
Correct prediction
Energy consumption = 129.489943 pJ
sum error= 0
Actual label: 6
Output voltages: [0.13461, 0.21499, 0.38396, 0.001066, 0.21014, 0.083303, 0.79872, 0.0012401, 0.48515, 0.010674]
Predicted label: 6
Correct prediction
Energy consumption = 140.520672 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79866, 0.058057, 0.04809, 0.024112, 0.02562, 0.026753, 0.71953, 0.025631, 0.3331, 0.023789]
Predicted label: 0
Correct prediction
Energy consumption = 154.821097 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0032093, 0.014778, 0.33159, 0.0069684, 0.79864, 0.0025258, 0.061449, 0.046324, 0.023364, 0.16282]
Predicted label: 4
Correct prediction
Energy consumption = 155.502787 pJ
sum error= 0
Actual label: 1
Output voltages: [0.009962, 0.79852, 0.027961, 0.044319, 0.037889, 0.0020439, 0.4652, 0.013996, 0.47589, 0.04601]
Predicted label: 1
Correct prediction
Energy consumption = 161.225499 pJ
sum error= 0
Actual label: 9
Output voltages: [0.37945, 0.001986, 0.04637, 0.025501, 0.26151, 0.050517, 0.021375, 0.087187, 0.26562, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 150.604687 pJ
sum error= 0
Actual label: 5
Output voltages: [0.13641, 0.00194, 0.0011644, 0.47239, 0.26949, 0.79823, 0.13148, 0.0039495, 0.30661, 0.041135]
Predicted label: 5
Correct prediction
Energy consumption = 146.445698 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 6 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 6 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 6 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.29598, 0.035836, 0.0011347, 0.7363, 0.0017919, 0.027363, 0.0010691, 0.79876, 0.072, 0.50872]
Predicted label: 7
Correct prediction
Energy consumption = 156.750959 pJ
sum error= 0
Actual label: 8
Output voltages: [0.028825, 0.0090132, 0.73508, 0.17225, 0.0079013, 0.015357, 0.0060791, 0.024483, 0.79867, 0.015708]
Predicted label: 8
Correct prediction
Energy consumption = 133.698428 pJ
sum error= 0
Actual label: 9
Output voltages: [0.083365, 0.028246, 0.013665, 0.044647, 0.024407, 0.082092, 0.026048, 0.049214, 0.49763, 0.79815]
Predicted label: 9
Correct prediction
Energy consumption = 151.417254 pJ
sum error= 0
Actual label: 3
Output voltages: [0.074491, 0.0045759, 0.3773, 0.79845, 0.0063346, 0.0026884, 0.0013461, 0.027395, 0.76967, 0.085858]
Predicted label: 3
Correct prediction
Energy consumption = 144.811703 pJ
sum error= 0
Actual label: 7
Output voltages: [0.014243, 0.0028764, 0.063791, 0.62447, 0.0040193, 0.020134, 0.0011132, 0.79816, 0.76767, 0.42749]
Predicted label: 7
Correct prediction
Energy consumption = 136.144826 pJ
sum error= 0
Actual label: 4
Output voltages: [0.054896, 0.090644, 0.030096, 0.034027, 0.79879, 0.0011672, 0.027174, 0.018433, 0.021723, 0.65371]
Predicted label: 4
Correct prediction
Energy consumption = 158.580163 pJ
sum error= 0
Actual label: 6
Output voltages: [0.63679, 0.33371, 0.17315, 0.0085206, 0.013782, 0.0041557, 0.79782, 0.001072, 0.49125, 0.050954]
Predicted label: 6
Correct prediction
Energy consumption = 157.456601 pJ
sum error= 0
Actual label: 4
Output voltages: [0.004392, 0.018754, 0.17438, 0.023216, 0.79862, 0.0067568, 0.3224, 0.21379, 0.022396, 0.042459]
Predicted label: 4
Correct prediction
Energy consumption = 148.602938 pJ
sum error= 0
Actual label: 3
Output voltages: [0.036663, 0.003055, 0.2276, 0.79879, 0.017586, 0.012905, 0.0064703, 0.045756, 0.46721, 0.3256]
Predicted label: 3
Correct prediction
Energy consumption = 148.172796 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79868, 0.037576, 0.054378, 0.031144, 0.0010738, 0.011701, 0.44759, 0.012116, 0.18615, 0.03538]
Predicted label: 0
Correct prediction
Energy consumption = 146.142399 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 7 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 7 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 7 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.70147, 0.0016992, 0.10939, 0.25703, 0.0040499, 0.0012187, 0.0010946, 0.79879, 0.71659, 0.20835]
Predicted label: 7
Correct prediction
Energy consumption = 152.997263 pJ
sum error= 0
Actual label: 0
Output voltages: [0.7987, 0.043589, 0.02443, 0.0064496, 0.014555, 0.020101, 0.48413, 0.0045996, 0.1455, 0.026114]
Predicted label: 0
Correct prediction
Energy consumption = 149.889191 pJ
sum error= 0
Actual label: 2
Output voltages: [0.71421, 0.028336, 0.79873, 0.022085, 0.0028296, 0.0011607, 0.083065, 0.03137, 0.21686, 0.0072451]
Predicted label: 2
Correct prediction
Energy consumption = 140.957366 pJ
sum error= 0
Actual label: 9
Output voltages: [0.14503, 0.0039229, 0.016675, 0.021427, 0.22023, 0.0022762, 0.0023359, 0.0081488, 0.61938, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 145.963008 pJ
sum error= 0
Actual label: 1
Output voltages: [0.087296, 0.79851, 0.023911, 0.24583, 0.036478, 0.008282, 0.54769, 0.0024454, 0.11652, 0.13152]
Predicted label: 1
Correct prediction
Energy consumption = 160.209906 pJ
sum error= 0
Actual label: 7
Output voltages: [0.065043, 0.002891, 0.40448, 0.50996, 0.020776, 0.0010692, 0.0011649, 0.79659, 0.41342, 0.21819]
Predicted label: 7
Correct prediction
Energy consumption = 152.292857 pJ
sum error= 0
Actual label: 3
Output voltages: [0.33641, 0.03585, 0.061994, 0.79859, 0.030925, 0.026336, 0.025995, 0.022665, 0.65501, 0.083496]
Predicted label: 3
Correct prediction
Energy consumption = 143.493592 pJ
sum error= 0
Actual label: 2
Output voltages: [0.69567, 0.18207, 0.79865, 0.07928, 0.0076902, 0.0011421, 0.044228, 0.25261, 0.33204, 0.028429]
Predicted label: 2
Correct prediction
Energy consumption = 138.864548 pJ
sum error= 0
Actual label: 9
Output voltages: [0.04617, 0.014725, 0.030057, 0.051516, 0.3522, 0.0013615, 0.0032261, 0.0063464, 0.614, 0.79421]
Predicted label: 9
Correct prediction
Energy consumption = 146.951651 pJ
sum error= 0
Actual label: 7
Output voltages: [0.4569, 0.011052, 0.032068, 0.63785, 0.0028036, 0.013146, 0.0012706, 0.79862, 0.52667, 0.47904]
Predicted label: 7
Correct prediction
Energy consumption = 139.438854 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 8 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 8 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 8 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.38615, 0.0088668, 0.075165, 0.016529, 0.038151, 0.015233, 0.0013314, 0.79878, 0.26122, 0.77405]
Predicted label: 7
Correct prediction
Energy consumption = 159.396822 pJ
sum error= 0
Actual label: 6
Output voltages: [0.11584, 0.028786, 0.21583, 0.0014844, 0.3955, 0.23813, 0.79875, 0.0040746, 0.47501, 0.0046221]
Predicted label: 6
Correct prediction
Energy consumption = 154.341413 pJ
sum error= 0
Actual label: 2
Output voltages: [0.61309, 0.061929, 0.79868, 0.062105, 0.043426, 0.0011596, 0.34004, 0.075988, 0.37448, 0.053292]
Predicted label: 2
Correct prediction
Energy consumption = 147.840177 pJ
sum error= 0
Actual label: 7
Output voltages: [0.069517, 0.026113, 0.0092241, 0.054087, 0.031125, 0.013105, 0.0010697, 0.79867, 0.059007, 0.34089]
Predicted label: 7
Correct prediction
Energy consumption = 155.558598 pJ
sum error= 0
Actual label: 8
Output voltages: [0.02751, 0.032491, 0.13253, 0.070677, 0.038178, 0.011894, 0.19926, 0.0079234, 0.79875, 0.036221]
Predicted label: 8
Correct prediction
Energy consumption = 147.927584 pJ
sum error= 0
Actual label: 4
Output voltages: [0.001827, 0.02498, 0.020308, 0.006091, 0.79859, 0.0027215, 0.19563, 0.47676, 0.14492, 0.015776]
Predicted label: 4
Correct prediction
Energy consumption = 153.913502 pJ
sum error= 0
Actual label: 7
Output voltages: [0.29152, 0.065559, 0.155, 0.44686, 0.0013991, 0.0017302, 0.0011544, 0.79874, 0.71026, 0.43099]
Predicted label: 7
Correct prediction
Energy consumption = 153.318879 pJ
sum error= 0
Actual label: 3
Output voltages: [0.73878, 0.065227, 0.046258, 0.79872, 0.061255, 0.020851, 0.028728, 0.22234, 0.25443, 0.011025]
Predicted label: 3
Correct prediction
Energy consumption = 142.034646 pJ
sum error= 0
Actual label: 6
Output voltages: [0.22553, 0.15218, 0.27538, 0.024641, 0.25199, 0.22293, 0.79864, 0.0041206, 0.21273, 0.029722]
Predicted label: 6
Correct prediction
Energy consumption = 149.435874 pJ
sum error= 0
Actual label: 1
Output voltages: [0.029174, 0.79876, 0.32783, 0.036281, 0.40828, 0.0010803, 0.60954, 0.0044779, 0.2293, 0.002947]
Predicted label: 1
Correct prediction
Energy consumption = 161.706574 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 9 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 9 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 9 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.090048, 0.036726, 0.022491, 0.7987, 0.010011, 0.0022862, 0.018826, 0.011569, 0.52135, 0.062948]
Predicted label: 3
Correct prediction
Energy consumption = 152.686567 pJ
sum error= 0
Actual label: 6
Output voltages: [0.27047, 0.054658, 0.15541, 0.011597, 0.32375, 0.20346, 0.79878, 0.0012491, 0.47253, 0.016148]
Predicted label: 6
Correct prediction
Energy consumption = 146.029289 pJ
sum error= 0
Actual label: 9
Output voltages: [0.30187, 0.0020039, 0.018475, 0.052569, 0.74963, 0.0011793, 0.0010752, 0.0012582, 0.36579, 0.76916]
Predicted label: 9
Correct prediction
Energy consumption = 148.123348 pJ
sum error= 0
Actual label: 3
Output voltages: [0.15518, 0.014974, 0.17196, 0.79879, 0.23038, 0.031726, 0.025624, 0.0035783, 0.49963, 0.27737]
Predicted label: 3
Correct prediction
Energy consumption = 153.759039 pJ
sum error= 0
Actual label: 1
Output voltages: [0.026873, 0.79876, 0.28747, 0.0081235, 0.073658, 0.0010959, 0.76449, 0.0010704, 0.032963, 0.075678]
Predicted label: 1
Correct prediction
Energy consumption = 162.047468 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0028381, 0.01714, 0.01442, 0.015027, 0.79866, 0.0049307, 0.19733, 0.036476, 0.083376, 0.01337]
Predicted label: 4
Correct prediction
Energy consumption = 138.090045 pJ
sum error= 0
Actual label: 1
Output voltages: [0.0044633, 0.79837, 0.020473, 0.3761, 0.087734, 0.0027887, 0.01543, 0.0010761, 0.089719, 0.21476]
Predicted label: 1
Correct prediction
Energy consumption = 157.131673 pJ
sum error= 0
Actual label: 7
Output voltages: [0.047206, 0.011362, 0.25318, 0.16844, 0.0027827, 0.0010815, 0.0011689, 0.79866, 0.79294, 0.016238]
Predicted label: 7
Correct prediction
Energy consumption = 150.180458 pJ
sum error= 0
Actual label: 6
Output voltages: [0.040487, 0.027142, 0.2507, 0.0013726, 0.31588, 0.082837, 0.79878, 0.0024387, 0.64433, 0.0014494]
Predicted label: 6
Correct prediction
Energy consumption = 151.068665 pJ
sum error= 0
Actual label: 9
Output voltages: [0.0646, 0.020878, 0.035891, 0.13288, 0.17538, 0.22722, 0.043331, 0.033473, 0.39863, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 155.792473 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 10 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 10 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 10 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.04374, 0.12721, 0.28225, 0.0015947, 0.17553, 0.40117, 0.79865, 0.012846, 0.38496, 0.02658]
Predicted label: 6
Correct prediction
Energy consumption = 149.684457 pJ
sum error= 0
Actual label: 0
Output voltages: [0.79879, 0.12899, 0.015083, 0.035452, 0.016067, 0.044422, 0.55161, 0.010668, 0.03707, 0.03537]
Predicted label: 0
Correct prediction
Energy consumption = 148.602732 pJ
sum error= 0
Actual label: 5
Output voltages: [0.26026, 0.0010719, 0.013021, 0.48713, 0.0028716, 0.79741, 0.014579, 0.11736, 0.78433, 0.098677]
Predicted label: 5
Correct prediction
Energy consumption = 140.177845 pJ
sum error= 0
Actual label: 4
Output voltages: [0.017581, 0.011995, 0.43974, 0.010436, 0.79859, 0.00345, 0.053082, 0.038168, 0.016214, 0.054291]
Predicted label: 4
Correct prediction
Energy consumption = 155.511871 pJ
sum error= 0
Actual label: 9
Output voltages: [0.12948, 0.001085, 0.0021176, 0.13519, 0.033605, 0.67711, 0.0019286, 0.077244, 0.7291, 0.78107]
Predicted label: 9
Correct prediction
Energy consumption = 148.668768 pJ
sum error= 0
Actual label: 9
Output voltages: [0.11009, 0.019231, 0.025361, 0.042955, 0.044502, 0.060085, 0.023257, 0.051168, 0.45747, 0.79558]
Predicted label: 9
Correct prediction
Energy consumption = 141.153017 pJ
sum error= 0
Actual label: 2
Output voltages: [0.51177, 0.0041974, 0.79879, 0.20433, 0.019292, 0.001134, 0.021749, 0.03477, 0.4717, 0.0061137]
Predicted label: 2
Correct prediction
Energy consumption = 150.427445 pJ
sum error= 0
Actual label: 1
Output voltages: [0.53631, 0.79857, 0.209, 0.29453, 0.061512, 0.0015989, 0.72664, 0.0010736, 0.069711, 0.10425]
Predicted label: 1
Correct prediction
Energy consumption = 152.315726 pJ
sum error= 0
Actual label: 9
Output voltages: [0.40349, 0.037633, 0.0082501, 0.040039, 0.041522, 0.0095391, 0.0071675, 0.02204, 0.26574, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 157.328839 pJ
sum error= 0
Actual label: 4
Output voltages: [0.027205, 0.0075276, 0.09376, 0.0065532, 0.79857, 0.025915, 0.52947, 0.080614, 0.040315, 0.0026732]
Predicted label: 4
Correct prediction
Energy consumption = 151.282366 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 11 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 11 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 11 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.13976, 0.028347, 0.068633, 0.28404, 0.0066502, 0.31599, 0.026152, 0.0077492, 0.79876, 0.26184]
Predicted label: 8
Correct prediction
Energy consumption = 153.634893 pJ
sum error= 0
Actual label: 7
Output voltages: [0.12507, 0.2835, 0.24215, 0.15541, 0.0020858, 0.0010827, 0.0010659, 0.79855, 0.46978, 0.52583]
Predicted label: 7
Correct prediction
Energy consumption = 161.610914 pJ
sum error= 0
Actual label: 3
Output voltages: [0.22483, 0.034686, 0.030675, 0.79864, 0.0083128, 0.016916, 0.025119, 0.022786, 0.44712, 0.096697]
Predicted label: 3
Correct prediction
Energy consumption = 148.958555 pJ
sum error= 0
Actual label: 9
Output voltages: [0.28493, 0.052053, 0.022844, 0.71591, 0.028586, 0.053372, 0.014125, 0.052947, 0.071811, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 150.571839 pJ
sum error= 0
Actual label: 7
Output voltages: [0.2895, 0.0030844, 0.33308, 0.30652, 0.011266, 0.0011041, 0.001111, 0.79208, 0.17563, 0.61008]
Predicted label: 7
Correct prediction
Energy consumption = 141.968543 pJ
sum error= 0
Actual label: 4
Output voltages: [0.039596, 0.039714, 0.01896, 0.0025637, 0.77962, 0.007503, 0.13358, 0.016183, 0.056058, 0.75329]
Predicted label: 4
Correct prediction
Energy consumption = 153.898844 pJ
sum error= 0
Actual label: 4
Output voltages: [0.012406, 0.03974, 0.32014, 0.0044119, 0.79878, 0.0011379, 0.026733, 0.057943, 0.024444, 0.66302]
Predicted label: 4
Correct prediction
Energy consumption = 147.864479 pJ
sum error= 0
Actual label: 4
Output voltages: [0.002519, 0.0066962, 0.30391, 0.0060887, 0.79856, 0.0039047, 0.14153, 0.019695, 0.038765, 0.054484]
Predicted label: 4
Correct prediction
Energy consumption = 137.291213 pJ
sum error= 0
Actual label: 9
Output voltages: [0.41162, 0.0042684, 0.053448, 0.031094, 0.48575, 0.0087864, 0.0029471, 0.056962, 0.037066, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 150.700151 pJ
sum error= 0
Actual label: 2
Output voltages: [0.098779, 0.036151, 0.79877, 0.062279, 0.0072798, 0.0012285, 0.02296, 0.76335, 0.63896, 0.0061033]
Predicted label: 2
Correct prediction
Energy consumption = 147.131583 pJ
sum error= 0
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 12 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 12 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 12 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.052347, 0.0010713, 0.017486, 0.37193, 0.030712, 0.79792, 0.017372, 0.033839, 0.77847, 0.18366]
Predicted label: 5
Correct prediction
Energy consumption = 147.889778 pJ
sum error= 0
Actual label: 4
Output voltages: [0.0047002, 0.018707, 0.009597, 0.0023442, 0.79036, 0.024729, 0.1212, 0.046557, 0.42963, 0.15392]
Predicted label: 4
Correct prediction
Energy consumption = 149.553910 pJ
sum error= 0
Actual label: 7
Output voltages: [0.081798, 0.011199, 0.045998, 0.11456, 0.0015938, 0.015882, 0.0010717, 0.79843, 0.20021, 0.64552]
Predicted label: 7
Correct prediction
Energy consumption = 159.530025 pJ
sum error= 0
Actual label: 6
Output voltages: [0.040329, 0.28991, 0.42188, 0.0034279, 0.12731, 0.049786, 0.79866, 0.0041649, 0.40559, 0.0106]
Predicted label: 6
Correct prediction
Energy consumption = 153.814534 pJ
sum error= 0
Actual label: 7
Output voltages: [0.028107, 0.046855, 0.018774, 0.0078988, 0.46597, 0.002754, 0.001066, 0.79383, 0.54847, 0.58499]
Predicted label: 7
Correct prediction
Energy consumption = 147.685946 pJ
sum error= 0
Actual label: 9
Output voltages: [0.25205, 0.026807, 0.041064, 0.0069205, 0.79879, 0.0059255, 0.29618, 0.018133, 0.020444, 0.7747]
Predicted label: 4
Wrong prediction!
Energy consumption = 148.458894 pJ
sum error= 1
Actual label: 0
Output voltages: [0.79878, 0.028913, 0.21086, 0.0049835, 0.03765, 0.025407, 0.2292, 0.0029527, 0.33088, 0.03523]
Predicted label: 0
Correct prediction
Energy consumption = 151.871199 pJ
sum error= 1
Actual label: 5
Output voltages: [0.02096, 0.001124, 0.0021712, 0.13888, 0.027949, 0.79877, 0.27932, 0.012305, 0.76325, 0.013788]
Predicted label: 5
Correct prediction
Energy consumption = 147.481151 pJ
sum error= 1
Actual label: 8
Output voltages: [0.031204, 0.0053311, 0.027702, 0.212, 0.0031605, 0.047898, 0.018541, 0.0032529, 0.79873, 0.28062]
Predicted label: 8
Correct prediction
Energy consumption = 141.286322 pJ
sum error= 1
Actual label: 5
Output voltages: [0.064021, 0.0013282, 0.0011694, 0.4579, 0.026292, 0.79869, 0.18101, 0.013561, 0.73339, 0.16735]
Predicted label: 5
Correct prediction
Energy consumption = 142.462784 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 13 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 13 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 13 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.22435, 0.028103, 0.040256, 0.012193, 0.38025, 0.47065, 0.79869, 0.001185, 0.70136, 0.020521]
Predicted label: 6
Correct prediction
Energy consumption = 149.863961 pJ
sum error= 1
Actual label: 6
Output voltages: [0.10177, 0.035657, 0.036945, 0.012497, 0.37662, 0.14183, 0.79878, 0.0017668, 0.74516, 0.0098219]
Predicted label: 6
Correct prediction
Energy consumption = 138.247294 pJ
sum error= 1
Actual label: 5
Output voltages: [0.02389, 0.0010689, 0.00178, 0.2652, 0.19381, 0.79778, 0.1817, 0.033832, 0.79097, 0.070842]
Predicted label: 5
Correct prediction
Energy consumption = 140.321406 pJ
sum error= 1
Actual label: 7
Output voltages: [0.077855, 0.0035552, 0.035522, 0.52778, 0.0016663, 0.025172, 0.0011508, 0.79871, 0.45098, 0.28606]
Predicted label: 7
Correct prediction
Energy consumption = 146.603822 pJ
sum error= 1
Actual label: 8
Output voltages: [0.02919, 0.044943, 0.082794, 0.23096, 0.0026176, 0.032248, 0.040381, 0.016845, 0.79868, 0.10949]
Predicted label: 8
Correct prediction
Energy consumption = 151.512943 pJ
sum error= 1
Actual label: 1
Output voltages: [0.0021374, 0.79858, 0.049603, 0.032561, 0.0415, 0.0012678, 0.43605, 0.0081358, 0.22829, 0.044827]
Predicted label: 1
Correct prediction
Energy consumption = 161.809327 pJ
sum error= 1
Actual label: 0
Output voltages: [0.79866, 0.096646, 0.26351, 0.0066996, 0.012822, 0.0046773, 0.60485, 0.022434, 0.23206, 0.34945]
Predicted label: 0
Correct prediction
Energy consumption = 162.945415 pJ
sum error= 1
Actual label: 1
Output voltages: [0.033418, 0.79857, 0.23612, 0.049253, 0.14134, 0.0010671, 0.37039, 0.0091843, 0.035399, 0.042589]
Predicted label: 1
Correct prediction
Energy consumption = 158.453333 pJ
sum error= 1
Actual label: 6
Output voltages: [0.2834, 0.095551, 0.32961, 0.0018523, 0.49578, 0.25984, 0.79869, 0.0026308, 0.11462, 0.016468]
Predicted label: 6
Correct prediction
Energy consumption = 147.311031 pJ
sum error= 1
Actual label: 4
Output voltages: [0.011615, 0.0098522, 0.034513, 0.011518, 0.79314, 0.0064711, 0.04271, 0.0013773, 0.19346, 0.036905]
Predicted label: 4
Correct prediction
Energy consumption = 153.580920 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 14 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 14 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 14 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.10898, 0.0086724, 0.091106, 0.0018446, 0.36461, 0.08301, 0.79879, 0.0039057, 0.71956, 0.0065749]
Predicted label: 6
Correct prediction
Energy consumption = 154.562810 pJ
sum error= 1
Actual label: 7
Output voltages: [0.36805, 0.097378, 0.049529, 0.048516, 0.0015834, 0.0038631, 0.0010737, 0.79873, 0.2056, 0.48576]
Predicted label: 7
Correct prediction
Energy consumption = 162.573434 pJ
sum error= 1
Actual label: 3
Output voltages: [0.047585, 0.013749, 0.39437, 0.79853, 0.022711, 0.0010669, 0.001671, 0.0011432, 0.70756, 0.034248]
Predicted label: 3
Correct prediction
Energy consumption = 142.391550 pJ
sum error= 1
Actual label: 1
Output voltages: [0.019124, 0.79852, 0.040168, 0.031785, 0.061278, 0.0020109, 0.49446, 0.021782, 0.10713, 0.039437]
Predicted label: 1
Correct prediction
Energy consumption = 164.008491 pJ
sum error= 1
Actual label: 7
Output voltages: [0.45327, 0.0010664, 0.30339, 0.052089, 0.17923, 0.0011781, 0.0010994, 0.78134, 0.53754, 0.088779]
Predicted label: 7
Correct prediction
Energy consumption = 145.133799 pJ
sum error= 1
Actual label: 1
Output voltages: [0.0019078, 0.79873, 0.0051159, 0.59237, 0.20359, 0.025828, 0.0052733, 0.021957, 0.013201, 0.65805]
Predicted label: 1
Correct prediction
Energy consumption = 164.248725 pJ
sum error= 1
Actual label: 8
Output voltages: [0.030835, 0.037843, 0.15916, 0.18194, 0.0029373, 0.0164, 0.014193, 0.011046, 0.79879, 0.57341]
Predicted label: 8
Correct prediction
Energy consumption = 149.183280 pJ
sum error= 1
Actual label: 2
Output voltages: [0.46475, 0.018684, 0.79879, 0.042449, 0.017141, 0.0011025, 0.030338, 0.023112, 0.52157, 0.0080298]
Predicted label: 2
Correct prediction
Energy consumption = 148.405935 pJ
sum error= 1
Actual label: 0
Output voltages: [0.79879, 0.19182, 0.13395, 0.043642, 0.031885, 0.0067615, 0.6447, 0.0084709, 0.16987, 0.044225]
Predicted label: 0
Correct prediction
Energy consumption = 154.952542 pJ
sum error= 1
Actual label: 2
Output voltages: [0.45695, 0.0014676, 0.7978, 0.15972, 0.40208, 0.0011168, 0.022751, 0.0023483, 0.43611, 0.26906]
Predicted label: 2
Correct prediction
Energy consumption = 146.979553 pJ
sum error= 1
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 15 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 15 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 15 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.095955, 0.034974, 0.023823, 0.28419, 0.25856, 0.0444, 0.11259, 0.022779, 0.31924, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 160.760097 pJ
sum error= 1
Actual label: 9
Output voltages: [0.76696, 0.0010926, 0.21907, 0.025244, 0.42522, 0.0031628, 0.0010665, 0.002719, 0.29408, 0.76232]
Predicted label: 0
Wrong prediction!
Energy consumption = 146.711651 pJ
sum error= 2
Actual label: 5
Output voltages: [0.052321, 0.013735, 0.012734, 0.40065, 0.05162, 0.79876, 0.38724, 0.0041238, 0.39102, 0.051767]
Predicted label: 5
Correct prediction
Energy consumption = 140.759892 pJ
sum error= 2
Actual label: 5
Output voltages: [0.031075, 0.0010724, 0.0034315, 0.29671, 0.012484, 0.79495, 0.066699, 0.011328, 0.77171, 0.085432]
Predicted label: 5
Correct prediction
Energy consumption = 140.041585 pJ
sum error= 2
Actual label: 1
Output voltages: [0.042671, 0.79872, 0.035159, 0.10155, 0.002191, 0.0010789, 0.18614, 0.0028222, 0.14578, 0.085926]
Predicted label: 1
Correct prediction
Energy consumption = 168.795618 pJ
sum error= 2
Actual label: 5
Output voltages: [0.032321, 0.0011327, 0.0012552, 0.21023, 0.24018, 0.79877, 0.3281, 0.032034, 0.77634, 0.022779]
Predicted label: 5
Correct prediction
Energy consumption = 146.886950 pJ
sum error= 2
Actual label: 6
Output voltages: [0.032778, 0.034934, 0.50944, 0.0011033, 0.40683, 0.11573, 0.79879, 0.0010855, 0.29017, 0.0029668]
Predicted label: 6
Correct prediction
Energy consumption = 144.923861 pJ
sum error= 2
Actual label: 0
Output voltages: [0.79879, 0.041078, 0.054462, 0.019306, 0.029501, 0.0039488, 0.70329, 0.0075967, 0.044678, 0.44443]
Predicted label: 0
Correct prediction
Energy consumption = 152.277130 pJ
sum error= 2
Actual label: 3
Output voltages: [0.77995, 0.027221, 0.13748, 0.79877, 0.0035124, 0.02392, 0.11923, 0.028225, 0.20581, 0.0098315]
Predicted label: 3
Correct prediction
Energy consumption = 147.678606 pJ
sum error= 2
Actual label: 4
Output voltages: [0.016445, 0.28043, 0.031463, 0.55207, 0.79879, 0.0017173, 0.022133, 0.030256, 0.001635, 0.31072]
Predicted label: 4
Correct prediction
Energy consumption = 149.191239 pJ
sum error= 2
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 16 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 16 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 16 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0039666, 0.034869, 0.50075, 0.012688, 0.7987, 0.0012304, 0.33409, 0.0013783, 0.13838, 0.1792]
Predicted label: 4
Correct prediction
Energy consumption = 159.596325 pJ
sum error= 2
Actual label: 6
Output voltages: [0.25412, 0.0057945, 0.044932, 0.0042816, 0.34713, 0.107, 0.79772, 0.0010978, 0.72961, 0.0061471]
Predicted label: 6
Correct prediction
Energy consumption = 140.277308 pJ
sum error= 2
Actual label: 5
Output voltages: [0.029099, 0.0023218, 0.010989, 0.60552, 0.036197, 0.79832, 0.23101, 0.041535, 0.74287, 0.26519]
Predicted label: 5
Correct prediction
Energy consumption = 145.420860 pJ
sum error= 2
Actual label: 4
Output voltages: [0.009777, 0.010173, 0.27204, 0.025866, 0.79862, 0.0026121, 0.06966, 0.10098, 0.0341, 0.038388]
Predicted label: 4
Correct prediction
Energy consumption = 157.402994 pJ
sum error= 2
Actual label: 6
Output voltages: [0.066655, 0.063072, 0.45287, 0.0013307, 0.18193, 0.016008, 0.79848, 0.0028636, 0.19566, 0.003043]
Predicted label: 6
Correct prediction
Energy consumption = 151.201189 pJ
sum error= 2
Actual label: 5
Output voltages: [0.045236, 0.0010852, 0.0020297, 0.45025, 0.016307, 0.79689, 0.041963, 0.18348, 0.76215, 0.070876]
Predicted label: 5
Correct prediction
Energy consumption = 143.187482 pJ
sum error= 2
Actual label: 4
Output voltages: [0.0023444, 0.031292, 0.043457, 0.0030883, 0.79875, 0.0021331, 0.59759, 0.27104, 0.022623, 0.022618]
Predicted label: 4
Correct prediction
Energy consumption = 156.476798 pJ
sum error= 2
Actual label: 5
Output voltages: [0.39572, 0.0018535, 0.0011097, 0.65629, 0.09089, 0.79874, 0.22441, 0.0093266, 0.32888, 0.007387]
Predicted label: 5
Correct prediction
Energy consumption = 134.984700 pJ
sum error= 2
Actual label: 1
Output voltages: [0.036623, 0.79863, 0.077332, 0.054988, 0.011514, 0.0016573, 0.23282, 0.001685, 0.60409, 0.023282]
Predicted label: 1
Correct prediction
Energy consumption = 161.588253 pJ
sum error= 2
Actual label: 4
Output voltages: [0.015783, 0.0093242, 0.04172, 0.025075, 0.79868, 0.0014873, 0.058722, 0.19133, 0.11555, 0.016621]
Predicted label: 4
Correct prediction
Energy consumption = 157.155379 pJ
sum error= 2
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 17 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 17 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 17 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.069237, 0.023419, 0.36593, 0.11049, 0.79876, 0.010662, 0.032078, 0.014336, 0.015563, 0.53762]
Predicted label: 4
Correct prediction
Energy consumption = 156.635527 pJ
sum error= 2
Actual label: 7
Output voltages: [0.3266, 0.004493, 0.6889, 0.090036, 0.028551, 0.0011549, 0.0010816, 0.77072, 0.79415, 0.32687]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.355503 pJ
sum error= 3
Actual label: 2
Output voltages: [0.53473, 0.13108, 0.79879, 0.54003, 0.0011566, 0.0010667, 0.041375, 0.021183, 0.672, 0.0011545]
Predicted label: 2
Correct prediction
Energy consumption = 137.365034 pJ
sum error= 3
Actual label: 3
Output voltages: [0.52553, 0.015572, 0.045404, 0.79875, 0.007674, 0.06387, 0.0071748, 0.023869, 0.21968, 0.013233]
Predicted label: 3
Correct prediction
Energy consumption = 139.741351 pJ
sum error= 3
Actual label: 2
Output voltages: [0.73119, 0.052293, 0.79874, 0.22924, 0.025598, 0.0011468, 0.2293, 0.034285, 0.46861, 0.066521]
Predicted label: 2
Correct prediction
Energy consumption = 147.006164 pJ
sum error= 3
Actual label: 7
Output voltages: [0.44536, 0.65381, 0.2526, 0.44715, 0.0020425, 0.001101, 0.0015311, 0.79218, 0.68522, 0.13128]
Predicted label: 7
Correct prediction
Energy consumption = 159.894987 pJ
sum error= 3
Actual label: 1
Output voltages: [0.32999, 0.79836, 0.072723, 0.071423, 0.0068564, 0.0020216, 0.74699, 0.0099805, 0.035166, 0.076785]
Predicted label: 1
Correct prediction
Energy consumption = 155.703971 pJ
sum error= 3
Actual label: 8
Output voltages: [0.50939, 0.021538, 0.075564, 0.28571, 0.040862, 0.0015209, 0.0387, 0.0010671, 0.7984, 0.41776]
Predicted label: 8
Correct prediction
Energy consumption = 164.056542 pJ
sum error= 3
Actual label: 1
Output voltages: [0.015876, 0.79855, 0.10798, 0.14697, 0.0048249, 0.0011274, 0.68196, 0.010215, 0.018668, 0.012119]
Predicted label: 1
Correct prediction
Energy consumption = 159.702522 pJ
sum error= 3
Actual label: 8
Output voltages: [0.030888, 0.044542, 0.39331, 0.029432, 0.035346, 0.0029249, 0.36599, 0.0047256, 0.79878, 0.3517]
Predicted label: 8
Correct prediction
Energy consumption = 152.278303 pJ
sum error= 3
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 18 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 18 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 18 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.027049, 0.79856, 0.026729, 0.16349, 0.12106, 0.0030751, 0.32374, 0.0010794, 0.25876, 0.29479]
Predicted label: 1
Correct prediction
Energy consumption = 166.287186 pJ
sum error= 3
Actual label: 8
Output voltages: [0.047106, 0.024452, 0.75605, 0.047737, 0.0081357, 0.0019399, 0.17761, 0.013167, 0.79874, 0.10395]
Predicted label: 8
Correct prediction
Energy consumption = 151.180300 pJ
sum error= 3
Actual label: 5
Output voltages: [0.025278, 0.001491, 0.0084464, 0.27612, 0.016148, 0.79851, 0.081064, 0.003968, 0.73685, 0.028886]
Predicted label: 5
Correct prediction
Energy consumption = 146.393700 pJ
sum error= 3
Actual label: 0
Output voltages: [0.79879, 0.049471, 0.036255, 0.005024, 0.0043699, 0.0038316, 0.5182, 0.0054871, 0.044678, 0.03623]
Predicted label: 0
Correct prediction
Energy consumption = 149.968591 pJ
sum error= 3
Actual label: 8
Output voltages: [0.52222, 0.0010708, 0.65052, 0.79325, 0.0025748, 0.0010666, 0.0017508, 0.24572, 0.74862, 0.015574]
Predicted label: 3
Wrong prediction!
Energy consumption = 148.483408 pJ
sum error= 4
Actual label: 9
Output voltages: [0.070991, 0.011707, 0.0014556, 0.06623, 0.62573, 0.0040562, 0.25667, 0.0073655, 0.028407, 0.78399]
Predicted label: 9
Correct prediction
Energy consumption = 149.340577 pJ
sum error= 4
Actual label: 2
Output voltages: [0.46213, 0.04512, 0.79879, 0.18781, 0.021498, 0.0012779, 0.17155, 0.031718, 0.5169, 0.038103]
Predicted label: 2
Correct prediction
Energy consumption = 148.737190 pJ
sum error= 4
Actual label: 5
Output voltages: [0.032739, 0.0011094, 0.015762, 0.23839, 0.011473, 0.79817, 0.1143, 0.036608, 0.78433, 0.094572]
Predicted label: 5
Correct prediction
Energy consumption = 146.358007 pJ
sum error= 4
Actual label: 0
Output voltages: [0.79731, 0.026632, 0.066158, 0.026283, 0.021338, 0.032328, 0.4776, 0.003695, 0.38575, 0.011932]
Predicted label: 0
Correct prediction
Energy consumption = 153.212275 pJ
sum error= 4
Actual label: 1
Output voltages: [0.0010975, 0.79859, 0.026357, 0.72749, 0.38326, 0.0018238, 0.0046867, 0.054205, 0.2033, 0.036412]
Predicted label: 1
Correct prediction
Energy consumption = 167.169337 pJ
sum error= 4
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 19 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 19 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 19 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.06895, 0.79856, 0.0098298, 0.20538, 0.026298, 0.0011426, 0.038561, 0.0019288, 0.63739, 0.2279]
Predicted label: 1
Correct prediction
Energy consumption = 163.109885 pJ
sum error= 4
Actual label: 1
Output voltages: [0.0010746, 0.79879, 0.70898, 0.59595, 0.13547, 0.0029719, 0.0037696, 0.23309, 0.019542, 0.1043]
Predicted label: 1
Correct prediction
Energy consumption = 156.245182 pJ
sum error= 4
Actual label: 0
Output voltages: [0.79876, 0.030931, 0.068613, 0.024322, 0.010941, 0.0064041, 0.38341, 0.030323, 0.17803, 0.024569]
Predicted label: 0
Correct prediction
Energy consumption = 149.348205 pJ
sum error= 4
Actual label: 9
Output voltages: [0.18024, 0.0029904, 0.030202, 0.031097, 0.3891, 0.0039525, 0.0010678, 0.25051, 0.23133, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 157.664004 pJ
sum error= 4
Actual label: 0
Output voltages: [0.79875, 0.088727, 0.12871, 0.038066, 0.021074, 0.0066028, 0.34163, 0.026052, 0.14951, 0.36824]
Predicted label: 0
Correct prediction
Energy consumption = 160.827322 pJ
sum error= 4
Actual label: 3
Output voltages: [0.029576, 0.0076035, 0.17329, 0.7987, 0.029624, 0.0011387, 0.036972, 0.029249, 0.55235, 0.18556]
Predicted label: 3
Correct prediction
Energy consumption = 153.210806 pJ
sum error= 4
Actual label: 1
Output voltages: [0.024687, 0.79844, 0.107, 0.030412, 0.015815, 0.0012741, 0.61102, 0.0042333, 0.077382, 0.1219]
Predicted label: 1
Correct prediction
Energy consumption = 163.544881 pJ
sum error= 4
Actual label: 6
Output voltages: [0.14974, 0.044978, 0.35385, 0.0011702, 0.17303, 0.1327, 0.79875, 0.006665, 0.69287, 0.014507]
Predicted label: 6
Correct prediction
Energy consumption = 147.813521 pJ
sum error= 4
Actual label: 4
Output voltages: [0.0022872, 0.0052729, 0.049508, 0.027998, 0.79871, 0.001589, 0.06756, 0.084677, 0.042463, 0.015289]
Predicted label: 4
Correct prediction
Energy consumption = 155.196826 pJ
sum error= 4
Actual label: 2
Output voltages: [0.051865, 0.018396, 0.79865, 0.48274, 0.0062197, 0.001093, 0.20416, 0.36073, 0.75704, 0.0034323]
Predicted label: 2
Correct prediction
Energy consumption = 148.600329 pJ
sum error= 4
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 20 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 20 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 20 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.74735, 0.0024059, 0.060695, 0.79879, 0.022429, 0.0026522, 0.0036574, 0.011658, 0.68624, 0.0030471]
Predicted label: 3
Correct prediction
Energy consumption = 148.860292 pJ
sum error= 4
Actual label: 6
Output voltages: [0.2293, 0.049293, 0.2555, 0.0071825, 0.32641, 0.22016, 0.79876, 0.0014222, 0.42274, 0.021651]
Predicted label: 6
Correct prediction
Energy consumption = 139.641722 pJ
sum error= 4
Actual label: 1
Output voltages: [0.014225, 0.79868, 0.016363, 0.071018, 0.016964, 0.005128, 0.60038, 0.0014362, 0.29248, 0.014658]
Predicted label: 1
Correct prediction
Energy consumption = 152.644477 pJ
sum error= 4
Actual label: 1
Output voltages: [0.074436, 0.79861, 0.002083, 0.061856, 0.30797, 0.031599, 0.34324, 0.0013278, 0.017126, 0.56965]
Predicted label: 1
Correct prediction
Energy consumption = 161.577918 pJ
sum error= 4
Actual label: 1
Output voltages: [0.0087564, 0.79863, 0.005933, 0.0058328, 0.12914, 0.0024101, 0.42901, 0.0026925, 0.58083, 0.075862]
Predicted label: 1
Correct prediction
Energy consumption = 150.269267 pJ
sum error= 4
Actual label: 3
Output voltages: [0.12105, 0.022941, 0.044644, 0.79858, 0.02858, 0.011929, 0.026744, 0.043113, 0.4324, 0.15846]
Predicted label: 3
Correct prediction
Energy consumption = 149.226589 pJ
sum error= 4
Actual label: 9
Output voltages: [0.074789, 0.014279, 0.11074, 0.019528, 0.00643, 0.02436, 0.0029228, 0.047641, 0.78921, 0.77189]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.689600 pJ
sum error= 5
Actual label: 5
Output voltages: [0.26928, 0.0011491, 0.0010849, 0.27829, 0.0056855, 0.79736, 0.042406, 0.39544, 0.76908, 0.0093525]
Predicted label: 5
Correct prediction
Energy consumption = 146.195628 pJ
sum error= 5
Actual label: 2
Output voltages: [0.53304, 0.005211, 0.79869, 0.173, 0.027937, 0.0010672, 0.073849, 0.34768, 0.38553, 0.0036205]
Predicted label: 2
Correct prediction
Energy consumption = 144.040430 pJ
sum error= 5
Actual label: 9
Output voltages: [0.27267, 0.0010659, 0.0017463, 0.24366, 0.26264, 0.029111, 0.0024925, 0.046329, 0.32644, 0.79171]
Predicted label: 9
Correct prediction
Energy consumption = 155.485575 pJ
sum error= 5
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 21 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 21 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 21 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0078946, 0.0048411, 0.20565, 0.01073, 0.79867, 0.0013976, 0.27201, 0.032162, 0.084544, 0.044687]
Predicted label: 4
Correct prediction
Energy consumption = 160.280524 pJ
sum error= 5
Actual label: 5
Output voltages: [0.023223, 0.0073151, 0.0016854, 0.43075, 0.12186, 0.79813, 0.049383, 0.0010967, 0.57863, 0.010992]
Predicted label: 5
Correct prediction
Energy consumption = 141.433096 pJ
sum error= 5
Actual label: 9
Output voltages: [0.24554, 0.0022562, 0.031123, 0.18602, 0.028599, 0.18076, 0.0012331, 0.20151, 0.047701, 0.79765]
Predicted label: 9
Correct prediction
Energy consumption = 153.807754 pJ
sum error= 5
Actual label: 3
Output voltages: [0.28431, 0.06951, 0.39589, 0.79874, 0.0056395, 0.0031867, 0.0042274, 0.042508, 0.35263, 0.17423]
Predicted label: 3
Correct prediction
Energy consumption = 145.225536 pJ
sum error= 5
Actual label: 9
Output voltages: [0.28977, 0.0031477, 0.03634, 0.018284, 0.053498, 0.0015121, 0.0011952, 0.042289, 0.68768, 0.78895]
Predicted label: 9
Correct prediction
Energy consumption = 150.574971 pJ
sum error= 5
Actual label: 0
Output voltages: [0.79879, 0.084019, 0.12398, 0.035907, 0.015014, 0.016509, 0.29917, 0.012312, 0.039215, 0.14399]
Predicted label: 0
Correct prediction
Energy consumption = 156.621622 pJ
sum error= 5
Actual label: 3
Output voltages: [0.33448, 0.016187, 0.071043, 0.79873, 0.0076408, 0.0026059, 0.011382, 0.0087284, 0.49963, 0.033063]
Predicted label: 3
Correct prediction
Energy consumption = 147.325385 pJ
sum error= 5
Actual label: 6
Output voltages: [0.57248, 0.0021862, 0.0029801, 0.26114, 0.19957, 0.79852, 0.78758, 0.0057949, 0.67668, 0.014626]
Predicted label: 5
Wrong prediction!
Energy consumption = 147.660827 pJ
sum error= 6
Actual label: 5
Output voltages: [0.038409, 0.005106, 0.0010661, 0.072331, 0.028707, 0.79877, 0.37127, 0.016658, 0.66274, 0.021311]
Predicted label: 5
Correct prediction
Energy consumption = 148.487176 pJ
sum error= 6
Actual label: 5
Output voltages: [0.2355, 0.0018653, 0.0011147, 0.6908, 0.024237, 0.79833, 0.23477, 0.017396, 0.70108, 0.3469]
Predicted label: 5
Correct prediction
Energy consumption = 142.394751 pJ
sum error= 6
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 22 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 22 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 22 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.20775, 0.039608, 0.018472, 0.0068543, 0.059417, 0.010158, 0.0012202, 0.79855, 0.28037, 0.13264]
Predicted label: 7
Correct prediction
Energy consumption = 157.596897 pJ
sum error= 6
Actual label: 2
Output voltages: [0.73726, 0.0010664, 0.79664, 0.75848, 0.0019672, 0.0028264, 0.0019412, 0.031755, 0.37448, 0.028042]
Predicted label: 2
Correct prediction
Energy consumption = 147.244494 pJ
sum error= 6
Actual label: 2
Output voltages: [0.37191, 0.0015497, 0.7987, 0.025301, 0.021537, 0.0012515, 0.07493, 0.16424, 0.73048, 0.016442]
Predicted label: 2
Correct prediction
Energy consumption = 136.874262 pJ
sum error= 6
Actual label: 7
Output voltages: [0.26438, 0.28759, 0.065925, 0.078928, 0.013393, 0.0036279, 0.0026655, 0.79858, 0.16058, 0.26007]
Predicted label: 7
Correct prediction
Energy consumption = 152.641539 pJ
sum error= 6
Actual label: 1
Output voltages: [0.047061, 0.79878, 0.010913, 0.007132, 0.085543, 0.0016601, 0.44392, 0.0016418, 0.46427, 0.0089281]
Predicted label: 1
Correct prediction
Energy consumption = 155.501608 pJ
sum error= 6
Actual label: 2
Output voltages: [0.11908, 0.11207, 0.79878, 0.02678, 0.0016568, 0.0013093, 0.048786, 0.063558, 0.57919, 0.015647]
Predicted label: 2
Correct prediction
Energy consumption = 137.400148 pJ
sum error= 6
Actual label: 8
Output voltages: [0.015413, 0.24194, 0.14369, 0.10195, 0.0083283, 0.019004, 0.0076756, 0.029835, 0.7987, 0.44797]
Predicted label: 8
Correct prediction
Energy consumption = 140.957521 pJ
sum error= 6
Actual label: 4
Output voltages: [0.0060198, 0.025397, 0.024964, 0.058908, 0.79865, 0.0012023, 0.20762, 0.12327, 0.044583, 0.0060778]
Predicted label: 4
Correct prediction
Energy consumption = 154.655247 pJ
sum error= 6
Actual label: 1
Output voltages: [0.0070588, 0.79858, 0.052995, 0.033517, 0.08585, 0.0015718, 0.48388, 0.02075, 0.53208, 0.017591]
Predicted label: 1
Correct prediction
Energy consumption = 161.429136 pJ
sum error= 6
Actual label: 7
Output voltages: [0.36326, 0.048526, 0.30144, 0.20647, 0.008008, 0.0011207, 0.001074, 0.79879, 0.026314, 0.19831]
Predicted label: 7
Correct prediction
Energy consumption = 152.010668 pJ
sum error= 6
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 23 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 23 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 23 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.061563, 0.0029082, 0.043388, 0.79878, 0.27775, 0.15197, 0.085425, 0.010967, 0.28989, 0.044298]
Predicted label: 3
Correct prediction
Energy consumption = 152.322679 pJ
sum error= 6
Actual label: 3
Output voltages: [0.23267, 0.029149, 0.056817, 0.79863, 0.012255, 0.025671, 0.014367, 0.0033235, 0.43619, 0.054692]
Predicted label: 3
Correct prediction
Energy consumption = 138.582245 pJ
sum error= 6
Actual label: 8
Output voltages: [0.034912, 0.0011898, 0.10331, 0.14666, 0.0034833, 0.43638, 0.28865, 0.0010833, 0.79784, 0.17927]
Predicted label: 8
Correct prediction
Energy consumption = 149.796716 pJ
sum error= 6
Actual label: 8
Output voltages: [0.007455, 0.021873, 0.042996, 0.032978, 0.011585, 0.0020915, 0.015983, 0.047713, 0.79879, 0.60097]
Predicted label: 8
Correct prediction
Energy consumption = 144.583456 pJ
sum error= 6
Actual label: 7
Output voltages: [0.19917, 0.25122, 0.30707, 0.42362, 0.0011417, 0.0015138, 0.0010675, 0.79878, 0.31733, 0.19393]
Predicted label: 7
Correct prediction
Energy consumption = 156.288892 pJ
sum error= 6
Actual label: 9
Output voltages: [0.62754, 0.0041469, 0.11729, 0.012663, 0.05404, 0.044913, 0.016833, 0.039704, 0.53803, 0.79642]
Predicted label: 9
Correct prediction
Energy consumption = 148.839957 pJ
sum error= 6
Actual label: 2
Output voltages: [0.68019, 0.24721, 0.79879, 0.020436, 0.013815, 0.0013345, 0.32118, 0.056015, 0.37451, 0.054638]
Predicted label: 2
Correct prediction
Energy consumption = 148.596102 pJ
sum error= 6
Actual label: 2
Output voltages: [0.27171, 0.62855, 0.79879, 0.0304, 0.042754, 0.0013271, 0.34993, 0.041618, 0.038015, 0.14069]
Predicted label: 2
Correct prediction
Energy consumption = 135.860058 pJ
sum error= 6
Actual label: 4
Output voltages: [0.010119, 0.027627, 0.11336, 0.0067739, 0.79875, 0.0034366, 0.32001, 0.14501, 0.048108, 0.05055]
Predicted label: 4
Correct prediction
Energy consumption = 146.641135 pJ
sum error= 6
Actual label: 1
Output voltages: [0.014339, 0.79867, 0.058742, 0.75853, 0.013604, 0.023245, 0.050136, 0.0057357, 0.04343, 0.26097]
Predicted label: 1
Correct prediction
Energy consumption = 168.394292 pJ
sum error= 6
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 24 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 24 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 24 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.017827, 0.0010715, 0.0019177, 0.13259, 0.10914, 0.79549, 0.24149, 0.014645, 0.77566, 0.076451]
Predicted label: 5
Correct prediction
Energy consumption = 146.825882 pJ
sum error= 6
Actual label: 9
Output voltages: [0.6225, 0.0011072, 0.062397, 0.012717, 0.15985, 0.032206, 0.017075, 0.0010992, 0.73793, 0.5985]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.313493 pJ
sum error= 7
Actual label: 8
Output voltages: [0.03331, 0.18508, 0.2776, 0.024078, 0.025604, 0.001074, 0.057739, 0.0041597, 0.79862, 0.47246]
Predicted label: 8
Correct prediction
Energy consumption = 140.284189 pJ
sum error= 7
Actual label: 7
Output voltages: [0.043667, 0.0088343, 0.21591, 0.56147, 0.05937, 0.0010871, 0.0010726, 0.79721, 0.30883, 0.66477]
Predicted label: 7
Correct prediction
Energy consumption = 145.301293 pJ
sum error= 7
Actual label: 2
Output voltages: [0.46317, 0.03111, 0.79879, 0.18256, 0.0048193, 0.0017433, 0.011566, 0.72663, 0.56241, 0.028905]
Predicted label: 2
Correct prediction
Energy consumption = 143.366053 pJ
sum error= 7
Actual label: 3
Output voltages: [0.42772, 0.0042328, 0.021434, 0.79758, 0.0010704, 0.48784, 0.27635, 0.27302, 0.48318, 0.0010972]
Predicted label: 3
Correct prediction
Energy consumption = 139.492730 pJ
sum error= 7
Actual label: 0
Output voltages: [0.79785, 0.044989, 0.083554, 0.0057639, 0.015368, 0.15316, 0.49331, 0.0011129, 0.036236, 0.55451]
Predicted label: 0
Correct prediction
Energy consumption = 151.198561 pJ
sum error= 7
Actual label: 4
Output voltages: [0.51044, 0.35313, 0.43077, 0.0032541, 0.47339, 0.011514, 0.77783, 0.0012124, 0.19561, 0.0020995]
Predicted label: 6
Wrong prediction!
Energy consumption = 146.053309 pJ
sum error= 8
Actual label: 4
Output voltages: [0.0032059, 0.014568, 0.09512, 0.015747, 0.79867, 0.001172, 0.12268, 0.044545, 0.020788, 0.074128]
Predicted label: 4
Correct prediction
Energy consumption = 147.373156 pJ
sum error= 8
Actual label: 2
Output voltages: [0.061881, 0.30544, 0.79879, 0.23433, 0.0069813, 0.001312, 0.12341, 0.021684, 0.51141, 0.022581]
Predicted label: 2
Correct prediction
Energy consumption = 150.795465 pJ
sum error= 8
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 25 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 25 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 25 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.1058, 0.032621, 0.31181, 0.040558, 0.79831, 0.0010732, 0.023559, 0.032664, 0.043829, 0.65506]
Predicted label: 4
Correct prediction
Energy consumption = 162.534389 pJ
sum error= 8
Actual label: 1
Output voltages: [0.037306, 0.79872, 0.027272, 0.026868, 0.091112, 0.011715, 0.50336, 0.001231, 0.19194, 0.010475]
Predicted label: 1
Correct prediction
Energy consumption = 160.551802 pJ
sum error= 8
Actual label: 9
Output voltages: [0.17169, 0.023117, 0.061279, 0.046016, 0.040026, 0.012705, 0.0091721, 0.023835, 0.64418, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 156.190501 pJ
sum error= 8
Actual label: 5
Output voltages: [0.035299, 0.0010661, 0.0038534, 0.56421, 0.012476, 0.7982, 0.022664, 0.056081, 0.75638, 0.2223]
Predicted label: 5
Correct prediction
Energy consumption = 149.341415 pJ
sum error= 8
Actual label: 7
Output voltages: [0.17772, 0.030557, 0.11967, 0.3507, 0.0061875, 0.001076, 0.00326, 0.79866, 0.035038, 0.37999]
Predicted label: 7
Correct prediction
Energy consumption = 158.695881 pJ
sum error= 8
Actual label: 7
Output voltages: [0.3323, 0.15615, 0.76057, 0.30837, 0.0018838, 0.0012802, 0.0052916, 0.7908, 0.26837, 0.057594]
Predicted label: 7
Correct prediction
Energy consumption = 148.724452 pJ
sum error= 8
Actual label: 2
Output voltages: [0.26876, 0.49405, 0.7987, 0.29431, 0.0043264, 0.0011893, 0.15646, 0.0091708, 0.29619, 0.042314]
Predicted label: 2
Correct prediction
Energy consumption = 143.538395 pJ
sum error= 8
Actual label: 8
Output voltages: [0.20452, 0.10176, 0.069386, 0.40761, 0.0014231, 0.00229, 0.67687, 0.0034102, 0.79764, 0.032435]
Predicted label: 8
Correct prediction
Energy consumption = 152.688382 pJ
sum error= 8
Actual label: 2
Output voltages: [0.73776, 0.079852, 0.79841, 0.49403, 0.0062316, 0.0010676, 0.33242, 0.013261, 0.20577, 0.040236]
Predicted label: 2
Correct prediction
Energy consumption = 140.406227 pJ
sum error= 8
Actual label: 6
Output voltages: [0.78222, 0.015391, 0.016654, 0.0026463, 0.16044, 0.48121, 0.79735, 0.013238, 0.31527, 0.018558]
Predicted label: 6
Correct prediction
Energy consumption = 150.856907 pJ
sum error= 8
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 26 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 26 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 26 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.018678, 0.041884, 0.46263, 0.024046, 0.01749, 0.02732, 0.023417, 0.005895, 0.7987, 0.062234]
Predicted label: 8
Correct prediction
Energy consumption = 141.519705 pJ
sum error= 8
Actual label: 5
Output voltages: [0.31205, 0.017976, 0.001192, 0.069306, 0.0041075, 0.7987, 0.013025, 0.0016162, 0.78923, 0.0013886]
Predicted label: 5
Correct prediction
Energy consumption = 151.735531 pJ
sum error= 8
Actual label: 7
Output voltages: [0.20718, 0.032337, 0.011498, 0.29202, 0.0075434, 0.0047113, 0.0011112, 0.79877, 0.63835, 0.741]
Predicted label: 7
Correct prediction
Energy consumption = 152.471132 pJ
sum error= 8
Actual label: 7
Output voltages: [0.12377, 0.049734, 0.098826, 0.10845, 0.010314, 0.0010922, 0.0010678, 0.79869, 0.17288, 0.41289]
Predicted label: 7
Correct prediction
Energy consumption = 142.321620 pJ
sum error= 8
Actual label: 9
Output voltages: [0.025384, 0.14034, 0.24344, 0.039488, 0.66891, 0.03182, 0.0053888, 0.0070102, 0.064218, 0.79843]
Predicted label: 9
Correct prediction
Energy consumption = 157.264670 pJ
sum error= 8
Actual label: 1
Output voltages: [0.0042984, 0.79842, 0.10527, 0.051926, 0.013648, 0.0071799, 0.35805, 0.009104, 0.15214, 0.048946]
Predicted label: 1
Correct prediction
Energy consumption = 157.629279 pJ
sum error= 8
Actual label: 8
Output voltages: [0.63383, 0.019582, 0.051796, 0.74128, 0.0011752, 0.019268, 0.032767, 0.0024784, 0.76942, 0.17807]
Predicted label: 8
Correct prediction
Energy consumption = 159.338749 pJ
sum error= 8
Actual label: 1
Output voltages: [0.041013, 0.79852, 0.068867, 0.27482, 0.045907, 0.0051183, 0.76198, 0.0019625, 0.0292, 0.11813]
Predicted label: 1
Correct prediction
Energy consumption = 158.796466 pJ
sum error= 8
Actual label: 8
Output voltages: [0.22515, 0.0010676, 0.3261, 0.0093307, 0.015671, 0.33511, 0.019157, 0.0017845, 0.79849, 0.25492]
Predicted label: 8
Correct prediction
Energy consumption = 150.014544 pJ
sum error= 8
Actual label: 0
Output voltages: [0.79879, 0.0093833, 0.0693, 0.013823, 0.0014939, 0.021133, 0.49023, 0.032874, 0.18726, 0.012526]
Predicted label: 0
Correct prediction
Energy consumption = 142.470958 pJ
sum error= 8
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 27 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 27 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 27 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.54774, 0.0064976, 0.20368, 0.79867, 0.02776, 0.14477, 0.0046097, 0.018767, 0.35932, 0.047592]
Predicted label: 3
Correct prediction
Energy consumption = 144.175860 pJ
sum error= 8
Actual label: 0
Output voltages: [0.79879, 0.091811, 0.19795, 0.011421, 0.031904, 0.0014564, 0.75697, 0.0087007, 0.14266, 0.29324]
Predicted label: 0
Correct prediction
Energy consumption = 158.771050 pJ
sum error= 8
Actual label: 1
Output voltages: [0.0081759, 0.79851, 0.051328, 0.090588, 0.028197, 0.014451, 0.3113, 0.01796, 0.49873, 0.050821]
Predicted label: 1
Correct prediction
Energy consumption = 165.229154 pJ
sum error= 8
Actual label: 9
Output voltages: [0.04952, 0.0031516, 0.027871, 0.028282, 0.068574, 0.020485, 0.015112, 0.047915, 0.6072, 0.79559]
Predicted label: 9
Correct prediction
Energy consumption = 155.644284 pJ
sum error= 8
Actual label: 9
Output voltages: [0.14036, 0.015605, 0.018043, 0.68951, 0.25472, 0.32583, 0.0087773, 0.035835, 0.23597, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 144.765696 pJ
sum error= 8
Actual label: 4
Output voltages: [0.0035286, 0.028279, 0.22448, 0.019791, 0.79863, 0.0016929, 0.11394, 0.027426, 0.02346, 0.17075]
Predicted label: 4
Correct prediction
Energy consumption = 151.079794 pJ
sum error= 8
Actual label: 1
Output voltages: [0.032532, 0.79869, 0.35958, 0.034785, 0.05009, 0.0010859, 0.57216, 0.0015151, 0.08904, 0.020855]
Predicted label: 1
Correct prediction
Energy consumption = 164.837040 pJ
sum error= 8
Actual label: 8
Output voltages: [0.018666, 0.077632, 0.11389, 0.021836, 0.018732, 0.0035358, 0.039171, 0.010034, 0.79879, 0.40182]
Predicted label: 8
Correct prediction
Energy consumption = 145.424421 pJ
sum error= 8
Actual label: 2
Output voltages: [0.086992, 0.05274, 0.7987, 0.040678, 0.030656, 0.0012144, 0.36511, 0.037799, 0.39411, 0.011462]
Predicted label: 2
Correct prediction
Energy consumption = 148.872425 pJ
sum error= 8
Actual label: 1
Output voltages: [0.15491, 0.79838, 0.027166, 0.044469, 0.011029, 0.0043785, 0.41272, 0.0021391, 0.17795, 0.26732]
Predicted label: 1
Correct prediction
Energy consumption = 162.818506 pJ
sum error= 8
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 28 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 28 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 28 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.39011, 0.20609, 0.79877, 0.15214, 0.011608, 0.0012164, 0.30935, 0.021092, 0.65678, 0.036343]
Predicted label: 2
Correct prediction
Energy consumption = 151.533641 pJ
sum error= 8
Actual label: 9
Output voltages: [0.21524, 0.015605, 0.013379, 0.021034, 0.16514, 0.023128, 0.0040087, 0.0073678, 0.44767, 0.79711]
Predicted label: 9
Correct prediction
Energy consumption = 150.570344 pJ
sum error= 8
Actual label: 7
Output voltages: [0.0017439, 0.29372, 0.28961, 0.79398, 0.0033144, 0.0012901, 0.016418, 0.77008, 0.6884, 0.046986]
Predicted label: 3
Wrong prediction!
Energy consumption = 153.920290 pJ
sum error= 9
Actual label: 5
Output voltages: [0.011721, 0.011214, 0.0029593, 0.46725, 0.010657, 0.79879, 0.38255, 0.0080431, 0.74092, 0.0044822]
Predicted label: 5
Correct prediction
Energy consumption = 140.914957 pJ
sum error= 9
Actual label: 9
Output voltages: [0.43405, 0.0013128, 0.35449, 0.022507, 0.39504, 0.0027778, 0.055433, 0.0080481, 0.031534, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 155.181751 pJ
sum error= 9
Actual label: 2
Output voltages: [0.63599, 0.16776, 0.79855, 0.19969, 0.031576, 0.0012313, 0.20338, 0.036672, 0.43922, 0.031049]
Predicted label: 2
Correct prediction
Energy consumption = 153.789495 pJ
sum error= 9
Actual label: 6
Output voltages: [0.26809, 0.026615, 0.026971, 0.0088055, 0.11436, 0.16503, 0.7976, 0.011053, 0.77524, 0.012285]
Predicted label: 6
Correct prediction
Energy consumption = 149.840160 pJ
sum error= 9
Actual label: 4
Output voltages: [0.013836, 0.021589, 0.12099, 0.055483, 0.79876, 0.0014343, 0.033209, 0.32702, 0.011928, 0.42866]
Predicted label: 4
Correct prediction
Energy consumption = 147.803837 pJ
sum error= 9
Actual label: 1
Output voltages: [0.0011632, 0.79876, 0.0012279, 0.019296, 0.026434, 0.016242, 0.49256, 0.21137, 0.60635, 0.0072902]
Predicted label: 1
Correct prediction
Energy consumption = 157.243370 pJ
sum error= 9
Actual label: 5
Output voltages: [0.016782, 0.0013319, 0.037415, 0.065766, 0.0094456, 0.73862, 0.36224, 0.005101, 0.78495, 0.047324]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.252359 pJ
sum error= 10
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 29 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 29 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 29 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.037116, 0.0019599, 0.0015582, 0.38814, 0.58064, 0.54523, 0.28903, 0.0012628, 0.75546, 0.033708]
Predicted label: 8
Correct prediction
Energy consumption = 153.946481 pJ
sum error= 10
Actual label: 2
Output voltages: [0.26372, 0.3057, 0.79844, 0.19095, 0.0027403, 0.0012502, 0.10093, 0.0015419, 0.33309, 0.01139]
Predicted label: 2
Correct prediction
Energy consumption = 145.355449 pJ
sum error= 10
Actual label: 9
Output voltages: [0.28579, 0.020645, 0.17139, 0.045299, 0.17519, 0.027363, 0.010851, 0.014549, 0.067575, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 155.827180 pJ
sum error= 10
Actual label: 2
Output voltages: [0.46065, 0.048547, 0.79861, 0.028907, 0.0080447, 0.0010692, 0.15355, 0.068394, 0.40732, 0.071957]
Predicted label: 2
Correct prediction
Energy consumption = 145.383777 pJ
sum error= 10
Actual label: 0
Output voltages: [0.79879, 0.028389, 0.051633, 0.026909, 0.016859, 0.015591, 0.41985, 0.026825, 0.04315, 0.03373]
Predicted label: 0
Correct prediction
Energy consumption = 159.399829 pJ
sum error= 10
Actual label: 4
Output voltages: [0.014722, 0.0021983, 0.21565, 0.03413, 0.79866, 0.023982, 0.17282, 0.024334, 0.016967, 0.52296]
Predicted label: 4
Correct prediction
Energy consumption = 158.524608 pJ
sum error= 10
Actual label: 0
Output voltages: [0.79877, 0.051271, 0.14285, 0.0202, 0.011822, 0.0047048, 0.35183, 0.013309, 0.04454, 0.02694]
Predicted label: 0
Correct prediction
Energy consumption = 147.745413 pJ
sum error= 10
Actual label: 0
Output voltages: [0.79847, 0.020115, 0.040428, 0.077326, 0.0010802, 0.055835, 0.43974, 0.0025712, 0.43537, 0.12423]
Predicted label: 0
Correct prediction
Energy consumption = 142.046375 pJ
sum error= 10
Actual label: 2
Output voltages: [0.24665, 0.069436, 0.79809, 0.50619, 0.0014085, 0.0011272, 0.24731, 0.0074023, 0.72458, 0.0097439]
Predicted label: 2
Correct prediction
Energy consumption = 140.028662 pJ
sum error= 10
Actual label: 8
Output voltages: [0.028353, 0.047768, 0.13805, 0.35405, 0.005217, 0.36447, 0.023339, 0.028928, 0.7987, 0.019823]
Predicted label: 8
Correct prediction
Energy consumption = 152.411051 pJ
sum error= 10
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 30 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 30 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 30 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.023766, 0.27184, 0.66761, 0.0012114, 0.78673, 0.001104, 0.79135, 0.0068824, 0.016096, 0.0048165]
Predicted label: 6
Wrong prediction!
Energy consumption = 150.473396 pJ
sum error= 11
Actual label: 7
Output voltages: [0.27911, 0.0017466, 0.042026, 0.68082, 0.026884, 0.0016996, 0.0010825, 0.79802, 0.45607, 0.5638]
Predicted label: 7
Correct prediction
Energy consumption = 147.769230 pJ
sum error= 11
Actual label: 1
Output voltages: [0.0061761, 0.79853, 0.050543, 0.065596, 0.049869, 0.012925, 0.76516, 0.0010949, 0.03658, 0.44594]
Predicted label: 1
Correct prediction
Energy consumption = 159.230560 pJ
sum error= 11
Actual label: 2
Output voltages: [0.52667, 0.011295, 0.79875, 0.24048, 0.018758, 0.0010821, 0.16094, 0.18334, 0.57831, 0.018705]
Predicted label: 2
Correct prediction
Energy consumption = 140.118934 pJ
sum error= 11
Actual label: 4
Output voltages: [0.0024501, 0.013271, 0.0062944, 0.0013346, 0.79879, 0.0016553, 0.044972, 0.1793, 0.34094, 0.013471]
Predicted label: 4
Correct prediction
Energy consumption = 155.802592 pJ
sum error= 11
Actual label: 0
Output voltages: [0.79244, 0.051231, 0.18946, 0.0050251, 0.0010674, 0.12779, 0.12569, 0.0011399, 0.54958, 0.22061]
Predicted label: 0
Correct prediction
Energy consumption = 156.095372 pJ
sum error= 11
Actual label: 2
Output voltages: [0.26945, 0.24315, 0.79866, 0.021514, 0.021763, 0.0014263, 0.39075, 0.023305, 0.42488, 0.037536]
Predicted label: 2
Correct prediction
Energy consumption = 147.384547 pJ
sum error= 11
Actual label: 7
Output voltages: [0.043644, 0.0062411, 0.18954, 0.51652, 0.022864, 0.0011954, 0.0010939, 0.79758, 0.52519, 0.11237]
Predicted label: 7
Correct prediction
Energy consumption = 146.345092 pJ
sum error= 11
Actual label: 4
Output voltages: [0.0014207, 0.036071, 0.02725, 0.0069898, 0.79797, 0.0013552, 0.039052, 0.020934, 0.313, 0.022909]
Predicted label: 4
Correct prediction
Energy consumption = 151.248475 pJ
sum error= 11
Actual label: 3
Output voltages: [0.53601, 0.021566, 0.18179, 0.7986, 0.019616, 0.020155, 0.022829, 0.018898, 0.59321, 0.023798]
Predicted label: 3
Correct prediction
Energy consumption = 150.659750 pJ
sum error= 11
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 31 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 31 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 31 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.19223, 0.033912, 0.11382, 0.79868, 0.037779, 0.0064858, 0.021955, 0.01014, 0.5045, 0.10738]
Predicted label: 3
Correct prediction
Energy consumption = 152.035604 pJ
sum error= 11
Actual label: 0
Output voltages: [0.79767, 0.022985, 0.096907, 0.0045022, 0.027968, 0.0065606, 0.74768, 0.022979, 0.11398, 0.046691]
Predicted label: 0
Correct prediction
Energy consumption = 156.708633 pJ
sum error= 11
Actual label: 0
Output voltages: [0.79879, 0.090072, 0.17691, 0.033457, 0.029094, 0.001626, 0.56628, 0.015316, 0.087209, 0.22374]
Predicted label: 0
Correct prediction
Energy consumption = 148.826386 pJ
sum error= 11
Actual label: 3
Output voltages: [0.018746, 0.0011361, 0.11069, 0.79828, 0.15799, 0.498, 0.014948, 0.0017463, 0.56851, 0.0043444]
Predicted label: 3
Correct prediction
Energy consumption = 145.302818 pJ
sum error= 11
Actual label: 1
Output voltages: [0.016278, 0.79842, 0.10093, 0.60188, 0.36418, 0.0078054, 0.35268, 0.17081, 0.015187, 0.13448]
Predicted label: 1
Correct prediction
Energy consumption = 163.517326 pJ
sum error= 11
Actual label: 9
Output voltages: [0.22155, 0.026113, 0.024489, 0.058627, 0.1204, 0.058475, 0.12138, 0.04163, 0.44297, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 154.455081 pJ
sum error= 11
Actual label: 6
Output voltages: [0.043893, 0.024253, 0.024758, 0.010936, 0.06053, 0.48976, 0.79879, 0.0063689, 0.65049, 0.012918]
Predicted label: 6
Correct prediction
Energy consumption = 149.230856 pJ
sum error= 11
Actual label: 5
Output voltages: [0.046475, 0.0011176, 0.0012804, 0.33131, 0.22901, 0.79872, 0.28954, 0.052703, 0.79278, 0.0030559]
Predicted label: 5
Correct prediction
Energy consumption = 132.801364 pJ
sum error= 11
Actual label: 2
Output voltages: [0.76659, 0.0010728, 0.78357, 0.76753, 0.00434, 0.0028627, 0.015236, 0.0889, 0.78651, 0.024842]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.936483 pJ
sum error= 12
Actual label: 5
Output voltages: [0.02331, 0.0010697, 0.019094, 0.30228, 0.03519, 0.79826, 0.18938, 0.018132, 0.77964, 0.04151]
Predicted label: 5
Correct prediction
Energy consumption = 142.362593 pJ
sum error= 12
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 32 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 32 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 32 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.018404, 0.78407, 0.017929, 0.3849, 0.006202, 0.029743, 0.0024921, 0.02117, 0.78625, 0.75941]
Predicted label: 8
Wrong prediction!
Energy consumption = 161.944219 pJ
sum error= 13
Actual label: 2
Output voltages: [0.3133, 0.22651, 0.68741, 0.75538, 0.0011123, 0.0010992, 0.025994, 0.51055, 0.73683, 0.12566]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.084417 pJ
sum error= 14
Actual label: 9
Output voltages: [0.44127, 0.013747, 0.044489, 0.021778, 0.14528, 0.018657, 0.0077219, 0.010531, 0.39734, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 145.911910 pJ
sum error= 14
Actual label: 3
Output voltages: [0.29643, 0.01363, 0.037127, 0.79867, 0.0075159, 0.027346, 0.0065213, 0.022591, 0.58002, 0.052739]
Predicted label: 3
Correct prediction
Energy consumption = 146.569105 pJ
sum error= 14
Actual label: 0
Output voltages: [0.78731, 0.17756, 0.0010849, 0.16746, 0.02161, 0.41811, 0.76687, 0.0010748, 0.033236, 0.049209]
Predicted label: 0
Correct prediction
Energy consumption = 161.085793 pJ
sum error= 14
Actual label: 4
Output voltages: [0.0049365, 0.02687, 0.01763, 0.015488, 0.79879, 0.0011328, 0.27121, 0.050675, 0.039791, 0.010218]
Predicted label: 4
Correct prediction
Energy consumption = 146.331171 pJ
sum error= 14
Actual label: 2
Output voltages: [0.041286, 0.76395, 0.77976, 0.053079, 0.13636, 0.0010712, 0.43713, 0.01223, 0.051708, 0.0065621]
Predicted label: 2
Correct prediction
Energy consumption = 152.905571 pJ
sum error= 14
Actual label: 0
Output voltages: [0.79877, 0.041707, 0.041237, 0.014864, 0.023023, 0.0021217, 0.55535, 0.016548, 0.25381, 0.18621]
Predicted label: 0
Correct prediction
Energy consumption = 154.285246 pJ
sum error= 14
Actual label: 7
Output voltages: [0.013572, 0.032843, 0.29421, 0.020445, 0.0082793, 0.0010726, 0.0013291, 0.79857, 0.10105, 0.041634]
Predicted label: 7
Correct prediction
Energy consumption = 147.203580 pJ
sum error= 14
Actual label: 1
Output voltages: [0.0017134, 0.79849, 0.045815, 0.046228, 0.0079195, 0.0020719, 0.63188, 0.020044, 0.33314, 0.019611]
Predicted label: 1
Correct prediction
Energy consumption = 162.322938 pJ
sum error= 14
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 33 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 33 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 33 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.034376, 0.7985, 0.36062, 0.69444, 0.010495, 0.0010679, 0.63975, 0.0066232, 0.022283, 0.1924]
Predicted label: 1
Correct prediction
Energy consumption = 167.612978 pJ
sum error= 14
Actual label: 2
Output voltages: [0.085764, 0.42214, 0.79879, 0.07179, 0.0042019, 0.0013723, 0.39803, 0.020943, 0.33572, 0.22731]
Predicted label: 2
Correct prediction
Energy consumption = 146.461950 pJ
sum error= 14
Actual label: 1
Output voltages: [0.012109, 0.79846, 0.10991, 0.036187, 0.0084581, 0.0015932, 0.57214, 0.0018658, 0.16032, 0.15764]
Predicted label: 1
Correct prediction
Energy consumption = 157.575149 pJ
sum error= 14
Actual label: 5
Output voltages: [0.050559, 0.0012765, 0.011856, 0.048622, 0.0084392, 0.79879, 0.14537, 0.015171, 0.7801, 0.030773]
Predicted label: 5
Correct prediction
Energy consumption = 152.502898 pJ
sum error= 14
Actual label: 3
Output voltages: [0.21627, 0.031794, 0.031963, 0.79871, 0.0059379, 0.0047726, 0.021122, 0.011884, 0.52679, 0.060467]
Predicted label: 3
Correct prediction
Energy consumption = 149.842239 pJ
sum error= 14
Actual label: 3
Output voltages: [0.37936, 0.048533, 0.072488, 0.79867, 0.023831, 0.0018759, 0.019641, 0.0093569, 0.46292, 0.045586]
Predicted label: 3
Correct prediction
Energy consumption = 135.830701 pJ
sum error= 14
Actual label: 9
Output voltages: [0.41067, 0.0081872, 0.0099605, 0.019832, 0.7778, 0.026584, 0.016896, 0.017099, 0.023846, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 149.948787 pJ
sum error= 14
Actual label: 7
Output voltages: [0.60214, 0.037744, 0.069828, 0.71241, 0.0010697, 0.0011704, 0.0013102, 0.79874, 0.042824, 0.37509]
Predicted label: 7
Correct prediction
Energy consumption = 146.993053 pJ
sum error= 14
Actual label: 8
Output voltages: [0.71785, 0.0020894, 0.26925, 0.016671, 0.012565, 0.030682, 0.010241, 0.0011374, 0.79878, 0.048198]
Predicted label: 8
Correct prediction
Energy consumption = 148.212252 pJ
sum error= 14
Actual label: 6
Output voltages: [0.040933, 0.042256, 0.17401, 0.0026098, 0.12183, 0.22681, 0.79877, 0.0016614, 0.4239, 0.012624]
Predicted label: 6
Correct prediction
Energy consumption = 139.070127 pJ
sum error= 14
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 34 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 34 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 34 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.047313, 0.0043907, 0.060846, 0.082429, 0.0052805, 0.64142, 0.56716, 0.0012276, 0.43593, 0.0082395]
Predicted label: 5
Correct prediction
Energy consumption = 158.592227 pJ
sum error= 14
Actual label: 6
Output voltages: [0.035996, 0.0051727, 0.030779, 0.0034847, 0.11059, 0.15609, 0.79867, 0.0068359, 0.73346, 0.010416]
Predicted label: 6
Correct prediction
Energy consumption = 147.089815 pJ
sum error= 14
Actual label: 1
Output voltages: [0.015067, 0.79851, 0.042185, 0.086022, 0.013631, 0.0011008, 0.74486, 0.0071258, 0.043268, 0.24799]
Predicted label: 1
Correct prediction
Energy consumption = 164.885560 pJ
sum error= 14
Actual label: 3
Output voltages: [0.26635, 0.023143, 0.038407, 0.79875, 0.063317, 0.46105, 0.045148, 0.0027978, 0.35011, 0.087393]
Predicted label: 3
Correct prediction
Energy consumption = 148.728560 pJ
sum error= 14
Actual label: 8
Output voltages: [0.038309, 0.016087, 0.13313, 0.11608, 0.0063104, 0.053493, 0.72174, 0.0010961, 0.79711, 0.022962]
Predicted label: 8
Correct prediction
Energy consumption = 150.718534 pJ
sum error= 14
Actual label: 1
Output voltages: [0.031908, 0.79855, 0.1863, 0.17922, 0.31716, 0.0037791, 0.22936, 0.0079748, 0.046654, 0.10441]
Predicted label: 1
Correct prediction
Energy consumption = 165.315675 pJ
sum error= 14
Actual label: 0
Output voltages: [0.79873, 0.3311, 0.38317, 0.020627, 0.0067326, 0.0028816, 0.16502, 0.037731, 0.42376, 0.20964]
Predicted label: 0
Correct prediction
Energy consumption = 159.818411 pJ
sum error= 14
Actual label: 5
Output voltages: [0.0044807, 0.0014772, 0.0011441, 0.49796, 0.18363, 0.78505, 0.33973, 0.0016495, 0.67702, 0.02696]
Predicted label: 5
Correct prediction
Energy consumption = 144.445737 pJ
sum error= 14
Actual label: 1
Output voltages: [0.014167, 0.79867, 0.0063075, 0.035665, 0.031152, 0.0020778, 0.53117, 0.0040272, 0.43046, 0.038189]
Predicted label: 1
Correct prediction
Energy consumption = 161.476086 pJ
sum error= 14
Actual label: 3
Output voltages: [0.022996, 0.076033, 0.22611, 0.79875, 0.015737, 0.0014883, 0.0032594, 0.036601, 0.54777, 0.024623]
Predicted label: 3
Correct prediction
Energy consumption = 149.969393 pJ
sum error= 14
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 35 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 35 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 35 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0012734, 0.79878, 0.22872, 0.57425, 0.44461, 0.0010664, 0.020048, 0.023724, 0.082547, 0.095759]
Predicted label: 1
Correct prediction
Energy consumption = 166.643690 pJ
sum error= 14
Actual label: 5
Output voltages: [0.18299, 0.0012448, 0.010942, 0.26411, 0.0066959, 0.79879, 0.16992, 0.091952, 0.77914, 0.025534]
Predicted label: 5
Correct prediction
Energy consumption = 149.572689 pJ
sum error= 14
Actual label: 5
Output voltages: [0.54441, 0.012801, 0.0016329, 0.38151, 0.007385, 0.79873, 0.14605, 0.011072, 0.74421, 0.051391]
Predicted label: 5
Correct prediction
Energy consumption = 135.668432 pJ
sum error= 14
Actual label: 6
Output voltages: [0.46675, 0.12882, 0.13338, 0.014567, 0.14328, 0.061027, 0.79879, 0.001074, 0.36314, 0.023311]
Predicted label: 6
Correct prediction
Energy consumption = 151.284094 pJ
sum error= 14
Actual label: 1
Output voltages: [0.042237, 0.7983, 0.25663, 0.0066449, 0.30622, 0.0011925, 0.18184, 0.0055721, 0.12841, 0.015243]
Predicted label: 1
Correct prediction
Energy consumption = 155.447130 pJ
sum error= 14
Actual label: 8
Output voltages: [0.018045, 0.0033396, 0.0020778, 0.23329, 0.011218, 0.32127, 0.3998, 0.0013388, 0.79867, 0.04947]
Predicted label: 8
Correct prediction
Energy consumption = 146.124700 pJ
sum error= 14
Actual label: 5
Output voltages: [0.035555, 0.0029656, 0.0032649, 0.48436, 0.019452, 0.79868, 0.2086, 0.1616, 0.75582, 0.036589]
Predicted label: 5
Correct prediction
Energy consumption = 140.299425 pJ
sum error= 14
Actual label: 1
Output voltages: [0.032531, 0.79853, 0.012355, 0.016483, 0.013391, 0.017374, 0.25795, 0.0027931, 0.48767, 0.018107]
Predicted label: 1
Correct prediction
Energy consumption = 167.327897 pJ
sum error= 14
Actual label: 7
Output voltages: [0.22432, 0.52264, 0.27739, 0.055697, 0.055131, 0.0013043, 0.0010659, 0.79771, 0.0015146, 0.37262]
Predicted label: 7
Correct prediction
Energy consumption = 157.029577 pJ
sum error= 14
Actual label: 9
Output voltages: [0.062478, 0.01599, 0.11132, 0.012815, 0.49736, 0.0016634, 0.001565, 0.0022459, 0.36461, 0.79551]
Predicted label: 9
Correct prediction
Energy consumption = 149.152216 pJ
sum error= 14
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 36 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 36 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 36 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0081655, 0.0053385, 0.17997, 0.014849, 0.79876, 0.021585, 0.28619, 0.071234, 0.028179, 0.15993]
Predicted label: 4
Correct prediction
Energy consumption = 151.543915 pJ
sum error= 14
Actual label: 6
Output voltages: [0.050285, 0.053157, 0.047373, 0.0075906, 0.12952, 0.52323, 0.79869, 0.016729, 0.46147, 0.020743]
Predicted label: 6
Correct prediction
Energy consumption = 146.020542 pJ
sum error= 14
Actual label: 2
Output voltages: [0.56857, 0.12547, 0.79876, 0.10128, 0.0016849, 0.0012911, 0.47788, 0.4558, 0.33368, 0.011216]
Predicted label: 2
Correct prediction
Energy consumption = 151.962116 pJ
sum error= 14
Actual label: 2
Output voltages: [0.31593, 0.7559, 0.79837, 0.031814, 0.0056541, 0.0012654, 0.19968, 0.009975, 0.094925, 0.035083]
Predicted label: 2
Correct prediction
Energy consumption = 141.317652 pJ
sum error= 14
Actual label: 5
Output voltages: [0.030465, 0.0011594, 0.012092, 0.13691, 0.030406, 0.79402, 0.05396, 0.0061773, 0.78885, 0.076643]
Predicted label: 5
Correct prediction
Energy consumption = 142.137600 pJ
sum error= 14
Actual label: 0
Output voltages: [0.79711, 0.018749, 0.011273, 0.16414, 0.082386, 0.0089063, 0.33287, 0.02865, 0.73311, 0.16015]
Predicted label: 0
Correct prediction
Energy consumption = 158.640076 pJ
sum error= 14
Actual label: 6
Output voltages: [0.74477, 0.06343, 0.021504, 0.0035746, 0.032558, 0.21524, 0.79865, 0.020229, 0.16025, 0.01963]
Predicted label: 6
Correct prediction
Energy consumption = 145.313503 pJ
sum error= 14
Actual label: 5
Output voltages: [0.011112, 0.0010992, 0.20686, 0.69724, 0.040309, 0.60338, 0.0016719, 0.0052925, 0.78812, 0.12179]
Predicted label: 8
Wrong prediction!
Energy consumption = 145.929143 pJ
sum error= 15
Actual label: 6
Output voltages: [0.2134, 0.23756, 0.05305, 0.010033, 0.30739, 0.22535, 0.79874, 0.0011439, 0.52248, 0.010294]
Predicted label: 6
Correct prediction
Energy consumption = 149.802135 pJ
sum error= 15
Actual label: 3
Output voltages: [0.39969, 0.024166, 0.072133, 0.79872, 0.0039277, 0.02072, 0.001331, 0.057583, 0.54765, 0.063708]
Predicted label: 3
Correct prediction
Energy consumption = 150.061213 pJ
sum error= 15
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 37 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 37 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 37 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.50706, 0.55771, 0.12741, 0.50786, 0.0012025, 0.0010699, 0.0028309, 0.79874, 0.028299, 0.59475]
Predicted label: 7
Correct prediction
Energy consumption = 159.422812 pJ
sum error= 15
Actual label: 2
Output voltages: [0.2805, 0.02299, 0.79866, 0.031246, 0.026475, 0.0011602, 0.28654, 0.022833, 0.65182, 0.020321]
Predicted label: 2
Correct prediction
Energy consumption = 140.140502 pJ
sum error= 15
Actual label: 0
Output voltages: [0.79695, 0.020855, 0.021534, 0.0042107, 0.0035077, 0.12822, 0.62712, 0.016027, 0.035351, 0.18401]
Predicted label: 0
Correct prediction
Energy consumption = 156.835412 pJ
sum error= 15
Actual label: 8
Output voltages: [0.22479, 0.042715, 0.22013, 0.028425, 0.031389, 0.0016591, 0.47654, 0.0041538, 0.79879, 0.18451]
Predicted label: 8
Correct prediction
Energy consumption = 154.198245 pJ
sum error= 15
Actual label: 8
Output voltages: [0.020312, 0.043997, 0.32573, 0.02038, 0.015439, 0.016055, 0.021123, 0.003709, 0.79872, 0.1361]
Predicted label: 8
Correct prediction
Energy consumption = 146.946189 pJ
sum error= 15
Actual label: 5
Output voltages: [0.029806, 0.0010834, 0.0042877, 0.20944, 0.029095, 0.79879, 0.32319, 0.028902, 0.77208, 0.015473]
Predicted label: 5
Correct prediction
Energy consumption = 145.968708 pJ
sum error= 15
Actual label: 4
Output voltages: [0.052904, 0.064087, 0.029059, 0.11804, 0.79875, 0.0056394, 0.040801, 0.016658, 0.025421, 0.52984]
Predicted label: 4
Correct prediction
Energy consumption = 157.900258 pJ
sum error= 15
Actual label: 1
Output voltages: [0.02962, 0.79834, 0.01962, 0.13865, 0.046995, 0.0041752, 0.53941, 0.02836, 0.036296, 0.26714]
Predicted label: 1
Correct prediction
Energy consumption = 167.286080 pJ
sum error= 15
Actual label: 1
Output voltages: [0.013921, 0.79858, 0.1918, 0.039558, 0.033952, 0.0012713, 0.63914, 0.0031033, 0.18133, 0.032282]
Predicted label: 1
Correct prediction
Energy consumption = 154.046011 pJ
sum error= 15
Actual label: 4
Output voltages: [0.008635, 0.019629, 0.18938, 0.013427, 0.79857, 0.0056632, 0.074507, 0.030319, 0.040325, 0.035619]
Predicted label: 4
Correct prediction
Energy consumption = 153.396968 pJ
sum error= 15
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 38 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 38 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 38 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.78845, 0.020356, 0.73415, 0.002561, 0.001458, 0.0055665, 0.39046, 0.0014856, 0.30713, 0.027857]
Predicted label: 0
Correct prediction
Energy consumption = 154.042007 pJ
sum error= 15
Actual label: 3
Output voltages: [0.221, 0.022293, 0.65465, 0.79812, 0.0010718, 0.0011056, 0.0028633, 0.42903, 0.77477, 0.010872]
Predicted label: 3
Correct prediction
Energy consumption = 142.808349 pJ
sum error= 15
Actual label: 3
Output voltages: [0.11554, 0.0096219, 0.13045, 0.79872, 0.0169, 0.012076, 0.013083, 0.061059, 0.70594, 0.10461]
Predicted label: 3
Correct prediction
Energy consumption = 133.263579 pJ
sum error= 15
Actual label: 7
Output voltages: [0.13208, 0.15452, 0.16482, 0.51174, 0.0018956, 0.0016232, 0.001086, 0.79869, 0.34054, 0.64621]
Predicted label: 7
Correct prediction
Energy consumption = 151.472487 pJ
sum error= 15
Actual label: 6
Output voltages: [0.030131, 0.27594, 0.49687, 0.0030749, 0.16243, 0.019877, 0.79874, 0.0010927, 0.45683, 0.021264]
Predicted label: 6
Correct prediction
Energy consumption = 143.813218 pJ
sum error= 15
Actual label: 1
Output voltages: [0.0061287, 0.79842, 0.022609, 0.050196, 0.023352, 0.0086396, 0.74191, 0.0057708, 0.38495, 0.04102]
Predicted label: 1
Correct prediction
Energy consumption = 162.279190 pJ
sum error= 15
Actual label: 6
Output voltages: [0.47907, 0.032935, 0.019539, 0.0055284, 0.30558, 0.45265, 0.79879, 0.017413, 0.52964, 0.010048]
Predicted label: 6
Correct prediction
Energy consumption = 150.484996 pJ
sum error= 15
Actual label: 2
Output voltages: [0.21531, 0.38128, 0.7987, 0.20785, 0.025393, 0.0011595, 0.22157, 0.0080419, 0.28409, 0.051928]
Predicted label: 2
Correct prediction
Energy consumption = 147.717736 pJ
sum error= 15
Actual label: 1
Output voltages: [0.42947, 0.7983, 0.5432, 0.0011178, 0.21099, 0.0011541, 0.036608, 0.022064, 0.048913, 0.071291]
Predicted label: 1
Correct prediction
Energy consumption = 154.381540 pJ
sum error= 15
Actual label: 9
Output voltages: [0.17066, 0.0025224, 0.020443, 0.0059043, 0.14047, 0.028366, 0.0022035, 0.046712, 0.74704, 0.78645]
Predicted label: 9
Correct prediction
Energy consumption = 151.842031 pJ
sum error= 15
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 39 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 39 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 39 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.56886, 0.011224, 0.79876, 0.15395, 0.0052596, 0.0010779, 0.21138, 0.029506, 0.26984, 0.014385]
Predicted label: 2
Correct prediction
Energy consumption = 146.347659 pJ
sum error= 15
Actual label: 8
Output voltages: [0.15696, 0.0058188, 0.18116, 0.13497, 0.031287, 0.0058033, 0.030469, 0.0023642, 0.79879, 0.012016]
Predicted label: 8
Correct prediction
Energy consumption = 146.420983 pJ
sum error= 15
Actual label: 6
Output voltages: [0.19628, 0.050029, 0.21024, 0.014051, 0.28182, 0.31497, 0.79879, 0.0028824, 0.37767, 0.019728]
Predicted label: 6
Correct prediction
Energy consumption = 144.220931 pJ
sum error= 15
Actual label: 1
Output voltages: [0.048957, 0.79841, 0.05228, 0.18203, 0.16186, 0.0015208, 0.30024, 0.0038768, 0.036165, 0.3493]
Predicted label: 1
Correct prediction
Energy consumption = 169.621939 pJ
sum error= 15
Actual label: 9
Output voltages: [0.74708, 0.010244, 0.0073307, 0.14847, 0.73259, 0.0061289, 0.0076137, 0.0048943, 0.04996, 0.79678]
Predicted label: 9
Correct prediction
Energy consumption = 150.299058 pJ
sum error= 15
Actual label: 5
Output voltages: [0.049694, 0.0010768, 0.0121, 0.4503, 0.022387, 0.79843, 0.093244, 0.1106, 0.77208, 0.18976]
Predicted label: 5
Correct prediction
Energy consumption = 145.560532 pJ
sum error= 15
Actual label: 2
Output voltages: [0.54414, 0.025434, 0.79868, 0.15545, 0.033007, 0.0011595, 0.2959, 0.20412, 0.3252, 0.015092]
Predicted label: 2
Correct prediction
Energy consumption = 150.237807 pJ
sum error= 15
Actual label: 5
Output voltages: [0.0096143, 0.0014243, 0.035789, 0.35693, 0.058883, 0.77288, 0.11986, 0.0016727, 0.79513, 0.27231]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.440632 pJ
sum error= 16
Actual label: 4
Output voltages: [0.014381, 0.017333, 0.17006, 0.012229, 0.7986, 0.002631, 0.13244, 0.049241, 0.044054, 0.051572]
Predicted label: 4
Correct prediction
Energy consumption = 151.479563 pJ
sum error= 16
Actual label: 4
Output voltages: [0.0035449, 0.026476, 0.26558, 0.0038765, 0.79869, 0.0019076, 0.13163, 0.26388, 0.02003, 0.035412]
Predicted label: 4
Correct prediction
Energy consumption = 140.681500 pJ
sum error= 16
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 40 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 40 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 40 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.49671, 0.013957, 0.79875, 0.14228, 0.0093566, 0.0010872, 0.015507, 0.032177, 0.50639, 0.007949]
Predicted label: 2
Correct prediction
Energy consumption = 155.556993 pJ
sum error= 16
Actual label: 8
Output voltages: [0.07373, 0.0055433, 0.41368, 0.6257, 0.014995, 0.0012867, 0.03876, 0.003879, 0.7984, 0.10978]
Predicted label: 8
Correct prediction
Energy consumption = 146.492902 pJ
sum error= 16
Actual label: 3
Output voltages: [0.47465, 0.0021433, 0.26194, 0.79879, 0.29436, 0.12993, 0.021727, 0.0014487, 0.51046, 0.020215]
Predicted label: 3
Correct prediction
Energy consumption = 142.134647 pJ
sum error= 16
Actual label: 8
Output voltages: [0.0039928, 0.028895, 0.22299, 0.038943, 0.0035475, 0.011351, 0.065237, 0.020626, 0.79878, 0.28467]
Predicted label: 8
Correct prediction
Energy consumption = 145.342889 pJ
sum error= 16
Actual label: 2
Output voltages: [0.12425, 0.035417, 0.79879, 0.0408, 0.0026585, 0.0012896, 0.02701, 0.40199, 0.69488, 0.090829]
Predicted label: 2
Correct prediction
Energy consumption = 147.253055 pJ
sum error= 16
Actual label: 4
Output voltages: [0.041513, 0.0035986, 0.17066, 0.011602, 0.79879, 0.035441, 0.03214, 0.0019986, 0.055189, 0.60962]
Predicted label: 4
Correct prediction
Energy consumption = 154.786164 pJ
sum error= 16
Actual label: 5
Output voltages: [0.41527, 0.001088, 0.0010883, 0.30731, 0.028866, 0.74816, 0.033498, 0.0057487, 0.77447, 0.26471]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.317195 pJ
sum error= 17
Actual label: 0
Output voltages: [0.79876, 0.12453, 0.044155, 0.028743, 0.0022741, 0.040522, 0.52775, 0.019964, 0.13158, 0.017013]
Predicted label: 0
Correct prediction
Energy consumption = 150.447776 pJ
sum error= 17
Actual label: 3
Output voltages: [0.52607, 0.022897, 0.043038, 0.79869, 0.017748, 0.010953, 0.14202, 0.023609, 0.45558, 0.012019]
Predicted label: 3
Correct prediction
Energy consumption = 153.866639 pJ
sum error= 17
Actual label: 1
Output voltages: [0.0081207, 0.79861, 0.0018817, 0.20454, 0.035195, 0.02243, 0.42691, 0.0069322, 0.21644, 0.25376]
Predicted label: 1
Correct prediction
Energy consumption = 160.278866 pJ
sum error= 17
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 41 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 41 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 41 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.33312, 0.12124, 0.0061195, 0.37518, 0.016637, 0.023445, 0.001107, 0.79877, 0.12854, 0.74155]
Predicted label: 7
Correct prediction
Energy consumption = 154.157904 pJ
sum error= 17
Actual label: 7
Output voltages: [0.049018, 0.31229, 0.52343, 0.10781, 0.003668, 0.001081, 0.0033168, 0.79568, 0.59393, 0.06218]
Predicted label: 7
Correct prediction
Energy consumption = 151.351919 pJ
sum error= 17
Actual label: 5
Output voltages: [0.013366, 0.0018411, 0.0013033, 0.43181, 0.024247, 0.79715, 0.013674, 0.03167, 0.63589, 0.24191]
Predicted label: 5
Correct prediction
Energy consumption = 148.141192 pJ
sum error= 17
Actual label: 7
Output voltages: [0.27784, 0.014201, 0.017321, 0.061035, 0.020465, 0.0059236, 0.0011135, 0.79862, 0.69569, 0.25992]
Predicted label: 7
Correct prediction
Energy consumption = 151.825087 pJ
sum error= 17
Actual label: 9
Output voltages: [0.34945, 0.037506, 0.0078998, 0.036996, 0.73243, 0.0090367, 0.029495, 0.12973, 0.015285, 0.79791]
Predicted label: 9
Correct prediction
Energy consumption = 151.879948 pJ
sum error= 17
Actual label: 7
Output voltages: [0.02058, 0.019197, 0.010434, 0.27592, 0.035619, 0.016007, 0.0010859, 0.79876, 0.042419, 0.12413]
Predicted label: 7
Correct prediction
Energy consumption = 150.095217 pJ
sum error= 17
Actual label: 1
Output voltages: [0.0029893, 0.79852, 0.038048, 0.03282, 0.00858, 0.0017691, 0.7381, 0.0068515, 0.26813, 0.025536]
Predicted label: 1
Correct prediction
Energy consumption = 159.966779 pJ
sum error= 17
Actual label: 9
Output voltages: [0.028237, 0.014625, 0.0049669, 0.35165, 0.010176, 0.0093396, 0.0011362, 0.38056, 0.74536, 0.7701]
Predicted label: 9
Correct prediction
Energy consumption = 155.864537 pJ
sum error= 17
Actual label: 2
Output voltages: [0.45411, 0.0058081, 0.79871, 0.2871, 0.022029, 0.0011064, 0.057307, 0.069769, 0.66538, 0.0091281]
Predicted label: 2
Correct prediction
Energy consumption = 145.103963 pJ
sum error= 17
Actual label: 1
Output voltages: [0.0086107, 0.79833, 0.036426, 0.10195, 0.0091783, 0.03899, 0.64633, 0.04941, 0.084409, 0.045371]
Predicted label: 1
Correct prediction
Energy consumption = 164.538668 pJ
sum error= 17
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 42 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 42 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 42 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.20578, 0.026341, 0.2603, 0.0086575, 0.79859, 0.0016163, 0.011979, 0.036228, 0.048322, 0.034535]
Predicted label: 4
Correct prediction
Energy consumption = 143.950282 pJ
sum error= 17
Actual label: 2
Output voltages: [0.4597, 0.026385, 0.79872, 0.060078, 0.013857, 0.0010939, 0.32833, 0.026764, 0.44858, 0.032958]
Predicted label: 2
Correct prediction
Energy consumption = 142.352052 pJ
sum error= 17
Actual label: 9
Output voltages: [0.41675, 0.012256, 0.017297, 0.030805, 0.06761, 0.0099094, 0.004374, 0.21683, 0.33391, 0.79652]
Predicted label: 9
Correct prediction
Energy consumption = 154.800409 pJ
sum error= 17
Actual label: 2
Output voltages: [0.58084, 0.21965, 0.79872, 0.10562, 0.015141, 0.0012003, 0.2534, 0.10075, 0.62786, 0.10387]
Predicted label: 2
Correct prediction
Energy consumption = 149.127055 pJ
sum error= 17
Actual label: 0
Output voltages: [0.7987, 0.21626, 0.034467, 0.0018296, 0.031199, 0.003976, 0.4344, 0.004001, 0.024866, 0.30792]
Predicted label: 0
Correct prediction
Energy consumption = 155.497208 pJ
sum error= 17
Actual label: 4
Output voltages: [0.039489, 0.032921, 0.38936, 0.0010803, 0.79879, 0.0019493, 0.63021, 0.044275, 0.033598, 0.037072]
Predicted label: 4
Correct prediction
Energy consumption = 152.255571 pJ
sum error= 17
Actual label: 9
Output voltages: [0.26623, 0.0065627, 0.018616, 0.091027, 0.48147, 0.0069927, 0.0017673, 0.0090913, 0.26111, 0.79703]
Predicted label: 9
Correct prediction
Energy consumption = 150.220854 pJ
sum error= 17
Actual label: 1
Output voltages: [0.0453, 0.79865, 0.30231, 0.21695, 0.10037, 0.0078084, 0.39202, 0.0010864, 0.020766, 0.151]
Predicted label: 1
Correct prediction
Energy consumption = 163.904460 pJ
sum error= 17
Actual label: 4
Output voltages: [0.028013, 0.039703, 0.1622, 0.008724, 0.79874, 0.0010948, 0.63314, 0.018838, 0.019814, 0.011845]
Predicted label: 4
Correct prediction
Energy consumption = 152.414056 pJ
sum error= 17
Actual label: 8
Output voltages: [0.028544, 0.0307, 0.065023, 0.14229, 0.007409, 0.031573, 0.027133, 0.0065291, 0.79879, 0.33503]
Predicted label: 8
Correct prediction
Energy consumption = 153.096801 pJ
sum error= 17
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 43 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 43 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 43 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.018853, 0.7986, 0.027856, 0.0428, 0.02129, 0.001258, 0.74715, 0.0013282, 0.13547, 0.036789]
Predicted label: 1
Correct prediction
Energy consumption = 165.320488 pJ
sum error= 17
Actual label: 8
Output voltages: [0.061631, 0.0073616, 0.57126, 0.022103, 0.016979, 0.020011, 0.028338, 0.001557, 0.79878, 0.52559]
Predicted label: 8
Correct prediction
Energy consumption = 145.436898 pJ
sum error= 17
Actual label: 4
Output voltages: [0.012734, 0.030392, 0.2693, 0.14272, 0.79865, 0.056431, 0.29869, 0.10827, 0.022355, 0.036412]
Predicted label: 4
Correct prediction
Energy consumption = 150.337952 pJ
sum error= 17
Actual label: 5
Output voltages: [0.037522, 0.0012075, 0.001075, 0.59507, 0.049891, 0.79804, 0.22011, 0.0036115, 0.66652, 0.0056192]
Predicted label: 5
Correct prediction
Energy consumption = 137.944462 pJ
sum error= 17
Actual label: 9
Output voltages: [0.42556, 0.013885, 0.044257, 0.20422, 0.38194, 0.016367, 0.029946, 0.022489, 0.31436, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 158.919455 pJ
sum error= 17
Actual label: 8
Output voltages: [0.014023, 0.1269, 0.33778, 0.34393, 0.0062644, 0.0010746, 0.0044609, 0.24235, 0.79876, 0.014475]
Predicted label: 8
Correct prediction
Energy consumption = 147.053651 pJ
sum error= 17
Actual label: 8
Output voltages: [0.019954, 0.13126, 0.27717, 0.022414, 0.025215, 0.0089651, 0.024042, 0.016742, 0.79877, 0.14094]
Predicted label: 8
Correct prediction
Energy consumption = 147.065918 pJ
sum error= 17
Actual label: 3
Output voltages: [0.085898, 0.0072545, 0.11479, 0.79869, 0.023638, 0.04667, 0.0089291, 0.10848, 0.77417, 0.021323]
Predicted label: 3
Correct prediction
Energy consumption = 143.237538 pJ
sum error= 17
Actual label: 7
Output voltages: [0.055763, 0.023032, 0.015498, 0.12451, 0.016716, 0.0018389, 0.0010665, 0.79868, 0.06133, 0.20533]
Predicted label: 7
Correct prediction
Energy consumption = 150.387430 pJ
sum error= 17
Actual label: 6
Output voltages: [0.62286, 0.022676, 0.026434, 0.002984, 0.16066, 0.48641, 0.79868, 0.012704, 0.44406, 0.01329]
Predicted label: 6
Correct prediction
Energy consumption = 153.028120 pJ
sum error= 17
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 44 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 44 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 44 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.16573, 0.036112, 0.0075659, 0.0085839, 0.0020206, 0.46241, 0.013898, 0.05144, 0.039336]
Predicted label: 0
Correct prediction
Energy consumption = 150.445540 pJ
sum error= 17
Actual label: 0
Output voltages: [0.79565, 0.028666, 0.017998, 0.013382, 0.041354, 0.0045005, 0.73927, 0.023433, 0.048689, 0.012321]
Predicted label: 0
Correct prediction
Energy consumption = 145.670208 pJ
sum error= 17
Actual label: 3
Output voltages: [0.17549, 0.0076281, 0.050184, 0.79866, 0.033452, 0.047287, 0.043721, 0.013466, 0.56743, 0.23024]
Predicted label: 3
Correct prediction
Energy consumption = 149.529704 pJ
sum error= 17
Actual label: 0
Output voltages: [0.77705, 0.036842, 0.18763, 0.042051, 0.0033381, 0.0024225, 0.29833, 0.019109, 0.77681, 0.36219]
Predicted label: 0
Correct prediction
Energy consumption = 164.563020 pJ
sum error= 17
Actual label: 2
Output voltages: [0.20063, 0.0010736, 0.76798, 0.74394, 0.0015116, 0.0070678, 0.0012513, 0.060005, 0.78693, 0.0062792]
Predicted label: 8
Wrong prediction!
Energy consumption = 141.300257 pJ
sum error= 18
Actual label: 6
Output voltages: [0.7901, 0.0010921, 0.0056577, 0.0011554, 0.45165, 0.19744, 0.7546, 0.02586, 0.24945, 0.018818]
Predicted label: 0
Wrong prediction!
Energy consumption = 142.474234 pJ
sum error= 19
Actual label: 6
Output voltages: [0.15641, 0.039009, 0.023882, 0.0503, 0.042671, 0.37576, 0.79875, 0.0010982, 0.44895, 0.1647]
Predicted label: 6
Correct prediction
Energy consumption = 145.676034 pJ
sum error= 19
Actual label: 4
Output voltages: [0.022231, 0.0042289, 0.032679, 0.012897, 0.79877, 0.0010765, 0.011044, 0.23012, 0.16735, 0.12754]
Predicted label: 4
Correct prediction
Energy consumption = 141.528223 pJ
sum error= 19
Actual label: 9
Output voltages: [0.039144, 0.032668, 0.031518, 0.7529, 0.0014086, 0.064514, 0.020201, 0.0011657, 0.79723, 0.41159]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.982673 pJ
sum error= 20
Actual label: 3
Output voltages: [0.161, 0.0010659, 0.044239, 0.79514, 0.049332, 0.774, 0.027316, 0.14788, 0.7262, 0.018708]
Predicted label: 3
Correct prediction
Energy consumption = 144.704425 pJ
sum error= 20
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 45 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 45 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 45 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.025241, 0.0043077, 0.11708, 0.79878, 0.2808, 0.039913, 0.043549, 0.0037565, 0.21004, 0.23443]
Predicted label: 3
Correct prediction
Energy consumption = 154.648999 pJ
sum error= 20
Actual label: 3
Output voltages: [0.048935, 0.013197, 0.086441, 0.79879, 0.0143, 0.0041028, 0.0015709, 0.024606, 0.71751, 0.041334]
Predicted label: 3
Correct prediction
Energy consumption = 132.852789 pJ
sum error= 20
Actual label: 2
Output voltages: [0.35067, 0.53978, 0.79878, 0.20267, 0.011888, 0.0013254, 0.11963, 0.020771, 0.044454, 0.092095]
Predicted label: 2
Correct prediction
Energy consumption = 146.900705 pJ
sum error= 20
Actual label: 3
Output voltages: [0.1145, 0.011336, 0.1656, 0.7987, 0.0093478, 0.0059188, 0.019504, 0.020612, 0.3561, 0.06716]
Predicted label: 3
Correct prediction
Energy consumption = 142.901138 pJ
sum error= 20
Actual label: 9
Output voltages: [0.68183, 0.0093317, 0.03042, 0.039553, 0.42763, 0.043701, 0.014547, 0.0072527, 0.17426, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.029038 pJ
sum error= 20
Actual label: 1
Output voltages: [0.052825, 0.79864, 0.29532, 0.031645, 0.14919, 0.001105, 0.62054, 0.0035374, 0.086986, 0.034473]
Predicted label: 1
Correct prediction
Energy consumption = 166.365563 pJ
sum error= 20
Actual label: 2
Output voltages: [0.31979, 0.57956, 0.79824, 0.014142, 0.011977, 0.0013893, 0.051865, 0.30665, 0.060131, 0.020717]
Predicted label: 2
Correct prediction
Energy consumption = 145.457684 pJ
sum error= 20
Actual label: 6
Output voltages: [0.034649, 0.018403, 0.043389, 0.017903, 0.38276, 0.21871, 0.79873, 0.0011951, 0.77409, 0.017871]
Predicted label: 6
Correct prediction
Energy consumption = 150.738475 pJ
sum error= 20
Actual label: 8
Output voltages: [0.0043683, 0.27327, 0.22679, 0.048529, 0.010927, 0.010857, 0.016079, 0.034424, 0.79871, 0.3218]
Predicted label: 8
Correct prediction
Energy consumption = 142.947057 pJ
sum error= 20
Actual label: 0
Output voltages: [0.79395, 0.034997, 0.040335, 0.0070117, 0.0039105, 0.10096, 0.7331, 0.016431, 0.019691, 0.0103]
Predicted label: 0
Correct prediction
Energy consumption = 159.958103 pJ
sum error= 20
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 46 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 46 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 46 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.023389, 0.013408, 0.0062113, 0.56704, 0.01684, 0.79877, 0.025212, 0.018148, 0.76054, 0.018923]
Predicted label: 5
Correct prediction
Energy consumption = 148.721543 pJ
sum error= 20
Actual label: 6
Output voltages: [0.3955, 0.042196, 0.39429, 0.0011351, 0.34057, 0.021812, 0.79879, 0.0010943, 0.16479, 0.017732]
Predicted label: 6
Correct prediction
Energy consumption = 143.664849 pJ
sum error= 20
Actual label: 6
Output voltages: [0.033486, 0.0035942, 0.10941, 0.022381, 0.040614, 0.76486, 0.79826, 0.0010704, 0.76026, 0.050576]
Predicted label: 6
Correct prediction
Energy consumption = 138.282675 pJ
sum error= 20
Actual label: 6
Output voltages: [0.38549, 0.031302, 0.16445, 0.0041961, 0.26296, 0.14688, 0.79879, 0.0010733, 0.5283, 0.023004]
Predicted label: 6
Correct prediction
Energy consumption = 134.408426 pJ
sum error= 20
Actual label: 3
Output voltages: [0.15393, 0.030766, 0.12312, 0.79878, 0.0011022, 0.013043, 0.0017214, 0.11838, 0.7905, 0.0077911]
Predicted label: 3
Correct prediction
Energy consumption = 144.118922 pJ
sum error= 20
Actual label: 8
Output voltages: [0.0093152, 0.13014, 0.078402, 0.43918, 0.0011403, 0.022823, 0.0017977, 0.12297, 0.79876, 0.18985]
Predicted label: 8
Correct prediction
Energy consumption = 144.282215 pJ
sum error= 20
Actual label: 8
Output voltages: [0.023421, 0.041417, 0.72203, 0.030507, 0.017618, 0.0087344, 0.027441, 0.0073336, 0.7987, 0.047388]
Predicted label: 8
Correct prediction
Energy consumption = 140.554023 pJ
sum error= 20
Actual label: 2
Output voltages: [0.46722, 0.1469, 0.79877, 0.050143, 0.0039519, 0.0013104, 0.1512, 0.14481, 0.44257, 0.023037]
Predicted label: 2
Correct prediction
Energy consumption = 144.500374 pJ
sum error= 20
Actual label: 7
Output voltages: [0.41761, 0.0083145, 0.63337, 0.52253, 0.0043657, 0.0011535, 0.0011064, 0.72871, 0.74632, 0.35831]
Predicted label: 8
Wrong prediction!
Energy consumption = 135.054842 pJ
sum error= 21
Actual label: 5
Output voltages: [0.085694, 0.0010679, 0.02477, 0.095148, 0.0058979, 0.74677, 0.016333, 0.0015327, 0.79551, 0.22735]
Predicted label: 8
Wrong prediction!
Energy consumption = 141.966578 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 47 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 47 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 47 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.02986, 0.0067287, 0.33711, 0.73906, 0.0011773, 0.087754, 0.0042598, 0.010918, 0.79879, 0.036633]
Predicted label: 8
Correct prediction
Energy consumption = 150.330367 pJ
sum error= 22
Actual label: 9
Output voltages: [0.45798, 0.0088627, 0.0050818, 0.23726, 0.032287, 0.024433, 0.0012468, 0.7457, 0.74462, 0.78523]
Predicted label: 9
Correct prediction
Energy consumption = 150.085964 pJ
sum error= 22
Actual label: 6
Output voltages: [0.34421, 0.048443, 0.35036, 0.0011922, 0.10102, 0.12918, 0.79879, 0.0018362, 0.36393, 0.0156]
Predicted label: 6
Correct prediction
Energy consumption = 149.335266 pJ
sum error= 22
Actual label: 1
Output voltages: [0.0095567, 0.79836, 0.020247, 0.21796, 0.011604, 0.01209, 0.276, 0.013756, 0.047439, 0.21416]
Predicted label: 1
Correct prediction
Energy consumption = 162.384350 pJ
sum error= 22
Actual label: 8
Output voltages: [0.011919, 0.26817, 0.064877, 0.26518, 0.0015172, 0.0044705, 0.0018357, 0.0086734, 0.79877, 0.48336]
Predicted label: 8
Correct prediction
Energy consumption = 145.571205 pJ
sum error= 22
Actual label: 4
Output voltages: [0.015399, 0.0039582, 0.073254, 0.0021134, 0.79863, 0.053513, 0.13971, 0.15044, 0.055523, 0.28806]
Predicted label: 4
Correct prediction
Energy consumption = 155.651241 pJ
sum error= 22
Actual label: 1
Output voltages: [0.19593, 0.79847, 0.22277, 0.062742, 0.011789, 0.0010984, 0.4138, 0.0029486, 0.25621, 0.22285]
Predicted label: 1
Correct prediction
Energy consumption = 162.499740 pJ
sum error= 22
Actual label: 2
Output voltages: [0.14478, 0.033029, 0.79876, 0.044219, 0.0047468, 0.0011478, 0.053541, 0.014205, 0.74, 0.013032]
Predicted label: 2
Correct prediction
Energy consumption = 142.437339 pJ
sum error= 22
Actual label: 5
Output voltages: [0.2957, 0.0010663, 0.0040083, 0.58214, 0.065237, 0.78518, 0.57054, 0.00126, 0.75174, 0.0048928]
Predicted label: 5
Correct prediction
Energy consumption = 149.275853 pJ
sum error= 22
Actual label: 9
Output voltages: [0.11975, 0.0021712, 0.039324, 0.31324, 0.033444, 0.03197, 0.0029538, 0.022343, 0.7557, 0.79127]
Predicted label: 9
Correct prediction
Energy consumption = 150.597112 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 48 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 48 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 48 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0069534, 0.79861, 0.021344, 0.015267, 0.013833, 0.0053822, 0.60917, 0.0057805, 0.50488, 0.0058873]
Predicted label: 1
Correct prediction
Energy consumption = 158.939967 pJ
sum error= 22
Actual label: 9
Output voltages: [0.40254, 0.015814, 0.012489, 0.027956, 0.1945, 0.015653, 0.0082002, 0.018205, 0.38699, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 160.490293 pJ
sum error= 22
Actual label: 7
Output voltages: [0.54316, 0.44701, 0.0086619, 0.59898, 0.0015648, 0.0047813, 0.0010739, 0.79879, 0.050233, 0.51739]
Predicted label: 7
Correct prediction
Energy consumption = 152.189331 pJ
sum error= 22
Actual label: 5
Output voltages: [0.047642, 0.0021368, 0.0010685, 0.024194, 0.057577, 0.79871, 0.15505, 0.01204, 0.65568, 0.0065819]
Predicted label: 5
Correct prediction
Energy consumption = 144.371167 pJ
sum error= 22
Actual label: 4
Output voltages: [0.017617, 0.0096842, 0.17276, 0.0080472, 0.79868, 0.0018608, 0.11258, 0.47875, 0.017008, 0.02375]
Predicted label: 4
Correct prediction
Energy consumption = 152.081484 pJ
sum error= 22
Actual label: 0
Output voltages: [0.79879, 0.29547, 0.10828, 0.044944, 0.010665, 0.0079787, 0.60027, 0.0031774, 0.19024, 0.50126]
Predicted label: 0
Correct prediction
Energy consumption = 160.136136 pJ
sum error= 22
Actual label: 8
Output voltages: [0.012419, 0.053792, 0.030689, 0.056244, 0.010249, 0.011541, 0.016586, 0.018127, 0.79874, 0.41628]
Predicted label: 8
Correct prediction
Energy consumption = 144.467002 pJ
sum error= 22
Actual label: 9
Output voltages: [0.57427, 0.0020695, 0.023156, 0.003913, 0.17028, 0.0060676, 0.0056898, 0.20682, 0.40517, 0.79385]
Predicted label: 9
Correct prediction
Energy consumption = 145.242106 pJ
sum error= 22
Actual label: 9
Output voltages: [0.048324, 0.0050885, 0.0381, 0.011094, 0.034067, 0.0050936, 0.0015654, 0.027323, 0.77332, 0.79022]
Predicted label: 9
Correct prediction
Energy consumption = 140.179611 pJ
sum error= 22
Actual label: 1
Output voltages: [0.03256, 0.79843, 0.028881, 0.027436, 0.027524, 0.011558, 0.59468, 0.0013752, 0.38684, 0.025059]
Predicted label: 1
Correct prediction
Energy consumption = 163.797072 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 49 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 49 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 49 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79486, 0.029246, 0.27267, 0.0051384, 0.11305, 0.0010964, 0.70262, 0.01744, 0.022457, 0.022621]
Predicted label: 0
Correct prediction
Energy consumption = 147.064704 pJ
sum error= 22
Actual label: 5
Output voltages: [0.035875, 0.0011059, 0.001583, 0.309, 0.045621, 0.79879, 0.030413, 0.047425, 0.66695, 0.051403]
Predicted label: 5
Correct prediction
Energy consumption = 144.471974 pJ
sum error= 22
Actual label: 2
Output voltages: [0.019188, 0.038431, 0.79533, 0.48401, 0.0011768, 0.0010768, 0.20034, 0.020009, 0.77121, 0.0025703]
Predicted label: 2
Correct prediction
Energy consumption = 141.751793 pJ
sum error= 22
Actual label: 3
Output voltages: [0.30065, 0.014322, 0.11835, 0.79872, 0.025147, 0.0015105, 0.019199, 0.043811, 0.63929, 0.011113]
Predicted label: 3
Correct prediction
Energy consumption = 138.182552 pJ
sum error= 22
Actual label: 7
Output voltages: [0.086324, 0.033755, 0.034091, 0.22714, 0.00226, 0.003249, 0.0011236, 0.79873, 0.55738, 0.37722]
Predicted label: 7
Correct prediction
Energy consumption = 150.446526 pJ
sum error= 22
Actual label: 8
Output voltages: [0.37044, 0.03751, 0.27076, 0.051454, 0.021524, 0.0011052, 0.66735, 0.0010842, 0.78108, 0.039344]
Predicted label: 8
Correct prediction
Energy consumption = 150.903385 pJ
sum error= 22
Actual label: 9
Output voltages: [0.20813, 0.0066467, 0.015319, 0.34834, 0.019214, 0.23016, 0.0020643, 0.6619, 0.080571, 0.76199]
Predicted label: 9
Correct prediction
Energy consumption = 160.330386 pJ
sum error= 22
Actual label: 4
Output voltages: [0.054051, 0.1654, 0.19697, 0.0011251, 0.79707, 0.0011101, 0.013717, 0.0054429, 0.41319, 0.48354]
Predicted label: 4
Correct prediction
Energy consumption = 152.878270 pJ
sum error= 22
Actual label: 0
Output voltages: [0.79865, 0.0082422, 0.044527, 0.043682, 0.023173, 0.0018779, 0.040563, 0.057635, 0.46664, 0.050244]
Predicted label: 0
Correct prediction
Energy consumption = 157.191349 pJ
sum error= 22
Actual label: 6
Output voltages: [0.079991, 0.025003, 0.043489, 0.0026702, 0.077839, 0.30601, 0.79879, 0.014529, 0.75742, 0.003528]
Predicted label: 6
Correct prediction
Energy consumption = 142.892070 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 50 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 50 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 50 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.35789, 0.030855, 0.031436, 0.79862, 0.019392, 0.0056298, 0.012547, 0.019952, 0.60705, 0.040738]
Predicted label: 3
Correct prediction
Energy consumption = 150.349573 pJ
sum error= 22
Actual label: 9
Output voltages: [0.42617, 0.0051286, 0.10373, 0.022808, 0.25104, 0.0066714, 0.060655, 0.0019672, 0.028174, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.311470 pJ
sum error= 22
Actual label: 5
Output voltages: [0.048505, 0.0014571, 0.03529, 0.60693, 0.029331, 0.79849, 0.013924, 0.016307, 0.77613, 0.027242]
Predicted label: 5
Correct prediction
Energy consumption = 142.980756 pJ
sum error= 22
Actual label: 2
Output voltages: [0.4505, 0.0056561, 0.79821, 0.24772, 0.026265, 0.0011269, 0.057452, 0.029921, 0.7053, 0.022638]
Predicted label: 2
Correct prediction
Energy consumption = 144.701553 pJ
sum error= 22
Actual label: 1
Output voltages: [0.01247, 0.79854, 0.014465, 0.094334, 0.018715, 0.0014272, 0.12865, 0.015988, 0.7484, 0.03909]
Predicted label: 1
Correct prediction
Energy consumption = 162.728639 pJ
sum error= 22
Actual label: 3
Output voltages: [0.068119, 0.027623, 0.17751, 0.79872, 0.011826, 0.0021256, 0.0034044, 0.0021097, 0.72608, 0.039825]
Predicted label: 3
Correct prediction
Energy consumption = 141.201825 pJ
sum error= 22
Actual label: 1
Output voltages: [0.029942, 0.7986, 0.0011538, 0.02583, 0.44457, 0.034238, 0.50604, 0.0037265, 0.19086, 0.090648]
Predicted label: 1
Correct prediction
Energy consumption = 159.431116 pJ
sum error= 22
Actual label: 3
Output voltages: [0.18095, 0.024183, 0.064773, 0.79879, 0.22952, 0.11633, 0.023521, 0.0068117, 0.47413, 0.014612]
Predicted label: 3
Correct prediction
Energy consumption = 147.347447 pJ
sum error= 22
Actual label: 6
Output voltages: [0.011317, 0.013706, 0.074126, 0.012119, 0.043273, 0.25286, 0.79858, 0.0018198, 0.77175, 0.038966]
Predicted label: 6
Correct prediction
Energy consumption = 146.264153 pJ
sum error= 22
Actual label: 5
Output voltages: [0.027122, 0.0010725, 0.014665, 0.33829, 0.0094486, 0.79761, 0.024331, 0.042166, 0.7756, 0.17415]
Predicted label: 5
Correct prediction
Energy consumption = 142.847764 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 51 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 51 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 51 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.22548, 0.0016272, 0.47315, 0.089926, 0.0025792, 0.0010729, 0.0010835, 0.77693, 0.45348, 0.50647]
Predicted label: 7
Correct prediction
Energy consumption = 147.937970 pJ
sum error= 22
Actual label: 4
Output voltages: [0.0010682, 0.070208, 0.017769, 0.0037778, 0.78879, 0.0087332, 0.023352, 0.0098875, 0.5494, 0.30654]
Predicted label: 4
Correct prediction
Energy consumption = 153.486891 pJ
sum error= 22
Actual label: 2
Output voltages: [0.25355, 0.19477, 0.79876, 0.12617, 0.026386, 0.0013105, 0.15019, 0.034505, 0.42698, 0.049218]
Predicted label: 2
Correct prediction
Energy consumption = 149.477812 pJ
sum error= 22
Actual label: 2
Output voltages: [0.44186, 0.05146, 0.79875, 0.24907, 0.016989, 0.0011345, 0.37219, 0.016194, 0.1264, 0.031028]
Predicted label: 2
Correct prediction
Energy consumption = 143.469554 pJ
sum error= 22
Actual label: 6
Output voltages: [0.42041, 0.043612, 0.2014, 0.0075111, 0.049778, 0.028485, 0.79878, 0.0010903, 0.62993, 0.018746]
Predicted label: 6
Correct prediction
Energy consumption = 154.093034 pJ
sum error= 22
Actual label: 3
Output voltages: [0.029665, 0.018879, 0.047276, 0.7987, 0.028276, 0.015748, 0.0022323, 0.11883, 0.50527, 0.27244]
Predicted label: 3
Correct prediction
Energy consumption = 149.470226 pJ
sum error= 22
Actual label: 2
Output voltages: [0.33425, 0.0053186, 0.79879, 0.17201, 0.17295, 0.0026381, 0.034488, 0.039829, 0.43191, 0.031285]
Predicted label: 2
Correct prediction
Energy consumption = 143.081910 pJ
sum error= 22
Actual label: 6
Output voltages: [0.079584, 0.049617, 0.16771, 0.0079007, 0.18555, 0.3201, 0.79872, 0.0028004, 0.49414, 0.005826]
Predicted label: 6
Correct prediction
Energy consumption = 152.794628 pJ
sum error= 22
Actual label: 5
Output voltages: [0.013219, 0.0010696, 0.0013755, 0.23182, 0.048048, 0.78842, 0.16307, 0.013726, 0.78483, 0.021735]
Predicted label: 5
Correct prediction
Energy consumption = 145.432409 pJ
sum error= 22
Actual label: 4
Output voltages: [0.029052, 0.014986, 0.23282, 0.027396, 0.79877, 0.0050767, 0.021077, 0.039602, 0.037429, 0.37268]
Predicted label: 4
Correct prediction
Energy consumption = 160.137518 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 52 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 52 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 52 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0030617, 0.25805, 0.086181, 0.092952, 0.0023003, 0.029881, 0.017014, 0.013955, 0.79877, 0.28105]
Predicted label: 8
Correct prediction
Energy consumption = 157.667400 pJ
sum error= 22
Actual label: 9
Output voltages: [0.15344, 0.072736, 0.056374, 0.01725, 0.56334, 0.022785, 0.0033159, 0.022499, 0.1532, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 159.087709 pJ
sum error= 22
Actual label: 7
Output voltages: [0.09173, 0.0023482, 0.029775, 0.63681, 0.0074768, 0.0020458, 0.0010716, 0.79868, 0.2184, 0.73248]
Predicted label: 7
Correct prediction
Energy consumption = 145.752040 pJ
sum error= 22
Actual label: 1
Output voltages: [0.0016032, 0.79874, 0.011329, 0.0039554, 0.064493, 0.0019888, 0.14375, 0.00741, 0.4242, 0.029276]
Predicted label: 1
Correct prediction
Energy consumption = 140.696204 pJ
sum error= 22
Actual label: 3
Output voltages: [0.56691, 0.021299, 0.12706, 0.79867, 0.013402, 0.013786, 0.023533, 0.033886, 0.67701, 0.0028518]
Predicted label: 3
Correct prediction
Energy consumption = 144.040031 pJ
sum error= 22
Actual label: 0
Output voltages: [0.79878, 0.032833, 0.01851, 0.0022017, 0.01931, 0.017049, 0.53291, 0.010419, 0.12521, 0.031127]
Predicted label: 0
Correct prediction
Energy consumption = 157.666587 pJ
sum error= 22
Actual label: 3
Output voltages: [0.035536, 0.0033962, 0.0078296, 0.79759, 0.020292, 0.27358, 0.030692, 0.015888, 0.64194, 0.029037]
Predicted label: 3
Correct prediction
Energy consumption = 155.061031 pJ
sum error= 22
Actual label: 8
Output voltages: [0.74528, 0.016309, 0.47658, 0.22778, 0.01242, 0.05424, 0.0088956, 0.002856, 0.79879, 0.46364]
Predicted label: 8
Correct prediction
Energy consumption = 145.437856 pJ
sum error= 22
Actual label: 3
Output voltages: [0.29421, 0.002208, 0.20648, 0.79877, 0.0011854, 0.0017938, 0.018738, 0.03072, 0.7468, 0.0080649]
Predicted label: 3
Correct prediction
Energy consumption = 137.241111 pJ
sum error= 22
Actual label: 1
Output voltages: [0.0057825, 0.79856, 0.10488, 0.26873, 0.012987, 0.0023135, 0.77707, 0.0086869, 0.031636, 0.12043]
Predicted label: 1
Correct prediction
Energy consumption = 155.213574 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 53 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 53 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 53 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.15596, 0.068232, 0.018325, 0.031206, 0.77619, 0.0011509, 0.0024039, 0.0010736, 0.099743, 0.79695]
Predicted label: 9
Correct prediction
Energy consumption = 155.121171 pJ
sum error= 22
Actual label: 3
Output voltages: [0.20156, 0.0041485, 0.23896, 0.79875, 0.0012613, 0.0015831, 0.24235, 0.039284, 0.51678, 0.0050106]
Predicted label: 3
Correct prediction
Energy consumption = 152.056429 pJ
sum error= 22
Actual label: 4
Output voltages: [0.085103, 0.058614, 0.041127, 0.0097919, 0.79864, 0.0013548, 0.44771, 0.020086, 0.012787, 0.023619]
Predicted label: 4
Correct prediction
Energy consumption = 164.344470 pJ
sum error= 22
Actual label: 4
Output voltages: [0.011697, 0.025514, 0.49419, 0.0010722, 0.79868, 0.0010739, 0.16135, 0.00383, 0.017877, 0.34487]
Predicted label: 4
Correct prediction
Energy consumption = 149.784718 pJ
sum error= 22
Actual label: 6
Output voltages: [0.039693, 0.058011, 0.13285, 0.0037286, 0.12087, 0.11791, 0.79878, 0.008647, 0.71251, 0.006598]
Predicted label: 6
Correct prediction
Energy consumption = 149.832625 pJ
sum error= 22
Actual label: 4
Output voltages: [0.014819, 0.0073409, 0.31407, 0.0034188, 0.79868, 0.0063468, 0.31448, 0.29882, 0.025579, 0.010248]
Predicted label: 4
Correct prediction
Energy consumption = 149.125545 pJ
sum error= 22
Actual label: 2
Output voltages: [0.25916, 0.16168, 0.79879, 0.035881, 0.039486, 0.0012628, 0.25536, 0.53382, 0.37572, 0.02711]
Predicted label: 2
Correct prediction
Energy consumption = 153.263857 pJ
sum error= 22
Actual label: 1
Output voltages: [0.011577, 0.79869, 0.070709, 0.0085724, 0.02081, 0.0011254, 0.51337, 0.0011382, 0.48528, 0.01989]
Predicted label: 1
Correct prediction
Energy consumption = 157.979776 pJ
sum error= 22
Actual label: 8
Output voltages: [0.077822, 0.041472, 0.46975, 0.073837, 0.032439, 0.034336, 0.075165, 0.001303, 0.79879, 0.049364]
Predicted label: 8
Correct prediction
Energy consumption = 150.060552 pJ
sum error= 22
Actual label: 2
Output voltages: [0.74331, 0.013041, 0.79879, 0.04747, 0.056241, 0.0010897, 0.021487, 0.036718, 0.62443, 0.0054955]
Predicted label: 2
Correct prediction
Energy consumption = 141.006479 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 54 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 54 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 54 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.043457, 0.0016371, 0.004497, 0.47871, 0.020698, 0.7986, 0.03063, 0.045297, 0.77397, 0.082068]
Predicted label: 5
Correct prediction
Energy consumption = 149.800769 pJ
sum error= 22
Actual label: 4
Output voltages: [0.0024008, 0.016648, 0.18346, 0.027575, 0.79864, 0.0014285, 0.086651, 0.093513, 0.021541, 0.13577]
Predicted label: 4
Correct prediction
Energy consumption = 154.514462 pJ
sum error= 22
Actual label: 8
Output voltages: [0.0051619, 0.032731, 0.049701, 0.25485, 0.0038495, 0.016727, 0.017037, 0.022832, 0.79878, 0.35242]
Predicted label: 8
Correct prediction
Energy consumption = 147.930986 pJ
sum error= 22
Actual label: 8
Output voltages: [0.005383, 0.012697, 0.044036, 0.52345, 0.0052995, 0.025344, 0.003284, 0.059043, 0.79813, 0.42846]
Predicted label: 8
Correct prediction
Energy consumption = 148.070375 pJ
sum error= 22
Actual label: 4
Output voltages: [0.0056351, 0.073573, 0.073239, 0.015369, 0.79865, 0.013404, 0.21586, 0.16863, 0.0401, 0.035998]
Predicted label: 4
Correct prediction
Energy consumption = 158.427285 pJ
sum error= 22
Actual label: 0
Output voltages: [0.79876, 0.0267, 0.23173, 0.012251, 0.010176, 0.0032717, 0.34317, 0.015026, 0.27045, 0.22216]
Predicted label: 0
Correct prediction
Energy consumption = 150.658516 pJ
sum error= 22
Actual label: 0
Output voltages: [0.79869, 0.026936, 0.024873, 0.0025011, 0.013132, 0.0056346, 0.73389, 0.00965, 0.08568, 0.059097]
Predicted label: 0
Correct prediction
Energy consumption = 141.103370 pJ
sum error= 22
Actual label: 2
Output voltages: [0.033262, 0.11699, 0.79877, 0.36319, 0.0015374, 0.0010732, 0.37595, 0.0083069, 0.76963, 0.013746]
Predicted label: 2
Correct prediction
Energy consumption = 140.635613 pJ
sum error= 22
Actual label: 3
Output voltages: [0.5216, 0.012351, 0.42564, 0.79865, 0.014539, 0.04022, 0.0056424, 0.039967, 0.60817, 0.011794]
Predicted label: 3
Correct prediction
Energy consumption = 143.011073 pJ
sum error= 22
Actual label: 2
Output voltages: [0.56684, 0.024791, 0.79869, 0.10439, 0.0044779, 0.0010713, 0.40872, 0.037914, 0.29822, 0.0093887]
Predicted label: 2
Correct prediction
Energy consumption = 142.323631 pJ
sum error= 22
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 55 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 55 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 55 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.24774, 0.011355, 0.028077, 0.76633, 0.27628, 0.0011405, 0.0011698, 0.69776, 0.46362, 0.24679]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.024443 pJ
sum error= 23
Actual label: 7
Output voltages: [0.049267, 0.039974, 0.054231, 0.47116, 0.0012581, 0.0012332, 0.0011321, 0.7956, 0.19226, 0.21734]
Predicted label: 7
Correct prediction
Energy consumption = 141.539711 pJ
sum error= 23
Actual label: 0
Output voltages: [0.79775, 0.0028407, 0.0011626, 0.014064, 0.037558, 0.17006, 0.6839, 0.049304, 0.092005, 0.3172]
Predicted label: 0
Correct prediction
Energy consumption = 157.708456 pJ
sum error= 23
Actual label: 8
Output voltages: [0.014355, 0.01822, 0.0051263, 0.15261, 0.024599, 0.11513, 0.17878, 0.024146, 0.79879, 0.011152]
Predicted label: 8
Correct prediction
Energy consumption = 146.541596 pJ
sum error= 23
Actual label: 7
Output voltages: [0.0036946, 0.036363, 0.66668, 0.021865, 0.048724, 0.0010988, 0.0010726, 0.79864, 0.69864, 0.0083102]
Predicted label: 7
Correct prediction
Energy consumption = 150.350349 pJ
sum error= 23
Actual label: 4
Output voltages: [0.0079019, 0.030106, 0.096018, 0.0011279, 0.79878, 0.0013493, 0.10162, 0.029843, 0.034871, 0.047295]
Predicted label: 4
Correct prediction
Energy consumption = 151.499183 pJ
sum error= 23
Actual label: 4
Output voltages: [0.0052353, 0.034087, 0.063467, 0.0058409, 0.79859, 0.0055127, 0.088292, 0.026606, 0.035542, 0.14028]
Predicted label: 4
Correct prediction
Energy consumption = 142.313341 pJ
sum error= 23
Actual label: 7
Output voltages: [0.036214, 0.58551, 0.28554, 0.030524, 0.010411, 0.0011473, 0.0010806, 0.79876, 0.050094, 0.34032]
Predicted label: 7
Correct prediction
Energy consumption = 158.800321 pJ
sum error= 23
Actual label: 9
Output voltages: [0.23066, 0.029702, 0.013075, 0.045615, 0.069446, 0.010986, 0.014101, 0.026117, 0.25124, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 155.390512 pJ
sum error= 23
Actual label: 6
Output voltages: [0.30008, 0.0091969, 0.1843, 0.0010704, 0.30537, 0.020227, 0.79806, 0.0011093, 0.25522, 0.0035646]
Predicted label: 6
Correct prediction
Energy consumption = 139.629328 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 56 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 56 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 56 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.39898, 0.015007, 0.028439, 0.051047, 0.38307, 0.030102, 0.0084235, 0.0021852, 0.33374, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 151.257200 pJ
sum error= 23
Actual label: 0
Output voltages: [0.78741, 0.032669, 0.050085, 0.0136, 0.0010669, 0.015106, 0.72419, 0.026194, 0.13599, 0.031956]
Predicted label: 0
Correct prediction
Energy consumption = 146.946954 pJ
sum error= 23
Actual label: 9
Output voltages: [0.2407, 0.04943, 0.026782, 0.45273, 0.22909, 0.025371, 0.17741, 0.031964, 0.044678, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 151.431526 pJ
sum error= 23
Actual label: 8
Output voltages: [0.02212, 0.018275, 0.095612, 0.032138, 0.025488, 0.018469, 0.044257, 0.0090846, 0.79876, 0.28088]
Predicted label: 8
Correct prediction
Energy consumption = 149.713656 pJ
sum error= 23
Actual label: 0
Output voltages: [0.79866, 0.19496, 0.027177, 0.0069052, 0.014294, 0.002598, 0.61696, 0.030802, 0.052136, 0.25185]
Predicted label: 0
Correct prediction
Energy consumption = 157.415589 pJ
sum error= 23
Actual label: 4
Output voltages: [0.0011257, 0.008515, 0.024632, 0.0042783, 0.79865, 0.01548, 0.050783, 0.061385, 0.26286, 0.024038]
Predicted label: 4
Correct prediction
Energy consumption = 149.310677 pJ
sum error= 23
Actual label: 6
Output voltages: [0.050113, 0.030045, 0.032247, 0.018404, 0.31745, 0.11867, 0.79875, 0.0049822, 0.72618, 0.0012151]
Predicted label: 6
Correct prediction
Energy consumption = 146.462982 pJ
sum error= 23
Actual label: 0
Output voltages: [0.79875, 0.036871, 0.20662, 0.019839, 0.0033182, 0.028263, 0.30221, 0.019486, 0.27514, 0.13068]
Predicted label: 0
Correct prediction
Energy consumption = 153.629212 pJ
sum error= 23
Actual label: 6
Output voltages: [0.15331, 0.35731, 0.069642, 0.037027, 0.19154, 0.19169, 0.79879, 0.0016291, 0.74971, 0.0043533]
Predicted label: 6
Correct prediction
Energy consumption = 146.677608 pJ
sum error= 23
Actual label: 3
Output voltages: [0.004528, 0.0022824, 0.027332, 0.79879, 0.046488, 0.058333, 0.045564, 0.078051, 0.66185, 0.0056206]
Predicted label: 3
Correct prediction
Energy consumption = 144.996266 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 57 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 57 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 57 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.24404, 0.0098025, 0.014051, 0.66834, 0.026299, 0.79877, 0.04941, 0.033309, 0.77398, 0.4677]
Predicted label: 5
Correct prediction
Energy consumption = 148.419394 pJ
sum error= 23
Actual label: 4
Output voltages: [0.22158, 0.006942, 0.0090594, 0.010026, 0.79879, 0.0018633, 0.01634, 0.018856, 0.0081745, 0.70378]
Predicted label: 4
Correct prediction
Energy consumption = 152.723040 pJ
sum error= 23
Actual label: 8
Output voltages: [0.13345, 0.0011612, 0.15706, 0.23623, 0.015853, 0.047459, 0.0011389, 0.006743, 0.79876, 0.11004]
Predicted label: 8
Correct prediction
Energy consumption = 156.483550 pJ
sum error= 23
Actual label: 3
Output voltages: [0.4945, 0.011023, 0.018984, 0.79869, 0.013925, 0.021115, 0.056933, 0.0086513, 0.49946, 0.031854]
Predicted label: 3
Correct prediction
Energy consumption = 147.869059 pJ
sum error= 23
Actual label: 3
Output voltages: [0.6153, 0.046129, 0.069043, 0.79875, 0.0010746, 0.29063, 0.0012823, 0.21837, 0.6722, 0.006789]
Predicted label: 3
Correct prediction
Energy consumption = 141.316113 pJ
sum error= 23
Actual label: 9
Output voltages: [0.29827, 0.0070779, 0.0086791, 0.029116, 0.10043, 0.0077041, 0.0011201, 0.027485, 0.56704, 0.79336]
Predicted label: 9
Correct prediction
Energy consumption = 147.980729 pJ
sum error= 23
Actual label: 3
Output voltages: [0.27613, 0.0097736, 0.012605, 0.79866, 0.0054371, 0.055619, 0.014977, 0.031974, 0.68838, 0.038236]
Predicted label: 3
Correct prediction
Energy consumption = 140.910291 pJ
sum error= 23
Actual label: 3
Output voltages: [0.035672, 0.11449, 0.0078964, 0.79868, 0.010015, 0.0010867, 0.0036767, 0.10273, 0.44775, 0.053792]
Predicted label: 3
Correct prediction
Energy consumption = 131.006793 pJ
sum error= 23
Actual label: 3
Output voltages: [0.18175, 0.024516, 0.12656, 0.79806, 0.0021403, 0.009566, 0.0018044, 0.084822, 0.79182, 0.017742]
Predicted label: 3
Correct prediction
Energy consumption = 128.752390 pJ
sum error= 23
Actual label: 7
Output voltages: [0.57601, 0.025063, 0.01118, 0.35521, 0.078271, 0.014078, 0.0011098, 0.79862, 0.20891, 0.3014]
Predicted label: 7
Correct prediction
Energy consumption = 151.604321 pJ
sum error= 23
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 58 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 58 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 58 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.003825, 0.28002, 0.05321, 0.21269, 0.0045648, 0.0052217, 0.004646, 0.042338, 0.79875, 0.30553]
Predicted label: 8
Correct prediction
Energy consumption = 150.669360 pJ
sum error= 23
Actual label: 0
Output voltages: [0.79871, 0.012692, 0.038916, 0.0019066, 0.0074693, 0.012903, 0.59593, 0.005256, 0.088038, 0.036787]
Predicted label: 0
Correct prediction
Energy consumption = 154.114692 pJ
sum error= 23
Actual label: 8
Output voltages: [0.012909, 0.045225, 0.76556, 0.68205, 0.058064, 0.0012106, 0.069842, 0.0010989, 0.69114, 0.049359]
Predicted label: 2
Wrong prediction!
Energy consumption = 148.331427 pJ
sum error= 24
Actual label: 2
Output voltages: [0.10276, 0.0049974, 0.65457, 0.42678, 0.0013578, 0.001132, 0.0011986, 0.74145, 0.77411, 0.0061519]
Predicted label: 8
Wrong prediction!
Energy consumption = 139.095637 pJ
sum error= 25
Actual label: 1
Output voltages: [0.011485, 0.79869, 0.0042901, 0.46344, 0.095521, 0.019283, 0.037451, 0.30531, 0.026303, 0.046136]
Predicted label: 1
Correct prediction
Energy consumption = 162.258325 pJ
sum error= 25
Actual label: 7
Output voltages: [0.16474, 0.26943, 0.019923, 0.34181, 0.0064069, 0.0029762, 0.0010936, 0.79876, 0.16071, 0.38294]
Predicted label: 7
Correct prediction
Energy consumption = 155.099291 pJ
sum error= 25
Actual label: 0
Output voltages: [0.79875, 0.058771, 0.03291, 0.034198, 0.010897, 0.019105, 0.33031, 0.015314, 0.04362, 0.03648]
Predicted label: 0
Correct prediction
Energy consumption = 153.777193 pJ
sum error= 25
Actual label: 6
Output voltages: [0.16397, 0.043599, 0.055146, 0.0050433, 0.33603, 0.1629, 0.79873, 0.0020329, 0.59598, 0.013786]
Predicted label: 6
Correct prediction
Energy consumption = 142.576210 pJ
sum error= 25
Actual label: 5
Output voltages: [0.098497, 0.0013101, 0.0018536, 0.62441, 0.026288, 0.79879, 0.14315, 0.063989, 0.74051, 0.071983]
Predicted label: 5
Correct prediction
Energy consumption = 141.313370 pJ
sum error= 25
Actual label: 4
Output voltages: [0.0034653, 0.050372, 0.10857, 0.0047233, 0.79873, 0.0015471, 0.028589, 0.023408, 0.37544, 0.18815]
Predicted label: 4
Correct prediction
Energy consumption = 158.893935 pJ
sum error= 25
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 59 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 59 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 59 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.50697, 0.050738, 0.076776, 0.79868, 0.023823, 0.0027208, 0.0052505, 0.016703, 0.41828, 0.033796]
Predicted label: 3
Correct prediction
Energy consumption = 148.690744 pJ
sum error= 25
Actual label: 8
Output voltages: [0.42348, 0.36157, 0.36032, 0.76629, 0.001076, 0.0010665, 0.36954, 0.026206, 0.75105, 0.0085289]
Predicted label: 3
Wrong prediction!
Energy consumption = 152.132499 pJ
sum error= 26
Actual label: 0
Output voltages: [0.79878, 0.13501, 0.024717, 0.056171, 0.009452, 0.026405, 0.57987, 0.0095795, 0.083685, 0.073855]
Predicted label: 0
Correct prediction
Energy consumption = 148.780380 pJ
sum error= 26
Actual label: 9
Output voltages: [0.17837, 0.011886, 0.0057312, 0.018384, 0.037708, 0.0011618, 0.0010719, 0.010251, 0.67106, 0.79638]
Predicted label: 9
Correct prediction
Energy consumption = 150.127145 pJ
sum error= 26
Actual label: 6
Output voltages: [0.11539, 0.12589, 0.13801, 0.017982, 0.19626, 0.063244, 0.79878, 0.0055179, 0.68964, 0.0126]
Predicted label: 6
Correct prediction
Energy consumption = 155.766075 pJ
sum error= 26
Actual label: 3
Output voltages: [0.2626, 0.0086234, 0.24634, 0.79878, 0.18168, 0.040988, 0.029077, 0.013745, 0.6844, 0.0047224]
Predicted label: 3
Correct prediction
Energy consumption = 144.278100 pJ
sum error= 26
Actual label: 8
Output voltages: [0.032005, 0.0023859, 0.048954, 0.047672, 0.026192, 0.1874, 0.018079, 0.015157, 0.79862, 0.50119]
Predicted label: 8
Correct prediction
Energy consumption = 141.366443 pJ
sum error= 26
Actual label: 0
Output voltages: [0.79712, 0.0012305, 0.41804, 0.0014089, 0.19444, 0.022665, 0.65209, 0.14727, 0.0019179, 0.015096]
Predicted label: 0
Correct prediction
Energy consumption = 141.205031 pJ
sum error= 26
Actual label: 9
Output voltages: [0.28693, 0.0086739, 0.045478, 0.0030946, 0.16422, 0.0051547, 0.0010808, 0.042598, 0.58441, 0.79835]
Predicted label: 9
Correct prediction
Energy consumption = 151.137238 pJ
sum error= 26
Actual label: 9
Output voltages: [0.74698, 0.0069583, 0.026353, 0.10963, 0.12861, 0.028305, 0.0015347, 0.12213, 0.043496, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 146.016631 pJ
sum error= 26
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 60 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 60 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 60 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.050664, 0.049983, 0.34693, 0.0037646, 0.41766, 0.37113, 0.79876, 0.001091, 0.3873, 0.035882]
Predicted label: 6
Correct prediction
Energy consumption = 147.630289 pJ
sum error= 26
Actual label: 8
Output voltages: [0.20703, 0.06091, 0.061888, 0.14435, 0.031545, 0.0010659, 0.012576, 0.029475, 0.79803, 0.25362]
Predicted label: 8
Correct prediction
Energy consumption = 153.186746 pJ
sum error= 26
Actual label: 6
Output voltages: [0.39385, 0.031039, 0.23986, 0.0020592, 0.25386, 0.097315, 0.79877, 0.0012174, 0.58897, 0.022268]
Predicted label: 6
Correct prediction
Energy consumption = 137.080538 pJ
sum error= 26
Actual label: 8
Output voltages: [0.015188, 0.01576, 0.037995, 0.42637, 0.014271, 0.33392, 0.049139, 0.0015983, 0.79879, 0.20124]
Predicted label: 8
Correct prediction
Energy consumption = 147.189988 pJ
sum error= 26
Actual label: 5
Output voltages: [0.040725, 0.0029227, 0.014867, 0.31935, 0.011072, 0.79868, 0.17587, 0.028734, 0.74396, 0.034946]
Predicted label: 5
Correct prediction
Energy consumption = 142.612820 pJ
sum error= 26
Actual label: 7
Output voltages: [0.17197, 0.025441, 0.086782, 0.73121, 0.018948, 0.0010892, 0.0011536, 0.79811, 0.41845, 0.20994]
Predicted label: 7
Correct prediction
Energy consumption = 144.110209 pJ
sum error= 26
Actual label: 8
Output voltages: [0.030111, 0.038802, 0.13888, 0.69124, 0.0015398, 0.012904, 0.058566, 0.0025657, 0.79751, 0.38555]
Predicted label: 8
Correct prediction
Energy consumption = 147.680900 pJ
sum error= 26
Actual label: 6
Output voltages: [0.024862, 0.20982, 0.33386, 0.012145, 0.0401, 0.2832, 0.79876, 0.0032975, 0.58105, 0.017195]
Predicted label: 6
Correct prediction
Energy consumption = 146.604081 pJ
sum error= 26
Actual label: 0
Output voltages: [0.79876, 0.2117, 0.087493, 0.029071, 0.011772, 0.017014, 0.085189, 0.025839, 0.048187, 0.30911]
Predicted label: 0
Correct prediction
Energy consumption = 156.102235 pJ
sum error= 26
Actual label: 2
Output voltages: [0.36254, 0.21967, 0.79879, 0.038775, 0.022771, 0.0012927, 0.45657, 0.02094, 0.46982, 0.047418]
Predicted label: 2
Correct prediction
Energy consumption = 147.631072 pJ
sum error= 26
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 61 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 61 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 61 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.022958, 0.0033544, 0.13995, 0.0011322, 0.79874, 0.0011227, 0.17633, 0.008193, 0.54663, 0.0023521]
Predicted label: 4
Correct prediction
Energy consumption = 149.895358 pJ
sum error= 26
Actual label: 0
Output voltages: [0.79876, 0.022796, 0.16476, 0.019478, 0.020726, 0.0024606, 0.6291, 0.071083, 0.10786, 0.037082]
Predicted label: 0
Correct prediction
Energy consumption = 161.707086 pJ
sum error= 26
Actual label: 2
Output voltages: [0.44312, 0.041185, 0.79868, 0.095322, 0.032279, 0.0010876, 0.20233, 0.21122, 0.43134, 0.020006]
Predicted label: 2
Correct prediction
Energy consumption = 139.781808 pJ
sum error= 26
Actual label: 2
Output voltages: [0.29448, 0.15515, 0.78322, 0.75887, 0.0010811, 0.0011336, 0.031592, 0.0088079, 0.55803, 0.17028]
Predicted label: 2
Correct prediction
Energy consumption = 150.799163 pJ
sum error= 26
Actual label: 3
Output voltages: [0.30585, 0.17624, 0.045853, 0.79865, 0.017183, 0.0011817, 0.0028291, 0.011629, 0.28304, 0.27145]
Predicted label: 3
Correct prediction
Energy consumption = 143.502648 pJ
sum error= 26
Actual label: 1
Output voltages: [0.053637, 0.79879, 0.331, 0.028641, 0.26522, 0.0010687, 0.53147, 0.0014966, 0.22786, 0.006221]
Predicted label: 1
Correct prediction
Energy consumption = 148.797279 pJ
sum error= 26
Actual label: 9
Output voltages: [0.2078, 0.0078851, 0.016522, 0.17471, 0.37881, 0.19357, 0.0027624, 0.092849, 0.042728, 0.79811]
Predicted label: 9
Correct prediction
Energy consumption = 161.035241 pJ
sum error= 26
Actual label: 7
Output voltages: [0.08903, 0.0019448, 0.47937, 0.4246, 0.036895, 0.0011804, 0.0011095, 0.79776, 0.73819, 0.014993]
Predicted label: 7
Correct prediction
Energy consumption = 144.660067 pJ
sum error= 26
Actual label: 5
Output voltages: [0.10167, 0.0013132, 0.0020796, 0.71184, 0.016228, 0.79876, 0.054289, 0.044652, 0.74695, 0.03607]
Predicted label: 5
Correct prediction
Energy consumption = 144.576896 pJ
sum error= 26
Actual label: 1
Output voltages: [0.00449, 0.43234, 0.024671, 0.02232, 0.0016087, 0.0037829, 0.025432, 0.048031, 0.79877, 0.29651]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.373997 pJ
sum error= 27
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 62 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 62 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 62 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7987, 0.06415, 0.11297, 0.014947, 0.017815, 0.0020456, 0.4111, 0.02566, 0.21105, 0.032602]
Predicted label: 0
Correct prediction
Energy consumption = 161.446838 pJ
sum error= 27
Actual label: 8
Output voltages: [0.013418, 0.13447, 0.21057, 0.16611, 0.0089107, 0.013812, 0.029914, 0.0030354, 0.79879, 0.39658]
Predicted label: 8
Correct prediction
Energy consumption = 156.565607 pJ
sum error= 27
Actual label: 4
Output voltages: [0.026575, 0.025055, 0.044187, 0.012648, 0.79862, 0.0040391, 0.18844, 0.033229, 0.04273, 0.067057]
Predicted label: 4
Correct prediction
Energy consumption = 157.105892 pJ
sum error= 27
Actual label: 6
Output voltages: [0.040912, 0.011503, 0.34745, 0.0015801, 0.31021, 0.066265, 0.79879, 0.0017851, 0.45392, 0.0061656]
Predicted label: 6
Correct prediction
Energy consumption = 146.792549 pJ
sum error= 27
Actual label: 2
Output voltages: [0.010128, 0.30803, 0.79864, 0.0094209, 0.0037217, 0.001219, 0.18009, 0.017374, 0.73779, 0.1552]
Predicted label: 2
Correct prediction
Energy consumption = 147.432493 pJ
sum error= 27
Actual label: 6
Output voltages: [0.030529, 0.055812, 0.46485, 0.0011733, 0.7842, 0.028472, 0.79756, 0.0022221, 0.048487, 0.015793]
Predicted label: 6
Correct prediction
Energy consumption = 144.380574 pJ
sum error= 27
Actual label: 7
Output voltages: [0.063431, 0.22589, 0.57979, 0.10527, 0.016611, 0.0010745, 0.0010736, 0.79871, 0.26534, 0.21758]
Predicted label: 7
Correct prediction
Energy consumption = 155.502569 pJ
sum error= 27
Actual label: 9
Output voltages: [0.14788, 0.0092766, 0.048357, 0.042022, 0.046603, 0.040764, 0.03187, 0.053143, 0.40917, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 151.435668 pJ
sum error= 27
Actual label: 3
Output voltages: [0.023898, 0.030573, 0.28782, 0.79878, 0.011642, 0.0010661, 0.0022421, 0.025168, 0.34349, 0.41252]
Predicted label: 3
Correct prediction
Energy consumption = 142.978243 pJ
sum error= 27
Actual label: 2
Output voltages: [0.64504, 0.0037336, 0.79839, 0.15727, 0.0043752, 0.0010663, 0.058822, 0.065002, 0.45517, 0.002842]
Predicted label: 2
Correct prediction
Energy consumption = 139.357781 pJ
sum error= 27
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 63 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 63 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 63 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.11114, 0.040227, 0.031576, 0.30536, 0.034243, 0.061227, 0.031933, 0.065888, 0.33702, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 155.306749 pJ
sum error= 27
Actual label: 8
Output voltages: [0.11584, 0.01736, 0.25238, 0.012136, 0.030554, 0.018445, 0.032622, 0.030854, 0.79878, 0.28192]
Predicted label: 8
Correct prediction
Energy consumption = 149.821651 pJ
sum error= 27
Actual label: 2
Output voltages: [0.42953, 0.012652, 0.79876, 0.40684, 0.0022149, 0.0010677, 0.030858, 0.28548, 0.59889, 0.0070797]
Predicted label: 2
Correct prediction
Energy consumption = 145.901737 pJ
sum error= 27
Actual label: 2
Output voltages: [0.46773, 0.1143, 0.79866, 0.023522, 0.023386, 0.0012184, 0.31148, 0.033308, 0.31481, 0.027696]
Predicted label: 2
Correct prediction
Energy consumption = 137.049858 pJ
sum error= 27
Actual label: 9
Output voltages: [0.35905, 0.0090646, 0.023969, 0.018243, 0.17498, 0.099581, 0.0051846, 0.1829, 0.21236, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 148.213243 pJ
sum error= 27
Actual label: 2
Output voltages: [0.28596, 0.056353, 0.79879, 0.036372, 0.013099, 0.0012663, 0.42771, 0.023314, 0.48053, 0.062881]
Predicted label: 2
Correct prediction
Energy consumption = 147.082328 pJ
sum error= 27
Actual label: 7
Output voltages: [0.23105, 0.011222, 0.0054894, 0.024067, 0.024307, 0.0052278, 0.0010682, 0.7987, 0.71886, 0.41741]
Predicted label: 7
Correct prediction
Energy consumption = 151.981106 pJ
sum error= 27
Actual label: 3
Output voltages: [0.44643, 0.017182, 0.4031, 0.79879, 0.01369, 0.0010854, 0.010343, 0.026689, 0.7216, 0.0037991]
Predicted label: 3
Correct prediction
Energy consumption = 142.880210 pJ
sum error= 27
Actual label: 5
Output voltages: [0.19232, 0.0028958, 0.0010783, 0.48272, 0.02641, 0.79876, 0.10336, 0.068082, 0.52593, 0.0050266]
Predicted label: 5
Correct prediction
Energy consumption = 154.892173 pJ
sum error= 27
Actual label: 9
Output voltages: [0.32642, 0.01144, 0.030765, 0.042046, 0.50061, 0.004273, 0.0044702, 0.0056546, 0.47317, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 150.845338 pJ
sum error= 27
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 64 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 64 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 64 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.00501, 0.79863, 0.030473, 0.24645, 0.021349, 0.0019966, 0.0055108, 0.072389, 0.1476, 0.15904]
Predicted label: 1
Correct prediction
Energy consumption = 167.017810 pJ
sum error= 27
Actual label: 8
Output voltages: [0.077565, 0.0098469, 0.039943, 0.74699, 0.0034712, 0.017374, 0.31232, 0.0010737, 0.79751, 0.088212]
Predicted label: 8
Correct prediction
Energy consumption = 150.334098 pJ
sum error= 27
Actual label: 0
Output voltages: [0.79875, 0.0017904, 0.007581, 0.02692, 0.0070964, 0.20746, 0.031982, 0.19542, 0.012034, 0.15907]
Predicted label: 0
Correct prediction
Energy consumption = 136.282859 pJ
sum error= 27
Actual label: 2
Output voltages: [0.16598, 0.15469, 0.79878, 0.099999, 0.017839, 0.001336, 0.082416, 0.02205, 0.31701, 0.039418]
Predicted label: 2
Correct prediction
Energy consumption = 149.356478 pJ
sum error= 27
Actual label: 0
Output voltages: [0.79879, 0.092227, 0.096566, 0.01258, 0.028049, 0.0015022, 0.4124, 0.01639, 0.059946, 0.34196]
Predicted label: 0
Correct prediction
Energy consumption = 153.952183 pJ
sum error= 27
Actual label: 5
Output voltages: [0.031281, 0.0010934, 0.024234, 0.28394, 0.056659, 0.79057, 0.59469, 0.0021891, 0.75117, 0.058278]
Predicted label: 5
Correct prediction
Energy consumption = 152.042163 pJ
sum error= 27
Actual label: 2
Output voltages: [0.06795, 0.44669, 0.72411, 0.050889, 0.27847, 0.0043392, 0.78459, 0.0030051, 0.293, 0.0011097]
Predicted label: 6
Wrong prediction!
Energy consumption = 150.895978 pJ
sum error= 28
Actual label: 1
Output voltages: [0.035495, 0.79844, 0.034847, 0.040075, 0.052881, 0.0074276, 0.27614, 0.032625, 0.042585, 0.29557]
Predicted label: 1
Correct prediction
Energy consumption = 166.643823 pJ
sum error= 28
Actual label: 3
Output voltages: [0.11941, 0.025503, 0.040858, 0.79875, 0.011369, 0.005901, 0.0051315, 0.0089843, 0.75005, 0.040922]
Predicted label: 3
Correct prediction
Energy consumption = 139.526929 pJ
sum error= 28
Actual label: 7
Output voltages: [0.19524, 0.038559, 0.38482, 0.68454, 0.0017583, 0.0010838, 0.0031847, 0.7985, 0.03889, 0.69853]
Predicted label: 7
Correct prediction
Energy consumption = 156.188391 pJ
sum error= 28
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 65 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 65 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 65 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.1162, 0.040609, 0.036166, 0.0020409, 0.13457, 0.49118, 0.79874, 0.011386, 0.39207, 0.00699]
Predicted label: 6
Correct prediction
Energy consumption = 152.569231 pJ
sum error= 28
Actual label: 7
Output voltages: [0.13569, 0.021616, 0.037753, 0.27728, 0.0065629, 0.0041227, 0.001085, 0.79862, 0.16482, 0.38972]
Predicted label: 7
Correct prediction
Energy consumption = 162.451690 pJ
sum error= 28
Actual label: 1
Output voltages: [0.014476, 0.79853, 0.043894, 0.082553, 0.026922, 0.0017423, 0.43422, 0.0014495, 0.36296, 0.076784]
Predicted label: 1
Correct prediction
Energy consumption = 161.428610 pJ
sum error= 28
Actual label: 2
Output voltages: [0.61961, 0.36544, 0.79878, 0.034171, 0.0065001, 0.0012675, 0.39824, 0.10009, 0.33047, 0.046744]
Predicted label: 2
Correct prediction
Energy consumption = 152.180861 pJ
sum error= 28
Actual label: 5
Output voltages: [0.10449, 0.0027204, 0.0011201, 0.51188, 0.00323, 0.79877, 0.018016, 0.011054, 0.70051, 0.10559]
Predicted label: 5
Correct prediction
Energy consumption = 152.285219 pJ
sum error= 28
Actual label: 8
Output voltages: [0.17048, 0.0035991, 0.49444, 0.11481, 0.0066221, 0.027242, 0.0072452, 0.010839, 0.79877, 0.028686]
Predicted label: 8
Correct prediction
Energy consumption = 142.647849 pJ
sum error= 28
Actual label: 0
Output voltages: [0.79872, 0.20256, 0.020439, 0.029174, 0.0018868, 0.1761, 0.42364, 0.014538, 0.30637, 0.020594]
Predicted label: 0
Correct prediction
Energy consumption = 152.116552 pJ
sum error= 28
Actual label: 3
Output voltages: [0.49056, 0.047306, 0.16196, 0.79862, 0.011831, 0.013263, 0.015197, 0.02041, 0.56747, 0.037688]
Predicted label: 3
Correct prediction
Energy consumption = 144.402882 pJ
sum error= 28
Actual label: 7
Output voltages: [0.48429, 0.016326, 0.0062392, 0.037037, 0.64449, 0.002118, 0.0010713, 0.79878, 0.13619, 0.052488]
Predicted label: 7
Correct prediction
Energy consumption = 143.971527 pJ
sum error= 28
Actual label: 2
Output voltages: [0.073893, 0.58921, 0.78053, 0.012827, 0.022695, 0.0012865, 0.014811, 0.57072, 0.4586, 0.0070044]
Predicted label: 2
Correct prediction
Energy consumption = 151.681797 pJ
sum error= 28
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 66 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 66 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 66 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.023289, 0.023416, 0.26822, 0.01989, 0.79873, 0.0010694, 0.54015, 0.072074, 0.0027719, 0.035602]
Predicted label: 4
Correct prediction
Energy consumption = 154.918897 pJ
sum error= 28
Actual label: 0
Output voltages: [0.79876, 0.078888, 0.052575, 0.029796, 0.0090613, 0.0046565, 0.72202, 0.12819, 0.11339, 0.34563]
Predicted label: 0
Correct prediction
Energy consumption = 164.193538 pJ
sum error= 28
Actual label: 9
Output voltages: [0.49738, 0.0053343, 0.026847, 0.25957, 0.17203, 0.0092254, 0.018663, 0.072304, 0.2036, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 154.389199 pJ
sum error= 28
Actual label: 1
Output voltages: [0.047785, 0.79854, 0.29603, 0.29607, 0.31055, 0.0016956, 0.55158, 0.012823, 0.022902, 0.066359]
Predicted label: 1
Correct prediction
Energy consumption = 171.642624 pJ
sum error= 28
Actual label: 8
Output voltages: [0.010914, 0.02732, 0.28646, 0.056518, 0.029249, 0.035364, 0.013731, 0.064224, 0.79863, 0.035767]
Predicted label: 8
Correct prediction
Energy consumption = 142.866749 pJ
sum error= 28
Actual label: 6
Output voltages: [0.26322, 0.036359, 0.32441, 0.0010859, 0.45338, 0.11166, 0.79875, 0.0018846, 0.26126, 0.011934]
Predicted label: 6
Correct prediction
Energy consumption = 144.542768 pJ
sum error= 28
Actual label: 7
Output voltages: [0.096657, 0.060222, 0.029612, 0.016029, 0.016741, 0.001069, 0.0010706, 0.79879, 0.032281, 0.54581]
Predicted label: 7
Correct prediction
Energy consumption = 155.029316 pJ
sum error= 28
Actual label: 7
Output voltages: [0.58097, 0.73221, 0.043585, 0.79133, 0.0010686, 0.0010713, 0.0012118, 0.7565, 0.55533, 0.027405]
Predicted label: 3
Wrong prediction!
Energy consumption = 157.121754 pJ
sum error= 29
Actual label: 4
Output voltages: [0.0010704, 0.13983, 0.29554, 0.011642, 0.79878, 0.0013098, 0.32716, 0.035509, 0.020863, 0.26626]
Predicted label: 4
Correct prediction
Energy consumption = 157.064337 pJ
sum error= 29
Actual label: 3
Output voltages: [0.025628, 0.039473, 0.1052, 0.79862, 0.015287, 0.0027274, 0.011841, 0.020781, 0.21356, 0.48163]
Predicted label: 3
Correct prediction
Energy consumption = 150.436363 pJ
sum error= 29
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 67 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 67 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 67 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0013336, 0.016855, 0.015377, 0.0028236, 0.79865, 0.025103, 0.0090515, 0.030659, 0.27353, 0.056039]
Predicted label: 4
Correct prediction
Energy consumption = 147.906546 pJ
sum error= 29
Actual label: 9
Output voltages: [0.067061, 0.0015445, 0.011737, 0.47074, 0.2762, 0.11019, 0.12768, 0.020091, 0.12678, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 146.168686 pJ
sum error= 29
Actual label: 1
Output voltages: [0.048007, 0.79856, 0.28242, 0.14865, 0.12785, 0.0017758, 0.62151, 0.0033017, 0.057589, 0.019106]
Predicted label: 1
Correct prediction
Energy consumption = 167.886699 pJ
sum error= 29
Actual label: 9
Output voltages: [0.36339, 0.0052421, 0.033915, 0.017056, 0.037215, 0.015053, 0.0085193, 0.010305, 0.74786, 0.79519]
Predicted label: 9
Correct prediction
Energy consumption = 143.619161 pJ
sum error= 29
Actual label: 5
Output voltages: [0.042231, 0.0011121, 0.0020856, 0.79672, 0.13782, 0.77673, 0.18307, 0.016889, 0.45922, 0.0026987]
Predicted label: 3
Wrong prediction!
Energy consumption = 150.328861 pJ
sum error= 30
Actual label: 1
Output voltages: [0.053083, 0.79848, 0.067349, 0.046003, 0.020676, 0.0023054, 0.70143, 0.019874, 0.12582, 0.048232]
Predicted label: 1
Correct prediction
Energy consumption = 168.518626 pJ
sum error= 30
Actual label: 7
Output voltages: [0.10272, 0.262, 0.3795, 0.042571, 0.0012487, 0.0011556, 0.0011374, 0.79878, 0.64444, 0.38031]
Predicted label: 7
Correct prediction
Energy consumption = 151.380550 pJ
sum error= 30
Actual label: 3
Output voltages: [0.66925, 0.024379, 0.040918, 0.7987, 0.0087614, 0.018485, 0.015973, 0.011957, 0.56304, 0.022185]
Predicted label: 3
Correct prediction
Energy consumption = 143.595317 pJ
sum error= 30
Actual label: 9
Output voltages: [0.026881, 0.013987, 0.023323, 0.037407, 0.62547, 0.024937, 0.19429, 0.17253, 0.088414, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 153.717483 pJ
sum error= 30
Actual label: 7
Output voltages: [0.22005, 0.12797, 0.61315, 0.20599, 0.0030509, 0.0011419, 0.0036536, 0.79879, 0.033679, 0.33098]
Predicted label: 7
Correct prediction
Energy consumption = 160.043084 pJ
sum error= 30
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 68 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 68 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 68 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.26713, 0.033601, 0.54451, 0.001066, 0.36692, 0.05488, 0.79878, 0.0027376, 0.42852, 0.0084854]
Predicted label: 6
Correct prediction
Energy consumption = 144.199894 pJ
sum error= 30
Actual label: 9
Output voltages: [0.11001, 0.0027435, 0.043813, 0.060818, 0.056844, 0.040056, 0.0042483, 0.22211, 0.48847, 0.79813]
Predicted label: 9
Correct prediction
Energy consumption = 150.869372 pJ
sum error= 30
Actual label: 1
Output voltages: [0.049263, 0.79837, 0.2118, 0.067439, 0.017976, 0.0055569, 0.73443, 0.010313, 0.034657, 0.049547]
Predicted label: 1
Correct prediction
Energy consumption = 167.672393 pJ
sum error= 30
Actual label: 3
Output voltages: [0.46709, 0.021902, 0.038608, 0.79876, 0.0055318, 0.26086, 0.024605, 0.0036278, 0.34758, 0.030041]
Predicted label: 3
Correct prediction
Energy consumption = 154.052394 pJ
sum error= 30
Actual label: 7
Output voltages: [0.0025144, 0.26901, 0.42804, 0.75977, 0.0019828, 0.0090832, 0.0046809, 0.76887, 0.031153, 0.22635]
Predicted label: 7
Correct prediction
Energy consumption = 146.754520 pJ
sum error= 30
Actual label: 8
Output voltages: [0.017623, 0.047134, 0.59937, 0.083198, 0.017398, 0.0056476, 0.029035, 0.035118, 0.79877, 0.39091]
Predicted label: 8
Correct prediction
Energy consumption = 143.656127 pJ
sum error= 30
Actual label: 3
Output voltages: [0.48623, 0.0214, 0.19897, 0.79869, 0.033825, 0.0036724, 0.012034, 0.015457, 0.59178, 0.034742]
Predicted label: 3
Correct prediction
Energy consumption = 144.987550 pJ
sum error= 30
Actual label: 3
Output voltages: [0.042783, 0.043091, 0.10931, 0.79877, 0.0069198, 0.002222, 0.021597, 0.0017222, 0.55876, 0.21447]
Predicted label: 3
Correct prediction
Energy consumption = 132.490997 pJ
sum error= 30
Actual label: 6
Output voltages: [0.0038038, 0.0074255, 0.044543, 0.01706, 0.13148, 0.23728, 0.7987, 0.0022314, 0.78017, 0.066045]
Predicted label: 6
Correct prediction
Energy consumption = 148.849101 pJ
sum error= 30
Actual label: 7
Output voltages: [0.63307, 0.10938, 0.0010855, 0.027123, 0.73922, 0.0073726, 0.0037758, 0.78116, 0.058596, 0.53613]
Predicted label: 7
Correct prediction
Energy consumption = 164.667058 pJ
sum error= 30
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 69 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 69 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 69 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.1103, 0.030114, 0.79876, 0.39107, 0.024922, 0.0013582, 0.044245, 0.044048, 0.41637, 0.019078]
Predicted label: 2
Correct prediction
Energy consumption = 149.436989 pJ
sum error= 30
Actual label: 8
Output voltages: [0.0015434, 0.0015151, 0.086167, 0.012952, 0.75804, 0.005418, 0.021894, 0.37419, 0.79576, 0.015727]
Predicted label: 8
Correct prediction
Energy consumption = 143.314148 pJ
sum error= 30
Actual label: 5
Output voltages: [0.027064, 0.016625, 0.0010702, 0.74674, 0.0038641, 0.79869, 0.16686, 0.086123, 0.56949, 0.0095681]
Predicted label: 5
Correct prediction
Energy consumption = 152.614026 pJ
sum error= 30
Actual label: 8
Output voltages: [0.031197, 0.017059, 0.015058, 0.23079, 0.018495, 0.020381, 0.014922, 0.008283, 0.79877, 0.041023]
Predicted label: 8
Correct prediction
Energy consumption = 146.476399 pJ
sum error= 30
Actual label: 5
Output voltages: [0.024611, 0.023732, 0.0011131, 0.74649, 0.07432, 0.79869, 0.076804, 0.028844, 0.65093, 0.0084799]
Predicted label: 5
Correct prediction
Energy consumption = 152.509577 pJ
sum error= 30
Actual label: 1
Output voltages: [0.0080161, 0.79848, 0.02708, 0.10449, 0.12881, 0.0015775, 0.53508, 0.03257, 0.14508, 0.055054]
Predicted label: 1
Correct prediction
Energy consumption = 162.162132 pJ
sum error= 30
Actual label: 1
Output voltages: [0.038188, 0.79844, 0.0043463, 0.26733, 0.0061636, 0.029208, 0.25914, 0.036879, 0.43771, 0.17329]
Predicted label: 1
Correct prediction
Energy consumption = 148.704263 pJ
sum error= 30
Actual label: 4
Output voltages: [0.010993, 0.015411, 0.23192, 0.013384, 0.79851, 0.0090219, 0.10488, 0.051527, 0.037313, 0.033425]
Predicted label: 4
Correct prediction
Energy consumption = 153.241838 pJ
sum error= 30
Actual label: 4
Output voltages: [0.0012722, 0.0036279, 0.45661, 0.0018499, 0.79529, 0.0053227, 0.037065, 0.012649, 0.62463, 0.021113]
Predicted label: 4
Correct prediction
Energy consumption = 145.897106 pJ
sum error= 30
Actual label: 3
Output voltages: [0.083578, 0.017744, 0.21599, 0.79874, 0.02113, 0.01408, 0.0020037, 0.045989, 0.42831, 0.030929]
Predicted label: 3
Correct prediction
Energy consumption = 143.249730 pJ
sum error= 30
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 70 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 70 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 70 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.015253, 0.79841, 0.17521, 0.44346, 0.12049, 0.001079, 0.0079671, 0.010193, 0.11199, 0.1426]
Predicted label: 1
Correct prediction
Energy consumption = 165.558466 pJ
sum error= 30
Actual label: 0
Output voltages: [0.79877, 0.095387, 0.02727, 0.10723, 0.0030824, 0.032366, 0.44715, 0.04016, 0.15102, 0.01889]
Predicted label: 0
Correct prediction
Energy consumption = 151.732705 pJ
sum error= 30
Actual label: 7
Output voltages: [0.022832, 0.37493, 0.54325, 0.031376, 0.0049431, 0.0011141, 0.0010866, 0.79878, 0.64749, 0.27978]
Predicted label: 7
Correct prediction
Energy consumption = 158.268202 pJ
sum error= 30
Actual label: 7
Output voltages: [0.35866, 0.091559, 0.049569, 0.55355, 0.0013961, 0.0028035, 0.0011035, 0.79873, 0.024142, 0.53019]
Predicted label: 7
Correct prediction
Energy consumption = 145.595433 pJ
sum error= 30
Actual label: 0
Output voltages: [0.79879, 0.055765, 0.029931, 0.03037, 0.014636, 0.011901, 0.47548, 0.026687, 0.055164, 0.041465]
Predicted label: 0
Correct prediction
Energy consumption = 147.054533 pJ
sum error= 30
Actual label: 7
Output voltages: [0.037851, 0.076832, 0.025027, 0.17961, 0.0057765, 0.0016231, 0.0010863, 0.79865, 0.064396, 0.41432]
Predicted label: 7
Correct prediction
Energy consumption = 156.213803 pJ
sum error= 30
Actual label: 9
Output voltages: [0.53364, 0.0023115, 0.01995, 0.011828, 0.03093, 0.055097, 0.0025544, 0.59364, 0.29884, 0.79333]
Predicted label: 9
Correct prediction
Energy consumption = 148.108479 pJ
sum error= 30
Actual label: 4
Output voltages: [0.0010659, 0.062283, 0.063636, 0.0013178, 0.79404, 0.0012002, 0.0073743, 0.022729, 0.63402, 0.1798]
Predicted label: 4
Correct prediction
Energy consumption = 146.352674 pJ
sum error= 30
Actual label: 4
Output voltages: [0.021871, 0.015269, 0.063617, 0.0027397, 0.79865, 0.0056023, 0.19999, 0.036783, 0.060964, 0.019216]
Predicted label: 4
Correct prediction
Energy consumption = 151.087236 pJ
sum error= 30
Actual label: 8
Output voltages: [0.041307, 0.050469, 0.20109, 0.68112, 0.0012315, 0.025489, 0.071554, 0.0046603, 0.79878, 0.13225]
Predicted label: 8
Correct prediction
Energy consumption = 155.042394 pJ
sum error= 30
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 71 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 71 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 71 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.028126, 0.0010692, 0.0013665, 0.36274, 0.014616, 0.79826, 0.080075, 0.041185, 0.79289, 0.0051773]
Predicted label: 5
Correct prediction
Energy consumption = 147.293383 pJ
sum error= 30
Actual label: 5
Output voltages: [0.25306, 0.001115, 0.034538, 0.38289, 0.015805, 0.7955, 0.02349, 0.019571, 0.79614, 0.053967]
Predicted label: 8
Wrong prediction!
Energy consumption = 129.615776 pJ
sum error= 31
Actual label: 4
Output voltages: [0.023523, 0.021334, 0.032567, 0.029381, 0.7986, 0.0068783, 0.08676, 0.042972, 0.054613, 0.47536]
Predicted label: 4
Correct prediction
Energy consumption = 155.911213 pJ
sum error= 31
Actual label: 0
Output voltages: [0.79879, 0.10279, 0.038071, 0.016564, 0.0084053, 0.012937, 0.44841, 0.017726, 0.066569, 0.056397]
Predicted label: 0
Correct prediction
Energy consumption = 157.424474 pJ
sum error= 31
Actual label: 8
Output voltages: [0.40542, 0.0026393, 0.31908, 0.060909, 0.01041, 0.042536, 0.0024655, 0.0075383, 0.79876, 0.36011]
Predicted label: 8
Correct prediction
Energy consumption = 147.594227 pJ
sum error= 31
Actual label: 2
Output voltages: [0.29625, 0.02462, 0.7987, 0.27426, 0.0028177, 0.001111, 0.10366, 0.036883, 0.69501, 0.02409]
Predicted label: 2
Correct prediction
Energy consumption = 141.632155 pJ
sum error= 31
Actual label: 1
Output voltages: [0.14745, 0.78645, 0.46677, 0.7479, 0.0011954, 0.0011933, 0.080621, 0.060998, 0.1342, 0.025374]
Predicted label: 1
Correct prediction
Energy consumption = 151.342108 pJ
sum error= 31
Actual label: 0
Output voltages: [0.47904, 0.0023587, 0.10069, 0.26682, 0.052743, 0.001075, 0.74867, 0.0036222, 0.028394, 0.0075645]
Predicted label: 6
Wrong prediction!
Energy consumption = 143.387427 pJ
sum error= 32
Actual label: 8
Output voltages: [0.28879, 0.01642, 0.71234, 0.02366, 0.036013, 0.0025829, 0.055414, 0.0031614, 0.79879, 0.31037]
Predicted label: 8
Correct prediction
Energy consumption = 155.263626 pJ
sum error= 32
Actual label: 4
Output voltages: [0.023816, 0.012624, 0.056221, 0.0023106, 0.79867, 0.018637, 0.073415, 0.025858, 0.12344, 0.12828]
Predicted label: 4
Correct prediction
Energy consumption = 152.301013 pJ
sum error= 32
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 72 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 72 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 72 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.022363, 0.0015879, 0.049308, 0.3773, 0.033012, 0.79339, 0.42305, 0.0070294, 0.794, 0.026869]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.507408 pJ
sum error= 33
Actual label: 0
Output voltages: [0.79876, 0.041274, 0.042432, 0.049168, 0.0083424, 0.29695, 0.50904, 0.0014038, 0.024103, 0.40317]
Predicted label: 0
Correct prediction
Energy consumption = 149.520266 pJ
sum error= 33
Actual label: 4
Output voltages: [0.028946, 0.018424, 0.15126, 0.015019, 0.79865, 0.0082146, 0.22788, 0.25024, 0.046615, 0.024491]
Predicted label: 4
Correct prediction
Energy consumption = 153.786470 pJ
sum error= 33
Actual label: 0
Output voltages: [0.79867, 0.044232, 0.036036, 0.015123, 0.029269, 0.0024902, 0.75969, 0.039773, 0.21005, 0.076998]
Predicted label: 0
Correct prediction
Energy consumption = 158.624014 pJ
sum error= 33
Actual label: 6
Output voltages: [0.12171, 0.087627, 0.20203, 0.0072027, 0.25847, 0.17633, 0.7987, 0.0023929, 0.51562, 0.011322]
Predicted label: 6
Correct prediction
Energy consumption = 141.530662 pJ
sum error= 33
Actual label: 1
Output voltages: [0.003629, 0.79864, 0.0041502, 0.046461, 0.10392, 0.0026476, 0.41768, 0.0049735, 0.38771, 0.053976]
Predicted label: 1
Correct prediction
Energy consumption = 164.511012 pJ
sum error= 33
Actual label: 7
Output voltages: [0.022375, 0.020359, 0.071119, 0.052672, 0.063435, 0.05088, 0.0010683, 0.7942, 0.021092, 0.44547]
Predicted label: 7
Correct prediction
Energy consumption = 155.871538 pJ
sum error= 33
Actual label: 3
Output voltages: [0.19438, 0.0235, 0.051665, 0.79878, 0.0011199, 0.011024, 0.01423, 0.0084177, 0.28771, 0.039932]
Predicted label: 3
Correct prediction
Energy consumption = 142.536886 pJ
sum error= 33
Actual label: 2
Output voltages: [0.24661, 0.047171, 0.79879, 0.066001, 0.0039522, 0.0010714, 0.16237, 0.17877, 0.78978, 0.047359]
Predicted label: 2
Correct prediction
Energy consumption = 141.815290 pJ
sum error= 33
Actual label: 6
Output voltages: [0.24353, 0.003387, 0.064756, 0.014679, 0.37278, 0.58738, 0.79863, 0.0011157, 0.72766, 0.024819]
Predicted label: 6
Correct prediction
Energy consumption = 145.553132 pJ
sum error= 33
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 73 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 73 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 73 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.46638, 0.061392, 0.13894, 0.01073, 0.085784, 0.0027801, 0.0072789, 0.79879, 0.045127, 0.47255]
Predicted label: 7
Correct prediction
Energy consumption = 157.202979 pJ
sum error= 33
Actual label: 2
Output voltages: [0.70784, 0.004135, 0.79878, 0.18245, 0.026358, 0.0011157, 0.048729, 0.04764, 0.58437, 0.013243]
Predicted label: 2
Correct prediction
Energy consumption = 144.165852 pJ
sum error= 33
Actual label: 6
Output voltages: [0.27419, 0.036777, 0.18161, 0.0030053, 0.2594, 0.16143, 0.79879, 0.0014939, 0.5317, 0.021722]
Predicted label: 6
Correct prediction
Energy consumption = 145.564674 pJ
sum error= 33
Actual label: 9
Output voltages: [0.048791, 0.024615, 0.018986, 0.16093, 0.058501, 0.006845, 0.0016548, 0.034912, 0.43158, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 150.447428 pJ
sum error= 33
Actual label: 3
Output voltages: [0.47041, 0.0045632, 0.12048, 0.79872, 0.011105, 0.057811, 0.011932, 0.020926, 0.49274, 0.01287]
Predicted label: 3
Correct prediction
Energy consumption = 146.272076 pJ
sum error= 33
Actual label: 1
Output voltages: [0.036165, 0.79838, 0.072719, 0.18201, 0.058399, 0.035238, 0.50608, 0.0088683, 0.22274, 0.056065]
Predicted label: 1
Correct prediction
Energy consumption = 162.895822 pJ
sum error= 33
Actual label: 4
Output voltages: [0.013925, 0.0039323, 0.20891, 0.003178, 0.79854, 0.0023613, 0.34759, 0.056356, 0.11246, 0.04754]
Predicted label: 4
Correct prediction
Energy consumption = 150.038904 pJ
sum error= 33
Actual label: 6
Output voltages: [0.40163, 0.011984, 0.35136, 0.0010763, 0.25477, 0.21128, 0.79878, 0.0069959, 0.43664, 0.013012]
Predicted label: 6
Correct prediction
Energy consumption = 142.499549 pJ
sum error= 33
Actual label: 2
Output voltages: [0.31429, 0.097318, 0.79849, 0.41969, 0.0044265, 0.0012796, 0.16629, 0.0043137, 0.37824, 0.021288]
Predicted label: 2
Correct prediction
Energy consumption = 149.644493 pJ
sum error= 33
Actual label: 5
Output voltages: [0.17341, 0.0026524, 0.0020026, 0.3485, 0.029593, 0.79876, 0.53393, 0.031419, 0.74497, 0.036659]
Predicted label: 5
Correct prediction
Energy consumption = 146.108159 pJ
sum error= 33
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 74 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 74 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 74 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.11181, 0.10897, 0.014821, 0.13336, 0.55638, 0.0029049, 0.0010968, 0.0018627, 0.020353, 0.79878]
Predicted label: 9
Wrong prediction!
Energy consumption = 157.272633 pJ
sum error= 34
Actual label: 2
Output voltages: [0.22905, 0.33552, 0.79877, 0.040684, 0.0059781, 0.0012464, 0.17633, 0.13226, 0.67571, 0.30136]
Predicted label: 2
Correct prediction
Energy consumption = 149.826530 pJ
sum error= 34
Actual label: 0
Output voltages: [0.79868, 0.034171, 0.22957, 0.010301, 0.0085058, 0.01268, 0.17713, 0.0088575, 0.042076, 0.049902]
Predicted label: 0
Correct prediction
Energy consumption = 144.879412 pJ
sum error= 34
Actual label: 6
Output voltages: [0.41777, 0.012217, 0.18807, 0.0026037, 0.66062, 0.27314, 0.79878, 0.012041, 0.60749, 0.018077]
Predicted label: 6
Correct prediction
Energy consumption = 147.472541 pJ
sum error= 34
Actual label: 2
Output voltages: [0.35638, 0.1836, 0.79873, 0.10442, 0.018884, 0.0011107, 0.32922, 0.010923, 0.1023, 0.016437]
Predicted label: 2
Correct prediction
Energy consumption = 151.074098 pJ
sum error= 34
Actual label: 1
Output voltages: [0.011034, 0.79877, 0.0049032, 0.013492, 0.31156, 0.0099242, 0.66147, 0.0016313, 0.64257, 0.029698]
Predicted label: 1
Correct prediction
Energy consumption = 162.280509 pJ
sum error= 34
Actual label: 7
Output voltages: [0.022673, 0.43398, 0.050057, 0.065874, 0.0020867, 0.0010659, 0.0010674, 0.79871, 0.051258, 0.26458]
Predicted label: 7
Correct prediction
Energy consumption = 156.726453 pJ
sum error= 34
Actual label: 3
Output voltages: [0.04726, 0.027288, 0.053366, 0.79875, 0.014157, 0.0028301, 0.011273, 0.022882, 0.66796, 0.11208]
Predicted label: 3
Correct prediction
Energy consumption = 144.209106 pJ
sum error= 34
Actual label: 4
Output voltages: [0.05561, 0.015814, 0.092952, 0.019805, 0.79857, 0.0086247, 0.044442, 0.014374, 0.03099, 0.30186]
Predicted label: 4
Correct prediction
Energy consumption = 148.152091 pJ
sum error= 34
Actual label: 1
Output voltages: [0.012938, 0.79845, 0.04345, 0.027945, 0.011726, 0.0027108, 0.65672, 0.0028614, 0.39643, 0.02712]
Predicted label: 1
Correct prediction
Energy consumption = 166.285999 pJ
sum error= 34
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 75 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 75 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 75 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79861, 0.24999, 0.01792, 0.042435, 0.010582, 0.04038, 0.75377, 0.023972, 0.23093, 0.016865]
Predicted label: 0
Correct prediction
Energy consumption = 158.298323 pJ
sum error= 34
Actual label: 5
Output voltages: [0.02795, 0.0010686, 0.0032178, 0.37699, 0.30283, 0.79871, 0.058712, 0.045499, 0.77034, 0.40569]
Predicted label: 5
Correct prediction
Energy consumption = 144.952837 pJ
sum error= 34
Actual label: 4
Output voltages: [0.024619, 0.048768, 0.047648, 0.007956, 0.79877, 0.0010659, 0.179, 0.16099, 0.012198, 0.031098]
Predicted label: 4
Correct prediction
Energy consumption = 159.143738 pJ
sum error= 34
Actual label: 3
Output voltages: [0.755, 0.0010704, 0.58105, 0.79862, 0.014867, 0.0043974, 0.0062129, 0.03138, 0.70702, 0.015262]
Predicted label: 3
Correct prediction
Energy consumption = 145.811384 pJ
sum error= 34
Actual label: 1
Output voltages: [0.016109, 0.79853, 0.012932, 0.027044, 0.024129, 0.0024985, 0.509, 0.0098607, 0.6885, 0.030957]
Predicted label: 1
Correct prediction
Energy consumption = 163.091676 pJ
sum error= 34
Actual label: 1
Output voltages: [0.0095642, 0.79855, 0.033187, 0.22674, 0.047534, 0.030548, 0.055992, 0.010173, 0.022944, 0.32954]
Predicted label: 1
Correct prediction
Energy consumption = 158.677158 pJ
sum error= 34
Actual label: 7
Output voltages: [0.42782, 0.077017, 0.3295, 0.39409, 0.0069629, 0.0011573, 0.0010674, 0.79879, 0.26465, 0.14846]
Predicted label: 7
Correct prediction
Energy consumption = 156.108512 pJ
sum error= 34
Actual label: 4
Output voltages: [0.0018792, 0.0063917, 0.14984, 0.0099067, 0.79872, 0.0011187, 0.24767, 0.034367, 0.047148, 0.018343]
Predicted label: 4
Correct prediction
Energy consumption = 155.046140 pJ
sum error= 34
Actual label: 9
Output voltages: [0.55939, 0.028228, 0.028077, 0.195, 0.45986, 0.031671, 0.0048329, 0.018821, 0.22246, 0.79849]
Predicted label: 9
Correct prediction
Energy consumption = 147.567011 pJ
sum error= 34
Actual label: 9
Output voltages: [0.083041, 0.011898, 0.013596, 0.03152, 0.032456, 0.0062856, 0.0012368, 0.028088, 0.75623, 0.79666]
Predicted label: 9
Correct prediction
Energy consumption = 139.013958 pJ
sum error= 34
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 76 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 76 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 76 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.032833, 0.014755, 0.058443, 0.2342, 0.7965, 0.0010697, 0.001066, 0.0038157, 0.033017, 0.72449]
Predicted label: 4
Correct prediction
Energy consumption = 154.721503 pJ
sum error= 34
Actual label: 8
Output voltages: [0.021095, 0.030008, 0.33257, 0.053244, 0.012695, 0.015579, 0.068729, 0.0033152, 0.79879, 0.51811]
Predicted label: 8
Correct prediction
Energy consumption = 146.575222 pJ
sum error= 34
Actual label: 4
Output voltages: [0.035625, 0.0038009, 0.5261, 0.020807, 0.79873, 0.0015205, 0.17877, 0.041968, 0.019906, 0.10624]
Predicted label: 4
Correct prediction
Energy consumption = 153.090381 pJ
sum error= 34
Actual label: 0
Output voltages: [0.79017, 0.058149, 0.74422, 0.029413, 0.0010963, 0.0038015, 0.09379, 0.013117, 0.5736, 0.0085595]
Predicted label: 0
Correct prediction
Energy consumption = 148.892193 pJ
sum error= 34
Actual label: 2
Output voltages: [0.553, 0.0029153, 0.79879, 0.16905, 0.013263, 0.0010698, 0.070308, 0.097616, 0.70436, 0.010953]
Predicted label: 2
Correct prediction
Energy consumption = 132.992734 pJ
sum error= 34
Actual label: 4
Output voltages: [0.0016295, 0.0025435, 0.03109, 0.0059914, 0.7987, 0.0010744, 0.16148, 0.047939, 0.060078, 0.025199]
Predicted label: 4
Correct prediction
Energy consumption = 158.337684 pJ
sum error= 34
Actual label: 5
Output voltages: [0.038075, 0.0011334, 0.051993, 0.086276, 0.0020107, 0.79536, 0.025166, 0.016735, 0.79822, 0.019451]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.452194 pJ
sum error= 35
Actual label: 1
Output voltages: [0.24939, 0.79858, 0.22832, 0.027154, 0.45775, 0.001066, 0.07621, 0.0073707, 0.013652, 0.14788]
Predicted label: 1
Correct prediction
Energy consumption = 166.331531 pJ
sum error= 35
Actual label: 1
Output voltages: [0.024022, 0.79851, 0.046974, 0.077966, 0.0028543, 0.0015947, 0.78236, 0.001904, 0.043087, 0.085936]
Predicted label: 1
Correct prediction
Energy consumption = 148.325732 pJ
sum error= 35
Actual label: 6
Output voltages: [0.17882, 0.012963, 0.0097485, 0.048367, 0.035975, 0.76812, 0.79822, 0.0063689, 0.70664, 0.018982]
Predicted label: 6
Correct prediction
Energy consumption = 150.938614 pJ
sum error= 35
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 77 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 77 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 77 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.015372, 0.032645, 0.081133, 0.0026799, 0.79878, 0.0016379, 0.47528, 0.20134, 0.048551, 0.016593]
Predicted label: 4
Correct prediction
Energy consumption = 156.165384 pJ
sum error= 35
Actual label: 7
Output voltages: [0.26935, 0.080577, 0.023278, 0.0099107, 0.0059972, 0.020602, 0.0026361, 0.79879, 0.19207, 0.7483]
Predicted label: 7
Correct prediction
Energy consumption = 157.002542 pJ
sum error= 35
Actual label: 1
Output voltages: [0.016339, 0.79867, 0.0024393, 0.05639, 0.0024312, 0.0011257, 0.11763, 0.024277, 0.661, 0.16339]
Predicted label: 1
Correct prediction
Energy consumption = 161.153953 pJ
sum error= 35
Actual label: 9
Output voltages: [0.49339, 0.01962, 0.033319, 0.07452, 0.17302, 0.015787, 0.0065869, 0.069487, 0.081826, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 157.832490 pJ
sum error= 35
Actual label: 4
Output voltages: [0.015194, 0.039212, 0.16291, 0.0053622, 0.79866, 0.0011561, 0.0016218, 0.050391, 0.025366, 0.5838]
Predicted label: 4
Correct prediction
Energy consumption = 156.321536 pJ
sum error= 35
Actual label: 2
Output voltages: [0.52797, 0.034869, 0.79879, 0.070572, 0.011485, 0.0011821, 0.4528, 0.062206, 0.74991, 0.044221]
Predicted label: 2
Correct prediction
Energy consumption = 148.370137 pJ
sum error= 35
Actual label: 4
Output voltages: [0.013808, 0.002065, 0.33781, 0.0061403, 0.79875, 0.090702, 0.15849, 0.011721, 0.026561, 0.75178]
Predicted label: 4
Correct prediction
Energy consumption = 153.279057 pJ
sum error= 35
Actual label: 1
Output voltages: [0.35447, 0.79854, 0.047085, 0.29271, 0.021127, 0.0042111, 0.51913, 0.012887, 0.054514, 0.096093]
Predicted label: 1
Correct prediction
Energy consumption = 166.733560 pJ
sum error= 35
Actual label: 5
Output voltages: [0.027901, 0.0010704, 0.0020976, 0.14887, 0.080141, 0.79849, 0.17034, 0.026484, 0.78884, 0.038422]
Predicted label: 5
Correct prediction
Energy consumption = 144.346610 pJ
sum error= 35
Actual label: 5
Output voltages: [0.40966, 0.027641, 0.0011108, 0.57264, 0.16159, 0.79869, 0.30492, 0.0011672, 0.36779, 0.034639]
Predicted label: 5
Correct prediction
Energy consumption = 145.413350 pJ
sum error= 35
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 78 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 78 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 78 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.72544, 0.028626, 0.0022851, 0.79824, 0.015271, 0.75204, 0.013236, 0.29383, 0.48343, 0.0016635]
Predicted label: 3
Correct prediction
Energy consumption = 147.720158 pJ
sum error= 35
Actual label: 8
Output voltages: [0.41769, 0.32479, 0.029328, 0.052255, 0.0022047, 0.044302, 0.66236, 0.0012594, 0.79223, 0.013232]
Predicted label: 8
Correct prediction
Energy consumption = 152.481173 pJ
sum error= 35
Actual label: 3
Output voltages: [0.50693, 0.020107, 0.1271, 0.79871, 0.02053, 0.0083599, 0.01779, 0.020724, 0.60589, 0.016741]
Predicted label: 3
Correct prediction
Energy consumption = 142.218160 pJ
sum error= 35
Actual label: 1
Output voltages: [0.020288, 0.79855, 0.024193, 0.039116, 0.031056, 0.0042332, 0.3806, 0.0019169, 0.36591, 0.026471]
Predicted label: 1
Correct prediction
Energy consumption = 162.130634 pJ
sum error= 35
Actual label: 4
Output voltages: [0.029771, 0.0011481, 0.4706, 0.033654, 0.79862, 0.036024, 0.062373, 0.018265, 0.0244, 0.60265]
Predicted label: 4
Correct prediction
Energy consumption = 162.329483 pJ
sum error= 35
Actual label: 5
Output voltages: [0.061858, 0.0010697, 0.011724, 0.61153, 0.015032, 0.79871, 0.03311, 0.45121, 0.71419, 0.14092]
Predicted label: 5
Correct prediction
Energy consumption = 143.714278 pJ
sum error= 35
Actual label: 6
Output voltages: [0.41978, 0.036639, 0.03734, 0.015864, 0.040249, 0.71094, 0.79876, 0.004353, 0.47672, 0.0083204]
Predicted label: 6
Correct prediction
Energy consumption = 148.794952 pJ
sum error= 35
Actual label: 8
Output voltages: [0.31139, 0.0063589, 0.20575, 0.088159, 0.019869, 0.031264, 0.0099672, 0.0030101, 0.79878, 0.51086]
Predicted label: 8
Correct prediction
Energy consumption = 142.428176 pJ
sum error= 35
Actual label: 9
Output voltages: [0.044362, 0.0021544, 0.015513, 0.33333, 0.058679, 0.018877, 0.0026405, 0.42206, 0.38165, 0.79737]
Predicted label: 9
Correct prediction
Energy consumption = 158.535646 pJ
sum error= 35
Actual label: 4
Output voltages: [0.015989, 0.030381, 0.21919, 0.035676, 0.7987, 0.0011283, 0.12483, 0.058032, 0.0071642, 0.22759]
Predicted label: 4
Correct prediction
Energy consumption = 154.532777 pJ
sum error= 35
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 79 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 79 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 79 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.036969, 0.7985, 0.017355, 0.20793, 0.012265, 0.0018331, 0.62714, 0.0040381, 0.17846, 0.030163]
Predicted label: 1
Correct prediction
Energy consumption = 163.817135 pJ
sum error= 35
Actual label: 5
Output voltages: [0.0026031, 0.0011686, 0.031333, 0.10911, 0.1699, 0.79382, 0.041246, 0.12156, 0.76728, 0.24866]
Predicted label: 5
Correct prediction
Energy consumption = 149.790155 pJ
sum error= 35
Actual label: 3
Output voltages: [0.093091, 0.0095728, 0.036867, 0.79875, 0.011235, 0.010672, 0.0079233, 0.045022, 0.73209, 0.055886]
Predicted label: 3
Correct prediction
Energy consumption = 136.882846 pJ
sum error= 35
Actual label: 8
Output voltages: [0.020527, 0.032004, 0.31107, 0.069464, 0.0043048, 0.026341, 0.014136, 0.021431, 0.79878, 0.3323]
Predicted label: 8
Correct prediction
Energy consumption = 145.635333 pJ
sum error= 35
Actual label: 0
Output voltages: [0.79876, 0.24632, 0.015069, 0.015277, 0.0046999, 0.010445, 0.63907, 0.022963, 0.10545, 0.041306]
Predicted label: 0
Correct prediction
Energy consumption = 152.434945 pJ
sum error= 35
Actual label: 3
Output voltages: [0.7479, 0.2383, 0.15532, 0.79852, 0.010635, 0.054223, 0.028388, 0.024202, 0.32551, 0.011177]
Predicted label: 3
Correct prediction
Energy consumption = 153.012123 pJ
sum error= 35
Actual label: 2
Output voltages: [0.56286, 0.0032471, 0.79879, 0.056278, 0.026608, 0.0010995, 0.022071, 0.036693, 0.33934, 0.0092169]
Predicted label: 2
Correct prediction
Energy consumption = 146.397592 pJ
sum error= 35
Actual label: 5
Output voltages: [0.36745, 0.69327, 0.001072, 0.083292, 0.0011623, 0.73608, 0.02275, 0.0011283, 0.7754, 0.011709]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.705758 pJ
sum error= 36
Actual label: 1
Output voltages: [0.041853, 0.79845, 0.16673, 0.236, 0.035978, 0.0034274, 0.68945, 0.0013414, 0.023307, 0.36868]
Predicted label: 1
Correct prediction
Energy consumption = 155.443262 pJ
sum error= 36
Actual label: 2
Output voltages: [0.3996, 0.42072, 0.79876, 0.38964, 0.025543, 0.0011715, 0.24828, 0.10821, 0.33827, 0.056373]
Predicted label: 2
Correct prediction
Energy consumption = 147.699550 pJ
sum error= 36
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 80 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 80 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 80 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.5978, 0.031586, 0.50788, 0.42845, 0.047504, 0.0014384, 0.033058, 0.0010696, 0.79807, 0.36229]
Predicted label: 8
Correct prediction
Energy consumption = 158.198620 pJ
sum error= 36
Actual label: 3
Output voltages: [0.27538, 0.0091551, 0.049859, 0.79874, 0.023157, 0.023303, 0.039452, 0.031468, 0.67491, 0.022033]
Predicted label: 3
Correct prediction
Energy consumption = 140.377640 pJ
sum error= 36
Actual label: 4
Output voltages: [0.0015485, 0.027892, 0.058595, 0.0046768, 0.79868, 0.001979, 0.35255, 0.34119, 0.015105, 0.048549]
Predicted label: 4
Correct prediction
Energy consumption = 149.996235 pJ
sum error= 36
Actual label: 4
Output voltages: [0.016353, 0.0082617, 0.22619, 0.0010732, 0.79865, 0.0012202, 0.22536, 0.026465, 0.025992, 0.025479]
Predicted label: 4
Correct prediction
Energy consumption = 145.526364 pJ
sum error= 36
Actual label: 0
Output voltages: [0.79566, 0.0061646, 0.43188, 0.051812, 0.0017163, 0.0092125, 0.33662, 0.015927, 0.61212, 0.2752]
Predicted label: 0
Correct prediction
Energy consumption = 146.235457 pJ
sum error= 36
Actual label: 8
Output voltages: [0.058795, 0.0096597, 0.28324, 0.090752, 0.015384, 0.024377, 0.0087898, 0.026104, 0.79865, 0.038875]
Predicted label: 8
Correct prediction
Energy consumption = 146.094533 pJ
sum error= 36
Actual label: 8
Output voltages: [0.024906, 0.040035, 0.077635, 0.038765, 0.01424, 0.046255, 0.22607, 0.0099199, 0.79878, 0.27224]
Predicted label: 8
Correct prediction
Energy consumption = 148.567726 pJ
sum error= 36
Actual label: 3
Output voltages: [0.59128, 0.0069979, 0.32699, 0.79864, 0.032452, 0.01967, 0.011367, 0.016006, 0.57818, 0.010605]
Predicted label: 3
Correct prediction
Energy consumption = 146.071375 pJ
sum error= 36
Actual label: 3
Output voltages: [0.3377, 0.0051489, 0.025931, 0.79865, 0.032059, 0.021051, 0.054097, 0.020655, 0.36646, 0.024059]
Predicted label: 3
Correct prediction
Energy consumption = 136.898600 pJ
sum error= 36
Actual label: 1
Output voltages: [0.036757, 0.79844, 0.0025339, 0.046449, 0.075453, 0.023462, 0.18949, 0.0058179, 0.14064, 0.08062]
Predicted label: 1
Correct prediction
Energy consumption = 169.570173 pJ
sum error= 36
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 81 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 81 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 81 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.15402, 0.019605, 0.79529, 0.1456, 0.0012809, 0.0010847, 0.0098848, 0.79512, 0.38768, 0.04589]
Predicted label: 2
Wrong prediction!
Energy consumption = 151.212429 pJ
sum error= 37
Actual label: 3
Output voltages: [0.16466, 0.046243, 0.044864, 0.79864, 0.021043, 0.0021852, 0.0050478, 0.03784, 0.56409, 0.0435]
Predicted label: 3
Correct prediction
Energy consumption = 140.449478 pJ
sum error= 37
Actual label: 5
Output voltages: [0.041849, 0.0010828, 0.0034794, 0.26423, 0.039005, 0.79842, 0.16129, 0.027938, 0.78579, 0.1729]
Predicted label: 5
Correct prediction
Energy consumption = 143.712609 pJ
sum error= 37
Actual label: 9
Output voltages: [0.59411, 0.0028449, 0.080169, 0.0093727, 0.20393, 0.010626, 0.0038411, 0.018049, 0.76488, 0.79626]
Predicted label: 9
Correct prediction
Energy consumption = 142.677814 pJ
sum error= 37
Actual label: 6
Output voltages: [0.12933, 0.05397, 0.09414, 0.0061795, 0.36807, 0.28163, 0.79872, 0.0050854, 0.43106, 0.011332]
Predicted label: 6
Correct prediction
Energy consumption = 152.142430 pJ
sum error= 37
Actual label: 3
Output voltages: [0.45389, 0.0070763, 0.08741, 0.79869, 0.0086616, 0.026801, 0.016704, 0.0052849, 0.55, 0.11747]
Predicted label: 3
Correct prediction
Energy consumption = 150.669380 pJ
sum error= 37
Actual label: 2
Output voltages: [0.31595, 0.03548, 0.79878, 0.056349, 0.019488, 0.0012558, 0.47976, 0.023961, 0.75643, 0.07491]
Predicted label: 2
Correct prediction
Energy consumption = 146.167604 pJ
sum error= 37
Actual label: 6
Output voltages: [0.30045, 0.013982, 0.10254, 0.0052349, 0.45534, 0.028957, 0.79879, 0.0010663, 0.65622, 0.017314]
Predicted label: 6
Correct prediction
Energy consumption = 141.650885 pJ
sum error= 37
Actual label: 1
Output voltages: [0.073398, 0.79863, 0.026823, 0.07855, 0.0046246, 0.0011527, 0.73594, 0.0015529, 0.31726, 0.038382]
Predicted label: 1
Correct prediction
Energy consumption = 153.989269 pJ
sum error= 37
Actual label: 3
Output voltages: [0.72759, 0.0064791, 0.069782, 0.79879, 0.030648, 0.0053277, 0.0026627, 0.0267, 0.17729, 0.0030809]
Predicted label: 3
Correct prediction
Energy consumption = 143.885893 pJ
sum error= 37
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 82 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 82 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 82 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.31487, 0.058252, 0.45596, 0.0016671, 0.35703, 0.033333, 0.79879, 0.0010676, 0.42144, 0.031118]
Predicted label: 6
Correct prediction
Energy consumption = 148.576663 pJ
sum error= 37
Actual label: 0
Output voltages: [0.79879, 0.25334, 0.040301, 0.019691, 0.015105, 0.0064468, 0.32422, 0.011143, 0.037049, 0.37351]
Predicted label: 0
Correct prediction
Energy consumption = 153.516730 pJ
sum error= 37
Actual label: 7
Output voltages: [0.62298, 0.013378, 0.0067777, 0.3822, 0.005078, 0.032555, 0.0011221, 0.79875, 0.72997, 0.42051]
Predicted label: 7
Correct prediction
Energy consumption = 150.075856 pJ
sum error= 37
Actual label: 2
Output voltages: [0.12483, 0.036486, 0.79856, 0.070187, 0.047396, 0.0011352, 0.20544, 0.016155, 0.77801, 0.033887]
Predicted label: 2
Correct prediction
Energy consumption = 145.802958 pJ
sum error= 37
Actual label: 1
Output voltages: [0.0053045, 0.79852, 0.05155, 0.031002, 0.03943, 0.001502, 0.37288, 0.0078482, 0.24965, 0.016178]
Predicted label: 1
Correct prediction
Energy consumption = 159.353125 pJ
sum error= 37
Actual label: 7
Output voltages: [0.1891, 0.013528, 0.022414, 0.36627, 0.0019948, 0.0034544, 0.0011421, 0.79878, 0.61412, 0.59249]
Predicted label: 7
Correct prediction
Energy consumption = 160.797703 pJ
sum error= 37
Actual label: 1
Output voltages: [0.013091, 0.7984, 0.011059, 0.37497, 0.0073457, 0.0017728, 0.78457, 0.024138, 0.075105, 0.087765]
Predicted label: 1
Correct prediction
Energy consumption = 159.261408 pJ
sum error= 37
Actual label: 4
Output voltages: [0.0026222, 0.0055909, 0.018021, 0.034528, 0.79818, 0.035941, 0.01789, 0.010801, 0.1281, 0.20737]
Predicted label: 4
Correct prediction
Energy consumption = 144.349323 pJ
sum error= 37
Actual label: 2
Output voltages: [0.36554, 0.036625, 0.79876, 0.11738, 0.022832, 0.0012264, 0.22553, 0.016364, 0.54684, 0.028925]
Predicted label: 2
Correct prediction
Energy consumption = 147.065562 pJ
sum error= 37
Actual label: 4
Output voltages: [0.24878, 0.011973, 0.28252, 0.023315, 0.79862, 0.0010663, 0.06341, 0.018162, 0.76481, 0.0043662]
Predicted label: 4
Correct prediction
Energy consumption = 138.424233 pJ
sum error= 37
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 83 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 83 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 83 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.38587, 0.016448, 0.79877, 0.14561, 0.036202, 0.0011896, 0.047633, 0.16816, 0.32682, 0.034451]
Predicted label: 2
Correct prediction
Energy consumption = 154.411912 pJ
sum error= 37
Actual label: 1
Output voltages: [0.037408, 0.79852, 0.20275, 0.055228, 0.024252, 0.0010659, 0.50534, 0.0013179, 0.22655, 0.25174]
Predicted label: 1
Correct prediction
Energy consumption = 162.371902 pJ
sum error= 37
Actual label: 7
Output voltages: [0.019518, 0.0048676, 0.054573, 0.2548, 0.041845, 0.001085, 0.0013389, 0.79879, 0.20907, 0.35467]
Predicted label: 7
Correct prediction
Energy consumption = 146.638779 pJ
sum error= 37
Actual label: 9
Output voltages: [0.70591, 0.011168, 0.0013291, 0.22524, 0.522, 0.02902, 0.0028461, 0.0019348, 0.068224, 0.79786]
Predicted label: 9
Correct prediction
Energy consumption = 149.320817 pJ
sum error= 37
Actual label: 6
Output voltages: [0.060527, 0.3637, 0.054548, 0.039622, 0.056282, 0.018378, 0.79874, 0.001066, 0.73268, 0.0073791]
Predicted label: 6
Correct prediction
Energy consumption = 156.362496 pJ
sum error= 37
Actual label: 1
Output voltages: [0.035948, 0.79838, 0.032194, 0.063404, 0.045216, 0.0089269, 0.61596, 0.0096387, 0.10718, 0.055732]
Predicted label: 1
Correct prediction
Energy consumption = 160.095302 pJ
sum error= 37
Actual label: 1
Output voltages: [0.012448, 0.79866, 0.48473, 0.34369, 0.072864, 0.0011083, 0.17986, 0.015336, 0.1114, 0.050988]
Predicted label: 1
Correct prediction
Energy consumption = 150.552391 pJ
sum error= 37
Actual label: 2
Output voltages: [0.25309, 0.38979, 0.79877, 0.018814, 0.010194, 0.0013355, 0.11776, 0.071703, 0.30013, 0.013823]
Predicted label: 2
Correct prediction
Energy consumption = 144.041166 pJ
sum error= 37
Actual label: 4
Output voltages: [0.014344, 0.015962, 0.04844, 0.011191, 0.79861, 0.0011903, 0.022325, 0.17882, 0.017196, 0.3368]
Predicted label: 4
Correct prediction
Energy consumption = 152.096361 pJ
sum error= 37
Actual label: 8
Output voltages: [0.2509, 0.0010795, 0.0068274, 0.27488, 0.081397, 0.028066, 0.55619, 0.0010676, 0.79682, 0.023202]
Predicted label: 8
Correct prediction
Energy consumption = 147.670241 pJ
sum error= 37
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 84 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 84 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 84 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.016971, 0.79869, 0.15409, 0.17652, 0.059484, 0.001404, 0.60184, 0.0039892, 0.38252, 0.1122]
Predicted label: 1
Correct prediction
Energy consumption = 162.966125 pJ
sum error= 37
Actual label: 7
Output voltages: [0.10473, 0.010084, 0.2285, 0.030397, 0.034156, 0.0011601, 0.0011628, 0.79856, 0.27986, 0.38613]
Predicted label: 7
Correct prediction
Energy consumption = 149.131003 pJ
sum error= 37
Actual label: 7
Output voltages: [0.18496, 0.053366, 0.76703, 0.026746, 0.0041472, 0.0014021, 0.013199, 0.7843, 0.088003, 0.16722]
Predicted label: 7
Correct prediction
Energy consumption = 145.189765 pJ
sum error= 37
Actual label: 4
Output voltages: [0.010089, 0.005126, 0.28882, 0.0064706, 0.79856, 0.0020319, 0.15307, 0.020161, 0.035842, 0.089576]
Predicted label: 4
Correct prediction
Energy consumption = 154.321876 pJ
sum error= 37
Actual label: 8
Output voltages: [0.0058563, 0.12949, 0.036332, 0.062839, 0.001094, 0.021293, 0.0017015, 0.50623, 0.79878, 0.07058]
Predicted label: 8
Correct prediction
Energy consumption = 148.765159 pJ
sum error= 37
Actual label: 0
Output voltages: [0.79876, 0.050111, 0.027417, 0.045727, 0.0021047, 0.037877, 0.16029, 0.043483, 0.29692, 0.027171]
Predicted label: 0
Correct prediction
Energy consumption = 147.377288 pJ
sum error= 37
Actual label: 7
Output voltages: [0.79774, 0.020623, 0.050347, 0.033076, 0.10309, 0.0092606, 0.015248, 0.10116, 0.019277, 0.75176]
Predicted label: 0
Wrong prediction!
Energy consumption = 146.865534 pJ
sum error= 38
Actual label: 3
Output voltages: [0.23677, 0.041768, 0.28985, 0.79876, 0.02748, 0.0012764, 0.0053576, 0.0050194, 0.6369, 0.057913]
Predicted label: 3
Correct prediction
Energy consumption = 141.214052 pJ
sum error= 38
Actual label: 1
Output voltages: [0.011741, 0.79853, 0.061913, 0.18133, 0.097181, 0.0022863, 0.65239, 0.0047212, 0.034454, 0.037134]
Predicted label: 1
Correct prediction
Energy consumption = 157.170606 pJ
sum error= 38
Actual label: 3
Output voltages: [0.3186, 0.023882, 0.39546, 0.79878, 0.058252, 0.0014492, 0.0064731, 0.0034486, 0.64328, 0.011514]
Predicted label: 3
Correct prediction
Energy consumption = 147.279681 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 85 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 85 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 85 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.37634, 0.79869, 0.17251, 0.018416, 0.33402, 0.0020487, 0.16222, 0.001706, 0.28895, 0.056725]
Predicted label: 1
Correct prediction
Energy consumption = 164.955985 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79879, 0.050665, 0.062827, 0.032667, 0.029047, 0.0030198, 0.38238, 0.0075124, 0.33745, 0.057708]
Predicted label: 0
Correct prediction
Energy consumption = 155.726676 pJ
sum error= 38
Actual label: 7
Output voltages: [0.030418, 0.085634, 0.051696, 0.02718, 0.010223, 0.0010696, 0.0021654, 0.79855, 0.11897, 0.035102]
Predicted label: 7
Correct prediction
Energy consumption = 153.836966 pJ
sum error= 38
Actual label: 7
Output voltages: [0.11804, 0.21191, 0.51091, 0.15253, 0.0010829, 0.0010735, 0.0010659, 0.79873, 0.75646, 0.040439]
Predicted label: 7
Correct prediction
Energy consumption = 137.703793 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79842, 0.25886, 0.025686, 0.016131, 0.0027702, 0.0067557, 0.72395, 0.051993, 0.15811, 0.049337]
Predicted label: 0
Correct prediction
Energy consumption = 152.014263 pJ
sum error= 38
Actual label: 3
Output voltages: [0.11704, 0.016586, 0.11064, 0.79875, 0.016876, 0.0030829, 0.0030048, 0.020055, 0.59807, 0.043691]
Predicted label: 3
Correct prediction
Energy consumption = 146.708568 pJ
sum error= 38
Actual label: 5
Output voltages: [0.10938, 0.0010814, 0.0011257, 0.049495, 0.14971, 0.79849, 0.026648, 0.01578, 0.78222, 0.048528]
Predicted label: 5
Correct prediction
Energy consumption = 131.829691 pJ
sum error= 38
Actual label: 5
Output voltages: [0.028749, 0.021777, 0.0011438, 0.68746, 0.0013131, 0.79872, 0.028689, 0.072534, 0.60145, 0.023146]
Predicted label: 5
Correct prediction
Energy consumption = 146.410448 pJ
sum error= 38
Actual label: 2
Output voltages: [0.37623, 0.016823, 0.79876, 0.04804, 0.0080422, 0.001129, 0.030874, 0.039662, 0.48104, 0.010342]
Predicted label: 2
Correct prediction
Energy consumption = 152.584005 pJ
sum error= 38
Actual label: 7
Output voltages: [0.033206, 0.051298, 0.012797, 0.038658, 0.0099453, 0.0011369, 0.0010843, 0.79872, 0.029674, 0.54717]
Predicted label: 7
Correct prediction
Energy consumption = 156.462917 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 86 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 86 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 86 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.044698, 0.14267, 0.6733, 0.0013358, 0.20633, 0.16667, 0.79871, 0.0014037, 0.48002, 0.026019]
Predicted label: 6
Correct prediction
Energy consumption = 147.444063 pJ
sum error= 38
Actual label: 6
Output voltages: [0.42974, 0.011222, 0.22672, 0.0021745, 0.29627, 0.25016, 0.79879, 0.0023922, 0.43678, 0.0087504]
Predicted label: 6
Correct prediction
Energy consumption = 137.766225 pJ
sum error= 38
Actual label: 9
Output voltages: [0.42236, 0.011637, 0.037599, 0.025386, 0.021563, 0.015641, 0.0095524, 0.32941, 0.43308, 0.78837]
Predicted label: 9
Correct prediction
Energy consumption = 157.556286 pJ
sum error= 38
Actual label: 2
Output voltages: [0.69459, 0.0066978, 0.79878, 0.21001, 0.0014549, 0.001078, 0.036067, 0.36762, 0.72257, 0.0038529]
Predicted label: 2
Correct prediction
Energy consumption = 147.522406 pJ
sum error= 38
Actual label: 8
Output voltages: [0.056913, 0.042318, 0.27854, 0.02605, 0.025082, 0.026685, 0.02379, 0.0029281, 0.79878, 0.22842]
Predicted label: 8
Correct prediction
Energy consumption = 143.320833 pJ
sum error= 38
Actual label: 3
Output voltages: [0.67928, 0.025364, 0.03683, 0.79864, 0.0080215, 0.019943, 0.01883, 0.018677, 0.49901, 0.041303]
Predicted label: 3
Correct prediction
Energy consumption = 151.767411 pJ
sum error= 38
Actual label: 5
Output voltages: [0.016406, 0.0011499, 0.0054413, 0.36192, 0.039608, 0.79785, 0.42526, 0.033095, 0.61632, 0.32717]
Predicted label: 5
Correct prediction
Energy consumption = 147.569624 pJ
sum error= 38
Actual label: 2
Output voltages: [0.49604, 0.19795, 0.79876, 0.02666, 0.012227, 0.0014236, 0.28209, 0.054366, 0.30237, 0.03034]
Predicted label: 2
Correct prediction
Energy consumption = 156.081845 pJ
sum error= 38
Actual label: 2
Output voltages: [0.77876, 0.02247, 0.79807, 0.12997, 0.0038376, 0.0010682, 0.11975, 0.050798, 0.20124, 0.015008]
Predicted label: 2
Correct prediction
Energy consumption = 144.220575 pJ
sum error= 38
Actual label: 5
Output voltages: [0.049928, 0.0025263, 0.0066201, 0.39181, 0.016921, 0.79873, 0.08238, 0.0083551, 0.71715, 0.062492]
Predicted label: 5
Correct prediction
Energy consumption = 152.368346 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 87 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 87 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 87 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.050269, 0.021552, 0.021722, 0.009952, 0.07724, 0.12633, 0.7983, 0.02387, 0.7904, 0.029777]
Predicted label: 6
Correct prediction
Energy consumption = 149.849978 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79868, 0.024403, 0.055845, 0.028708, 0.030959, 0.0026891, 0.38376, 0.070293, 0.087353, 0.09981]
Predicted label: 0
Correct prediction
Energy consumption = 145.191730 pJ
sum error= 38
Actual label: 8
Output voltages: [0.02724, 0.019843, 0.018465, 0.38697, 0.0030914, 0.019097, 0.0066438, 0.0032352, 0.79873, 0.36708]
Predicted label: 8
Correct prediction
Energy consumption = 156.840980 pJ
sum error= 38
Actual label: 2
Output voltages: [0.24533, 0.045936, 0.79873, 0.063831, 0.03195, 0.0012257, 0.029928, 0.65218, 0.18232, 0.16929]
Predicted label: 2
Correct prediction
Energy consumption = 149.861924 pJ
sum error= 38
Actual label: 9
Output voltages: [0.32935, 0.0085779, 0.018122, 0.050263, 0.52028, 0.0014578, 0.0062136, 0.0021412, 0.46939, 0.7938]
Predicted label: 9
Correct prediction
Energy consumption = 157.101320 pJ
sum error= 38
Actual label: 2
Output voltages: [0.40696, 0.0047472, 0.79877, 0.19978, 0.0010862, 0.0011335, 0.010049, 0.29868, 0.74347, 0.0020377]
Predicted label: 2
Correct prediction
Energy consumption = 147.702564 pJ
sum error= 38
Actual label: 8
Output voltages: [0.16779, 0.030226, 0.32826, 0.24827, 0.002762, 0.27469, 0.017803, 0.0044775, 0.79869, 0.44633]
Predicted label: 8
Correct prediction
Energy consumption = 144.395860 pJ
sum error= 38
Actual label: 8
Output voltages: [0.084093, 0.02064, 0.33395, 0.061531, 0.026452, 0.0044904, 0.747, 0.0018035, 0.79871, 0.11534]
Predicted label: 8
Correct prediction
Energy consumption = 143.086761 pJ
sum error= 38
Actual label: 8
Output voltages: [0.19989, 0.012134, 0.57566, 0.033906, 0.047698, 0.015363, 0.30541, 0.003998, 0.79879, 0.45527]
Predicted label: 8
Correct prediction
Energy consumption = 147.048208 pJ
sum error= 38
Actual label: 8
Output voltages: [0.074063, 0.10855, 0.13946, 0.053824, 0.0016859, 0.026042, 0.051877, 0.0063977, 0.79879, 0.013887]
Predicted label: 8
Correct prediction
Energy consumption = 145.942535 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 88 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 88 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 88 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28632, 0.10845, 0.27594, 0.011324, 0.0077566, 0.033884, 0.001146, 0.79879, 0.2414, 0.74193]
Predicted label: 7
Correct prediction
Energy consumption = 148.339715 pJ
sum error= 38
Actual label: 4
Output voltages: [0.013343, 0.024097, 0.083181, 0.13945, 0.79824, 0.04566, 0.023766, 0.0030358, 0.17078, 0.77231]
Predicted label: 4
Correct prediction
Energy consumption = 159.305175 pJ
sum error= 38
Actual label: 9
Output voltages: [0.37018, 0.019386, 0.019075, 0.058136, 0.32675, 0.015911, 0.023854, 0.024777, 0.11707, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 145.545808 pJ
sum error= 38
Actual label: 3
Output voltages: [0.46333, 0.001508, 0.25304, 0.79858, 0.017184, 0.31566, 0.012476, 0.025048, 0.039767, 0.17719]
Predicted label: 3
Correct prediction
Energy consumption = 152.755284 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79874, 0.039691, 0.026627, 0.0022332, 0.039577, 0.0046629, 0.4785, 0.046914, 0.43153, 0.11776]
Predicted label: 0
Correct prediction
Energy consumption = 163.512399 pJ
sum error= 38
Actual label: 6
Output voltages: [0.19878, 0.014117, 0.077817, 0.0076993, 0.72303, 0.45928, 0.79879, 0.016962, 0.22361, 0.0029514]
Predicted label: 6
Correct prediction
Energy consumption = 140.162410 pJ
sum error= 38
Actual label: 6
Output voltages: [0.23673, 0.20437, 0.23323, 0.038622, 0.09931, 0.33875, 0.79869, 0.0021199, 0.43409, 0.026097]
Predicted label: 6
Correct prediction
Energy consumption = 143.078735 pJ
sum error= 38
Actual label: 3
Output voltages: [0.28036, 0.029299, 0.051362, 0.79864, 0.027164, 0.0048851, 0.011305, 0.023918, 0.48917, 0.086003]
Predicted label: 3
Correct prediction
Energy consumption = 148.938246 pJ
sum error= 38
Actual label: 2
Output voltages: [0.19959, 0.0050528, 0.79879, 0.26635, 0.01305, 0.0011016, 0.011344, 0.17198, 0.48086, 0.013398]
Predicted label: 2
Correct prediction
Energy consumption = 142.985953 pJ
sum error= 38
Actual label: 1
Output voltages: [0.0069014, 0.79845, 0.032287, 0.090805, 0.021433, 0.009062, 0.77192, 0.010966, 0.27985, 0.05312]
Predicted label: 1
Correct prediction
Energy consumption = 162.509796 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 89 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 89 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 89 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.25122, 0.0068478, 0.057182, 0.79872, 0.031968, 0.36027, 0.047266, 0.0096244, 0.60768, 0.03284]
Predicted label: 3
Correct prediction
Energy consumption = 149.464190 pJ
sum error= 38
Actual label: 2
Output voltages: [0.43397, 0.71742, 0.79878, 0.083852, 0.0092094, 0.0012413, 0.33473, 0.0022974, 0.52449, 0.27946]
Predicted label: 2
Correct prediction
Energy consumption = 148.463257 pJ
sum error= 38
Actual label: 2
Output voltages: [0.56308, 0.012861, 0.79871, 0.055895, 0.023968, 0.0011498, 0.19301, 0.029196, 0.49408, 0.05607]
Predicted label: 2
Correct prediction
Energy consumption = 143.010438 pJ
sum error= 38
Actual label: 9
Output voltages: [0.57349, 0.0134, 0.0066248, 0.029964, 0.068972, 0.13575, 0.048305, 0.043864, 0.27873, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 154.865359 pJ
sum error= 38
Actual label: 3
Output voltages: [0.45992, 0.02144, 0.45969, 0.79639, 0.011829, 0.0032052, 0.44024, 0.0017178, 0.74276, 0.0028665]
Predicted label: 3
Correct prediction
Energy consumption = 149.721946 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79415, 0.030548, 0.039415, 0.023079, 0.071732, 0.20175, 0.7583, 0.013757, 0.098606, 0.0093515]
Predicted label: 0
Correct prediction
Energy consumption = 157.142909 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79815, 0.022048, 0.028376, 0.0077417, 0.022889, 0.0055187, 0.75412, 0.017167, 0.052365, 0.033537]
Predicted label: 0
Correct prediction
Energy consumption = 138.542503 pJ
sum error= 38
Actual label: 5
Output voltages: [0.01193, 0.001331, 0.0053626, 0.41793, 0.062593, 0.79695, 0.43693, 0.012073, 0.77888, 0.040991]
Predicted label: 5
Correct prediction
Energy consumption = 140.647545 pJ
sum error= 38
Actual label: 7
Output voltages: [0.22993, 0.0060733, 0.1624, 0.66931, 0.0042922, 0.0011112, 0.0010677, 0.79558, 0.451, 0.09983]
Predicted label: 7
Correct prediction
Energy consumption = 147.124071 pJ
sum error= 38
Actual label: 8
Output voltages: [0.027591, 0.022456, 0.10131, 0.29192, 0.0042757, 0.24831, 0.018488, 0.0034355, 0.79876, 0.15986]
Predicted label: 8
Correct prediction
Energy consumption = 145.724394 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 90 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 90 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 90 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.012076, 0.79469, 0.0138, 0.78916, 0.29316, 0.71489, 0.15779, 0.0018649, 0.017804, 0.1398]
Predicted label: 1
Correct prediction
Energy consumption = 164.983946 pJ
sum error= 38
Actual label: 4
Output voltages: [0.010478, 0.091123, 0.088286, 0.025466, 0.79873, 0.011445, 0.031998, 0.030468, 0.0082728, 0.3279]
Predicted label: 4
Correct prediction
Energy consumption = 157.873527 pJ
sum error= 38
Actual label: 4
Output voltages: [0.010202, 0.013741, 0.016777, 0.0010898, 0.79845, 0.0074338, 0.010998, 0.058745, 0.43537, 0.14998]
Predicted label: 4
Correct prediction
Energy consumption = 150.290998 pJ
sum error= 38
Actual label: 6
Output voltages: [0.26568, 0.022371, 0.20802, 0.013958, 0.2141, 0.46881, 0.79877, 0.0017504, 0.45825, 0.013215]
Predicted label: 6
Correct prediction
Energy consumption = 147.806074 pJ
sum error= 38
Actual label: 0
Output voltages: [0.79814, 0.11734, 0.028105, 0.022283, 0.0039334, 0.01102, 0.73773, 0.019559, 0.081707, 0.15115]
Predicted label: 0
Correct prediction
Energy consumption = 154.373106 pJ
sum error= 38
Actual label: 2
Output voltages: [0.54019, 0.023908, 0.79875, 0.032543, 0.020029, 0.0011927, 0.1164, 0.025624, 0.36742, 0.029553]
Predicted label: 2
Correct prediction
Energy consumption = 150.069473 pJ
sum error= 38
Actual label: 9
Output voltages: [0.080802, 0.0010824, 0.034026, 0.057797, 0.76245, 0.011674, 0.0020402, 0.73822, 0.019214, 0.78215]
Predicted label: 9
Correct prediction
Energy consumption = 150.669256 pJ
sum error= 38
Actual label: 1
Output voltages: [0.0093913, 0.79879, 0.019342, 0.0085004, 0.073709, 0.001073, 0.52751, 0.014438, 0.3648, 0.10167]
Predicted label: 1
Correct prediction
Energy consumption = 157.791140 pJ
sum error= 38
Actual label: 4
Output voltages: [0.0014687, 0.018519, 0.21502, 0.038391, 0.79869, 0.0011053, 0.016492, 0.042036, 0.019533, 0.036746]
Predicted label: 4
Correct prediction
Energy consumption = 147.513065 pJ
sum error= 38
Actual label: 7
Output voltages: [0.21352, 0.063141, 0.022683, 0.19839, 0.0083808, 0.0029843, 0.0012507, 0.79879, 0.050788, 0.65567]
Predicted label: 7
Correct prediction
Energy consumption = 146.284333 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 91 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 91 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 91 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0014127, 0.01612, 0.049346, 0.0033571, 0.7986, 0.0031966, 0.30698, 0.3269, 0.052029, 0.030122]
Predicted label: 4
Correct prediction
Energy consumption = 153.965864 pJ
sum error= 38
Actual label: 7
Output voltages: [0.313, 0.2067, 0.58983, 0.14663, 0.0013509, 0.0011603, 0.0019823, 0.79877, 0.35743, 0.026568]
Predicted label: 7
Correct prediction
Energy consumption = 158.898797 pJ
sum error= 38
Actual label: 3
Output voltages: [0.037683, 0.012555, 0.046102, 0.79869, 0.041466, 0.006053, 0.01998, 0.01973, 0.61192, 0.22353]
Predicted label: 3
Correct prediction
Energy consumption = 141.555456 pJ
sum error= 38
Actual label: 9
Output voltages: [0.44389, 0.0044255, 0.099672, 0.045715, 0.55178, 0.015687, 0.014093, 0.013714, 0.062773, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 144.946545 pJ
sum error= 38
Actual label: 8
Output voltages: [0.032194, 0.028047, 0.081587, 0.35478, 0.0025752, 0.082881, 0.041879, 0.021662, 0.79875, 0.055882]
Predicted label: 8
Correct prediction
Energy consumption = 160.161987 pJ
sum error= 38
Actual label: 8
Output voltages: [0.040015, 0.029247, 0.049624, 0.24676, 0.0023789, 0.019586, 0.041825, 0.021981, 0.79864, 0.058825]
Predicted label: 8
Correct prediction
Energy consumption = 147.845509 pJ
sum error= 38
Actual label: 4
Output voltages: [0.36206, 0.0012137, 0.33685, 0.0011033, 0.79879, 0.0010807, 0.34413, 0.004967, 0.17371, 0.20941]
Predicted label: 4
Correct prediction
Energy consumption = 152.151053 pJ
sum error= 38
Actual label: 7
Output voltages: [0.039884, 0.089833, 0.025686, 0.10285, 0.012425, 0.0020394, 0.0010659, 0.79855, 0.051058, 0.13323]
Predicted label: 7
Correct prediction
Energy consumption = 156.248993 pJ
sum error= 38
Actual label: 1
Output voltages: [0.27953, 0.79865, 0.31853, 0.090925, 0.17049, 0.0077051, 0.49087, 0.0015284, 0.0097746, 0.090326]
Predicted label: 1
Correct prediction
Energy consumption = 161.313285 pJ
sum error= 38
Actual label: 2
Output voltages: [0.48816, 0.010388, 0.79875, 0.19692, 0.0024719, 0.0011317, 0.061387, 0.24223, 0.59754, 0.04648]
Predicted label: 2
Correct prediction
Energy consumption = 147.507389 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 92 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 92 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 92 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.019703, 0.79839, 0.0061828, 0.19217, 0.15192, 0.0014081, 0.097452, 0.033441, 0.12104, 0.38563]
Predicted label: 1
Correct prediction
Energy consumption = 167.618104 pJ
sum error= 38
Actual label: 2
Output voltages: [0.71264, 0.0079933, 0.79473, 0.30173, 0.013517, 0.0010915, 0.23272, 0.032038, 0.71287, 0.022281]
Predicted label: 2
Correct prediction
Energy consumption = 149.990355 pJ
sum error= 38
Actual label: 2
Output voltages: [0.20312, 0.39771, 0.79879, 0.095571, 0.0018693, 0.0012605, 0.14384, 0.044386, 0.54586, 0.069016]
Predicted label: 2
Correct prediction
Energy consumption = 138.632113 pJ
sum error= 38
Actual label: 3
Output voltages: [0.19321, 0.022098, 0.05352, 0.79875, 0.005766, 0.0011256, 0.013702, 0.020768, 0.66259, 0.018763]
Predicted label: 3
Correct prediction
Energy consumption = 135.399676 pJ
sum error= 38
Actual label: 2
Output voltages: [0.18248, 0.28586, 0.79873, 0.022724, 0.0011065, 0.0012068, 0.0077395, 0.75912, 0.50199, 0.035627]
Predicted label: 2
Correct prediction
Energy consumption = 139.419578 pJ
sum error= 38
Actual label: 3
Output voltages: [0.3096, 0.012671, 0.21451, 0.79871, 0.11489, 0.0033977, 0.0051289, 0.018817, 0.42425, 0.041387]
Predicted label: 3
Correct prediction
Energy consumption = 138.752412 pJ
sum error= 38
Actual label: 2
Output voltages: [0.71565, 0.32958, 0.7393, 0.014472, 0.052696, 0.0010708, 0.24489, 0.021044, 0.36185, 0.013761]
Predicted label: 2
Correct prediction
Energy consumption = 153.527259 pJ
sum error= 38
Actual label: 3
Output voltages: [0.50606, 0.022982, 0.15701, 0.79872, 0.0059855, 0.0096449, 0.022746, 0.015434, 0.36795, 0.046919]
Predicted label: 3
Correct prediction
Energy consumption = 150.464956 pJ
sum error= 38
Actual label: 9
Output voltages: [0.22446, 0.0073168, 0.021948, 0.017608, 0.13536, 0.027726, 0.0087155, 0.040528, 0.68073, 0.79322]
Predicted label: 9
Correct prediction
Energy consumption = 147.698860 pJ
sum error= 38
Actual label: 1
Output voltages: [0.0074907, 0.79845, 0.0066993, 0.32126, 0.049941, 0.046732, 0.13765, 0.016186, 0.16484, 0.062615]
Predicted label: 1
Correct prediction
Energy consumption = 170.372897 pJ
sum error= 38
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 93 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 93 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 93 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28868, 0.034193, 0.1412, 0.77273, 0.0080812, 0.0011819, 0.0016344, 0.74069, 0.37079, 0.26709]
Predicted label: 3
Wrong prediction!
Energy consumption = 152.891592 pJ
sum error= 39
Actual label: 4
Output voltages: [0.23334, 0.013911, 0.059365, 0.045737, 0.75059, 0.0068127, 0.039366, 0.10412, 0.032562, 0.76898]
Predicted label: 9
Wrong prediction!
Energy consumption = 156.579248 pJ
sum error= 40
Actual label: 0
Output voltages: [0.79853, 0.10409, 0.22926, 0.012541, 0.0015606, 0.051247, 0.26919, 0.0020455, 0.17625, 0.19962]
Predicted label: 0
Correct prediction
Energy consumption = 157.207822 pJ
sum error= 40
Actual label: 3
Output voltages: [0.6245, 0.024824, 0.03317, 0.79855, 0.043467, 0.037091, 0.047221, 0.018435, 0.6202, 0.023958]
Predicted label: 3
Correct prediction
Energy consumption = 150.990493 pJ
sum error= 40
Actual label: 5
Output voltages: [0.0049259, 0.0022233, 0.0054997, 0.19322, 0.054484, 0.78972, 0.18839, 0.10192, 0.30163, 0.54545]
Predicted label: 5
Correct prediction
Energy consumption = 151.220723 pJ
sum error= 40
Actual label: 5
Output voltages: [0.099907, 0.0016403, 0.0010812, 0.45163, 0.010527, 0.79876, 0.045157, 0.023287, 0.7831, 0.0043032]
Predicted label: 5
Correct prediction
Energy consumption = 132.358621 pJ
sum error= 40
Actual label: 8
Output voltages: [0.32593, 0.0012637, 0.19736, 0.15613, 0.029463, 0.75334, 0.011116, 0.0012823, 0.79877, 0.043093]
Predicted label: 8
Correct prediction
Energy consumption = 145.370826 pJ
sum error= 40
Actual label: 6
Output voltages: [0.20964, 0.012948, 0.4124, 0.0010666, 0.30735, 0.028237, 0.79875, 0.0023155, 0.41672, 0.006474]
Predicted label: 6
Correct prediction
Energy consumption = 147.984346 pJ
sum error= 40
Actual label: 3
Output voltages: [0.0045847, 0.0035372, 0.014583, 0.7638, 0.044396, 0.60494, 0.12707, 0.0012902, 0.78499, 0.11556]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.906547 pJ
sum error= 41
Actual label: 2
Output voltages: [0.49107, 0.017629, 0.79861, 0.14352, 0.010803, 0.0012761, 0.17248, 0.38488, 0.4711, 0.0045681]
Predicted label: 2
Correct prediction
Energy consumption = 150.338126 pJ
sum error= 41
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 94 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 94 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 94 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.42357, 0.0061731, 0.048337, 0.038431, 0.061726, 0.73714, 0.79815, 0.0010788, 0.43415, 0.11601]
Predicted label: 6
Correct prediction
Energy consumption = 148.625642 pJ
sum error= 41
Actual label: 7
Output voltages: [0.10833, 0.010636, 0.040072, 0.58004, 0.0079337, 0.0070388, 0.0011291, 0.79863, 0.49938, 0.51632]
Predicted label: 7
Correct prediction
Energy consumption = 158.207891 pJ
sum error= 41
Actual label: 6
Output voltages: [0.1773, 0.019728, 0.26423, 0.0015404, 0.31224, 0.35295, 0.79877, 0.0011978, 0.42955, 0.0085818]
Predicted label: 6
Correct prediction
Energy consumption = 148.620359 pJ
sum error= 41
Actual label: 6
Output voltages: [0.16074, 0.0042215, 0.091988, 0.0033823, 0.28255, 0.62172, 0.79828, 0.0079455, 0.5749, 0.0027449]
Predicted label: 6
Correct prediction
Energy consumption = 134.979318 pJ
sum error= 41
Actual label: 3
Output voltages: [0.192, 0.12129, 0.025184, 0.79864, 0.016989, 0.012234, 0.017019, 0.015741, 0.73328, 0.050845]
Predicted label: 3
Correct prediction
Energy consumption = 156.442386 pJ
sum error= 41
Actual label: 2
Output voltages: [0.52647, 0.14461, 0.79876, 0.10592, 0.034657, 0.0012172, 0.41937, 0.0096156, 0.4865, 0.05051]
Predicted label: 2
Correct prediction
Energy consumption = 143.737438 pJ
sum error= 41
Actual label: 7
Output voltages: [0.043661, 0.30234, 0.44891, 0.33174, 0.0013559, 0.0012599, 0.0013316, 0.79728, 0.039309, 0.31446]
Predicted label: 7
Correct prediction
Energy consumption = 156.145362 pJ
sum error= 41
Actual label: 8
Output voltages: [0.10255, 0.03159, 0.014281, 0.13728, 0.024061, 0.0020919, 0.015437, 0.02036, 0.59243, 0.79654]
Predicted label: 9
Wrong prediction!
Energy consumption = 156.105380 pJ
sum error= 42
Actual label: 1
Output voltages: [0.013207, 0.79871, 0.0432, 0.083525, 0.029474, 0.0013346, 0.36352, 0.0039818, 0.045261, 0.032079]
Predicted label: 1
Correct prediction
Energy consumption = 164.037003 pJ
sum error= 42
Actual label: 1
Output voltages: [0.038203, 0.79866, 0.055425, 0.081659, 0.099114, 0.001696, 0.27354, 0.0037455, 0.14492, 0.045514]
Predicted label: 1
Correct prediction
Energy consumption = 152.101295 pJ
sum error= 42
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 95 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 95 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 95 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.050395, 0.0057921, 0.58402, 0.30024, 0.0223, 0.0012019, 0.0013979, 0.79017, 0.50057, 0.068686]
Predicted label: 7
Correct prediction
Energy consumption = 150.475858 pJ
sum error= 42
Actual label: 5
Output voltages: [0.047026, 0.0010745, 0.0010668, 0.012017, 0.16895, 0.78994, 0.037956, 0.063733, 0.75076, 0.40424]
Predicted label: 5
Correct prediction
Energy consumption = 155.862409 pJ
sum error= 42
Actual label: 6
Output voltages: [0.11188, 0.027379, 0.21894, 0.0013182, 0.16654, 0.40906, 0.79874, 0.008094, 0.4042, 0.012624]
Predicted label: 6
Correct prediction
Energy consumption = 144.844520 pJ
sum error= 42
Actual label: 4
Output voltages: [0.0047849, 0.016057, 0.095521, 0.011176, 0.79868, 0.0016464, 0.037059, 0.022022, 0.034215, 0.023497]
Predicted label: 4
Correct prediction
Energy consumption = 146.264857 pJ
sum error= 42
Actual label: 9
Output voltages: [0.48124, 0.021826, 0.02417, 0.045767, 0.045225, 0.051618, 0.001681, 0.038499, 0.27148, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 150.181847 pJ
sum error= 42
Actual label: 5
Output voltages: [0.035573, 0.0011376, 0.0096322, 0.38721, 0.025048, 0.79235, 0.23362, 0.021691, 0.78593, 0.016409]
Predicted label: 5
Correct prediction
Energy consumption = 145.264503 pJ
sum error= 42
Actual label: 1
Output voltages: [0.046782, 0.79139, 0.40234, 0.18557, 0.0096703, 0.0024793, 0.60427, 0.0021524, 0.44803, 0.001285]
Predicted label: 1
Correct prediction
Energy consumption = 153.940817 pJ
sum error= 42
Actual label: 3
Output voltages: [0.04068, 0.0023749, 0.042349, 0.79867, 0.067103, 0.042362, 0.13221, 0.00764, 0.55501, 0.074852]
Predicted label: 3
Correct prediction
Energy consumption = 143.291828 pJ
sum error= 42
Actual label: 3
Output voltages: [0.66732, 0.04086, 0.067103, 0.79877, 0.0087508, 0.01043, 0.0049353, 0.029435, 0.16666, 0.014628]
Predicted label: 3
Correct prediction
Energy consumption = 140.813210 pJ
sum error= 42
Actual label: 4
Output voltages: [0.002436, 0.095215, 0.089832, 0.40376, 0.79878, 0.005225, 0.099594, 0.011014, 0.02611, 0.46281]
Predicted label: 4
Correct prediction
Energy consumption = 153.479917 pJ
sum error= 42
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 96 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 96 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 96 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.16871, 0.0010663, 0.031829, 0.098881, 0.0065647, 0.016372, 0.0010686, 0.64279, 0.77839, 0.77224]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.270279 pJ
sum error= 43
Actual label: 8
Output voltages: [0.010871, 0.036542, 0.082058, 0.2902, 0.0027584, 0.014112, 0.0078881, 0.0069078, 0.79877, 0.06662]
Predicted label: 8
Correct prediction
Energy consumption = 142.302890 pJ
sum error= 43
Actual label: 9
Output voltages: [0.2753, 0.0014076, 0.011066, 0.0066463, 0.2651, 0.011139, 0.0025576, 0.21201, 0.31013, 0.79782]
Predicted label: 9
Correct prediction
Energy consumption = 149.438348 pJ
sum error= 43
Actual label: 1
Output voltages: [0.012478, 0.79872, 0.0014115, 0.031061, 0.62317, 0.0012459, 0.24098, 0.0025136, 0.29628, 0.43574]
Predicted label: 1
Correct prediction
Energy consumption = 161.858275 pJ
sum error= 43
Actual label: 1
Output voltages: [0.049741, 0.79874, 0.030983, 0.0030684, 0.17928, 0.0019551, 0.61021, 0.0064592, 0.34301, 0.012467]
Predicted label: 1
Correct prediction
Energy consumption = 146.557648 pJ
sum error= 43
Actual label: 6
Output voltages: [0.79166, 0.20961, 0.020325, 0.011953, 0.066052, 0.36963, 0.79403, 0.0983, 0.37464, 0.0010822]
Predicted label: 6
Correct prediction
Energy consumption = 141.219265 pJ
sum error= 43
Actual label: 9
Output voltages: [0.054218, 0.0048365, 0.017555, 0.022866, 0.017457, 0.0026084, 0.0010882, 0.079972, 0.76953, 0.78833]
Predicted label: 9
Correct prediction
Energy consumption = 152.102264 pJ
sum error= 43
Actual label: 1
Output voltages: [0.023116, 0.79844, 0.035227, 0.040734, 0.0074677, 0.0037234, 0.65585, 0.0022372, 0.27165, 0.036038]
Predicted label: 1
Correct prediction
Energy consumption = 165.263704 pJ
sum error= 43
Actual label: 4
Output voltages: [0.0085679, 0.008144, 0.51682, 0.0024627, 0.79861, 0.0010865, 0.045041, 0.03207, 0.014519, 0.35405]
Predicted label: 4
Correct prediction
Energy consumption = 154.446220 pJ
sum error= 43
Actual label: 4
Output voltages: [0.0033076, 0.0013296, 0.026519, 0.31756, 0.79777, 0.0052001, 0.019967, 0.036684, 0.39123, 0.032011]
Predicted label: 4
Correct prediction
Energy consumption = 142.741797 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 97 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 97 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 97 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.002476, 0.0010967, 0.0048728, 0.23919, 0.17014, 0.79336, 0.12195, 0.026424, 0.74534, 0.17635]
Predicted label: 5
Correct prediction
Energy consumption = 141.823150 pJ
sum error= 43
Actual label: 4
Output voltages: [0.0023685, 0.014159, 0.43682, 0.026021, 0.79873, 0.035521, 0.038246, 0.023029, 0.050625, 0.054319]
Predicted label: 4
Correct prediction
Energy consumption = 153.580400 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79876, 0.11913, 0.019948, 0.01072, 0.022322, 0.02053, 0.54306, 0.0069035, 0.047676, 0.035611]
Predicted label: 0
Correct prediction
Energy consumption = 151.157388 pJ
sum error= 43
Actual label: 6
Output voltages: [0.033986, 0.32894, 0.41328, 0.0014972, 0.26078, 0.18071, 0.79866, 0.0016335, 0.36846, 0.020105]
Predicted label: 6
Correct prediction
Energy consumption = 144.624694 pJ
sum error= 43
Actual label: 2
Output voltages: [0.21223, 0.04397, 0.79879, 0.086541, 0.015336, 0.0013428, 0.17085, 0.031354, 0.44172, 0.024878]
Predicted label: 2
Correct prediction
Energy consumption = 152.947352 pJ
sum error= 43
Actual label: 2
Output voltages: [0.56583, 0.0051959, 0.79758, 0.40779, 0.0025812, 0.0010993, 0.043853, 0.020086, 0.52591, 0.005107]
Predicted label: 2
Correct prediction
Energy consumption = 137.013266 pJ
sum error= 43
Actual label: 3
Output voltages: [0.037088, 0.2629, 0.3418, 0.79879, 0.05278, 0.0010708, 0.0023313, 0.0012518, 0.58742, 0.14399]
Predicted label: 3
Correct prediction
Energy consumption = 143.688631 pJ
sum error= 43
Actual label: 1
Output voltages: [0.010939, 0.7986, 0.33464, 0.0257, 0.25167, 0.0085506, 0.79603, 0.0035657, 0.01125, 0.03649]
Predicted label: 1
Correct prediction
Energy consumption = 163.126285 pJ
sum error= 43
Actual label: 5
Output voltages: [0.054779, 0.0048321, 0.036191, 0.4329, 0.018314, 0.79866, 0.02077, 0.011589, 0.77292, 0.24517]
Predicted label: 5
Correct prediction
Energy consumption = 151.674051 pJ
sum error= 43
Actual label: 1
Output voltages: [0.0046098, 0.79851, 0.031699, 0.06482, 0.0096545, 0.00109, 0.41848, 0.0045877, 0.22895, 0.20663]
Predicted label: 1
Correct prediction
Energy consumption = 160.728959 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 98 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 98 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 98 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.64378, 0.016516, 0.79879, 0.10484, 0.033796, 0.0011221, 0.18469, 0.046165, 0.46715, 0.029606]
Predicted label: 2
Correct prediction
Energy consumption = 153.354314 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79856, 0.037652, 0.021198, 0.028336, 0.020117, 0.0067347, 0.72271, 0.016085, 0.22005, 0.045951]
Predicted label: 0
Correct prediction
Energy consumption = 150.360352 pJ
sum error= 43
Actual label: 3
Output voltages: [0.15207, 0.034255, 0.12742, 0.79879, 0.010239, 0.0030778, 0.024321, 0.0021531, 0.70329, 0.044867]
Predicted label: 3
Correct prediction
Energy consumption = 152.775273 pJ
sum error= 43
Actual label: 8
Output voltages: [0.27932, 0.039506, 0.30849, 0.12858, 0.027709, 0.025805, 0.050268, 0.0013056, 0.79869, 0.077608]
Predicted label: 8
Correct prediction
Energy consumption = 150.119011 pJ
sum error= 43
Actual label: 1
Output voltages: [0.050462, 0.79858, 0.56483, 0.03033, 0.10243, 0.0039916, 0.65533, 0.0010838, 0.016162, 0.12892]
Predicted label: 1
Correct prediction
Energy consumption = 162.313050 pJ
sum error= 43
Actual label: 2
Output voltages: [0.24441, 0.024573, 0.79878, 0.11354, 0.022007, 0.0012634, 0.32943, 0.030236, 0.54574, 0.023086]
Predicted label: 2
Correct prediction
Energy consumption = 148.064173 pJ
sum error= 43
Actual label: 6
Output voltages: [0.038787, 0.15683, 0.38287, 0.0015809, 0.17063, 0.099694, 0.79876, 0.0011168, 0.49209, 0.029746]
Predicted label: 6
Correct prediction
Energy consumption = 152.898158 pJ
sum error= 43
Actual label: 7
Output voltages: [0.036025, 0.0022317, 0.023511, 0.1676, 0.03586, 0.021181, 0.0011251, 0.79859, 0.62359, 0.13675]
Predicted label: 7
Correct prediction
Energy consumption = 153.778205 pJ
sum error= 43
Actual label: 1
Output voltages: [0.004621, 0.79873, 0.019328, 0.039184, 0.52714, 0.0038667, 0.0099353, 0.18923, 0.036113, 0.43744]
Predicted label: 1
Correct prediction
Energy consumption = 158.752990 pJ
sum error= 43
Actual label: 6
Output voltages: [0.39232, 0.045009, 0.34011, 0.0022953, 0.24964, 0.038975, 0.79875, 0.0033759, 0.3386, 0.0062878]
Predicted label: 6
Correct prediction
Energy consumption = 155.587147 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 99 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 99 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 99 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.56582, 0.023807, 0.78695, 0.52981, 0.095313, 0.0012208, 0.029448, 0.046448, 0.67856, 0.027959]
Predicted label: 2
Correct prediction
Energy consumption = 153.743457 pJ
sum error= 43
Actual label: 3
Output voltages: [0.16238, 0.0207, 0.032536, 0.7987, 0.0062847, 0.035813, 0.0040587, 0.038777, 0.71115, 0.01696]
Predicted label: 3
Correct prediction
Energy consumption = 136.757975 pJ
sum error= 43
Actual label: 9
Output voltages: [0.36424, 0.0010824, 0.033587, 0.0099597, 0.29463, 0.0012576, 0.0010664, 0.37479, 0.56317, 0.73737]
Predicted label: 9
Correct prediction
Energy consumption = 153.988061 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79864, 0.040007, 0.053204, 0.035018, 0.064104, 0.022575, 0.11912, 0.026693, 0.18832, 0.051312]
Predicted label: 0
Correct prediction
Energy consumption = 154.363103 pJ
sum error= 43
Actual label: 1
Output voltages: [0.0037777, 0.79874, 0.31724, 0.23724, 0.0029991, 0.0025312, 0.017705, 0.046442, 0.65083, 0.016525]
Predicted label: 1
Correct prediction
Energy consumption = 165.531074 pJ
sum error= 43
Actual label: 2
Output voltages: [0.76515, 0.01814, 0.79871, 0.29102, 0.0023449, 0.0015415, 0.046098, 0.28924, 0.35033, 0.018987]
Predicted label: 2
Correct prediction
Energy consumption = 149.847572 pJ
sum error= 43
Actual label: 2
Output voltages: [0.48773, 0.16517, 0.79868, 0.044668, 0.025199, 0.0011689, 0.42522, 0.037246, 0.66637, 0.036631]
Predicted label: 2
Correct prediction
Energy consumption = 132.105046 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79874, 0.092681, 0.027324, 0.014518, 0.013948, 0.0076265, 0.45734, 0.010249, 0.087525, 0.030673]
Predicted label: 0
Correct prediction
Energy consumption = 145.506982 pJ
sum error= 43
Actual label: 8
Output voltages: [0.015616, 0.055862, 0.052711, 0.017254, 0.0088316, 0.028939, 0.027763, 0.03244, 0.79868, 0.032026]
Predicted label: 8
Correct prediction
Energy consumption = 139.877872 pJ
sum error= 43
Actual label: 9
Output voltages: [0.61512, 0.0020356, 0.23226, 0.043278, 0.2165, 0.059751, 0.035414, 0.3635, 0.047948, 0.79809]
Predicted label: 9
Correct prediction
Energy consumption = 162.245943 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 100 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 100 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 100 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.50382, 0.029808, 0.013037, 0.20507, 0.53053, 0.010049, 0.011557, 0.0019113, 0.098639, 0.7984]
Predicted label: 9
Correct prediction
Energy consumption = 151.665247 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79726, 0.1238, 0.013764, 0.012426, 0.039061, 0.016682, 0.77788, 0.018811, 0.071364, 0.022744]
Predicted label: 0
Correct prediction
Energy consumption = 155.397183 pJ
sum error= 43
Actual label: 2
Output voltages: [0.21148, 0.046978, 0.79878, 0.14469, 0.0079758, 0.0010892, 0.3489, 0.041471, 0.78884, 0.01982]
Predicted label: 2
Correct prediction
Energy consumption = 150.691124 pJ
sum error= 43
Actual label: 5
Output voltages: [0.0037114, 0.0010699, 0.0077137, 0.74093, 0.081401, 0.76103, 0.29702, 0.030321, 0.6411, 0.15041]
Predicted label: 5
Correct prediction
Energy consumption = 149.046885 pJ
sum error= 43
Actual label: 1
Output voltages: [0.3491, 0.79871, 0.01757, 0.2233, 0.51646, 0.0056863, 0.028134, 0.013734, 0.059274, 0.2823]
Predicted label: 1
Correct prediction
Energy consumption = 163.657654 pJ
sum error= 43
Actual label: 9
Output voltages: [0.046199, 0.0051395, 0.0098372, 0.10589, 0.05559, 0.001324, 0.0072844, 0.19725, 0.474, 0.79839]
Predicted label: 9
Correct prediction
Energy consumption = 158.308739 pJ
sum error= 43
Actual label: 7
Output voltages: [0.075198, 0.028348, 0.0053908, 0.18764, 0.015677, 0.010131, 0.0010659, 0.79878, 0.15231, 0.57268]
Predicted label: 7
Correct prediction
Energy consumption = 153.906769 pJ
sum error= 43
Actual label: 8
Output voltages: [0.026169, 0.032566, 0.0097463, 0.43441, 0.0071858, 0.017792, 0.025295, 0.0016455, 0.79878, 0.50518]
Predicted label: 8
Correct prediction
Energy consumption = 152.416721 pJ
sum error= 43
Actual label: 1
Output voltages: [0.011897, 0.79843, 0.03746, 0.067853, 0.057146, 0.012273, 0.55083, 0.0016059, 0.14595, 0.42172]
Predicted label: 1
Correct prediction
Energy consumption = 159.567795 pJ
sum error= 43
Actual label: 0
Output voltages: [0.79831, 0.031051, 0.0085175, 0.0055314, 0.0053369, 0.18806, 0.58114, 0.0047375, 0.21199, 0.047215]
Predicted label: 0
Correct prediction
Energy consumption = 153.613875 pJ
sum error= 43
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 101 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 101 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 101 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.013137, 0.0042803, 0.30766, 0.0016677, 0.79576, 0.0011622, 0.0097021, 0.44641, 0.34003, 0.050011]
Predicted label: 4
Correct prediction
Energy consumption = 157.205372 pJ
sum error= 43
Actual label: 1
Output voltages: [0.027893, 0.79855, 0.081838, 0.052781, 0.023779, 0.0047443, 0.47298, 0.0026708, 0.077678, 0.057239]
Predicted label: 1
Correct prediction
Energy consumption = 162.095437 pJ
sum error= 43
Actual label: 7
Output voltages: [0.22172, 0.011553, 0.043761, 0.67382, 0.14798, 0.0010849, 0.001159, 0.79437, 0.28329, 0.43849]
Predicted label: 7
Correct prediction
Energy consumption = 146.882361 pJ
sum error= 43
Actual label: 9
Output voltages: [0.44263, 0.014955, 0.029122, 0.02178, 0.60745, 0.028903, 0.022183, 0.020373, 0.36824, 0.79798]
Predicted label: 9
Correct prediction
Energy consumption = 153.235804 pJ
sum error= 43
Actual label: 6
Output voltages: [0.75432, 0.0011461, 0.0040684, 0.38075, 0.012532, 0.79857, 0.19887, 0.017106, 0.74628, 0.0071037]
Predicted label: 5
Wrong prediction!
Energy consumption = 140.944983 pJ
sum error= 44
Actual label: 4
Output voltages: [0.01055, 0.035944, 0.049974, 0.018671, 0.79879, 0.0010961, 0.004401, 0.056912, 0.43434, 0.022497]
Predicted label: 4
Correct prediction
Energy consumption = 158.256448 pJ
sum error= 44
Actual label: 2
Output voltages: [0.30736, 0.011203, 0.79879, 0.31033, 0.0057842, 0.0010785, 0.03675, 0.014551, 0.51647, 0.014389]
Predicted label: 2
Correct prediction
Energy consumption = 146.774428 pJ
sum error= 44
Actual label: 6
Output voltages: [0.046105, 0.017047, 0.77689, 0.0012062, 0.11112, 0.0055915, 0.79799, 0.0012644, 0.028973, 0.0054768]
Predicted label: 6
Correct prediction
Energy consumption = 142.345682 pJ
sum error= 44
Actual label: 8
Output voltages: [0.055416, 0.0032577, 0.033624, 0.10508, 0.011558, 0.18874, 0.022766, 0.0012413, 0.79878, 0.28461]
Predicted label: 8
Correct prediction
Energy consumption = 152.673434 pJ
sum error= 44
Actual label: 1
Output voltages: [0.028511, 0.79879, 0.0067988, 0.020955, 0.4035, 0.0038817, 0.18544, 0.0091946, 0.064835, 0.020865]
Predicted label: 1
Correct prediction
Energy consumption = 155.007192 pJ
sum error= 44
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 102 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 102 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 102 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.14596, 0.0089524, 0.34383, 0.79879, 0.021365, 0.001177, 0.01171, 0.0028263, 0.72216, 0.026434]
Predicted label: 3
Correct prediction
Energy consumption = 143.616221 pJ
sum error= 44
Actual label: 7
Output voltages: [0.75544, 0.063427, 0.35683, 0.001641, 0.0015434, 0.0022837, 0.0040306, 0.79572, 0.76982, 0.23152]
Predicted label: 7
Correct prediction
Energy consumption = 136.821606 pJ
sum error= 44
Actual label: 5
Output voltages: [0.034786, 0.0010845, 0.0039911, 0.28338, 0.23901, 0.79875, 0.036527, 0.039034, 0.77494, 0.31928]
Predicted label: 5
Correct prediction
Energy consumption = 145.150450 pJ
sum error= 44
Actual label: 4
Output voltages: [0.018027, 0.013689, 0.10117, 0.0084596, 0.79874, 0.0054239, 0.41154, 0.04501, 0.034286, 0.03514]
Predicted label: 4
Correct prediction
Energy consumption = 155.128208 pJ
sum error= 44
Actual label: 4
Output voltages: [0.0092295, 0.021625, 0.080786, 0.014566, 0.79857, 0.033265, 0.062922, 0.19759, 0.11338, 0.015318]
Predicted label: 4
Correct prediction
Energy consumption = 142.989961 pJ
sum error= 44
Actual label: 1
Output voltages: [0.029567, 0.79868, 0.047771, 0.072158, 0.082209, 0.0011805, 0.72554, 0.0040038, 0.17035, 0.027185]
Predicted label: 1
Correct prediction
Energy consumption = 155.126252 pJ
sum error= 44
Actual label: 8
Output voltages: [0.097162, 0.0013124, 0.0024399, 0.17672, 0.0073288, 0.75203, 0.037409, 0.0042459, 0.79872, 0.050392]
Predicted label: 8
Correct prediction
Energy consumption = 157.305489 pJ
sum error= 44
Actual label: 1
Output voltages: [0.075465, 0.79869, 0.34411, 0.033854, 0.071199, 0.0011495, 0.41209, 0.0038628, 0.13175, 0.027616]
Predicted label: 1
Correct prediction
Energy consumption = 166.405728 pJ
sum error= 44
Actual label: 3
Output voltages: [0.13567, 0.0070786, 0.14411, 0.79838, 0.036129, 0.016946, 0.012271, 0.0069527, 0.73743, 0.05633]
Predicted label: 3
Correct prediction
Energy consumption = 149.022206 pJ
sum error= 44
Actual label: 8
Output voltages: [0.028862, 0.24364, 0.022609, 0.06785, 0.010178, 0.018073, 0.01056, 0.054799, 0.79871, 0.064611]
Predicted label: 8
Correct prediction
Energy consumption = 150.197970 pJ
sum error= 44
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 103 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 103 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 103 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0030102, 0.79854, 0.11956, 0.046164, 0.010766, 0.001106, 0.32435, 0.0049137, 0.42771, 0.020027]
Predicted label: 1
Correct prediction
Energy consumption = 162.363842 pJ
sum error= 44
Actual label: 2
Output voltages: [0.048036, 0.015686, 0.79877, 0.085539, 0.077757, 0.0011325, 0.048917, 0.059445, 0.34185, 0.028547]
Predicted label: 2
Correct prediction
Energy consumption = 138.184080 pJ
sum error= 44
Actual label: 5
Output voltages: [0.04155, 0.0011027, 0.01236, 0.057601, 0.034031, 0.79879, 0.43884, 0.034767, 0.79303, 0.015862]
Predicted label: 5
Correct prediction
Energy consumption = 150.575338 pJ
sum error= 44
Actual label: 8
Output voltages: [0.048782, 0.74681, 0.052798, 0.18303, 0.019068, 0.0011045, 0.070984, 0.0011148, 0.76344, 0.21151]
Predicted label: 8
Correct prediction
Energy consumption = 159.512906 pJ
sum error= 44
Actual label: 0
Output voltages: [0.79876, 0.22171, 0.19567, 0.01901, 0.0039997, 0.0053061, 0.31103, 0.009828, 0.21273, 0.11808]
Predicted label: 0
Correct prediction
Energy consumption = 150.602795 pJ
sum error= 44
Actual label: 6
Output voltages: [0.05888, 0.025079, 0.35319, 0.001362, 0.33394, 0.017061, 0.79875, 0.0035486, 0.097536, 0.022086]
Predicted label: 6
Correct prediction
Energy consumption = 142.673048 pJ
sum error= 44
Actual label: 2
Output voltages: [0.36262, 0.28002, 0.79878, 0.022635, 0.01293, 0.0013936, 0.30972, 0.072726, 0.27856, 0.031296]
Predicted label: 2
Correct prediction
Energy consumption = 151.650411 pJ
sum error= 44
Actual label: 1
Output voltages: [0.0098597, 0.79841, 0.11354, 0.015612, 0.0080673, 0.0034823, 0.57917, 0.032106, 0.41144, 0.036947]
Predicted label: 1
Correct prediction
Energy consumption = 161.198924 pJ
sum error= 44
Actual label: 1
Output voltages: [0.072245, 0.79848, 0.02611, 0.12023, 0.004662, 0.0032117, 0.67859, 0.0012529, 0.070161, 0.054999]
Predicted label: 1
Correct prediction
Energy consumption = 150.045323 pJ
sum error= 44
Actual label: 7
Output voltages: [0.0012076, 0.71372, 0.62239, 0.76568, 0.59048, 0.0010802, 0.12959, 0.072135, 0.0033481, 0.27373]
Predicted label: 3
Wrong prediction!
Energy consumption = 148.641753 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 104 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 104 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 104 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.041567, 0.7984, 0.029497, 0.19834, 0.021778, 0.015482, 0.71655, 0.0079862, 0.020119, 0.053488]
Predicted label: 1
Correct prediction
Energy consumption = 164.664129 pJ
sum error= 45
Actual label: 5
Output voltages: [0.0032656, 0.0011319, 0.0027578, 0.065069, 0.20062, 0.79869, 0.35165, 0.0084571, 0.78042, 0.036684]
Predicted label: 5
Correct prediction
Energy consumption = 147.138740 pJ
sum error= 45
Actual label: 3
Output voltages: [0.047649, 0.012528, 0.075062, 0.79873, 0.26577, 0.03085, 0.042976, 0.0094066, 0.43025, 0.20751]
Predicted label: 3
Correct prediction
Energy consumption = 146.023033 pJ
sum error= 45
Actual label: 4
Output voltages: [0.028036, 0.018226, 0.1715, 0.00152, 0.79872, 0.033, 0.016251, 0.13759, 0.28599, 0.047142]
Predicted label: 4
Correct prediction
Energy consumption = 155.482631 pJ
sum error= 45
Actual label: 6
Output voltages: [0.55481, 0.13235, 0.51759, 0.0027378, 0.0061976, 0.001066, 0.76294, 0.0067548, 0.71613, 0.026046]
Predicted label: 6
Correct prediction
Energy consumption = 149.884256 pJ
sum error= 45
Actual label: 9
Output voltages: [0.22844, 0.14752, 0.14412, 0.049432, 0.74535, 0.0014963, 0.0010773, 0.0032897, 0.18559, 0.78069]
Predicted label: 9
Correct prediction
Energy consumption = 160.245937 pJ
sum error= 45
Actual label: 5
Output voltages: [0.040493, 0.0010707, 0.0020591, 0.38493, 0.04647, 0.79845, 0.041982, 0.010722, 0.73111, 0.32328]
Predicted label: 5
Correct prediction
Energy consumption = 147.997011 pJ
sum error= 45
Actual label: 0
Output voltages: [0.79879, 0.049779, 0.028212, 0.010786, 0.018452, 0.0053414, 0.74166, 0.010705, 0.19044, 0.098508]
Predicted label: 0
Correct prediction
Energy consumption = 141.948004 pJ
sum error= 45
Actual label: 9
Output voltages: [0.025333, 0.0023464, 0.017754, 0.058813, 0.48077, 0.26661, 0.28414, 0.027853, 0.034265, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 142.655499 pJ
sum error= 45
Actual label: 2
Output voltages: [0.56659, 0.016651, 0.79874, 0.15818, 0.030569, 0.0011446, 0.2752, 0.037511, 0.41262, 0.018844]
Predicted label: 2
Correct prediction
Energy consumption = 143.628840 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 105 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 105 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 105 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.63677, 0.0012, 0.79879, 0.18693, 0.010782, 0.001072, 0.0040027, 0.24486, 0.76367, 0.018479]
Predicted label: 2
Correct prediction
Energy consumption = 140.630650 pJ
sum error= 45
Actual label: 4
Output voltages: [0.011502, 0.095011, 0.035919, 0.0091254, 0.79877, 0.0030853, 0.18523, 0.37067, 0.041993, 0.043855]
Predicted label: 4
Correct prediction
Energy consumption = 152.038372 pJ
sum error= 45
Actual label: 8
Output voltages: [0.042343, 0.019614, 0.045722, 0.25226, 0.018796, 0.053795, 0.047833, 0.0028513, 0.79879, 0.25378]
Predicted label: 8
Correct prediction
Energy consumption = 148.659541 pJ
sum error= 45
Actual label: 2
Output voltages: [0.75263, 0.006331, 0.79878, 0.23479, 0.016626, 0.001066, 0.029447, 0.11623, 0.43907, 0.0077659]
Predicted label: 2
Correct prediction
Energy consumption = 150.682682 pJ
sum error= 45
Actual label: 1
Output voltages: [0.0075963, 0.79845, 0.042738, 0.055882, 0.013561, 0.00356, 0.58821, 0.020385, 0.13564, 0.025662]
Predicted label: 1
Correct prediction
Energy consumption = 162.635025 pJ
sum error= 45
Actual label: 7
Output voltages: [0.085296, 0.044361, 0.060361, 0.046028, 0.0030706, 0.001133, 0.0010688, 0.79872, 0.14615, 0.2906]
Predicted label: 7
Correct prediction
Energy consumption = 159.230696 pJ
sum error= 45
Actual label: 2
Output voltages: [0.61059, 0.049674, 0.79876, 0.22544, 0.026987, 0.0011683, 0.16533, 0.027606, 0.69684, 0.028224]
Predicted label: 2
Correct prediction
Energy consumption = 146.533589 pJ
sum error= 45
Actual label: 4
Output voltages: [0.0056277, 0.0090251, 0.28027, 0.0042423, 0.79875, 0.001481, 0.35732, 0.08262, 0.017167, 0.05415]
Predicted label: 4
Correct prediction
Energy consumption = 152.154170 pJ
sum error= 45
Actual label: 9
Output voltages: [0.4964, 0.017897, 0.037564, 0.017265, 0.16494, 0.0069275, 0.0011056, 0.032758, 0.30348, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 150.452282 pJ
sum error= 45
Actual label: 4
Output voltages: [0.019194, 0.027626, 0.13795, 0.021004, 0.79879, 0.0011352, 0.69196, 0.047011, 0.0040786, 0.033365]
Predicted label: 4
Correct prediction
Energy consumption = 155.482632 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 106 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 106 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 106 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.050051, 0.011666, 0.41574, 0.02365, 0.79872, 0.0011109, 0.28342, 0.013069, 0.012748, 0.46602]
Predicted label: 4
Correct prediction
Energy consumption = 151.023490 pJ
sum error= 45
Actual label: 0
Output voltages: [0.79867, 0.070215, 0.015826, 0.032012, 0.021707, 0.020839, 0.37641, 0.015193, 0.11684, 0.037255]
Predicted label: 0
Correct prediction
Energy consumption = 150.922994 pJ
sum error= 45
Actual label: 3
Output voltages: [0.00412, 0.0087479, 0.093215, 0.7982, 0.0022037, 0.0035428, 0.0010837, 0.40396, 0.74115, 0.41258]
Predicted label: 3
Correct prediction
Energy consumption = 150.314561 pJ
sum error= 45
Actual label: 9
Output voltages: [0.17595, 0.028943, 0.027387, 0.12808, 0.3147, 0.010271, 0.0054735, 0.019138, 0.25884, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 146.012380 pJ
sum error= 45
Actual label: 2
Output voltages: [0.30919, 0.0089108, 0.79639, 0.751, 0.016175, 0.0012315, 0.030117, 0.41488, 0.43497, 0.010312]
Predicted label: 2
Correct prediction
Energy consumption = 147.992917 pJ
sum error= 45
Actual label: 2
Output voltages: [0.28061, 0.028971, 0.79874, 0.068001, 0.022382, 0.0012875, 0.32443, 0.033018, 0.54645, 0.025662]
Predicted label: 2
Correct prediction
Energy consumption = 135.322817 pJ
sum error= 45
Actual label: 3
Output voltages: [0.036505, 0.14276, 0.02788, 0.79863, 0.017249, 0.0016718, 0.0059466, 0.2451, 0.10457, 0.11786]
Predicted label: 3
Correct prediction
Energy consumption = 150.405345 pJ
sum error= 45
Actual label: 3
Output voltages: [0.04298, 0.029647, 0.046588, 0.79875, 0.017226, 0.011315, 0.0058053, 0.015884, 0.58558, 0.058795]
Predicted label: 3
Correct prediction
Energy consumption = 137.064843 pJ
sum error= 45
Actual label: 8
Output voltages: [0.0011641, 0.7892, 0.021187, 0.031775, 0.36745, 0.25967, 0.041767, 0.0017818, 0.79741, 0.029245]
Predicted label: 8
Correct prediction
Energy consumption = 149.949334 pJ
sum error= 45
Actual label: 3
Output voltages: [0.043049, 0.0066645, 0.090212, 0.7987, 0.0059693, 0.03187, 0.0060289, 0.0078829, 0.77343, 0.19742]
Predicted label: 3
Correct prediction
Energy consumption = 145.929520 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 107 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 107 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 107 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.32308, 0.0011271, 0.0096289, 0.30128, 0.010818, 0.7976, 0.036904, 0.047555, 0.78688, 0.052818]
Predicted label: 5
Correct prediction
Energy consumption = 138.262768 pJ
sum error= 45
Actual label: 7
Output voltages: [0.22591, 0.17649, 0.12675, 0.030959, 0.019609, 0.0010806, 0.0010841, 0.79868, 0.11665, 0.11245]
Predicted label: 7
Correct prediction
Energy consumption = 155.555790 pJ
sum error= 45
Actual label: 3
Output voltages: [0.43005, 0.015893, 0.036695, 0.79865, 0.0016685, 0.56203, 0.0040247, 0.073877, 0.76009, 0.19282]
Predicted label: 3
Correct prediction
Energy consumption = 149.657742 pJ
sum error= 45
Actual label: 5
Output voltages: [0.019139, 0.0010683, 0.001259, 0.18594, 0.12415, 0.79698, 0.10109, 0.0051908, 0.77561, 0.17918]
Predicted label: 5
Correct prediction
Energy consumption = 136.723870 pJ
sum error= 45
Actual label: 8
Output voltages: [0.01075, 0.0027074, 0.044477, 0.48641, 0.017069, 0.037283, 0.0020116, 0.048062, 0.79875, 0.13436]
Predicted label: 8
Correct prediction
Energy consumption = 142.705541 pJ
sum error= 45
Actual label: 1
Output voltages: [0.02967, 0.7984, 0.02839, 0.10871, 0.027039, 0.0054643, 0.6814, 0.0012102, 0.029727, 0.057493]
Predicted label: 1
Correct prediction
Energy consumption = 166.921439 pJ
sum error= 45
Actual label: 2
Output voltages: [0.26754, 0.053596, 0.79879, 0.074063, 0.0046942, 0.0012668, 0.098207, 0.17916, 0.46982, 0.037181]
Predicted label: 2
Correct prediction
Energy consumption = 142.921032 pJ
sum error= 45
Actual label: 4
Output voltages: [0.013307, 0.004722, 0.02465, 0.0059407, 0.79878, 0.0011823, 0.10724, 0.23601, 0.4191, 0.0026032]
Predicted label: 4
Correct prediction
Energy consumption = 158.083205 pJ
sum error= 45
Actual label: 4
Output voltages: [0.084952, 0.011706, 0.1242, 0.0082455, 0.79859, 0.0011814, 0.56201, 0.019249, 0.057754, 0.027111]
Predicted label: 4
Correct prediction
Energy consumption = 141.244656 pJ
sum error= 45
Actual label: 6
Output voltages: [0.37245, 0.050522, 0.21906, 0.0015551, 0.15157, 0.069163, 0.79879, 0.0032291, 0.47584, 0.0083594]
Predicted label: 6
Correct prediction
Energy consumption = 149.576755 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 108 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 108 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 108 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.031188, 0.01179, 0.090166, 0.006558, 0.79879, 0.001138, 0.011621, 0.059222, 0.059845, 0.34489]
Predicted label: 4
Correct prediction
Energy consumption = 160.283586 pJ
sum error= 45
Actual label: 9
Output voltages: [0.31324, 0.0014234, 0.18108, 0.203, 0.1807, 0.01151, 0.0013478, 0.45971, 0.05614, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 151.017309 pJ
sum error= 45
Actual label: 5
Output voltages: [0.068865, 0.0024829, 0.0016157, 0.28244, 0.0016149, 0.79878, 0.39571, 0.047415, 0.75682, 0.0057211]
Predicted label: 5
Correct prediction
Energy consumption = 153.930803 pJ
sum error= 45
Actual label: 1
Output voltages: [0.0086124, 0.79855, 0.10585, 0.49817, 0.083483, 0.02897, 0.28934, 0.0076282, 0.029407, 0.33558]
Predicted label: 1
Correct prediction
Energy consumption = 165.660517 pJ
sum error= 45
Actual label: 0
Output voltages: [0.79863, 0.08557, 0.095618, 0.010542, 0.01535, 0.013219, 0.25412, 0.04243, 0.21777, 0.029367]
Predicted label: 0
Correct prediction
Energy consumption = 146.792499 pJ
sum error= 45
Actual label: 6
Output voltages: [0.019619, 0.090834, 0.19146, 0.0043287, 0.17112, 0.37122, 0.79868, 0.0022329, 0.49445, 0.0056789]
Predicted label: 6
Correct prediction
Energy consumption = 146.561711 pJ
sum error= 45
Actual label: 9
Output voltages: [0.5559, 0.0017531, 0.096643, 0.0040791, 0.16559, 0.01708, 0.0085219, 0.05839, 0.48442, 0.78663]
Predicted label: 9
Correct prediction
Energy consumption = 148.612087 pJ
sum error= 45
Actual label: 5
Output voltages: [0.020549, 0.002944, 0.02544, 0.048022, 0.0038054, 0.79683, 0.22446, 0.0028335, 0.74826, 0.027176]
Predicted label: 5
Correct prediction
Energy consumption = 154.802005 pJ
sum error= 45
Actual label: 9
Output voltages: [0.40771, 0.012136, 0.024398, 0.044321, 0.084079, 0.045279, 0.0045714, 0.21079, 0.67621, 0.79865]
Predicted label: 9
Correct prediction
Energy consumption = 144.769085 pJ
sum error= 45
Actual label: 5
Output voltages: [0.25693, 0.001069, 0.0010767, 0.70767, 0.28743, 0.79877, 0.51517, 0.027944, 0.55635, 0.39896]
Predicted label: 5
Correct prediction
Energy consumption = 149.238905 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 109 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 109 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 109 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.55594, 0.0052777, 0.046253, 0.019608, 0.052482, 0.011183, 0.029201, 0.021817, 0.37699, 0.7984]
Predicted label: 9
Correct prediction
Energy consumption = 154.690917 pJ
sum error= 45
Actual label: 7
Output voltages: [0.032855, 0.0094885, 0.18575, 0.23781, 0.0038065, 0.0012015, 0.0010659, 0.79868, 0.17383, 0.55127]
Predicted label: 7
Correct prediction
Energy consumption = 142.324464 pJ
sum error= 45
Actual label: 3
Output voltages: [0.05403, 0.015472, 0.15774, 0.79857, 0.32602, 0.47791, 0.018381, 0.035073, 0.27467, 0.025019]
Predicted label: 3
Correct prediction
Energy consumption = 143.300124 pJ
sum error= 45
Actual label: 8
Output voltages: [0.20474, 0.040878, 0.51818, 0.21866, 0.02334, 0.002309, 0.062435, 0.001145, 0.79877, 0.27586]
Predicted label: 8
Correct prediction
Energy consumption = 154.433696 pJ
sum error= 45
Actual label: 0
Output voltages: [0.79874, 0.039193, 0.024086, 0.030645, 0.03628, 0.0079972, 0.45886, 0.010875, 0.11625, 0.18927]
Predicted label: 0
Correct prediction
Energy consumption = 159.046138 pJ
sum error= 45
Actual label: 3
Output voltages: [0.42397, 0.042816, 0.025873, 0.79867, 0.014374, 0.013909, 0.013177, 0.010863, 0.45099, 0.075826]
Predicted label: 3
Correct prediction
Energy consumption = 150.424623 pJ
sum error= 45
Actual label: 7
Output voltages: [0.76009, 0.018473, 0.015064, 0.0011356, 0.0077042, 0.024458, 0.0069689, 0.78848, 0.24069, 0.48123]
Predicted label: 7
Correct prediction
Energy consumption = 155.915244 pJ
sum error= 45
Actual label: 1
Output voltages: [0.014362, 0.79857, 0.18652, 0.079338, 0.030624, 0.00127, 0.5547, 0.0058034, 0.039706, 0.030888]
Predicted label: 1
Correct prediction
Energy consumption = 168.025775 pJ
sum error= 45
Actual label: 3
Output voltages: [0.67418, 0.026306, 0.018241, 0.79855, 0.032065, 0.20541, 0.03156, 0.011618, 0.49053, 0.038752]
Predicted label: 3
Correct prediction
Energy consumption = 148.209650 pJ
sum error= 45
Actual label: 6
Output voltages: [0.11298, 0.039755, 0.11399, 0.019465, 0.2415, 0.16142, 0.79853, 0.0027049, 0.48189, 0.0026111]
Predicted label: 6
Correct prediction
Energy consumption = 139.650631 pJ
sum error= 45
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 110 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 110 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 110 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.050764, 0.01654, 0.18841, 0.0043659, 0.0078671, 0.001154, 0.0012065, 0.79879, 0.76604, 0.10723]
Predicted label: 7
Correct prediction
Energy consumption = 153.358004 pJ
sum error= 45
Actual label: 8
Output voltages: [0.12193, 0.014577, 0.016161, 0.76124, 0.13142, 0.03458, 0.033011, 0.0015659, 0.79851, 0.051622]
Predicted label: 8
Correct prediction
Energy consumption = 152.225532 pJ
sum error= 45
Actual label: 5
Output voltages: [0.032487, 0.0010881, 0.0026804, 0.032454, 0.07048, 0.79873, 0.305, 0.020625, 0.78198, 0.034338]
Predicted label: 5
Correct prediction
Energy consumption = 137.139940 pJ
sum error= 45
Actual label: 9
Output voltages: [0.45385, 0.0061431, 0.045572, 0.2353, 0.61797, 0.020826, 0.0063876, 0.15606, 0.06576, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 142.847596 pJ
sum error= 45
Actual label: 7
Output voltages: [0.021596, 0.1047, 0.1586, 0.22207, 0.0069665, 0.001088, 0.0011651, 0.79862, 0.24805, 0.12112]
Predicted label: 7
Correct prediction
Energy consumption = 150.277918 pJ
sum error= 45
Actual label: 9
Output voltages: [0.080441, 0.0049439, 0.02604, 0.033996, 0.35776, 0.019323, 0.013754, 0.036946, 0.62928, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 142.504191 pJ
sum error= 45
Actual label: 6
Output voltages: [0.1835, 0.30771, 0.29236, 0.0072144, 0.033422, 0.3989, 0.79863, 0.0060097, 0.05185, 0.033476]
Predicted label: 6
Correct prediction
Energy consumption = 142.633949 pJ
sum error= 45
Actual label: 9
Output voltages: [0.75262, 0.0010893, 0.013422, 0.59744, 0.35846, 0.11875, 0.055383, 0.0010673, 0.67803, 0.70582]
Predicted label: 0
Wrong prediction!
Energy consumption = 151.221135 pJ
sum error= 46
Actual label: 6
Output voltages: [0.61735, 0.03701, 0.034321, 0.016426, 0.06942, 0.75044, 0.7987, 0.0010733, 0.10478, 0.040244]
Predicted label: 6
Correct prediction
Energy consumption = 144.476874 pJ
sum error= 46
Actual label: 3
Output voltages: [0.58765, 0.026028, 0.40251, 0.79876, 0.042469, 0.0040914, 0.04598, 0.0023833, 0.49771, 0.034298]
Predicted label: 3
Correct prediction
Energy consumption = 146.984409 pJ
sum error= 46
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 111 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 111 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 111 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.27682, 0.014726, 0.022944, 0.26639, 0.025774, 0.015448, 0.00107, 0.79857, 0.053935, 0.37344]
Predicted label: 7
Correct prediction
Energy consumption = 156.930359 pJ
sum error= 46
Actual label: 4
Output voltages: [0.002317, 0.0062178, 0.050479, 0.0044079, 0.79864, 0.0020914, 0.13174, 0.087875, 0.057314, 0.021796]
Predicted label: 4
Correct prediction
Energy consumption = 149.864504 pJ
sum error= 46
Actual label: 4
Output voltages: [0.71588, 0.423, 0.060405, 0.061742, 0.77804, 0.001132, 0.76467, 0.0026912, 0.042666, 0.0064055]
Predicted label: 4
Correct prediction
Energy consumption = 146.787696 pJ
sum error= 46
Actual label: 5
Output voltages: [0.027514, 0.0010665, 0.015345, 0.2122, 0.053278, 0.79874, 0.46685, 0.012837, 0.78954, 0.0091763]
Predicted label: 5
Correct prediction
Energy consumption = 146.249470 pJ
sum error= 46
Actual label: 3
Output voltages: [0.056558, 0.013482, 0.16833, 0.78856, 0.001144, 0.0011599, 0.030295, 0.0051099, 0.79664, 0.051675]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.162667 pJ
sum error= 47
Actual label: 5
Output voltages: [0.0057945, 0.0064313, 0.011356, 0.47434, 0.021647, 0.79786, 0.026656, 0.034438, 0.74311, 0.25904]
Predicted label: 5
Correct prediction
Energy consumption = 143.958914 pJ
sum error= 47
Actual label: 4
Output voltages: [0.0011161, 0.022362, 0.032103, 0.028567, 0.79878, 0.0014147, 0.018274, 0.021291, 0.05326, 0.081161]
Predicted label: 4
Correct prediction
Energy consumption = 139.773363 pJ
sum error= 47
Actual label: 7
Output voltages: [0.04142, 0.32619, 0.56819, 0.27492, 0.0012672, 0.001075, 0.0011509, 0.79869, 0.14732, 0.54652]
Predicted label: 7
Correct prediction
Energy consumption = 150.977638 pJ
sum error= 47
Actual label: 8
Output voltages: [0.088741, 0.049574, 0.38975, 0.044608, 0.0049647, 0.0019131, 0.04858, 0.017788, 0.79879, 0.12036]
Predicted label: 8
Correct prediction
Energy consumption = 144.857838 pJ
sum error= 47
Actual label: 7
Output voltages: [0.26883, 0.0011145, 0.7958, 0.1674, 0.0033975, 0.0011017, 0.0018663, 0.77437, 0.79755, 0.0030956]
Predicted label: 8
Wrong prediction!
Energy consumption = 136.566983 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 112 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 112 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 112 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.033921, 0.072157, 0.054461, 0.56121, 0.0012641, 0.06217, 0.021293, 0.0010665, 0.79879, 0.26412]
Predicted label: 8
Correct prediction
Energy consumption = 153.710926 pJ
sum error= 48
Actual label: 0
Output voltages: [0.79826, 0.029008, 0.034535, 0.032813, 0.036368, 0.0046985, 0.73854, 0.013235, 0.093605, 0.037994]
Predicted label: 0
Correct prediction
Energy consumption = 159.171758 pJ
sum error= 48
Actual label: 7
Output voltages: [0.43525, 0.04341, 0.061221, 0.41518, 0.0071303, 0.0012581, 0.0011149, 0.79867, 0.053454, 0.41831]
Predicted label: 7
Correct prediction
Energy consumption = 160.454403 pJ
sum error= 48
Actual label: 6
Output voltages: [0.040828, 0.13725, 0.29668, 0.0019803, 0.25362, 0.076353, 0.79868, 0.0032468, 0.53234, 0.005899]
Predicted label: 6
Correct prediction
Energy consumption = 148.745634 pJ
sum error= 48
Actual label: 8
Output voltages: [0.047401, 0.02979, 0.027491, 0.48266, 0.0011143, 0.032038, 0.022446, 0.018748, 0.79879, 0.29959]
Predicted label: 8
Correct prediction
Energy consumption = 147.370218 pJ
sum error= 48
Actual label: 8
Output voltages: [0.01039, 0.0089206, 0.018018, 0.10982, 0.017023, 0.011436, 0.015299, 0.034477, 0.79878, 0.38607]
Predicted label: 8
Correct prediction
Energy consumption = 142.577159 pJ
sum error= 48
Actual label: 7
Output voltages: [0.31492, 0.19111, 0.032194, 0.31387, 0.0065543, 0.0073605, 0.0010732, 0.79865, 0.040219, 0.17744]
Predicted label: 7
Correct prediction
Energy consumption = 146.812472 pJ
sum error= 48
Actual label: 3
Output voltages: [0.046472, 0.03116, 0.045823, 0.79878, 0.0069102, 0.0088478, 0.001481, 0.01317, 0.75873, 0.027575]
Predicted label: 3
Correct prediction
Energy consumption = 140.434254 pJ
sum error= 48
Actual label: 3
Output voltages: [0.74742, 0.0011145, 0.46409, 0.7986, 0.0011182, 0.020093, 0.0075848, 0.052058, 0.75793, 0.025901]
Predicted label: 3
Correct prediction
Energy consumption = 139.025846 pJ
sum error= 48
Actual label: 1
Output voltages: [0.051328, 0.7987, 0.027599, 0.028847, 0.004677, 0.0012505, 0.69622, 0.0013726, 0.44219, 0.01618]
Predicted label: 1
Correct prediction
Energy consumption = 158.660058 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 113 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 113 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 113 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.031176, 0.0025365, 0.27809, 0.087037, 0.065757, 0.011431, 0.162, 0.044635, 0.030934, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.513909 pJ
sum error= 48
Actual label: 5
Output voltages: [0.036288, 0.0010673, 0.0014128, 0.021088, 0.49601, 0.79877, 0.54931, 0.028935, 0.74097, 0.10943]
Predicted label: 5
Correct prediction
Energy consumption = 147.156327 pJ
sum error= 48
Actual label: 2
Output voltages: [0.5564, 0.0030582, 0.79842, 0.40463, 0.0059002, 0.0010738, 0.046554, 0.23095, 0.6545, 0.0041897]
Predicted label: 2
Correct prediction
Energy consumption = 152.862856 pJ
sum error= 48
Actual label: 7
Output voltages: [0.22313, 0.31001, 0.56568, 0.019147, 0.0064698, 0.001193, 0.0011229, 0.79874, 0.029778, 0.035081]
Predicted label: 7
Correct prediction
Energy consumption = 154.098210 pJ
sum error= 48
Actual label: 3
Output voltages: [0.14348, 0.010473, 0.293, 0.79871, 0.030235, 0.025914, 0.011484, 0.036689, 0.64704, 0.085438]
Predicted label: 3
Correct prediction
Energy consumption = 142.725181 pJ
sum error= 48
Actual label: 5
Output voltages: [0.68018, 0.029576, 0.0010664, 0.42503, 0.014226, 0.79878, 0.019301, 0.0026241, 0.5828, 0.030107]
Predicted label: 5
Correct prediction
Energy consumption = 149.316084 pJ
sum error= 48
Actual label: 1
Output voltages: [0.055298, 0.79863, 0.002109, 0.13683, 0.037952, 0.0017482, 0.5764, 0.0010663, 0.23075, 0.16333]
Predicted label: 1
Correct prediction
Energy consumption = 159.137793 pJ
sum error= 48
Actual label: 1
Output voltages: [0.014249, 0.79844, 0.064718, 0.022181, 0.017036, 0.0049194, 0.53443, 0.0022164, 0.19805, 0.027599]
Predicted label: 1
Correct prediction
Energy consumption = 151.952525 pJ
sum error= 48
Actual label: 2
Output voltages: [0.51168, 0.5805, 0.79871, 0.17226, 0.049604, 0.0013147, 0.21026, 0.20311, 0.10717, 0.045168]
Predicted label: 2
Correct prediction
Energy consumption = 145.477177 pJ
sum error= 48
Actual label: 1
Output voltages: [0.015622, 0.79867, 0.14217, 0.039226, 0.030304, 0.0011156, 0.5336, 0.0043382, 0.25274, 0.028197]
Predicted label: 1
Correct prediction
Energy consumption = 156.627920 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 114 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 114 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 114 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0091797, 0.0068313, 0.4822, 0.018444, 0.79864, 0.0019364, 0.12233, 0.037675, 0.010115, 0.35316]
Predicted label: 4
Correct prediction
Energy consumption = 157.664329 pJ
sum error= 48
Actual label: 7
Output voltages: [0.1499, 0.054114, 0.61429, 0.081914, 0.0024163, 0.0011141, 0.0018865, 0.79877, 0.050221, 0.27918]
Predicted label: 7
Correct prediction
Energy consumption = 168.383552 pJ
sum error= 48
Actual label: 4
Output voltages: [0.033803, 0.051248, 0.084161, 0.0099923, 0.79875, 0.0010757, 0.17878, 0.15223, 0.010513, 0.19512]
Predicted label: 4
Correct prediction
Energy consumption = 158.544867 pJ
sum error= 48
Actual label: 7
Output voltages: [0.015915, 0.017461, 0.041523, 0.70037, 0.014628, 0.0010851, 0.0011065, 0.79337, 0.7545, 0.011709]
Predicted label: 7
Correct prediction
Energy consumption = 148.302489 pJ
sum error= 48
Actual label: 5
Output voltages: [0.10672, 0.0010714, 0.0022607, 0.55312, 0.015453, 0.79879, 0.023501, 0.1122, 0.7666, 0.065899]
Predicted label: 5
Correct prediction
Energy consumption = 145.274704 pJ
sum error= 48
Actual label: 4
Output voltages: [0.037427, 0.030545, 0.049456, 0.015674, 0.79879, 0.002213, 0.050175, 0.023949, 0.016543, 0.28948]
Predicted label: 4
Correct prediction
Energy consumption = 157.379802 pJ
sum error= 48
Actual label: 5
Output voltages: [0.019699, 0.0011537, 0.0045621, 0.60528, 0.014301, 0.79853, 0.14559, 0.017594, 0.58998, 0.056518]
Predicted label: 5
Correct prediction
Energy consumption = 151.208052 pJ
sum error= 48
Actual label: 4
Output voltages: [0.011545, 0.017472, 0.019611, 0.0013533, 0.79874, 0.026933, 0.0016933, 0.4056, 0.018385, 0.43656]
Predicted label: 4
Correct prediction
Energy consumption = 153.429461 pJ
sum error= 48
Actual label: 0
Output voltages: [0.79876, 0.056123, 0.042556, 0.031347, 0.021165, 0.0027584, 0.68421, 0.019474, 0.19621, 0.093336]
Predicted label: 0
Correct prediction
Energy consumption = 157.103469 pJ
sum error= 48
Actual label: 8
Output voltages: [0.0065576, 0.051346, 0.17217, 0.023177, 0.0060471, 0.0045967, 0.028115, 0.029679, 0.79878, 0.4168]
Predicted label: 8
Correct prediction
Energy consumption = 150.388742 pJ
sum error= 48
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 115 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 115 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 115 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.13384, 0.0059472, 0.016647, 0.79869, 0.01828, 0.042079, 0.29589, 0.018461, 0.37234, 0.024972]
Predicted label: 3
Correct prediction
Energy consumption = 149.626978 pJ
sum error= 48
Actual label: 6
Output voltages: [0.084081, 0.066828, 0.019541, 0.014889, 0.23884, 0.22072, 0.79879, 0.011408, 0.74265, 0.015024]
Predicted label: 6
Correct prediction
Energy consumption = 153.657293 pJ
sum error= 48
Actual label: 9
Output voltages: [0.45882, 0.0032144, 0.021845, 0.018402, 0.037083, 0.036811, 0.0016951, 0.3824, 0.48247, 0.79574]
Predicted label: 9
Correct prediction
Energy consumption = 149.100180 pJ
sum error= 48
Actual label: 6
Output voltages: [0.13847, 0.020698, 0.062303, 0.12169, 0.016295, 0.72321, 0.77143, 0.0025658, 0.79026, 0.013128]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.934026 pJ
sum error= 49
Actual label: 0
Output voltages: [0.79879, 0.024216, 0.083161, 0.0063331, 0.041048, 0.0065436, 0.69842, 0.023989, 0.11262, 0.038432]
Predicted label: 0
Correct prediction
Energy consumption = 156.374679 pJ
sum error= 49
Actual label: 2
Output voltages: [0.46498, 0.27222, 0.79874, 0.069199, 0.027401, 0.0012635, 0.17199, 0.1808, 0.21149, 0.063954]
Predicted label: 2
Correct prediction
Energy consumption = 155.308385 pJ
sum error= 49
Actual label: 7
Output voltages: [0.031421, 0.21758, 0.17739, 0.4125, 0.0010695, 0.01116, 0.0012528, 0.79861, 0.72115, 0.066739]
Predicted label: 7
Correct prediction
Energy consumption = 144.518467 pJ
sum error= 49
Actual label: 4
Output voltages: [0.024089, 0.056427, 0.017321, 0.099095, 0.79872, 0.0011261, 0.10811, 0.035348, 0.0060187, 0.16444]
Predicted label: 4
Correct prediction
Energy consumption = 157.873813 pJ
sum error= 49
Actual label: 4
Output voltages: [0.0020913, 0.0079214, 0.27007, 0.010807, 0.79871, 0.0042037, 0.11007, 0.18426, 0.026715, 0.031128]
Predicted label: 4
Correct prediction
Energy consumption = 142.227720 pJ
sum error= 49
Actual label: 4
Output voltages: [0.010937, 0.014482, 0.031441, 0.01447, 0.79879, 0.0010893, 0.62603, 0.042124, 0.11668, 0.0078925]
Predicted label: 4
Correct prediction
Energy consumption = 143.593121 pJ
sum error= 49
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 116 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 116 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 116 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.016028, 0.004421, 0.30275, 0.02054, 0.79859, 0.014224, 0.64533, 0.045978, 0.017614, 0.039411]
Predicted label: 4
Correct prediction
Energy consumption = 156.506494 pJ
sum error= 49
Actual label: 6
Output voltages: [0.41923, 0.016909, 0.011443, 0.034177, 0.27995, 0.59354, 0.79858, 0.001267, 0.4314, 0.17781]
Predicted label: 6
Correct prediction
Energy consumption = 145.911298 pJ
sum error= 49
Actual label: 6
Output voltages: [0.29062, 0.016214, 0.14446, 0.0033256, 0.11383, 0.037763, 0.79879, 0.0010869, 0.6932, 0.064704]
Predicted label: 6
Correct prediction
Energy consumption = 133.259611 pJ
sum error= 49
Actual label: 4
Output voltages: [0.0056532, 0.0024004, 0.0289, 0.004835, 0.7987, 0.0019617, 0.3474, 0.57651, 0.1868, 0.0049334]
Predicted label: 4
Correct prediction
Energy consumption = 150.520668 pJ
sum error= 49
Actual label: 7
Output voltages: [0.26992, 0.0082095, 0.028655, 0.028267, 0.0078483, 0.0066023, 0.012309, 0.79827, 0.72766, 0.69171]
Predicted label: 7
Correct prediction
Energy consumption = 155.654605 pJ
sum error= 49
Actual label: 9
Output voltages: [0.5865, 0.005827, 0.029669, 0.022018, 0.18372, 0.0066043, 0.0055256, 0.096938, 0.24896, 0.79781]
Predicted label: 9
Correct prediction
Energy consumption = 146.447242 pJ
sum error= 49
Actual label: 3
Output voltages: [0.095965, 0.0032842, 0.061135, 0.78929, 0.0049564, 0.03868, 0.24039, 0.0079602, 0.15914, 0.0023319]
Predicted label: 3
Correct prediction
Energy consumption = 154.248410 pJ
sum error= 49
Actual label: 4
Output voltages: [0.0072771, 0.0093502, 0.026962, 0.013149, 0.79862, 0.0032837, 0.061439, 0.19385, 0.056445, 0.027781]
Predicted label: 4
Correct prediction
Energy consumption = 148.697257 pJ
sum error= 49
Actual label: 5
Output voltages: [0.048702, 0.001126, 0.001423, 0.32631, 0.018784, 0.79878, 0.36867, 0.031026, 0.7722, 0.0052894]
Predicted label: 5
Correct prediction
Energy consumption = 146.410629 pJ
sum error= 49
Actual label: 5
Output voltages: [0.13878, 0.0016416, 0.0023409, 0.044056, 0.018311, 0.78057, 0.21977, 0.0010742, 0.76459, 0.048437]
Predicted label: 5
Correct prediction
Energy consumption = 141.485968 pJ
sum error= 49
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 117 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 117 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 117 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.032664, 0.0065578, 0.0056171, 0.32497, 0.012856, 0.045557, 0.025832, 0.01434, 0.79873, 0.035557]
Predicted label: 8
Correct prediction
Energy consumption = 149.485722 pJ
sum error= 49
Actual label: 7
Output voltages: [0.064007, 0.047164, 0.034451, 0.28211, 0.0028106, 0.0040783, 0.0011428, 0.79877, 0.56251, 0.5761]
Predicted label: 7
Correct prediction
Energy consumption = 154.209775 pJ
sum error= 49
Actual label: 3
Output voltages: [0.18105, 0.023204, 0.052027, 0.79864, 0.037412, 0.0060889, 0.013399, 0.013908, 0.48471, 0.091645]
Predicted label: 3
Correct prediction
Energy consumption = 140.236812 pJ
sum error= 49
Actual label: 7
Output voltages: [0.34307, 0.05049, 0.012383, 0.0045846, 0.37339, 0.0011716, 0.0010699, 0.7566, 0.38912, 0.19571]
Predicted label: 7
Correct prediction
Energy consumption = 161.255854 pJ
sum error= 49
Actual label: 2
Output voltages: [0.33833, 0.19969, 0.79842, 0.64615, 0.0035582, 0.0011078, 0.26881, 0.0031636, 0.6746, 0.021812]
Predicted label: 2
Correct prediction
Energy consumption = 150.946135 pJ
sum error= 49
Actual label: 7
Output voltages: [0.028581, 0.22128, 0.045313, 0.039652, 0.024176, 0.0011221, 0.0011957, 0.79862, 0.083034, 0.21945]
Predicted label: 7
Correct prediction
Energy consumption = 152.797770 pJ
sum error= 49
Actual label: 0
Output voltages: [0.79879, 0.06262, 0.083081, 0.13364, 0.024939, 0.0025828, 0.36007, 0.0097474, 0.32226, 0.047469]
Predicted label: 0
Correct prediction
Energy consumption = 152.994217 pJ
sum error= 49
Actual label: 2
Output voltages: [0.4091, 0.15687, 0.79879, 0.13266, 0.0199, 0.0013014, 0.33045, 0.027346, 0.41987, 0.092277]
Predicted label: 2
Correct prediction
Energy consumption = 147.539615 pJ
sum error= 49
Actual label: 4
Output voltages: [0.76056, 0.0010663, 0.008093, 0.021144, 0.75746, 0.0010721, 0.19089, 0.0016692, 0.67672, 0.0054007]
Predicted label: 0
Wrong prediction!
Energy consumption = 145.111570 pJ
sum error= 50
Actual label: 1
Output voltages: [0.027169, 0.79845, 0.022136, 0.11857, 0.0094931, 0.001655, 0.57141, 0.0017216, 0.27141, 0.032789]
Predicted label: 1
Correct prediction
Energy consumption = 164.132354 pJ
sum error= 50
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 118 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 118 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 118 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.021124, 0.79868, 0.016761, 0.23721, 0.03254, 0.0045476, 0.29635, 0.0037714, 0.094314, 0.10479]
Predicted label: 1
Correct prediction
Energy consumption = 163.255958 pJ
sum error= 50
Actual label: 6
Output voltages: [0.22439, 0.41942, 0.078011, 0.069305, 0.0079782, 0.090341, 0.79792, 0.0031135, 0.74994, 0.002239]
Predicted label: 6
Correct prediction
Energy consumption = 145.819791 pJ
sum error= 50
Actual label: 6
Output voltages: [0.070821, 0.001209, 0.01001, 0.040722, 0.02165, 0.77005, 0.78225, 0.0019388, 0.54789, 0.020344]
Predicted label: 6
Correct prediction
Energy consumption = 152.687495 pJ
sum error= 50
Actual label: 9
Output voltages: [0.17077, 0.14435, 0.024027, 0.19837, 0.23301, 0.020248, 0.0086171, 0.0053606, 0.16533, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 153.069482 pJ
sum error= 50
Actual label: 2
Output voltages: [0.026752, 0.25656, 0.79878, 0.047626, 0.018614, 0.0011076, 0.36334, 0.1101, 0.47257, 0.045913]
Predicted label: 2
Correct prediction
Energy consumption = 149.773612 pJ
sum error= 50
Actual label: 8
Output voltages: [0.068797, 0.040194, 0.16407, 0.13126, 0.018054, 0.019821, 0.082071, 0.0036713, 0.79877, 0.16487]
Predicted label: 8
Correct prediction
Energy consumption = 140.801542 pJ
sum error= 50
Actual label: 7
Output voltages: [0.049965, 0.021495, 0.032973, 0.027876, 0.027329, 0.033171, 0.0010778, 0.79849, 0.07045, 0.030362]
Predicted label: 7
Correct prediction
Energy consumption = 150.469327 pJ
sum error= 50
Actual label: 2
Output voltages: [0.045318, 0.38519, 0.79868, 0.27232, 0.0015541, 0.0013769, 0.25915, 0.0041233, 0.35028, 0.023108]
Predicted label: 2
Correct prediction
Energy consumption = 143.657905 pJ
sum error= 50
Actual label: 0
Output voltages: [0.79879, 0.11659, 0.026966, 0.0065565, 0.022074, 0.0055713, 0.32121, 0.012504, 0.27484, 0.14927]
Predicted label: 0
Correct prediction
Energy consumption = 153.112683 pJ
sum error= 50
Actual label: 1
Output voltages: [0.028875, 0.79838, 0.027926, 0.052956, 0.011625, 0.0024131, 0.41705, 0.0043615, 0.4664, 0.05211]
Predicted label: 1
Correct prediction
Energy consumption = 163.681621 pJ
sum error= 50
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 119 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 119 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 119 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.037771, 0.0014203, 0.0085501, 0.60397, 0.012268, 0.79877, 0.020402, 0.094116, 0.75307, 0.057918]
Predicted label: 5
Correct prediction
Energy consumption = 149.946667 pJ
sum error= 50
Actual label: 0
Output voltages: [0.79878, 0.0019181, 0.24547, 0.0049496, 0.33056, 0.37186, 0.76434, 0.13989, 0.0075587, 0.048063]
Predicted label: 0
Correct prediction
Energy consumption = 136.293750 pJ
sum error= 50
Actual label: 9
Output voltages: [0.011281, 0.0037778, 0.089813, 0.011034, 0.010677, 0.070297, 0.0035632, 0.021551, 0.78741, 0.75514]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.504921 pJ
sum error= 51
Actual label: 1
Output voltages: [0.13823, 0.7984, 0.00966, 0.12322, 0.028994, 0.015812, 0.40693, 0.023124, 0.025659, 0.23822]
Predicted label: 1
Correct prediction
Energy consumption = 164.264643 pJ
sum error= 51
Actual label: 7
Output voltages: [0.49654, 0.0018975, 0.090721, 0.12169, 0.50952, 0.001066, 0.0010743, 0.62997, 0.37802, 0.42875]
Predicted label: 7
Correct prediction
Energy consumption = 147.340579 pJ
sum error= 51
Actual label: 0
Output voltages: [0.79879, 0.14481, 0.028408, 0.013794, 0.0074402, 0.0090657, 0.30411, 0.028125, 0.2538, 0.28552]
Predicted label: 0
Correct prediction
Energy consumption = 153.849202 pJ
sum error= 51
Actual label: 6
Output voltages: [0.04807, 0.075329, 0.14572, 0.0023036, 0.17827, 0.038231, 0.79878, 0.0038904, 0.74567, 0.0048547]
Predicted label: 6
Correct prediction
Energy consumption = 143.934252 pJ
sum error= 51
Actual label: 0
Output voltages: [0.79879, 0.16128, 0.12935, 0.030977, 0.010726, 0.0095128, 0.74995, 0.038352, 0.16037, 0.077992]
Predicted label: 0
Correct prediction
Energy consumption = 152.925345 pJ
sum error= 51
Actual label: 8
Output voltages: [0.019238, 0.031649, 0.020243, 0.021553, 0.029123, 0.065571, 0.024932, 0.021604, 0.79873, 0.095374]
Predicted label: 8
Correct prediction
Energy consumption = 146.526511 pJ
sum error= 51
Actual label: 6
Output voltages: [0.19531, 0.031133, 0.19653, 0.0031392, 0.19356, 0.71115, 0.79866, 0.0016826, 0.15163, 0.035496]
Predicted label: 6
Correct prediction
Energy consumption = 147.218832 pJ
sum error= 51
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 120 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 120 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 120 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.41879, 0.040196, 0.015425, 0.56791, 0.020878, 0.032281, 0.74479, 0.0011042, 0.76682, 0.34997]
Predicted label: 8
Correct prediction
Energy consumption = 161.394180 pJ
sum error= 51
Actual label: 1
Output voltages: [0.027012, 0.79852, 0.027997, 0.24089, 0.054985, 0.0074355, 0.59025, 0.0059161, 0.21684, 0.15979]
Predicted label: 1
Correct prediction
Energy consumption = 158.260366 pJ
sum error= 51
Actual label: 8
Output voltages: [0.16535, 0.0010726, 0.051782, 0.39673, 0.0032121, 0.71851, 0.01777, 0.0014917, 0.79877, 0.019528]
Predicted label: 8
Correct prediction
Energy consumption = 148.474271 pJ
sum error= 51
Actual label: 0
Output voltages: [0.79875, 0.085927, 0.049611, 0.014557, 0.024384, 0.011109, 0.50874, 0.023059, 0.11489, 0.0048839]
Predicted label: 0
Correct prediction
Energy consumption = 149.244003 pJ
sum error= 51
Actual label: 3
Output voltages: [0.0010957, 0.029091, 0.44022, 0.77612, 0.01386, 0.0011899, 0.0010932, 0.75399, 0.75006, 0.013172]
Predicted label: 3
Correct prediction
Energy consumption = 147.277921 pJ
sum error= 51
Actual label: 3
Output voltages: [0.53109, 0.02556, 0.21605, 0.79864, 0.0058388, 0.028289, 0.0036313, 0.04125, 0.28756, 0.044856]
Predicted label: 3
Correct prediction
Energy consumption = 139.820738 pJ
sum error= 51
Actual label: 7
Output voltages: [0.31698, 0.0017554, 0.79367, 0.086086, 0.0032256, 0.0011394, 0.0018167, 0.7423, 0.7749, 0.25266]
Predicted label: 2
Wrong prediction!
Energy consumption = 142.612589 pJ
sum error= 52
Actual label: 2
Output voltages: [0.64442, 0.054505, 0.79866, 0.048367, 0.013583, 0.0011367, 0.080944, 0.067073, 0.4264, 0.012429]
Predicted label: 2
Correct prediction
Energy consumption = 142.664803 pJ
sum error= 52
Actual label: 3
Output voltages: [0.014383, 0.020885, 0.075453, 0.7987, 0.021742, 0.0021743, 0.015358, 0.069299, 0.60058, 0.11101]
Predicted label: 3
Correct prediction
Energy consumption = 145.492954 pJ
sum error= 52
Actual label: 6
Output voltages: [0.092914, 0.28048, 0.027101, 0.13993, 0.033186, 0.77633, 0.79551, 0.010113, 0.46099, 0.0010675]
Predicted label: 6
Correct prediction
Energy consumption = 149.750815 pJ
sum error= 52
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 121 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 121 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 121 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.68892, 0.027702, 0.79878, 0.18126, 0.013346, 0.0011257, 0.052202, 0.032434, 0.70951, 0.016638]
Predicted label: 2
Correct prediction
Energy consumption = 149.207606 pJ
sum error= 52
Actual label: 1
Output voltages: [0.0058455, 0.79879, 0.1587, 0.027351, 0.52414, 0.0011125, 0.033123, 0.017414, 0.047855, 0.20055]
Predicted label: 1
Correct prediction
Energy consumption = 153.180068 pJ
sum error= 52
Actual label: 6
Output voltages: [0.20539, 0.040477, 0.026185, 0.027692, 0.060654, 0.13889, 0.77819, 0.016579, 0.79849, 0.0010659]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.355713 pJ
sum error= 53
Actual label: 1
Output voltages: [0.006833, 0.79849, 0.039939, 0.18451, 0.012451, 0.0015665, 0.69598, 0.011834, 0.038515, 0.030138]
Predicted label: 1
Correct prediction
Energy consumption = 162.366330 pJ
sum error= 53
Actual label: 1
Output voltages: [0.029642, 0.79862, 0.026492, 0.018232, 0.019249, 0.0010777, 0.42098, 0.0012289, 0.42278, 0.037542]
Predicted label: 1
Correct prediction
Energy consumption = 151.008898 pJ
sum error= 53
Actual label: 3
Output voltages: [0.30903, 0.015143, 0.21592, 0.79872, 0.02472, 0.0057951, 0.0045922, 0.012048, 0.73099, 0.0096443]
Predicted label: 3
Correct prediction
Energy consumption = 147.945661 pJ
sum error= 53
Actual label: 7
Output voltages: [0.031208, 0.19409, 0.019485, 0.13063, 0.011751, 0.0031035, 0.0011045, 0.79877, 0.028276, 0.68344]
Predicted label: 7
Correct prediction
Energy consumption = 159.260650 pJ
sum error= 53
Actual label: 9
Output voltages: [0.16432, 0.33255, 0.0032148, 0.34303, 0.010589, 0.0020583, 0.0016502, 0.045565, 0.52585, 0.79775]
Predicted label: 9
Correct prediction
Energy consumption = 151.342594 pJ
sum error= 53
Actual label: 0
Output voltages: [0.79875, 0.31893, 0.032281, 0.034406, 0.0022559, 0.014883, 0.60328, 0.10691, 0.23754, 0.030136]
Predicted label: 0
Correct prediction
Energy consumption = 144.610042 pJ
sum error= 53
Actual label: 8
Output voltages: [0.072434, 0.050262, 0.066177, 0.57254, 0.0014593, 0.017479, 0.030996, 0.01223, 0.79879, 0.18524]
Predicted label: 8
Correct prediction
Energy consumption = 152.262379 pJ
sum error= 53
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 122 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 122 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 122 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.080243, 0.012113, 0.0055608, 0.021603, 0.011766, 0.62518, 0.0056893, 0.1072, 0.19963]
Predicted label: 0
Correct prediction
Energy consumption = 159.563211 pJ
sum error= 53
Actual label: 5
Output voltages: [0.0051842, 0.0017421, 0.0065482, 0.31716, 0.015591, 0.78742, 0.046057, 0.013482, 0.73175, 0.12354]
Predicted label: 5
Correct prediction
Energy consumption = 139.209159 pJ
sum error= 53
Actual label: 4
Output voltages: [0.0012088, 0.0016034, 0.091628, 0.022344, 0.79868, 0.0010996, 0.20639, 0.042111, 0.045697, 0.013784]
Predicted label: 4
Correct prediction
Energy consumption = 154.575141 pJ
sum error= 53
Actual label: 0
Output voltages: [0.7886, 0.0031705, 0.052267, 0.0038455, 0.0042233, 0.11777, 0.7549, 0.0020028, 0.048101, 0.080663]
Predicted label: 0
Correct prediction
Energy consumption = 153.403110 pJ
sum error= 53
Actual label: 2
Output voltages: [0.67459, 0.029731, 0.75033, 0.19779, 0.71399, 0.0011636, 0.42464, 0.3235, 0.022503, 0.0011266]
Predicted label: 2
Correct prediction
Energy consumption = 145.866234 pJ
sum error= 53
Actual label: 8
Output voltages: [0.0041295, 0.062618, 0.16377, 0.027837, 0.018074, 0.0072479, 0.027351, 0.031937, 0.7987, 0.30264]
Predicted label: 8
Correct prediction
Energy consumption = 149.320549 pJ
sum error= 53
Actual label: 7
Output voltages: [0.2071, 0.28143, 0.79807, 0.47668, 0.011654, 0.0013548, 0.02313, 0.28282, 0.25172, 0.054048]
Predicted label: 2
Wrong prediction!
Energy consumption = 147.475425 pJ
sum error= 54
Actual label: 2
Output voltages: [0.049181, 0.34347, 0.79875, 0.28642, 0.031381, 0.0013011, 0.011328, 0.54858, 0.1962, 0.038325]
Predicted label: 2
Correct prediction
Energy consumption = 132.040818 pJ
sum error= 54
Actual label: 9
Output voltages: [0.053858, 0.0012771, 0.14562, 0.70799, 0.16409, 0.027861, 0.0011017, 0.13133, 0.51278, 0.74976]
Predicted label: 9
Correct prediction
Energy consumption = 150.142033 pJ
sum error= 54
Actual label: 8
Output voltages: [0.044097, 0.021255, 0.11791, 0.3476, 0.0016305, 0.049049, 0.0044291, 0.015528, 0.79879, 0.39287]
Predicted label: 8
Correct prediction
Energy consumption = 148.488150 pJ
sum error= 54
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 123 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 123 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 123 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.058581, 0.0031761, 0.21754, 0.0056281, 0.79867, 0.0010934, 0.03662, 0.041768, 0.029865, 0.11141]
Predicted label: 4
Correct prediction
Energy consumption = 156.075221 pJ
sum error= 54
Actual label: 0
Output voltages: [0.79811, 0.087562, 0.063259, 0.018061, 0.011769, 0.001115, 0.59895, 0.0044705, 0.050448, 0.34057]
Predicted label: 0
Correct prediction
Energy consumption = 156.400999 pJ
sum error= 54
Actual label: 9
Output voltages: [0.038119, 0.34886, 0.0012508, 0.025236, 0.76139, 0.0011639, 0.31969, 0.031436, 0.28669, 0.06463]
Predicted label: 4
Wrong prediction!
Energy consumption = 161.436100 pJ
sum error= 55
Actual label: 5
Output voltages: [0.042668, 0.0014387, 0.0010794, 0.54157, 0.056374, 0.7982, 0.5475, 0.0061627, 0.56902, 0.16057]
Predicted label: 5
Correct prediction
Energy consumption = 148.968416 pJ
sum error= 55
Actual label: 8
Output voltages: [0.18484, 0.0010784, 0.040601, 0.019076, 0.13905, 0.30734, 0.25992, 0.0020711, 0.79875, 0.0020712]
Predicted label: 8
Correct prediction
Energy consumption = 145.420661 pJ
sum error= 55
Actual label: 5
Output voltages: [0.016309, 0.0010724, 0.0053039, 0.060732, 0.11928, 0.79728, 0.1617, 0.025235, 0.7965, 0.038604]
Predicted label: 5
Correct prediction
Energy consumption = 136.913464 pJ
sum error= 55
Actual label: 1
Output voltages: [0.020464, 0.79869, 0.052218, 0.60518, 0.098468, 0.009237, 0.058698, 0.0011506, 0.022038, 0.58972]
Predicted label: 1
Correct prediction
Energy consumption = 164.155400 pJ
sum error= 55
Actual label: 2
Output voltages: [0.16415, 0.21111, 0.79879, 0.093652, 0.018007, 0.0013127, 0.39386, 0.0045578, 0.46609, 0.051383]
Predicted label: 2
Correct prediction
Energy consumption = 150.414089 pJ
sum error= 55
Actual label: 1
Output voltages: [0.030841, 0.79855, 0.033135, 0.028452, 0.016364, 0.0044011, 0.44457, 0.0023789, 0.34502, 0.02942]
Predicted label: 1
Correct prediction
Energy consumption = 158.829735 pJ
sum error= 55
Actual label: 3
Output voltages: [0.14023, 0.017265, 0.036054, 0.79872, 0.12593, 0.031219, 0.034931, 0.010862, 0.35631, 0.20444]
Predicted label: 3
Correct prediction
Energy consumption = 151.534543 pJ
sum error= 55
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 124 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 124 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 124 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.070205, 0.79868, 0.019342, 0.34443, 0.0010704, 0.0027171, 0.68293, 0.0017938, 0.19221, 0.0054643]
Predicted label: 1
Correct prediction
Energy consumption = 165.237374 pJ
sum error= 55
Actual label: 7
Output voltages: [0.02108, 0.1354, 0.77633, 0.0060383, 0.019408, 0.001128, 0.0010786, 0.79878, 0.31254, 0.10153]
Predicted label: 7
Correct prediction
Energy consumption = 139.751901 pJ
sum error= 55
Actual label: 4
Output voltages: [0.7313, 0.0051156, 0.002777, 0.026375, 0.79878, 0.017072, 0.043587, 0.0012393, 0.019609, 0.75479]
Predicted label: 4
Correct prediction
Energy consumption = 154.342686 pJ
sum error= 55
Actual label: 5
Output voltages: [0.20337, 0.0013647, 0.001138, 0.30311, 0.27823, 0.79515, 0.38065, 0.0011894, 0.56672, 0.053192]
Predicted label: 5
Correct prediction
Energy consumption = 150.288163 pJ
sum error= 55
Actual label: 7
Output voltages: [0.020949, 0.61736, 0.23865, 0.034258, 0.0059237, 0.0013116, 0.0011616, 0.79878, 0.056701, 0.23484]
Predicted label: 7
Correct prediction
Energy consumption = 166.102095 pJ
sum error= 55
Actual label: 2
Output voltages: [0.41209, 0.0014121, 0.79835, 0.24867, 0.0047505, 0.0011215, 0.040398, 0.06195, 0.68334, 0.00423]
Predicted label: 2
Correct prediction
Energy consumption = 142.707587 pJ
sum error= 55
Actual label: 0
Output voltages: [0.79879, 0.30636, 0.012913, 0.03593, 0.013814, 0.28594, 0.76476, 0.04271, 0.10115, 0.019271]
Predicted label: 0
Correct prediction
Energy consumption = 150.816370 pJ
sum error= 55
Actual label: 9
Output voltages: [0.78661, 0.0011663, 0.038525, 0.52459, 0.0011141, 0.11204, 0.0010804, 0.3315, 0.12363, 0.40566]
Predicted label: 0
Wrong prediction!
Energy consumption = 149.559538 pJ
sum error= 56
Actual label: 8
Output voltages: [0.33491, 0.0024961, 0.05863, 0.61807, 0.0026973, 0.77174, 0.58396, 0.0069545, 0.79239, 0.0053609]
Predicted label: 8
Correct prediction
Energy consumption = 154.504424 pJ
sum error= 56
Actual label: 8
Output voltages: [0.33627, 0.035991, 0.056273, 0.014576, 0.03255, 0.10724, 0.011631, 0.013925, 0.79878, 0.064176]
Predicted label: 8
Correct prediction
Energy consumption = 144.031573 pJ
sum error= 56
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 125 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 125 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 125 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.38133, 0.59571, 0.043306, 0.163, 0.01542, 0.15392, 0.79877, 0.022794, 0.6554, 0.005068]
Predicted label: 6
Correct prediction
Energy consumption = 153.951693 pJ
sum error= 56
Actual label: 2
Output voltages: [0.73335, 0.065832, 0.79824, 0.52774, 0.0080859, 0.0010852, 0.45062, 0.036865, 0.053694, 0.01053]
Predicted label: 2
Correct prediction
Energy consumption = 143.424181 pJ
sum error= 56
Actual label: 5
Output voltages: [0.053965, 0.0010683, 0.042137, 0.13748, 0.0041659, 0.7986, 0.16491, 0.0042715, 0.78373, 0.0084382]
Predicted label: 5
Correct prediction
Energy consumption = 141.293984 pJ
sum error= 56
Actual label: 4
Output voltages: [0.17163, 0.010022, 0.45199, 0.0058224, 0.79879, 0.0011297, 0.69122, 0.007866, 0.033976, 0.22158]
Predicted label: 4
Correct prediction
Energy consumption = 153.967480 pJ
sum error= 56
Actual label: 1
Output voltages: [0.036279, 0.79845, 0.025642, 0.056866, 0.052663, 0.0060419, 0.13334, 0.0018246, 0.41228, 0.04172]
Predicted label: 1
Correct prediction
Energy consumption = 165.300386 pJ
sum error= 56
Actual label: 9
Output voltages: [0.28492, 0.017992, 0.019663, 0.14565, 0.37682, 0.022773, 0.013427, 0.017865, 0.05072, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 158.128957 pJ
sum error= 56
Actual label: 2
Output voltages: [0.46166, 0.36939, 0.79863, 0.078151, 0.002424, 0.0010715, 0.027132, 0.17509, 0.1725, 0.038855]
Predicted label: 2
Correct prediction
Energy consumption = 145.714348 pJ
sum error= 56
Actual label: 1
Output voltages: [0.023403, 0.79876, 0.0011359, 0.0019355, 0.47334, 0.041876, 0.67062, 0.0073568, 0.021172, 0.010257]
Predicted label: 1
Correct prediction
Energy consumption = 152.503120 pJ
sum error= 56
Actual label: 5
Output voltages: [0.036462, 0.0025252, 0.010392, 0.33405, 0.011157, 0.79818, 0.01445, 0.012595, 0.77938, 0.24244]
Predicted label: 5
Correct prediction
Energy consumption = 154.794140 pJ
sum error= 56
Actual label: 8
Output voltages: [0.040759, 0.022226, 0.034716, 0.012117, 0.042071, 0.26352, 0.033589, 0.0075308, 0.79875, 0.12721]
Predicted label: 8
Correct prediction
Energy consumption = 144.110352 pJ
sum error= 56
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 126 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 126 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 126 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.074463, 0.79717, 0.015725, 0.033382, 0.0011212, 0.0012036, 0.0023143, 0.5998, 0.73229, 0.23785]
Predicted label: 1
Wrong prediction!
Energy consumption = 163.932105 pJ
sum error= 57
Actual label: 0
Output voltages: [0.79879, 0.041196, 0.029911, 0.014131, 0.014341, 0.014837, 0.55091, 0.024791, 0.077053, 0.026063]
Predicted label: 0
Correct prediction
Energy consumption = 154.989622 pJ
sum error= 57
Actual label: 2
Output voltages: [0.67684, 0.13972, 0.79869, 0.037801, 0.01287, 0.0012061, 0.1611, 0.049038, 0.46328, 0.023702]
Predicted label: 2
Correct prediction
Energy consumption = 149.891654 pJ
sum error= 57
Actual label: 4
Output voltages: [0.002578, 0.002251, 0.038133, 0.021213, 0.79866, 0.023728, 0.14528, 0.054529, 0.020275, 0.53621]
Predicted label: 4
Correct prediction
Energy consumption = 153.246438 pJ
sum error= 57
Actual label: 4
Output voltages: [0.02584, 0.0053986, 0.020571, 0.037871, 0.79879, 0.0084479, 0.043341, 0.3454, 0.035652, 0.04417]
Predicted label: 4
Correct prediction
Energy consumption = 148.679466 pJ
sum error= 57
Actual label: 3
Output voltages: [0.17493, 0.013881, 0.46615, 0.79877, 0.038404, 0.0010669, 0.0081792, 0.0047611, 0.53583, 0.04077]
Predicted label: 3
Correct prediction
Energy consumption = 144.907274 pJ
sum error= 57
Actual label: 6
Output voltages: [0.076501, 0.012694, 0.30225, 0.001894, 0.098759, 0.033262, 0.79868, 0.0033703, 0.25206, 0.027068]
Predicted label: 6
Correct prediction
Energy consumption = 149.802642 pJ
sum error= 57
Actual label: 8
Output voltages: [0.028407, 0.019748, 0.093448, 0.03551, 0.035931, 0.034994, 0.019513, 0.0039123, 0.79877, 0.26389]
Predicted label: 8
Correct prediction
Energy consumption = 154.837358 pJ
sum error= 57
Actual label: 8
Output voltages: [0.0049206, 0.037148, 0.49745, 0.14089, 0.0064728, 0.0061676, 0.025885, 0.16495, 0.79879, 0.085507]
Predicted label: 8
Correct prediction
Energy consumption = 141.848210 pJ
sum error= 57
Actual label: 2
Output voltages: [0.50388, 0.046072, 0.79879, 0.044631, 0.050768, 0.0011152, 0.16045, 0.023947, 0.053547, 0.30627]
Predicted label: 2
Correct prediction
Energy consumption = 151.964114 pJ
sum error= 57
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 127 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 127 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 127 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.011878, 0.0087785, 0.060467, 0.013242, 0.79874, 0.0011742, 0.0085562, 0.14219, 0.10561, 0.024553]
Predicted label: 4
Correct prediction
Energy consumption = 153.835877 pJ
sum error= 57
Actual label: 0
Output voltages: [0.79122, 0.046005, 0.068397, 0.0012635, 0.02136, 0.021648, 0.54067, 0.0049833, 0.024804, 0.24945]
Predicted label: 0
Correct prediction
Energy consumption = 156.329395 pJ
sum error= 57
Actual label: 5
Output voltages: [0.15005, 0.0011318, 0.001638, 0.032593, 0.15273, 0.79876, 0.023744, 0.052964, 0.78066, 0.2112]
Predicted label: 5
Correct prediction
Energy consumption = 139.302176 pJ
sum error= 57
Actual label: 0
Output voltages: [0.79877, 0.0098463, 0.0082136, 0.015556, 0.09468, 0.0066184, 0.73451, 0.03861, 0.19302, 0.19551]
Predicted label: 0
Correct prediction
Energy consumption = 148.599057 pJ
sum error= 57
Actual label: 4
Output voltages: [0.23123, 0.041765, 0.061763, 0.0071329, 0.79878, 0.0010703, 0.087331, 0.017204, 0.028646, 0.030175]
Predicted label: 4
Correct prediction
Energy consumption = 153.655891 pJ
sum error= 57
Actual label: 4
Output voltages: [0.038705, 0.013757, 0.11564, 0.09632, 0.79879, 0.001066, 0.010145, 0.011904, 0.033241, 0.22265]
Predicted label: 4
Correct prediction
Energy consumption = 151.764644 pJ
sum error= 57
Actual label: 7
Output voltages: [0.21199, 0.0042405, 0.095671, 0.72458, 0.032509, 0.0011585, 0.001119, 0.79304, 0.47107, 0.43403]
Predicted label: 7
Correct prediction
Energy consumption = 145.186806 pJ
sum error= 57
Actual label: 9
Output voltages: [0.26081, 0.007706, 0.016427, 0.029007, 0.43137, 0.077067, 0.027719, 0.044046, 0.27196, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 141.757720 pJ
sum error= 57
Actual label: 3
Output voltages: [0.28538, 0.026774, 0.041935, 0.79858, 0.026796, 0.015015, 0.023003, 0.033669, 0.5887, 0.081931]
Predicted label: 3
Correct prediction
Energy consumption = 142.851347 pJ
sum error= 57
Actual label: 4
Output voltages: [0.010534, 0.023443, 0.10147, 0.0051651, 0.79877, 0.0013894, 0.31971, 0.44663, 0.023102, 0.0069549]
Predicted label: 4
Correct prediction
Energy consumption = 139.103279 pJ
sum error= 57
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 128 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 128 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 128 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0073975, 0.79867, 0.090975, 0.091488, 0.13808, 0.00195, 0.31668, 0.029399, 0.2576, 0.021055]
Predicted label: 1
Correct prediction
Energy consumption = 170.029848 pJ
sum error= 57
Actual label: 5
Output voltages: [0.27936, 0.0020209, 0.0029118, 0.076645, 0.0024373, 0.79879, 0.12978, 0.060418, 0.7509, 0.0062934]
Predicted label: 5
Correct prediction
Energy consumption = 152.721536 pJ
sum error= 57
Actual label: 9
Output voltages: [0.46427, 0.0010752, 0.23569, 0.017162, 0.61767, 0.002554, 0.023107, 0.015574, 0.27217, 0.79408]
Predicted label: 9
Correct prediction
Energy consumption = 149.189810 pJ
sum error= 57
Actual label: 7
Output voltages: [0.16155, 0.0011378, 0.74046, 0.75109, 0.020721, 0.0011068, 0.001101, 0.05596, 0.75347, 0.048689]
Predicted label: 8
Wrong prediction!
Energy consumption = 140.142500 pJ
sum error= 58
Actual label: 3
Output voltages: [0.038407, 0.0097173, 0.035841, 0.79869, 0.048867, 0.016435, 0.057022, 0.017361, 0.60061, 0.10116]
Predicted label: 3
Correct prediction
Energy consumption = 132.398356 pJ
sum error= 58
Actual label: 5
Output voltages: [0.029847, 0.0087476, 0.0011817, 0.72977, 0.034944, 0.79873, 0.14562, 0.0080333, 0.48974, 0.012073]
Predicted label: 5
Correct prediction
Energy consumption = 138.127356 pJ
sum error= 58
Actual label: 8
Output voltages: [0.017873, 0.075892, 0.28359, 0.15972, 0.011868, 0.0050334, 0.032592, 0.019615, 0.79877, 0.17164]
Predicted label: 8
Correct prediction
Energy consumption = 150.835813 pJ
sum error= 58
Actual label: 8
Output voltages: [0.022387, 0.027441, 0.029407, 0.34707, 0.012984, 0.0028223, 0.014034, 0.015002, 0.79876, 0.12179]
Predicted label: 8
Correct prediction
Energy consumption = 145.439390 pJ
sum error= 58
Actual label: 0
Output voltages: [0.79839, 0.0041814, 0.047249, 0.08689, 0.024298, 0.0018754, 0.37886, 0.16061, 0.27657, 0.20979]
Predicted label: 0
Correct prediction
Energy consumption = 156.945071 pJ
sum error= 58
Actual label: 5
Output voltages: [0.29662, 0.036691, 0.0010823, 0.79202, 0.022105, 0.79771, 0.11819, 0.010752, 0.39215, 0.2962]
Predicted label: 5
Correct prediction
Energy consumption = 145.212040 pJ
sum error= 58
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 129 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 129 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 129 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.22493, 0.0027284, 0.023778, 0.79878, 0.29798, 0.19799, 0.047863, 0.0021102, 0.067458, 0.020194]
Predicted label: 3
Correct prediction
Energy consumption = 156.299939 pJ
sum error= 58
Actual label: 3
Output voltages: [0.074866, 0.009892, 0.027957, 0.79878, 0.041922, 0.010662, 0.051014, 0.068513, 0.4617, 0.0037676]
Predicted label: 3
Correct prediction
Energy consumption = 134.538322 pJ
sum error= 58
Actual label: 6
Output voltages: [0.031713, 0.0027162, 0.089298, 0.032194, 0.025979, 0.27004, 0.79784, 0.0011443, 0.27013, 0.11506]
Predicted label: 6
Correct prediction
Energy consumption = 146.960476 pJ
sum error= 58
Actual label: 6
Output voltages: [0.012161, 0.054203, 0.63533, 0.0014205, 0.23501, 0.39134, 0.79864, 0.0011842, 0.46868, 0.014685]
Predicted label: 6
Correct prediction
Energy consumption = 130.697251 pJ
sum error= 58
Actual label: 0
Output voltages: [0.79879, 0.12836, 0.048649, 0.022836, 0.0271, 0.0028215, 0.66943, 0.0082123, 0.18019, 0.058474]
Predicted label: 0
Correct prediction
Energy consumption = 155.179811 pJ
sum error= 58
Actual label: 1
Output voltages: [0.013652, 0.79865, 0.04261, 0.029876, 0.091472, 0.0011304, 0.62024, 0.0050633, 0.34971, 0.022276]
Predicted label: 1
Correct prediction
Energy consumption = 162.691039 pJ
sum error= 58
Actual label: 6
Output voltages: [0.031448, 0.0027287, 0.0019872, 0.37802, 0.030928, 0.48781, 0.78181, 0.0023692, 0.61112, 0.011379]
Predicted label: 6
Correct prediction
Energy consumption = 153.704920 pJ
sum error= 58
Actual label: 0
Output voltages: [0.7984, 0.29254, 0.017127, 0.0065601, 0.018542, 0.0041676, 0.75763, 0.012584, 0.14672, 0.27932]
Predicted label: 0
Correct prediction
Energy consumption = 154.243249 pJ
sum error= 58
Actual label: 3
Output voltages: [0.19548, 0.0083855, 0.087992, 0.79872, 0.049421, 0.0016322, 0.020305, 0.030014, 0.61808, 0.027442]
Predicted label: 3
Correct prediction
Energy consumption = 143.172693 pJ
sum error= 58
Actual label: 5
Output voltages: [0.050749, 0.049124, 0.016661, 0.79833, 0.0019577, 0.59582, 0.0011231, 0.42581, 0.21102, 0.036592]
Predicted label: 3
Wrong prediction!
Energy consumption = 145.870657 pJ
sum error= 59
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 130 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 130 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 130 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.025132, 0.010342, 0.13626, 0.0067467, 0.79868, 0.0010682, 0.013162, 0.041415, 0.02135, 0.39888]
Predicted label: 4
Correct prediction
Energy consumption = 155.193007 pJ
sum error= 59
Actual label: 4
Output voltages: [0.0094176, 0.022794, 0.20791, 0.0056637, 0.79868, 0.0010697, 0.041386, 0.027257, 0.02028, 0.28646]
Predicted label: 4
Correct prediction
Energy consumption = 144.675900 pJ
sum error= 59
Actual label: 1
Output voltages: [0.021895, 0.7984, 0.036527, 0.057886, 0.20762, 0.0028843, 0.39358, 0.0082612, 0.039161, 0.46321]
Predicted label: 1
Correct prediction
Energy consumption = 164.287743 pJ
sum error= 59
Actual label: 2
Output voltages: [0.76464, 0.13006, 0.79879, 0.058276, 0.023099, 0.0011492, 0.19956, 0.041047, 0.2761, 0.026523]
Predicted label: 2
Correct prediction
Energy consumption = 154.496645 pJ
sum error= 59
Actual label: 9
Output voltages: [0.30927, 0.040425, 0.28887, 0.22652, 0.043496, 0.048743, 0.011948, 0.14255, 0.13996, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 154.481426 pJ
sum error= 59
Actual label: 1
Output voltages: [0.0022866, 0.79847, 0.037465, 0.046015, 0.082646, 0.010626, 0.73939, 0.011838, 0.043382, 0.02003]
Predicted label: 1
Correct prediction
Energy consumption = 159.083630 pJ
sum error= 59
Actual label: 4
Output voltages: [0.0090851, 0.023787, 0.41604, 0.0034406, 0.7987, 0.0010742, 0.04099, 0.017287, 0.015891, 0.52056]
Predicted label: 4
Correct prediction
Energy consumption = 156.382496 pJ
sum error= 59
Actual label: 6
Output voltages: [0.1982, 0.046981, 0.090678, 0.0042244, 0.47993, 0.46451, 0.79878, 0.0021753, 0.41184, 0.0021832]
Predicted label: 6
Correct prediction
Energy consumption = 146.654924 pJ
sum error= 59
Actual label: 9
Output voltages: [0.72901, 0.0010923, 0.053148, 0.11935, 0.19927, 0.0079436, 0.0010889, 0.080703, 0.026582, 0.79277]
Predicted label: 9
Correct prediction
Energy consumption = 153.101180 pJ
sum error= 59
Actual label: 9
Output voltages: [0.23247, 0.0079469, 0.047921, 0.096942, 0.11305, 0.084948, 0.055466, 0.031079, 0.12338, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 148.189834 pJ
sum error= 59
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 131 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 131 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 131 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.12932, 0.012966, 0.045872, 0.79873, 0.0082739, 0.069069, 0.0090254, 0.040156, 0.34274, 0.015259]
Predicted label: 3
Correct prediction
Energy consumption = 156.215627 pJ
sum error= 59
Actual label: 9
Output voltages: [0.36583, 0.027102, 0.018876, 0.064832, 0.038584, 0.023197, 0.011402, 0.066599, 0.34027, 0.79831]
Predicted label: 9
Correct prediction
Energy consumption = 154.058951 pJ
sum error= 59
Actual label: 8
Output voltages: [0.48956, 0.0016368, 0.024281, 0.034658, 0.06752, 0.002728, 0.011164, 0.0043583, 0.77966, 0.57004]
Predicted label: 8
Correct prediction
Energy consumption = 145.739709 pJ
sum error= 59
Actual label: 4
Output voltages: [0.0019099, 0.0028187, 0.033917, 0.0073662, 0.79866, 0.0044277, 0.091465, 0.49167, 0.54503, 0.0038523]
Predicted label: 4
Correct prediction
Energy consumption = 153.818575 pJ
sum error= 59
Actual label: 4
Output voltages: [0.026957, 0.0020776, 0.28518, 0.00128, 0.79863, 0.010418, 0.30932, 0.080478, 0.054255, 0.023734]
Predicted label: 4
Correct prediction
Energy consumption = 144.112711 pJ
sum error= 59
Actual label: 3
Output voltages: [0.091049, 0.0039299, 0.099886, 0.79871, 0.26784, 0.70575, 0.042479, 0.014272, 0.38097, 0.036984]
Predicted label: 3
Correct prediction
Energy consumption = 145.322075 pJ
sum error= 59
Actual label: 1
Output voltages: [0.035685, 0.79868, 0.5727, 0.097819, 0.01796, 0.0011124, 0.31226, 0.0013966, 0.25717, 0.018072]
Predicted label: 1
Correct prediction
Energy consumption = 165.745169 pJ
sum error= 59
Actual label: 3
Output voltages: [0.036165, 0.027045, 0.064758, 0.79872, 0.017592, 0.0022109, 0.0063225, 0.009142, 0.66315, 0.061481]
Predicted label: 3
Correct prediction
Energy consumption = 138.757412 pJ
sum error= 59
Actual label: 1
Output voltages: [0.019762, 0.79872, 0.024099, 0.0093371, 0.10657, 0.0018489, 0.6081, 0.013682, 0.13875, 0.054054]
Predicted label: 1
Correct prediction
Energy consumption = 160.934876 pJ
sum error= 59
Actual label: 8
Output voltages: [0.7987, 0.0064168, 0.0033396, 0.53019, 0.0051142, 0.010409, 0.59852, 0.013856, 0.24787, 0.021212]
Predicted label: 0
Wrong prediction!
Energy consumption = 153.659730 pJ
sum error= 60
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 132 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 132 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 132 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.033584, 0.058193, 0.35983, 0.068331, 0.0065025, 0.0013686, 0.029682, 0.0026084, 0.79878, 0.19785]
Predicted label: 8
Correct prediction
Energy consumption = 154.918330 pJ
sum error= 60
Actual label: 7
Output voltages: [0.14916, 0.083089, 0.020424, 0.053076, 0.0028521, 0.0037151, 0.0010666, 0.79877, 0.36703, 0.53219]
Predicted label: 7
Correct prediction
Energy consumption = 161.891650 pJ
sum error= 60
Actual label: 9
Output voltages: [0.35555, 0.036171, 0.033714, 0.19095, 0.27151, 0.019145, 0.031564, 0.026993, 0.54087, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 141.383315 pJ
sum error= 60
Actual label: 4
Output voltages: [0.0016448, 0.0074066, 0.34787, 0.008923, 0.79863, 0.0013782, 0.14081, 0.041962, 0.022129, 0.097441]
Predicted label: 4
Correct prediction
Energy consumption = 152.466960 pJ
sum error= 60
Actual label: 8
Output voltages: [0.097266, 0.11408, 0.097058, 0.012588, 0.024777, 0.0088327, 0.01295, 0.026943, 0.79862, 0.11498]
Predicted label: 8
Correct prediction
Energy consumption = 157.083166 pJ
sum error= 60
Actual label: 8
Output voltages: [0.032119, 0.029384, 0.50283, 0.0075428, 0.2038, 0.024386, 0.081778, 0.0013194, 0.79872, 0.11286]
Predicted label: 8
Correct prediction
Energy consumption = 137.589169 pJ
sum error= 60
Actual label: 7
Output voltages: [0.21608, 0.037017, 0.76599, 0.019314, 0.0077552, 0.0012053, 0.006747, 0.71224, 0.69317, 0.59335]
Predicted label: 2
Wrong prediction!
Energy consumption = 150.207564 pJ
sum error= 61
Actual label: 9
Output voltages: [0.60671, 0.0073344, 0.069749, 0.14176, 0.038727, 0.21174, 0.0031214, 0.41787, 0.26377, 0.79764]
Predicted label: 9
Correct prediction
Energy consumption = 150.720981 pJ
sum error= 61
Actual label: 7
Output voltages: [0.050895, 0.14276, 0.01803, 0.1059, 0.035172, 0.0012803, 0.0032782, 0.79877, 0.30341, 0.54282]
Predicted label: 7
Correct prediction
Energy consumption = 156.967146 pJ
sum error= 61
Actual label: 1
Output voltages: [0.17196, 0.79845, 0.026891, 0.092711, 0.001364, 0.013223, 0.68895, 0.0015751, 0.35739, 0.028558]
Predicted label: 1
Correct prediction
Energy consumption = 161.974342 pJ
sum error= 61
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 133 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 133 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 133 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.021705, 0.0097078, 0.065865, 0.034537, 0.79869, 0.016, 0.022305, 0.013311, 0.2008, 0.034723]
Predicted label: 4
Correct prediction
Energy consumption = 158.484989 pJ
sum error= 61
Actual label: 5
Output voltages: [0.0014912, 0.001066, 0.017977, 0.43977, 0.071086, 0.73698, 0.12984, 0.01688, 0.77785, 0.17522]
Predicted label: 8
Wrong prediction!
Energy consumption = 145.326707 pJ
sum error= 62
Actual label: 6
Output voltages: [0.15094, 0.04194, 0.13437, 0.0040092, 0.41599, 0.42551, 0.79871, 0.0026259, 0.47535, 0.013859]
Predicted label: 6
Correct prediction
Energy consumption = 143.274169 pJ
sum error= 62
Actual label: 0
Output voltages: [0.79877, 0.093599, 0.02517, 0.015902, 0.013282, 0.015641, 0.5058, 0.015332, 0.13803, 0.022468]
Predicted label: 0
Correct prediction
Energy consumption = 150.603577 pJ
sum error= 62
Actual label: 5
Output voltages: [0.0092969, 0.0010661, 0.0018655, 0.13932, 0.052025, 0.76509, 0.16164, 0.019543, 0.75422, 0.459]
Predicted label: 5
Correct prediction
Energy consumption = 148.669371 pJ
sum error= 62
Actual label: 2
Output voltages: [0.40689, 0.192, 0.79874, 0.23075, 0.036579, 0.0011845, 0.42798, 0.014555, 0.28818, 0.055201]
Predicted label: 2
Correct prediction
Energy consumption = 150.919300 pJ
sum error= 62
Actual label: 2
Output voltages: [0.24104, 0.36865, 0.79877, 0.044036, 0.017631, 0.0013733, 0.30976, 0.036161, 0.19876, 0.033393]
Predicted label: 2
Correct prediction
Energy consumption = 140.920222 pJ
sum error= 62
Actual label: 2
Output voltages: [0.57675, 0.020779, 0.59897, 0.15536, 0.13171, 0.033413, 0.79614, 0.53522, 0.24146, 0.001094]
Predicted label: 6
Wrong prediction!
Energy consumption = 147.530897 pJ
sum error= 63
Actual label: 1
Output voltages: [0.020207, 0.79854, 0.21113, 0.16301, 0.1617, 0.0025781, 0.16985, 0.023021, 0.028674, 0.22452]
Predicted label: 1
Correct prediction
Energy consumption = 159.252350 pJ
sum error= 63
Actual label: 5
Output voltages: [0.044529, 0.0011496, 0.0055927, 0.35366, 0.0087109, 0.79879, 0.087786, 0.052149, 0.67461, 0.027854]
Predicted label: 5
Correct prediction
Energy consumption = 147.323625 pJ
sum error= 63
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 134 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 134 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 134 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.036556, 0.001081, 0.012722, 0.059972, 0.016677, 0.7976, 0.24998, 0.011254, 0.79069, 0.014262]
Predicted label: 5
Correct prediction
Energy consumption = 147.992326 pJ
sum error= 63
Actual label: 2
Output voltages: [0.46353, 0.042576, 0.79872, 0.11734, 0.019741, 0.0011718, 0.048468, 0.19381, 0.21541, 0.026485]
Predicted label: 2
Correct prediction
Energy consumption = 145.324033 pJ
sum error= 63
Actual label: 4
Output voltages: [0.048026, 0.0065336, 0.25655, 0.007328, 0.79868, 0.0088611, 0.011217, 0.040263, 0.017906, 0.35741]
Predicted label: 4
Correct prediction
Energy consumption = 161.281996 pJ
sum error= 63
Actual label: 9
Output voltages: [0.46968, 0.0075428, 0.039208, 0.01229, 0.051702, 0.020269, 0.0068149, 0.19609, 0.36231, 0.79769]
Predicted label: 9
Correct prediction
Energy consumption = 144.438559 pJ
sum error= 63
Actual label: 6
Output voltages: [0.41325, 0.20161, 0.082218, 0.0038062, 0.052594, 0.27255, 0.79872, 0.03943, 0.56647, 0.004073]
Predicted label: 6
Correct prediction
Energy consumption = 151.130010 pJ
sum error= 63
Actual label: 2
Output voltages: [0.30638, 0.0022537, 0.79874, 0.068512, 0.0094931, 0.0011443, 0.035378, 0.74975, 0.50737, 0.0092311]
Predicted label: 2
Correct prediction
Energy consumption = 133.669176 pJ
sum error= 63
Actual label: 7
Output voltages: [0.094679, 0.011218, 0.050814, 0.27453, 0.0039416, 0.014936, 0.0011716, 0.79856, 0.39392, 0.26848]
Predicted label: 7
Correct prediction
Energy consumption = 148.753882 pJ
sum error= 63
Actual label: 7
Output voltages: [0.2103, 0.028589, 0.0065618, 0.0023863, 0.15209, 0.0058008, 0.0010795, 0.79879, 0.33576, 0.55867]
Predicted label: 7
Correct prediction
Energy consumption = 144.584788 pJ
sum error= 63
Actual label: 2
Output voltages: [0.6017, 0.20395, 0.79863, 0.2583, 0.010356, 0.0010661, 0.18335, 0.023634, 0.04997, 0.057752]
Predicted label: 2
Correct prediction
Energy consumption = 148.793382 pJ
sum error= 63
Actual label: 2
Output voltages: [0.11863, 0.084165, 0.79827, 0.24824, 0.0028316, 0.0012156, 0.010661, 0.18643, 0.68576, 0.012708]
Predicted label: 2
Correct prediction
Energy consumption = 137.678557 pJ
sum error= 63
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 135 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 135 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 135 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.019641, 0.79835, 0.085748, 0.063091, 0.011585, 0.0026471, 0.56634, 0.0086644, 0.36928, 0.13372]
Predicted label: 1
Correct prediction
Energy consumption = 163.324343 pJ
sum error= 63
Actual label: 1
Output voltages: [0.026756, 0.79871, 0.058056, 0.013699, 0.038882, 0.0010661, 0.56459, 0.0010717, 0.35628, 0.0088469]
Predicted label: 1
Correct prediction
Energy consumption = 151.995285 pJ
sum error= 63
Actual label: 2
Output voltages: [0.67077, 0.0092703, 0.79879, 0.043139, 0.0033283, 0.0010893, 0.28408, 0.031474, 0.56559, 0.0076393]
Predicted label: 2
Correct prediction
Energy consumption = 142.608046 pJ
sum error= 63
Actual label: 8
Output voltages: [0.01075, 0.11984, 0.21929, 0.05849, 0.013926, 0.013712, 0.036353, 0.032886, 0.79876, 0.35766]
Predicted label: 8
Correct prediction
Energy consumption = 156.936082 pJ
sum error= 63
Actual label: 3
Output voltages: [0.4084, 0.072373, 0.19313, 0.79879, 0.003092, 0.0011534, 0.0054518, 0.0050409, 0.28781, 0.02368]
Predicted label: 3
Correct prediction
Energy consumption = 144.688931 pJ
sum error= 63
Actual label: 7
Output voltages: [0.019521, 0.040646, 0.060379, 0.0059333, 0.71137, 0.001192, 0.0011676, 0.71386, 0.50678, 0.49872]
Predicted label: 7
Correct prediction
Energy consumption = 157.270231 pJ
sum error= 63
Actual label: 2
Output voltages: [0.75456, 0.39157, 0.79873, 0.11971, 0.011646, 0.0011453, 0.075028, 0.053124, 0.31434, 0.029961]
Predicted label: 2
Correct prediction
Energy consumption = 155.024678 pJ
sum error= 63
Actual label: 4
Output voltages: [0.17198, 0.018298, 0.058315, 0.0039456, 0.79729, 0.0010859, 0.36125, 0.12575, 0.00198, 0.69528]
Predicted label: 4
Correct prediction
Energy consumption = 160.901997 pJ
sum error= 63
Actual label: 1
Output voltages: [0.037103, 0.79864, 0.40966, 0.53121, 0.0056801, 0.0010663, 0.34371, 0.015295, 0.030328, 0.024563]
Predicted label: 1
Correct prediction
Energy consumption = 163.162678 pJ
sum error= 63
Actual label: 7
Output voltages: [0.076371, 0.023386, 0.42018, 0.079606, 0.0017016, 0.0012724, 0.0010659, 0.79866, 0.48088, 0.022533]
Predicted label: 7
Correct prediction
Energy consumption = 153.819335 pJ
sum error= 63
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 136 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 136 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 136 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.034592, 0.79862, 0.029012, 0.31895, 0.0025078, 0.021322, 0.34858, 0.056803, 0.55957, 0.034466]
Predicted label: 1
Correct prediction
Energy consumption = 166.365932 pJ
sum error= 63
Actual label: 7
Output voltages: [0.032375, 0.2608, 0.37636, 0.36917, 0.0041514, 0.0013861, 0.0010948, 0.79871, 0.50382, 0.18624]
Predicted label: 7
Correct prediction
Energy consumption = 151.844356 pJ
sum error= 63
Actual label: 6
Output voltages: [0.058299, 0.12908, 0.32489, 0.0015563, 0.55166, 0.24024, 0.79865, 0.0023248, 0.035507, 0.011471]
Predicted label: 6
Correct prediction
Energy consumption = 149.520902 pJ
sum error= 63
Actual label: 7
Output voltages: [0.14493, 0.29951, 0.7626, 0.099441, 0.05471, 0.0014039, 0.010022, 0.78976, 0.0026998, 0.46119]
Predicted label: 7
Correct prediction
Energy consumption = 148.810803 pJ
sum error= 63
Actual label: 8
Output voltages: [0.41349, 0.0011515, 0.23159, 0.16373, 0.0094851, 0.017631, 0.0096295, 0.020484, 0.79878, 0.16788]
Predicted label: 8
Correct prediction
Energy consumption = 147.868934 pJ
sum error= 63
Actual label: 2
Output voltages: [0.24067, 0.53745, 0.79856, 0.053885, 0.0089197, 0.0010662, 0.040887, 0.30021, 0.2191, 0.033822]
Predicted label: 2
Correct prediction
Energy consumption = 144.092925 pJ
sum error= 63
Actual label: 7
Output voltages: [0.04085, 0.0096733, 0.03355, 0.032064, 0.0029909, 0.017563, 0.0011056, 0.79867, 0.63634, 0.14696]
Predicted label: 7
Correct prediction
Energy consumption = 149.287080 pJ
sum error= 63
Actual label: 3
Output voltages: [0.4927, 0.01008, 0.38978, 0.79877, 0.016064, 0.0061596, 0.010491, 0.032274, 0.68929, 0.021835]
Predicted label: 3
Correct prediction
Energy consumption = 137.911966 pJ
sum error= 63
Actual label: 1
Output voltages: [0.07734, 0.7985, 0.012756, 0.10054, 0.0038177, 0.024655, 0.26889, 0.0019485, 0.034626, 0.052329]
Predicted label: 1
Correct prediction
Energy consumption = 165.785443 pJ
sum error= 63
Actual label: 7
Output voltages: [0.085093, 0.0071378, 0.054091, 0.40759, 0.0021616, 0.043363, 0.0011328, 0.79856, 0.38173, 0.28136]
Predicted label: 7
Correct prediction
Energy consumption = 150.177979 pJ
sum error= 63
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 137 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 137 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 137 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.024795, 0.0011329, 0.0038298, 0.17605, 0.016219, 0.7827, 0.079873, 0.01784, 0.77408, 0.063886]
Predicted label: 5
Correct prediction
Energy consumption = 150.342940 pJ
sum error= 63
Actual label: 8
Output voltages: [0.045144, 0.012166, 0.02899, 0.085377, 0.0083086, 0.035716, 0.01079, 0.0016292, 0.79879, 0.55738]
Predicted label: 8
Correct prediction
Energy consumption = 146.894193 pJ
sum error= 63
Actual label: 2
Output voltages: [0.2174, 0.06823, 0.79876, 0.33679, 0.0033435, 0.0013171, 0.31313, 0.28746, 0.40998, 0.027461]
Predicted label: 2
Correct prediction
Energy consumption = 142.953726 pJ
sum error= 63
Actual label: 6
Output voltages: [0.14603, 0.073574, 0.047582, 0.0067173, 0.20974, 0.25443, 0.79879, 0.0027253, 0.45353, 0.002049]
Predicted label: 6
Correct prediction
Energy consumption = 150.175713 pJ
sum error= 63
Actual label: 2
Output voltages: [0.42764, 0.0044287, 0.79876, 0.16643, 0.0032984, 0.0010698, 0.022973, 0.028409, 0.71119, 0.002368]
Predicted label: 2
Correct prediction
Energy consumption = 143.027551 pJ
sum error= 63
Actual label: 2
Output voltages: [0.28707, 0.35418, 0.79879, 0.071162, 0.011834, 0.0012355, 0.12454, 0.015645, 0.4613, 0.060268]
Predicted label: 2
Correct prediction
Energy consumption = 141.443810 pJ
sum error= 63
Actual label: 5
Output voltages: [0.022137, 0.0010667, 0.0011676, 0.046833, 0.02575, 0.78946, 0.087678, 0.0082826, 0.79085, 0.074689]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.114702 pJ
sum error= 64
Actual label: 6
Output voltages: [0.019327, 0.0096823, 0.21705, 0.011263, 0.069342, 0.46096, 0.79859, 0.0011203, 0.69963, 0.062726]
Predicted label: 6
Correct prediction
Energy consumption = 140.807526 pJ
sum error= 64
Actual label: 5
Output voltages: [0.18917, 0.0076877, 0.0011865, 0.27881, 0.0047388, 0.7853, 0.78553, 0.0011756, 0.68859, 0.0012302]
Predicted label: 6
Wrong prediction!
Energy consumption = 139.287946 pJ
sum error= 65
Actual label: 0
Output voltages: [0.79877, 0.26522, 0.013363, 0.032795, 0.0051969, 0.038684, 0.62772, 0.026227, 0.23014, 0.042114]
Predicted label: 0
Correct prediction
Energy consumption = 145.323815 pJ
sum error= 65
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 138 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 138 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 138 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33518, 0.012228, 0.018525, 0.15322, 0.055286, 0.092929, 0.018239, 0.011128, 0.37047, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 158.531463 pJ
sum error= 65
Actual label: 2
Output voltages: [0.30178, 0.041734, 0.79875, 0.19007, 0.0083349, 0.0012094, 0.15849, 0.0096279, 0.68039, 0.0084737]
Predicted label: 2
Correct prediction
Energy consumption = 147.019082 pJ
sum error= 65
Actual label: 4
Output voltages: [0.0078523, 0.013519, 0.21955, 0.004626, 0.79854, 0.0082328, 0.089942, 0.04555, 0.045849, 0.031279]
Predicted label: 4
Correct prediction
Energy consumption = 152.337718 pJ
sum error= 65
Actual label: 3
Output voltages: [0.62322, 0.038279, 0.28249, 0.79878, 0.011219, 0.055179, 0.060519, 0.0019542, 0.17605, 0.0027124]
Predicted label: 3
Correct prediction
Energy consumption = 149.869178 pJ
sum error= 65
Actual label: 3
Output voltages: [0.043723, 0.21157, 0.028114, 0.79863, 0.0057083, 0.0022973, 0.0069366, 0.046507, 0.38803, 0.17908]
Predicted label: 3
Correct prediction
Energy consumption = 143.011182 pJ
sum error= 65
Actual label: 9
Output voltages: [0.27821, 0.010694, 0.082739, 0.010412, 0.068031, 0.012711, 0.0038183, 0.045562, 0.59821, 0.79667]
Predicted label: 9
Correct prediction
Energy consumption = 151.447013 pJ
sum error= 65
Actual label: 7
Output voltages: [0.044157, 0.003997, 0.19833, 0.026575, 0.038575, 0.018724, 0.001066, 0.79876, 0.029072, 0.54352]
Predicted label: 7
Correct prediction
Energy consumption = 146.368467 pJ
sum error= 65
Actual label: 6
Output voltages: [0.16303, 0.049971, 0.32839, 0.0022417, 0.44803, 0.36791, 0.79867, 0.0020344, 0.38528, 0.0060493]
Predicted label: 6
Correct prediction
Energy consumption = 152.200105 pJ
sum error= 65
Actual label: 6
Output voltages: [0.21244, 0.054035, 0.55497, 0.0026311, 0.31649, 0.15257, 0.79878, 0.0031453, 0.63697, 0.07156]
Predicted label: 6
Correct prediction
Energy consumption = 140.341005 pJ
sum error= 65
Actual label: 8
Output voltages: [0.030815, 0.037884, 0.046035, 0.32536, 0.007136, 0.011669, 0.027769, 0.0048348, 0.79878, 0.058878]
Predicted label: 8
Correct prediction
Energy consumption = 145.274790 pJ
sum error= 65
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 139 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 139 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 139 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.044986, 0.045463, 0.015489, 0.030394, 0.0033241, 0.71379, 0.015731, 0.042742, 0.30357]
Predicted label: 0
Correct prediction
Energy consumption = 154.102804 pJ
sum error= 65
Actual label: 4
Output voltages: [0.010031, 0.017123, 0.15157, 0.0032505, 0.79878, 0.068286, 0.18316, 0.01033, 0.061248, 0.30397]
Predicted label: 4
Correct prediction
Energy consumption = 163.680717 pJ
sum error= 65
Actual label: 1
Output voltages: [0.052257, 0.79865, 0.20907, 0.03388, 0.016279, 0.0029167, 0.081228, 0.010591, 0.35147, 0.019288]
Predicted label: 1
Correct prediction
Energy consumption = 169.457325 pJ
sum error= 65
Actual label: 5
Output voltages: [0.1543, 0.0010668, 0.027013, 0.77981, 0.0010936, 0.47537, 0.0093848, 0.53185, 0.51199, 0.0016446]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.465222 pJ
sum error= 66
Actual label: 8
Output voltages: [0.013131, 0.012769, 0.12457, 0.7448, 0.0016674, 0.0091671, 0.02243, 0.0057203, 0.79812, 0.47712]
Predicted label: 8
Correct prediction
Energy consumption = 150.859642 pJ
sum error= 66
Actual label: 2
Output voltages: [0.37541, 0.0022599, 0.76415, 0.7464, 0.033407, 0.0013212, 0.029315, 0.13368, 0.64215, 0.023944]
Predicted label: 2
Correct prediction
Energy consumption = 144.553614 pJ
sum error= 66
Actual label: 9
Output voltages: [0.041785, 0.038801, 0.022418, 0.062228, 0.13742, 0.007906, 0.0049789, 0.014312, 0.44726, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 151.907827 pJ
sum error= 66
Actual label: 1
Output voltages: [0.0041652, 0.7986, 0.021431, 0.10725, 0.15152, 0.0052582, 0.12265, 0.015483, 0.2607, 0.33591]
Predicted label: 1
Correct prediction
Energy consumption = 161.520152 pJ
sum error= 66
Actual label: 8
Output voltages: [0.080455, 0.060967, 0.31276, 0.089534, 0.0052554, 0.026618, 0.031512, 0.024532, 0.7987, 0.4564]
Predicted label: 8
Correct prediction
Energy consumption = 154.003264 pJ
sum error= 66
Actual label: 0
Output voltages: [0.79868, 0.11344, 0.041726, 0.0027593, 0.011893, 0.025297, 0.75187, 0.021311, 0.054891, 0.013752]
Predicted label: 0
Correct prediction
Energy consumption = 152.258977 pJ
sum error= 66
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 140 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 140 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 140 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.053468, 0.020293, 0.086359, 0.0031339, 0.39591, 0.19417, 0.79879, 0.0097801, 0.68067, 0.012672]
Predicted label: 6
Correct prediction
Energy consumption = 151.965182 pJ
sum error= 66
Actual label: 7
Output voltages: [0.32783, 0.046003, 0.0061684, 0.20163, 0.022808, 0.012043, 0.0014222, 0.79877, 0.094162, 0.64305]
Predicted label: 7
Correct prediction
Energy consumption = 158.794256 pJ
sum error= 66
Actual label: 2
Output voltages: [0.232, 0.031231, 0.7983, 0.024568, 0.029276, 0.0014559, 0.043127, 0.67989, 0.31986, 0.016454]
Predicted label: 2
Correct prediction
Energy consumption = 137.160261 pJ
sum error= 66
Actual label: 1
Output voltages: [0.029053, 0.79868, 0.14009, 0.018689, 0.035379, 0.0080892, 0.78675, 0.0010682, 0.45155, 0.04936]
Predicted label: 1
Correct prediction
Energy consumption = 149.614151 pJ
sum error= 66
Actual label: 0
Output voltages: [0.79774, 0.064145, 0.14632, 0.039191, 0.018735, 0.003526, 0.50026, 0.014319, 0.52638, 0.049395]
Predicted label: 0
Correct prediction
Energy consumption = 156.243409 pJ
sum error= 66
Actual label: 5
Output voltages: [0.10437, 0.0019243, 0.0011311, 0.49806, 0.030841, 0.79874, 0.39029, 0.016543, 0.76319, 0.0035434]
Predicted label: 5
Correct prediction
Energy consumption = 147.670714 pJ
sum error= 66
Actual label: 5
Output voltages: [0.043171, 0.0081292, 0.0063263, 0.03763, 0.02132, 0.79879, 0.19603, 0.037404, 0.77963, 0.055815]
Predicted label: 5
Correct prediction
Energy consumption = 142.534458 pJ
sum error= 66
Actual label: 2
Output voltages: [0.54472, 0.0031606, 0.79875, 0.056882, 0.034023, 0.0011156, 0.072866, 0.050061, 0.56459, 0.015492]
Predicted label: 2
Correct prediction
Energy consumption = 146.050689 pJ
sum error= 66
Actual label: 0
Output voltages: [0.79407, 0.02772, 0.024034, 0.0030477, 0.0095028, 0.0048472, 0.754, 0.11317, 0.038047, 0.06242]
Predicted label: 0
Correct prediction
Energy consumption = 142.537181 pJ
sum error= 66
Actual label: 2
Output voltages: [0.74689, 0.35251, 0.79878, 0.015621, 0.0062242, 0.0013685, 0.64208, 0.20929, 0.31376, 0.03194]
Predicted label: 2
Correct prediction
Energy consumption = 147.582387 pJ
sum error= 66
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 141 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 141 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 141 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.22313, 0.21141, 0.79212, 0.41464, 0.035689, 0.0010714, 0.65278, 0.18825, 0.11516, 0.0020633]
Predicted label: 2
Correct prediction
Energy consumption = 156.542168 pJ
sum error= 66
Actual label: 0
Output voltages: [0.79777, 0.025791, 0.019013, 0.19143, 0.16825, 0.019255, 0.37784, 0.029891, 0.48207, 0.414]
Predicted label: 0
Correct prediction
Energy consumption = 168.242278 pJ
sum error= 66
Actual label: 2
Output voltages: [0.24468, 0.47461, 0.79877, 0.049026, 0.023036, 0.0012962, 0.30507, 0.014551, 0.11338, 0.056745]
Predicted label: 2
Correct prediction
Energy consumption = 148.979746 pJ
sum error= 66
Actual label: 4
Output voltages: [0.022766, 0.081759, 0.049701, 0.0054784, 0.79864, 0.0053439, 0.395, 0.018817, 0.055021, 0.14262]
Predicted label: 4
Correct prediction
Energy consumption = 157.662119 pJ
sum error= 66
Actual label: 9
Output voltages: [0.53512, 0.5348, 0.0019486, 0.36496, 0.053373, 0.038613, 0.0081389, 0.049215, 0.014289, 0.79702]
Predicted label: 9
Correct prediction
Energy consumption = 163.217959 pJ
sum error= 66
Actual label: 8
Output voltages: [0.020936, 0.0012838, 0.035068, 0.061519, 0.018113, 0.20828, 0.70043, 0.0010824, 0.79114, 0.042528]
Predicted label: 8
Correct prediction
Energy consumption = 149.999417 pJ
sum error= 66
Actual label: 0
Output voltages: [0.79879, 0.022366, 0.023152, 0.031641, 0.027469, 0.0038967, 0.64365, 0.001712, 0.019526, 0.52425]
Predicted label: 0
Correct prediction
Energy consumption = 156.432356 pJ
sum error= 66
Actual label: 9
Output voltages: [0.39532, 0.021423, 0.034299, 0.29254, 0.033825, 0.072019, 0.003247, 0.42182, 0.20784, 0.7967]
Predicted label: 9
Correct prediction
Energy consumption = 148.058287 pJ
sum error= 66
Actual label: 9
Output voltages: [0.37144, 0.015611, 0.0047214, 0.19998, 0.041292, 0.086142, 0.010429, 0.040723, 0.052976, 0.7979]
Predicted label: 9
Correct prediction
Energy consumption = 141.499661 pJ
sum error= 66
Actual label: 4
Output voltages: [0.023738, 0.017606, 0.053745, 0.010752, 0.79861, 0.0041024, 0.24886, 0.31483, 0.0446, 0.063997]
Predicted label: 4
Correct prediction
Energy consumption = 145.394753 pJ
sum error= 66
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 142 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 142 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 142 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.055109, 0.040891, 0.21776, 0.003844, 0.20907, 0.4114, 0.79874, 0.010078, 0.55604, 0.011812]
Predicted label: 6
Correct prediction
Energy consumption = 152.544385 pJ
sum error= 66
Actual label: 5
Output voltages: [0.035579, 0.0011277, 0.0011058, 0.067817, 0.23683, 0.78337, 0.43623, 0.0012007, 0.78683, 0.02645]
Predicted label: 8
Wrong prediction!
Energy consumption = 138.026679 pJ
sum error= 67
Actual label: 4
Output voltages: [0.082188, 0.012962, 0.15938, 0.01626, 0.79877, 0.0030974, 0.25265, 0.017632, 0.015254, 0.14605]
Predicted label: 4
Correct prediction
Energy consumption = 153.569962 pJ
sum error= 67
Actual label: 9
Output voltages: [0.087625, 0.0014302, 0.045644, 0.22557, 0.17129, 0.0054511, 0.0017126, 0.16766, 0.55958, 0.7942]
Predicted label: 9
Correct prediction
Energy consumption = 140.012492 pJ
sum error= 67
Actual label: 1
Output voltages: [0.027771, 0.79844, 0.0033684, 0.18874, 0.012415, 0.0012058, 0.66927, 0.0038372, 0.34074, 0.081753]
Predicted label: 1
Correct prediction
Energy consumption = 159.857695 pJ
sum error= 67
Actual label: 8
Output voltages: [0.017566, 0.032459, 0.22916, 0.022458, 0.51665, 0.059268, 0.46306, 0.0011502, 0.75547, 0.0084804]
Predicted label: 8
Correct prediction
Energy consumption = 148.378299 pJ
sum error= 67
Actual label: 3
Output voltages: [0.17107, 0.026893, 0.038124, 0.79866, 0.024629, 0.0040358, 0.012268, 0.01533, 0.54767, 0.083013]
Predicted label: 3
Correct prediction
Energy consumption = 139.670948 pJ
sum error= 67
Actual label: 4
Output voltages: [0.034774, 0.0021006, 0.37901, 0.008537, 0.79874, 0.0010689, 0.33246, 0.013593, 0.072675, 0.034259]
Predicted label: 4
Correct prediction
Energy consumption = 144.478422 pJ
sum error= 67
Actual label: 9
Output voltages: [0.3478, 0.012916, 0.29146, 0.011233, 0.29405, 0.0062098, 0.0044255, 0.0092482, 0.2537, 0.79689]
Predicted label: 9
Correct prediction
Energy consumption = 146.481710 pJ
sum error= 67
Actual label: 9
Output voltages: [0.438, 0.0028128, 0.021897, 0.0089026, 0.1547, 0.0091832, 0.029497, 0.017832, 0.37586, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 142.057383 pJ
sum error= 67
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 143 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 143 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 143 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.017902, 0.79849, 0.014235, 0.085793, 0.0065395, 0.0013309, 0.4873, 0.0032575, 0.53942, 0.018026]
Predicted label: 1
Correct prediction
Energy consumption = 162.292844 pJ
sum error= 67
Actual label: 2
Output voltages: [0.23836, 0.1546, 0.79855, 0.30087, 0.0056982, 0.0013352, 0.14647, 0.077548, 0.58703, 0.074964]
Predicted label: 2
Correct prediction
Energy consumption = 152.608668 pJ
sum error= 67
Actual label: 2
Output voltages: [0.3793, 0.13919, 0.79879, 0.072898, 0.0096008, 0.001324, 0.50261, 0.0083321, 0.52218, 0.029033]
Predicted label: 2
Correct prediction
Energy consumption = 135.664055 pJ
sum error= 67
Actual label: 8
Output voltages: [0.024992, 0.77598, 0.0056663, 0.61017, 0.0021218, 0.0078612, 0.010412, 0.057143, 0.794, 0.069356]
Predicted label: 8
Correct prediction
Energy consumption = 153.170515 pJ
sum error= 67
Actual label: 1
Output voltages: [0.044628, 0.79848, 0.034768, 0.034951, 0.028875, 0.0027577, 0.43688, 0.0014913, 0.25885, 0.030978]
Predicted label: 1
Correct prediction
Energy consumption = 152.492516 pJ
sum error= 67
Actual label: 9
Output voltages: [0.31271, 0.001085, 0.088009, 0.017325, 0.14008, 0.015849, 0.0012356, 0.28779, 0.41154, 0.79575]
Predicted label: 9
Correct prediction
Energy consumption = 158.836192 pJ
sum error= 67
Actual label: 6
Output voltages: [0.06311, 0.019118, 0.024808, 0.010209, 0.064721, 0.051426, 0.79483, 0.010478, 0.7851, 0.0037515]
Predicted label: 6
Correct prediction
Energy consumption = 150.718729 pJ
sum error= 67
Actual label: 4
Output voltages: [0.042123, 0.021736, 0.053843, 0.011045, 0.79697, 0.04689, 0.020452, 0.0058702, 0.097915, 0.73843]
Predicted label: 4
Correct prediction
Energy consumption = 158.700217 pJ
sum error= 67
Actual label: 0
Output voltages: [0.79871, 0.24219, 0.045634, 0.0072331, 0.040912, 0.025963, 0.77154, 0.02566, 0.18066, 0.0064961]
Predicted label: 0
Correct prediction
Energy consumption = 155.652903 pJ
sum error= 67
Actual label: 9
Output voltages: [0.259, 0.020305, 0.013379, 0.053156, 0.51535, 0.0014367, 0.0012402, 0.0011458, 0.16498, 0.79791]
Predicted label: 9
Correct prediction
Energy consumption = 155.100817 pJ
sum error= 67
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 144 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 144 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 144 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0139, 0.037313, 0.032732, 0.0048125, 0.797, 0.014864, 0.030171, 0.0042443, 0.51307, 0.039119]
Predicted label: 4
Correct prediction
Energy consumption = 141.160752 pJ
sum error= 67
Actual label: 8
Output voltages: [0.037413, 0.0070186, 0.038635, 0.17167, 0.043389, 0.0046085, 0.0056784, 0.017599, 0.79748, 0.55776]
Predicted label: 8
Correct prediction
Energy consumption = 154.101922 pJ
sum error= 67
Actual label: 3
Output voltages: [0.54915, 0.010805, 0.14851, 0.79872, 0.023006, 0.0083895, 0.0048633, 0.01593, 0.55024, 0.040884]
Predicted label: 3
Correct prediction
Energy consumption = 143.962943 pJ
sum error= 67
Actual label: 8
Output voltages: [0.032259, 0.084021, 0.14687, 0.30754, 0.022509, 0.022938, 0.032312, 0.014035, 0.79868, 0.31157]
Predicted label: 8
Correct prediction
Energy consumption = 145.898318 pJ
sum error= 67
Actual label: 6
Output voltages: [0.59552, 0.0034669, 0.051076, 0.0010959, 0.65876, 0.019596, 0.79743, 0.033236, 0.1471, 0.004511]
Predicted label: 6
Correct prediction
Energy consumption = 155.506862 pJ
sum error= 67
Actual label: 0
Output voltages: [0.79869, 0.060115, 0.13264, 0.012987, 0.021569, 0.0048485, 0.63459, 0.0095991, 0.14339, 0.40801]
Predicted label: 0
Correct prediction
Energy consumption = 155.691329 pJ
sum error= 67
Actual label: 2
Output voltages: [0.35458, 0.015893, 0.79878, 0.049876, 0.01203, 0.0011319, 0.10629, 0.029527, 0.74582, 0.0093702]
Predicted label: 2
Correct prediction
Energy consumption = 143.368931 pJ
sum error= 67
Actual label: 5
Output voltages: [0.050198, 0.0010717, 0.0011048, 0.28979, 0.40688, 0.79875, 0.61076, 0.014278, 0.7794, 0.047092]
Predicted label: 5
Correct prediction
Energy consumption = 151.165834 pJ
sum error= 67
Actual label: 1
Output voltages: [0.042092, 0.79854, 0.15732, 0.01927, 0.037861, 0.0017309, 0.50023, 0.0077943, 0.084214, 0.11505]
Predicted label: 1
Correct prediction
Energy consumption = 168.060150 pJ
sum error= 67
Actual label: 9
Output voltages: [0.72193, 0.0034586, 0.029226, 0.016888, 0.018727, 0.031134, 0.0027332, 0.31434, 0.43896, 0.79719]
Predicted label: 9
Correct prediction
Energy consumption = 155.699493 pJ
sum error= 67
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 145 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 145 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 145 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.39249, 0.036001, 0.23594, 0.016351, 0.2377, 0.28239, 0.79878, 0.0012791, 0.37164, 0.029549]
Predicted label: 6
Correct prediction
Energy consumption = 145.671793 pJ
sum error= 67
Actual label: 2
Output voltages: [0.78543, 0.014315, 0.79879, 0.31699, 0.0032112, 0.0012612, 0.14118, 0.33311, 0.68717, 0.011031]
Predicted label: 2
Correct prediction
Energy consumption = 150.229167 pJ
sum error= 67
Actual label: 9
Output voltages: [0.52733, 0.0053486, 0.02706, 0.012924, 0.45667, 0.017046, 0.0015092, 0.011275, 0.35157, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 155.529563 pJ
sum error= 67
Actual label: 4
Output voltages: [0.019015, 0.026144, 0.095332, 0.009209, 0.79865, 0.0038153, 0.039776, 0.0098633, 0.021596, 0.29711]
Predicted label: 4
Correct prediction
Energy consumption = 144.480323 pJ
sum error= 67
Actual label: 0
Output voltages: [0.79877, 0.20098, 0.078685, 0.0059894, 0.0025553, 0.012181, 0.33876, 0.042152, 0.42019, 0.18548]
Predicted label: 0
Correct prediction
Energy consumption = 160.038028 pJ
sum error= 67
Actual label: 9
Output voltages: [0.22703, 0.0020349, 0.029518, 0.18668, 0.77645, 0.001201, 0.0014378, 0.0044024, 0.052566, 0.79702]
Predicted label: 9
Correct prediction
Energy consumption = 151.616538 pJ
sum error= 67
Actual label: 6
Output voltages: [0.1559, 0.17663, 0.33408, 0.0022163, 0.2494, 0.18459, 0.79869, 0.0093254, 0.27323, 0.0053257]
Predicted label: 6
Correct prediction
Energy consumption = 154.341774 pJ
sum error= 67
Actual label: 0
Output voltages: [0.79873, 0.2175, 0.026309, 0.0085131, 0.017357, 0.015995, 0.37602, 0.014478, 0.12947, 0.054571]
Predicted label: 0
Correct prediction
Energy consumption = 144.301959 pJ
sum error= 67
Actual label: 6
Output voltages: [0.2677, 0.057723, 0.28185, 0.019857, 0.065418, 0.45484, 0.79873, 0.0065661, 0.33719, 0.068082]
Predicted label: 6
Correct prediction
Energy consumption = 141.681229 pJ
sum error= 67
Actual label: 2
Output voltages: [0.046605, 0.023368, 0.79878, 0.32659, 0.017836, 0.0010662, 0.008503, 0.65991, 0.51227, 0.0092092]
Predicted label: 2
Correct prediction
Energy consumption = 152.898485 pJ
sum error= 67
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 146 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 146 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 146 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.0088083, 0.0010819, 0.0029445, 0.089851, 0.03717, 0.77632, 0.047925, 0.0033371, 0.78389, 0.14598]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.966609 pJ
sum error= 68
Actual label: 4
Output voltages: [0.027853, 0.011217, 0.38826, 0.0028277, 0.79856, 0.0094139, 0.36615, 0.035606, 0.030541, 0.095845]
Predicted label: 4
Correct prediction
Energy consumption = 150.574863 pJ
sum error= 68
Actual label: 2
Output voltages: [0.71287, 0.0013694, 0.76959, 0.737, 0.01073, 0.0011278, 0.0040984, 0.02133, 0.55684, 0.0020078]
Predicted label: 2
Correct prediction
Energy consumption = 150.293608 pJ
sum error= 68
Actual label: 3
Output voltages: [0.084844, 0.016166, 0.027091, 0.7987, 0.0173, 0.0091743, 0.0093403, 0.010319, 0.39294, 0.042682]
Predicted label: 3
Correct prediction
Energy consumption = 136.322649 pJ
sum error= 68
Actual label: 8
Output voltages: [0.021201, 0.12834, 0.020552, 0.031225, 0.01711, 0.057475, 0.021424, 0.099015, 0.79865, 0.30386]
Predicted label: 8
Correct prediction
Energy consumption = 152.008184 pJ
sum error= 68
Actual label: 4
Output voltages: [0.0017593, 0.065778, 0.32927, 0.015104, 0.79879, 0.0011783, 0.37874, 0.032881, 0.034924, 0.025925]
Predicted label: 4
Correct prediction
Energy consumption = 152.225097 pJ
sum error= 68
Actual label: 5
Output voltages: [0.48748, 0.028948, 0.0011607, 0.73235, 0.0057422, 0.79868, 0.014935, 0.0084498, 0.74164, 0.13807]
Predicted label: 5
Correct prediction
Energy consumption = 153.838485 pJ
sum error= 68
Actual label: 5
Output voltages: [0.019967, 0.0019503, 0.0014286, 0.20868, 0.10654, 0.79739, 0.027658, 0.13234, 0.72489, 0.55226]
Predicted label: 5
Correct prediction
Energy consumption = 143.827343 pJ
sum error= 68
Actual label: 0
Output voltages: [0.79846, 0.028445, 0.18134, 0.0042451, 0.010019, 0.0019048, 0.47251, 0.0055283, 0.29037, 0.027332]
Predicted label: 0
Correct prediction
Energy consumption = 143.496284 pJ
sum error= 68
Actual label: 3
Output voltages: [0.023521, 0.019981, 0.47147, 0.7986, 0.0038249, 0.46645, 0.47158, 0.042691, 0.013918, 0.0016875]
Predicted label: 3
Correct prediction
Energy consumption = 147.277483 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 147 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 147 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 147 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.017788, 0.0048017, 0.082929, 0.18825, 0.0011194, 0.27275, 0.0026574, 0.044863, 0.79874, 0.0044667]
Predicted label: 8
Correct prediction
Energy consumption = 146.330347 pJ
sum error= 68
Actual label: 5
Output voltages: [0.019139, 0.0017375, 0.0020226, 0.48679, 0.0075947, 0.79868, 0.21993, 0.01481, 0.75298, 0.041318]
Predicted label: 5
Correct prediction
Energy consumption = 142.249509 pJ
sum error= 68
Actual label: 3
Output voltages: [0.35514, 0.001066, 0.04091, 0.79879, 0.031969, 0.43771, 0.0050722, 0.011547, 0.45534, 0.024074]
Predicted label: 3
Correct prediction
Energy consumption = 137.007558 pJ
sum error= 68
Actual label: 5
Output voltages: [0.031771, 0.0060482, 0.0020099, 0.1415, 0.020723, 0.79865, 0.33964, 0.034749, 0.52977, 0.05841]
Predicted label: 5
Correct prediction
Energy consumption = 148.568752 pJ
sum error= 68
Actual label: 8
Output voltages: [0.023566, 0.056139, 0.10988, 0.34774, 0.018695, 0.0070852, 0.0069339, 0.025584, 0.79874, 0.25633]
Predicted label: 8
Correct prediction
Energy consumption = 149.793492 pJ
sum error= 68
Actual label: 6
Output voltages: [0.35256, 0.024736, 0.059809, 0.001948, 0.15495, 0.027262, 0.79874, 0.0022344, 0.68346, 0.012383]
Predicted label: 6
Correct prediction
Energy consumption = 153.072848 pJ
sum error= 68
Actual label: 5
Output voltages: [0.55671, 0.0016254, 0.0027148, 0.72322, 0.073213, 0.79879, 0.35292, 0.050933, 0.36047, 0.63553]
Predicted label: 5
Correct prediction
Energy consumption = 151.011886 pJ
sum error= 68
Actual label: 7
Output voltages: [0.13508, 0.046736, 0.039554, 0.15757, 0.03264, 0.001561, 0.0018331, 0.79849, 0.038193, 0.02739]
Predicted label: 7
Correct prediction
Energy consumption = 150.447723 pJ
sum error= 68
Actual label: 6
Output voltages: [0.058664, 0.024735, 0.026745, 0.014967, 0.35982, 0.1184, 0.79879, 0.0042113, 0.7545, 0.0061087]
Predicted label: 6
Correct prediction
Energy consumption = 156.619330 pJ
sum error= 68
Actual label: 3
Output voltages: [0.048974, 0.020344, 0.16225, 0.79877, 0.016717, 0.0023366, 0.0068573, 0.027094, 0.72776, 0.02063]
Predicted label: 3
Correct prediction
Energy consumption = 144.666433 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 148 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 148 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 148 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.12146, 0.0027726, 0.046702, 0.79879, 0.11983, 0.0024215, 0.012045, 0.033242, 0.66234, 0.055716]
Predicted label: 3
Correct prediction
Energy consumption = 144.303808 pJ
sum error= 68
Actual label: 9
Output voltages: [0.40704, 0.0031218, 0.0071503, 0.12485, 0.071639, 0.1823, 0.0013432, 0.46233, 0.080222, 0.7915]
Predicted label: 9
Correct prediction
Energy consumption = 149.406537 pJ
sum error= 68
Actual label: 6
Output voltages: [0.045341, 0.027989, 0.2635, 0.0015021, 0.047627, 0.43974, 0.79879, 0.002738, 0.46806, 0.0012958]
Predicted label: 6
Correct prediction
Energy consumption = 147.133656 pJ
sum error= 68
Actual label: 1
Output voltages: [0.042887, 0.79838, 0.033477, 0.22497, 0.019484, 0.012797, 0.4354, 0.0056052, 0.11043, 0.049773]
Predicted label: 1
Correct prediction
Energy consumption = 163.962679 pJ
sum error= 68
Actual label: 1
Output voltages: [0.038443, 0.79869, 0.001066, 0.023206, 0.25636, 0.031223, 0.17166, 0.00919, 0.28024, 0.12901]
Predicted label: 1
Correct prediction
Energy consumption = 156.159284 pJ
sum error= 68
Actual label: 2
Output voltages: [0.44511, 0.01291, 0.79876, 0.23488, 0.025422, 0.0011923, 0.023077, 0.047619, 0.29348, 0.012701]
Predicted label: 2
Correct prediction
Energy consumption = 148.076582 pJ
sum error= 68
Actual label: 9
Output voltages: [0.28754, 0.006651, 0.019304, 0.013757, 0.17662, 0.0029966, 0.013935, 0.012531, 0.088254, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 153.194472 pJ
sum error= 68
Actual label: 0
Output voltages: [0.79871, 0.04559, 0.082347, 0.0084387, 0.015041, 0.0083944, 0.29662, 0.015167, 0.041303, 0.027905]
Predicted label: 0
Correct prediction
Energy consumption = 149.286585 pJ
sum error= 68
Actual label: 4
Output voltages: [0.01169, 0.011297, 0.46818, 0.0013844, 0.7986, 0.0048089, 0.46323, 0.046207, 0.045017, 0.045806]
Predicted label: 4
Correct prediction
Energy consumption = 150.091925 pJ
sum error= 68
Actual label: 3
Output voltages: [0.074545, 0.0022216, 0.21227, 0.79878, 0.056965, 0.13255, 0.022484, 0.035183, 0.74469, 0.04025]
Predicted label: 3
Correct prediction
Energy consumption = 141.193966 pJ
sum error= 68
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 149 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 149 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 149 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.63459, 0.019901, 0.15746, 0.79863, 0.022927, 0.0047869, 0.047601, 0.024347, 0.48067, 0.012429]
Predicted label: 3
Correct prediction
Energy consumption = 144.566745 pJ
sum error= 68
Actual label: 6
Output voltages: [0.13614, 0.02241, 0.1584, 0.0020075, 0.45776, 0.15652, 0.79872, 0.0020081, 0.54021, 0.01324]
Predicted label: 6
Correct prediction
Energy consumption = 149.673644 pJ
sum error= 68
Actual label: 9
Output voltages: [0.25644, 0.006474, 0.015188, 0.043166, 0.041595, 0.014387, 0.0010823, 0.30895, 0.12485, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 159.644829 pJ
sum error= 68
Actual label: 5
Output voltages: [0.021046, 0.0011486, 0.0018658, 0.060775, 0.042328, 0.78614, 0.016118, 0.0035926, 0.7759, 0.24778]
Predicted label: 5
Correct prediction
Energy consumption = 145.399415 pJ
sum error= 68
Actual label: 7
Output voltages: [0.79868, 0.028578, 0.03782, 0.0012685, 0.012926, 0.0063216, 0.035699, 0.44232, 0.61522, 0.33424]
Predicted label: 0
Wrong prediction!
Energy consumption = 155.690701 pJ
sum error= 69
Actual label: 3
Output voltages: [0.52678, 0.44084, 0.20165, 0.79851, 0.0035583, 0.06162, 0.10537, 0.037487, 0.14311, 0.02852]
Predicted label: 3
Correct prediction
Energy consumption = 161.416340 pJ
sum error= 69
Actual label: 7
Output voltages: [0.14684, 0.040099, 0.060787, 0.049941, 0.0016979, 0.0015406, 0.001079, 0.79875, 0.04221, 0.62702]
Predicted label: 7
Correct prediction
Energy consumption = 156.800119 pJ
sum error= 69
Actual label: 7
Output voltages: [0.5784, 0.026443, 0.15101, 0.034093, 0.011673, 0.0010707, 0.0011203, 0.79875, 0.51028, 0.050187]
Predicted label: 7
Correct prediction
Energy consumption = 140.697648 pJ
sum error= 69
Actual label: 7
Output voltages: [0.051345, 0.39377, 0.081389, 0.027249, 0.067069, 0.0014782, 0.0011828, 0.7987, 0.028558, 0.026155]
Predicted label: 7
Correct prediction
Energy consumption = 137.082275 pJ
sum error= 69
Actual label: 8
Output voltages: [0.39674, 0.012949, 0.33925, 0.054866, 0.027696, 0.54692, 0.015327, 0.025888, 0.79869, 0.0085516]
Predicted label: 8
Correct prediction
Energy consumption = 146.212082 pJ
sum error= 69
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 150 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 150 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 150 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.74463, 0.19979, 0.28702, 0.79874, 0.001698, 0.001129, 0.0010753, 0.29848, 0.39936, 0.2174]
Predicted label: 3
Wrong prediction!
Energy consumption = 160.103459 pJ
sum error= 70
Actual label: 9
Output voltages: [0.059949, 0.019211, 0.20084, 0.08446, 0.062509, 0.011426, 0.047805, 0.018213, 0.055126, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 146.914550 pJ
sum error= 70
Actual label: 8
Output voltages: [0.039016, 0.019478, 0.035847, 0.41671, 0.0070727, 0.043475, 0.30767, 0.0029277, 0.79878, 0.053296]
Predicted label: 8
Correct prediction
Energy consumption = 152.050793 pJ
sum error= 70
Actual label: 3
Output voltages: [0.47525, 0.029526, 0.066328, 0.79869, 0.036416, 0.051497, 0.053439, 0.003829, 0.51345, 0.30268]
Predicted label: 3
Correct prediction
Energy consumption = 147.769844 pJ
sum error= 70
Actual label: 0
Output voltages: [0.79868, 0.030619, 0.039143, 0.026645, 0.058587, 0.0093844, 0.28464, 0.028132, 0.081565, 0.25414]
Predicted label: 0
Correct prediction
Energy consumption = 153.704614 pJ
sum error= 70
Actual label: 7
Output voltages: [0.47454, 0.13758, 0.75645, 0.13447, 0.0013321, 0.0011227, 0.008994, 0.77477, 0.33957, 0.066499]
Predicted label: 7
Correct prediction
Energy consumption = 157.938193 pJ
sum error= 70
Actual label: 2
Output voltages: [0.60442, 0.03199, 0.79876, 0.03667, 0.016014, 0.0012306, 0.11272, 0.038233, 0.37238, 0.023164]
Predicted label: 2
Correct prediction
Energy consumption = 138.578221 pJ
sum error= 70
Actual label: 7
Output voltages: [0.46717, 0.28489, 0.72583, 0.059417, 0.0068092, 0.0011851, 0.0015435, 0.79879, 0.031689, 0.34375]
Predicted label: 7
Correct prediction
Energy consumption = 152.526182 pJ
sum error= 70
Actual label: 9
Output voltages: [0.0075655, 0.0063711, 0.037298, 0.014501, 0.10352, 0.17373, 0.031609, 0.015122, 0.77266, 0.67352]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.500483 pJ
sum error= 71
Actual label: 4
Output voltages: [0.0015857, 0.0015291, 0.26676, 0.0046514, 0.79849, 0.0078215, 0.027249, 0.22507, 0.71558, 0.02587]
Predicted label: 4
Correct prediction
Energy consumption = 148.208110 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 151 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 151 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 151 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.043864, 0.0011708, 0.013902, 0.4053, 0.0044736, 0.79848, 0.12395, 0.090811, 0.7633, 0.20291]
Predicted label: 5
Correct prediction
Energy consumption = 146.867469 pJ
sum error= 71
Actual label: 4
Output voltages: [0.017979, 0.020922, 0.05289, 0.0021497, 0.79879, 0.010581, 0.14639, 0.041372, 0.32014, 0.0059713]
Predicted label: 4
Correct prediction
Energy consumption = 148.014731 pJ
sum error= 71
Actual label: 9
Output voltages: [0.49676, 0.018175, 0.0078448, 0.066888, 0.32962, 0.010344, 0.034662, 0.032942, 0.047249, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.223341 pJ
sum error= 71
Actual label: 3
Output voltages: [0.28209, 0.0072587, 0.01864, 0.79874, 0.066888, 0.035925, 0.032635, 0.0040018, 0.6269, 0.033359]
Predicted label: 3
Correct prediction
Energy consumption = 146.270961 pJ
sum error= 71
Actual label: 2
Output voltages: [0.050062, 0.31186, 0.79879, 0.11992, 0.0022484, 0.0012321, 0.13886, 0.021124, 0.62698, 0.070145]
Predicted label: 2
Correct prediction
Energy consumption = 143.828191 pJ
sum error= 71
Actual label: 1
Output voltages: [0.042118, 0.79855, 0.11831, 0.02898, 0.040372, 0.0012528, 0.47255, 0.0012627, 0.18564, 0.054755]
Predicted label: 1
Correct prediction
Energy consumption = 155.846147 pJ
sum error= 71
Actual label: 4
Output voltages: [0.034117, 0.013046, 0.082946, 0.064299, 0.79872, 0.0096508, 0.070475, 0.043411, 0.010751, 0.4819]
Predicted label: 4
Correct prediction
Energy consumption = 156.511738 pJ
sum error= 71
Actual label: 0
Output voltages: [0.79878, 0.13737, 0.021553, 0.022031, 0.011749, 0.0082302, 0.39975, 0.0058276, 0.043499, 0.25272]
Predicted label: 0
Correct prediction
Energy consumption = 161.662197 pJ
sum error= 71
Actual label: 2
Output voltages: [0.10447, 0.055408, 0.79871, 0.23557, 0.019192, 0.0013414, 0.0242, 0.11002, 0.46575, 0.031134]
Predicted label: 2
Correct prediction
Energy consumption = 147.817399 pJ
sum error= 71
Actual label: 3
Output voltages: [0.54607, 0.028431, 0.06027, 0.79863, 0.013839, 0.030605, 0.015582, 0.0079254, 0.46509, 0.026161]
Predicted label: 3
Correct prediction
Energy consumption = 139.972780 pJ
sum error= 71
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 152 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 152 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 152 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.52285, 0.0014337, 0.68292, 0.0017498, 0.0014355, 0.0048653, 0.0010787, 0.77901, 0.77509, 0.02305]
Predicted label: 7
Correct prediction
Energy consumption = 141.192826 pJ
sum error= 71
Actual label: 5
Output voltages: [0.046966, 0.0010948, 0.0062419, 0.54915, 0.022021, 0.79801, 0.029032, 0.045969, 0.77285, 0.14701]
Predicted label: 5
Correct prediction
Energy consumption = 145.897047 pJ
sum error= 71
Actual label: 7
Output voltages: [0.053943, 0.09113, 0.001077, 0.040391, 0.32127, 0.0022535, 0.0010969, 0.48684, 0.37903, 0.57572]
Predicted label: 9
Wrong prediction!
Energy consumption = 170.546826 pJ
sum error= 72
Actual label: 8
Output voltages: [0.01708, 0.0031786, 0.011457, 0.10401, 0.013377, 0.73065, 0.23168, 0.0078889, 0.79869, 0.029434]
Predicted label: 8
Correct prediction
Energy consumption = 147.422733 pJ
sum error= 72
Actual label: 8
Output voltages: [0.030264, 0.043839, 0.048868, 0.60363, 0.0010662, 0.17306, 0.0063673, 0.048318, 0.79878, 0.043596]
Predicted label: 8
Correct prediction
Energy consumption = 146.067636 pJ
sum error= 72
Actual label: 5
Output voltages: [0.71775, 0.0052893, 0.0046076, 0.38044, 0.004306, 0.79879, 0.2828, 0.056065, 0.36633, 0.010833]
Predicted label: 5
Correct prediction
Energy consumption = 151.037202 pJ
sum error= 72
Actual label: 0
Output voltages: [0.75337, 0.014451, 0.29139, 0.28895, 0.1433, 0.0013069, 0.30343, 0.0011134, 0.79628, 0.096449]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.517551 pJ
sum error= 73
Actual label: 1
Output voltages: [0.0020179, 0.74832, 0.33389, 0.046586, 0.0013053, 0.47411, 0.72356, 0.0013806, 0.031556, 0.0094895]
Predicted label: 1
Correct prediction
Energy consumption = 155.669558 pJ
sum error= 73
Actual label: 1
Output voltages: [0.10563, 0.79848, 0.11997, 0.11343, 0.0063678, 0.0024735, 0.71566, 0.0015145, 0.071564, 0.040832]
Predicted label: 1
Correct prediction
Energy consumption = 158.340473 pJ
sum error= 73
Actual label: 4
Output voltages: [0.0014281, 0.046577, 0.099899, 0.0021408, 0.79871, 0.0030045, 0.37123, 0.15924, 0.13324, 0.25351]
Predicted label: 4
Correct prediction
Energy consumption = 152.899404 pJ
sum error= 73
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 153 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 153 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 153 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.034284, 0.029187, 0.013281, 0.18981, 0.0010863, 0.20541, 0.0010689, 0.46257, 0.79859, 0.27626]
Predicted label: 8
Correct prediction
Energy consumption = 150.203021 pJ
sum error= 73
Actual label: 3
Output voltages: [0.10366, 0.0011612, 0.15689, 0.79877, 0.025669, 0.24289, 0.0093405, 0.0013746, 0.4902, 0.018427]
Predicted label: 3
Correct prediction
Energy consumption = 147.854096 pJ
sum error= 73
Actual label: 9
Output voltages: [0.24265, 0.016971, 0.026252, 0.048693, 0.2039, 0.015241, 0.0036832, 0.011003, 0.60239, 0.79864]
Predicted label: 9
Correct prediction
Energy consumption = 147.215108 pJ
sum error= 73
Actual label: 0
Output voltages: [0.7984, 0.039162, 0.010423, 0.022096, 0.029344, 0.020295, 0.74383, 0.05944, 0.10976, 0.022174]
Predicted label: 0
Correct prediction
Energy consumption = 148.782358 pJ
sum error= 73
Actual label: 0
Output voltages: [0.79723, 0.024321, 0.17918, 0.010337, 0.058742, 0.0013054, 0.73447, 0.039774, 0.16115, 0.041159]
Predicted label: 0
Correct prediction
Energy consumption = 148.318942 pJ
sum error= 73
Actual label: 0
Output voltages: [0.79878, 0.042419, 0.117, 0.057144, 0.027505, 0.0059614, 0.44971, 0.023387, 0.15418, 0.05948]
Predicted label: 0
Correct prediction
Energy consumption = 150.387253 pJ
sum error= 73
Actual label: 6
Output voltages: [0.032978, 0.019771, 0.50662, 0.001677, 0.012898, 0.36273, 0.79859, 0.0015568, 0.7621, 0.018504]
Predicted label: 6
Correct prediction
Energy consumption = 146.087700 pJ
sum error= 73
Actual label: 6
Output voltages: [0.22558, 0.02791, 0.15224, 0.0024944, 0.36526, 0.13283, 0.79879, 0.0027138, 0.74223, 0.0027119]
Predicted label: 6
Correct prediction
Energy consumption = 140.950203 pJ
sum error= 73
Actual label: 2
Output voltages: [0.14382, 0.21456, 0.76389, 0.6812, 0.040123, 0.0013277, 0.03952, 0.028101, 0.39179, 0.02433]
Predicted label: 2
Correct prediction
Energy consumption = 153.411150 pJ
sum error= 73
Actual label: 3
Output voltages: [0.73382, 0.013924, 0.047435, 0.79867, 0.0055216, 0.043202, 0.009293, 0.037478, 0.43899, 0.047641]
Predicted label: 3
Correct prediction
Energy consumption = 146.427134 pJ
sum error= 73
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 154 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 154 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 154 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25072, 0.049802, 0.034217, 0.35402, 0.0086227, 0.028344, 0.0010878, 0.79861, 0.029095, 0.22627]
Predicted label: 7
Correct prediction
Energy consumption = 151.163421 pJ
sum error= 73
Actual label: 8
Output voltages: [0.2747, 0.030241, 0.13696, 0.46849, 0.029001, 0.0031718, 0.14768, 0.0089144, 0.79879, 0.049098]
Predicted label: 8
Correct prediction
Energy consumption = 156.279569 pJ
sum error= 73
Actual label: 4
Output voltages: [0.015541, 0.0084122, 0.57328, 0.0068279, 0.79863, 0.0015246, 0.21106, 0.034328, 0.0158, 0.18187]
Predicted label: 4
Correct prediction
Energy consumption = 162.560608 pJ
sum error= 73
Actual label: 7
Output voltages: [0.30178, 0.0070638, 0.03384, 0.78601, 0.016457, 0.0012062, 0.0010746, 0.72828, 0.41421, 0.42022]
Predicted label: 3
Wrong prediction!
Energy consumption = 142.693018 pJ
sum error= 74
Actual label: 7
Output voltages: [0.14189, 0.17626, 0.041995, 0.53379, 0.0020379, 0.0084586, 0.0011012, 0.79876, 0.5243, 0.65741]
Predicted label: 7
Correct prediction
Energy consumption = 149.266701 pJ
sum error= 74
Actual label: 9
Output voltages: [0.21422, 0.0059751, 0.0084824, 0.27252, 0.15782, 0.11917, 0.0053443, 0.026421, 0.094049, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 143.942422 pJ
sum error= 74
Actual label: 2
Output voltages: [0.057353, 0.0064124, 0.77263, 0.65552, 0.042364, 0.0011685, 0.083415, 0.011443, 0.76811, 0.24472]
Predicted label: 2
Correct prediction
Energy consumption = 151.182132 pJ
sum error= 74
Actual label: 4
Output voltages: [0.066166, 0.50725, 0.022194, 0.24702, 0.78805, 0.0029567, 0.023924, 0.0025495, 0.017566, 0.77913]
Predicted label: 4
Correct prediction
Energy consumption = 162.466030 pJ
sum error= 74
Actual label: 1
Output voltages: [0.027449, 0.79855, 0.056022, 0.034131, 0.007188, 0.003999, 0.32256, 0.023233, 0.50899, 0.016897]
Predicted label: 1
Correct prediction
Energy consumption = 169.165287 pJ
sum error= 74
Actual label: 4
Output voltages: [0.14857, 0.27212, 0.48223, 0.0062452, 0.476, 0.0097175, 0.78794, 0.0012363, 0.38384, 0.0010665]
Predicted label: 6
Wrong prediction!
Energy consumption = 145.404958 pJ
sum error= 75
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 155 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 155 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 155 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.027232, 0.0011344, 0.0021444, 0.037411, 0.028213, 0.79875, 0.098852, 0.04079, 0.7672, 0.044438]
Predicted label: 5
Correct prediction
Energy consumption = 155.896420 pJ
sum error= 75
Actual label: 2
Output voltages: [0.065659, 0.7304, 0.79707, 0.743, 0.0027774, 0.0011142, 0.039239, 0.0047182, 0.19015, 0.031314]
Predicted label: 2
Correct prediction
Energy consumption = 161.162039 pJ
sum error= 75
Actual label: 4
Output voltages: [0.0037188, 0.0074372, 0.040901, 0.015846, 0.79877, 0.0010667, 0.20573, 0.18057, 0.019438, 0.043272]
Predicted label: 4
Correct prediction
Energy consumption = 157.535324 pJ
sum error= 75
Actual label: 9
Output voltages: [0.0045658, 0.0035743, 0.15594, 0.75489, 0.56925, 0.044054, 0.01516, 0.0014923, 0.56037, 0.61784]
Predicted label: 3
Wrong prediction!
Energy consumption = 153.953040 pJ
sum error= 76
Actual label: 9
Output voltages: [0.019461, 0.022367, 0.0069002, 0.023531, 0.013016, 0.0014015, 0.0010922, 0.054599, 0.7637, 0.79219]
Predicted label: 9
Correct prediction
Energy consumption = 152.749922 pJ
sum error= 76
Actual label: 1
Output voltages: [0.02526, 0.79851, 0.14575, 0.029632, 0.043766, 0.0021337, 0.48151, 0.0031602, 0.30223, 0.024406]
Predicted label: 1
Correct prediction
Energy consumption = 165.122039 pJ
sum error= 76
Actual label: 8
Output voltages: [0.069083, 0.012023, 0.43724, 0.0076854, 0.037734, 0.0016767, 0.033269, 0.015198, 0.79879, 0.18584]
Predicted label: 8
Correct prediction
Energy consumption = 146.998592 pJ
sum error= 76
Actual label: 4
Output voltages: [0.0076433, 0.021591, 0.11962, 0.014222, 0.79871, 0.0079714, 0.083767, 0.10597, 0.064993, 0.0075008]
Predicted label: 4
Correct prediction
Energy consumption = 144.934538 pJ
sum error= 76
Actual label: 0
Output voltages: [0.79879, 0.14223, 0.036542, 0.033367, 0.01192, 0.0092173, 0.67526, 0.11286, 0.2682, 0.082324]
Predicted label: 0
Correct prediction
Energy consumption = 158.972045 pJ
sum error= 76
Actual label: 9
Output voltages: [0.17717, 0.0051403, 0.016957, 0.79771, 0.040846, 0.01632, 0.004003, 0.014299, 0.032833, 0.75075]
Predicted label: 3
Wrong prediction!
Energy consumption = 158.325992 pJ
sum error= 77
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 156 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 156 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 156 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.059751, 0.011044, 0.073646, 0.23679, 0.0034218, 0.012145, 0.055053, 0.0017972, 0.79872, 0.052881]
Predicted label: 8
Correct prediction
Energy consumption = 154.824532 pJ
sum error= 77
Actual label: 4
Output voltages: [0.035075, 0.029235, 0.073213, 0.0092269, 0.79865, 0.0046678, 0.057527, 0.029607, 0.047792, 0.040161]
Predicted label: 4
Correct prediction
Energy consumption = 152.948008 pJ
sum error= 77
Actual label: 8
Output voltages: [0.73212, 0.0022448, 0.48229, 0.20672, 0.053268, 0.019556, 0.34564, 0.0013208, 0.79458, 0.063823]
Predicted label: 8
Correct prediction
Energy consumption = 160.829882 pJ
sum error= 77
Actual label: 7
Output voltages: [0.20671, 0.036741, 0.17209, 0.020081, 0.041615, 0.0031086, 0.0010964, 0.79864, 0.34795, 0.23835]
Predicted label: 7
Correct prediction
Energy consumption = 151.018776 pJ
sum error= 77
Actual label: 7
Output voltages: [0.18322, 0.060437, 0.014827, 0.034608, 0.0052584, 0.0032166, 0.0011493, 0.79867, 0.099239, 0.43329]
Predicted label: 7
Correct prediction
Energy consumption = 136.770049 pJ
sum error= 77
Actual label: 0
Output voltages: [0.79874, 0.051425, 0.037385, 0.0064527, 0.056567, 0.0088093, 0.77127, 0.0041096, 0.060518, 0.12]
Predicted label: 0
Correct prediction
Energy consumption = 154.029565 pJ
sum error= 77
Actual label: 7
Output voltages: [0.065174, 0.081237, 0.02554, 0.033251, 0.019355, 0.0089089, 0.0011293, 0.79436, 0.0099423, 0.77729]
Predicted label: 7
Correct prediction
Energy consumption = 157.477346 pJ
sum error= 77
Actual label: 8
Output voltages: [0.04108, 0.011041, 0.053843, 0.19724, 0.0089463, 0.13244, 0.02612, 0.016268, 0.7987, 0.033205]
Predicted label: 8
Correct prediction
Energy consumption = 152.333065 pJ
sum error= 77
Actual label: 8
Output voltages: [0.0095804, 0.0066686, 0.04734, 0.34712, 0.0030354, 0.1558, 0.037681, 0.01122, 0.79879, 0.077035]
Predicted label: 8
Correct prediction
Energy consumption = 147.104407 pJ
sum error= 77
Actual label: 6
Output voltages: [0.29949, 0.0014609, 0.48933, 0.0010688, 0.74788, 0.32247, 0.79865, 0.0012533, 0.1219, 0.020461]
Predicted label: 6
Correct prediction
Energy consumption = 143.095535 pJ
sum error= 77
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 157 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 157 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 157 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7866, 0.099484, 0.5358, 0.029477, 0.028615, 0.0010675, 0.59872, 0.025408, 0.22814, 0.014196]
Predicted label: 0
Correct prediction
Energy consumption = 154.175067 pJ
sum error= 77
Actual label: 4
Output voltages: [0.0034653, 0.028089, 0.38518, 0.016208, 0.79878, 0.023826, 0.081583, 0.021614, 0.032659, 0.54243]
Predicted label: 4
Correct prediction
Energy consumption = 155.997027 pJ
sum error= 77
Actual label: 8
Output voltages: [0.0072141, 0.10135, 0.17023, 0.17629, 0.012999, 0.014285, 0.0099041, 0.025051, 0.79875, 0.16427]
Predicted label: 8
Correct prediction
Energy consumption = 154.377711 pJ
sum error= 77
Actual label: 8
Output voltages: [0.099232, 0.021477, 0.56471, 0.074496, 0.026021, 0.002913, 0.17425, 0.0011451, 0.79879, 0.15591]
Predicted label: 8
Correct prediction
Energy consumption = 154.658919 pJ
sum error= 77
Actual label: 2
Output voltages: [0.52562, 0.047147, 0.79875, 0.02146, 0.042233, 0.0012177, 0.40321, 0.042141, 0.29229, 0.0184]
Predicted label: 2
Correct prediction
Energy consumption = 145.074641 pJ
sum error= 77
Actual label: 4
Output voltages: [0.014931, 0.017678, 0.22165, 0.013059, 0.79862, 0.0045354, 0.023514, 0.18879, 0.054206, 0.044073]
Predicted label: 4
Correct prediction
Energy consumption = 150.146856 pJ
sum error= 77
Actual label: 7
Output voltages: [0.69334, 0.3636, 0.12213, 0.4978, 0.003267, 0.0010876, 0.0094913, 0.79841, 0.033339, 0.13303]
Predicted label: 7
Correct prediction
Energy consumption = 158.648177 pJ
sum error= 77
Actual label: 6
Output voltages: [0.089578, 0.031832, 0.23544, 0.0035062, 0.19041, 0.35384, 0.79878, 0.0045558, 0.52549, 0.0019963]
Predicted label: 6
Correct prediction
Energy consumption = 148.104395 pJ
sum error= 77
Actual label: 6
Output voltages: [0.052249, 0.085315, 0.094823, 0.0074756, 0.1732, 0.50725, 0.79867, 0.0090418, 0.4874, 0.0063577]
Predicted label: 6
Correct prediction
Energy consumption = 135.363384 pJ
sum error= 77
Actual label: 6
Output voltages: [0.36307, 0.31143, 0.020335, 0.024894, 0.09669, 0.40698, 0.79879, 0.012994, 0.53388, 0.0036662]
Predicted label: 6
Correct prediction
Energy consumption = 146.144807 pJ
sum error= 77
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 158 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 158 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 158 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.024991, 0.007682, 0.052552, 0.04719, 0.79872, 0.0010846, 0.01242, 0.17805, 0.16855, 0.014708]
Predicted label: 4
Correct prediction
Energy consumption = 156.400627 pJ
sum error= 77
Actual label: 7
Output voltages: [0.14769, 0.0014046, 0.39465, 0.76131, 0.0064669, 0.0011294, 0.0011266, 0.73274, 0.53304, 0.59214]
Predicted label: 3
Wrong prediction!
Energy consumption = 143.258650 pJ
sum error= 78
Actual label: 1
Output voltages: [0.0094202, 0.79856, 0.0035717, 0.023219, 0.0080941, 0.0014867, 0.76092, 0.013911, 0.54232, 0.015833]
Predicted label: 1
Correct prediction
Energy consumption = 159.066091 pJ
sum error= 78
Actual label: 8
Output voltages: [0.026986, 0.028857, 0.050516, 0.16441, 0.012865, 0.015378, 0.034335, 0.030241, 0.79876, 0.4575]
Predicted label: 8
Correct prediction
Energy consumption = 152.431630 pJ
sum error= 78
Actual label: 8
Output voltages: [0.39496, 0.056379, 0.1945, 0.15661, 0.079732, 0.0020716, 0.030636, 0.001073, 0.79879, 0.11271]
Predicted label: 8
Correct prediction
Energy consumption = 152.375747 pJ
sum error= 78
Actual label: 2
Output voltages: [0.67647, 0.027418, 0.79875, 0.087113, 0.026836, 0.001164, 0.034961, 0.16526, 0.32055, 0.017626]
Predicted label: 2
Correct prediction
Energy consumption = 139.062424 pJ
sum error= 78
Actual label: 3
Output voltages: [0.50764, 0.059244, 0.058688, 0.79854, 0.09587, 0.0071614, 0.019323, 0.014957, 0.60101, 0.073772]
Predicted label: 3
Correct prediction
Energy consumption = 144.810801 pJ
sum error= 78
Actual label: 6
Output voltages: [0.15972, 0.0066666, 0.078071, 0.011928, 0.10974, 0.44789, 0.79849, 0.0010964, 0.58091, 0.27225]
Predicted label: 6
Correct prediction
Energy consumption = 147.078265 pJ
sum error= 78
Actual label: 3
Output voltages: [0.40562, 0.024614, 0.10251, 0.7986, 0.075089, 0.010889, 0.025063, 0.022787, 0.719, 0.045793]
Predicted label: 3
Correct prediction
Energy consumption = 146.366808 pJ
sum error= 78
Actual label: 0
Output voltages: [0.79779, 0.087118, 0.47617, 0.0036626, 0.0011158, 0.010954, 0.43713, 0.0016512, 0.30326, 0.021662]
Predicted label: 0
Correct prediction
Energy consumption = 152.693649 pJ
sum error= 78
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 159 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 159 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 159 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.041972, 0.10094, 0.042855, 0.048115, 0.0026855, 0.17932, 0.023832, 0.76982, 0.020362]
Predicted label: 0
Correct prediction
Energy consumption = 157.709251 pJ
sum error= 78
Actual label: 3
Output voltages: [0.15545, 0.021282, 0.10213, 0.79877, 0.001441, 0.0011341, 0.021261, 0.010406, 0.73423, 0.0076389]
Predicted label: 3
Correct prediction
Energy consumption = 149.953995 pJ
sum error= 78
Actual label: 7
Output voltages: [0.21309, 0.32457, 0.14961, 0.33013, 0.0032879, 0.001067, 0.0010945, 0.79867, 0.47365, 0.023683]
Predicted label: 7
Correct prediction
Energy consumption = 152.245347 pJ
sum error= 78
Actual label: 6
Output voltages: [0.36974, 0.057024, 0.063349, 0.0014014, 0.28875, 0.21394, 0.79879, 0.011445, 0.65494, 0.0013812]
Predicted label: 6
Correct prediction
Energy consumption = 152.864719 pJ
sum error= 78
Actual label: 9
Output voltages: [0.30994, 0.0098897, 0.066043, 0.22529, 0.73321, 0.012564, 0.0040984, 0.027883, 0.15973, 0.77321]
Predicted label: 9
Correct prediction
Energy consumption = 157.231705 pJ
sum error= 78
Actual label: 7
Output voltages: [0.3183, 0.1875, 0.77821, 0.46001, 0.0025993, 0.0011403, 0.006183, 0.79874, 0.14075, 0.075741]
Predicted label: 7
Correct prediction
Energy consumption = 154.442247 pJ
sum error= 78
Actual label: 9
Output voltages: [0.27279, 0.010178, 0.025715, 0.032755, 0.14673, 0.0043835, 0.03319, 0.033453, 0.29619, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 156.767290 pJ
sum error= 78
Actual label: 9
Output voltages: [0.11383, 0.033826, 0.021948, 0.032482, 0.01564, 0.0023119, 0.0010732, 0.029104, 0.77175, 0.79683]
Predicted label: 9
Correct prediction
Energy consumption = 150.196687 pJ
sum error= 78
Actual label: 5
Output voltages: [0.16572, 0.0015013, 0.0083698, 0.40499, 0.029725, 0.7982, 0.030922, 0.011538, 0.79352, 0.13202]
Predicted label: 5
Correct prediction
Energy consumption = 142.502850 pJ
sum error= 78
Actual label: 4
Output voltages: [0.007532, 0.023748, 0.21778, 0.0080627, 0.79876, 0.0024177, 0.066493, 0.022014, 0.14757, 0.25425]
Predicted label: 4
Correct prediction
Energy consumption = 154.458527 pJ
sum error= 78
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 160 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 160 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 160 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.21589, 0.0015736, 0.10898, 0.79876, 0.047727, 0.31277, 0.014506, 0.0064335, 0.48073, 0.031878]
Predicted label: 3
Correct prediction
Energy consumption = 144.718016 pJ
sum error= 78
Actual label: 3
Output voltages: [0.17353, 0.0010924, 0.51848, 0.79382, 0.0011904, 0.011649, 0.0023926, 0.087149, 0.79701, 0.0025403]
Predicted label: 8
Wrong prediction!
Energy consumption = 134.198206 pJ
sum error= 79
Actual label: 6
Output voltages: [0.018829, 0.036699, 0.042033, 0.0036078, 0.16156, 0.43072, 0.79876, 0.026024, 0.6475, 0.0018152]
Predicted label: 6
Correct prediction
Energy consumption = 151.692412 pJ
sum error= 79
Actual label: 1
Output voltages: [0.024872, 0.79847, 0.018052, 0.037674, 0.0028092, 0.0012224, 0.67585, 0.002283, 0.24922, 0.082279]
Predicted label: 1
Correct prediction
Energy consumption = 158.706358 pJ
sum error= 79
Actual label: 2
Output voltages: [0.50321, 0.049363, 0.79853, 0.088494, 0.015092, 0.0011973, 0.30151, 0.020615, 0.7273, 0.021055]
Predicted label: 2
Correct prediction
Energy consumption = 150.269365 pJ
sum error= 79
Actual label: 3
Output voltages: [0.10081, 0.018819, 0.15894, 0.79873, 0.040022, 0.0017312, 0.017763, 0.015497, 0.64877, 0.030642]
Predicted label: 3
Correct prediction
Energy consumption = 143.283745 pJ
sum error= 79
Actual label: 7
Output voltages: [0.025098, 0.023259, 0.05457, 0.035718, 0.022039, 0.0050745, 0.0010676, 0.79864, 0.24656, 0.27321]
Predicted label: 7
Correct prediction
Energy consumption = 153.156119 pJ
sum error= 79
Actual label: 3
Output voltages: [0.031069, 0.032564, 0.12145, 0.79867, 0.021414, 0.02135, 0.013866, 0.0020363, 0.39399, 0.153]
Predicted label: 3
Correct prediction
Energy consumption = 151.492499 pJ
sum error= 79
Actual label: 3
Output voltages: [0.40297, 0.0081139, 0.025688, 0.79863, 0.018768, 0.034202, 0.037559, 0.015831, 0.59462, 0.058074]
Predicted label: 3
Correct prediction
Energy consumption = 137.522074 pJ
sum error= 79
Actual label: 2
Output voltages: [0.28342, 0.0012672, 0.78362, 0.14677, 0.047721, 0.0010926, 0.39447, 0.013601, 0.65767, 0.005079]
Predicted label: 2
Correct prediction
Energy consumption = 140.051627 pJ
sum error= 79
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 161 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 161 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 161 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79856, 0.27885, 0.011384, 0.01027, 0.020935, 0.013638, 0.75086, 0.035785, 0.23997, 0.077631]
Predicted label: 0
Correct prediction
Energy consumption = 159.049954 pJ
sum error= 79
Actual label: 3
Output voltages: [0.75427, 0.029964, 0.012497, 0.79876, 0.0037904, 0.17354, 0.45416, 0.001542, 0.56689, 0.0053831]
Predicted label: 3
Correct prediction
Energy consumption = 149.665155 pJ
sum error= 79
Actual label: 3
Output voltages: [0.25153, 0.012258, 0.026511, 0.79879, 0.014309, 0.63402, 0.0064115, 0.042188, 0.55565, 0.010905]
Predicted label: 3
Correct prediction
Energy consumption = 137.510136 pJ
sum error= 79
Actual label: 8
Output voltages: [0.012781, 0.12356, 0.17399, 0.060086, 0.004286, 0.017328, 0.0071598, 0.021402, 0.79875, 0.5955]
Predicted label: 8
Correct prediction
Energy consumption = 147.937016 pJ
sum error= 79
Actual label: 4
Output voltages: [0.2187, 0.017446, 0.30869, 0.045739, 0.79878, 0.0011236, 0.56847, 0.0035189, 0.0033805, 0.50255]
Predicted label: 4
Correct prediction
Energy consumption = 152.666037 pJ
sum error= 79
Actual label: 3
Output voltages: [0.19227, 0.064213, 0.41584, 0.79878, 0.064658, 0.0013322, 0.0029287, 0.0088607, 0.26839, 0.0086753]
Predicted label: 3
Correct prediction
Energy consumption = 149.469519 pJ
sum error= 79
Actual label: 6
Output voltages: [0.35955, 0.033031, 0.4061, 0.004307, 0.46382, 0.091023, 0.79879, 0.0022917, 0.51765, 0.035659]
Predicted label: 6
Correct prediction
Energy consumption = 140.031454 pJ
sum error= 79
Actual label: 3
Output voltages: [0.25337, 0.0067973, 0.6868, 0.79825, 0.022106, 0.0033399, 0.0037815, 0.0017909, 0.64069, 0.040567]
Predicted label: 3
Correct prediction
Energy consumption = 143.655798 pJ
sum error= 79
Actual label: 5
Output voltages: [0.023009, 0.0058284, 0.0062318, 0.52284, 0.058088, 0.79875, 0.04383, 0.0072164, 0.7395, 0.0055251]
Predicted label: 5
Correct prediction
Energy consumption = 142.641022 pJ
sum error= 79
Actual label: 0
Output voltages: [0.79879, 0.13767, 0.033397, 0.053991, 0.040612, 0.0089353, 0.66593, 0.016001, 0.099142, 0.13449]
Predicted label: 0
Correct prediction
Energy consumption = 159.401587 pJ
sum error= 79
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 162 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 162 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 162 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.51167, 0.016172, 0.77751, 0.58688, 0.016412, 0.0011968, 0.052742, 0.015664, 0.78283, 0.018214]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.402867 pJ
sum error= 80
Actual label: 0
Output voltages: [0.75895, 0.029774, 0.035099, 0.0046732, 0.054517, 0.071104, 0.79676, 0.0020026, 0.15183, 0.016668]
Predicted label: 6
Wrong prediction!
Energy consumption = 153.096594 pJ
sum error= 81
Actual label: 9
Output voltages: [0.57614, 0.014073, 0.028298, 0.040181, 0.33168, 0.013669, 0.0087597, 0.015875, 0.18465, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 148.744464 pJ
sum error= 81
Actual label: 0
Output voltages: [0.79878, 0.26601, 0.10939, 0.014081, 0.0066652, 0.018599, 0.26034, 0.013648, 0.038609, 0.15174]
Predicted label: 0
Correct prediction
Energy consumption = 148.152098 pJ
sum error= 81
Actual label: 7
Output voltages: [0.068853, 0.52422, 0.026308, 0.0042221, 0.0021204, 0.0010836, 0.0010771, 0.79847, 0.3974, 0.65465]
Predicted label: 7
Correct prediction
Energy consumption = 151.167362 pJ
sum error= 81
Actual label: 4
Output voltages: [0.0051603, 0.010937, 0.29522, 0.025827, 0.79857, 0.011186, 0.28247, 0.093133, 0.031646, 0.053216]
Predicted label: 4
Correct prediction
Energy consumption = 150.039170 pJ
sum error= 81
Actual label: 6
Output voltages: [0.045867, 0.00274, 0.056545, 0.022177, 0.35616, 0.27277, 0.79791, 0.0010759, 0.77072, 0.037853]
Predicted label: 6
Correct prediction
Energy consumption = 147.453967 pJ
sum error= 81
Actual label: 9
Output voltages: [0.74229, 0.0040237, 0.50981, 0.0080767, 0.18707, 0.005809, 0.040696, 0.011645, 0.22847, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 147.179647 pJ
sum error= 81
Actual label: 3
Output voltages: [0.24601, 0.0035148, 0.043955, 0.79867, 0.013785, 0.12563, 0.027736, 0.012541, 0.4855, 0.058245]
Predicted label: 3
Correct prediction
Energy consumption = 151.467961 pJ
sum error= 81
Actual label: 5
Output voltages: [0.022201, 0.0012537, 0.0096366, 0.37044, 0.039904, 0.79846, 0.046428, 0.0032138, 0.77129, 0.050764]
Predicted label: 5
Correct prediction
Energy consumption = 142.365457 pJ
sum error= 81
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 163 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 163 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 163 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.011865, 0.79858, 0.14218, 0.038419, 0.0019434, 0.001075, 0.59745, 0.0033253, 0.14207, 0.0035526]
Predicted label: 1
Correct prediction
Energy consumption = 164.341465 pJ
sum error= 81
Actual label: 9
Output voltages: [0.27476, 0.019919, 0.025136, 0.02941, 0.056446, 0.02644, 0.0037481, 0.049583, 0.56508, 0.79706]
Predicted label: 9
Correct prediction
Energy consumption = 156.615915 pJ
sum error= 81
Actual label: 6
Output voltages: [0.15199, 0.035646, 0.31996, 0.0018315, 0.30045, 0.13719, 0.79878, 0.0023151, 0.25061, 0.0043431]
Predicted label: 6
Correct prediction
Energy consumption = 147.532927 pJ
sum error= 81
Actual label: 1
Output voltages: [0.011495, 0.79864, 0.052957, 0.0090589, 0.017356, 0.014975, 0.37466, 0.0034263, 0.7376, 0.019997]
Predicted label: 1
Correct prediction
Energy consumption = 160.991063 pJ
sum error= 81
Actual label: 4
Output voltages: [0.0010819, 0.27821, 0.028305, 0.001665, 0.79219, 0.0024662, 0.0063202, 0.066366, 0.58418, 0.057058]
Predicted label: 4
Correct prediction
Energy consumption = 150.251516 pJ
sum error= 81
Actual label: 5
Output voltages: [0.065452, 0.0032958, 0.0010823, 0.59335, 0.031693, 0.79877, 0.33967, 0.0012856, 0.51007, 0.0041456]
Predicted label: 5
Correct prediction
Energy consumption = 151.448955 pJ
sum error= 81
Actual label: 4
Output voltages: [0.0062296, 0.019961, 0.3651, 0.019073, 0.79874, 0.0040367, 0.040403, 0.30047, 0.046547, 0.0040407]
Predicted label: 4
Correct prediction
Energy consumption = 139.848282 pJ
sum error= 81
Actual label: 5
Output voltages: [0.034275, 0.0017031, 0.0010763, 0.74336, 0.049896, 0.78686, 0.4383, 0.0013741, 0.39666, 0.071833]
Predicted label: 5
Correct prediction
Energy consumption = 151.072527 pJ
sum error= 81
Actual label: 0
Output voltages: [0.79629, 0.025691, 0.19535, 0.011509, 0.0059592, 0.0011563, 0.33867, 0.023859, 0.22638, 0.051514]
Predicted label: 0
Correct prediction
Energy consumption = 163.530023 pJ
sum error= 81
Actual label: 5
Output voltages: [0.02784, 0.0030905, 0.0052369, 0.55716, 0.027025, 0.79877, 0.14005, 0.033234, 0.6976, 0.082619]
Predicted label: 5
Correct prediction
Energy consumption = 149.413520 pJ
sum error= 81
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 164 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 164 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 164 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.40792, 0.0010686, 0.044284, 0.01243, 0.38768, 0.038017, 0.0013905, 0.46257, 0.31223, 0.79802]
Predicted label: 9
Correct prediction
Energy consumption = 151.843761 pJ
sum error= 81
Actual label: 5
Output voltages: [0.036243, 0.0010661, 0.011349, 0.012517, 0.030928, 0.77242, 0.56612, 0.033795, 0.71479, 0.029879]
Predicted label: 5
Correct prediction
Energy consumption = 142.880008 pJ
sum error= 81
Actual label: 2
Output voltages: [0.11299, 0.092954, 0.79869, 0.055025, 0.023934, 0.0011365, 0.23516, 0.055707, 0.48501, 0.023982]
Predicted label: 2
Correct prediction
Energy consumption = 150.263880 pJ
sum error= 81
Actual label: 1
Output voltages: [0.050156, 0.79861, 0.3778, 0.04272, 0.021748, 0.0010716, 0.43629, 0.0011017, 0.16287, 0.015564]
Predicted label: 1
Correct prediction
Energy consumption = 159.255216 pJ
sum error= 81
Actual label: 2
Output voltages: [0.42699, 0.05051, 0.79878, 0.16656, 0.021145, 0.0012543, 0.48203, 0.028871, 0.58081, 0.039468]
Predicted label: 2
Correct prediction
Energy consumption = 144.699591 pJ
sum error= 81
Actual label: 9
Output voltages: [0.60577, 0.0050454, 0.043586, 0.034613, 0.2459, 0.021253, 0.016841, 0.28683, 0.032263, 0.79816]
Predicted label: 9
Correct prediction
Energy consumption = 154.182834 pJ
sum error= 81
Actual label: 1
Output voltages: [0.045127, 0.79875, 0.056389, 0.0030246, 0.77067, 0.0045532, 0.46092, 0.0010881, 0.044901, 0.28478]
Predicted label: 1
Correct prediction
Energy consumption = 156.608718 pJ
sum error= 81
Actual label: 9
Output voltages: [0.4142, 0.0064415, 0.01633, 0.021416, 0.42741, 0.019098, 0.0039661, 0.0014861, 0.39764, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 152.014687 pJ
sum error= 81
Actual label: 9
Output voltages: [0.23627, 0.0031821, 0.0242, 0.034056, 0.040704, 0.0045477, 0.0011168, 0.11182, 0.60994, 0.79841]
Predicted label: 9
Correct prediction
Energy consumption = 141.630006 pJ
sum error= 81
Actual label: 4
Output voltages: [0.0043832, 0.0046641, 0.27967, 0.011975, 0.79872, 0.0090004, 0.11589, 0.1367, 0.24548, 0.011511]
Predicted label: 4
Correct prediction
Energy consumption = 153.418469 pJ
sum error= 81
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 165 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 165 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 165 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79836, 0.14826, 0.20462, 0.010801, 0.0018146, 0.0033934, 0.67378, 0.012261, 0.33895, 0.066499]
Predicted label: 0
Correct prediction
Energy consumption = 156.710866 pJ
sum error= 81
Actual label: 8
Output voltages: [0.023517, 0.028685, 0.14742, 0.022651, 0.03712, 0.01796, 0.038434, 0.0053645, 0.79874, 0.2555]
Predicted label: 8
Correct prediction
Energy consumption = 149.551996 pJ
sum error= 81
Actual label: 4
Output voltages: [0.0037104, 0.0026382, 0.20206, 0.022429, 0.7986, 0.012181, 0.11702, 0.019107, 0.030835, 0.14506]
Predicted label: 4
Correct prediction
Energy consumption = 152.485004 pJ
sum error= 81
Actual label: 5
Output voltages: [0.022615, 0.0013808, 0.0011141, 0.2728, 0.060235, 0.79821, 0.13168, 0.021312, 0.72453, 0.35079]
Predicted label: 5
Correct prediction
Energy consumption = 145.945045 pJ
sum error= 81
Actual label: 2
Output voltages: [0.1072, 0.041486, 0.79873, 0.43022, 0.021338, 0.0011509, 0.017095, 0.37601, 0.30529, 0.037729]
Predicted label: 2
Correct prediction
Energy consumption = 154.234586 pJ
sum error= 81
Actual label: 9
Output voltages: [0.44189, 0.0081526, 0.020287, 0.014506, 0.33025, 0.016663, 0.004244, 0.008445, 0.50884, 0.79776]
Predicted label: 9
Correct prediction
Energy consumption = 149.975133 pJ
sum error= 81
Actual label: 2
Output voltages: [0.12454, 0.039133, 0.79873, 0.1643, 0.02156, 0.0012163, 0.39298, 0.015328, 0.59656, 0.035666]
Predicted label: 2
Correct prediction
Energy consumption = 150.205589 pJ
sum error= 81
Actual label: 1
Output voltages: [0.0020137, 0.79863, 0.23645, 0.12197, 0.18619, 0.0011244, 0.66546, 0.0028219, 0.036082, 0.055643]
Predicted label: 1
Correct prediction
Energy consumption = 161.046685 pJ
sum error= 81
Actual label: 2
Output voltages: [0.34031, 0.57643, 0.79871, 0.059422, 0.015705, 0.0012435, 0.14482, 0.0076344, 0.037988, 0.03599]
Predicted label: 2
Correct prediction
Energy consumption = 149.126252 pJ
sum error= 81
Actual label: 1
Output voltages: [0.015277, 0.79848, 0.0049814, 0.06475, 0.29385, 0.018859, 0.39317, 0.0054297, 0.14089, 0.255]
Predicted label: 1
Correct prediction
Energy consumption = 160.374944 pJ
sum error= 81
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 166 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 166 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 166 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.036082, 0.17111, 0.48999, 0.23069, 0.0016747, 0.0011002, 0.0010719, 0.79856, 0.24642, 0.38161]
Predicted label: 7
Correct prediction
Energy consumption = 156.353744 pJ
sum error= 81
Actual label: 3
Output voltages: [0.28896, 0.020342, 0.087691, 0.79871, 0.045508, 0.0084615, 0.016052, 0.0072103, 0.62676, 0.23665]
Predicted label: 3
Correct prediction
Energy consumption = 141.504360 pJ
sum error= 81
Actual label: 6
Output voltages: [0.050474, 0.021911, 0.095046, 0.0045804, 0.32863, 0.34718, 0.79876, 0.0013678, 0.67648, 0.0044446]
Predicted label: 6
Correct prediction
Energy consumption = 145.058955 pJ
sum error= 81
Actual label: 8
Output voltages: [0.017792, 0.018307, 0.05136, 0.047898, 0.020874, 0.11116, 0.01148, 0.044727, 0.79868, 0.026733]
Predicted label: 8
Correct prediction
Energy consumption = 155.791962 pJ
sum error= 81
Actual label: 8
Output voltages: [0.083637, 0.043763, 0.2584, 0.18223, 0.015763, 0.0096791, 0.16735, 0.0095765, 0.79879, 0.32446]
Predicted label: 8
Correct prediction
Energy consumption = 149.771408 pJ
sum error= 81
Actual label: 4
Output voltages: [0.019268, 0.025758, 0.16114, 0.0025665, 0.79866, 0.036942, 0.2833, 0.059247, 0.066108, 0.035561]
Predicted label: 4
Correct prediction
Energy consumption = 157.801654 pJ
sum error= 81
Actual label: 9
Output voltages: [0.2141, 0.028392, 0.043489, 0.16755, 0.25188, 0.030813, 0.0292, 0.0063377, 0.14204, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 150.062303 pJ
sum error= 81
Actual label: 1
Output voltages: [0.022791, 0.79868, 0.4105, 0.14173, 0.17477, 0.0012567, 0.56444, 0.0026979, 0.038759, 0.032542]
Predicted label: 1
Correct prediction
Energy consumption = 163.001042 pJ
sum error= 81
Actual label: 9
Output voltages: [0.039622, 0.022006, 0.023922, 0.44854, 0.0084132, 0.0039293, 0.0018367, 0.23101, 0.40643, 0.79805]
Predicted label: 9
Correct prediction
Energy consumption = 158.274290 pJ
sum error= 81
Actual label: 8
Output voltages: [0.035373, 0.0088222, 0.041441, 0.18998, 0.0070539, 0.031465, 0.016065, 0.012765, 0.79874, 0.21903]
Predicted label: 8
Correct prediction
Energy consumption = 142.102163 pJ
sum error= 81
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 167 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 167 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 167 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.27292, 0.0011347, 0.0026513, 0.14048, 0.027435, 0.79624, 0.051344, 0.0075569, 0.78105, 0.15419]
Predicted label: 5
Correct prediction
Energy consumption = 147.703632 pJ
sum error= 81
Actual label: 7
Output voltages: [0.0032985, 0.004706, 0.048303, 0.77377, 0.010417, 0.053973, 0.0011819, 0.76702, 0.6098, 0.75714]
Predicted label: 3
Wrong prediction!
Energy consumption = 145.632363 pJ
sum error= 82
Actual label: 5
Output voltages: [0.017216, 0.001228, 0.0046288, 0.28426, 0.039191, 0.79879, 0.26195, 0.0095701, 0.70908, 0.041582]
Predicted label: 5
Correct prediction
Energy consumption = 141.913535 pJ
sum error= 82
Actual label: 1
Output voltages: [0.037316, 0.79857, 0.019009, 0.1781, 0.033797, 0.0012178, 0.084105, 0.063079, 0.09862, 0.48208]
Predicted label: 1
Correct prediction
Energy consumption = 167.339875 pJ
sum error= 82
Actual label: 1
Output voltages: [0.10346, 0.79837, 0.043206, 0.27483, 0.010991, 0.0021708, 0.57961, 0.0021545, 0.11159, 0.33577]
Predicted label: 1
Correct prediction
Energy consumption = 150.869232 pJ
sum error= 82
Actual label: 8
Output voltages: [0.050289, 0.035592, 0.061557, 0.1716, 0.0019648, 0.046525, 0.026488, 0.0014046, 0.79874, 0.16343]
Predicted label: 8
Correct prediction
Energy consumption = 153.035786 pJ
sum error= 82
Actual label: 6
Output voltages: [0.10058, 0.0011844, 0.0011091, 0.20682, 0.20275, 0.79523, 0.78923, 0.001654, 0.77376, 0.026179]
Predicted label: 5
Wrong prediction!
Energy consumption = 149.704444 pJ
sum error= 83
Actual label: 5
Output voltages: [0.060469, 0.0015726, 0.0011023, 0.041334, 0.031222, 0.79853, 0.046469, 0.0017312, 0.76338, 0.021526]
Predicted label: 5
Correct prediction
Energy consumption = 139.169890 pJ
sum error= 83
Actual label: 2
Output voltages: [0.79854, 0.55973, 0.42305, 0.0010753, 0.30777, 0.0010807, 0.05273, 0.10173, 0.036792, 0.40248]
Predicted label: 0
Wrong prediction!
Energy consumption = 159.585666 pJ
sum error= 84
Actual label: 4
Output voltages: [0.0057489, 0.048693, 0.045605, 0.0029521, 0.7987, 0.0019924, 0.11302, 0.082764, 0.040027, 0.24605]
Predicted label: 4
Correct prediction
Energy consumption = 156.829044 pJ
sum error= 84
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 168 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 168 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 168 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0065795, 0.0049812, 0.089286, 0.24064, 0.79879, 0.0011213, 0.0023754, 0.0030362, 0.28382, 0.045093]
Predicted label: 4
Correct prediction
Energy consumption = 149.568832 pJ
sum error= 84
Actual label: 3
Output voltages: [0.17671, 0.020006, 0.46624, 0.73679, 0.0010807, 0.0010877, 0.0010929, 0.79804, 0.74164, 0.34946]
Predicted label: 7
Wrong prediction!
Energy consumption = 142.184158 pJ
sum error= 85
Actual label: 2
Output voltages: [0.76958, 0.055123, 0.79865, 0.45275, 0.016449, 0.001092, 0.28464, 0.084919, 0.27522, 0.15395]
Predicted label: 2
Correct prediction
Energy consumption = 142.491203 pJ
sum error= 85
Actual label: 3
Output voltages: [0.23505, 0.020757, 0.020269, 0.79869, 0.01223, 0.0049024, 0.0062821, 0.0074255, 0.53765, 0.04207]
Predicted label: 3
Correct prediction
Energy consumption = 143.669485 pJ
sum error= 85
Actual label: 5
Output voltages: [0.42014, 0.048907, 0.0016631, 0.56964, 0.0014956, 0.79875, 0.01739, 0.0012313, 0.48206, 0.019648]
Predicted label: 5
Correct prediction
Energy consumption = 153.107946 pJ
sum error= 85
Actual label: 6
Output voltages: [0.035891, 0.051338, 0.11205, 0.010784, 0.094441, 0.44959, 0.79875, 0.0069891, 0.63883, 0.002512]
Predicted label: 6
Correct prediction
Energy consumption = 144.274490 pJ
sum error= 85
Actual label: 8
Output voltages: [0.034451, 0.020689, 0.070192, 0.083995, 0.0083961, 0.1052, 0.7442, 0.018638, 0.78908, 0.0024165]
Predicted label: 8
Correct prediction
Energy consumption = 154.672460 pJ
sum error= 85
Actual label: 8
Output voltages: [0.04477, 0.3599, 0.026983, 0.039546, 0.034245, 0.0020195, 0.041265, 0.0013004, 0.79879, 0.69474]
Predicted label: 8
Correct prediction
Energy consumption = 153.547375 pJ
sum error= 85
Actual label: 6
Output voltages: [0.045168, 0.019826, 0.041911, 0.010071, 0.095384, 0.4302, 0.79875, 0.015431, 0.76116, 0.0051387]
Predicted label: 6
Correct prediction
Energy consumption = 151.510028 pJ
sum error= 85
Actual label: 2
Output voltages: [0.29775, 0.023223, 0.79877, 0.43829, 0.015342, 0.0011652, 0.1894, 0.21112, 0.44961, 0.013309]
Predicted label: 2
Correct prediction
Energy consumption = 148.493881 pJ
sum error= 85
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 169 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 169 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 169 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.11531, 0.0094564, 0.09011, 0.79873, 0.030969, 0.027888, 0.012207, 0.010143, 0.24155, 0.23011]
Predicted label: 3
Correct prediction
Energy consumption = 147.247669 pJ
sum error= 85
Actual label: 1
Output voltages: [0.021304, 0.7987, 0.21038, 0.016524, 0.0010753, 0.0011847, 0.12903, 0.30783, 0.7188, 0.0048054]
Predicted label: 1
Correct prediction
Energy consumption = 155.673865 pJ
sum error= 85
Actual label: 0
Output voltages: [0.79879, 0.052589, 0.46464, 0.0055753, 0.0013486, 0.002851, 0.13557, 0.02658, 0.052709, 0.043234]
Predicted label: 0
Correct prediction
Energy consumption = 158.495700 pJ
sum error= 85
Actual label: 5
Output voltages: [0.014995, 0.0029751, 0.0010661, 0.73009, 0.031502, 0.79874, 0.10317, 0.029212, 0.63486, 0.10602]
Predicted label: 5
Correct prediction
Energy consumption = 147.508586 pJ
sum error= 85
Actual label: 8
Output voltages: [0.37613, 0.15288, 0.50291, 0.77278, 0.0012437, 0.0013941, 0.023378, 0.06864, 0.79675, 0.094855]
Predicted label: 8
Correct prediction
Energy consumption = 156.927524 pJ
sum error= 85
Actual label: 9
Output voltages: [0.064014, 0.014705, 0.031271, 0.029446, 0.0053373, 0.0034167, 0.0015713, 0.046123, 0.79753, 0.78001]
Predicted label: 8
Wrong prediction!
Energy consumption = 142.453573 pJ
sum error= 86
Actual label: 2
Output voltages: [0.71411, 0.37782, 0.79842, 0.10728, 0.0015369, 0.0012646, 0.27476, 0.057529, 0.049996, 0.1785]
Predicted label: 2
Correct prediction
Energy consumption = 144.555317 pJ
sum error= 86
Actual label: 9
Output voltages: [0.26679, 0.014129, 0.01109, 0.38539, 0.60231, 0.0023151, 0.0036916, 0.0077444, 0.18745, 0.79819]
Predicted label: 9
Correct prediction
Energy consumption = 147.720345 pJ
sum error= 86
Actual label: 6
Output voltages: [0.051817, 0.025544, 0.49579, 0.00146, 0.043093, 0.22801, 0.79876, 0.0067197, 0.6257, 0.007639]
Predicted label: 6
Correct prediction
Energy consumption = 145.894886 pJ
sum error= 86
Actual label: 7
Output voltages: [0.28618, 0.018745, 0.024479, 0.28449, 0.021736, 0.0036472, 0.0010731, 0.7986, 0.14798, 0.37388]
Predicted label: 7
Correct prediction
Energy consumption = 161.699553 pJ
sum error= 86
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 170 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 170 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 170 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.19183, 0.029198, 0.02861, 0.0025617, 0.037784, 0.42755, 0.016978, 0.12661, 0.041577]
Predicted label: 0
Correct prediction
Energy consumption = 153.698519 pJ
sum error= 86
Actual label: 4
Output voltages: [0.043024, 0.0095384, 0.0049255, 0.0028618, 0.73981, 0.01743, 0.0065301, 0.051638, 0.35997, 0.78438]
Predicted label: 9
Wrong prediction!
Energy consumption = 159.676817 pJ
sum error= 87
Actual label: 8
Output voltages: [0.15917, 0.018436, 0.074237, 0.057101, 0.0017422, 0.76368, 0.022167, 0.003194, 0.79879, 0.01366]
Predicted label: 8
Correct prediction
Energy consumption = 149.373553 pJ
sum error= 87
Actual label: 7
Output voltages: [0.46196, 0.048469, 0.3174, 0.50753, 0.0010698, 0.0010784, 0.0010674, 0.79721, 0.31141, 0.39485]
Predicted label: 7
Correct prediction
Energy consumption = 147.537255 pJ
sum error= 87
Actual label: 1
Output voltages: [0.001832, 0.79864, 0.015969, 0.032913, 0.024279, 0.0050384, 0.36282, 0.0021051, 0.47786, 0.1654]
Predicted label: 1
Correct prediction
Energy consumption = 161.110159 pJ
sum error= 87
Actual label: 7
Output voltages: [0.10924, 0.61223, 0.079515, 0.28509, 0.011475, 0.0010813, 0.0010667, 0.79867, 0.037237, 0.048053]
Predicted label: 7
Correct prediction
Energy consumption = 149.713941 pJ
sum error= 87
Actual label: 4
Output voltages: [0.0092135, 0.029848, 0.15895, 0.0027452, 0.79867, 0.0044157, 0.0095955, 0.14659, 0.11979, 0.45598]
Predicted label: 4
Correct prediction
Energy consumption = 151.830784 pJ
sum error= 87
Actual label: 1
Output voltages: [0.039818, 0.79859, 0.053007, 0.23094, 0.30022, 0.0052461, 0.045822, 0.0018639, 0.027823, 0.18377]
Predicted label: 1
Correct prediction
Energy consumption = 162.851307 pJ
sum error= 87
Actual label: 0
Output voltages: [0.79866, 0.13843, 0.028071, 0.0096155, 0.012911, 0.021718, 0.75025, 0.011496, 0.27095, 0.15212]
Predicted label: 0
Correct prediction
Energy consumption = 148.190626 pJ
sum error= 87
Actual label: 9
Output voltages: [0.0010717, 0.053129, 0.045133, 0.77678, 0.19287, 0.0014577, 0.0089079, 0.0036135, 0.50799, 0.61869]
Predicted label: 3
Wrong prediction!
Energy consumption = 152.433778 pJ
sum error= 88
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 171 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 171 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 171 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.11175, 0.0168, 0.013102, 0.011668, 0.015948, 0.010019, 0.0010717, 0.79871, 0.27524, 0.37963]
Predicted label: 7
Correct prediction
Energy consumption = 154.357921 pJ
sum error= 88
Actual label: 2
Output voltages: [0.44953, 0.041283, 0.79879, 0.036208, 0.01578, 0.0012657, 0.44869, 0.010168, 0.65004, 0.021675]
Predicted label: 2
Correct prediction
Energy consumption = 144.980458 pJ
sum error= 88
Actual label: 0
Output voltages: [0.79355, 0.13049, 0.28134, 0.0066686, 0.0012132, 0.0013154, 0.050767, 0.0046095, 0.43645, 0.045793]
Predicted label: 0
Correct prediction
Energy consumption = 152.087247 pJ
sum error= 88
Actual label: 0
Output voltages: [0.79868, 0.29716, 0.02724, 0.036306, 0.017029, 0.1123, 0.51479, 0.021955, 0.21885, 0.061332]
Predicted label: 0
Correct prediction
Energy consumption = 145.764701 pJ
sum error= 88
Actual label: 9
Output voltages: [0.55122, 0.0059012, 0.026538, 0.010241, 0.29586, 0.0072761, 0.0016454, 0.033902, 0.49824, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 152.191166 pJ
sum error= 88
Actual label: 1
Output voltages: [0.18573, 0.79862, 0.32698, 0.038898, 0.0071318, 0.0017073, 0.18822, 0.0012982, 0.058769, 0.096525]
Predicted label: 1
Correct prediction
Energy consumption = 166.413971 pJ
sum error= 88
Actual label: 7
Output voltages: [0.037545, 0.26851, 0.30101, 0.036907, 0.0029146, 0.0010682, 0.0011174, 0.79878, 0.42594, 0.16768]
Predicted label: 7
Correct prediction
Energy consumption = 150.987072 pJ
sum error= 88
Actual label: 8
Output voltages: [0.50595, 0.013818, 0.1358, 0.07065, 0.036598, 0.019837, 0.46096, 0.0021176, 0.79661, 0.20044]
Predicted label: 8
Correct prediction
Energy consumption = 150.883449 pJ
sum error= 88
Actual label: 7
Output voltages: [0.14093, 0.0015268, 0.43102, 0.61995, 0.6632, 0.0010868, 0.0011654, 0.58668, 0.24313, 0.04547]
Predicted label: 4
Wrong prediction!
Energy consumption = 145.220590 pJ
sum error= 89
Actual label: 8
Output voltages: [0.018759, 0.030083, 0.057398, 0.051269, 0.015369, 0.012032, 0.020497, 0.022587, 0.79868, 0.19017]
Predicted label: 8
Correct prediction
Energy consumption = 146.767163 pJ
sum error= 89
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 172 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 172 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 172 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0041319, 0.0070662, 0.042599, 0.0021832, 0.79862, 0.010488, 0.33743, 0.1698, 0.22523, 0.0047403]
Predicted label: 4
Correct prediction
Energy consumption = 150.156520 pJ
sum error= 89
Actual label: 7
Output voltages: [0.045487, 0.038383, 0.055102, 0.090492, 0.3876, 0.0012099, 0.0010759, 0.59931, 0.7439, 0.76827]
Predicted label: 9
Wrong prediction!
Energy consumption = 159.863988 pJ
sum error= 90
Actual label: 2
Output voltages: [0.0067279, 0.0085827, 0.79872, 0.6465, 0.0034837, 0.001096, 0.22943, 0.49644, 0.51224, 0.018607]
Predicted label: 2
Correct prediction
Energy consumption = 139.439906 pJ
sum error= 90
Actual label: 0
Output voltages: [0.79873, 0.022251, 0.035245, 0.0081005, 0.028327, 0.0084093, 0.75441, 0.02068, 0.1572, 0.050868]
Predicted label: 0
Correct prediction
Energy consumption = 158.053650 pJ
sum error= 90
Actual label: 4
Output voltages: [0.0013119, 0.0013066, 0.58029, 0.021897, 0.79878, 0.0010713, 0.21898, 0.29065, 0.048577, 0.014911]
Predicted label: 4
Correct prediction
Energy consumption = 154.175294 pJ
sum error= 90
Actual label: 6
Output voltages: [0.067813, 0.050557, 0.023035, 0.0058516, 0.037217, 0.31232, 0.79861, 0.050124, 0.78479, 0.0042125]
Predicted label: 6
Correct prediction
Energy consumption = 150.414898 pJ
sum error= 90
Actual label: 0
Output voltages: [0.79878, 0.046472, 0.010889, 0.0058024, 0.021467, 0.0098967, 0.59076, 0.013804, 0.12998, 0.027503]
Predicted label: 0
Correct prediction
Energy consumption = 142.322475 pJ
sum error= 90
Actual label: 3
Output voltages: [0.038116, 0.32509, 0.027102, 0.79873, 0.0010936, 0.010085, 0.0030035, 0.10532, 0.74389, 0.032533]
Predicted label: 3
Correct prediction
Energy consumption = 146.925136 pJ
sum error= 90
Actual label: 1
Output voltages: [0.02188, 0.79836, 0.052998, 0.20642, 0.0070238, 0.010162, 0.75656, 0.01462, 0.12803, 0.15326]
Predicted label: 1
Correct prediction
Energy consumption = 162.008777 pJ
sum error= 90
Actual label: 1
Output voltages: [0.0030801, 0.79879, 0.31161, 0.24331, 0.020037, 0.0011372, 0.37379, 0.001477, 0.21227, 0.20385]
Predicted label: 1
Correct prediction
Energy consumption = 155.445288 pJ
sum error= 90
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 173 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 173 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 173 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34014, 0.077088, 0.024428, 0.79633, 0.0011662, 0.33914, 0.25536, 0.0016532, 0.7513, 0.0152]
Predicted label: 3
Correct prediction
Energy consumption = 162.094587 pJ
sum error= 90
Actual label: 3
Output voltages: [0.035796, 0.0011709, 0.50401, 0.79813, 0.0095599, 0.057354, 0.0030483, 0.0078275, 0.77071, 0.045696]
Predicted label: 3
Correct prediction
Energy consumption = 140.710510 pJ
sum error= 90
Actual label: 9
Output voltages: [0.53329, 0.023823, 0.040685, 0.061084, 0.13008, 0.051103, 0.0026478, 0.0060787, 0.3077, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 153.838066 pJ
sum error= 90
Actual label: 6
Output voltages: [0.32188, 0.35092, 0.077679, 0.001823, 0.24376, 0.25274, 0.79871, 0.0012389, 0.04514, 0.045947]
Predicted label: 6
Correct prediction
Energy consumption = 143.583863 pJ
sum error= 90
Actual label: 7
Output voltages: [0.75432, 0.02826, 0.0065777, 0.0026001, 0.040599, 0.027497, 0.016691, 0.79878, 0.33375, 0.18453]
Predicted label: 7
Correct prediction
Energy consumption = 151.610878 pJ
sum error= 90
Actual label: 4
Output voltages: [0.026945, 0.049974, 0.035815, 0.032496, 0.79868, 0.0014987, 0.1814, 0.22898, 0.026989, 0.25438]
Predicted label: 4
Correct prediction
Energy consumption = 152.516626 pJ
sum error= 90
Actual label: 1
Output voltages: [0.034147, 0.7984, 0.21183, 0.077704, 0.027409, 0.0080458, 0.58327, 0.0012665, 0.067441, 0.35446]
Predicted label: 1
Correct prediction
Energy consumption = 163.217825 pJ
sum error= 90
Actual label: 5
Output voltages: [0.020119, 0.03499, 0.40282, 0.056561, 0.0013205, 0.32089, 0.71883, 0.0017778, 0.73001, 0.0016171]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.824040 pJ
sum error= 91
Actual label: 3
Output voltages: [0.5046, 0.032012, 0.028289, 0.79858, 0.024566, 0.0080363, 0.022488, 0.011779, 0.50992, 0.04877]
Predicted label: 3
Correct prediction
Energy consumption = 145.885555 pJ
sum error= 91
Actual label: 0
Output voltages: [0.79878, 0.092845, 0.091755, 0.095203, 0.037253, 0.0048171, 0.57648, 0.014034, 0.25245, 0.032567]
Predicted label: 0
Correct prediction
Energy consumption = 157.996410 pJ
sum error= 91
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 174 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 174 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 174 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.031903, 0.0013276, 0.023994, 0.03421, 0.026403, 0.48358, 0.39627, 0.012016, 0.79853, 0.0016629]
Predicted label: 8
Correct prediction
Energy consumption = 154.007131 pJ
sum error= 91
Actual label: 7
Output voltages: [0.3635, 0.76711, 0.031713, 0.59188, 0.0012322, 0.0013991, 0.0015528, 0.79194, 0.66475, 0.03065]
Predicted label: 7
Correct prediction
Energy consumption = 157.954194 pJ
sum error= 91
Actual label: 3
Output voltages: [0.70432, 0.021207, 0.042336, 0.7986, 0.027389, 0.0051979, 0.017634, 0.015459, 0.46413, 0.029392]
Predicted label: 3
Correct prediction
Energy consumption = 146.518137 pJ
sum error= 91
Actual label: 9
Output voltages: [0.16034, 0.032748, 0.097651, 0.3087, 0.028378, 0.029416, 0.043724, 0.086803, 0.13283, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 153.907788 pJ
sum error= 91
Actual label: 6
Output voltages: [0.017562, 0.19519, 0.1974, 0.010127, 0.12176, 0.37223, 0.79866, 0.0048954, 0.75853, 0.0069285]
Predicted label: 6
Correct prediction
Energy consumption = 146.570564 pJ
sum error= 91
Actual label: 9
Output voltages: [0.53004, 0.017001, 0.021184, 0.026351, 0.24852, 0.020061, 0.003164, 0.018318, 0.41988, 0.79866]
Predicted label: 9
Correct prediction
Energy consumption = 150.543833 pJ
sum error= 91
Actual label: 3
Output voltages: [0.43837, 0.074547, 0.022362, 0.79871, 0.014044, 0.01625, 0.058054, 0.12355, 0.36433, 0.0067446]
Predicted label: 3
Correct prediction
Energy consumption = 144.657609 pJ
sum error= 91
Actual label: 5
Output voltages: [0.35284, 0.015003, 0.0010844, 0.39795, 0.018458, 0.7976, 0.10181, 0.0039302, 0.75254, 0.0041761]
Predicted label: 5
Correct prediction
Energy consumption = 144.138335 pJ
sum error= 91
Actual label: 0
Output voltages: [0.79751, 0.021106, 0.030706, 0.0045038, 0.023184, 0.0038399, 0.6902, 0.083827, 0.04474, 0.040045]
Predicted label: 0
Correct prediction
Energy consumption = 140.156763 pJ
sum error= 91
Actual label: 2
Output voltages: [0.54008, 0.18701, 0.79873, 0.070919, 0.0014529, 0.0012344, 0.051253, 0.36014, 0.47203, 0.23928]
Predicted label: 2
Correct prediction
Energy consumption = 144.751589 pJ
sum error= 91
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 175 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 175 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 175 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.10583, 0.030698, 0.36823, 0.42863, 0.075426, 0.0012319, 0.0010754, 0.79857, 0.54591, 0.037329]
Predicted label: 7
Correct prediction
Energy consumption = 154.583437 pJ
sum error= 91
Actual label: 4
Output voltages: [0.032095, 0.027322, 0.13316, 0.57961, 0.79878, 0.001067, 0.038579, 0.029578, 0.0020481, 0.049276]
Predicted label: 4
Correct prediction
Energy consumption = 149.246348 pJ
sum error= 91
Actual label: 5
Output voltages: [0.029346, 0.0011115, 0.019141, 0.54441, 0.0084754, 0.79869, 0.052478, 0.10796, 0.73511, 0.1133]
Predicted label: 5
Correct prediction
Energy consumption = 150.486823 pJ
sum error= 91
Actual label: 1
Output voltages: [0.033898, 0.79862, 0.038991, 0.3481, 0.041364, 0.014605, 0.1005, 0.0082683, 0.039, 0.20941]
Predicted label: 1
Correct prediction
Energy consumption = 163.988818 pJ
sum error= 91
Actual label: 7
Output voltages: [0.051315, 0.23902, 0.79236, 0.6903, 0.026896, 0.0013167, 0.019122, 0.46239, 0.32627, 0.0013058]
Predicted label: 2
Wrong prediction!
Energy consumption = 154.333674 pJ
sum error= 92
Actual label: 5
Output voltages: [0.044757, 0.0014159, 0.069472, 0.10915, 0.0024055, 0.78506, 0.18308, 0.13512, 0.75062, 0.057771]
Predicted label: 5
Correct prediction
Energy consumption = 147.167831 pJ
sum error= 92
Actual label: 8
Output voltages: [0.015918, 0.0049283, 0.017596, 0.39705, 0.0016305, 0.36661, 0.028744, 0.0018052, 0.79875, 0.039529]
Predicted label: 8
Correct prediction
Energy consumption = 141.408087 pJ
sum error= 92
Actual label: 0
Output voltages: [0.79853, 0.046685, 0.045334, 0.033305, 0.0068614, 0.0031019, 0.60323, 0.089256, 0.36681, 0.1813]
Predicted label: 0
Correct prediction
Energy consumption = 157.817763 pJ
sum error= 92
Actual label: 8
Output voltages: [0.26414, 0.02277, 0.10902, 0.15402, 0.0039019, 0.07033, 0.0032763, 0.0052752, 0.79869, 0.054728]
Predicted label: 8
Correct prediction
Energy consumption = 141.212714 pJ
sum error= 92
Actual label: 8
Output voltages: [0.044364, 0.017167, 0.027132, 0.0039776, 0.05748, 0.084394, 0.6228, 0.0022753, 0.79638, 0.01701]
Predicted label: 8
Correct prediction
Energy consumption = 136.225939 pJ
sum error= 92
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 176 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 176 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 176 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.016406, 0.79858, 0.030807, 0.16517, 0.079877, 0.0098261, 0.55633, 0.0014268, 0.43325, 0.035868]
Predicted label: 1
Correct prediction
Energy consumption = 160.334692 pJ
sum error= 92
Actual label: 5
Output voltages: [0.017779, 0.0011573, 0.0011104, 0.036238, 0.087979, 0.79423, 0.033262, 0.0091602, 0.78451, 0.053129]
Predicted label: 5
Correct prediction
Energy consumption = 150.703001 pJ
sum error= 92
Actual label: 0
Output voltages: [0.79833, 0.029321, 0.12137, 0.010241, 0.019683, 0.0025478, 0.59883, 0.013037, 0.33387, 0.57051]
Predicted label: 0
Correct prediction
Energy consumption = 153.576291 pJ
sum error= 92
Actual label: 3
Output voltages: [0.20269, 0.034425, 0.053545, 0.79855, 0.011567, 0.033702, 0.017631, 0.030699, 0.47052, 0.043381]
Predicted label: 3
Correct prediction
Energy consumption = 147.981399 pJ
sum error= 92
Actual label: 0
Output voltages: [0.7982, 0.035118, 0.03636, 0.011807, 0.021963, 0.0013195, 0.76569, 0.0074111, 0.27547, 0.057815]
Predicted label: 0
Correct prediction
Energy consumption = 155.444238 pJ
sum error= 92
Actual label: 3
Output voltages: [0.016283, 0.0011727, 0.017084, 0.79878, 0.040694, 0.205, 0.062883, 0.015359, 0.7458, 0.0026603]
Predicted label: 3
Correct prediction
Energy consumption = 144.427557 pJ
sum error= 92
Actual label: 1
Output voltages: [0.035922, 0.79875, 0.10075, 0.031568, 0.037481, 0.022382, 0.75531, 0.0018284, 0.048983, 0.001075]
Predicted label: 1
Correct prediction
Energy consumption = 155.922880 pJ
sum error= 92
Actual label: 4
Output voltages: [0.011424, 0.007345, 0.12766, 0.031842, 0.79866, 0.001278, 0.049085, 0.026317, 0.021242, 0.041514]
Predicted label: 4
Correct prediction
Energy consumption = 148.981089 pJ
sum error= 92
Actual label: 0
Output voltages: [0.79877, 0.054873, 0.024971, 0.021461, 0.017383, 0.017216, 0.38684, 0.0074899, 0.063979, 0.1285]
Predicted label: 0
Correct prediction
Energy consumption = 154.992382 pJ
sum error= 92
Actual label: 3
Output voltages: [0.0294, 0.0012088, 0.7827, 0.76494, 0.0093501, 0.0010669, 0.0065172, 0.093953, 0.78074, 0.017909]
Predicted label: 2
Wrong prediction!
Energy consumption = 142.644574 pJ
sum error= 93
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 177 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 177 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 177 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.042767, 0.13119, 0.51474, 0.33026, 0.0029986, 0.0010714, 0.0011012, 0.79872, 0.43033, 0.2312]
Predicted label: 7
Correct prediction
Energy consumption = 149.684476 pJ
sum error= 93
Actual label: 2
Output voltages: [0.41485, 0.29109, 0.79872, 0.048746, 0.010697, 0.0012196, 0.2453, 0.15722, 0.4507, 0.077192]
Predicted label: 2
Correct prediction
Energy consumption = 144.444433 pJ
sum error= 93
Actual label: 7
Output voltages: [0.013953, 0.0020684, 0.0012744, 0.4179, 0.76444, 0.47566, 0.003046, 0.798, 0.16158, 0.040621]
Predicted label: 7
Correct prediction
Energy consumption = 148.634725 pJ
sum error= 93
Actual label: 1
Output voltages: [0.13237, 0.79875, 0.011497, 0.010747, 0.046973, 0.033941, 0.79756, 0.0012474, 0.086851, 0.081356]
Predicted label: 1
Correct prediction
Energy consumption = 161.430438 pJ
sum error= 93
Actual label: 8
Output voltages: [0.026649, 0.00152, 0.018036, 0.47324, 0.0072687, 0.63312, 0.11721, 0.0022308, 0.79879, 0.21483]
Predicted label: 8
Correct prediction
Energy consumption = 152.649958 pJ
sum error= 93
Actual label: 0
Output voltages: [0.79876, 0.027484, 0.02907, 0.0014041, 0.027004, 0.071075, 0.10629, 0.024896, 0.56733, 0.26279]
Predicted label: 0
Correct prediction
Energy consumption = 154.712498 pJ
sum error= 93
Actual label: 7
Output voltages: [0.40357, 0.026673, 0.55979, 0.57923, 0.0022745, 0.0012261, 0.0010768, 0.7737, 0.037989, 0.51864]
Predicted label: 7
Correct prediction
Energy consumption = 155.620955 pJ
sum error= 93
Actual label: 0
Output voltages: [0.79878, 0.25783, 0.020254, 0.0062748, 0.037149, 0.013237, 0.53723, 0.0078052, 0.028336, 0.10445]
Predicted label: 0
Correct prediction
Energy consumption = 155.873707 pJ
sum error= 93
Actual label: 4
Output voltages: [0.015448, 0.019229, 0.11605, 0.0096276, 0.7987, 0.0016249, 0.5821, 0.0059572, 0.018328, 0.26032]
Predicted label: 4
Correct prediction
Energy consumption = 151.251934 pJ
sum error= 93
Actual label: 3
Output voltages: [0.22867, 0.021479, 0.062139, 0.79877, 0.015586, 0.0017701, 0.0065801, 0.0032342, 0.50482, 0.049726]
Predicted label: 3
Correct prediction
Energy consumption = 146.135613 pJ
sum error= 93
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 178 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 178 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 178 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0063407, 0.79863, 0.034218, 0.034326, 0.0023009, 0.0013675, 0.73039, 0.0091395, 0.31333, 0.0056708]
Predicted label: 1
Correct prediction
Energy consumption = 165.342230 pJ
sum error= 93
Actual label: 9
Output voltages: [0.77064, 0.0056872, 0.023751, 0.012259, 0.48522, 0.0029178, 0.084697, 0.0013564, 0.16448, 0.79681]
Predicted label: 9
Correct prediction
Energy consumption = 155.544868 pJ
sum error= 93
Actual label: 8
Output voltages: [0.31326, 0.0094179, 0.15429, 0.010422, 0.0098023, 0.10139, 0.015075, 0.038121, 0.79849, 0.4953]
Predicted label: 8
Correct prediction
Energy consumption = 153.295125 pJ
sum error= 93
Actual label: 7
Output voltages: [0.33382, 0.1037, 0.026177, 0.027133, 0.00447, 0.035954, 0.0010897, 0.79869, 0.051838, 0.5508]
Predicted label: 7
Correct prediction
Energy consumption = 145.899474 pJ
sum error= 93
Actual label: 7
Output voltages: [0.1075, 0.19759, 0.2092, 0.012141, 0.0085133, 0.0053893, 0.001133, 0.79862, 0.42484, 0.50799]
Predicted label: 7
Correct prediction
Energy consumption = 145.944242 pJ
sum error= 93
Actual label: 1
Output voltages: [0.021166, 0.79799, 0.035254, 0.30731, 0.056527, 0.0048529, 0.0054677, 0.003669, 0.41951, 0.048223]
Predicted label: 1
Correct prediction
Energy consumption = 163.591587 pJ
sum error= 93
Actual label: 4
Output voltages: [0.026318, 0.022371, 0.13493, 0.014751, 0.79868, 0.010949, 0.061137, 0.079222, 0.0232, 0.0050987]
Predicted label: 4
Correct prediction
Energy consumption = 152.871232 pJ
sum error= 93
Actual label: 9
Output voltages: [0.23307, 0.0036743, 0.019748, 0.05862, 0.47878, 0.093709, 0.033047, 0.040638, 0.078528, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 149.416864 pJ
sum error= 93
Actual label: 9
Output voltages: [0.46623, 0.029289, 0.0097653, 0.062323, 0.47102, 0.022892, 0.012945, 0.0025172, 0.37639, 0.79831]
Predicted label: 9
Correct prediction
Energy consumption = 154.911460 pJ
sum error= 93
Actual label: 3
Output voltages: [0.55657, 0.027692, 0.071721, 0.79874, 0.0080079, 0.0086496, 0.078579, 0.0014277, 0.45063, 0.037252]
Predicted label: 3
Correct prediction
Energy consumption = 150.859095 pJ
sum error= 93
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 179 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 179 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 179 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.57687, 0.17606, 0.55107, 0.0010906, 0.052298, 0.0011927, 0.0014486, 0.69999, 0.58238, 0.11964]
Predicted label: 7
Wrong prediction!
Energy consumption = 146.676916 pJ
sum error= 94
Actual label: 1
Output voltages: [0.0024061, 0.79863, 0.0012463, 0.055454, 0.014168, 0.0010686, 0.39249, 0.048973, 0.32629, 0.032994]
Predicted label: 1
Correct prediction
Energy consumption = 155.658359 pJ
sum error= 94
Actual label: 7
Output voltages: [0.28331, 0.0091069, 0.035106, 0.76812, 0.010519, 0.002237, 0.0011589, 0.79876, 0.20054, 0.36968]
Predicted label: 7
Correct prediction
Energy consumption = 144.349994 pJ
sum error= 94
Actual label: 9
Output voltages: [0.70271, 0.0027395, 0.048548, 0.010798, 0.57783, 0.01904, 0.0050601, 0.018303, 0.056913, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 138.383775 pJ
sum error= 94
Actual label: 0
Output voltages: [0.79879, 0.026603, 0.18137, 0.039243, 0.0038777, 0.0051996, 0.51519, 0.020297, 0.057992, 0.1713]
Predicted label: 0
Correct prediction
Energy consumption = 143.593693 pJ
sum error= 94
Actual label: 2
Output voltages: [0.65079, 0.019221, 0.79879, 0.13684, 0.019951, 0.0011654, 0.051295, 0.10175, 0.53656, 0.018414]
Predicted label: 2
Correct prediction
Energy consumption = 142.896913 pJ
sum error= 94
Actual label: 0
Output voltages: [0.79878, 0.031022, 0.03773, 0.0014556, 0.011123, 0.0050991, 0.41609, 0.0025231, 0.039288, 0.036991]
Predicted label: 0
Correct prediction
Energy consumption = 148.337788 pJ
sum error= 94
Actual label: 3
Output voltages: [0.49774, 0.01114, 0.028403, 0.79879, 0.01696, 0.041394, 0.28483, 0.015692, 0.19964, 0.10931]
Predicted label: 3
Correct prediction
Energy consumption = 151.448470 pJ
sum error= 94
Actual label: 3
Output voltages: [0.048362, 0.011773, 0.029741, 0.79873, 0.027311, 0.0061249, 0.051798, 0.015467, 0.44133, 0.14884]
Predicted label: 3
Correct prediction
Energy consumption = 136.134820 pJ
sum error= 94
Actual label: 7
Output voltages: [0.21963, 0.023425, 0.041986, 0.35402, 0.0091872, 0.001195, 0.0011211, 0.79861, 0.34872, 0.20211]
Predicted label: 7
Correct prediction
Energy consumption = 155.051586 pJ
sum error= 94
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 180 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 180 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 180 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.23836, 0.0040813, 0.15749, 0.021466, 0.22168, 0.017374, 0.79848, 0.0048781, 0.03445, 0.48712]
Predicted label: 6
Correct prediction
Energy consumption = 137.556365 pJ
sum error= 94
Actual label: 9
Output voltages: [0.45772, 0.001147, 0.048906, 0.035204, 0.063223, 0.030941, 0.0022245, 0.020798, 0.72435, 0.7915]
Predicted label: 9
Correct prediction
Energy consumption = 144.699026 pJ
sum error= 94
Actual label: 2
Output voltages: [0.43904, 0.089965, 0.79878, 0.17398, 0.008116, 0.0012061, 0.23314, 0.22121, 0.37847, 0.023366]
Predicted label: 2
Correct prediction
Energy consumption = 145.524135 pJ
sum error= 94
Actual label: 3
Output voltages: [0.13521, 0.034897, 0.057262, 0.79868, 0.02324, 0.019702, 0.018567, 0.018364, 0.32325, 0.17056]
Predicted label: 3
Correct prediction
Energy consumption = 142.878289 pJ
sum error= 94
Actual label: 3
Output voltages: [0.18623, 0.017096, 0.042309, 0.79867, 0.028805, 0.0037749, 0.0084724, 0.012867, 0.67656, 0.041268]
Predicted label: 3
Correct prediction
Energy consumption = 131.904848 pJ
sum error= 94
Actual label: 7
Output voltages: [0.24632, 0.15941, 0.043485, 0.32909, 0.0067392, 0.0061578, 0.0010697, 0.79865, 0.020288, 0.38246]
Predicted label: 7
Correct prediction
Energy consumption = 146.053158 pJ
sum error= 94
Actual label: 7
Output voltages: [0.36295, 0.050312, 0.46586, 0.25158, 0.0029428, 0.0011296, 0.001413, 0.79873, 0.046178, 0.37944]
Predicted label: 7
Correct prediction
Energy consumption = 147.306386 pJ
sum error= 94
Actual label: 0
Output voltages: [0.7987, 0.0463, 0.19944, 0.023035, 0.001475, 0.043686, 0.35785, 0.028776, 0.35779, 0.022468]
Predicted label: 0
Correct prediction
Energy consumption = 144.087194 pJ
sum error= 94
Actual label: 0
Output voltages: [0.77159, 0.025465, 0.31188, 0.0056321, 0.77869, 0.0010694, 0.61278, 0.019655, 0.015209, 0.024649]
Predicted label: 4
Wrong prediction!
Energy consumption = 139.122069 pJ
sum error= 95
Actual label: 7
Output voltages: [0.2495, 0.40167, 0.041025, 0.39085, 0.019377, 0.0011394, 0.0010885, 0.78865, 0.010398, 0.52995]
Predicted label: 7
Correct prediction
Energy consumption = 157.657461 pJ
sum error= 95
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 181 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 181 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 181 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.11589, 0.0010795, 0.016892, 0.3874, 0.0093232, 0.79875, 0.053235, 0.018442, 0.78325, 0.027797]
Predicted label: 5
Correct prediction
Energy consumption = 145.848289 pJ
sum error= 95
Actual label: 2
Output voltages: [0.63819, 0.0010926, 0.76379, 0.78085, 0.013063, 0.0014599, 0.003237, 0.049825, 0.71992, 0.027021]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.222040 pJ
sum error= 96
Actual label: 9
Output voltages: [0.77064, 0.0014845, 0.0042057, 0.014731, 0.50205, 0.094272, 0.027801, 0.061908, 0.09723, 0.7979]
Predicted label: 9
Correct prediction
Energy consumption = 161.423263 pJ
sum error= 96
Actual label: 8
Output voltages: [0.31399, 0.0011813, 0.023031, 0.54593, 0.0026352, 0.62085, 0.0089277, 0.0013338, 0.79879, 0.14453]
Predicted label: 8
Correct prediction
Energy consumption = 150.074307 pJ
sum error= 96
Actual label: 7
Output voltages: [0.069766, 0.078983, 0.33068, 0.016835, 0.0020711, 0.0017159, 0.0010679, 0.79827, 0.79587, 0.013172]
Predicted label: 7
Correct prediction
Energy consumption = 142.300565 pJ
sum error= 96
Actual label: 4
Output voltages: [0.0055727, 0.0080535, 0.23689, 0.012453, 0.79854, 0.002936, 0.044614, 0.025879, 0.040853, 0.048978]
Predicted label: 4
Correct prediction
Energy consumption = 151.237004 pJ
sum error= 96
Actual label: 4
Output voltages: [0.001339, 0.0025019, 0.1934, 0.0044701, 0.79876, 0.0014258, 0.16607, 0.05406, 0.031431, 0.080952]
Predicted label: 4
Correct prediction
Energy consumption = 144.133916 pJ
sum error= 96
Actual label: 2
Output voltages: [0.7533, 0.21049, 0.79876, 0.4656, 0.0098917, 0.0011463, 0.30738, 0.067969, 0.49071, 0.043634]
Predicted label: 2
Correct prediction
Energy consumption = 149.162786 pJ
sum error= 96
Actual label: 6
Output voltages: [0.10642, 0.22209, 0.047689, 0.017906, 0.071019, 0.34939, 0.79877, 0.001674, 0.40375, 0.029423]
Predicted label: 6
Correct prediction
Energy consumption = 153.297464 pJ
sum error= 96
Actual label: 6
Output voltages: [0.1976, 0.0074483, 0.24222, 0.0073666, 0.2647, 0.35531, 0.79756, 0.0015564, 0.74034, 0.002938]
Predicted label: 6
Correct prediction
Energy consumption = 135.299074 pJ
sum error= 96
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 182 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 182 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 182 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.2879, 0.79865, 0.025635, 0.0068309, 0.35855, 0.0059585, 0.33578, 0.005154, 0.0034846, 0.22119]
Predicted label: 1
Correct prediction
Energy consumption = 157.334498 pJ
sum error= 96
Actual label: 9
Output voltages: [0.37959, 0.010024, 0.02509, 0.023221, 0.24328, 0.063542, 0.0085987, 0.03729, 0.29413, 0.79751]
Predicted label: 9
Correct prediction
Energy consumption = 158.344610 pJ
sum error= 96
Actual label: 6
Output voltages: [0.33328, 0.0066769, 0.012742, 0.20972, 0.051078, 0.79668, 0.78852, 0.0040395, 0.67288, 0.0092668]
Predicted label: 5
Wrong prediction!
Energy consumption = 154.561867 pJ
sum error= 97
Actual label: 8
Output voltages: [0.0072208, 0.02297, 0.12513, 0.048103, 0.033508, 0.034809, 0.1278, 0.0011443, 0.7973, 0.33989]
Predicted label: 8
Correct prediction
Energy consumption = 148.105195 pJ
sum error= 97
Actual label: 2
Output voltages: [0.61818, 0.075386, 0.79878, 0.035013, 0.0039861, 0.0013086, 0.26174, 0.22065, 0.4819, 0.036189]
Predicted label: 2
Correct prediction
Energy consumption = 151.149756 pJ
sum error= 97
Actual label: 9
Output voltages: [0.32089, 0.005948, 0.031631, 0.037734, 0.2223, 0.0051498, 0.001879, 0.018174, 0.41501, 0.7981]
Predicted label: 9
Correct prediction
Energy consumption = 149.534357 pJ
sum error= 97
Actual label: 0
Output voltages: [0.7986, 0.041988, 0.047576, 0.0066699, 0.003994, 0.0018256, 0.62764, 0.010223, 0.050403, 0.046378]
Predicted label: 0
Correct prediction
Energy consumption = 150.427576 pJ
sum error= 97
Actual label: 8
Output voltages: [0.027948, 0.15641, 0.20759, 0.37188, 0.008846, 0.0098002, 0.24554, 0.0035966, 0.79877, 0.10813]
Predicted label: 8
Correct prediction
Energy consumption = 155.669959 pJ
sum error= 97
Actual label: 3
Output voltages: [0.27236, 0.023344, 0.0072369, 0.79848, 0.0013733, 0.25862, 0.017157, 0.74569, 0.036742, 0.013503]
Predicted label: 3
Correct prediction
Energy consumption = 157.026578 pJ
sum error= 97
Actual label: 1
Output voltages: [0.13533, 0.79835, 0.030035, 0.051339, 0.0028005, 0.0021921, 0.35406, 0.015516, 0.048701, 0.30649]
Predicted label: 1
Correct prediction
Energy consumption = 163.053461 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 183 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 183 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 183 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0035323, 0.79858, 0.03166, 0.04804, 0.034806, 0.0016366, 0.76878, 0.011032, 0.32852, 0.029033]
Predicted label: 1
Correct prediction
Energy consumption = 168.113228 pJ
sum error= 97
Actual label: 6
Output voltages: [0.32131, 0.021063, 0.044818, 0.015468, 0.14752, 0.57057, 0.79875, 0.0011097, 0.51615, 0.044053]
Predicted label: 6
Correct prediction
Energy consumption = 147.008026 pJ
sum error= 97
Actual label: 3
Output voltages: [0.4275, 0.0034341, 0.016437, 0.79869, 0.024413, 0.20101, 0.0095674, 0.023865, 0.41849, 0.043861]
Predicted label: 3
Correct prediction
Energy consumption = 146.367758 pJ
sum error= 97
Actual label: 5
Output voltages: [0.061009, 0.0013138, 0.0063633, 0.72022, 0.0091807, 0.79859, 0.01409, 0.085399, 0.75668, 0.06008]
Predicted label: 5
Correct prediction
Energy consumption = 139.474536 pJ
sum error= 97
Actual label: 1
Output voltages: [0.048577, 0.7985, 0.14163, 0.10096, 0.1703, 0.0010917, 0.53982, 0.023191, 0.021253, 0.041777]
Predicted label: 1
Correct prediction
Energy consumption = 171.482087 pJ
sum error= 97
Actual label: 1
Output voltages: [0.072541, 0.79852, 0.019787, 0.13788, 0.018368, 0.0058574, 0.59611, 0.0011944, 0.17282, 0.12407]
Predicted label: 1
Correct prediction
Energy consumption = 157.255347 pJ
sum error= 97
Actual label: 1
Output voltages: [0.0057644, 0.79856, 0.023525, 0.26974, 0.017624, 0.0011079, 0.51776, 0.011625, 0.29355, 0.045157]
Predicted label: 1
Correct prediction
Energy consumption = 154.435627 pJ
sum error= 97
Actual label: 3
Output voltages: [0.23145, 0.0074296, 0.025621, 0.79872, 0.036177, 0.35146, 0.055805, 0.0051189, 0.64924, 0.047155]
Predicted label: 3
Correct prediction
Energy consumption = 147.196055 pJ
sum error= 97
Actual label: 1
Output voltages: [0.023299, 0.78768, 0.6695, 0.65394, 0.19344, 0.0012799, 0.29727, 0.0012749, 0.036898, 0.22773]
Predicted label: 1
Correct prediction
Energy consumption = 154.539553 pJ
sum error= 97
Actual label: 2
Output voltages: [0.13936, 0.057705, 0.79768, 0.5483, 0.0037028, 0.0012612, 0.095756, 0.0072663, 0.50973, 0.022403]
Predicted label: 2
Correct prediction
Energy consumption = 145.028398 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 184 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 184 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 184 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.47264, 0.066772, 0.20468, 0.79871, 0.0087359, 0.009651, 0.04776, 0.037688, 0.18394, 0.0072248]
Predicted label: 3
Correct prediction
Energy consumption = 153.328830 pJ
sum error= 97
Actual label: 0
Output voltages: [0.79878, 0.1009, 0.0091074, 0.0056832, 0.017461, 0.037288, 0.7169, 0.016026, 0.12535, 0.19793]
Predicted label: 0
Correct prediction
Energy consumption = 154.207290 pJ
sum error= 97
Actual label: 2
Output voltages: [0.038204, 0.062052, 0.79879, 0.1033, 0.020429, 0.0012416, 0.38393, 0.027539, 0.68817, 0.11366]
Predicted label: 2
Correct prediction
Energy consumption = 152.819031 pJ
sum error= 97
Actual label: 0
Output voltages: [0.79878, 0.0089569, 0.43403, 0.021941, 0.027479, 0.0024962, 0.038908, 0.019776, 0.46485, 0.26942]
Predicted label: 0
Correct prediction
Energy consumption = 149.317273 pJ
sum error= 97
Actual label: 1
Output voltages: [0.013485, 0.7984, 0.10292, 0.48542, 0.0059635, 0.0013731, 0.28175, 0.045143, 0.36668, 0.027321]
Predicted label: 1
Correct prediction
Energy consumption = 164.284827 pJ
sum error= 97
Actual label: 3
Output voltages: [0.13747, 0.018857, 0.019776, 0.7987, 0.0079778, 0.0058829, 0.010847, 0.012052, 0.64083, 0.041506]
Predicted label: 3
Correct prediction
Energy consumption = 141.919873 pJ
sum error= 97
Actual label: 5
Output voltages: [0.027257, 0.0012811, 0.013302, 0.29375, 0.015696, 0.78914, 0.012, 0.0021015, 0.78225, 0.019272]
Predicted label: 5
Correct prediction
Energy consumption = 138.282451 pJ
sum error= 97
Actual label: 5
Output voltages: [0.44792, 0.0012555, 0.0031334, 0.0046326, 0.0022125, 0.78799, 0.36153, 0.0045789, 0.6341, 0.028747]
Predicted label: 5
Correct prediction
Energy consumption = 138.405338 pJ
sum error= 97
Actual label: 7
Output voltages: [0.05313, 0.20629, 0.77102, 0.017326, 0.004865, 0.0011166, 0.0010931, 0.79875, 0.42551, 0.13967]
Predicted label: 7
Correct prediction
Energy consumption = 148.438538 pJ
sum error= 97
Actual label: 4
Output voltages: [0.035337, 0.0021053, 0.55056, 0.27502, 0.79879, 0.0070545, 0.015124, 0.0068832, 0.060726, 0.050202]
Predicted label: 4
Correct prediction
Energy consumption = 140.570666 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 185 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 185 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 185 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.071763, 0.034145, 0.035434, 0.19124, 0.0045636, 0.0015604, 0.016095, 0.012336, 0.79854, 0.58208]
Predicted label: 8
Correct prediction
Energy consumption = 150.971346 pJ
sum error= 97
Actual label: 9
Output voltages: [0.48734, 0.0048449, 0.01871, 0.014975, 0.36778, 0.0056679, 0.001502, 0.021561, 0.47753, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 147.572085 pJ
sum error= 97
Actual label: 6
Output voltages: [0.31188, 0.03687, 0.0064569, 0.02141, 0.44185, 0.49395, 0.79877, 0.0012497, 0.57447, 0.011427]
Predicted label: 6
Correct prediction
Energy consumption = 155.096170 pJ
sum error= 97
Actual label: 9
Output voltages: [0.59064, 0.0014308, 0.097075, 0.02895, 0.42743, 0.018765, 0.025991, 0.23259, 0.03689, 0.79466]
Predicted label: 9
Correct prediction
Energy consumption = 155.725654 pJ
sum error= 97
Actual label: 6
Output voltages: [0.037341, 0.082009, 0.36858, 0.0011206, 0.44142, 0.13297, 0.7987, 0.0011874, 0.52052, 0.0085753]
Predicted label: 6
Correct prediction
Energy consumption = 146.193988 pJ
sum error= 97
Actual label: 8
Output voltages: [0.013592, 0.018757, 0.1161, 0.39707, 0.0014332, 0.016658, 0.0051691, 0.01039, 0.79871, 0.34735]
Predicted label: 8
Correct prediction
Energy consumption = 149.573200 pJ
sum error= 97
Actual label: 3
Output voltages: [0.35171, 0.040456, 0.78314, 0.79852, 0.066281, 0.0010663, 0.0070908, 0.0014309, 0.32476, 0.018992]
Predicted label: 3
Correct prediction
Energy consumption = 133.140767 pJ
sum error= 97
Actual label: 6
Output voltages: [0.029695, 0.0065249, 0.47036, 0.0030311, 0.72062, 0.20993, 0.7987, 0.0040047, 0.40598, 0.0082151]
Predicted label: 6
Correct prediction
Energy consumption = 147.931313 pJ
sum error= 97
Actual label: 6
Output voltages: [0.050677, 0.015607, 0.2887, 0.0023315, 0.40716, 0.20193, 0.79878, 0.0012086, 0.72271, 0.010411]
Predicted label: 6
Correct prediction
Energy consumption = 140.513345 pJ
sum error= 97
Actual label: 8
Output voltages: [0.012326, 0.051069, 0.35705, 0.016811, 0.013723, 0.0075432, 0.1351, 0.0094587, 0.79878, 0.26658]
Predicted label: 8
Correct prediction
Energy consumption = 139.919599 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 186 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 186 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 186 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.031186, 0.0010663, 0.0034698, 0.21635, 0.0342, 0.79876, 0.16098, 0.072581, 0.77751, 0.059349]
Predicted label: 5
Correct prediction
Energy consumption = 150.205845 pJ
sum error= 97
Actual label: 1
Output voltages: [0.032104, 0.79878, 0.019152, 0.31842, 0.033874, 0.0017591, 0.0022329, 0.3439, 0.35728, 0.096482]
Predicted label: 1
Correct prediction
Energy consumption = 160.410272 pJ
sum error= 97
Actual label: 4
Output voltages: [0.01061, 0.0029682, 0.086185, 0.0080316, 0.79879, 0.0010718, 0.00975, 0.033362, 0.063798, 0.34321]
Predicted label: 4
Correct prediction
Energy consumption = 161.172776 pJ
sum error= 97
Actual label: 2
Output voltages: [0.24892, 0.0013162, 0.79806, 0.52426, 0.017686, 0.0011482, 0.040772, 0.14637, 0.67209, 0.020796]
Predicted label: 2
Correct prediction
Energy consumption = 147.792830 pJ
sum error= 97
Actual label: 4
Output voltages: [0.0042214, 0.016714, 0.21895, 0.012825, 0.79863, 0.0035797, 0.032524, 0.026455, 0.05327, 0.022176]
Predicted label: 4
Correct prediction
Energy consumption = 155.442128 pJ
sum error= 97
Actual label: 4
Output voltages: [0.001688, 0.021502, 0.027069, 0.053909, 0.79875, 0.0012133, 0.040436, 0.13427, 0.0567, 0.044453]
Predicted label: 4
Correct prediction
Energy consumption = 135.648547 pJ
sum error= 97
Actual label: 5
Output voltages: [0.14112, 0.0011095, 0.0019805, 0.25064, 0.08273, 0.79695, 0.051989, 0.048103, 0.79074, 0.20101]
Predicted label: 5
Correct prediction
Energy consumption = 144.543777 pJ
sum error= 97
Actual label: 1
Output voltages: [0.022457, 0.79839, 0.25143, 0.047043, 0.023413, 0.0034834, 0.58839, 0.006392, 0.22109, 0.10989]
Predicted label: 1
Correct prediction
Energy consumption = 167.587283 pJ
sum error= 97
Actual label: 1
Output voltages: [0.0021215, 0.79875, 0.027, 0.024079, 0.53587, 0.0010806, 0.028668, 0.077015, 0.074588, 0.060282]
Predicted label: 1
Correct prediction
Energy consumption = 140.800048 pJ
sum error= 97
Actual label: 9
Output voltages: [0.32839, 0.0031222, 0.012992, 0.29239, 0.040021, 0.0055433, 0.0011809, 0.026666, 0.19186, 0.79601]
Predicted label: 9
Correct prediction
Energy consumption = 153.852843 pJ
sum error= 97
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 187 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 187 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 187 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.24075, 0.038007, 0.011842, 0.012677, 0.012925, 0.45296, 0.011818, 0.15186, 0.12196]
Predicted label: 0
Correct prediction
Energy consumption = 152.823658 pJ
sum error= 97
Actual label: 2
Output voltages: [0.079195, 0.031992, 0.76501, 0.5415, 0.038299, 0.001087, 0.28123, 0.0020506, 0.79798, 0.027609]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.448807 pJ
sum error= 98
Actual label: 4
Output voltages: [0.0073126, 0.013124, 0.046339, 0.013727, 0.79872, 0.0010823, 0.027611, 0.11033, 0.042307, 0.22751]
Predicted label: 4
Correct prediction
Energy consumption = 156.880673 pJ
sum error= 98
Actual label: 9
Output voltages: [0.20652, 0.029035, 0.025153, 0.46943, 0.049236, 0.010601, 0.029053, 0.02351, 0.052083, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 145.727796 pJ
sum error= 98
Actual label: 5
Output voltages: [0.01939, 0.0022529, 0.001542, 0.67963, 0.13437, 0.79822, 0.62943, 0.010768, 0.60137, 0.3997]
Predicted label: 5
Correct prediction
Energy consumption = 143.090195 pJ
sum error= 98
Actual label: 7
Output voltages: [0.22678, 0.11208, 0.03831, 0.031058, 0.010027, 0.0012141, 0.0010673, 0.79859, 0.12742, 0.1286]
Predicted label: 7
Correct prediction
Energy consumption = 155.427106 pJ
sum error= 98
Actual label: 1
Output voltages: [0.0030295, 0.79851, 0.13765, 0.10366, 0.05083, 0.001516, 0.59461, 0.0047649, 0.08107, 0.29562]
Predicted label: 1
Correct prediction
Energy consumption = 160.136754 pJ
sum error= 98
Actual label: 8
Output voltages: [0.064639, 0.050178, 0.046679, 0.67479, 0.0015465, 0.03185, 0.0059944, 0.0031044, 0.79874, 0.2871]
Predicted label: 8
Correct prediction
Energy consumption = 153.717589 pJ
sum error= 98
Actual label: 8
Output voltages: [0.13624, 0.042175, 0.045772, 0.79866, 0.034503, 0.003541, 0.084181, 0.11081, 0.69802, 0.04282]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.693286 pJ
sum error= 99
Actual label: 5
Output voltages: [0.091196, 0.0014317, 0.0034384, 0.66856, 0.010211, 0.79869, 0.33138, 0.0078723, 0.69111, 0.041269]
Predicted label: 5
Correct prediction
Energy consumption = 139.340947 pJ
sum error= 99
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 188 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 188 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 188 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.67542, 0.028264, 0.21826, 0.0010721, 0.061676, 0.0012012, 0.79683, 0.0043485, 0.357, 0.017209]
Predicted label: 6
Correct prediction
Energy consumption = 161.834811 pJ
sum error= 99
Actual label: 9
Output voltages: [0.32458, 0.012278, 0.0092005, 0.027441, 0.058664, 0.0059489, 0.0010855, 0.018529, 0.52774, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 153.802849 pJ
sum error= 99
Actual label: 8
Output voltages: [0.042821, 0.0024789, 0.34501, 0.53001, 0.0019104, 0.26462, 0.016441, 0.036727, 0.79874, 0.3574]
Predicted label: 8
Correct prediction
Energy consumption = 140.906335 pJ
sum error= 99
Actual label: 7
Output voltages: [0.31442, 0.11109, 0.027364, 0.15504, 0.1702, 0.029719, 0.0020194, 0.78485, 0.0013434, 0.74389]
Predicted label: 7
Correct prediction
Energy consumption = 156.426686 pJ
sum error= 99
Actual label: 1
Output voltages: [0.030878, 0.79851, 0.026238, 0.047705, 0.031663, 0.0015507, 0.72267, 0.0012627, 0.30153, 0.14575]
Predicted label: 1
Correct prediction
Energy consumption = 164.542548 pJ
sum error= 99
Actual label: 1
Output voltages: [0.13587, 0.79875, 0.16104, 0.010205, 0.37743, 0.0027281, 0.69778, 0.0019939, 0.16407, 0.02291]
Predicted label: 1
Correct prediction
Energy consumption = 137.926894 pJ
sum error= 99
Actual label: 6
Output voltages: [0.16425, 0.34597, 0.038151, 0.10511, 0.011006, 0.29922, 0.79875, 0.016123, 0.71396, 0.0020018]
Predicted label: 6
Correct prediction
Energy consumption = 143.877041 pJ
sum error= 99
Actual label: 7
Output voltages: [0.15432, 0.038929, 0.02882, 0.0059903, 0.014518, 0.010358, 0.0010835, 0.79872, 0.30075, 0.48566]
Predicted label: 7
Correct prediction
Energy consumption = 159.047580 pJ
sum error= 99
Actual label: 6
Output voltages: [0.10943, 0.045275, 0.0097903, 0.038287, 0.073924, 0.48752, 0.7987, 0.015932, 0.65073, 0.0024652]
Predicted label: 6
Correct prediction
Energy consumption = 149.250401 pJ
sum error= 99
Actual label: 3
Output voltages: [0.38252, 0.021838, 0.099758, 0.79859, 0.019774, 0.016676, 0.015184, 0.032856, 0.69735, 0.015303]
Predicted label: 3
Correct prediction
Energy consumption = 147.889236 pJ
sum error= 99
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 189 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 189 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 189 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.65032, 0.17278, 0.79877, 0.15052, 0.040836, 0.0012235, 0.32528, 0.035556, 0.45049, 0.044286]
Predicted label: 2
Correct prediction
Energy consumption = 149.883113 pJ
sum error= 99
Actual label: 2
Output voltages: [0.38679, 0.044485, 0.79871, 0.064545, 0.03962, 0.0012244, 0.2016, 0.022256, 0.27123, 0.026462]
Predicted label: 2
Correct prediction
Energy consumption = 134.088568 pJ
sum error= 99
Actual label: 0
Output voltages: [0.79876, 0.28655, 0.043765, 0.011382, 0.0064213, 0.0072266, 0.39742, 0.0061855, 0.058137, 0.44291]
Predicted label: 0
Correct prediction
Energy consumption = 145.168338 pJ
sum error= 99
Actual label: 8
Output voltages: [0.031627, 0.011395, 0.6452, 0.26622, 0.016169, 0.0016433, 0.15631, 0.0071021, 0.79874, 0.093317]
Predicted label: 8
Correct prediction
Energy consumption = 151.134638 pJ
sum error= 99
Actual label: 9
Output voltages: [0.022711, 0.015974, 0.010384, 0.031397, 0.008527, 0.041554, 0.0056651, 0.016908, 0.78433, 0.76783]
Predicted label: 8
Wrong prediction!
Energy consumption = 157.001328 pJ
sum error= 100
Actual label: 2
Output voltages: [0.50329, 0.027715, 0.79855, 0.1379, 0.026176, 0.0036109, 0.076708, 0.040186, 0.37189, 0.014695]
Predicted label: 2
Correct prediction
Energy consumption = 141.656822 pJ
sum error= 100
Actual label: 5
Output voltages: [0.02247, 0.0010662, 0.0094675, 0.14169, 0.020147, 0.79374, 0.20875, 0.022856, 0.77675, 0.26677]
Predicted label: 5
Correct prediction
Energy consumption = 141.454089 pJ
sum error= 100
Actual label: 1
Output voltages: [0.0026902, 0.7985, 0.041404, 0.030281, 0.28271, 0.040075, 0.2853, 0.0084447, 0.37675, 0.058145]
Predicted label: 1
Correct prediction
Energy consumption = 170.112235 pJ
sum error= 100
Actual label: 0
Output voltages: [0.79868, 0.17441, 0.0073675, 0.010979, 0.010057, 0.042755, 0.5082, 0.010483, 0.052948, 0.051676]
Predicted label: 0
Correct prediction
Energy consumption = 152.309483 pJ
sum error= 100
Actual label: 8
Output voltages: [0.0087598, 0.0062494, 0.033705, 0.78569, 0.024737, 0.0088006, 0.0032603, 0.028645, 0.79826, 0.13013]
Predicted label: 8
Correct prediction
Energy consumption = 155.830300 pJ
sum error= 100
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 190 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 190 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 190 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.040499, 0.79303, 0.040989, 0.030089, 0.2598, 0.0016896, 0.42653, 0.001214, 0.06383, 0.001924]
Predicted label: 1
Correct prediction
Energy consumption = 155.380720 pJ
sum error= 100
Actual label: 9
Output voltages: [0.0094266, 0.0059478, 0.03373, 0.0015788, 0.7853, 0.36995, 0.026807, 0.028896, 0.50892, 0.37937]
Predicted label: 4
Wrong prediction!
Energy consumption = 156.555255 pJ
sum error= 101
Actual label: 5
Output voltages: [0.024946, 0.0017588, 0.0040518, 0.42623, 0.022644, 0.79869, 0.30589, 0.043139, 0.67191, 0.35247]
Predicted label: 5
Correct prediction
Energy consumption = 148.322937 pJ
sum error= 101
Actual label: 7
Output voltages: [0.0055872, 0.070042, 0.77081, 0.35706, 0.040421, 0.0014012, 0.014314, 0.78259, 0.44483, 0.0084647]
Predicted label: 7
Correct prediction
Energy consumption = 143.278095 pJ
sum error= 101
Actual label: 9
Output voltages: [0.23081, 0.013862, 0.039366, 0.0051194, 0.55634, 0.0094884, 0.0030917, 0.015684, 0.19284, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 154.514972 pJ
sum error= 101
Actual label: 6
Output voltages: [0.41751, 0.033323, 0.034989, 0.015408, 0.44015, 0.41672, 0.79879, 0.0017276, 0.49153, 0.009559]
Predicted label: 6
Correct prediction
Energy consumption = 153.656258 pJ
sum error= 101
Actual label: 9
Output voltages: [0.11198, 0.026767, 0.027968, 0.026868, 0.08159, 0.025583, 0.0042843, 0.010401, 0.44565, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 152.745750 pJ
sum error= 101
Actual label: 0
Output voltages: [0.79879, 0.029381, 0.33199, 0.05929, 0.057085, 0.0040697, 0.064488, 0.040333, 0.25146, 0.068191]
Predicted label: 0
Correct prediction
Energy consumption = 158.793786 pJ
sum error= 101
Actual label: 6
Output voltages: [0.3417, 0.020782, 0.18562, 0.0011507, 0.36625, 0.03356, 0.79867, 0.019796, 0.10306, 0.0039246]
Predicted label: 6
Correct prediction
Energy consumption = 145.918103 pJ
sum error= 101
Actual label: 1
Output voltages: [0.062305, 0.76025, 0.053901, 0.72336, 0.031747, 0.0011809, 0.0033159, 0.044192, 0.73995, 0.057274]
Predicted label: 1
Correct prediction
Energy consumption = 164.750348 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 191 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 191 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 191 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.035744, 0.0010693, 0.0060569, 0.16012, 0.016479, 0.79801, 0.26434, 0.046817, 0.75406, 0.085344]
Predicted label: 5
Correct prediction
Energy consumption = 147.953983 pJ
sum error= 101
Actual label: 5
Output voltages: [0.75472, 0.0016032, 0.011844, 0.16601, 0.0079152, 0.78777, 0.75881, 0.017651, 0.3855, 0.032023]
Predicted label: 5
Correct prediction
Energy consumption = 147.675990 pJ
sum error= 101
Actual label: 8
Output voltages: [0.023132, 0.060542, 0.022925, 0.011053, 0.024212, 0.4581, 0.0082486, 0.058506, 0.79868, 0.025116]
Predicted label: 8
Correct prediction
Energy consumption = 154.252796 pJ
sum error= 101
Actual label: 3
Output voltages: [0.52021, 0.0099744, 0.023579, 0.79867, 0.0038298, 0.010502, 0.027399, 0.06181, 0.56213, 0.063277]
Predicted label: 3
Correct prediction
Energy consumption = 152.392700 pJ
sum error= 101
Actual label: 8
Output voltages: [0.013912, 0.023676, 0.27756, 0.14373, 0.012485, 0.31686, 0.02931, 0.017725, 0.79863, 0.026394]
Predicted label: 8
Correct prediction
Energy consumption = 146.109145 pJ
sum error= 101
Actual label: 2
Output voltages: [0.15587, 0.088042, 0.79875, 0.25095, 0.013807, 0.0013776, 0.22408, 0.050535, 0.49748, 0.18015]
Predicted label: 2
Correct prediction
Energy consumption = 148.407450 pJ
sum error= 101
Actual label: 6
Output voltages: [0.20312, 0.02208, 0.03034, 0.0026909, 0.2019, 0.10924, 0.79872, 0.012005, 0.78265, 0.0022602]
Predicted label: 6
Correct prediction
Energy consumption = 149.413890 pJ
sum error= 101
Actual label: 5
Output voltages: [0.0309, 0.001108, 0.011724, 0.3221, 0.020081, 0.79813, 0.042531, 0.040941, 0.79662, 0.012459]
Predicted label: 5
Correct prediction
Energy consumption = 139.678697 pJ
sum error= 101
Actual label: 0
Output voltages: [0.798, 0.046495, 0.16558, 0.020117, 0.019294, 0.002292, 0.67905, 0.036025, 0.17642, 0.13733]
Predicted label: 0
Correct prediction
Energy consumption = 158.620389 pJ
sum error= 101
Actual label: 7
Output voltages: [0.038175, 0.056528, 0.14802, 0.17849, 0.0024989, 0.0039141, 0.0011119, 0.79871, 0.62238, 0.36]
Predicted label: 7
Correct prediction
Energy consumption = 154.043308 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 192 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 192 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 192 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.019253, 0.026299, 0.095095, 0.13677, 0.79876, 0.001092, 0.012634, 0.25828, 0.0050479, 0.22537]
Predicted label: 4
Correct prediction
Energy consumption = 149.410457 pJ
sum error= 101
Actual label: 6
Output voltages: [0.043053, 0.063826, 0.20166, 0.0012749, 0.33841, 0.25096, 0.79876, 0.0014602, 0.71335, 0.0043452]
Predicted label: 6
Correct prediction
Energy consumption = 146.286238 pJ
sum error= 101
Actual label: 1
Output voltages: [0.037302, 0.79845, 0.010115, 0.060203, 0.011135, 0.0040181, 0.72464, 0.0011726, 0.1564, 0.029022]
Predicted label: 1
Correct prediction
Energy consumption = 158.619787 pJ
sum error= 101
Actual label: 3
Output voltages: [0.3547, 0.056335, 0.035613, 0.79866, 0.01376, 0.0020925, 0.04518, 0.020906, 0.70452, 0.030796]
Predicted label: 3
Correct prediction
Energy consumption = 146.473563 pJ
sum error= 101
Actual label: 4
Output voltages: [0.0057313, 0.0011956, 0.35442, 0.0052071, 0.7986, 0.0050554, 0.056621, 0.00645, 0.23907, 0.54051]
Predicted label: 4
Correct prediction
Energy consumption = 151.799618 pJ
sum error= 101
Actual label: 7
Output voltages: [0.15187, 0.025176, 0.069671, 0.050911, 0.015758, 0.0011582, 0.0010668, 0.79861, 0.088512, 0.20518]
Predicted label: 7
Correct prediction
Energy consumption = 156.449948 pJ
sum error= 101
Actual label: 3
Output voltages: [0.047814, 0.0066095, 0.07101, 0.79877, 0.049235, 0.041425, 0.042962, 0.10028, 0.68118, 0.045159]
Predicted label: 3
Correct prediction
Energy consumption = 137.312543 pJ
sum error= 101
Actual label: 2
Output voltages: [0.31712, 0.078046, 0.79878, 0.043356, 0.0043522, 0.0012932, 0.1783, 0.049857, 0.73643, 0.020691]
Predicted label: 2
Correct prediction
Energy consumption = 146.982218 pJ
sum error= 101
Actual label: 3
Output voltages: [0.22082, 0.021222, 0.074759, 0.79863, 0.013756, 0.054394, 0.0067552, 0.12651, 0.6739, 0.061462]
Predicted label: 3
Correct prediction
Energy consumption = 135.400451 pJ
sum error= 101
Actual label: 4
Output voltages: [0.042493, 0.012698, 0.04986, 0.012626, 0.79876, 0.0010707, 0.051026, 0.195, 0.021092, 0.28501]
Predicted label: 4
Correct prediction
Energy consumption = 154.956815 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 193 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 193 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 193 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.22644, 0.016822, 0.79872, 0.32959, 0.37991, 0.0010745, 0.030086, 0.19169, 0.35648, 0.023823]
Predicted label: 2
Correct prediction
Energy consumption = 144.844789 pJ
sum error= 101
Actual label: 5
Output voltages: [0.05154, 0.0011223, 0.011089, 0.35447, 0.048646, 0.79874, 0.23876, 0.056104, 0.77053, 0.087762]
Predicted label: 5
Correct prediction
Energy consumption = 150.264992 pJ
sum error= 101
Actual label: 2
Output voltages: [0.34695, 0.028257, 0.79875, 0.33236, 0.02292, 0.0011195, 0.042189, 0.50103, 0.44578, 0.025849]
Predicted label: 2
Correct prediction
Energy consumption = 146.309581 pJ
sum error= 101
Actual label: 7
Output voltages: [0.23709, 0.0041977, 0.10635, 0.51622, 0.0143, 0.0011865, 0.0010664, 0.79444, 0.4687, 0.1832]
Predicted label: 7
Correct prediction
Energy consumption = 145.573926 pJ
sum error= 101
Actual label: 1
Output voltages: [0.023434, 0.79853, 0.017458, 0.024887, 0.0087666, 0.0017216, 0.5222, 0.020963, 0.3994, 0.01718]
Predicted label: 1
Correct prediction
Energy consumption = 160.657652 pJ
sum error= 101
Actual label: 7
Output voltages: [0.28, 0.022091, 0.041005, 0.057753, 0.0052112, 0.0068416, 0.0011608, 0.79867, 0.47418, 0.40382]
Predicted label: 7
Correct prediction
Energy consumption = 150.035952 pJ
sum error= 101
Actual label: 2
Output voltages: [0.72826, 0.0098503, 0.79879, 0.16223, 0.025644, 0.0010945, 0.047799, 0.063461, 0.50923, 0.021416]
Predicted label: 2
Correct prediction
Energy consumption = 145.996356 pJ
sum error= 101
Actual label: 6
Output voltages: [0.084669, 0.017112, 0.023527, 0.0037308, 0.35615, 0.44093, 0.79878, 0.010342, 0.75955, 0.0059341]
Predicted label: 6
Correct prediction
Energy consumption = 155.893427 pJ
sum error= 101
Actual label: 4
Output voltages: [0.033801, 0.0024533, 0.25972, 0.010243, 0.79877, 0.0013461, 0.72744, 0.026142, 0.012396, 0.048428]
Predicted label: 4
Correct prediction
Energy consumption = 150.935895 pJ
sum error= 101
Actual label: 1
Output voltages: [0.015474, 0.79848, 0.034881, 0.056533, 0.022504, 0.0090928, 0.64497, 0.026916, 0.42013, 0.032173]
Predicted label: 1
Correct prediction
Energy consumption = 161.567733 pJ
sum error= 101
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 194 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 194 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 194 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.62837, 0.0052883, 0.0011123, 0.14938, 0.030426, 0.79879, 0.3628, 0.0061281, 0.57856, 0.054741]
Predicted label: 5
Correct prediction
Energy consumption = 151.256376 pJ
sum error= 101
Actual label: 7
Output voltages: [0.04585, 0.0016998, 0.69404, 0.099702, 0.0058082, 0.0023735, 0.0017499, 0.79879, 0.22498, 0.076989]
Predicted label: 7
Correct prediction
Energy consumption = 138.156384 pJ
sum error= 101
Actual label: 8
Output voltages: [0.0018551, 0.022772, 0.17723, 0.0057235, 0.22908, 0.027539, 0.037835, 0.0087692, 0.79877, 0.066939]
Predicted label: 8
Correct prediction
Energy consumption = 152.962763 pJ
sum error= 101
Actual label: 6
Output voltages: [0.30883, 0.033317, 0.019636, 0.019675, 0.13521, 0.38093, 0.79848, 0.068772, 0.78043, 0.0031167]
Predicted label: 6
Correct prediction
Energy consumption = 150.884408 pJ
sum error= 101
Actual label: 0
Output voltages: [0.79859, 0.107, 0.034971, 0.013461, 0.0020071, 0.0035525, 0.58361, 0.034718, 0.23434, 0.10004]
Predicted label: 0
Correct prediction
Energy consumption = 135.528519 pJ
sum error= 101
Actual label: 1
Output voltages: [0.027321, 0.79859, 0.10206, 0.16833, 0.041383, 0.0010724, 0.43542, 0.0021039, 0.34619, 0.0063146]
Predicted label: 1
Correct prediction
Energy consumption = 160.352687 pJ
sum error= 101
Actual label: 8
Output voltages: [0.014523, 0.01144, 0.056452, 0.045683, 0.01056, 0.063089, 0.016186, 0.018176, 0.79868, 0.016017]
Predicted label: 8
Correct prediction
Energy consumption = 150.828086 pJ
sum error= 101
Actual label: 2
Output voltages: [0.29842, 0.021136, 0.79863, 0.014141, 0.0088721, 0.0011365, 0.14823, 0.046699, 0.50644, 0.0045157]
Predicted label: 2
Correct prediction
Energy consumption = 140.306475 pJ
sum error= 101
Actual label: 5
Output voltages: [0.42528, 0.001502, 0.0014665, 0.54294, 0.17521, 0.77085, 0.0010971, 0.77871, 0.41874, 0.15825]
Predicted label: 7
Wrong prediction!
Energy consumption = 148.829320 pJ
sum error= 102
Actual label: 7
Output voltages: [0.32036, 0.020465, 0.43535, 0.014202, 0.0070204, 0.0011142, 0.0012931, 0.79879, 0.11825, 0.029154]
Predicted label: 7
Correct prediction
Energy consumption = 146.784113 pJ
sum error= 102
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 195 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 195 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 195 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.21446, 0.015605, 0.01737, 0.049346, 0.013752, 0.01065, 0.0011069, 0.79859, 0.13774, 0.2581]
Predicted label: 7
Correct prediction
Energy consumption = 152.523231 pJ
sum error= 102
Actual label: 6
Output voltages: [0.040082, 0.019666, 0.40391, 0.0010783, 0.61471, 0.27487, 0.79871, 0.0014104, 0.49528, 0.0036337]
Predicted label: 6
Correct prediction
Energy consumption = 151.907587 pJ
sum error= 102
Actual label: 9
Output voltages: [0.1503, 0.0044664, 0.041425, 0.54494, 0.30915, 0.0060283, 0.0010849, 0.012679, 0.05949, 0.7983]
Predicted label: 9
Correct prediction
Energy consumption = 158.979056 pJ
sum error= 102
Actual label: 3
Output voltages: [0.19725, 0.023464, 0.056633, 0.79874, 0.0066255, 0.032674, 0.0086924, 0.041063, 0.71679, 0.085881]
Predicted label: 3
Correct prediction
Energy consumption = 149.309472 pJ
sum error= 102
Actual label: 5
Output voltages: [0.12659, 0.0011344, 0.0095676, 0.23905, 0.0023023, 0.79853, 0.10774, 0.029087, 0.69257, 0.05525]
Predicted label: 5
Correct prediction
Energy consumption = 144.664422 pJ
sum error= 102
Actual label: 8
Output voltages: [0.33674, 0.013206, 0.24637, 0.6356, 0.0073156, 0.0011542, 0.040032, 0.0010797, 0.79617, 0.32334]
Predicted label: 8
Correct prediction
Energy consumption = 152.125521 pJ
sum error= 102
Actual label: 4
Output voltages: [0.048008, 0.020161, 0.23795, 0.0049604, 0.79873, 0.0011217, 0.34076, 0.025679, 0.015901, 0.34688]
Predicted label: 4
Correct prediction
Energy consumption = 148.277187 pJ
sum error= 102
Actual label: 2
Output voltages: [0.55677, 0.18404, 0.79876, 0.047349, 0.13351, 0.0010662, 0.23276, 0.01958, 0.27266, 0.017807]
Predicted label: 2
Correct prediction
Energy consumption = 143.289737 pJ
sum error= 102
Actual label: 4
Output voltages: [0.0064503, 0.017647, 0.19735, 0.0063703, 0.7986, 0.0028103, 0.036361, 0.16785, 0.027244, 0.12494]
Predicted label: 4
Correct prediction
Energy consumption = 157.693872 pJ
sum error= 102
Actual label: 0
Output voltages: [0.79875, 0.039432, 0.11866, 0.014915, 0.028948, 0.011134, 0.60347, 0.037351, 0.034787, 0.21624]
Predicted label: 0
Correct prediction
Energy consumption = 161.839397 pJ
sum error= 102
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 196 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 196 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 196 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.023313, 0.024597, 0.47735, 0.083334, 0.010208, 0.033208, 0.020914, 0.0043943, 0.79871, 0.17596]
Predicted label: 8
Correct prediction
Energy consumption = 149.327032 pJ
sum error= 102
Actual label: 8
Output voltages: [0.14941, 0.022572, 0.20529, 0.28988, 0.0096583, 0.01715, 0.045248, 0.008059, 0.79879, 0.011728]
Predicted label: 8
Correct prediction
Energy consumption = 148.136423 pJ
sum error= 102
Actual label: 3
Output voltages: [0.082014, 0.0072012, 0.079356, 0.79874, 0.0067453, 0.040003, 0.0045817, 0.033332, 0.75633, 0.024064]
Predicted label: 3
Correct prediction
Energy consumption = 141.975713 pJ
sum error= 102
Actual label: 4
Output voltages: [0.0069059, 0.0089632, 0.29344, 0.027836, 0.7987, 0.0012287, 0.26993, 0.21597, 0.01647, 0.29504]
Predicted label: 4
Correct prediction
Energy consumption = 157.653799 pJ
sum error= 102
Actual label: 9
Output voltages: [0.22865, 0.03026, 0.018289, 0.12235, 0.26852, 0.020932, 0.015507, 0.10239, 0.022199, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 155.110996 pJ
sum error= 102
Actual label: 2
Output voltages: [0.27537, 0.72082, 0.79879, 0.053801, 0.012907, 0.0011793, 0.041701, 0.13663, 0.025573, 0.029011]
Predicted label: 2
Correct prediction
Energy consumption = 158.378263 pJ
sum error= 102
Actual label: 7
Output voltages: [0.28657, 0.0052335, 0.031607, 0.34246, 0.0047354, 0.0044908, 0.001146, 0.79876, 0.74816, 0.39419]
Predicted label: 7
Correct prediction
Energy consumption = 146.614404 pJ
sum error= 102
Actual label: 5
Output voltages: [0.074639, 0.0013105, 0.011485, 0.26539, 0.005891, 0.79865, 0.12458, 0.017532, 0.70858, 0.04603]
Predicted label: 5
Correct prediction
Energy consumption = 145.082034 pJ
sum error= 102
Actual label: 8
Output voltages: [0.011979, 0.14018, 0.022364, 0.51147, 0.0024817, 0.036151, 0.037678, 0.0010758, 0.79873, 0.39202]
Predicted label: 8
Correct prediction
Energy consumption = 144.212965 pJ
sum error= 102
Actual label: 6
Output voltages: [0.4834, 0.086637, 0.11711, 0.0080718, 0.055055, 0.035437, 0.79848, 0.0011461, 0.39562, 0.002482]
Predicted label: 6
Correct prediction
Energy consumption = 154.850111 pJ
sum error= 102
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 197 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 197 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 197 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.034742, 0.001335, 0.009235, 0.19179, 0.036749, 0.79871, 0.095914, 0.025348, 0.77346, 0.33998]
Predicted label: 5
Correct prediction
Energy consumption = 144.808897 pJ
sum error= 102
Actual label: 6
Output voltages: [0.022135, 0.094675, 0.27249, 0.0010711, 0.057156, 0.21176, 0.79875, 0.0021916, 0.73303, 0.011623]
Predicted label: 6
Correct prediction
Energy consumption = 143.763142 pJ
sum error= 102
Actual label: 0
Output voltages: [0.79874, 0.16442, 0.11369, 0.048813, 0.0034836, 0.0026283, 0.29107, 0.0048925, 0.27466, 0.094449]
Predicted label: 0
Correct prediction
Energy consumption = 150.471871 pJ
sum error= 102
Actual label: 8
Output voltages: [0.45795, 0.0048706, 0.36832, 0.60435, 0.0091668, 0.25596, 0.017947, 0.0029989, 0.79878, 0.054209]
Predicted label: 8
Correct prediction
Energy consumption = 149.332660 pJ
sum error= 102
Actual label: 6
Output voltages: [0.050429, 0.022381, 0.21372, 0.008203, 0.34905, 0.092469, 0.79876, 0.0028516, 0.59776, 0.012166]
Predicted label: 6
Correct prediction
Energy consumption = 149.477416 pJ
sum error= 102
Actual label: 7
Output voltages: [0.026045, 0.086009, 0.2508, 0.015018, 0.06128, 0.0010727, 0.0011626, 0.79855, 0.12399, 0.05947]
Predicted label: 7
Correct prediction
Energy consumption = 146.979749 pJ
sum error= 102
Actual label: 3
Output voltages: [0.22663, 0.0098478, 0.28523, 0.79877, 0.041014, 0.037942, 0.013983, 0.026953, 0.42871, 0.27977]
Predicted label: 3
Correct prediction
Energy consumption = 147.603510 pJ
sum error= 102
Actual label: 6
Output voltages: [0.23676, 0.014743, 0.029381, 0.0013123, 0.32812, 0.29757, 0.79869, 0.0011412, 0.37774, 0.011088]
Predicted label: 6
Correct prediction
Energy consumption = 146.741315 pJ
sum error= 102
Actual label: 4
Output voltages: [0.0043272, 0.018637, 0.026869, 0.007587, 0.7987, 0.0032946, 0.2056, 0.39056, 0.27819, 0.0045791]
Predicted label: 4
Correct prediction
Energy consumption = 153.165002 pJ
sum error= 102
Actual label: 9
Output voltages: [0.38276, 0.0071808, 0.043249, 0.050493, 0.50359, 0.046499, 0.054735, 0.044114, 0.021881, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 152.914908 pJ
sum error= 102
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 198 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 198 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 198 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.010619, 0.0096776, 0.015627, 0.015499, 0.79863, 0.0010672, 0.04286, 0.13891, 0.029169, 0.017517]
Predicted label: 4
Correct prediction
Energy consumption = 158.634217 pJ
sum error= 102
Actual label: 6
Output voltages: [0.20022, 0.090212, 0.16158, 0.0013781, 0.047325, 0.17142, 0.79875, 0.0020278, 0.036498, 0.015204]
Predicted label: 6
Correct prediction
Energy consumption = 147.595907 pJ
sum error= 102
Actual label: 6
Output voltages: [0.045002, 0.001218, 0.015358, 0.024662, 0.29441, 0.57567, 0.78102, 0.0047938, 0.78495, 0.011051]
Predicted label: 8
Wrong prediction!
Energy consumption = 137.294831 pJ
sum error= 103
Actual label: 3
Output voltages: [0.22977, 0.018576, 0.36756, 0.79878, 0.01856, 0.0010852, 0.012303, 0.0022515, 0.57557, 0.028119]
Predicted label: 3
Correct prediction
Energy consumption = 150.192754 pJ
sum error= 103
Actual label: 2
Output voltages: [0.78548, 0.27401, 0.77218, 0.028641, 0.0012202, 0.014713, 0.10363, 0.0027657, 0.45485, 0.018691]
Predicted label: 0
Wrong prediction!
Energy consumption = 143.742571 pJ
sum error= 104
Actual label: 4
Output voltages: [0.0032971, 0.011221, 0.014093, 0.0040295, 0.79877, 0.0011299, 0.30578, 0.12572, 0.033895, 0.012437]
Predicted label: 4
Correct prediction
Energy consumption = 155.294142 pJ
sum error= 104
Actual label: 1
Output voltages: [0.022838, 0.79843, 0.29767, 0.054344, 0.047659, 0.0025875, 0.59579, 0.0046814, 0.066587, 0.12876]
Predicted label: 1
Correct prediction
Energy consumption = 158.540115 pJ
sum error= 104
Actual label: 0
Output voltages: [0.79879, 0.034291, 0.035265, 0.0081644, 0.0068353, 0.0024162, 0.50039, 0.02765, 0.10449, 0.16351]
Predicted label: 0
Correct prediction
Energy consumption = 144.952936 pJ
sum error= 104
Actual label: 1
Output voltages: [0.042376, 0.79864, 0.51496, 0.024393, 0.076803, 0.0010719, 0.50253, 0.0010836, 0.013215, 0.058362]
Predicted label: 1
Correct prediction
Energy consumption = 160.642328 pJ
sum error= 104
Actual label: 4
Output voltages: [0.025595, 0.27322, 0.11067, 0.027201, 0.79876, 0.0011045, 0.42391, 0.012065, 0.001475, 0.070129]
Predicted label: 4
Correct prediction
Energy consumption = 151.045857 pJ
sum error= 104
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 199 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 199 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 199 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.39258, 0.042845, 0.062012, 0.0071936, 0.40361, 0.39355, 0.79879, 0.0037848, 0.28137, 0.0023169]
Predicted label: 6
Correct prediction
Energy consumption = 150.538853 pJ
sum error= 104
Actual label: 2
Output voltages: [0.61515, 0.031648, 0.79879, 0.14116, 0.0046751, 0.0011369, 0.07474, 0.049387, 0.50036, 0.021431]
Predicted label: 2
Correct prediction
Energy consumption = 149.855343 pJ
sum error= 104
Actual label: 9
Output voltages: [0.072885, 0.0075065, 0.030799, 0.019406, 0.0222, 0.0081792, 0.0018326, 0.030731, 0.79458, 0.78608]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.299235 pJ
sum error= 105
Actual label: 1
Output voltages: [0.25974, 0.79752, 0.29254, 0.010783, 0.0080689, 0.0010876, 0.2787, 0.0023596, 0.35946, 0.018047]
Predicted label: 1
Correct prediction
Energy consumption = 144.612792 pJ
sum error= 105
Actual label: 1
Output voltages: [0.012379, 0.7985, 0.063886, 0.020731, 0.08349, 0.0085288, 0.35458, 0.0065024, 0.24294, 0.074753]
Predicted label: 1
Correct prediction
Energy consumption = 160.186486 pJ
sum error= 105
Actual label: 0
Output voltages: [0.79863, 0.3127, 0.066169, 0.1746, 0.0063504, 0.080133, 0.21683, 0.003137, 0.33929, 0.093001]
Predicted label: 0
Correct prediction
Energy consumption = 153.948194 pJ
sum error= 105
Actual label: 6
Output voltages: [0.10285, 0.013818, 0.022233, 0.011661, 0.35276, 0.57823, 0.79879, 0.0011259, 0.77645, 0.010944]
Predicted label: 6
Correct prediction
Energy consumption = 145.104743 pJ
sum error= 105
Actual label: 3
Output voltages: [0.35496, 0.028578, 0.025449, 0.79865, 0.0092911, 0.0099266, 0.02155, 0.0049948, 0.45661, 0.067851]
Predicted label: 3
Correct prediction
Energy consumption = 145.984504 pJ
sum error= 105
Actual label: 9
Output voltages: [0.36752, 0.0091051, 0.022628, 0.15861, 0.31706, 0.041173, 0.018362, 0.0067145, 0.15779, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 154.155172 pJ
sum error= 105
Actual label: 5
Output voltages: [0.04525, 0.0010667, 0.025259, 0.34396, 0.0037988, 0.79674, 0.0087583, 0.025995, 0.79618, 0.060272]
Predicted label: 5
Correct prediction
Energy consumption = 146.117443 pJ
sum error= 105
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 200 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 200 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 200 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.050318, 0.0086411, 0.15817, 0.0044064, 0.3775, 0.42624, 0.79879, 0.0027641, 0.60862, 0.0082242]
Predicted label: 6
Correct prediction
Energy consumption = 148.287887 pJ
sum error= 105
Actual label: 5
Output voltages: [0.02161, 0.0026393, 0.024754, 0.074624, 0.0054957, 0.79714, 0.031604, 0.023453, 0.79847, 0.030942]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.002099 pJ
sum error= 106
Actual label: 6
Output voltages: [0.286, 0.012257, 0.10472, 0.010662, 0.37948, 0.36039, 0.79878, 0.0013407, 0.59008, 0.01161]
Predicted label: 6
Correct prediction
Energy consumption = 147.206494 pJ
sum error= 106
Actual label: 5
Output voltages: [0.016384, 0.0011047, 0.0010749, 0.17842, 0.04882, 0.79811, 0.36331, 0.015398, 0.58662, 0.040421]
Predicted label: 5
Correct prediction
Energy consumption = 149.955814 pJ
sum error= 106
Actual label: 8
Output voltages: [0.030604, 0.039604, 0.17827, 0.48687, 0.0014967, 0.08876, 0.0049161, 0.046113, 0.79877, 0.049162]
Predicted label: 8
Correct prediction
Energy consumption = 148.368521 pJ
sum error= 106
Actual label: 4
Output voltages: [0.02213, 0.0069975, 0.22821, 0.0027326, 0.79864, 0.0013891, 0.40883, 0.043765, 0.021001, 0.026424]
Predicted label: 4
Correct prediction
Energy consumption = 154.578812 pJ
sum error= 106
Actual label: 6
Output voltages: [0.046356, 0.06766, 0.20895, 0.0054977, 0.050024, 0.044033, 0.79879, 0.0017595, 0.58248, 0.011256]
Predicted label: 6
Correct prediction
Energy consumption = 149.140575 pJ
sum error= 106
Actual label: 4
Output voltages: [0.018853, 0.019573, 0.13282, 0.0062115, 0.79855, 0.0071181, 0.10316, 0.041906, 0.047679, 0.10609]
Predicted label: 4
Correct prediction
Energy consumption = 156.967964 pJ
sum error= 106
Actual label: 3
Output voltages: [0.12976, 0.034058, 0.049929, 0.79863, 0.032087, 0.0059603, 0.01299, 0.020411, 0.47921, 0.045654]
Predicted label: 3
Correct prediction
Energy consumption = 140.882735 pJ
sum error= 106
Actual label: 9
Output voltages: [0.42615, 0.0041994, 0.028679, 0.011258, 0.043001, 0.0047076, 0.033704, 0.033203, 0.49728, 0.79378]
Predicted label: 9
Correct prediction
Energy consumption = 144.660747 pJ
sum error= 106
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 201 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 201 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 201 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.042507, 0.79865, 0.039603, 0.22152, 0.12821, 0.018007, 0.70176, 0.001116, 0.0068154, 0.090866]
Predicted label: 1
Correct prediction
Energy consumption = 160.916716 pJ
sum error= 106
Actual label: 3
Output voltages: [0.053975, 0.045547, 0.044386, 0.79859, 0.02446, 0.0033292, 0.010207, 0.026998, 0.36316, 0.20044]
Predicted label: 3
Correct prediction
Energy consumption = 154.627066 pJ
sum error= 106
Actual label: 4
Output voltages: [0.0012209, 0.023642, 0.28966, 0.0023771, 0.79879, 0.0016811, 0.14761, 0.27723, 0.023276, 0.12294]
Predicted label: 4
Correct prediction
Energy consumption = 156.251882 pJ
sum error= 106
Actual label: 1
Output voltages: [0.032337, 0.79856, 0.022079, 0.27119, 0.04645, 0.009137, 0.24974, 0.0013293, 0.39352, 0.042405]
Predicted label: 1
Correct prediction
Energy consumption = 159.349720 pJ
sum error= 106
Actual label: 9
Output voltages: [0.2849, 0.018649, 0.034419, 0.24837, 0.50346, 0.021213, 0.022132, 0.0031652, 0.049147, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 153.232484 pJ
sum error= 106
Actual label: 1
Output voltages: [0.031921, 0.79864, 0.22591, 0.34417, 0.095946, 0.0037342, 0.40493, 0.0011297, 0.096606, 0.41382]
Predicted label: 1
Correct prediction
Energy consumption = 159.419784 pJ
sum error= 106
Actual label: 7
Output voltages: [0.16229, 0.0015934, 0.7957, 0.22261, 0.0028678, 0.0011197, 0.0032371, 0.75014, 0.7718, 0.012826]
Predicted label: 2
Wrong prediction!
Energy consumption = 143.107782 pJ
sum error= 107
Actual label: 1
Output voltages: [0.045656, 0.79871, 0.0048989, 0.050583, 0.29164, 0.0014937, 0.017771, 0.026833, 0.49948, 0.052338]
Predicted label: 1
Correct prediction
Energy consumption = 164.653591 pJ
sum error= 107
Actual label: 1
Output voltages: [0.47733, 0.58181, 0.263, 0.085812, 0.0024132, 0.0011256, 0.012995, 0.72391, 0.76691, 0.0015578]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.247503 pJ
sum error= 108
Actual label: 9
Output voltages: [0.41644, 0.0094244, 0.03069, 0.022068, 0.30738, 0.0067575, 0.0012359, 0.019526, 0.48245, 0.79819]
Predicted label: 9
Correct prediction
Energy consumption = 151.510353 pJ
sum error= 108
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 202 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 202 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 202 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.087595, 0.0019353, 0.17538, 0.79874, 0.047544, 0.24111, 0.023729, 0.016465, 0.45042, 0.039346]
Predicted label: 3
Correct prediction
Energy consumption = 145.365996 pJ
sum error= 108
Actual label: 5
Output voltages: [0.027996, 0.0010666, 0.0025281, 0.29878, 0.10296, 0.79398, 0.092625, 0.011343, 0.77404, 0.25396]
Predicted label: 5
Correct prediction
Energy consumption = 141.046141 pJ
sum error= 108
Actual label: 4
Output voltages: [0.0023056, 0.009186, 0.32414, 0.026541, 0.79866, 0.0026909, 0.24011, 0.041232, 0.018125, 0.040061]
Predicted label: 4
Correct prediction
Energy consumption = 159.088843 pJ
sum error= 108
Actual label: 0
Output voltages: [0.79877, 0.18862, 0.10026, 0.027133, 0.0010835, 0.048414, 0.39157, 0.0035773, 0.24075, 0.049558]
Predicted label: 0
Correct prediction
Energy consumption = 158.958246 pJ
sum error= 108
Actual label: 7
Output voltages: [0.42373, 0.4233, 0.015223, 0.0045596, 0.0060251, 0.0021127, 0.0065405, 0.79749, 0.28907, 0.46447]
Predicted label: 7
Correct prediction
Energy consumption = 162.022422 pJ
sum error= 108
Actual label: 3
Output voltages: [0.40126, 0.0054008, 0.10443, 0.79872, 0.0018231, 0.020867, 0.14597, 0.0086606, 0.57906, 0.0085902]
Predicted label: 3
Correct prediction
Energy consumption = 155.451442 pJ
sum error= 108
Actual label: 6
Output voltages: [0.05038, 0.01906, 0.2397, 0.0019315, 0.23329, 0.22442, 0.79872, 0.0051491, 0.67576, 0.0045185]
Predicted label: 6
Correct prediction
Energy consumption = 142.943652 pJ
sum error= 108
Actual label: 1
Output voltages: [0.019055, 0.79863, 0.0010752, 0.10861, 0.012466, 0.30262, 0.53312, 0.0081864, 0.23826, 0.037643]
Predicted label: 1
Correct prediction
Energy consumption = 159.593316 pJ
sum error= 108
Actual label: 7
Output voltages: [0.039085, 0.46078, 0.24632, 0.042112, 0.0093021, 0.002598, 0.0011931, 0.79852, 0.45246, 0.006228]
Predicted label: 7
Correct prediction
Energy consumption = 144.002897 pJ
sum error= 108
Actual label: 5
Output voltages: [0.10827, 0.0043732, 0.0010774, 0.075245, 0.0048013, 0.79227, 0.28455, 0.2991, 0.49891, 0.042798]
Predicted label: 5
Correct prediction
Energy consumption = 161.970593 pJ
sum error= 108
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 203 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 203 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 203 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.0025855, 0.0011105, 0.0035201, 0.16176, 0.29292, 0.79677, 0.5641, 0.0088898, 0.76532, 0.087157]
Predicted label: 5
Correct prediction
Energy consumption = 144.316374 pJ
sum error= 108
Actual label: 3
Output voltages: [0.06918, 0.012536, 0.43737, 0.79877, 0.036584, 0.0057538, 0.031802, 0.035492, 0.7629, 0.1597]
Predicted label: 3
Correct prediction
Energy consumption = 139.943483 pJ
sum error= 108
Actual label: 3
Output voltages: [0.2136, 0.017458, 0.049038, 0.79862, 0.018539, 0.013824, 0.019097, 0.047705, 0.51141, 0.095227]
Predicted label: 3
Correct prediction
Energy consumption = 130.895519 pJ
sum error= 108
Actual label: 0
Output voltages: [0.79848, 0.018995, 0.36679, 0.011713, 0.027792, 0.0010735, 0.033842, 0.047156, 0.47555, 0.24693]
Predicted label: 0
Correct prediction
Energy consumption = 151.650437 pJ
sum error= 108
Actual label: 1
Output voltages: [0.01205, 0.79846, 0.0040352, 0.61711, 0.013434, 0.10873, 0.098418, 0.037757, 0.39961, 0.2918]
Predicted label: 1
Correct prediction
Energy consumption = 167.470730 pJ
sum error= 108
Actual label: 5
Output voltages: [0.029662, 0.0032962, 0.02069, 0.79818, 0.25683, 0.78934, 0.048919, 0.026793, 0.17853, 0.010632]
Predicted label: 3
Wrong prediction!
Energy consumption = 146.418932 pJ
sum error= 109
Actual label: 7
Output voltages: [0.15707, 0.031793, 0.0221, 0.026314, 0.018522, 0.0059746, 0.0010666, 0.79866, 0.042028, 0.59326]
Predicted label: 7
Correct prediction
Energy consumption = 154.820064 pJ
sum error= 109
Actual label: 5
Output voltages: [0.4112, 0.0011834, 0.010143, 0.32929, 0.0064424, 0.79701, 0.25159, 0.043428, 0.74575, 0.043232]
Predicted label: 5
Correct prediction
Energy consumption = 145.599970 pJ
sum error= 109
Actual label: 8
Output voltages: [0.015862, 0.65256, 0.051677, 0.29041, 0.0039805, 0.0085522, 0.044306, 0.0026551, 0.79877, 0.26319]
Predicted label: 8
Correct prediction
Energy consumption = 151.730012 pJ
sum error= 109
Actual label: 6
Output voltages: [0.05917, 0.25665, 0.43592, 0.0026101, 0.020692, 0.027457, 0.79879, 0.0017813, 0.68852, 0.010138]
Predicted label: 6
Correct prediction
Energy consumption = 150.068446 pJ
sum error= 109
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 204 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 204 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 204 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.39933, 0.0012877, 0.0010909, 0.286, 0.0465, 0.79865, 0.4845, 0.001066, 0.75097, 0.0019963]
Predicted label: 5
Correct prediction
Energy consumption = 140.308310 pJ
sum error= 109
Actual label: 1
Output voltages: [0.081666, 0.79848, 0.21624, 0.040398, 0.018231, 0.0011382, 0.41587, 0.01129, 0.062248, 0.037992]
Predicted label: 1
Correct prediction
Energy consumption = 164.298176 pJ
sum error= 109
Actual label: 0
Output voltages: [0.79878, 0.12881, 0.048209, 0.025648, 0.028616, 0.0044068, 0.49189, 0.01318, 0.064035, 0.59797]
Predicted label: 0
Correct prediction
Energy consumption = 159.322382 pJ
sum error= 109
Actual label: 4
Output voltages: [0.001068, 0.12294, 0.017247, 0.0027351, 0.7754, 0.0052826, 0.29462, 0.018674, 0.66198, 0.088947]
Predicted label: 4
Correct prediction
Energy consumption = 150.407458 pJ
sum error= 109
Actual label: 2
Output voltages: [0.67199, 0.081958, 0.75273, 0.016876, 0.0012813, 0.0016635, 0.022, 0.56581, 0.71239, 0.041464]
Predicted label: 2
Correct prediction
Energy consumption = 151.451755 pJ
sum error= 109
Actual label: 3
Output voltages: [0.48646, 0.003669, 0.095554, 0.79869, 0.025067, 0.20891, 0.017962, 0.013891, 0.5586, 0.048322]
Predicted label: 3
Correct prediction
Energy consumption = 137.143715 pJ
sum error= 109
Actual label: 4
Output voltages: [0.011452, 0.0065008, 0.10385, 0.015543, 0.79873, 0.0042857, 0.081878, 0.06112, 0.25957, 0.011263]
Predicted label: 4
Correct prediction
Energy consumption = 151.991211 pJ
sum error= 109
Actual label: 6
Output voltages: [0.35006, 0.0051401, 0.040796, 0.00131, 0.17156, 0.30757, 0.7986, 0.0011932, 0.28586, 0.0096819]
Predicted label: 6
Correct prediction
Energy consumption = 144.834343 pJ
sum error= 109
Actual label: 7
Output voltages: [0.32401, 0.013809, 0.03284, 0.17859, 0.026352, 0.0012692, 0.0010685, 0.79866, 0.19857, 0.75789]
Predicted label: 7
Correct prediction
Energy consumption = 156.381835 pJ
sum error= 109
Actual label: 9
Output voltages: [0.39456, 0.0055291, 0.16023, 0.27581, 0.45597, 0.0014482, 0.051695, 0.0011579, 0.033068, 0.79859]
Predicted label: 9
Correct prediction
Energy consumption = 150.404999 pJ
sum error= 109
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 205 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 205 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 205 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.42161, 0.074071, 0.48272, 0.18214, 0.01168, 0.0021183, 0.026703, 0.0036126, 0.79851, 0.29186]
Predicted label: 8
Correct prediction
Energy consumption = 162.086056 pJ
sum error= 109
Actual label: 1
Output voltages: [0.030057, 0.79851, 0.19243, 0.48061, 0.29992, 0.0080769, 0.49885, 0.0046592, 0.016166, 0.025461]
Predicted label: 1
Correct prediction
Energy consumption = 159.893789 pJ
sum error= 109
Actual label: 8
Output voltages: [0.047285, 0.0071088, 0.080244, 0.0020103, 0.75697, 0.010141, 0.20192, 0.0013333, 0.7894, 0.0067159]
Predicted label: 8
Correct prediction
Energy consumption = 137.350353 pJ
sum error= 109
Actual label: 4
Output voltages: [0.021514, 0.0037391, 0.041012, 0.030232, 0.69579, 0.0028949, 0.0043985, 0.035142, 0.3061, 0.69466]
Predicted label: 4
Correct prediction
Energy consumption = 144.282414 pJ
sum error= 109
Actual label: 9
Output voltages: [0.49963, 0.013472, 0.027314, 0.056181, 0.10524, 0.024447, 0.0015834, 0.030347, 0.43831, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 140.724421 pJ
sum error= 109
Actual label: 2
Output voltages: [0.38084, 0.017084, 0.79874, 0.028793, 0.013448, 0.0011277, 0.071046, 0.041932, 0.47272, 0.020346]
Predicted label: 2
Correct prediction
Energy consumption = 146.043847 pJ
sum error= 109
Actual label: 8
Output voltages: [0.12811, 0.018584, 0.11643, 0.51106, 0.0042695, 0.0064766, 0.010799, 0.0010665, 0.79876, 0.27291]
Predicted label: 8
Correct prediction
Energy consumption = 144.641231 pJ
sum error= 109
Actual label: 6
Output voltages: [0.071729, 0.025888, 0.17382, 0.00271, 0.39541, 0.33632, 0.79874, 0.0045442, 0.22525, 0.0059839]
Predicted label: 6
Correct prediction
Energy consumption = 152.313140 pJ
sum error= 109
Actual label: 2
Output voltages: [0.66308, 0.0923, 0.79873, 0.016783, 0.0073082, 0.0012705, 0.043348, 0.44618, 0.21266, 0.022002]
Predicted label: 2
Correct prediction
Energy consumption = 144.125992 pJ
sum error= 109
Actual label: 7
Output voltages: [0.18611, 0.63186, 0.026103, 0.37441, 0.00397, 0.0011685, 0.0027107, 0.79828, 0.018801, 0.46035]
Predicted label: 7
Correct prediction
Energy consumption = 154.238656 pJ
sum error= 109
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 206 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 206 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 206 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79845, 0.053276, 0.036804, 0.021781, 0.026168, 0.011785, 0.77116, 0.052079, 0.14701, 0.047692]
Predicted label: 0
Correct prediction
Energy consumption = 153.119716 pJ
sum error= 109
Actual label: 0
Output voltages: [0.79878, 0.052801, 0.035338, 0.062038, 0.0075585, 0.0040156, 0.69381, 0.031832, 0.33871, 0.15255]
Predicted label: 0
Correct prediction
Energy consumption = 149.667592 pJ
sum error= 109
Actual label: 6
Output voltages: [0.032976, 0.1328, 0.41013, 0.0015421, 0.28008, 0.17954, 0.79863, 0.0027075, 0.30199, 0.018816]
Predicted label: 6
Correct prediction
Energy consumption = 139.163349 pJ
sum error= 109
Actual label: 7
Output voltages: [0.020665, 0.30867, 0.7929, 0.052393, 0.0063732, 0.0011342, 0.01613, 0.79243, 0.62543, 0.0018611]
Predicted label: 2
Wrong prediction!
Energy consumption = 141.793243 pJ
sum error= 110
Actual label: 5
Output voltages: [0.018131, 0.0010686, 0.0028727, 0.30602, 0.046441, 0.79878, 0.25342, 0.016251, 0.73273, 0.015649]
Predicted label: 5
Correct prediction
Energy consumption = 148.388815 pJ
sum error= 110
Actual label: 8
Output voltages: [0.02589, 0.011472, 0.050259, 0.25908, 0.01124, 0.052939, 0.019698, 0.0010739, 0.79853, 0.66942]
Predicted label: 8
Correct prediction
Energy consumption = 147.456916 pJ
sum error= 110
Actual label: 6
Output voltages: [0.36711, 0.028606, 0.030931, 0.010034, 0.43997, 0.63133, 0.79873, 0.0079371, 0.74641, 0.0013195]
Predicted label: 6
Correct prediction
Energy consumption = 149.892694 pJ
sum error= 110
Actual label: 0
Output voltages: [0.79868, 0.039699, 0.060923, 0.049072, 0.035534, 0.0061998, 0.50256, 0.032389, 0.32219, 0.033859]
Predicted label: 0
Correct prediction
Energy consumption = 150.272571 pJ
sum error= 110
Actual label: 9
Output voltages: [0.050539, 0.0011404, 0.06326, 0.010364, 0.75689, 0.36182, 0.039613, 0.014959, 0.18783, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 155.868399 pJ
sum error= 110
Actual label: 3
Output voltages: [0.48247, 0.036521, 0.18423, 0.79871, 0.032723, 0.021787, 0.1115, 0.013819, 0.3265, 0.032655]
Predicted label: 3
Correct prediction
Energy consumption = 148.739996 pJ
sum error= 110
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 207 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 207 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 207 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.19854, 0.026587, 0.019158, 0.0033268, 0.49975, 0.0010668, 0.15119, 0.023368, 0.18831, 0.76529]
Predicted label: 9
Wrong prediction!
Energy consumption = 163.649594 pJ
sum error= 111
Actual label: 1
Output voltages: [0.039939, 0.79844, 0.01744, 0.039139, 0.027913, 0.014975, 0.031131, 0.090128, 0.0032517, 0.3092]
Predicted label: 1
Correct prediction
Energy consumption = 159.423840 pJ
sum error= 111
Actual label: 3
Output voltages: [0.19826, 0.014661, 0.29915, 0.79879, 0.036191, 0.0011823, 0.012144, 0.003347, 0.75054, 0.021329]
Predicted label: 3
Correct prediction
Energy consumption = 145.285349 pJ
sum error= 111
Actual label: 5
Output voltages: [0.77596, 0.019418, 0.0010935, 0.55119, 0.0051473, 0.79127, 0.75921, 0.011437, 0.54268, 0.0099899]
Predicted label: 5
Correct prediction
Energy consumption = 151.471975 pJ
sum error= 111
Actual label: 4
Output voltages: [0.0058935, 0.004545, 0.011985, 0.0018142, 0.79875, 0.0048111, 0.1238, 0.2109, 0.32696, 0.023949]
Predicted label: 4
Correct prediction
Energy consumption = 147.760621 pJ
sum error= 111
Actual label: 3
Output voltages: [0.14585, 0.0066154, 0.046758, 0.79873, 0.035817, 0.0018247, 0.093276, 0.010668, 0.68104, 0.027487]
Predicted label: 3
Correct prediction
Energy consumption = 146.087357 pJ
sum error= 111
Actual label: 3
Output voltages: [0.15156, 0.018091, 0.15021, 0.79875, 0.040877, 0.0042346, 0.0055996, 0.002861, 0.47847, 0.039037]
Predicted label: 3
Correct prediction
Energy consumption = 138.245328 pJ
sum error= 111
Actual label: 5
Output voltages: [0.045319, 0.0025242, 0.011907, 0.56635, 0.022048, 0.79831, 0.03681, 0.050106, 0.7763, 0.099954]
Predicted label: 5
Correct prediction
Energy consumption = 139.121225 pJ
sum error= 111
Actual label: 5
Output voltages: [0.233, 0.0016818, 0.0011695, 0.3719, 0.030333, 0.79879, 0.40354, 0.0044492, 0.71911, 0.057835]
Predicted label: 5
Correct prediction
Energy consumption = 140.453095 pJ
sum error= 111
Actual label: 6
Output voltages: [0.126, 0.1102, 0.19238, 0.013633, 0.33188, 0.28067, 0.79878, 0.011969, 0.73646, 0.0028687]
Predicted label: 6
Correct prediction
Energy consumption = 152.768526 pJ
sum error= 111
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 208 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 208 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 208 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.043708, 0.02372, 0.088909, 0.79877, 0.0056571, 0.027701, 0.0014081, 0.16498, 0.78224, 0.018265]
Predicted label: 3
Correct prediction
Energy consumption = 142.475195 pJ
sum error= 111
Actual label: 0
Output voltages: [0.79878, 0.029561, 0.036269, 0.049988, 0.027412, 0.020891, 0.43429, 0.03179, 0.18914, 0.01126]
Predicted label: 0
Correct prediction
Energy consumption = 158.737155 pJ
sum error= 111
Actual label: 2
Output voltages: [0.41069, 0.57314, 0.79864, 0.021192, 0.0085419, 0.0014508, 0.29364, 0.036643, 0.31891, 0.041504]
Predicted label: 2
Correct prediction
Energy consumption = 156.168068 pJ
sum error= 111
Actual label: 3
Output voltages: [0.52559, 0.021939, 0.157, 0.79873, 0.012907, 0.0049699, 0.022732, 0.015343, 0.59308, 0.040863]
Predicted label: 3
Correct prediction
Energy consumption = 141.981544 pJ
sum error= 111
Actual label: 4
Output voltages: [0.0089618, 0.0032976, 0.18485, 0.031012, 0.79879, 0.047246, 0.31999, 0.14726, 0.037721, 0.33439]
Predicted label: 4
Correct prediction
Energy consumption = 153.332955 pJ
sum error= 111
Actual label: 2
Output voltages: [0.26067, 0.046828, 0.79879, 0.061013, 0.01113, 0.0012819, 0.28171, 0.015185, 0.49129, 0.022655]
Predicted label: 2
Correct prediction
Energy consumption = 152.290045 pJ
sum error= 111
Actual label: 3
Output voltages: [0.04075, 0.018466, 0.050879, 0.79878, 0.027528, 0.0014626, 0.0092261, 0.0069114, 0.43074, 0.24631]
Predicted label: 3
Correct prediction
Energy consumption = 139.893324 pJ
sum error= 111
Actual label: 0
Output voltages: [0.79857, 0.059992, 0.02567, 0.028351, 0.014402, 0.0051441, 0.63577, 0.017217, 0.3827, 0.02481]
Predicted label: 0
Correct prediction
Energy consumption = 151.429718 pJ
sum error= 111
Actual label: 9
Output voltages: [0.41344, 0.011869, 0.03078, 0.037701, 0.081004, 0.048456, 0.0049281, 0.069967, 0.46309, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 151.778789 pJ
sum error= 111
Actual label: 9
Output voltages: [0.36029, 0.032195, 0.010214, 0.060108, 0.18165, 0.01928, 0.0019757, 0.025004, 0.16384, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 140.003444 pJ
sum error= 111
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 209 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 209 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 209 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.19172, 0.58529, 0.039076, 0.084395, 0.79855, 0.0011141, 0.015907, 0.014241, 0.0090827, 0.52171]
Predicted label: 4
Correct prediction
Energy consumption = 158.994294 pJ
sum error= 111
Actual label: 7
Output voltages: [0.12876, 0.097505, 0.001264, 0.42442, 0.0011224, 0.033957, 0.0011838, 0.79766, 0.38022, 0.65192]
Predicted label: 7
Correct prediction
Energy consumption = 151.538101 pJ
sum error= 111
Actual label: 2
Output voltages: [0.42265, 0.046295, 0.79874, 0.11002, 0.026313, 0.001253, 0.4787, 0.038954, 0.71878, 0.046088]
Predicted label: 2
Correct prediction
Energy consumption = 146.238302 pJ
sum error= 111
Actual label: 8
Output voltages: [0.05584, 0.7948, 0.030586, 0.11031, 0.24696, 0.0012934, 0.0062162, 0.0011388, 0.66033, 0.3773]
Predicted label: 1
Wrong prediction!
Energy consumption = 148.194229 pJ
sum error= 112
Actual label: 4
Output voltages: [0.010289, 0.0097625, 0.10856, 0.0095877, 0.79877, 0.0011283, 0.017808, 0.07082, 0.042159, 0.27974]
Predicted label: 4
Correct prediction
Energy consumption = 157.695958 pJ
sum error= 112
Actual label: 7
Output voltages: [0.036291, 0.050347, 0.42309, 0.384, 0.016845, 0.0010841, 0.0010695, 0.79878, 0.020898, 0.41738]
Predicted label: 7
Correct prediction
Energy consumption = 149.425585 pJ
sum error= 112
Actual label: 0
Output voltages: [0.79876, 0.1175, 0.050881, 0.024588, 0.028232, 0.0038856, 0.61642, 0.014538, 0.1068, 0.27695]
Predicted label: 0
Correct prediction
Energy consumption = 153.285757 pJ
sum error= 112
Actual label: 6
Output voltages: [0.024214, 0.034347, 0.1979, 0.0015637, 0.051657, 0.18872, 0.79877, 0.010557, 0.39708, 0.0029384]
Predicted label: 6
Correct prediction
Energy consumption = 149.695526 pJ
sum error= 112
Actual label: 2
Output voltages: [0.77351, 0.023206, 0.7974, 0.070609, 0.0014766, 0.0010675, 0.049865, 0.12691, 0.25055, 0.034739]
Predicted label: 2
Correct prediction
Energy consumption = 148.532878 pJ
sum error= 112
Actual label: 8
Output voltages: [0.021148, 0.026724, 0.023369, 0.066242, 0.0055326, 0.044558, 0.014024, 0.22397, 0.79879, 0.02843]
Predicted label: 8
Correct prediction
Energy consumption = 143.560519 pJ
sum error= 112
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 210 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 210 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 210 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.053429, 0.0010785, 0.0056026, 0.21085, 0.053239, 0.79847, 0.044148, 0.041986, 0.79778, 0.042091]
Predicted label: 5
Correct prediction
Energy consumption = 148.139386 pJ
sum error= 112
Actual label: 2
Output voltages: [0.35622, 0.027424, 0.79879, 0.069381, 0.013216, 0.001264, 0.45914, 0.03675, 0.73443, 0.041554]
Predicted label: 2
Correct prediction
Energy consumption = 147.377268 pJ
sum error= 112
Actual label: 8
Output voltages: [0.048083, 0.036556, 0.32458, 0.20658, 0.03468, 0.010082, 0.038136, 0.0030297, 0.79869, 0.070372]
Predicted label: 8
Correct prediction
Energy consumption = 139.542614 pJ
sum error= 112
Actual label: 5
Output voltages: [0.048143, 0.0069728, 0.0013975, 0.035614, 0.036534, 0.79831, 0.050928, 0.002201, 0.79337, 0.021477]
Predicted label: 5
Correct prediction
Energy consumption = 144.094747 pJ
sum error= 112
Actual label: 7
Output voltages: [0.031043, 0.04946, 0.20859, 0.041988, 0.0094638, 0.0010666, 0.0013276, 0.79859, 0.046573, 0.025147]
Predicted label: 7
Correct prediction
Energy consumption = 159.185568 pJ
sum error= 112
Actual label: 3
Output voltages: [0.27199, 0.0030952, 0.19446, 0.79845, 0.023464, 0.034467, 0.0028964, 0.042797, 0.78456, 0.021838]
Predicted label: 3
Correct prediction
Energy consumption = 146.384585 pJ
sum error= 112
Actual label: 0
Output voltages: [0.79843, 0.16109, 0.22785, 0.0017476, 0.0066521, 0.0010839, 0.17538, 0.023634, 0.23132, 0.18066]
Predicted label: 0
Correct prediction
Energy consumption = 145.993991 pJ
sum error= 112
Actual label: 8
Output voltages: [0.75767, 0.024964, 0.27352, 0.47388, 0.027739, 0.013523, 0.35898, 0.0026543, 0.79863, 0.48143]
Predicted label: 8
Correct prediction
Energy consumption = 141.560478 pJ
sum error= 112
Actual label: 2
Output voltages: [0.32343, 0.031691, 0.79866, 0.29603, 0.05265, 0.001156, 0.099302, 0.010578, 0.73271, 0.027437]
Predicted label: 2
Correct prediction
Energy consumption = 148.815963 pJ
sum error= 112
Actual label: 3
Output voltages: [0.0023742, 0.48649, 0.49519, 0.030801, 0.048487, 0.13408, 0.0010666, 0.49517, 0.70612, 0.048545]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.013729 pJ
sum error= 113
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 211 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 211 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 211 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.2167, 0.36543, 0.79878, 0.13813, 0.0030522, 0.00122, 0.3071, 0.0055444, 0.66512, 0.17579]
Predicted label: 2
Correct prediction
Energy consumption = 145.887414 pJ
sum error= 113
Actual label: 8
Output voltages: [0.02712, 0.0026511, 0.16558, 0.032571, 0.020449, 0.29706, 0.033531, 0.0039906, 0.7987, 0.024891]
Predicted label: 8
Correct prediction
Energy consumption = 140.021897 pJ
sum error= 113
Actual label: 2
Output voltages: [0.40646, 0.041001, 0.79879, 0.12708, 0.020438, 0.0012192, 0.20129, 0.047749, 0.39572, 0.035431]
Predicted label: 2
Correct prediction
Energy consumption = 147.202339 pJ
sum error= 113
Actual label: 5
Output voltages: [0.017474, 0.0013825, 0.0020741, 0.27047, 0.043142, 0.79875, 0.29401, 0.023318, 0.77812, 0.045196]
Predicted label: 5
Correct prediction
Energy consumption = 145.857380 pJ
sum error= 113
Actual label: 5
Output voltages: [0.052201, 0.0015686, 0.00259, 0.59392, 0.021309, 0.79879, 0.15103, 0.02518, 0.72634, 0.15295]
Predicted label: 5
Correct prediction
Energy consumption = 133.489977 pJ
sum error= 113
Actual label: 7
Output voltages: [0.76413, 0.22773, 0.01503, 0.0063779, 0.0027392, 0.092456, 0.017951, 0.79721, 0.49402, 0.065926]
Predicted label: 7
Correct prediction
Energy consumption = 159.361776 pJ
sum error= 113
Actual label: 6
Output voltages: [0.025348, 0.0054859, 0.029506, 0.0095493, 0.37738, 0.088982, 0.79781, 0.0011318, 0.76208, 0.030949]
Predicted label: 6
Correct prediction
Energy consumption = 146.477699 pJ
sum error= 113
Actual label: 4
Output voltages: [0.0036145, 0.0073779, 0.031629, 0.0080851, 0.7986, 0.0019399, 0.16216, 0.22721, 0.058279, 0.039366]
Predicted label: 4
Correct prediction
Energy consumption = 153.666047 pJ
sum error= 113
Actual label: 6
Output voltages: [0.77518, 0.54001, 0.20441, 0.01161, 0.0023503, 0.0033911, 0.74041, 0.0084019, 0.44003, 0.041422]
Predicted label: 0
Wrong prediction!
Energy consumption = 161.369121 pJ
sum error= 114
Actual label: 8
Output voltages: [0.016398, 0.036021, 0.072796, 0.050436, 0.0073138, 0.025543, 0.025393, 0.014575, 0.79871, 0.022328]
Predicted label: 8
Correct prediction
Energy consumption = 158.893455 pJ
sum error= 114
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 212 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 212 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 212 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.012156, 0.0079678, 0.30069, 0.038169, 0.7987, 0.0011192, 0.022585, 0.067368, 0.0068382, 0.037868]
Predicted label: 4
Correct prediction
Energy consumption = 156.513939 pJ
sum error= 114
Actual label: 8
Output voltages: [0.0015548, 0.25833, 0.14502, 0.013745, 0.011685, 0.023136, 0.48066, 0.019094, 0.79811, 0.037821]
Predicted label: 8
Correct prediction
Energy consumption = 160.314016 pJ
sum error= 114
Actual label: 2
Output voltages: [0.12627, 0.075867, 0.79878, 0.19109, 0.011374, 0.0012611, 0.01387, 0.48499, 0.052082, 0.15018]
Predicted label: 2
Correct prediction
Energy consumption = 148.635962 pJ
sum error= 114
Actual label: 7
Output voltages: [0.11906, 0.13065, 0.72418, 0.049445, 0.11092, 0.00108, 0.0010666, 0.79872, 0.024481, 0.03365]
Predicted label: 7
Correct prediction
Energy consumption = 142.793833 pJ
sum error= 114
Actual label: 4
Output voltages: [0.0042108, 0.0031303, 0.39437, 0.018648, 0.79864, 0.0010996, 0.42467, 0.03713, 0.014709, 0.0362]
Predicted label: 4
Correct prediction
Energy consumption = 150.408470 pJ
sum error= 114
Actual label: 5
Output voltages: [0.21226, 0.020171, 0.001067, 0.69753, 0.0093197, 0.74346, 0.47791, 0.0013186, 0.37775, 0.55509]
Predicted label: 5
Correct prediction
Energy consumption = 159.898745 pJ
sum error= 114
Actual label: 2
Output voltages: [0.36454, 0.12565, 0.79879, 0.40622, 0.010067, 0.0012936, 0.25693, 0.0777, 0.39307, 0.021875]
Predicted label: 2
Correct prediction
Energy consumption = 148.193458 pJ
sum error= 114
Actual label: 0
Output voltages: [0.79876, 0.087411, 0.019604, 0.014401, 0.015771, 0.015174, 0.58596, 0.017733, 0.15278, 0.015967]
Predicted label: 0
Correct prediction
Energy consumption = 148.264509 pJ
sum error= 114
Actual label: 3
Output voltages: [0.24672, 0.029903, 0.022729, 0.79869, 0.010128, 0.0051324, 0.0099595, 0.0069872, 0.51115, 0.056328]
Predicted label: 3
Correct prediction
Energy consumption = 147.817813 pJ
sum error= 114
Actual label: 9
Output voltages: [0.016219, 0.0010823, 0.41717, 0.021391, 0.054174, 0.036313, 0.0069315, 0.0012565, 0.79719, 0.39449]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.362256 pJ
sum error= 115
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 213 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 213 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 213 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.043821, 0.011976, 0.024156, 0.16223, 0.52339, 0.0068433, 0.001732, 0.0049986, 0.32803, 0.77534]
Predicted label: 9
Wrong prediction!
Energy consumption = 150.626646 pJ
sum error= 116
Actual label: 6
Output voltages: [0.77937, 0.026265, 0.32499, 0.018648, 0.024602, 0.0014952, 0.77284, 0.014328, 0.61158, 0.018884]
Predicted label: 0
Wrong prediction!
Energy consumption = 154.337905 pJ
sum error= 117
Actual label: 7
Output voltages: [0.020523, 0.020061, 0.020277, 0.32676, 0.021904, 0.0020566, 0.0010666, 0.79874, 0.18044, 0.42613]
Predicted label: 7
Correct prediction
Energy consumption = 158.200094 pJ
sum error= 117
Actual label: 2
Output voltages: [0.39676, 0.058763, 0.79877, 0.20941, 0.022422, 0.0012797, 0.25751, 0.082115, 0.46512, 0.075708]
Predicted label: 2
Correct prediction
Energy consumption = 149.457797 pJ
sum error= 117
Actual label: 5
Output voltages: [0.090783, 0.0010687, 0.0011304, 0.040102, 0.16798, 0.79878, 0.21559, 0.0032257, 0.78688, 0.0071055]
Predicted label: 5
Correct prediction
Energy consumption = 142.513766 pJ
sum error= 117
Actual label: 6
Output voltages: [0.10978, 0.79804, 0.093622, 0.0159, 0.029108, 0.063012, 0.76469, 0.0032902, 0.31514, 0.0030454]
Predicted label: 1
Wrong prediction!
Energy consumption = 149.134717 pJ
sum error= 118
Actual label: 1
Output voltages: [0.0028577, 0.79868, 0.50009, 0.51319, 0.22545, 0.014578, 0.029252, 0.36431, 0.0039247, 0.044861]
Predicted label: 1
Correct prediction
Energy consumption = 162.740767 pJ
sum error= 118
Actual label: 1
Output voltages: [0.025046, 0.79852, 0.017505, 0.012196, 0.015487, 0.002738, 0.48168, 0.0020188, 0.58517, 0.02103]
Predicted label: 1
Correct prediction
Energy consumption = 161.163323 pJ
sum error= 118
Actual label: 2
Output voltages: [0.2426, 0.038618, 0.79876, 0.044208, 0.0033041, 0.0010681, 0.25021, 0.032026, 0.78146, 0.030706]
Predicted label: 2
Correct prediction
Energy consumption = 144.453459 pJ
sum error= 118
Actual label: 3
Output voltages: [0.29006, 0.018161, 0.21004, 0.7987, 0.029328, 0.04859, 0.019416, 0.021137, 0.71827, 0.1117]
Predicted label: 3
Correct prediction
Energy consumption = 136.006303 pJ
sum error= 118
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 214 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 214 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 214 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.39237, 0.04025, 0.39784, 0.0011877, 0.25165, 0.028486, 0.7987, 0.0068388, 0.023734, 0.054969]
Predicted label: 6
Correct prediction
Energy consumption = 155.054200 pJ
sum error= 118
Actual label: 7
Output voltages: [0.039613, 0.039641, 0.048944, 0.59935, 0.001472, 0.0058048, 0.0010857, 0.79872, 0.22206, 0.7121]
Predicted label: 7
Correct prediction
Energy consumption = 164.992784 pJ
sum error= 118
Actual label: 8
Output voltages: [0.03051, 0.047415, 0.32161, 0.1158, 0.016085, 0.0051889, 0.33148, 0.001786, 0.79877, 0.30283]
Predicted label: 8
Correct prediction
Energy consumption = 149.794263 pJ
sum error= 118
Actual label: 7
Output voltages: [0.34825, 0.073647, 0.7625, 0.029014, 0.0016255, 0.0011856, 0.0012849, 0.79875, 0.42025, 0.074325]
Predicted label: 7
Correct prediction
Energy consumption = 155.281428 pJ
sum error= 118
Actual label: 6
Output voltages: [0.13686, 0.027912, 0.079665, 0.0077878, 0.22503, 0.12166, 0.79877, 0.0078804, 0.73401, 0.0052595]
Predicted label: 6
Correct prediction
Energy consumption = 155.122887 pJ
sum error= 118
Actual label: 4
Output voltages: [0.028053, 0.019782, 0.31512, 0.0011377, 0.79879, 0.001066, 0.71959, 0.012841, 0.30611, 0.037319]
Predicted label: 4
Correct prediction
Energy consumption = 143.561129 pJ
sum error= 118
Actual label: 8
Output voltages: [0.12024, 0.031019, 0.22781, 0.028963, 0.014668, 0.032244, 0.02378, 0.0030006, 0.79874, 0.20987]
Predicted label: 8
Correct prediction
Energy consumption = 155.989029 pJ
sum error= 118
Actual label: 9
Output voltages: [0.072589, 0.0037051, 0.014558, 0.034775, 0.15571, 0.0024337, 0.0081981, 0.040467, 0.64854, 0.79784]
Predicted label: 9
Correct prediction
Energy consumption = 155.939389 pJ
sum error= 118
Actual label: 4
Output voltages: [0.17368, 0.01036, 0.30409, 0.019319, 0.79863, 0.0012308, 0.053263, 0.014386, 0.024148, 0.48065]
Predicted label: 4
Correct prediction
Energy consumption = 140.940039 pJ
sum error= 118
Actual label: 8
Output voltages: [0.13133, 0.42188, 0.78079, 0.059409, 0.015299, 0.0011966, 0.017038, 0.062209, 0.72827, 0.038063]
Predicted label: 2
Wrong prediction!
Energy consumption = 149.955925 pJ
sum error= 119
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 215 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 215 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 215 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.024961, 0.082462, 0.044931, 0.0045294, 0.082399, 0.38125, 0.79877, 0.0026464, 0.48122, 0.0015063]
Predicted label: 6
Correct prediction
Energy consumption = 149.773317 pJ
sum error= 119
Actual label: 3
Output voltages: [0.13387, 0.0012557, 0.10908, 0.79873, 0.10774, 0.017033, 0.053909, 0.0044898, 0.57597, 0.0026531]
Predicted label: 3
Correct prediction
Energy consumption = 140.781606 pJ
sum error= 119
Actual label: 8
Output voltages: [0.075235, 0.021202, 0.22142, 0.20204, 0.026866, 0.012674, 0.20226, 0.0064403, 0.79875, 0.027717]
Predicted label: 8
Correct prediction
Energy consumption = 154.452813 pJ
sum error= 119
Actual label: 3
Output voltages: [0.02179, 0.0080613, 0.23654, 0.79873, 0.10429, 0.31192, 0.025265, 0.013528, 0.42958, 0.0079822]
Predicted label: 3
Correct prediction
Energy consumption = 142.167331 pJ
sum error= 119
Actual label: 1
Output voltages: [0.044069, 0.79867, 0.59379, 0.055879, 0.057571, 0.0010679, 0.53667, 0.0050059, 0.096496, 0.039782]
Predicted label: 1
Correct prediction
Energy consumption = 165.135428 pJ
sum error= 119
Actual label: 0
Output voltages: [0.79877, 0.046028, 0.015076, 0.025503, 0.028575, 0.013698, 0.73119, 0.011199, 0.31713, 0.02863]
Predicted label: 0
Correct prediction
Energy consumption = 156.304088 pJ
sum error= 119
Actual label: 6
Output voltages: [0.19732, 0.29818, 0.062118, 0.021456, 0.09958, 0.065473, 0.79876, 0.0034466, 0.43656, 0.01373]
Predicted label: 6
Correct prediction
Energy consumption = 141.065592 pJ
sum error= 119
Actual label: 2
Output voltages: [0.36312, 0.030961, 0.79877, 0.12331, 0.0098983, 0.0013449, 0.24298, 0.092754, 0.48804, 0.030266]
Predicted label: 2
Correct prediction
Energy consumption = 150.503135 pJ
sum error= 119
Actual label: 2
Output voltages: [0.28061, 0.14615, 0.79873, 0.43516, 0.0086064, 0.0014048, 0.020594, 0.16767, 0.2677, 0.018903]
Predicted label: 2
Correct prediction
Energy consumption = 138.985606 pJ
sum error= 119
Actual label: 5
Output voltages: [0.038449, 0.0066113, 0.0027523, 0.20928, 0.029343, 0.79878, 0.11839, 0.010905, 0.7413, 0.021662]
Predicted label: 5
Correct prediction
Energy consumption = 149.393472 pJ
sum error= 119
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 216 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 216 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 216 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.1617, 0.046118, 0.0549, 0.0087092, 0.24124, 0.58618, 0.79876, 0.0059891, 0.57569, 0.0033737]
Predicted label: 6
Correct prediction
Energy consumption = 151.253930 pJ
sum error= 119
Actual label: 9
Output voltages: [0.045195, 0.0021568, 0.0050213, 0.052691, 0.78124, 0.041548, 0.02167, 0.11941, 0.029823, 0.78526]
Predicted label: 9
Correct prediction
Energy consumption = 152.158742 pJ
sum error= 119
Actual label: 5
Output voltages: [0.046899, 0.001072, 0.01759, 0.0089524, 0.052723, 0.79564, 0.50199, 0.0071053, 0.77432, 0.044723]
Predicted label: 5
Correct prediction
Energy consumption = 151.680528 pJ
sum error= 119
Actual label: 8
Output voltages: [0.017256, 0.01188, 0.20366, 0.45402, 0.0019677, 0.0049779, 0.12112, 0.016462, 0.79878, 0.045685]
Predicted label: 8
Correct prediction
Energy consumption = 149.556089 pJ
sum error= 119
Actual label: 1
Output voltages: [0.011402, 0.79841, 0.035068, 0.042613, 0.028903, 0.0061249, 0.61238, 0.0026392, 0.27167, 0.1657]
Predicted label: 1
Correct prediction
Energy consumption = 164.416424 pJ
sum error= 119
Actual label: 4
Output voltages: [0.0051048, 0.023621, 0.081416, 0.0054004, 0.79864, 0.0025538, 0.33234, 0.26834, 0.019153, 0.067407]
Predicted label: 4
Correct prediction
Energy consumption = 155.942360 pJ
sum error= 119
Actual label: 1
Output voltages: [0.0069455, 0.79872, 0.036651, 0.46958, 0.24937, 0.0010991, 0.024322, 0.029522, 0.17406, 0.14432]
Predicted label: 1
Correct prediction
Energy consumption = 156.831327 pJ
sum error= 119
Actual label: 7
Output voltages: [0.32556, 0.025817, 0.28809, 0.010008, 0.012848, 0.0018663, 0.0011334, 0.79869, 0.54642, 0.26776]
Predicted label: 7
Correct prediction
Energy consumption = 152.065456 pJ
sum error= 119
Actual label: 8
Output voltages: [0.24664, 0.011853, 0.25867, 0.2927, 0.013962, 0.022163, 0.22721, 0.0090544, 0.79878, 0.05247]
Predicted label: 8
Correct prediction
Energy consumption = 157.524179 pJ
sum error= 119
Actual label: 4
Output voltages: [0.044721, 0.024377, 0.043622, 0.0011704, 0.77442, 0.0011457, 0.013756, 0.013892, 0.071463, 0.7861]
Predicted label: 9
Wrong prediction!
Energy consumption = 165.969860 pJ
sum error= 120
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 217 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 217 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 217 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.082785, 0.026454, 0.3858, 0.0011188, 0.39052, 0.14283, 0.79879, 0.0010704, 0.42207, 0.002711]
Predicted label: 6
Correct prediction
Energy consumption = 145.722287 pJ
sum error= 120
Actual label: 1
Output voltages: [0.0014376, 0.79856, 0.048508, 0.57994, 0.021988, 0.030675, 0.036701, 0.016255, 0.010842, 0.1757]
Predicted label: 1
Correct prediction
Energy consumption = 164.108390 pJ
sum error= 120
Actual label: 8
Output voltages: [0.013343, 0.020595, 0.06854, 0.1657, 0.0031526, 0.019574, 0.17013, 0.024237, 0.7987, 0.042397]
Predicted label: 8
Correct prediction
Energy consumption = 153.202811 pJ
sum error= 120
Actual label: 4
Output voltages: [0.0072641, 0.0052063, 0.057389, 0.010612, 0.79875, 0.010433, 0.060004, 0.22088, 0.52123, 0.001751]
Predicted label: 4
Correct prediction
Energy consumption = 150.047576 pJ
sum error= 120
Actual label: 3
Output voltages: [0.41809, 0.08604, 0.042507, 0.79878, 0.0031061, 0.77814, 0.035728, 0.14443, 0.041508, 0.0015419]
Predicted label: 3
Correct prediction
Energy consumption = 155.982201 pJ
sum error= 120
Actual label: 1
Output voltages: [0.0055705, 0.79854, 0.003122, 0.046294, 0.16657, 0.0010849, 0.12567, 0.012454, 0.20348, 0.18643]
Predicted label: 1
Correct prediction
Energy consumption = 164.596675 pJ
sum error= 120
Actual label: 2
Output voltages: [0.50135, 0.031319, 0.79878, 0.27589, 0.18579, 0.0011672, 0.042382, 0.082745, 0.067622, 0.013953]
Predicted label: 2
Correct prediction
Energy consumption = 149.360712 pJ
sum error= 120
Actual label: 8
Output voltages: [0.32008, 0.015326, 0.35104, 0.046719, 0.039555, 0.022322, 0.43649, 0.0067934, 0.79878, 0.034582]
Predicted label: 8
Correct prediction
Energy consumption = 148.627959 pJ
sum error= 120
Actual label: 0
Output voltages: [0.79877, 0.14978, 0.11219, 0.02874, 0.0040644, 0.0036202, 0.37762, 0.053698, 0.19155, 0.041906]
Predicted label: 0
Correct prediction
Energy consumption = 153.865233 pJ
sum error= 120
Actual label: 8
Output voltages: [0.056131, 0.012103, 0.41818, 0.67289, 0.005009, 0.0021963, 0.010233, 0.0025455, 0.7987, 0.10248]
Predicted label: 8
Correct prediction
Energy consumption = 147.933338 pJ
sum error= 120
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 218 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 218 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 218 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.084541, 0.0012067, 0.0016869, 0.54632, 0.049414, 0.79876, 0.074236, 0.053967, 0.736, 0.13357]
Predicted label: 5
Correct prediction
Energy consumption = 148.558087 pJ
sum error= 120
Actual label: 9
Output voltages: [0.56694, 0.0033548, 0.17684, 0.010643, 0.45547, 0.011527, 0.0057373, 0.0041131, 0.064534, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 150.280066 pJ
sum error= 120
Actual label: 1
Output voltages: [0.4352, 0.41026, 0.58818, 0.79521, 0.001229, 0.014256, 0.0051501, 0.0060068, 0.46261, 0.0041776]
Predicted label: 3
Wrong prediction!
Energy consumption = 158.752749 pJ
sum error= 121
Actual label: 4
Output voltages: [0.047841, 0.024421, 0.073469, 0.0050071, 0.79879, 0.0049464, 0.72665, 0.023456, 0.020172, 0.022453]
Predicted label: 4
Correct prediction
Energy consumption = 154.182779 pJ
sum error= 121
Actual label: 2
Output voltages: [0.31019, 0.026278, 0.79879, 0.097528, 0.034419, 0.0012262, 0.1871, 0.013615, 0.57195, 0.046228]
Predicted label: 2
Correct prediction
Energy consumption = 147.445943 pJ
sum error= 121
Actual label: 0
Output voltages: [0.79857, 0.17319, 0.031044, 0.01077, 0.0036446, 0.0094805, 0.40918, 0.070989, 0.46516, 0.028385]
Predicted label: 0
Correct prediction
Energy consumption = 163.985637 pJ
sum error= 121
Actual label: 2
Output voltages: [0.49244, 0.0084703, 0.77934, 0.78057, 0.02468, 0.0011982, 0.0092216, 0.0080558, 0.61178, 0.026751]
Predicted label: 3
Wrong prediction!
Energy consumption = 147.535555 pJ
sum error= 122
Actual label: 7
Output voltages: [0.14014, 0.033121, 0.46537, 0.027107, 0.0029959, 0.0015044, 0.0011017, 0.79853, 0.59434, 0.038132]
Predicted label: 7
Correct prediction
Energy consumption = 152.596116 pJ
sum error= 122
Actual label: 0
Output voltages: [0.79872, 0.017194, 0.016088, 0.04002, 0.0070776, 0.015355, 0.55744, 0.024871, 0.23551, 0.47794]
Predicted label: 0
Correct prediction
Energy consumption = 149.374263 pJ
sum error= 122
Actual label: 9
Output voltages: [0.0037706, 0.7857, 0.0029372, 0.16156, 0.034131, 0.019272, 0.0012221, 0.03287, 0.78239, 0.62665]
Predicted label: 1
Wrong prediction!
Energy consumption = 151.974441 pJ
sum error= 123
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 219 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 219 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 219 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79824, 0.13455, 0.17499, 0.033819, 0.023496, 0.0035408, 0.52998, 0.010796, 0.27108, 0.024754]
Predicted label: 0
Correct prediction
Energy consumption = 163.503534 pJ
sum error= 123
Actual label: 2
Output voltages: [0.52702, 0.045139, 0.79879, 0.24806, 0.019245, 0.0012118, 0.46572, 0.019586, 0.6519, 0.094541]
Predicted label: 2
Correct prediction
Energy consumption = 146.822752 pJ
sum error= 123
Actual label: 5
Output voltages: [0.28727, 0.0014321, 0.025584, 0.56954, 0.022723, 0.79745, 0.12265, 0.0055245, 0.78928, 0.059788]
Predicted label: 5
Correct prediction
Energy consumption = 145.693189 pJ
sum error= 123
Actual label: 7
Output voltages: [0.037224, 0.072076, 0.52041, 0.1513, 0.001067, 0.0014244, 0.0011348, 0.79878, 0.68663, 0.47501]
Predicted label: 7
Correct prediction
Energy consumption = 143.091494 pJ
sum error= 123
Actual label: 6
Output voltages: [0.021494, 0.22069, 0.51404, 0.0013258, 0.071037, 0.040789, 0.79877, 0.0012756, 0.40996, 0.003586]
Predicted label: 6
Correct prediction
Energy consumption = 142.923289 pJ
sum error= 123
Actual label: 7
Output voltages: [0.70038, 0.0074146, 0.77478, 0.0078981, 0.0011736, 0.0010762, 0.0011078, 0.79736, 0.62344, 0.038661]
Predicted label: 7
Correct prediction
Energy consumption = 142.522486 pJ
sum error= 123
Actual label: 9
Output voltages: [0.35139, 0.0068617, 0.024969, 0.010314, 0.056382, 0.013678, 0.0031774, 0.063011, 0.6474, 0.79401]
Predicted label: 9
Correct prediction
Energy consumption = 146.499710 pJ
sum error= 123
Actual label: 4
Output voltages: [0.021528, 0.019289, 0.084043, 0.0032187, 0.79701, 0.0016844, 0.48856, 0.015593, 0.36471, 0.0011443]
Predicted label: 4
Correct prediction
Energy consumption = 154.431111 pJ
sum error= 123
Actual label: 2
Output voltages: [0.36791, 0.41246, 0.79878, 0.0060876, 0.019508, 0.0014073, 0.1247, 0.23798, 0.24112, 0.011579]
Predicted label: 2
Correct prediction
Energy consumption = 150.807975 pJ
sum error= 123
Actual label: 6
Output voltages: [0.16073, 0.018204, 0.033241, 0.046046, 0.22766, 0.52957, 0.79865, 0.0078587, 0.75882, 0.0033805]
Predicted label: 6
Correct prediction
Energy consumption = 146.797401 pJ
sum error= 123
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 220 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 220 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 220 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.32924, 0.031003, 0.76944, 0.091898, 0.28039, 0.0011404, 0.78395, 0.0052987, 0.2061, 0.001088]
Predicted label: 6
Wrong prediction!
Energy consumption = 144.670446 pJ
sum error= 124
Actual label: 4
Output voltages: [0.0042168, 0.011599, 0.023782, 0.13821, 0.79878, 0.1367, 0.028805, 0.0082326, 0.072258, 0.72411]
Predicted label: 4
Correct prediction
Energy consumption = 156.644948 pJ
sum error= 124
Actual label: 4
Output voltages: [0.0088053, 0.0042748, 0.026311, 0.0037773, 0.79875, 0.0020104, 0.053479, 0.1518, 0.42716, 0.0011445]
Predicted label: 4
Correct prediction
Energy consumption = 146.057518 pJ
sum error= 124
Actual label: 8
Output voltages: [0.089505, 0.03803, 0.22429, 0.16989, 0.019593, 0.011233, 0.070679, 0.006567, 0.79875, 0.44211]
Predicted label: 8
Correct prediction
Energy consumption = 153.579607 pJ
sum error= 124
Actual label: 0
Output voltages: [0.79867, 0.0087122, 0.020154, 0.14498, 0.010324, 0.041236, 0.028958, 0.080612, 0.69664, 0.28684]
Predicted label: 0
Correct prediction
Energy consumption = 156.792515 pJ
sum error= 124
Actual label: 4
Output voltages: [0.008664, 0.040407, 0.07701, 0.0033316, 0.79879, 0.0011664, 0.47807, 0.039867, 0.029374, 0.040228]
Predicted label: 4
Correct prediction
Energy consumption = 150.658295 pJ
sum error= 124
Actual label: 4
Output voltages: [0.0039889, 0.034876, 0.18684, 0.016868, 0.79874, 0.0012698, 0.06246, 0.14524, 0.014027, 0.078395]
Predicted label: 4
Correct prediction
Energy consumption = 142.474994 pJ
sum error= 124
Actual label: 5
Output voltages: [0.043327, 0.0010808, 0.0040112, 0.045326, 0.019121, 0.79876, 0.11357, 0.020035, 0.77252, 0.0041496]
Predicted label: 5
Correct prediction
Energy consumption = 151.785046 pJ
sum error= 124
Actual label: 8
Output voltages: [0.045549, 0.028237, 0.16435, 0.54021, 0.0068524, 0.0014424, 0.078573, 0.01911, 0.79878, 0.20295]
Predicted label: 8
Correct prediction
Energy consumption = 152.233989 pJ
sum error= 124
Actual label: 0
Output voltages: [0.79878, 0.0065835, 0.076107, 0.0018168, 0.020047, 0.0049505, 0.04951, 0.011158, 0.26179, 0.039683]
Predicted label: 0
Correct prediction
Energy consumption = 154.128672 pJ
sum error= 124
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 221 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 221 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 221 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.042229, 0.027571, 0.2298, 0.0020863, 0.3907, 0.30335, 0.7987, 0.0039242, 0.58831, 0.0061227]
Predicted label: 6
Correct prediction
Energy consumption = 147.125580 pJ
sum error= 124
Actual label: 8
Output voltages: [0.15509, 0.001679, 0.13212, 0.072646, 0.012783, 0.074061, 0.0033514, 0.0095732, 0.79876, 0.086901]
Predicted label: 8
Correct prediction
Energy consumption = 150.918398 pJ
sum error= 124
Actual label: 9
Output voltages: [0.16847, 0.0038857, 0.030576, 0.0043132, 0.093543, 0.016873, 0.0070009, 0.021256, 0.67608, 0.79779]
Predicted label: 9
Correct prediction
Energy consumption = 143.993709 pJ
sum error= 124
Actual label: 8
Output voltages: [0.024609, 0.059274, 0.035323, 0.52365, 0.0044063, 0.12688, 0.008309, 0.021321, 0.79878, 0.38361]
Predicted label: 8
Correct prediction
Energy consumption = 147.655503 pJ
sum error= 124
Actual label: 5
Output voltages: [0.14491, 0.0011698, 0.0046905, 0.47197, 0.008361, 0.79878, 0.18912, 0.035387, 0.6915, 0.023891]
Predicted label: 5
Correct prediction
Energy consumption = 142.106260 pJ
sum error= 124
Actual label: 6
Output voltages: [0.20593, 0.017871, 0.47022, 0.010983, 0.066612, 0.16564, 0.79858, 0.0010706, 0.75074, 0.045216]
Predicted label: 6
Correct prediction
Energy consumption = 140.078167 pJ
sum error= 124
Actual label: 9
Output voltages: [0.20363, 0.0056783, 0.0096451, 0.082411, 0.45452, 0.28657, 0.045796, 0.029058, 0.042057, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 157.952890 pJ
sum error= 124
Actual label: 0
Output voltages: [0.79872, 0.014818, 0.031717, 0.0046981, 0.019704, 0.03006, 0.28868, 0.017325, 0.026771, 0.022887]
Predicted label: 0
Correct prediction
Energy consumption = 151.510197 pJ
sum error= 124
Actual label: 4
Output voltages: [0.012382, 0.0019896, 0.028665, 0.035152, 0.79876, 0.0034711, 0.12556, 0.026574, 0.32217, 0.025039]
Predicted label: 4
Correct prediction
Energy consumption = 156.691928 pJ
sum error= 124
Actual label: 8
Output voltages: [0.17609, 0.0047453, 0.44079, 0.0062334, 0.016036, 0.0070552, 0.006652, 0.0014249, 0.79829, 0.64609]
Predicted label: 8
Correct prediction
Energy consumption = 145.327882 pJ
sum error= 124
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 222 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 222 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 222 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.22221, 0.032629, 0.030033, 0.12113, 0.021769, 0.0018034, 0.0010906, 0.79869, 0.47325, 0.45537]
Predicted label: 7
Correct prediction
Energy consumption = 153.386142 pJ
sum error= 124
Actual label: 1
Output voltages: [0.041546, 0.79869, 0.047579, 0.0013661, 0.24764, 0.022122, 0.22856, 0.015843, 0.67488, 0.49706]
Predicted label: 1
Correct prediction
Energy consumption = 155.887522 pJ
sum error= 124
Actual label: 3
Output voltages: [0.4555, 0.0024617, 0.012518, 0.79877, 0.0022438, 0.59231, 0.010004, 0.042165, 0.16279, 0.0011634]
Predicted label: 3
Correct prediction
Energy consumption = 151.216554 pJ
sum error= 124
Actual label: 4
Output voltages: [0.0035242, 0.014452, 0.15203, 0.0063823, 0.79866, 0.0067147, 0.25471, 0.07819, 0.034025, 0.026175]
Predicted label: 4
Correct prediction
Energy consumption = 154.022823 pJ
sum error= 124
Actual label: 5
Output voltages: [0.31613, 0.0019501, 0.0072356, 0.19735, 0.0055656, 0.77462, 0.74839, 0.0023568, 0.75197, 0.04165]
Predicted label: 5
Correct prediction
Energy consumption = 155.579028 pJ
sum error= 124
Actual label: 8
Output voltages: [0.076639, 0.039038, 0.38192, 0.41054, 0.0015762, 0.0043271, 0.021532, 0.010547, 0.79418, 0.64041]
Predicted label: 8
Correct prediction
Energy consumption = 152.206275 pJ
sum error= 124
Actual label: 0
Output voltages: [0.79797, 0.018695, 0.024777, 0.0056011, 0.032551, 0.0034038, 0.69121, 0.017981, 0.1515, 0.036713]
Predicted label: 0
Correct prediction
Energy consumption = 152.625282 pJ
sum error= 124
Actual label: 9
Output voltages: [0.51379, 0.0092093, 0.010248, 0.11662, 0.2852, 0.15923, 0.01948, 0.0083553, 0.045874, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 148.227084 pJ
sum error= 124
Actual label: 1
Output voltages: [0.020561, 0.79854, 0.0010813, 0.03107, 0.42709, 0.030243, 0.74221, 0.0057285, 0.053108, 0.037133]
Predicted label: 1
Correct prediction
Energy consumption = 161.283577 pJ
sum error= 124
Actual label: 3
Output voltages: [0.13489, 0.024463, 0.22059, 0.79878, 0.010418, 0.0028292, 0.0053318, 0.021621, 0.74012, 0.03026]
Predicted label: 3
Correct prediction
Energy consumption = 145.721519 pJ
sum error= 124
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 223 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 223 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 223 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.091529, 0.025464, 0.30365, 0.79879, 0.04755, 0.0071946, 0.03551, 0.0016589, 0.46987, 0.33615]
Predicted label: 3
Correct prediction
Energy consumption = 144.848635 pJ
sum error= 124
Actual label: 6
Output voltages: [0.044634, 0.04121, 0.28759, 0.0061417, 0.2967, 0.099219, 0.79872, 0.0015073, 0.55969, 0.024631]
Predicted label: 6
Correct prediction
Energy consumption = 144.001418 pJ
sum error= 124
Actual label: 9
Output voltages: [0.51265, 0.033567, 0.011724, 0.10575, 0.21734, 0.018547, 0.062729, 0.0072957, 0.36739, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.692394 pJ
sum error= 124
Actual label: 8
Output voltages: [0.010707, 0.010121, 0.30119, 0.019925, 0.037081, 0.051473, 0.035235, 0.0043192, 0.79875, 0.039603]
Predicted label: 8
Correct prediction
Energy consumption = 144.350929 pJ
sum error= 124
Actual label: 7
Output voltages: [0.30863, 0.041084, 0.44161, 0.026375, 0.0035663, 0.0012116, 0.0010813, 0.79875, 0.20207, 0.026424]
Predicted label: 7
Correct prediction
Energy consumption = 154.931456 pJ
sum error= 124
Actual label: 1
Output voltages: [0.073122, 0.79875, 0.35849, 0.0065305, 0.73432, 0.0012005, 0.32901, 0.0029669, 0.068555, 0.0038728]
Predicted label: 1
Correct prediction
Energy consumption = 150.078756 pJ
sum error= 124
Actual label: 0
Output voltages: [0.79877, 0.12569, 0.079218, 0.019865, 0.017024, 0.0093807, 0.42472, 0.026242, 0.041928, 0.020565]
Predicted label: 0
Correct prediction
Energy consumption = 151.321085 pJ
sum error= 124
Actual label: 5
Output voltages: [0.025951, 0.0014892, 0.32981, 0.031416, 0.001359, 0.78037, 0.74078, 0.0015424, 0.78133, 0.025654]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.137916 pJ
sum error= 125
Actual label: 7
Output voltages: [0.5191, 0.020226, 0.055103, 0.68895, 0.0012863, 0.0011085, 0.0010667, 0.79827, 0.2121, 0.32785]
Predicted label: 7
Correct prediction
Energy consumption = 160.401377 pJ
sum error= 125
Actual label: 1
Output voltages: [0.012125, 0.79843, 0.0082798, 0.10867, 0.038912, 0.0108, 0.31769, 0.019913, 0.13168, 0.044416]
Predicted label: 1
Correct prediction
Energy consumption = 160.502516 pJ
sum error= 125
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 224 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 224 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 224 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30833, 0.03782, 0.015934, 0.10017, 0.012844, 0.036058, 0.001079, 0.79859, 0.2125, 0.43487]
Predicted label: 7
Correct prediction
Energy consumption = 155.773615 pJ
sum error= 125
Actual label: 5
Output voltages: [0.16908, 0.0011083, 0.0010806, 0.39664, 0.045497, 0.79874, 0.4448, 0.053361, 0.76801, 0.018231]
Predicted label: 5
Correct prediction
Energy consumption = 149.992581 pJ
sum error= 125
Actual label: 2
Output voltages: [0.17176, 0.041964, 0.79879, 0.040768, 0.0038513, 0.0013023, 0.030764, 0.18434, 0.48251, 0.010102]
Predicted label: 2
Correct prediction
Energy consumption = 157.653317 pJ
sum error= 125
Actual label: 7
Output voltages: [0.22157, 0.022302, 0.0021631, 0.32178, 0.026842, 0.01475, 0.0010866, 0.79835, 0.52016, 0.74585]
Predicted label: 7
Correct prediction
Energy consumption = 149.293244 pJ
sum error= 125
Actual label: 9
Output voltages: [0.19657, 0.03774, 0.017057, 0.26573, 0.19696, 0.016994, 0.014389, 0.01498, 0.22785, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 144.831254 pJ
sum error= 125
Actual label: 1
Output voltages: [0.059537, 0.7985, 0.026385, 0.03786, 0.039209, 0.0022087, 0.62593, 0.0052319, 0.1455, 0.022801]
Predicted label: 1
Correct prediction
Energy consumption = 167.177617 pJ
sum error= 125
Actual label: 8
Output voltages: [0.0063989, 0.22918, 0.021258, 0.35145, 0.0019126, 0.19407, 0.24386, 0.0042959, 0.79852, 0.29597]
Predicted label: 8
Correct prediction
Energy consumption = 149.804713 pJ
sum error= 125
Actual label: 5
Output voltages: [0.038511, 0.0010955, 0.0064409, 0.14832, 0.015044, 0.79422, 0.054372, 0.039222, 0.7438, 0.36582]
Predicted label: 5
Correct prediction
Energy consumption = 144.487732 pJ
sum error= 125
Actual label: 2
Output voltages: [0.65901, 0.019833, 0.79879, 0.25241, 0.0036355, 0.0012084, 0.24751, 0.27303, 0.65899, 0.10867]
Predicted label: 2
Correct prediction
Energy consumption = 149.258477 pJ
sum error= 125
Actual label: 4
Output voltages: [0.0053291, 0.0023665, 0.61944, 0.0081353, 0.79859, 0.001214, 0.042348, 0.049344, 0.020308, 0.043965]
Predicted label: 4
Correct prediction
Energy consumption = 149.133140 pJ
sum error= 125
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 225 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 225 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 225 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.056516, 0.01585, 0.02626, 0.38557, 0.40058, 0.0068955, 0.026297, 0.017692, 0.32916, 0.7984]
Predicted label: 9
Correct prediction
Energy consumption = 153.975024 pJ
sum error= 125
Actual label: 4
Output voltages: [0.041493, 0.016419, 0.075384, 0.0069043, 0.79873, 0.0041195, 0.02587, 0.11528, 0.051775, 0.43974]
Predicted label: 4
Correct prediction
Energy consumption = 148.421252 pJ
sum error= 125
Actual label: 7
Output voltages: [0.023618, 0.029321, 0.057453, 0.45795, 0.0052911, 0.0017578, 0.0010917, 0.79878, 0.26726, 0.46262]
Predicted label: 7
Correct prediction
Energy consumption = 154.184404 pJ
sum error= 125
Actual label: 2
Output voltages: [0.21399, 0.013443, 0.79878, 0.017385, 0.023439, 0.0011081, 0.05463, 0.18393, 0.72815, 0.0030961]
Predicted label: 2
Correct prediction
Energy consumption = 141.081905 pJ
sum error= 125
Actual label: 2
Output voltages: [0.48342, 0.0012099, 0.79878, 0.48939, 0.015237, 0.001207, 0.013076, 0.044914, 0.69764, 0.024767]
Predicted label: 2
Correct prediction
Energy consumption = 128.955513 pJ
sum error= 125
Actual label: 3
Output voltages: [0.11162, 0.0064377, 0.023547, 0.79869, 0.008981, 0.0026805, 0.037748, 0.021498, 0.45853, 0.036728]
Predicted label: 3
Correct prediction
Energy consumption = 141.182612 pJ
sum error= 125
Actual label: 4
Output voltages: [0.002737, 0.0088258, 0.19125, 0.018188, 0.79857, 0.0062697, 0.27616, 0.051563, 0.033404, 0.037683]
Predicted label: 4
Correct prediction
Energy consumption = 153.678533 pJ
sum error= 125
Actual label: 9
Output voltages: [0.76638, 0.0022293, 0.030356, 0.027793, 0.1927, 0.037919, 0.011373, 0.37182, 0.36086, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 152.815548 pJ
sum error= 125
Actual label: 1
Output voltages: [0.0042127, 0.79759, 0.28081, 0.0091429, 0.50789, 0.0010862, 0.37871, 0.0042827, 0.23979, 0.064498]
Predicted label: 1
Correct prediction
Energy consumption = 161.598099 pJ
sum error= 125
Actual label: 9
Output voltages: [0.70013, 0.002916, 0.0208, 0.028744, 0.23436, 0.021145, 0.0074451, 0.049008, 0.063762, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.444776 pJ
sum error= 125
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 226 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 226 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 226 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.26948, 0.017664, 0.79879, 0.20042, 0.009156, 0.0010984, 0.034434, 0.044698, 0.51484, 0.011246]
Predicted label: 2
Correct prediction
Energy consumption = 150.991924 pJ
sum error= 125
Actual label: 1
Output voltages: [0.039267, 0.79867, 0.1492, 0.015241, 0.22129, 0.001101, 0.65609, 0.0014964, 0.078498, 0.041772]
Predicted label: 1
Correct prediction
Energy consumption = 155.833805 pJ
sum error= 125
Actual label: 7
Output voltages: [0.026226, 0.22148, 0.35934, 0.087914, 0.0094011, 0.0010884, 0.0010714, 0.79872, 0.059815, 0.15245]
Predicted label: 7
Correct prediction
Energy consumption = 149.807961 pJ
sum error= 125
Actual label: 9
Output voltages: [0.72275, 0.001085, 0.082239, 0.0013413, 0.234, 0.0034977, 0.002294, 0.0020047, 0.47666, 0.79074]
Predicted label: 9
Correct prediction
Energy consumption = 148.041163 pJ
sum error= 125
Actual label: 4
Output voltages: [0.032221, 0.0025202, 0.45577, 0.10891, 0.79863, 0.011324, 0.17421, 0.046101, 0.010792, 0.27411]
Predicted label: 4
Correct prediction
Energy consumption = 148.776642 pJ
sum error= 125
Actual label: 4
Output voltages: [0.0116, 0.0095063, 0.086978, 0.026058, 0.79865, 0.0027156, 0.076463, 0.17176, 0.020106, 0.035548]
Predicted label: 4
Correct prediction
Energy consumption = 148.676168 pJ
sum error= 125
Actual label: 1
Output voltages: [0.043058, 0.52584, 0.065903, 0.78832, 0.0069173, 0.28416, 0.76475, 0.31893, 0.0025314, 0.0010938]
Predicted label: 3
Wrong prediction!
Energy consumption = 152.950373 pJ
sum error= 126
Actual label: 6
Output voltages: [0.19272, 0.13417, 0.04995, 0.0013132, 0.056835, 0.30972, 0.79872, 0.0056548, 0.28499, 0.021655]
Predicted label: 6
Correct prediction
Energy consumption = 150.108889 pJ
sum error= 126
Actual label: 7
Output voltages: [0.36949, 0.17009, 0.0023638, 0.0040008, 0.045692, 0.0093463, 0.039087, 0.79697, 0.03208, 0.40782]
Predicted label: 7
Correct prediction
Energy consumption = 148.359739 pJ
sum error= 126
Actual label: 2
Output voltages: [0.43005, 0.36463, 0.79878, 0.049051, 0.016925, 0.0013788, 0.37553, 0.08017, 0.37285, 0.062562]
Predicted label: 2
Correct prediction
Energy consumption = 152.825319 pJ
sum error= 126
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 227 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 227 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 227 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.025347, 0.30089, 0.65176, 0.015233, 0.017568, 0.0011918, 0.001066, 0.79874, 0.15542, 0.080206]
Predicted label: 7
Correct prediction
Energy consumption = 157.507239 pJ
sum error= 126
Actual label: 8
Output voltages: [0.01033, 0.050831, 0.053692, 0.045989, 0.020422, 0.010161, 0.014309, 0.034852, 0.79871, 0.33583]
Predicted label: 8
Correct prediction
Energy consumption = 153.068226 pJ
sum error= 126
Actual label: 8
Output voltages: [0.5905, 0.014042, 0.050149, 0.16706, 0.020725, 0.034384, 0.69054, 0.0068026, 0.79835, 0.011156]
Predicted label: 8
Correct prediction
Energy consumption = 145.674397 pJ
sum error= 126
Actual label: 1
Output voltages: [0.0079157, 0.79874, 0.03064, 0.03777, 0.034534, 0.0010998, 0.29742, 0.047663, 0.29762, 0.036279]
Predicted label: 1
Correct prediction
Energy consumption = 156.034059 pJ
sum error= 126
Actual label: 9
Output voltages: [0.38588, 0.04739, 0.045065, 0.093895, 0.22616, 0.023757, 0.0015142, 0.0084883, 0.37771, 0.79844]
Predicted label: 9
Correct prediction
Energy consumption = 151.905635 pJ
sum error= 126
Actual label: 7
Output voltages: [0.050608, 0.021371, 0.034126, 0.10901, 0.0079867, 0.0058041, 0.0010722, 0.79858, 0.036626, 0.309]
Predicted label: 7
Correct prediction
Energy consumption = 151.086382 pJ
sum error= 126
Actual label: 1
Output voltages: [0.029711, 0.79874, 0.005166, 0.75063, 0.015976, 0.036344, 0.016893, 0.001066, 0.40044, 0.76335]
Predicted label: 1
Correct prediction
Energy consumption = 159.583865 pJ
sum error= 126
Actual label: 1
Output voltages: [0.0039838, 0.79864, 0.0018675, 0.023274, 0.30946, 0.31221, 0.40903, 0.0018993, 0.035847, 0.028457]
Predicted label: 1
Correct prediction
Energy consumption = 153.254274 pJ
sum error= 126
Actual label: 7
Output voltages: [0.43454, 0.024649, 0.042051, 0.041458, 0.0015933, 0.0019189, 0.0011386, 0.79873, 0.62006, 0.18663]
Predicted label: 7
Correct prediction
Energy consumption = 152.899907 pJ
sum error= 126
Actual label: 5
Output voltages: [0.050221, 0.0010921, 0.001305, 0.28913, 0.013547, 0.79864, 0.020447, 0.11191, 0.78207, 0.018616]
Predicted label: 5
Correct prediction
Energy consumption = 140.249082 pJ
sum error= 126
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 228 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 228 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 228 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.11997, 0.0018524, 0.0010668, 0.74445, 0.18644, 0.77772, 0.015429, 0.3532, 0.028571, 0.0010717]
Predicted label: 5
Wrong prediction!
Energy consumption = 159.801133 pJ
sum error= 127
Actual label: 3
Output voltages: [0.34839, 0.013872, 0.035714, 0.79862, 0.011976, 0.024564, 0.024902, 0.012029, 0.54997, 0.095836]
Predicted label: 3
Correct prediction
Energy consumption = 140.962687 pJ
sum error= 127
Actual label: 5
Output voltages: [0.016676, 0.001066, 0.0026218, 0.22609, 0.037742, 0.79839, 0.24857, 0.016034, 0.76688, 0.066995]
Predicted label: 5
Correct prediction
Energy consumption = 143.607847 pJ
sum error= 127
Actual label: 1
Output voltages: [0.0038533, 0.79855, 0.027387, 0.16813, 0.32691, 0.0081946, 0.039209, 0.0089086, 0.50191, 0.043135]
Predicted label: 1
Correct prediction
Energy consumption = 167.557774 pJ
sum error= 127
Actual label: 3
Output voltages: [0.26144, 0.0067699, 0.11622, 0.79867, 0.02649, 0.086605, 0.016792, 0.021024, 0.54367, 0.039771]
Predicted label: 3
Correct prediction
Energy consumption = 143.145087 pJ
sum error= 127
Actual label: 7
Output voltages: [0.25415, 0.0096392, 0.13772, 0.023677, 0.031023, 0.0010661, 0.0010881, 0.79863, 0.11406, 0.071715]
Predicted label: 7
Correct prediction
Energy consumption = 146.048157 pJ
sum error= 127
Actual label: 6
Output voltages: [0.23411, 0.023798, 0.21106, 0.0010665, 0.20848, 0.015358, 0.79879, 0.003265, 0.3124, 0.023297]
Predicted label: 6
Correct prediction
Energy consumption = 154.732703 pJ
sum error= 127
Actual label: 1
Output voltages: [0.026294, 0.79854, 0.32009, 0.031493, 0.01276, 0.0010679, 0.37874, 0.0081194, 0.058496, 0.14361]
Predicted label: 1
Correct prediction
Energy consumption = 160.560326 pJ
sum error= 127
Actual label: 3
Output voltages: [0.75027, 0.013672, 0.040473, 0.79879, 0.0012011, 0.15932, 0.0054997, 0.0069971, 0.52008, 0.0023346]
Predicted label: 3
Correct prediction
Energy consumption = 145.296310 pJ
sum error= 127
Actual label: 8
Output voltages: [0.43037, 0.005822, 0.51301, 0.024859, 0.044062, 0.0092466, 0.029116, 0.0043399, 0.79878, 0.15504]
Predicted label: 8
Correct prediction
Energy consumption = 146.690844 pJ
sum error= 127
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 229 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 229 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 229 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.040619, 0.12256, 0.25159, 0.024929, 0.022632, 0.0011072, 0.0010725, 0.79871, 0.065713, 0.074874]
Predicted label: 7
Correct prediction
Energy consumption = 155.246973 pJ
sum error= 127
Actual label: 5
Output voltages: [0.36974, 0.0024666, 0.0037636, 0.33565, 0.0011605, 0.79802, 0.037122, 0.049871, 0.78329, 0.017658]
Predicted label: 5
Correct prediction
Energy consumption = 149.527840 pJ
sum error= 127
Actual label: 9
Output voltages: [0.64407, 0.015495, 0.010542, 0.43291, 0.079561, 0.018051, 0.0043099, 0.016415, 0.36378, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 147.119674 pJ
sum error= 127
Actual label: 9
Output voltages: [0.55582, 0.0042628, 0.69798, 0.0011499, 0.21967, 0.0010875, 0.7871, 0.0033359, 0.038632, 0.48612]
Predicted label: 6
Wrong prediction!
Energy consumption = 151.891435 pJ
sum error= 128
Actual label: 0
Output voltages: [0.79875, 0.060696, 0.015406, 0.020169, 0.0017095, 0.028621, 0.22527, 0.027396, 0.35878, 0.044635]
Predicted label: 0
Correct prediction
Energy consumption = 141.210353 pJ
sum error= 128
Actual label: 0
Output voltages: [0.79872, 0.16463, 0.033951, 0.0066135, 0.014243, 0.01805, 0.25187, 0.019474, 0.048673, 0.046133]
Predicted label: 0
Correct prediction
Energy consumption = 138.479728 pJ
sum error= 128
Actual label: 2
Output voltages: [0.20868, 0.48562, 0.7984, 0.33481, 0.0046485, 0.0012297, 0.37908, 0.025795, 0.64074, 0.03654]
Predicted label: 2
Correct prediction
Energy consumption = 152.273997 pJ
sum error= 128
Actual label: 8
Output voltages: [0.032844, 0.034536, 0.14086, 0.25143, 0.00537, 0.019083, 0.039711, 0.0083296, 0.79875, 0.26988]
Predicted label: 8
Correct prediction
Energy consumption = 147.403128 pJ
sum error= 128
Actual label: 8
Output voltages: [0.060598, 0.0037381, 0.026543, 0.58295, 0.0072149, 0.33198, 0.1704, 0.0036067, 0.79877, 0.055819]
Predicted label: 8
Correct prediction
Energy consumption = 143.046961 pJ
sum error= 128
Actual label: 2
Output voltages: [0.6629, 0.12541, 0.79867, 0.039265, 0.0010682, 0.0011132, 0.038471, 0.69222, 0.58752, 0.04341]
Predicted label: 2
Correct prediction
Energy consumption = 142.890279 pJ
sum error= 128
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 230 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 230 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 230 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.52866, 0.013658, 0.13189, 0.79869, 0.051584, 0.01211, 0.0048825, 0.052784, 0.40947, 0.012199]
Predicted label: 3
Correct prediction
Energy consumption = 143.076675 pJ
sum error= 128
Actual label: 7
Output voltages: [0.24225, 0.17109, 0.028349, 0.22817, 0.020241, 0.0010921, 0.0011496, 0.79875, 0.24501, 0.16231]
Predicted label: 7
Correct prediction
Energy consumption = 150.028999 pJ
sum error= 128
Actual label: 1
Output voltages: [0.004671, 0.79877, 0.13778, 0.42869, 0.06099, 0.0010685, 0.1962, 0.015214, 0.64, 0.091926]
Predicted label: 1
Correct prediction
Energy consumption = 158.316709 pJ
sum error= 128
Actual label: 3
Output voltages: [0.25878, 0.056147, 0.04073, 0.7986, 0.021458, 0.0089369, 0.03159, 0.012978, 0.45585, 0.2074]
Predicted label: 3
Correct prediction
Energy consumption = 141.334313 pJ
sum error= 128
Actual label: 0
Output voltages: [0.78493, 0.0022085, 0.033472, 0.0010822, 0.017704, 0.03941, 0.74151, 0.0011823, 0.042999, 0.11568]
Predicted label: 0
Correct prediction
Energy consumption = 150.987083 pJ
sum error= 128
Actual label: 3
Output voltages: [0.4053, 0.016754, 0.14456, 0.79876, 0.0076238, 0.014611, 0.0013976, 0.0022553, 0.7216, 0.0069818]
Predicted label: 3
Correct prediction
Energy consumption = 146.600875 pJ
sum error= 128
Actual label: 4
Output voltages: [0.0015213, 0.01907, 0.018104, 0.014691, 0.79871, 0.0017558, 0.050201, 0.02642, 0.04837, 0.040127]
Predicted label: 4
Correct prediction
Energy consumption = 151.125939 pJ
sum error= 128
Actual label: 4
Output voltages: [0.0088491, 0.0040865, 0.054922, 0.14612, 0.79877, 0.0010762, 0.033335, 0.070915, 0.12398, 0.01625]
Predicted label: 4
Correct prediction
Energy consumption = 143.420962 pJ
sum error= 128
Actual label: 3
Output voltages: [0.27754, 0.0085283, 0.18203, 0.79325, 0.0074987, 0.41171, 0.0010702, 0.22806, 0.78878, 0.010907]
Predicted label: 3
Correct prediction
Energy consumption = 147.809498 pJ
sum error= 128
Actual label: 8
Output voltages: [0.015371, 0.012793, 0.031864, 0.38172, 0.0027012, 0.29995, 0.027672, 0.0030444, 0.79877, 0.15666]
Predicted label: 8
Correct prediction
Energy consumption = 140.732494 pJ
sum error= 128
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 231 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 231 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 231 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33104, 0.0065826, 0.014557, 0.01666, 0.46203, 0.020598, 0.049797, 0.020377, 0.29029, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.323692 pJ
sum error= 128
Actual label: 2
Output voltages: [0.56406, 0.036222, 0.79786, 0.054729, 0.025114, 0.0013232, 0.34115, 0.075674, 0.64124, 0.024492]
Predicted label: 2
Correct prediction
Energy consumption = 153.000798 pJ
sum error= 128
Actual label: 3
Output voltages: [0.0433, 0.02121, 0.1334, 0.79879, 0.026244, 0.0055034, 0.0048019, 0.0064437, 0.62314, 0.022454]
Predicted label: 3
Correct prediction
Energy consumption = 133.734170 pJ
sum error= 128
Actual label: 9
Output voltages: [0.31338, 0.034978, 0.0091986, 0.75082, 0.023517, 0.010322, 0.0031304, 0.03131, 0.24966, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 149.117177 pJ
sum error= 128
Actual label: 7
Output voltages: [0.26266, 0.052518, 0.71445, 0.12957, 0.0014096, 0.0010666, 0.0010901, 0.79878, 0.32946, 0.073561]
Predicted label: 7
Correct prediction
Energy consumption = 141.457259 pJ
sum error= 128
Actual label: 1
Output voltages: [0.082031, 0.79853, 0.10173, 0.26415, 0.015411, 0.0029564, 0.099621, 0.0017869, 0.27744, 0.036168]
Predicted label: 1
Correct prediction
Energy consumption = 160.368636 pJ
sum error= 128
Actual label: 1
Output voltages: [0.22224, 0.79869, 0.75067, 0.31934, 0.057369, 0.0012052, 0.27672, 0.0011531, 0.036186, 0.20097]
Predicted label: 1
Correct prediction
Energy consumption = 152.994303 pJ
sum error= 128
Actual label: 7
Output voltages: [0.63397, 0.66694, 0.19484, 0.43931, 0.001728, 0.001442, 0.0011249, 0.79879, 0.014427, 0.5938]
Predicted label: 7
Correct prediction
Energy consumption = 154.738112 pJ
sum error= 128
Actual label: 0
Output voltages: [0.79316, 0.012146, 0.042498, 0.00282, 0.01343, 0.019482, 0.77192, 0.001684, 0.11356, 0.34721]
Predicted label: 0
Correct prediction
Energy consumption = 156.715488 pJ
sum error= 128
Actual label: 4
Output voltages: [0.014476, 0.006299, 0.27975, 0.0086428, 0.79863, 0.0045428, 0.6348, 0.086079, 0.047524, 0.025077]
Predicted label: 4
Correct prediction
Energy consumption = 145.724991 pJ
sum error= 128
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 232 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 232 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 232 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.20813, 0.10296, 0.023302, 0.083792, 0.25994, 0.047387, 0.0070906, 0.014621, 0.12138, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 153.515274 pJ
sum error= 128
Actual label: 6
Output voltages: [0.041728, 0.0425, 0.28032, 0.002641, 0.37142, 0.16918, 0.79868, 0.0046176, 0.52812, 0.010533]
Predicted label: 6
Correct prediction
Energy consumption = 147.671250 pJ
sum error= 128
Actual label: 5
Output voltages: [0.15331, 0.0012401, 0.010353, 0.57563, 0.021289, 0.79878, 0.029719, 0.061589, 0.77598, 0.095628]
Predicted label: 5
Correct prediction
Energy consumption = 143.506125 pJ
sum error= 128
Actual label: 9
Output voltages: [0.55843, 0.0035623, 0.025174, 0.033359, 0.18893, 0.065722, 0.010768, 0.092962, 0.1677, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.024989 pJ
sum error= 128
Actual label: 1
Output voltages: [0.017544, 0.79844, 0.016357, 0.16765, 0.034322, 0.0076776, 0.58197, 0.0099955, 0.048085, 0.11222]
Predicted label: 1
Correct prediction
Energy consumption = 168.782741 pJ
sum error= 128
Actual label: 7
Output voltages: [0.066962, 0.41786, 0.56655, 0.79876, 0.024152, 0.0010691, 0.045817, 0.1451, 0.042443, 0.22808]
Predicted label: 3
Wrong prediction!
Energy consumption = 151.628530 pJ
sum error= 129
Actual label: 0
Output voltages: [0.73083, 0.0022366, 0.038778, 0.023214, 0.0062933, 0.13913, 0.21954, 0.0011152, 0.7253, 0.12271]
Predicted label: 0
Correct prediction
Energy consumption = 148.963331 pJ
sum error= 129
Actual label: 2
Output voltages: [0.086957, 0.083324, 0.79879, 0.043095, 0.015482, 0.0012274, 0.3623, 0.019684, 0.68132, 0.045762]
Predicted label: 2
Correct prediction
Energy consumption = 150.035978 pJ
sum error= 129
Actual label: 0
Output voltages: [0.79879, 0.14582, 0.03587, 0.021287, 0.0090613, 0.04544, 0.72115, 0.04572, 0.129, 0.034807]
Predicted label: 0
Correct prediction
Energy consumption = 144.044330 pJ
sum error= 129
Actual label: 0
Output voltages: [0.79857, 0.014813, 0.78652, 0.070232, 0.0017633, 0.0010807, 0.11257, 0.7429, 0.025209, 0.0067986]
Predicted label: 0
Correct prediction
Energy consumption = 134.081020 pJ
sum error= 129
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 233 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 233 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 233 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0027877, 0.0081714, 0.15453, 0.011612, 0.79866, 0.0019182, 0.079614, 0.04235, 0.046502, 0.023287]
Predicted label: 4
Correct prediction
Energy consumption = 159.423688 pJ
sum error= 129
Actual label: 6
Output voltages: [0.041865, 0.037589, 0.46023, 0.0012562, 0.65, 0.31383, 0.79877, 0.0012591, 0.045543, 0.001151]
Predicted label: 6
Correct prediction
Energy consumption = 143.082569 pJ
sum error= 129
Actual label: 7
Output voltages: [0.21524, 0.021488, 0.021187, 0.37757, 0.0031379, 0.0012058, 0.0010913, 0.79867, 0.059902, 0.12558]
Predicted label: 7
Correct prediction
Energy consumption = 157.833051 pJ
sum error= 129
Actual label: 0
Output voltages: [0.79833, 0.056184, 0.27868, 0.0076236, 0.0076238, 0.0011854, 0.38387, 0.02282, 0.25198, 0.26555]
Predicted label: 0
Correct prediction
Energy consumption = 149.693897 pJ
sum error= 129
Actual label: 7
Output voltages: [0.20218, 0.016353, 0.51339, 0.030444, 0.0038823, 0.0010861, 0.0011637, 0.79879, 0.76131, 0.057768]
Predicted label: 7
Correct prediction
Energy consumption = 136.783634 pJ
sum error= 129
Actual label: 1
Output voltages: [0.0033229, 0.79849, 0.079963, 0.044085, 0.11665, 0.0072922, 0.46323, 0.02312, 0.15733, 0.074375]
Predicted label: 1
Correct prediction
Energy consumption = 162.763898 pJ
sum error= 129
Actual label: 4
Output voltages: [0.0010771, 0.019369, 0.032588, 0.0050455, 0.79873, 0.0011675, 0.36896, 0.31264, 0.039486, 0.012012]
Predicted label: 4
Correct prediction
Energy consumption = 150.993268 pJ
sum error= 129
Actual label: 6
Output voltages: [0.23966, 0.021419, 0.30409, 0.0011658, 0.25959, 0.46894, 0.79877, 0.0032729, 0.33723, 0.014617]
Predicted label: 6
Correct prediction
Energy consumption = 135.735027 pJ
sum error= 129
Actual label: 4
Output voltages: [0.025294, 0.073352, 0.046755, 0.15527, 0.79872, 0.001083, 0.017024, 0.008105, 0.0086069, 0.35737]
Predicted label: 4
Correct prediction
Energy consumption = 148.351952 pJ
sum error= 129
Actual label: 5
Output voltages: [0.042528, 0.0017554, 0.0011776, 0.28001, 0.0040967, 0.79835, 0.040285, 0.03568, 0.77009, 0.015846]
Predicted label: 5
Correct prediction
Energy consumption = 161.300849 pJ
sum error= 129
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 234 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 234 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 234 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0066216, 0.011315, 0.21487, 0.0041907, 0.79873, 0.0015304, 0.20658, 0.044206, 0.022955, 0.045898]
Predicted label: 4
Correct prediction
Energy consumption = 158.252943 pJ
sum error= 129
Actual label: 9
Output voltages: [0.66674, 0.0033234, 0.1069, 0.037029, 0.55303, 0.023683, 0.01162, 0.0047288, 0.029115, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 152.106674 pJ
sum error= 129
Actual label: 9
Output voltages: [0.62536, 0.0011683, 0.032559, 0.011766, 0.028568, 0.0071033, 0.0010707, 0.30929, 0.44026, 0.79609]
Predicted label: 9
Correct prediction
Energy consumption = 144.868528 pJ
sum error= 129
Actual label: 1
Output voltages: [0.39412, 0.79873, 0.61679, 0.078489, 0.034776, 0.0013429, 0.21683, 0.078801, 0.1905, 0.091426]
Predicted label: 1
Correct prediction
Energy consumption = 164.763860 pJ
sum error= 129
Actual label: 7
Output voltages: [0.27907, 0.091683, 0.0022263, 0.040535, 0.0032978, 0.0014769, 0.0010843, 0.79864, 0.46671, 0.45212]
Predicted label: 7
Correct prediction
Energy consumption = 148.947688 pJ
sum error= 129
Actual label: 9
Output voltages: [0.46518, 0.0010994, 0.0072726, 0.032074, 0.02989, 0.0093872, 0.0010665, 0.71944, 0.66939, 0.76249]
Predicted label: 9
Correct prediction
Energy consumption = 149.240094 pJ
sum error= 129
Actual label: 5
Output voltages: [0.049223, 0.0011135, 0.0012453, 0.41772, 0.3759, 0.79817, 0.14864, 0.010081, 0.78798, 0.050649]
Predicted label: 5
Correct prediction
Energy consumption = 138.846193 pJ
sum error= 129
Actual label: 3
Output voltages: [0.76044, 0.0088428, 0.32031, 0.79869, 0.077926, 0.064736, 0.010201, 0.029843, 0.60956, 0.025983]
Predicted label: 3
Correct prediction
Energy consumption = 134.613332 pJ
sum error= 129
Actual label: 3
Output voltages: [0.015461, 0.038646, 0.19693, 0.79879, 0.0088621, 0.0078755, 0.0081346, 0.046844, 0.42933, 0.28888]
Predicted label: 3
Correct prediction
Energy consumption = 140.909769 pJ
sum error= 129
Actual label: 8
Output voltages: [0.028537, 0.013158, 0.039328, 0.234, 0.0063544, 0.042416, 0.016401, 0.0054652, 0.79874, 0.23397]
Predicted label: 8
Correct prediction
Energy consumption = 144.820601 pJ
sum error= 129
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 235 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 235 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 235 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.21961, 0.029022, 0.79858, 0.057828, 0.029298, 0.0010877, 0.059688, 0.050673, 0.33548, 0.017281]
Predicted label: 2
Correct prediction
Energy consumption = 139.092139 pJ
sum error= 129
Actual label: 3
Output voltages: [0.68547, 0.063558, 0.03857, 0.7576, 0.0085339, 0.63813, 0.67917, 0.21424, 0.018196, 0.0012117]
Predicted label: 3
Correct prediction
Energy consumption = 140.071039 pJ
sum error= 129
Actual label: 6
Output voltages: [0.036928, 0.0068153, 0.68572, 0.0010822, 0.048265, 0.57908, 0.79861, 0.0012447, 0.47425, 0.021985]
Predicted label: 6
Correct prediction
Energy consumption = 137.608740 pJ
sum error= 129
Actual label: 2
Output voltages: [0.58773, 0.024999, 0.79712, 0.18235, 0.081238, 0.0011761, 0.30091, 0.018411, 0.71642, 0.020891]
Predicted label: 2
Correct prediction
Energy consumption = 145.203414 pJ
sum error= 129
Actual label: 2
Output voltages: [0.28082, 0.23276, 0.79879, 0.15414, 0.023319, 0.0012991, 0.36679, 0.0040621, 0.54786, 0.33666]
Predicted label: 2
Correct prediction
Energy consumption = 139.254127 pJ
sum error= 129
Actual label: 1
Output voltages: [0.038217, 0.79869, 0.014815, 0.037219, 0.047348, 0.0015181, 0.58217, 0.0010696, 0.41865, 0.031046]
Predicted label: 1
Correct prediction
Energy consumption = 156.660980 pJ
sum error= 129
Actual label: 1
Output voltages: [0.054671, 0.79835, 0.044496, 0.29398, 0.01358, 0.0086769, 0.69526, 0.02487, 0.12586, 0.097431]
Predicted label: 1
Correct prediction
Energy consumption = 146.392477 pJ
sum error= 129
Actual label: 1
Output voltages: [0.01534, 0.79859, 0.26096, 0.018301, 0.0071794, 0.0010833, 0.34917, 0.0015411, 0.27972, 0.016551]
Predicted label: 1
Correct prediction
Energy consumption = 153.145689 pJ
sum error= 129
Actual label: 1
Output voltages: [0.15778, 0.79778, 0.166, 0.32002, 0.41212, 0.0010976, 0.10432, 0.001378, 0.047078, 0.0014344]
Predicted label: 1
Correct prediction
Energy consumption = 142.806083 pJ
sum error= 129
Actual label: 1
Output voltages: [0.09696, 0.79864, 0.038241, 0.30687, 0.025184, 0.0011828, 0.076294, 0.0018739, 0.59847, 0.25686]
Predicted label: 1
Correct prediction
Energy consumption = 155.055143 pJ
sum error= 129
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 236 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 236 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 236 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.10152, 0.037638, 0.051245, 0.015477, 0.56196, 0.23019, 0.79873, 0.0021147, 0.61767, 0.0074839]
Predicted label: 6
Correct prediction
Energy consumption = 146.750556 pJ
sum error= 129
Actual label: 9
Output voltages: [0.1331, 0.0054428, 0.15517, 0.18012, 0.7987, 0.0011002, 0.0013397, 0.0087874, 0.033053, 0.78972]
Predicted label: 4
Wrong prediction!
Energy consumption = 152.249411 pJ
sum error= 130
Actual label: 8
Output voltages: [0.038822, 0.22022, 0.18727, 0.010391, 0.057287, 0.0011739, 0.34592, 0.001067, 0.79774, 0.29704]
Predicted label: 8
Correct prediction
Energy consumption = 159.842387 pJ
sum error= 130
Actual label: 4
Output voltages: [0.0058039, 0.012034, 0.018267, 0.0026499, 0.79838, 0.03911, 0.046838, 0.579, 0.28162, 0.0037255]
Predicted label: 4
Correct prediction
Energy consumption = 149.779013 pJ
sum error= 130
Actual label: 3
Output voltages: [0.38256, 0.012637, 0.037346, 0.79863, 0.019469, 0.01976, 0.020879, 0.017275, 0.55463, 0.041068]
Predicted label: 3
Correct prediction
Energy consumption = 150.370749 pJ
sum error= 130
Actual label: 7
Output voltages: [0.28579, 0.18006, 0.062178, 0.0033699, 0.0059195, 0.0013619, 0.001066, 0.79867, 0.57914, 0.03705]
Predicted label: 7
Correct prediction
Energy consumption = 133.919125 pJ
sum error= 130
Actual label: 1
Output voltages: [0.052172, 0.79839, 0.22272, 0.26381, 0.2295, 0.0022012, 0.41604, 0.0098907, 0.003947, 0.19099]
Predicted label: 1
Correct prediction
Energy consumption = 165.136030 pJ
sum error= 130
Actual label: 6
Output voltages: [0.18717, 0.024882, 0.023405, 0.026934, 0.59742, 0.45589, 0.79879, 0.011857, 0.74962, 0.0029345]
Predicted label: 6
Correct prediction
Energy consumption = 155.246202 pJ
sum error= 130
Actual label: 4
Output voltages: [0.011457, 0.0089682, 0.04077, 0.0026367, 0.7986, 0.0012062, 0.033906, 0.15361, 0.040256, 0.046705]
Predicted label: 4
Correct prediction
Energy consumption = 148.567342 pJ
sum error= 130
Actual label: 5
Output voltages: [0.011556, 0.014307, 0.0011542, 0.74189, 0.26366, 0.77772, 0.047079, 0.032094, 0.71186, 0.19892]
Predicted label: 5
Correct prediction
Energy consumption = 146.202435 pJ
sum error= 130
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 237 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 237 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 237 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.78172, 0.0020876, 0.014177, 0.0024978, 0.019543, 0.37602, 0.76276, 0.0013941, 0.28894, 0.1448]
Predicted label: 0
Correct prediction
Energy consumption = 155.650429 pJ
sum error= 130
Actual label: 4
Output voltages: [0.013119, 0.01341, 0.32598, 0.0035311, 0.79872, 0.0012949, 0.13617, 0.0089386, 0.027927, 0.57026]
Predicted label: 4
Correct prediction
Energy consumption = 144.938224 pJ
sum error= 130
Actual label: 7
Output voltages: [0.028151, 0.13683, 0.22338, 0.050863, 0.0035043, 0.0011409, 0.002635, 0.79861, 0.044423, 0.30824]
Predicted label: 7
Correct prediction
Energy consumption = 153.662879 pJ
sum error= 130
Actual label: 4
Output voltages: [0.0013213, 0.0036511, 0.039084, 0.037913, 0.79879, 0.0010791, 0.049222, 0.072097, 0.034959, 0.010283]
Predicted label: 4
Correct prediction
Energy consumption = 149.482288 pJ
sum error= 130
Actual label: 2
Output voltages: [0.39901, 0.16808, 0.79868, 0.053088, 0.0089231, 0.0011616, 0.16765, 0.058524, 0.7026, 0.019967]
Predicted label: 2
Correct prediction
Energy consumption = 153.909620 pJ
sum error= 130
Actual label: 4
Output voltages: [0.0092259, 0.0075549, 0.1869, 0.012122, 0.7986, 0.0079254, 0.28025, 0.024968, 0.037094, 0.28417]
Predicted label: 4
Correct prediction
Energy consumption = 154.180974 pJ
sum error= 130
Actual label: 0
Output voltages: [0.79875, 0.010454, 0.10621, 0.013865, 0.02843, 0.006915, 0.42845, 0.011679, 0.32147, 0.033468]
Predicted label: 0
Correct prediction
Energy consumption = 153.733787 pJ
sum error= 130
Actual label: 7
Output voltages: [0.051451, 0.15846, 0.38065, 0.085125, 0.010642, 0.0011352, 0.0011993, 0.79879, 0.41184, 0.33801]
Predicted label: 7
Correct prediction
Energy consumption = 145.307121 pJ
sum error= 130
Actual label: 0
Output voltages: [0.79878, 0.0012457, 0.030813, 0.0049234, 0.0090167, 0.19027, 0.26614, 0.024265, 0.68069, 0.0081117]
Predicted label: 0
Correct prediction
Energy consumption = 154.715069 pJ
sum error= 130
Actual label: 1
Output voltages: [0.0036736, 0.79865, 0.2863, 0.24243, 0.012697, 0.001116, 0.69935, 0.0044801, 0.036156, 0.024926]
Predicted label: 1
Correct prediction
Energy consumption = 160.745447 pJ
sum error= 130
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 238 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 238 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 238 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.57459, 0.0060321, 0.26402, 0.0099801, 0.2216, 0.0055586, 0.15733, 0.0031814, 0.27757, 0.79856]
Predicted label: 9
Correct prediction
Energy consumption = 157.235419 pJ
sum error= 130
Actual label: 8
Output voltages: [0.0098061, 0.030306, 0.12583, 0.011398, 0.0096808, 0.0021996, 0.034707, 0.03554, 0.79874, 0.42429]
Predicted label: 8
Correct prediction
Energy consumption = 141.563684 pJ
sum error= 130
Actual label: 8
Output voltages: [0.038008, 0.0012768, 0.38783, 0.52369, 0.0058993, 0.0054834, 0.010177, 0.04507, 0.79868, 0.072829]
Predicted label: 8
Correct prediction
Energy consumption = 146.385628 pJ
sum error= 130
Actual label: 6
Output voltages: [0.07701, 0.18608, 0.40956, 0.0027174, 0.18312, 0.12284, 0.79872, 0.0014597, 0.47639, 0.0052963]
Predicted label: 6
Correct prediction
Energy consumption = 149.788341 pJ
sum error= 130
Actual label: 0
Output voltages: [0.79877, 0.029646, 0.048879, 0.048354, 0.0092391, 0.016944, 0.53846, 0.033258, 0.24356, 0.41314]
Predicted label: 0
Correct prediction
Energy consumption = 159.617292 pJ
sum error= 130
Actual label: 0
Output voltages: [0.79831, 0.18944, 0.025503, 0.0065529, 0.0032063, 0.0022279, 0.67451, 0.038577, 0.15822, 0.15125]
Predicted label: 0
Correct prediction
Energy consumption = 132.887864 pJ
sum error= 130
Actual label: 4
Output voltages: [0.003904, 0.01417, 0.015266, 0.002684, 0.79858, 0.010964, 0.03054, 0.16636, 0.28202, 0.057118]
Predicted label: 4
Correct prediction
Energy consumption = 158.576551 pJ
sum error= 130
Actual label: 9
Output voltages: [0.082225, 0.79323, 0.022286, 0.019557, 0.11616, 0.0049277, 0.012993, 0.0045481, 0.067323, 0.39343]
Predicted label: 1
Wrong prediction!
Energy consumption = 158.478930 pJ
sum error= 131
Actual label: 6
Output voltages: [0.091228, 0.024723, 0.16292, 0.002876, 0.23492, 0.067923, 0.79879, 0.0068118, 0.71319, 0.0047086]
Predicted label: 6
Correct prediction
Energy consumption = 155.629050 pJ
sum error= 131
Actual label: 8
Output voltages: [0.0062792, 0.029262, 0.040772, 0.13666, 0.017466, 0.023062, 0.060692, 0.0022364, 0.79878, 0.37533]
Predicted label: 8
Correct prediction
Energy consumption = 149.290530 pJ
sum error= 131
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 239 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 239 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 239 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.22257, 0.25439, 0.79878, 0.075467, 0.0087199, 0.0013797, 0.26099, 0.030022, 0.35408, 0.073651]
Predicted label: 2
Correct prediction
Energy consumption = 151.928772 pJ
sum error= 131
Actual label: 2
Output voltages: [0.29513, 0.067252, 0.79879, 0.049849, 0.007482, 0.00123, 0.30192, 0.026328, 0.61647, 0.023375]
Predicted label: 2
Correct prediction
Energy consumption = 135.742574 pJ
sum error= 131
Actual label: 3
Output voltages: [0.38477, 0.045443, 0.051974, 0.79869, 0.0030253, 0.0054979, 0.016597, 0.01994, 0.5583, 0.039279]
Predicted label: 3
Correct prediction
Energy consumption = 149.363926 pJ
sum error= 131
Actual label: 8
Output voltages: [0.013471, 0.0032558, 0.12303, 0.36143, 0.010948, 0.016455, 0.021333, 0.0011126, 0.7966, 0.43105]
Predicted label: 8
Correct prediction
Energy consumption = 144.842271 pJ
sum error= 131
Actual label: 4
Output voltages: [0.031011, 0.017882, 0.30652, 0.0092962, 0.79869, 0.0011006, 0.047795, 0.041871, 0.025462, 0.66268]
Predicted label: 4
Correct prediction
Energy consumption = 144.962880 pJ
sum error= 131
Actual label: 8
Output voltages: [0.27973, 0.016019, 0.096898, 0.33108, 0.023766, 0.020794, 0.31154, 0.0010672, 0.79602, 0.0047958]
Predicted label: 8
Correct prediction
Energy consumption = 151.961724 pJ
sum error= 131
Actual label: 2
Output voltages: [0.61687, 0.017333, 0.79879, 0.10317, 0.0037462, 0.0012563, 0.31228, 0.13348, 0.41272, 0.001101]
Predicted label: 2
Correct prediction
Energy consumption = 142.743751 pJ
sum error= 131
Actual label: 2
Output voltages: [0.16029, 0.087001, 0.7985, 0.09636, 0.0013914, 0.0013149, 0.055033, 0.028392, 0.50979, 0.019381]
Predicted label: 2
Correct prediction
Energy consumption = 145.892374 pJ
sum error= 131
Actual label: 1
Output voltages: [0.033574, 0.79877, 0.027672, 0.028328, 0.015004, 0.0028419, 0.035579, 0.0037245, 0.7644, 0.010046]
Predicted label: 1
Correct prediction
Energy consumption = 150.873805 pJ
sum error= 131
Actual label: 7
Output voltages: [0.097954, 0.059436, 0.2321, 0.047312, 0.0047938, 0.0012898, 0.0011437, 0.79855, 0.092261, 0.23906]
Predicted label: 7
Correct prediction
Energy consumption = 149.345208 pJ
sum error= 131
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 240 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 240 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 240 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.036905, 0.0010679, 0.0053783, 0.60625, 0.0034344, 0.79879, 0.013103, 0.30743, 0.67333, 0.035604]
Predicted label: 5
Correct prediction
Energy consumption = 143.344309 pJ
sum error= 131
Actual label: 4
Output voltages: [0.0011602, 0.0023904, 0.12162, 0.022399, 0.79861, 0.0011363, 0.2213, 0.15067, 0.0308, 0.071793]
Predicted label: 4
Correct prediction
Energy consumption = 160.104252 pJ
sum error= 131
Actual label: 4
Output voltages: [0.0032039, 0.0091471, 0.082582, 0.021415, 0.79859, 0.0026976, 0.19738, 0.12626, 0.035467, 0.021624]
Predicted label: 4
Correct prediction
Energy consumption = 144.911403 pJ
sum error= 131
Actual label: 0
Output voltages: [0.79874, 0.063445, 0.022282, 0.10003, 0.003731, 0.16272, 0.35305, 0.01004, 0.02066, 0.080307]
Predicted label: 0
Correct prediction
Energy consumption = 165.043205 pJ
sum error= 131
Actual label: 4
Output voltages: [0.010718, 0.0037023, 0.31315, 0.013049, 0.79851, 0.0025141, 0.53991, 0.023025, 0.033322, 0.036377]
Predicted label: 4
Correct prediction
Energy consumption = 144.719644 pJ
sum error= 131
Actual label: 3
Output voltages: [0.72746, 0.0038597, 0.44432, 0.79879, 0.0045594, 0.025608, 0.0065319, 0.039582, 0.24134, 0.0044709]
Predicted label: 3
Correct prediction
Energy consumption = 150.955471 pJ
sum error= 131
Actual label: 9
Output voltages: [0.37715, 0.52166, 0.011162, 0.034223, 0.15214, 0.0011064, 0.021753, 0.011943, 0.40453, 0.75572]
Predicted label: 9
Correct prediction
Energy consumption = 156.589163 pJ
sum error= 131
Actual label: 7
Output voltages: [0.22701, 0.04813, 0.021092, 0.040516, 0.0089231, 0.012646, 0.0010758, 0.79867, 0.46052, 0.35477]
Predicted label: 7
Correct prediction
Energy consumption = 155.947155 pJ
sum error= 131
Actual label: 3
Output voltages: [0.16096, 0.036772, 0.024191, 0.79872, 0.043235, 0.036321, 0.0055076, 0.0070665, 0.2557, 0.043097]
Predicted label: 3
Correct prediction
Energy consumption = 152.374931 pJ
sum error= 131
Actual label: 1
Output voltages: [0.083229, 0.79877, 0.20532, 0.057363, 0.16796, 0.0011595, 0.1295, 0.010496, 0.29707, 0.1667]
Predicted label: 1
Correct prediction
Energy consumption = 163.055760 pJ
sum error= 131
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 241 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 241 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 241 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.013144, 0.048292, 0.20018, 0.0023408, 0.0013465, 0.11979, 0.03076, 0.052177, 0.036148]
Predicted label: 0
Correct prediction
Energy consumption = 160.729882 pJ
sum error= 131
Actual label: 1
Output voltages: [0.091107, 0.79835, 0.020132, 0.091881, 0.0037052, 0.0020451, 0.61202, 0.0057985, 0.14848, 0.17848]
Predicted label: 1
Correct prediction
Energy consumption = 164.102623 pJ
sum error= 131
Actual label: 2
Output voltages: [0.16942, 0.24753, 0.79874, 0.011428, 0.014527, 0.001339, 0.11664, 0.025326, 0.28141, 0.16311]
Predicted label: 2
Correct prediction
Energy consumption = 141.052465 pJ
sum error= 131
Actual label: 5
Output voltages: [0.209, 0.0011878, 0.0011638, 0.38007, 0.033639, 0.79868, 0.27166, 0.1969, 0.79482, 0.0067827]
Predicted label: 5
Correct prediction
Energy consumption = 152.755906 pJ
sum error= 131
Actual label: 9
Output voltages: [0.035566, 0.0023008, 0.053983, 0.022949, 0.77796, 0.0011653, 0.001519, 0.032841, 0.54084, 0.54349]
Predicted label: 4
Wrong prediction!
Energy consumption = 154.141690 pJ
sum error= 132
Actual label: 2
Output voltages: [0.29889, 0.010769, 0.79877, 0.030698, 0.039107, 0.0013271, 0.15299, 0.036108, 0.61164, 0.070843]
Predicted label: 2
Correct prediction
Energy consumption = 146.517013 pJ
sum error= 132
Actual label: 1
Output voltages: [0.012025, 0.79871, 0.014262, 0.12444, 0.03012, 0.0016839, 0.77336, 0.001474, 0.48668, 0.012507]
Predicted label: 1
Correct prediction
Energy consumption = 156.991573 pJ
sum error= 132
Actual label: 0
Output voltages: [0.79509, 0.044735, 0.065697, 0.021111, 0.021467, 0.0011775, 0.68931, 0.003581, 0.26016, 0.020819]
Predicted label: 0
Correct prediction
Energy consumption = 145.909819 pJ
sum error= 132
Actual label: 1
Output voltages: [0.12929, 0.79853, 0.019221, 0.01729, 0.40945, 0.0050046, 0.31689, 0.0060175, 0.018673, 0.064459]
Predicted label: 1
Correct prediction
Energy consumption = 161.070285 pJ
sum error= 132
Actual label: 8
Output voltages: [0.13326, 0.023371, 0.037684, 0.55868, 0.0013933, 0.020192, 0.022293, 0.0014906, 0.79877, 0.36423]
Predicted label: 8
Correct prediction
Energy consumption = 151.406400 pJ
sum error= 132
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 242 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 242 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 242 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.15878, 0.011184, 0.026901, 0.14875, 0.36027, 0.015463, 0.060995, 0.0084207, 0.068629, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 148.993229 pJ
sum error= 132
Actual label: 1
Output voltages: [0.024352, 0.79858, 0.051674, 0.6277, 0.0077329, 0.003989, 0.15389, 0.012021, 0.0048294, 0.2932]
Predicted label: 1
Correct prediction
Energy consumption = 169.225726 pJ
sum error= 132
Actual label: 6
Output voltages: [0.57853, 0.0024184, 0.0079209, 0.0020685, 0.75294, 0.0038432, 0.76071, 0.21223, 0.04701, 0.058328]
Predicted label: 6
Correct prediction
Energy consumption = 157.126819 pJ
sum error= 132
Actual label: 8
Output voltages: [0.012891, 0.047709, 0.16789, 0.028027, 0.0095892, 0.021876, 0.013877, 0.004699, 0.79879, 0.53429]
Predicted label: 8
Correct prediction
Energy consumption = 149.584056 pJ
sum error= 132
Actual label: 3
Output voltages: [0.26749, 0.010335, 0.047461, 0.79862, 0.038717, 0.023971, 0.012118, 0.036889, 0.39673, 0.086747]
Predicted label: 3
Correct prediction
Energy consumption = 149.999220 pJ
sum error= 132
Actual label: 8
Output voltages: [0.013035, 0.043787, 0.03161, 0.11967, 0.0068198, 0.047068, 0.0077978, 0.27571, 0.79869, 0.13277]
Predicted label: 8
Correct prediction
Energy consumption = 148.768659 pJ
sum error= 132
Actual label: 9
Output voltages: [0.33445, 0.0011289, 0.016958, 0.29357, 0.1376, 0.0032777, 0.0016872, 0.5776, 0.32225, 0.77029]
Predicted label: 9
Correct prediction
Energy consumption = 157.303716 pJ
sum error= 132
Actual label: 3
Output voltages: [0.2319, 0.021861, 0.087371, 0.79876, 0.0057869, 0.0040482, 0.0072931, 0.0036411, 0.53224, 0.050479]
Predicted label: 3
Correct prediction
Energy consumption = 139.004078 pJ
sum error= 132
Actual label: 6
Output voltages: [0.028261, 0.085186, 0.62849, 0.001066, 0.191, 0.044258, 0.79876, 0.0031855, 0.38709, 0.0034792]
Predicted label: 6
Correct prediction
Energy consumption = 152.089232 pJ
sum error= 132
Actual label: 2
Output voltages: [0.26082, 0.71917, 0.79852, 0.018294, 0.0030133, 0.0013799, 0.045214, 0.32947, 0.25207, 0.0074253]
Predicted label: 2
Correct prediction
Energy consumption = 147.399305 pJ
sum error= 132
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 243 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 243 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 243 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.01852, 0.04324, 0.053362, 0.45856, 0.001263, 0.037937, 0.02294, 0.0084773, 0.79879, 0.26854]
Predicted label: 8
Correct prediction
Energy consumption = 155.267750 pJ
sum error= 132
Actual label: 3
Output voltages: [0.77506, 0.0048302, 0.21229, 0.79872, 0.035746, 0.070834, 0.0019617, 0.029952, 0.54055, 0.023632]
Predicted label: 3
Correct prediction
Energy consumption = 145.910053 pJ
sum error= 132
Actual label: 2
Output voltages: [0.24947, 0.47809, 0.79875, 0.03946, 0.015716, 0.0013537, 0.21341, 0.074291, 0.14979, 0.19748]
Predicted label: 2
Correct prediction
Energy consumption = 145.311890 pJ
sum error= 132
Actual label: 2
Output voltages: [0.010739, 0.24367, 0.79698, 0.13653, 0.004435, 0.0012537, 0.023054, 0.11061, 0.61895, 0.023564]
Predicted label: 2
Correct prediction
Energy consumption = 140.715825 pJ
sum error= 132
Actual label: 1
Output voltages: [0.032395, 0.79868, 0.50605, 0.4152, 0.0012355, 0.0011054, 0.25952, 0.004442, 0.24595, 0.11901]
Predicted label: 1
Correct prediction
Energy consumption = 153.475345 pJ
sum error= 132
Actual label: 0
Output voltages: [0.79869, 0.082947, 0.084454, 0.0054305, 0.013391, 0.016177, 0.43122, 0.011641, 0.13451, 0.032541]
Predicted label: 0
Correct prediction
Energy consumption = 153.144246 pJ
sum error= 132
Actual label: 4
Output voltages: [0.025764, 0.0017652, 0.32073, 0.010917, 0.7986, 0.001616, 0.13086, 0.029371, 0.02724, 0.16329]
Predicted label: 4
Correct prediction
Energy consumption = 152.294050 pJ
sum error= 132
Actual label: 2
Output voltages: [0.28515, 0.72102, 0.79536, 0.036224, 0.069938, 0.0016066, 0.023786, 0.35166, 0.13827, 0.0048425]
Predicted label: 2
Correct prediction
Energy consumption = 145.657725 pJ
sum error= 132
Actual label: 9
Output voltages: [0.44621, 0.021715, 0.0091493, 0.047205, 0.084878, 0.0067487, 0.0013105, 0.040326, 0.26406, 0.79856]
Predicted label: 9
Correct prediction
Energy consumption = 161.850274 pJ
sum error= 132
Actual label: 2
Output voltages: [0.5273, 0.027757, 0.79879, 0.15381, 0.002023, 0.0010684, 0.3717, 0.021728, 0.7676, 0.017891]
Predicted label: 2
Correct prediction
Energy consumption = 149.480314 pJ
sum error= 132
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 244 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 244 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 244 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0038997, 0.018307, 0.25715, 0.025102, 0.79859, 0.016483, 0.20868, 0.45122, 0.036448, 0.023422]
Predicted label: 4
Correct prediction
Energy consumption = 152.704971 pJ
sum error= 132
Actual label: 3
Output voltages: [0.26413, 0.041723, 0.074585, 0.7987, 0.010609, 0.0014372, 0.019959, 0.03768, 0.21126, 0.1152]
Predicted label: 3
Correct prediction
Energy consumption = 153.190420 pJ
sum error= 132
Actual label: 7
Output voltages: [0.70389, 0.033473, 0.7476, 0.014328, 0.0010782, 0.0012388, 0.0014212, 0.7987, 0.68106, 0.19242]
Predicted label: 7
Correct prediction
Energy consumption = 152.958155 pJ
sum error= 132
Actual label: 9
Output voltages: [0.28543, 0.010057, 0.028185, 0.019349, 0.088993, 0.023251, 0.014452, 0.041382, 0.49077, 0.79601]
Predicted label: 9
Correct prediction
Energy consumption = 148.629324 pJ
sum error= 132
Actual label: 1
Output voltages: [0.10448, 0.79835, 0.20203, 0.17858, 0.0053793, 0.0037565, 0.69294, 0.0023567, 0.019237, 0.043553]
Predicted label: 1
Correct prediction
Energy consumption = 166.687885 pJ
sum error= 132
Actual label: 5
Output voltages: [0.017953, 0.0013735, 0.0010687, 0.1307, 0.13955, 0.79632, 0.035916, 0.06384, 0.49513, 0.12441]
Predicted label: 5
Correct prediction
Energy consumption = 154.769123 pJ
sum error= 132
Actual label: 2
Output voltages: [0.4521, 0.6517, 0.79879, 0.39119, 0.0064449, 0.0012267, 0.40528, 0.0064498, 0.19924, 0.093479]
Predicted label: 2
Correct prediction
Energy consumption = 155.550618 pJ
sum error= 132
Actual label: 4
Output voltages: [0.37384, 0.018812, 0.018872, 0.042269, 0.7984, 0.0011023, 0.0064431, 0.13859, 0.0059883, 0.78543]
Predicted label: 4
Correct prediction
Energy consumption = 156.423943 pJ
sum error= 132
Actual label: 9
Output voltages: [0.14633, 0.019425, 0.011404, 0.024044, 0.082721, 0.014616, 0.010022, 0.010566, 0.46769, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 143.951838 pJ
sum error= 132
Actual label: 0
Output voltages: [0.79606, 0.13863, 0.024076, 0.023446, 0.017221, 0.0042468, 0.75613, 0.056214, 0.23712, 0.19624]
Predicted label: 0
Correct prediction
Energy consumption = 161.130880 pJ
sum error= 132
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 245 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 245 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 245 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.040107, 0.0012207, 0.023373, 0.79852, 0.0095043, 0.61231, 0.049981, 0.029905, 0.27064, 0.0016729]
Predicted label: 3
Correct prediction
Energy consumption = 149.570346 pJ
sum error= 132
Actual label: 8
Output voltages: [0.0075816, 0.081421, 0.086014, 0.12527, 0.0085941, 0.029734, 0.015761, 0.061319, 0.79874, 0.13423]
Predicted label: 8
Correct prediction
Energy consumption = 152.598119 pJ
sum error= 132
Actual label: 5
Output voltages: [0.033624, 0.0014442, 0.0046544, 0.31373, 0.01484, 0.79878, 0.11128, 0.14369, 0.75251, 0.040222]
Predicted label: 5
Correct prediction
Energy consumption = 144.904101 pJ
sum error= 132
Actual label: 3
Output voltages: [0.19158, 0.045126, 0.087616, 0.79858, 0.031554, 0.016999, 0.020386, 0.056783, 0.30771, 0.24855]
Predicted label: 3
Correct prediction
Energy consumption = 145.853978 pJ
sum error= 132
Actual label: 6
Output voltages: [0.42782, 0.019077, 0.0096098, 0.2883, 0.0027334, 0.79402, 0.79719, 0.0064813, 0.59749, 0.0078698]
Predicted label: 6
Correct prediction
Energy consumption = 157.349222 pJ
sum error= 132
Actual label: 0
Output voltages: [0.79249, 0.029162, 0.24851, 0.0098287, 0.011374, 0.0022273, 0.76952, 0.022689, 0.093099, 0.08582]
Predicted label: 0
Correct prediction
Energy consumption = 143.041334 pJ
sum error= 132
Actual label: 9
Output voltages: [0.037618, 0.01727, 0.023751, 0.050277, 0.017143, 0.006615, 0.0025683, 0.020959, 0.66348, 0.79336]
Predicted label: 9
Correct prediction
Energy consumption = 149.309570 pJ
sum error= 132
Actual label: 4
Output voltages: [0.0014792, 0.010569, 0.060022, 0.0013824, 0.78094, 0.004769, 0.33517, 0.032332, 0.75249, 0.021431]
Predicted label: 4
Correct prediction
Energy consumption = 144.992177 pJ
sum error= 132
Actual label: 6
Output voltages: [0.12185, 0.035603, 0.078978, 0.0096687, 0.33029, 0.33838, 0.7987, 0.0017213, 0.631, 0.012892]
Predicted label: 6
Correct prediction
Energy consumption = 146.720269 pJ
sum error= 132
Actual label: 2
Output voltages: [0.31349, 0.62493, 0.79877, 0.080821, 0.0026759, 0.0011972, 0.035656, 0.34414, 0.033889, 0.13672]
Predicted label: 2
Correct prediction
Energy consumption = 161.680787 pJ
sum error= 132
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 246 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 246 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 246 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.023775, 0.0011507, 0.0010667, 0.27509, 0.45364, 0.79877, 0.52872, 0.015506, 0.77762, 0.028799]
Predicted label: 5
Correct prediction
Energy consumption = 150.791961 pJ
sum error= 132
Actual label: 0
Output voltages: [0.79876, 0.032746, 0.17433, 0.042207, 0.041711, 0.0018316, 0.28441, 0.012257, 0.036653, 0.38566]
Predicted label: 0
Correct prediction
Energy consumption = 157.908559 pJ
sum error= 132
Actual label: 2
Output voltages: [0.77715, 0.021668, 0.56739, 0.028168, 0.006575, 0.001128, 0.44477, 0.0056304, 0.7099, 0.15282]
Predicted label: 0
Wrong prediction!
Energy consumption = 146.048100 pJ
sum error= 133
Actual label: 7
Output voltages: [0.28061, 0.13446, 0.37932, 0.038485, 0.0043958, 0.0010674, 0.0011343, 0.79879, 0.12482, 0.47285]
Predicted label: 7
Correct prediction
Energy consumption = 153.178710 pJ
sum error= 133
Actual label: 4
Output voltages: [0.012925, 0.0017453, 0.20341, 0.014773, 0.79859, 0.012697, 0.25485, 0.0062263, 0.062253, 0.62235]
Predicted label: 4
Correct prediction
Energy consumption = 153.332824 pJ
sum error= 133
Actual label: 6
Output voltages: [0.058198, 0.019306, 0.11404, 0.0046144, 0.35873, 0.72361, 0.79876, 0.0010992, 0.38109, 0.0043063]
Predicted label: 6
Correct prediction
Energy consumption = 145.319556 pJ
sum error= 133
Actual label: 6
Output voltages: [0.059328, 0.044407, 0.049598, 0.0046295, 0.23038, 0.74361, 0.79872, 0.0019274, 0.30665, 0.073303]
Predicted label: 6
Correct prediction
Energy consumption = 126.642515 pJ
sum error= 133
Actual label: 8
Output voltages: [0.011969, 0.025765, 0.17868, 0.10546, 0.014088, 0.02226, 0.041743, 0.025517, 0.79879, 0.22594]
Predicted label: 8
Correct prediction
Energy consumption = 146.511874 pJ
sum error= 133
Actual label: 6
Output voltages: [0.053541, 0.30079, 0.11034, 0.0069169, 0.10201, 0.33999, 0.79859, 0.0071426, 0.19805, 0.020566]
Predicted label: 6
Correct prediction
Energy consumption = 148.815260 pJ
sum error= 133
Actual label: 6
Output voltages: [0.47183, 0.098926, 0.072975, 0.0021013, 0.21294, 0.21759, 0.79876, 0.016154, 0.45242, 0.0018329]
Predicted label: 6
Correct prediction
Energy consumption = 145.617552 pJ
sum error= 133
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 247 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 247 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 247 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.17571, 0.019416, 0.04525, 0.023216, 0.017528, 0.03712, 0.0082463, 0.050541, 0.79876, 0.41782]
Predicted label: 8
Correct prediction
Energy consumption = 154.259898 pJ
sum error= 133
Actual label: 6
Output voltages: [0.046827, 0.023428, 0.26363, 0.0022631, 0.46572, 0.064236, 0.79874, 0.0017834, 0.61368, 0.0062284]
Predicted label: 6
Correct prediction
Energy consumption = 147.800301 pJ
sum error= 133
Actual label: 9
Output voltages: [0.36903, 0.0024312, 0.0031216, 0.048483, 0.43013, 0.0046237, 0.0061715, 0.0033686, 0.56285, 0.79737]
Predicted label: 9
Correct prediction
Energy consumption = 151.289857 pJ
sum error= 133
Actual label: 1
Output voltages: [0.045893, 0.79874, 0.0057691, 0.035581, 0.18783, 0.010394, 0.42969, 0.0030593, 0.46934, 0.028487]
Predicted label: 1
Correct prediction
Energy consumption = 164.242649 pJ
sum error= 133
Actual label: 7
Output voltages: [0.15092, 0.065256, 0.050258, 0.25055, 0.012835, 0.0010691, 0.0011141, 0.79879, 0.64904, 0.048117]
Predicted label: 7
Correct prediction
Energy consumption = 157.767428 pJ
sum error= 133
Actual label: 2
Output voltages: [0.026596, 0.14826, 0.79876, 0.029058, 0.0018427, 0.0012378, 0.054155, 0.087349, 0.57422, 0.03374]
Predicted label: 2
Correct prediction
Energy consumption = 141.958130 pJ
sum error= 133
Actual label: 5
Output voltages: [0.083347, 0.016534, 0.0013319, 0.76676, 0.009974, 0.79656, 0.30365, 0.060522, 0.3587, 0.018608]
Predicted label: 5
Correct prediction
Energy consumption = 142.103940 pJ
sum error= 133
Actual label: 9
Output voltages: [0.10604, 0.0039175, 0.034343, 0.0064304, 0.38485, 0.022863, 0.023185, 0.022396, 0.34754, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 147.501175 pJ
sum error= 133
Actual label: 9
Output voltages: [0.32576, 0.0068059, 0.030767, 0.10673, 0.15865, 0.10256, 0.0018957, 0.027722, 0.095002, 0.79736]
Predicted label: 9
Correct prediction
Energy consumption = 146.331444 pJ
sum error= 133
Actual label: 0
Output voltages: [0.79867, 0.070939, 0.05864, 0.012448, 0.011598, 0.0033, 0.31211, 0.027691, 0.049999, 0.29792]
Predicted label: 0
Correct prediction
Energy consumption = 151.054337 pJ
sum error= 133
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 248 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 248 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 248 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.54946, 0.11448, 0.76106, 0.004757, 0.0028649, 0.0010703, 0.0019048, 0.79089, 0.059259, 0.68809]
Predicted label: 7
Correct prediction
Energy consumption = 149.239194 pJ
sum error= 133
Actual label: 2
Output voltages: [0.25883, 0.014134, 0.79878, 0.17407, 0.025412, 0.0012698, 0.30987, 0.10552, 0.72815, 0.0445]
Predicted label: 2
Correct prediction
Energy consumption = 142.954538 pJ
sum error= 133
Actual label: 7
Output voltages: [0.046468, 0.058767, 0.20385, 0.26774, 0.0010712, 0.0010874, 0.0011226, 0.79879, 0.74265, 0.14085]
Predicted label: 7
Correct prediction
Energy consumption = 153.960565 pJ
sum error= 133
Actual label: 6
Output voltages: [0.18798, 0.1386, 0.26706, 0.012035, 0.25986, 0.15429, 0.79875, 0.0011587, 0.18757, 0.01817]
Predicted label: 6
Correct prediction
Energy consumption = 150.216078 pJ
sum error= 133
Actual label: 7
Output voltages: [0.055428, 0.0053268, 0.0050091, 0.020604, 0.031613, 0.0086519, 0.0011224, 0.79879, 0.65319, 0.56506]
Predicted label: 7
Correct prediction
Energy consumption = 157.485059 pJ
sum error= 133
Actual label: 0
Output voltages: [0.79878, 0.18347, 0.010775, 0.033496, 0.0049865, 0.045045, 0.37682, 0.036019, 0.043594, 0.025526]
Predicted label: 0
Correct prediction
Energy consumption = 154.729292 pJ
sum error= 133
Actual label: 6
Output voltages: [0.11444, 0.015753, 0.43504, 0.0013147, 0.16828, 0.25413, 0.79878, 0.0054145, 0.47721, 0.0043999]
Predicted label: 6
Correct prediction
Energy consumption = 140.876002 pJ
sum error= 133
Actual label: 5
Output voltages: [0.012243, 0.0020709, 0.0011175, 0.078928, 0.046016, 0.79875, 0.33128, 0.012286, 0.72934, 0.051092]
Predicted label: 5
Correct prediction
Energy consumption = 151.941116 pJ
sum error= 133
Actual label: 2
Output voltages: [0.32554, 0.29458, 0.73759, 0.0030967, 0.1653, 0.0012849, 0.031822, 0.5819, 0.47492, 0.0056282]
Predicted label: 2
Correct prediction
Energy consumption = 162.010304 pJ
sum error= 133
Actual label: 4
Output voltages: [0.004024, 0.0068697, 0.14286, 0.0085891, 0.79863, 0.0028089, 0.27871, 0.017772, 0.044517, 0.17009]
Predicted label: 4
Correct prediction
Energy consumption = 151.911152 pJ
sum error= 133
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 249 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 249 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 249 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.033526, 0.14709, 0.36351, 0.018007, 0.01307, 0.0011562, 0.001184, 0.79879, 0.45079, 0.040444]
Predicted label: 7
Correct prediction
Energy consumption = 149.679059 pJ
sum error= 133
Actual label: 2
Output voltages: [0.39818, 0.25796, 0.79879, 0.44213, 0.023625, 0.0012462, 0.042238, 0.18082, 0.088925, 0.037489]
Predicted label: 2
Correct prediction
Energy consumption = 141.579835 pJ
sum error= 133
Actual label: 0
Output voltages: [0.79878, 0.544, 0.01982, 0.0088277, 0.015797, 0.0068635, 0.493, 0.027163, 0.10508, 0.48753]
Predicted label: 0
Correct prediction
Energy consumption = 145.681255 pJ
sum error= 133
Actual label: 9
Output voltages: [0.51264, 0.0177, 0.031719, 0.22074, 0.31665, 0.011579, 0.0010756, 0.12032, 0.12952, 0.7985]
Predicted label: 9
Correct prediction
Energy consumption = 152.722795 pJ
sum error= 133
Actual label: 9
Output voltages: [0.34243, 0.0055996, 0.021754, 0.26792, 0.35791, 0.060849, 0.021036, 0.011952, 0.063008, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 143.920391 pJ
sum error= 133
Actual label: 2
Output voltages: [0.35222, 0.027717, 0.79877, 0.18082, 0.047896, 0.0012146, 0.033218, 0.032053, 0.33672, 0.026765]
Predicted label: 2
Correct prediction
Energy consumption = 145.721435 pJ
sum error= 133
Actual label: 2
Output voltages: [0.05212, 0.034707, 0.79839, 0.60768, 0.01089, 0.0012086, 0.020592, 0.038074, 0.22367, 0.0086666]
Predicted label: 2
Correct prediction
Energy consumption = 135.300461 pJ
sum error= 133
Actual label: 9
Output voltages: [0.23692, 0.018501, 0.010647, 0.050259, 0.12166, 0.0078114, 0.0011381, 0.0031889, 0.4548, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 145.195518 pJ
sum error= 133
Actual label: 4
Output voltages: [0.0062785, 0.011734, 0.15813, 0.023858, 0.79858, 0.025867, 0.13369, 0.078889, 0.019796, 0.32413]
Predicted label: 4
Correct prediction
Energy consumption = 152.940417 pJ
sum error= 133
Actual label: 4
Output voltages: [0.0036091, 0.0053883, 0.2349, 0.0064617, 0.79855, 0.0020549, 0.14272, 0.27511, 0.03637, 0.27181]
Predicted label: 4
Correct prediction
Energy consumption = 146.189900 pJ
sum error= 133
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 250 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 250 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 250 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.24311, 0.29188, 0.79878, 0.050549, 0.031961, 0.0012928, 0.34914, 0.17278, 0.44792, 0.046342]
Predicted label: 2
Correct prediction
Energy consumption = 151.424811 pJ
sum error= 133
Actual label: 3
Output voltages: [0.75322, 0.012234, 0.02949, 0.79865, 0.013045, 0.027794, 0.010069, 0.025902, 0.29618, 0.04495]
Predicted label: 3
Correct prediction
Energy consumption = 143.527232 pJ
sum error= 133
Actual label: 3
Output voltages: [0.68509, 0.19774, 0.063674, 0.79872, 0.0089654, 0.010719, 0.027024, 0.003078, 0.48955, 0.014993]
Predicted label: 3
Correct prediction
Energy consumption = 137.260864 pJ
sum error= 133
Actual label: 2
Output voltages: [0.48165, 0.025405, 0.79874, 0.075128, 0.031786, 0.0010977, 0.1552, 0.042278, 0.36943, 0.0040625]
Predicted label: 2
Correct prediction
Energy consumption = 143.935136 pJ
sum error= 133
Actual label: 1
Output voltages: [0.0051779, 0.79841, 0.21816, 0.3619, 0.012063, 0.0018025, 0.34672, 0.028954, 0.014528, 0.08045]
Predicted label: 1
Correct prediction
Energy consumption = 158.365834 pJ
sum error= 133
Actual label: 7
Output voltages: [0.60813, 0.032584, 0.0046118, 0.0015095, 0.02812, 0.058955, 0.0015528, 0.79876, 0.27451, 0.047121]
Predicted label: 7
Correct prediction
Energy consumption = 158.663285 pJ
sum error= 133
Actual label: 0
Output voltages: [0.7987, 0.048787, 0.027153, 0.0050548, 0.049221, 0.01013, 0.76211, 0.0079027, 0.03396, 0.17501]
Predicted label: 0
Correct prediction
Energy consumption = 153.106816 pJ
sum error= 133
Actual label: 7
Output voltages: [0.18981, 0.01693, 0.14987, 0.79828, 0.019397, 0.0011117, 0.0010744, 0.74674, 0.43773, 0.036595]
Predicted label: 3
Wrong prediction!
Energy consumption = 148.304321 pJ
sum error= 134
Actual label: 6
Output voltages: [0.030929, 0.060215, 0.042518, 0.031168, 0.057215, 0.6917, 0.79878, 0.010447, 0.3564, 0.0074748]
Predicted label: 6
Correct prediction
Energy consumption = 149.493428 pJ
sum error= 134
Actual label: 4
Output voltages: [0.0022375, 0.0092778, 0.076465, 0.025922, 0.79872, 0.0059099, 0.03064, 0.028272, 0.072188, 0.043971]
Predicted label: 4
Correct prediction
Energy consumption = 152.664278 pJ
sum error= 134
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 251 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 251 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 251 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.013101, 0.79863, 0.033798, 0.022887, 0.027793, 0.0023317, 0.66483, 0.0027907, 0.40959, 0.0083981]
Predicted label: 1
Correct prediction
Energy consumption = 157.203545 pJ
sum error= 134
Actual label: 3
Output voltages: [0.17011, 0.0085575, 0.40123, 0.79873, 0.037384, 0.0020444, 0.052597, 0.039032, 0.61177, 0.049592]
Predicted label: 3
Correct prediction
Energy consumption = 143.590862 pJ
sum error= 134
Actual label: 8
Output voltages: [0.30575, 0.017109, 0.16996, 0.097275, 0.0016241, 0.0042926, 0.0081962, 0.0010917, 0.79381, 0.73597]
Predicted label: 8
Correct prediction
Energy consumption = 154.866768 pJ
sum error= 134
Actual label: 7
Output voltages: [0.26884, 0.031744, 0.22127, 0.72807, 0.018053, 0.0011151, 0.0013535, 0.78645, 0.40431, 0.048705]
Predicted label: 7
Correct prediction
Energy consumption = 150.460157 pJ
sum error= 134
Actual label: 4
Output voltages: [0.035252, 0.034815, 0.30265, 0.0029864, 0.79877, 0.0011184, 0.37001, 0.038291, 0.012172, 0.62122]
Predicted label: 4
Correct prediction
Energy consumption = 155.518847 pJ
sum error= 134
Actual label: 5
Output voltages: [0.24886, 0.0011688, 0.025735, 0.060513, 0.012601, 0.79809, 0.069116, 0.016503, 0.77447, 0.0046907]
Predicted label: 5
Correct prediction
Energy consumption = 151.524465 pJ
sum error= 134
Actual label: 9
Output voltages: [0.42461, 0.012436, 0.41538, 0.070325, 0.22501, 0.0024877, 0.15265, 0.0092444, 0.045751, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 146.825282 pJ
sum error= 134
Actual label: 2
Output voltages: [0.55348, 0.032546, 0.79868, 0.57442, 0.0016915, 0.0011825, 0.11049, 0.10441, 0.61368, 0.014035]
Predicted label: 2
Correct prediction
Energy consumption = 142.519100 pJ
sum error= 134
Actual label: 5
Output voltages: [0.051606, 0.0011469, 0.001925, 0.22594, 0.024953, 0.79879, 0.27958, 0.052467, 0.7501, 0.042104]
Predicted label: 5
Correct prediction
Energy consumption = 146.454335 pJ
sum error= 134
Actual label: 1
Output voltages: [0.010661, 0.79837, 0.022105, 0.071322, 0.019374, 0.0096988, 0.43478, 0.0051299, 0.0418, 0.11292]
Predicted label: 1
Correct prediction
Energy consumption = 166.937838 pJ
sum error= 134
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 252 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 252 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 252 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.048888, 0.12596, 0.04377, 0.34353, 0.008277, 0.0013576, 0.18981, 0.041635, 0.79865, 0.06067]
Predicted label: 8
Correct prediction
Energy consumption = 160.655893 pJ
sum error= 134
Actual label: 7
Output voltages: [0.7743, 0.056684, 0.15403, 0.0013477, 0.045726, 0.0011146, 0.0023085, 0.75599, 0.53506, 0.028321]
Predicted label: 0
Wrong prediction!
Energy consumption = 146.162079 pJ
sum error= 135
Actual label: 3
Output voltages: [0.050287, 0.003224, 0.051307, 0.79875, 0.1199, 0.018851, 0.015642, 0.061476, 0.50885, 0.16431]
Predicted label: 3
Correct prediction
Energy consumption = 149.636207 pJ
sum error= 135
Actual label: 7
Output voltages: [0.047511, 0.010295, 0.0024939, 0.0021265, 0.37584, 0.022891, 0.0069208, 0.79869, 0.178, 0.010355]
Predicted label: 7
Correct prediction
Energy consumption = 154.000542 pJ
sum error= 135
Actual label: 1
Output voltages: [0.0036497, 0.79857, 0.057804, 0.028619, 0.050158, 0.008031, 0.67066, 0.0014142, 0.42671, 0.040646]
Predicted label: 1
Correct prediction
Energy consumption = 163.285340 pJ
sum error= 135
Actual label: 5
Output voltages: [0.020071, 0.0016617, 0.0019218, 0.1543, 0.0067416, 0.78145, 0.063977, 0.0010917, 0.66479, 0.074339]
Predicted label: 5
Correct prediction
Energy consumption = 153.837869 pJ
sum error= 135
Actual label: 5
Output voltages: [0.01257, 0.0029506, 0.029907, 0.70957, 0.031486, 0.77745, 0.034977, 0.0047924, 0.7932, 0.051715]
Predicted label: 8
Wrong prediction!
Energy consumption = 142.352742 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79818, 0.2151, 0.057803, 0.042346, 0.02078, 0.0013231, 0.76812, 0.0039458, 0.24587, 0.18957]
Predicted label: 0
Correct prediction
Energy consumption = 152.660634 pJ
sum error= 136
Actual label: 9
Output voltages: [0.6108, 0.00954, 0.036206, 0.022838, 0.71699, 0.0026328, 0.035956, 0.023853, 0.031614, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 151.345469 pJ
sum error= 136
Actual label: 1
Output voltages: [0.01824, 0.79861, 0.041864, 0.042774, 0.012694, 0.0010719, 0.58412, 0.0027743, 0.33954, 0.01219]
Predicted label: 1
Correct prediction
Energy consumption = 162.887056 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 253 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 253 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 253 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.025474, 0.021751, 0.078102, 0.0061863, 0.79879, 0.0011188, 0.044432, 0.15703, 0.031604, 0.22454]
Predicted label: 4
Correct prediction
Energy consumption = 164.218824 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79878, 0.2051, 0.028152, 0.019288, 0.004479, 0.013804, 0.59179, 0.051334, 0.13895, 0.020044]
Predicted label: 0
Correct prediction
Energy consumption = 149.323414 pJ
sum error= 136
Actual label: 6
Output voltages: [0.10024, 0.42512, 0.033057, 0.076075, 0.0028166, 0.52957, 0.79512, 0.013409, 0.76175, 0.0035354]
Predicted label: 6
Correct prediction
Energy consumption = 150.441442 pJ
sum error= 136
Actual label: 3
Output voltages: [0.10475, 0.050393, 0.19622, 0.79872, 0.14245, 0.038757, 0.019795, 0.032405, 0.76469, 0.021895]
Predicted label: 3
Correct prediction
Energy consumption = 150.707569 pJ
sum error= 136
Actual label: 3
Output voltages: [0.023576, 0.0069819, 0.0019168, 0.79728, 0.026529, 0.69448, 0.022815, 0.028544, 0.60169, 0.0093248]
Predicted label: 3
Correct prediction
Energy consumption = 138.319396 pJ
sum error= 136
Actual label: 6
Output voltages: [0.090783, 0.18619, 0.27255, 0.0014139, 0.41239, 0.30619, 0.79868, 0.0014533, 0.35862, 0.023307]
Predicted label: 6
Correct prediction
Energy consumption = 160.986824 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79875, 0.048643, 0.033784, 0.024204, 0.016605, 0.0065734, 0.40782, 0.029026, 0.048266, 0.14627]
Predicted label: 0
Correct prediction
Energy consumption = 145.831200 pJ
sum error= 136
Actual label: 4
Output voltages: [0.0031779, 0.0087701, 0.070592, 0.012674, 0.79864, 0.0020535, 0.034979, 0.16608, 0.32533, 0.0085966]
Predicted label: 4
Correct prediction
Energy consumption = 159.313589 pJ
sum error= 136
Actual label: 9
Output voltages: [0.039283, 0.023207, 0.10096, 0.19505, 0.040412, 0.029046, 0.049031, 0.035178, 0.31459, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 146.648026 pJ
sum error= 136
Actual label: 7
Output voltages: [0.69062, 0.0091729, 0.046595, 0.70307, 0.084153, 0.0010729, 0.0012459, 0.78518, 0.071272, 0.052476]
Predicted label: 7
Correct prediction
Energy consumption = 145.083004 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 254 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 254 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 254 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.28009, 0.0011195, 0.013592, 0.3575, 0.0094306, 0.79814, 0.032404, 0.02378, 0.77667, 0.25933]
Predicted label: 5
Correct prediction
Energy consumption = 147.696325 pJ
sum error= 136
Actual label: 1
Output voltages: [0.038776, 0.7985, 0.052625, 0.13772, 0.14114, 0.0063056, 0.49498, 0.0037457, 0.148, 0.055658]
Predicted label: 1
Correct prediction
Energy consumption = 169.014452 pJ
sum error= 136
Actual label: 6
Output voltages: [0.43627, 0.028154, 0.062565, 0.020734, 0.028509, 0.087347, 0.79869, 0.009778, 0.42336, 0.0086974]
Predicted label: 6
Correct prediction
Energy consumption = 141.133518 pJ
sum error= 136
Actual label: 8
Output voltages: [0.027685, 0.013581, 0.021698, 0.53337, 0.0017026, 0.055422, 0.010955, 0.0067178, 0.79878, 0.018296]
Predicted label: 8
Correct prediction
Energy consumption = 145.745666 pJ
sum error= 136
Actual label: 9
Output voltages: [0.24374, 0.0041006, 0.028623, 0.14838, 0.064281, 0.0033481, 0.0010941, 0.23058, 0.39196, 0.79727]
Predicted label: 9
Correct prediction
Energy consumption = 149.219078 pJ
sum error= 136
Actual label: 5
Output voltages: [0.088056, 0.0035358, 0.0053745, 0.50822, 0.022305, 0.79807, 0.15999, 0.02664, 0.75947, 0.099297]
Predicted label: 5
Correct prediction
Energy consumption = 144.830077 pJ
sum error= 136
Actual label: 5
Output voltages: [0.041455, 0.039572, 0.0068022, 0.20072, 0.068422, 0.79866, 0.26803, 0.012515, 0.29399, 0.064884]
Predicted label: 5
Correct prediction
Energy consumption = 139.409142 pJ
sum error= 136
Actual label: 7
Output voltages: [0.061653, 0.014636, 0.42261, 0.069952, 0.0055217, 0.0011311, 0.0020341, 0.79878, 0.25824, 0.079352]
Predicted label: 7
Correct prediction
Energy consumption = 151.365729 pJ
sum error= 136
Actual label: 9
Output voltages: [0.39543, 0.0097118, 0.01711, 0.030126, 0.3753, 0.015174, 0.0028783, 0.0050128, 0.39422, 0.79836]
Predicted label: 9
Correct prediction
Energy consumption = 143.995386 pJ
sum error= 136
Actual label: 3
Output voltages: [0.060496, 0.050059, 0.040588, 0.79867, 0.025856, 0.0054602, 0.019592, 0.011589, 0.74259, 0.14889]
Predicted label: 3
Correct prediction
Energy consumption = 151.528971 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 255 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 255 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 255 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.23069, 0.0069401, 0.24943, 0.68567, 0.0028519, 0.0014414, 0.014347, 0.00107, 0.79685, 0.25376]
Predicted label: 8
Correct prediction
Energy consumption = 158.580670 pJ
sum error= 136
Actual label: 3
Output voltages: [0.06302, 0.019695, 0.54972, 0.79829, 0.015749, 0.0050948, 0.021324, 0.0010869, 0.67065, 0.033224]
Predicted label: 3
Correct prediction
Energy consumption = 142.218135 pJ
sum error= 136
Actual label: 8
Output voltages: [0.11429, 0.01145, 0.64763, 0.0052766, 0.025599, 0.001868, 0.038006, 0.02018, 0.79879, 0.13591]
Predicted label: 8
Correct prediction
Energy consumption = 145.185820 pJ
sum error= 136
Actual label: 1
Output voltages: [0.0012078, 0.79857, 0.032713, 0.024499, 0.2457, 0.048674, 0.43264, 0.0044707, 0.42417, 0.02964]
Predicted label: 1
Correct prediction
Energy consumption = 164.818378 pJ
sum error= 136
Actual label: 5
Output voltages: [0.029887, 0.0011347, 0.001068, 0.39854, 0.13338, 0.79877, 0.26526, 0.0030899, 0.72369, 0.039014]
Predicted label: 5
Correct prediction
Energy consumption = 142.714167 pJ
sum error= 136
Actual label: 3
Output voltages: [0.56068, 0.033448, 0.025543, 0.79861, 0.012648, 0.020107, 0.023783, 0.013649, 0.51448, 0.044186]
Predicted label: 3
Correct prediction
Energy consumption = 146.402024 pJ
sum error= 136
Actual label: 5
Output voltages: [0.029314, 0.001066, 0.0036569, 0.16628, 0.021706, 0.79216, 0.54809, 0.010967, 0.78551, 0.010426]
Predicted label: 5
Correct prediction
Energy consumption = 141.705177 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79879, 0.068988, 0.29306, 0.022445, 0.034171, 0.0023356, 0.5609, 0.010801, 0.61575, 0.020584]
Predicted label: 0
Correct prediction
Energy consumption = 155.580600 pJ
sum error= 136
Actual label: 5
Output voltages: [0.010956, 0.0010674, 0.0010905, 0.43057, 0.048725, 0.79807, 0.044647, 0.0082475, 0.74874, 0.099043]
Predicted label: 5
Correct prediction
Energy consumption = 156.207586 pJ
sum error= 136
Actual label: 5
Output voltages: [0.026507, 0.0011327, 0.021727, 0.74812, 0.039147, 0.77998, 0.030229, 0.05874, 0.70289, 0.03861]
Predicted label: 5
Correct prediction
Energy consumption = 144.570175 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 256 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 256 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 256 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.38504, 0.0077952, 0.050051, 0.79611, 0.0017563, 0.4816, 0.42592, 0.010697, 0.31681, 0.001101]
Predicted label: 3
Correct prediction
Energy consumption = 150.708914 pJ
sum error= 136
Actual label: 8
Output voltages: [0.032387, 0.026643, 0.17024, 0.059461, 0.02141, 0.037556, 0.032912, 0.015884, 0.7986, 0.18592]
Predicted label: 8
Correct prediction
Energy consumption = 148.643783 pJ
sum error= 136
Actual label: 6
Output voltages: [0.11333, 0.026361, 0.13513, 0.017703, 0.43855, 0.35945, 0.79855, 0.0029853, 0.7395, 0.013437]
Predicted label: 6
Correct prediction
Energy consumption = 151.810779 pJ
sum error= 136
Actual label: 7
Output voltages: [0.12409, 0.07025, 0.33422, 0.049981, 0.0022624, 0.001157, 0.0010664, 0.79874, 0.63309, 0.31718]
Predicted label: 7
Correct prediction
Energy consumption = 163.883337 pJ
sum error= 136
Actual label: 7
Output voltages: [0.31841, 0.43698, 0.35172, 0.080058, 0.01012, 0.0010693, 0.0010675, 0.79872, 0.36785, 0.24854]
Predicted label: 7
Correct prediction
Energy consumption = 142.515104 pJ
sum error= 136
Actual label: 7
Output voltages: [0.40374, 0.02206, 0.0069141, 0.24724, 0.019897, 0.0025159, 0.0011206, 0.79872, 0.60801, 0.40849]
Predicted label: 7
Correct prediction
Energy consumption = 144.596782 pJ
sum error= 136
Actual label: 3
Output voltages: [0.19497, 0.017823, 0.11333, 0.79873, 0.014115, 0.0012152, 0.0066355, 0.0060629, 0.63414, 0.035802]
Predicted label: 3
Correct prediction
Energy consumption = 149.154760 pJ
sum error= 136
Actual label: 7
Output voltages: [0.19517, 0.020756, 0.028895, 0.36175, 0.0043049, 0.0011383, 0.0012001, 0.79872, 0.5959, 0.17322]
Predicted label: 7
Correct prediction
Energy consumption = 147.931154 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79879, 0.17867, 0.0094499, 0.021233, 0.029376, 0.049044, 0.45445, 0.0062641, 0.013998, 0.26383]
Predicted label: 0
Correct prediction
Energy consumption = 154.423172 pJ
sum error= 136
Actual label: 5
Output voltages: [0.035888, 0.0010663, 0.0011543, 0.4225, 0.016501, 0.79879, 0.03082, 0.03689, 0.6671, 0.041973]
Predicted label: 5
Correct prediction
Energy consumption = 146.595255 pJ
sum error= 136
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 257 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 257 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 257 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.17292, 0.008342, 0.019555, 0.023482, 0.096209, 0.028907, 0.0038005, 0.024968, 0.59554, 0.79811]
Predicted label: 9
Correct prediction
Energy consumption = 155.024178 pJ
sum error= 136
Actual label: 0
Output voltages: [0.79854, 0.030899, 0.034263, 0.03535, 0.04919, 0.0023442, 0.67608, 0.041643, 0.45232, 0.037082]
Predicted label: 0
Correct prediction
Energy consumption = 161.150809 pJ
sum error= 136
Actual label: 2
Output voltages: [0.49903, 0.039728, 0.79874, 0.040845, 0.0097961, 0.0012111, 0.025094, 0.069105, 0.55429, 0.014549]
Predicted label: 2
Correct prediction
Energy consumption = 149.427546 pJ
sum error= 136
Actual label: 5
Output voltages: [0.32618, 0.016936, 0.0017715, 0.20483, 0.001085, 0.78893, 0.0041699, 0.0041304, 0.79875, 0.041659]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.916725 pJ
sum error= 137
Actual label: 5
Output voltages: [0.037501, 0.0012849, 0.002494, 0.56536, 0.014909, 0.7987, 0.037638, 0.39552, 0.67876, 0.26267]
Predicted label: 5
Correct prediction
Energy consumption = 144.978788 pJ
sum error= 137
Actual label: 3
Output voltages: [0.27532, 0.020075, 0.029022, 0.79866, 0.013121, 0.0089589, 0.011146, 0.016495, 0.55704, 0.12069]
Predicted label: 3
Correct prediction
Energy consumption = 139.340356 pJ
sum error= 137
Actual label: 1
Output voltages: [0.1725, 0.7986, 0.37318, 0.031, 0.010698, 0.0010976, 0.34834, 0.0016578, 0.12314, 0.092435]
Predicted label: 1
Correct prediction
Energy consumption = 160.548656 pJ
sum error= 137
Actual label: 7
Output voltages: [0.013461, 0.46233, 0.20073, 0.00585, 0.024137, 0.0011323, 0.0010664, 0.79879, 0.29912, 0.13681]
Predicted label: 7
Correct prediction
Energy consumption = 154.986864 pJ
sum error= 137
Actual label: 7
Output voltages: [0.30752, 0.20491, 0.79845, 0.036162, 0.0048398, 0.0012711, 0.001823, 0.79246, 0.15328, 0.56362]
Predicted label: 2
Wrong prediction!
Energy consumption = 142.584420 pJ
sum error= 138
Actual label: 8
Output voltages: [0.018917, 0.052143, 0.32394, 0.063319, 0.012003, 0.014912, 0.23765, 0.02797, 0.79867, 0.17326]
Predicted label: 8
Correct prediction
Energy consumption = 152.882836 pJ
sum error= 138
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 258 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 258 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 258 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.070696, 0.018911, 0.022526, 0.040272, 0.47338, 0.2752, 0.79879, 0.0018878, 0.75279, 0.017532]
Predicted label: 6
Correct prediction
Energy consumption = 153.880918 pJ
sum error= 138
Actual label: 5
Output voltages: [0.027838, 0.0011884, 0.0011035, 0.077812, 0.037868, 0.79871, 0.040077, 0.0037531, 0.59016, 0.042321]
Predicted label: 5
Correct prediction
Energy consumption = 147.337232 pJ
sum error= 138
Actual label: 9
Output voltages: [0.62476, 0.0030141, 0.11483, 0.43223, 0.030684, 0.028285, 0.0010815, 0.7443, 0.50244, 0.76615]
Predicted label: 9
Correct prediction
Energy consumption = 147.155615 pJ
sum error= 138
Actual label: 3
Output voltages: [0.052647, 0.010116, 0.30033, 0.79879, 0.011526, 0.013032, 0.0045835, 0.0057947, 0.76079, 0.030985]
Predicted label: 3
Correct prediction
Energy consumption = 140.853015 pJ
sum error= 138
Actual label: 8
Output voltages: [0.014538, 0.06878, 0.34863, 0.24446, 0.0055861, 0.025958, 0.19805, 0.044807, 0.79871, 0.038332]
Predicted label: 8
Correct prediction
Energy consumption = 147.431874 pJ
sum error= 138
Actual label: 9
Output voltages: [0.26904, 0.030394, 0.03303, 0.31997, 0.043293, 0.030597, 0.041732, 0.1014, 0.13178, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 154.170577 pJ
sum error= 138
Actual label: 5
Output voltages: [0.13681, 0.0013427, 0.001112, 0.54364, 0.12995, 0.79877, 0.14758, 0.02975, 0.72909, 0.1131]
Predicted label: 5
Correct prediction
Energy consumption = 149.242755 pJ
sum error= 138
Actual label: 3
Output voltages: [0.37367, 0.0021927, 0.016058, 0.79877, 0.0092531, 0.71515, 0.008009, 0.02221, 0.52947, 0.017333]
Predicted label: 3
Correct prediction
Energy consumption = 140.236769 pJ
sum error= 138
Actual label: 7
Output voltages: [0.5376, 0.028495, 0.0013214, 0.039718, 0.11986, 0.11781, 0.0016992, 0.79873, 0.57387, 0.74563]
Predicted label: 7
Correct prediction
Energy consumption = 151.618184 pJ
sum error= 138
Actual label: 9
Output voltages: [0.7847, 0.0073657, 0.031519, 0.014198, 0.040513, 0.024419, 0.029374, 0.0039525, 0.22283, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 148.888973 pJ
sum error= 138
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 259 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 259 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 259 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.053838, 0.79863, 0.056712, 0.054852, 0.027401, 0.0010681, 0.56056, 0.0013474, 0.14723, 0.10089]
Predicted label: 1
Correct prediction
Energy consumption = 171.128715 pJ
sum error= 138
Actual label: 7
Output voltages: [0.049218, 0.1067, 0.23783, 0.20921, 0.0085993, 0.0011018, 0.0057017, 0.79866, 0.049168, 0.1874]
Predicted label: 7
Correct prediction
Energy consumption = 155.210494 pJ
sum error= 138
Actual label: 0
Output voltages: [0.7987, 0.040411, 0.31455, 0.027638, 0.0087383, 0.0036616, 0.052831, 0.036765, 0.033092, 0.056571]
Predicted label: 0
Correct prediction
Energy consumption = 144.364367 pJ
sum error= 138
Actual label: 0
Output voltages: [0.79597, 0.03902, 0.049179, 0.024924, 0.016637, 0.0010858, 0.49188, 0.018035, 0.66609, 0.080525]
Predicted label: 0
Correct prediction
Energy consumption = 143.348422 pJ
sum error= 138
Actual label: 3
Output voltages: [0.37298, 0.0027981, 0.14199, 0.79875, 0.045164, 0.34825, 0.012272, 0.0065236, 0.52244, 0.019234]
Predicted label: 3
Correct prediction
Energy consumption = 145.512785 pJ
sum error= 138
Actual label: 7
Output voltages: [0.21321, 0.031404, 0.014433, 0.029235, 0.025426, 0.0027693, 0.0010877, 0.79868, 0.15005, 0.39084]
Predicted label: 7
Correct prediction
Energy consumption = 156.467888 pJ
sum error= 138
Actual label: 2
Output voltages: [0.075314, 0.44314, 0.7987, 0.038992, 0.012741, 0.0012441, 0.21176, 0.37045, 0.36057, 0.27943]
Predicted label: 2
Correct prediction
Energy consumption = 147.268379 pJ
sum error= 138
Actual label: 5
Output voltages: [0.010684, 0.0013625, 0.048157, 0.73066, 0.013722, 0.76728, 0.015839, 0.010279, 0.78764, 0.044645]
Predicted label: 8
Wrong prediction!
Energy consumption = 139.583243 pJ
sum error= 139
Actual label: 8
Output voltages: [0.037064, 0.032072, 0.76235, 0.026525, 0.03362, 0.0028706, 0.06848, 0.043213, 0.79879, 0.12281]
Predicted label: 8
Correct prediction
Energy consumption = 147.335683 pJ
sum error= 139
Actual label: 1
Output voltages: [0.026061, 0.79847, 0.04526, 0.16389, 0.0036638, 0.0011361, 0.34843, 0.0075949, 0.55016, 0.14674]
Predicted label: 1
Correct prediction
Energy consumption = 153.404517 pJ
sum error= 139
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 260 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 260 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 260 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.016599, 0.04399, 0.11126, 0.045156, 0.058155, 0.038212, 0.22286, 0.041326, 0.79868, 0.034862]
Predicted label: 8
Correct prediction
Energy consumption = 162.551201 pJ
sum error= 139
Actual label: 6
Output voltages: [0.2051, 0.12518, 0.35799, 0.0019339, 0.28374, 0.18413, 0.79874, 0.0013856, 0.47892, 0.026482]
Predicted label: 6
Correct prediction
Energy consumption = 151.526584 pJ
sum error= 139
Actual label: 2
Output voltages: [0.29975, 0.3445, 0.79789, 0.28689, 0.013889, 0.0012678, 0.024389, 0.034183, 0.19451, 0.037778]
Predicted label: 2
Correct prediction
Energy consumption = 154.426711 pJ
sum error= 139
Actual label: 9
Output voltages: [0.077916, 0.0061979, 0.046116, 0.015419, 0.037441, 0.0097408, 0.0013155, 0.039177, 0.75242, 0.79261]
Predicted label: 9
Correct prediction
Energy consumption = 158.942785 pJ
sum error= 139
Actual label: 5
Output voltages: [0.035736, 0.0020367, 0.0037128, 0.78563, 0.0070433, 0.76954, 0.036601, 0.016788, 0.65374, 0.092968]
Predicted label: 3
Wrong prediction!
Energy consumption = 142.637891 pJ
sum error= 140
Actual label: 7
Output voltages: [0.14812, 0.014085, 0.0059784, 0.045576, 0.01223, 0.0041243, 0.0010759, 0.79873, 0.073793, 0.66316]
Predicted label: 7
Correct prediction
Energy consumption = 151.314407 pJ
sum error= 140
Actual label: 5
Output voltages: [0.14461, 0.0010741, 0.011991, 0.20007, 0.010068, 0.79877, 0.066905, 0.04481, 0.7192, 0.089254]
Predicted label: 5
Correct prediction
Energy consumption = 146.349890 pJ
sum error= 140
Actual label: 7
Output voltages: [0.073085, 0.002861, 0.77449, 0.027815, 0.30481, 0.0010689, 0.0055674, 0.5845, 0.76175, 0.046086]
Predicted label: 2
Wrong prediction!
Energy consumption = 155.888550 pJ
sum error= 141
Actual label: 8
Output voltages: [0.0044683, 0.17376, 0.050066, 0.02256, 0.0051452, 0.0023843, 0.019944, 0.0095403, 0.79878, 0.4072]
Predicted label: 8
Correct prediction
Energy consumption = 153.385712 pJ
sum error= 141
Actual label: 6
Output voltages: [0.64564, 0.0315, 0.018894, 0.034797, 0.1471, 0.709, 0.79879, 0.0011033, 0.18049, 0.037824]
Predicted label: 6
Correct prediction
Energy consumption = 142.960047 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 261 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 261 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 261 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.071021, 0.009159, 0.79808, 0.21555, 0.0026284, 0.0011336, 0.042357, 0.031854, 0.7709, 0.022746]
Predicted label: 2
Correct prediction
Energy consumption = 143.550440 pJ
sum error= 141
Actual label: 5
Output voltages: [0.63344, 0.031644, 0.0010867, 0.75519, 0.0044377, 0.79452, 0.27172, 0.0054298, 0.58566, 0.0016113]
Predicted label: 5
Correct prediction
Energy consumption = 147.914552 pJ
sum error= 141
Actual label: 1
Output voltages: [0.088026, 0.79875, 0.046112, 0.28147, 0.010113, 0.0017352, 0.16519, 0.0010733, 0.42834, 0.041421]
Predicted label: 1
Correct prediction
Energy consumption = 158.550622 pJ
sum error= 141
Actual label: 4
Output voltages: [0.020122, 0.0076775, 0.20691, 0.0030027, 0.7987, 0.0021018, 0.1676, 0.33949, 0.053227, 0.1316]
Predicted label: 4
Correct prediction
Energy consumption = 160.379125 pJ
sum error= 141
Actual label: 8
Output voltages: [0.018335, 0.17119, 0.41815, 0.048832, 0.021264, 0.0065218, 0.04338, 0.0079651, 0.7987, 0.3087]
Predicted label: 8
Correct prediction
Energy consumption = 154.973327 pJ
sum error= 141
Actual label: 4
Output voltages: [0.0055294, 0.0038711, 0.048472, 0.03968, 0.79864, 0.0014247, 0.055059, 0.033044, 0.18943, 0.021155]
Predicted label: 4
Correct prediction
Energy consumption = 153.196866 pJ
sum error= 141
Actual label: 5
Output voltages: [0.0043788, 0.0020903, 0.026964, 0.1854, 0.051231, 0.79681, 0.22672, 0.0094136, 0.79556, 0.26075]
Predicted label: 5
Correct prediction
Energy consumption = 143.800751 pJ
sum error= 141
Actual label: 8
Output voltages: [0.010663, 0.058535, 0.03717, 0.057784, 0.0025442, 0.015548, 0.013988, 0.021646, 0.79874, 0.2636]
Predicted label: 8
Correct prediction
Energy consumption = 146.902860 pJ
sum error= 141
Actual label: 3
Output voltages: [0.26696, 0.0013163, 0.042993, 0.79879, 0.10438, 0.78085, 0.026436, 0.071399, 0.36684, 0.012204]
Predicted label: 3
Correct prediction
Energy consumption = 147.264960 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79877, 0.064694, 0.069299, 0.020541, 0.018875, 0.0017424, 0.50361, 0.01073, 0.32894, 0.030281]
Predicted label: 0
Correct prediction
Energy consumption = 157.640640 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 262 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 262 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 262 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.047475, 0.044987, 0.29781, 0.001595, 0.15485, 0.094826, 0.79875, 0.0037494, 0.71873, 0.0266]
Predicted label: 6
Correct prediction
Energy consumption = 150.156959 pJ
sum error= 141
Actual label: 2
Output voltages: [0.495, 0.0026771, 0.79877, 0.024022, 0.040342, 0.0013532, 0.12217, 0.047682, 0.64393, 0.0012902]
Predicted label: 2
Correct prediction
Energy consumption = 144.456799 pJ
sum error= 141
Actual label: 7
Output voltages: [0.040524, 0.040565, 0.035953, 0.59691, 0.14727, 0.0012416, 0.0010661, 0.79874, 0.20288, 0.054222]
Predicted label: 7
Correct prediction
Energy consumption = 149.701483 pJ
sum error= 141
Actual label: 3
Output voltages: [0.14399, 0.0071147, 0.056154, 0.79858, 0.041623, 0.034134, 0.015075, 0.017318, 0.43585, 0.10929]
Predicted label: 3
Correct prediction
Energy consumption = 140.855798 pJ
sum error= 141
Actual label: 3
Output voltages: [0.35224, 0.026919, 0.020305, 0.79864, 0.017574, 0.012673, 0.0056833, 0.012661, 0.36276, 0.039276]
Predicted label: 3
Correct prediction
Energy consumption = 138.059267 pJ
sum error= 141
Actual label: 2
Output voltages: [0.25563, 0.62689, 0.79865, 0.16487, 0.018817, 0.001386, 0.058242, 0.020677, 0.046309, 0.020144]
Predicted label: 2
Correct prediction
Energy consumption = 149.175828 pJ
sum error= 141
Actual label: 1
Output voltages: [0.0012631, 0.79864, 0.020437, 0.15416, 0.05127, 0.0021592, 0.58743, 0.02124, 0.65384, 0.02086]
Predicted label: 1
Correct prediction
Energy consumption = 159.637098 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79617, 0.042527, 0.036219, 0.041013, 0.014051, 0.0061821, 0.68151, 0.042378, 0.29448, 0.023912]
Predicted label: 0
Correct prediction
Energy consumption = 153.090291 pJ
sum error= 141
Actual label: 7
Output voltages: [0.046873, 0.0067282, 0.51162, 0.48417, 0.032789, 0.0010828, 0.0012161, 0.79853, 0.098035, 0.39925]
Predicted label: 7
Correct prediction
Energy consumption = 149.812895 pJ
sum error= 141
Actual label: 3
Output voltages: [0.037604, 0.023296, 0.053946, 0.79639, 0.0341, 0.46678, 0.014109, 0.0013816, 0.6565, 0.3186]
Predicted label: 3
Correct prediction
Energy consumption = 141.982230 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 263 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 263 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 263 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.025346, 0.019505, 0.065941, 0.0040576, 0.79867, 0.0074951, 0.034297, 0.046444, 0.02499, 0.53158]
Predicted label: 4
Correct prediction
Energy consumption = 161.530470 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79861, 0.02333, 0.019191, 0.0014899, 0.22226, 0.02305, 0.79437, 0.049691, 0.043945, 0.048356]
Predicted label: 0
Correct prediction
Energy consumption = 154.756092 pJ
sum error= 141
Actual label: 3
Output voltages: [0.11901, 0.010254, 0.25124, 0.79877, 0.0033971, 0.039004, 0.003487, 0.001358, 0.70539, 0.021744]
Predicted label: 3
Correct prediction
Energy consumption = 149.267613 pJ
sum error= 141
Actual label: 9
Output voltages: [0.18019, 0.020745, 0.034082, 0.022488, 0.028321, 0.010543, 0.0023705, 0.014638, 0.76343, 0.79694]
Predicted label: 9
Correct prediction
Energy consumption = 143.552740 pJ
sum error= 141
Actual label: 3
Output voltages: [0.44389, 0.025084, 0.03165, 0.7987, 0.019008, 0.019175, 0.014908, 0.0042294, 0.4711, 0.066097]
Predicted label: 3
Correct prediction
Energy consumption = 145.522324 pJ
sum error= 141
Actual label: 2
Output voltages: [0.30292, 0.038418, 0.79879, 0.23405, 0.024058, 0.0011819, 0.26784, 0.64627, 0.086255, 0.023435]
Predicted label: 2
Correct prediction
Energy consumption = 138.077663 pJ
sum error= 141
Actual label: 8
Output voltages: [0.25175, 0.026652, 0.41378, 0.19549, 0.0052042, 0.038047, 0.015963, 0.015156, 0.79879, 0.38664]
Predicted label: 8
Correct prediction
Energy consumption = 153.593108 pJ
sum error= 141
Actual label: 9
Output voltages: [0.33834, 0.001066, 0.20894, 0.027193, 0.76258, 0.0077874, 0.020668, 0.011956, 0.024837, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 147.008623 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79879, 0.1065, 0.045105, 0.094032, 0.0012119, 0.026692, 0.58994, 0.010545, 0.2002, 0.049981]
Predicted label: 0
Correct prediction
Energy consumption = 144.876891 pJ
sum error= 141
Actual label: 3
Output voltages: [0.15505, 0.0063814, 0.082622, 0.79869, 0.055328, 0.028219, 0.035218, 0.025953, 0.51974, 0.050438]
Predicted label: 3
Correct prediction
Energy consumption = 138.968346 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 264 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 264 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 264 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.011565, 0.3036, 0.045314, 0.19101, 0.0045105, 0.0095717, 0.02095, 0.007387, 0.79869, 0.47468]
Predicted label: 8
Correct prediction
Energy consumption = 149.815388 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79879, 0.0043398, 0.0077417, 0.028708, 0.0011644, 0.24583, 0.32391, 0.019353, 0.47841, 0.0011343]
Predicted label: 0
Correct prediction
Energy consumption = 148.819910 pJ
sum error= 141
Actual label: 7
Output voltages: [0.020337, 0.068238, 0.022389, 0.0077642, 0.032203, 0.0011212, 0.0010713, 0.79867, 0.057896, 0.043697]
Predicted label: 7
Correct prediction
Energy consumption = 156.324327 pJ
sum error= 141
Actual label: 6
Output voltages: [0.23855, 0.10577, 0.029826, 0.016615, 0.27452, 0.29785, 0.79871, 0.0041282, 0.63224, 0.012945]
Predicted label: 6
Correct prediction
Energy consumption = 150.276689 pJ
sum error= 141
Actual label: 5
Output voltages: [0.026938, 0.0010727, 0.0029278, 0.30118, 0.023716, 0.79866, 0.31021, 0.022842, 0.75095, 0.03208]
Predicted label: 5
Correct prediction
Energy consumption = 145.955105 pJ
sum error= 141
Actual label: 4
Output voltages: [0.015668, 0.0016034, 0.04463, 0.03126, 0.79869, 0.0010677, 0.17666, 0.36582, 0.073215, 0.018196]
Predicted label: 4
Correct prediction
Energy consumption = 158.096279 pJ
sum error= 141
Actual label: 7
Output voltages: [0.037629, 0.12761, 0.22279, 0.16789, 0.0037338, 0.0010798, 0.001316, 0.79869, 0.29098, 0.35854]
Predicted label: 7
Correct prediction
Energy consumption = 153.727974 pJ
sum error= 141
Actual label: 3
Output voltages: [0.54166, 0.06078, 0.090172, 0.79855, 0.14254, 0.014646, 0.022838, 0.020481, 0.70559, 0.073931]
Predicted label: 3
Correct prediction
Energy consumption = 147.491699 pJ
sum error= 141
Actual label: 9
Output voltages: [0.77045, 0.0011512, 0.42758, 0.17775, 0.58938, 0.001572, 0.0014411, 0.0015154, 0.059206, 0.79512]
Predicted label: 9
Correct prediction
Energy consumption = 147.508491 pJ
sum error= 141
Actual label: 0
Output voltages: [0.79867, 0.030557, 0.38099, 0.0080316, 0.029178, 0.0011023, 0.46182, 0.025235, 0.44332, 0.037191]
Predicted label: 0
Correct prediction
Energy consumption = 137.294550 pJ
sum error= 141
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 265 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 265 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 265 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.029269, 0.01258, 0.16115, 0.030377, 0.038395, 0.025658, 0.020627, 0.0016819, 0.79876, 0.26323]
Predicted label: 8
Correct prediction
Energy consumption = 153.387161 pJ
sum error= 141
Actual label: 6
Output voltages: [0.40009, 0.049728, 0.030172, 0.007912, 0.55574, 0.28939, 0.79876, 0.0030254, 0.50254, 0.013889]
Predicted label: 6
Correct prediction
Energy consumption = 151.406041 pJ
sum error= 141
Actual label: 2
Output voltages: [0.023609, 0.6752, 0.79871, 0.007522, 0.0173, 0.0013394, 0.038371, 0.51416, 0.13082, 0.026196]
Predicted label: 2
Correct prediction
Energy consumption = 152.823350 pJ
sum error= 141
Actual label: 5
Output voltages: [0.058362, 0.0010668, 0.0019025, 0.17613, 0.021428, 0.79871, 0.058376, 0.055944, 0.79422, 0.0084515]
Predicted label: 5
Correct prediction
Energy consumption = 144.982490 pJ
sum error= 141
Actual label: 6
Output voltages: [0.32417, 0.79879, 0.34863, 0.045919, 0.020054, 0.001795, 0.76564, 0.0015511, 0.24172, 0.0018804]
Predicted label: 1
Wrong prediction!
Energy consumption = 159.432332 pJ
sum error= 142
Actual label: 1
Output voltages: [0.021513, 0.7984, 0.13092, 0.024499, 0.066431, 0.0074662, 0.59818, 0.0088932, 0.13149, 0.033992]
Predicted label: 1
Correct prediction
Energy consumption = 145.903007 pJ
sum error= 142
Actual label: 0
Output voltages: [0.79878, 0.050926, 0.062618, 0.0022124, 0.034561, 0.0069135, 0.35473, 0.028888, 0.2204, 0.46136]
Predicted label: 0
Correct prediction
Energy consumption = 156.598287 pJ
sum error= 142
Actual label: 0
Output voltages: [0.79861, 0.19095, 0.01961, 0.019247, 0.0067799, 0.014979, 0.71591, 0.032503, 0.10522, 0.03317]
Predicted label: 0
Correct prediction
Energy consumption = 143.432595 pJ
sum error= 142
Actual label: 4
Output voltages: [0.010969, 0.08391, 0.021304, 0.0024202, 0.79876, 0.0012403, 0.4658, 0.02298, 0.046033, 0.0069374]
Predicted label: 4
Correct prediction
Energy consumption = 159.957909 pJ
sum error= 142
Actual label: 4
Output voltages: [0.0010686, 0.03926, 0.0071712, 0.0077453, 0.7958, 0.0019222, 0.039244, 0.069255, 0.45798, 0.027433]
Predicted label: 4
Correct prediction
Energy consumption = 147.580573 pJ
sum error= 142
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 266 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 266 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 266 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.028504, 0.051162, 0.0031594, 0.048325, 0.0056872, 0.5114, 0.0087365, 0.38062, 0.3066]
Predicted label: 0
Correct prediction
Energy consumption = 157.211649 pJ
sum error= 142
Actual label: 1
Output voltages: [0.012111, 0.7986, 0.057107, 0.049421, 0.042757, 0.0012022, 0.75457, 0.0021624, 0.25254, 0.071028]
Predicted label: 1
Correct prediction
Energy consumption = 161.030414 pJ
sum error= 142
Actual label: 2
Output voltages: [0.47407, 0.021639, 0.79879, 0.3339, 0.030212, 0.0010789, 0.051938, 0.12549, 0.57006, 0.0073266]
Predicted label: 2
Correct prediction
Energy consumption = 149.493541 pJ
sum error= 142
Actual label: 3
Output voltages: [0.25766, 0.020026, 0.053058, 0.79867, 0.018159, 0.0016462, 0.021354, 0.048145, 0.63351, 0.035785]
Predicted label: 3
Correct prediction
Energy consumption = 144.107741 pJ
sum error= 142
Actual label: 2
Output voltages: [0.6746, 0.0068653, 0.7982, 0.049193, 0.016485, 0.0010858, 0.15237, 0.026275, 0.60142, 0.029495]
Predicted label: 2
Correct prediction
Energy consumption = 141.232669 pJ
sum error= 142
Actual label: 7
Output voltages: [0.39387, 0.0059379, 0.6645, 0.69223, 0.0094234, 0.0012844, 0.0017237, 0.79396, 0.21698, 0.2613]
Predicted label: 7
Correct prediction
Energy consumption = 140.738777 pJ
sum error= 142
Actual label: 7
Output voltages: [0.060728, 0.007057, 0.043773, 0.52105, 0.0067672, 0.011819, 0.0010791, 0.79871, 0.086703, 0.65752]
Predicted label: 7
Correct prediction
Energy consumption = 133.223787 pJ
sum error= 142
Actual label: 8
Output voltages: [0.04068, 0.003123, 0.022812, 0.055148, 0.001281, 0.4886, 0.012187, 0.010192, 0.79879, 0.020128]
Predicted label: 8
Correct prediction
Energy consumption = 146.235811 pJ
sum error= 142
Actual label: 5
Output voltages: [0.082599, 0.0011254, 0.0056899, 0.70559, 0.14245, 0.62085, 0.17769, 0.010271, 0.61186, 0.60375]
Predicted label: 3
Wrong prediction!
Energy consumption = 147.742402 pJ
sum error= 143
Actual label: 2
Output voltages: [0.28371, 0.034414, 0.79873, 0.090517, 0.010229, 0.0012032, 0.045456, 0.035162, 0.34774, 0.019955]
Predicted label: 2
Correct prediction
Energy consumption = 150.276760 pJ
sum error= 143
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 267 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 267 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 267 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.48117, 0.0011087, 0.0045823, 0.70184, 0.0026371, 0.77163, 0.016196, 0.0381, 0.77968, 0.036059]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.172698 pJ
sum error= 144
Actual label: 7
Output voltages: [0.14122, 0.18393, 0.72366, 0.019121, 0.016036, 0.0010812, 0.0010767, 0.79873, 0.17696, 0.033999]
Predicted label: 7
Correct prediction
Energy consumption = 141.600529 pJ
sum error= 144
Actual label: 6
Output voltages: [0.2937, 0.033909, 0.13446, 0.0020012, 0.086228, 0.27179, 0.79879, 0.0019388, 0.42141, 0.0049847]
Predicted label: 6
Correct prediction
Energy consumption = 160.372196 pJ
sum error= 144
Actual label: 9
Output voltages: [0.40218, 0.044624, 0.011368, 0.0254, 0.477, 0.0021095, 0.0048558, 0.022636, 0.059403, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 156.846392 pJ
sum error= 144
Actual label: 1
Output voltages: [0.22332, 0.79846, 0.053633, 0.16968, 0.062539, 0.0015076, 0.24807, 0.012098, 0.02738, 0.21842]
Predicted label: 1
Correct prediction
Energy consumption = 164.489797 pJ
sum error= 144
Actual label: 4
Output voltages: [0.003347, 0.021055, 0.036579, 0.0010859, 0.79869, 0.0023886, 0.10321, 0.20085, 0.21036, 0.037118]
Predicted label: 4
Correct prediction
Energy consumption = 154.811762 pJ
sum error= 144
Actual label: 1
Output voltages: [0.01957, 0.79855, 0.0014449, 0.049533, 0.075633, 0.020201, 0.57074, 0.0079189, 0.11103, 0.095051]
Predicted label: 1
Correct prediction
Energy consumption = 154.310218 pJ
sum error= 144
Actual label: 6
Output voltages: [0.081232, 0.033345, 0.11931, 0.0033174, 0.4535, 0.19647, 0.79877, 0.0030281, 0.53708, 0.002467]
Predicted label: 6
Correct prediction
Energy consumption = 143.710618 pJ
sum error= 144
Actual label: 4
Output voltages: [0.16546, 0.007794, 0.74639, 0.0035876, 0.79878, 0.0011557, 0.055849, 0.03618, 0.029783, 0.53225]
Predicted label: 4
Correct prediction
Energy consumption = 154.383601 pJ
sum error= 144
Actual label: 2
Output voltages: [0.44582, 0.014046, 0.79878, 0.044274, 0.02826, 0.0011127, 0.046541, 0.022003, 0.37115, 0.017586]
Predicted label: 2
Correct prediction
Energy consumption = 150.214232 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 268 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 268 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 268 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.010995, 0.020922, 0.3374, 0.005704, 0.79873, 0.0010678, 0.44976, 0.06252, 0.025799, 0.094448]
Predicted label: 4
Correct prediction
Energy consumption = 153.842935 pJ
sum error= 144
Actual label: 3
Output voltages: [0.16407, 0.014738, 0.065119, 0.79873, 0.01345, 0.23392, 0.0031403, 0.0055719, 0.49869, 0.018146]
Predicted label: 3
Correct prediction
Energy consumption = 148.598008 pJ
sum error= 144
Actual label: 5
Output voltages: [0.035898, 0.0010989, 0.0010806, 0.35557, 0.3606, 0.7987, 0.33866, 0.0066975, 0.78963, 0.037865]
Predicted label: 5
Correct prediction
Energy consumption = 134.620172 pJ
sum error= 144
Actual label: 4
Output voltages: [0.010092, 0.0014613, 0.20262, 0.016974, 0.79873, 0.0010775, 0.021362, 0.18596, 0.042184, 0.052277]
Predicted label: 4
Correct prediction
Energy consumption = 153.059212 pJ
sum error= 144
Actual label: 3
Output voltages: [0.64281, 0.054399, 0.062082, 0.79877, 0.0010793, 0.0072359, 0.096057, 0.12015, 0.59876, 0.0011507]
Predicted label: 3
Correct prediction
Energy consumption = 145.967122 pJ
sum error= 144
Actual label: 9
Output voltages: [0.50628, 0.026699, 0.014333, 0.097721, 0.050844, 0.027645, 0.0025197, 0.032665, 0.30156, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 148.768280 pJ
sum error= 144
Actual label: 5
Output voltages: [0.16919, 0.0019419, 0.0012335, 0.27974, 0.13519, 0.79877, 0.040058, 0.063028, 0.77769, 0.04628]
Predicted label: 5
Correct prediction
Energy consumption = 147.198794 pJ
sum error= 144
Actual label: 0
Output voltages: [0.79878, 0.1971, 0.02576, 0.022557, 0.0074593, 0.021397, 0.45273, 0.027654, 0.063595, 0.024937]
Predicted label: 0
Correct prediction
Energy consumption = 149.810380 pJ
sum error= 144
Actual label: 1
Output voltages: [0.040119, 0.79838, 0.033805, 0.17422, 0.0049754, 0.01745, 0.72754, 0.012247, 0.15792, 0.11578]
Predicted label: 1
Correct prediction
Energy consumption = 164.317846 pJ
sum error= 144
Actual label: 5
Output voltages: [0.050496, 0.0010943, 0.002908, 0.68504, 0.012639, 0.7863, 0.077717, 0.052214, 0.46581, 0.026679]
Predicted label: 5
Correct prediction
Energy consumption = 152.722874 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 269 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 269 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 269 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.031573, 0.025569, 0.037799, 0.79876, 0.012078, 0.0027087, 0.0056151, 0.022924, 0.75829, 0.027898]
Predicted label: 3
Correct prediction
Energy consumption = 144.370456 pJ
sum error= 144
Actual label: 8
Output voltages: [0.026613, 0.045897, 0.08895, 0.053591, 0.0043676, 0.021929, 0.035969, 0.0069794, 0.79876, 0.10964]
Predicted label: 8
Correct prediction
Energy consumption = 146.383644 pJ
sum error= 144
Actual label: 9
Output voltages: [0.1961, 0.008795, 0.034705, 0.032492, 0.031234, 0.010975, 0.0059073, 0.22426, 0.56525, 0.79598]
Predicted label: 9
Correct prediction
Energy consumption = 154.278731 pJ
sum error= 144
Actual label: 1
Output voltages: [0.0025649, 0.79862, 0.045526, 0.023749, 0.020406, 0.0019268, 0.72276, 0.0031068, 0.43672, 0.012731]
Predicted label: 1
Correct prediction
Energy consumption = 163.978985 pJ
sum error= 144
Actual label: 9
Output voltages: [0.58357, 0.029971, 0.052109, 0.028533, 0.21803, 0.017735, 0.0026337, 0.0098585, 0.27851, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 157.188062 pJ
sum error= 144
Actual label: 7
Output voltages: [0.36985, 0.013855, 0.044413, 0.1675, 0.025123, 0.026008, 0.017876, 0.7984, 0.095353, 0.027584]
Predicted label: 7
Correct prediction
Energy consumption = 142.932840 pJ
sum error= 144
Actual label: 9
Output voltages: [0.1707, 0.027283, 0.20124, 0.21389, 0.15688, 0.043007, 0.053699, 0.016476, 0.15017, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 151.625934 pJ
sum error= 144
Actual label: 5
Output voltages: [0.018151, 0.0012007, 0.0016726, 0.27789, 0.027507, 0.79764, 0.093259, 0.0037878, 0.67894, 0.2689]
Predicted label: 5
Correct prediction
Energy consumption = 139.932118 pJ
sum error= 144
Actual label: 5
Output voltages: [0.0028241, 0.0017784, 0.0011767, 0.1057, 0.047644, 0.79531, 0.035972, 0.0018495, 0.72506, 0.093095]
Predicted label: 5
Correct prediction
Energy consumption = 138.480942 pJ
sum error= 144
Actual label: 2
Output voltages: [0.058795, 0.46397, 0.79839, 0.022756, 0.047462, 0.0012588, 0.07778, 0.030394, 0.25473, 0.033038]
Predicted label: 2
Correct prediction
Energy consumption = 157.920428 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 270 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 270 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 270 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.071246, 0.037859, 0.060245, 0.45102, 0.0021614, 0.0023349, 0.0012752, 0.79876, 0.017526, 0.50008]
Predicted label: 7
Correct prediction
Energy consumption = 157.464215 pJ
sum error= 144
Actual label: 4
Output voltages: [0.017858, 0.0051642, 0.032953, 0.012913, 0.79868, 0.0033469, 0.30919, 0.24016, 0.27236, 0.0046675]
Predicted label: 4
Correct prediction
Energy consumption = 157.338709 pJ
sum error= 144
Actual label: 6
Output voltages: [0.33869, 0.043301, 0.14082, 0.0028438, 0.39746, 0.072642, 0.79879, 0.0011645, 0.45699, 0.014778]
Predicted label: 6
Correct prediction
Energy consumption = 144.125357 pJ
sum error= 144
Actual label: 0
Output voltages: [0.79875, 0.11187, 0.0092719, 0.031195, 0.0090328, 0.072077, 0.56954, 0.02169, 0.2264, 0.020119]
Predicted label: 0
Correct prediction
Energy consumption = 141.218312 pJ
sum error= 144
Actual label: 1
Output voltages: [0.024822, 0.79862, 0.0051318, 0.027194, 0.020044, 0.0034221, 0.32482, 0.0025299, 0.74629, 0.020735]
Predicted label: 1
Correct prediction
Energy consumption = 160.377563 pJ
sum error= 144
Actual label: 1
Output voltages: [0.060294, 0.79861, 0.30986, 0.1267, 0.0045736, 0.002706, 0.13576, 0.0012251, 0.75457, 0.058523]
Predicted label: 1
Correct prediction
Energy consumption = 146.677282 pJ
sum error= 144
Actual label: 1
Output voltages: [0.05431, 0.7985, 0.0067106, 0.41158, 0.073044, 0.02537, 0.25904, 0.0037894, 0.35788, 0.11495]
Predicted label: 1
Correct prediction
Energy consumption = 159.949616 pJ
sum error= 144
Actual label: 0
Output voltages: [0.79875, 0.10799, 0.05753, 0.018038, 0.0093729, 0.012831, 0.40497, 0.026162, 0.045045, 0.018248]
Predicted label: 0
Correct prediction
Energy consumption = 151.638469 pJ
sum error= 144
Actual label: 4
Output voltages: [0.032646, 0.011214, 0.05628, 0.077225, 0.79865, 0.013716, 0.077198, 0.03241, 0.027442, 0.20836]
Predicted label: 4
Correct prediction
Energy consumption = 155.672981 pJ
sum error= 144
Actual label: 4
Output voltages: [0.0179, 0.0064119, 0.54431, 0.032973, 0.79872, 0.0010813, 0.043082, 0.095354, 0.023065, 0.16228]
Predicted label: 4
Correct prediction
Energy consumption = 133.081606 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 271 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 271 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 271 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.33293, 0.032589, 0.086137, 0.33138, 0.002242, 0.0010701, 0.0020175, 0.79871, 0.058579, 0.41031]
Predicted label: 7
Correct prediction
Energy consumption = 159.500433 pJ
sum error= 144
Actual label: 6
Output voltages: [0.17366, 0.029159, 0.33535, 0.0013327, 0.23221, 0.39271, 0.79873, 0.0086148, 0.47732, 0.016113]
Predicted label: 6
Correct prediction
Energy consumption = 146.933891 pJ
sum error= 144
Actual label: 3
Output voltages: [0.30732, 0.011874, 0.034583, 0.7987, 0.014247, 0.015461, 0.0087523, 0.012567, 0.50669, 0.11737]
Predicted label: 3
Correct prediction
Energy consumption = 147.362566 pJ
sum error= 144
Actual label: 0
Output voltages: [0.78949, 0.048164, 0.23689, 0.046667, 0.022089, 0.0010719, 0.55697, 0.010485, 0.73309, 0.076706]
Predicted label: 0
Correct prediction
Energy consumption = 158.698448 pJ
sum error= 144
Actual label: 0
Output voltages: [0.79879, 0.067122, 0.016394, 0.015149, 0.030278, 0.010081, 0.74292, 0.0097771, 0.070094, 0.14446]
Predicted label: 0
Correct prediction
Energy consumption = 141.147382 pJ
sum error= 144
Actual label: 4
Output voltages: [0.001083, 0.011192, 0.046349, 0.038983, 0.79879, 0.0011591, 0.0092803, 0.46766, 0.15249, 0.0029131]
Predicted label: 4
Correct prediction
Energy consumption = 150.371582 pJ
sum error= 144
Actual label: 3
Output voltages: [0.40036, 0.0088063, 0.28229, 0.79877, 0.045786, 0.0028363, 0.012276, 0.0010793, 0.67356, 0.037095]
Predicted label: 3
Correct prediction
Energy consumption = 150.475226 pJ
sum error= 144
Actual label: 0
Output voltages: [0.7986, 0.085224, 0.048629, 0.015594, 0.001842, 0.003481, 0.45201, 0.0027278, 0.061327, 0.10203]
Predicted label: 0
Correct prediction
Energy consumption = 152.957024 pJ
sum error= 144
Actual label: 6
Output voltages: [0.048637, 0.013833, 0.050569, 0.015032, 0.28878, 0.10683, 0.79871, 0.011056, 0.56978, 0.0034112]
Predicted label: 6
Correct prediction
Energy consumption = 147.389249 pJ
sum error= 144
Actual label: 1
Output voltages: [0.029086, 0.79869, 0.0011658, 0.039016, 0.46467, 0.03796, 0.72308, 0.0039036, 0.029636, 0.030666]
Predicted label: 1
Correct prediction
Energy consumption = 155.905994 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 272 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 272 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 272 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.069026, 0.0015968, 0.045342, 0.055993, 0.5362, 0.0012561, 0.0015508, 0.0086465, 0.48969, 0.7835]
Predicted label: 9
Correct prediction
Energy consumption = 160.259095 pJ
sum error= 144
Actual label: 6
Output voltages: [0.028669, 0.0081368, 0.1795, 0.022077, 0.035325, 0.72335, 0.79847, 0.0010777, 0.75737, 0.035733]
Predicted label: 6
Correct prediction
Energy consumption = 152.219539 pJ
sum error= 144
Actual label: 1
Output voltages: [0.0036028, 0.79868, 0.069095, 0.14427, 0.014592, 0.001237, 0.038325, 0.0022239, 0.57196, 0.14729]
Predicted label: 1
Correct prediction
Energy consumption = 166.510461 pJ
sum error= 144
Actual label: 3
Output voltages: [0.28553, 0.013138, 0.46372, 0.79879, 0.02627, 0.0016522, 0.0028666, 0.0022848, 0.65545, 0.021376]
Predicted label: 3
Correct prediction
Energy consumption = 145.225859 pJ
sum error= 144
Actual label: 8
Output voltages: [0.0014933, 0.008389, 0.27467, 0.01852, 0.013844, 0.22752, 0.60406, 0.0011069, 0.79531, 0.052313]
Predicted label: 8
Correct prediction
Energy consumption = 150.149789 pJ
sum error= 144
Actual label: 1
Output voltages: [0.031968, 0.7986, 0.042996, 0.0063598, 0.21569, 0.0020476, 0.54913, 0.0026622, 0.22082, 0.028798]
Predicted label: 1
Correct prediction
Energy consumption = 158.706558 pJ
sum error= 144
Actual label: 2
Output voltages: [0.50705, 0.0063642, 0.79871, 0.09374, 0.0056874, 0.0012509, 0.044517, 0.066875, 0.52966, 0.013858]
Predicted label: 2
Correct prediction
Energy consumption = 149.344922 pJ
sum error= 144
Actual label: 5
Output voltages: [0.07752, 0.0010796, 0.0030923, 0.23874, 0.028341, 0.79859, 0.072347, 0.068509, 0.79302, 0.027658]
Predicted label: 5
Correct prediction
Energy consumption = 148.784275 pJ
sum error= 144
Actual label: 6
Output voltages: [0.23493, 0.080519, 0.27211, 0.0018627, 0.11018, 0.27581, 0.79874, 0.0048483, 0.55078, 0.00697]
Predicted label: 6
Correct prediction
Energy consumption = 150.994535 pJ
sum error= 144
Actual label: 2
Output voltages: [0.40771, 0.28696, 0.79866, 0.052001, 0.022003, 0.0011923, 0.20679, 0.27006, 0.36765, 0.03059]
Predicted label: 2
Correct prediction
Energy consumption = 146.498820 pJ
sum error= 144
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 273 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 273 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 273 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.11327, 0.0010769, 0.28996, 0.7516, 0.63417, 0.0011275, 0.013585, 0.35301, 0.29789, 0.0089236]
Predicted label: 3
Wrong prediction!
Energy consumption = 150.088852 pJ
sum error= 145
Actual label: 3
Output voltages: [0.027271, 0.0092297, 0.037543, 0.79876, 0.35735, 0.36846, 0.36312, 0.010167, 0.38567, 0.12789]
Predicted label: 3
Correct prediction
Energy consumption = 139.353091 pJ
sum error= 145
Actual label: 6
Output voltages: [0.08285, 0.0051777, 0.0014781, 0.045177, 0.18005, 0.71355, 0.7977, 0.01123, 0.59797, 0.0012376]
Predicted label: 6
Correct prediction
Energy consumption = 153.385420 pJ
sum error= 145
Actual label: 0
Output voltages: [0.79868, 0.053155, 0.42881, 0.017607, 0.035052, 0.0010802, 0.13998, 0.042097, 0.27333, 0.068059]
Predicted label: 0
Correct prediction
Energy consumption = 156.406342 pJ
sum error= 145
Actual label: 1
Output voltages: [0.15335, 0.79409, 0.0035095, 0.014817, 0.74876, 0.0012221, 0.46599, 0.0010851, 0.65827, 0.043827]
Predicted label: 1
Correct prediction
Energy consumption = 150.049094 pJ
sum error= 145
Actual label: 9
Output voltages: [0.78673, 0.012109, 0.10584, 0.32252, 0.079523, 0.03205, 0.14719, 0.18342, 0.0016358, 0.77028]
Predicted label: 0
Wrong prediction!
Energy consumption = 154.619512 pJ
sum error= 146
Actual label: 7
Output voltages: [0.78228, 0.010837, 0.4263, 0.093291, 0.0049022, 0.0028443, 0.0010785, 0.79875, 0.41707, 0.19026]
Predicted label: 7
Correct prediction
Energy consumption = 146.842464 pJ
sum error= 146
Actual label: 6
Output voltages: [0.12261, 0.23873, 0.34748, 0.0046784, 0.078007, 0.074125, 0.79876, 0.0013054, 0.32652, 0.0070477]
Predicted label: 6
Correct prediction
Energy consumption = 154.256069 pJ
sum error= 146
Actual label: 6
Output voltages: [0.12597, 0.38148, 0.3251, 0.00155, 0.15702, 0.2299, 0.79869, 0.0019372, 0.26939, 0.011121]
Predicted label: 6
Correct prediction
Energy consumption = 141.355030 pJ
sum error= 146
Actual label: 8
Output voltages: [0.14658, 0.083231, 0.028416, 0.26503, 0.013228, 0.0013126, 0.030895, 0.002352, 0.79746, 0.62623]
Predicted label: 8
Correct prediction
Energy consumption = 155.442430 pJ
sum error= 146
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 274 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 274 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 274 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.55526, 0.017006, 0.018211, 0.16361, 0.4226, 0.0019536, 0.0010759, 0.022905, 0.28875, 0.79278]
Predicted label: 9
Correct prediction
Energy consumption = 154.297359 pJ
sum error= 146
Actual label: 2
Output voltages: [0.30198, 0.27372, 0.7986, 0.033759, 0.0074408, 0.0011493, 0.055529, 0.12766, 0.2721, 0.0085183]
Predicted label: 2
Correct prediction
Energy consumption = 149.575081 pJ
sum error= 146
Actual label: 9
Output voltages: [0.77003, 0.029096, 0.076116, 0.48362, 0.0046726, 0.0037526, 0.072792, 0.045172, 0.64163, 0.79776]
Predicted label: 9
Correct prediction
Energy consumption = 162.254470 pJ
sum error= 146
Actual label: 5
Output voltages: [0.010002, 0.0050028, 0.010028, 0.079012, 0.013855, 0.79843, 0.58367, 0.0017509, 0.63407, 0.023826]
Predicted label: 5
Correct prediction
Energy consumption = 156.386754 pJ
sum error= 146
Actual label: 8
Output voltages: [0.004984, 0.031804, 0.079063, 0.02705, 0.035388, 0.046762, 0.028267, 0.0094104, 0.79873, 0.26314]
Predicted label: 8
Correct prediction
Energy consumption = 142.998189 pJ
sum error= 146
Actual label: 3
Output voltages: [0.20366, 0.021462, 0.41186, 0.79877, 0.023168, 0.001094, 0.011243, 0.0030756, 0.49215, 0.013143]
Predicted label: 3
Correct prediction
Energy consumption = 138.143723 pJ
sum error= 146
Actual label: 1
Output voltages: [0.013524, 0.79876, 0.008477, 0.0068577, 0.031915, 0.0015667, 0.50564, 0.022326, 0.32284, 0.043857]
Predicted label: 1
Correct prediction
Energy consumption = 155.624838 pJ
sum error= 146
Actual label: 0
Output voltages: [0.79872, 0.073758, 0.021809, 0.0083229, 0.123, 0.0098638, 0.64702, 0.030516, 0.038173, 0.049602]
Predicted label: 0
Correct prediction
Energy consumption = 153.195116 pJ
sum error= 146
Actual label: 0
Output voltages: [0.79878, 0.017572, 0.01148, 0.0034475, 0.029587, 0.0053876, 0.32523, 0.048141, 0.22371, 0.15262]
Predicted label: 0
Correct prediction
Energy consumption = 145.477121 pJ
sum error= 146
Actual label: 7
Output voltages: [0.41677, 0.0038322, 0.0039571, 0.052399, 0.044462, 0.33941, 0.0010732, 0.79879, 0.35895, 0.71158]
Predicted label: 7
Correct prediction
Energy consumption = 153.254015 pJ
sum error= 146
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 275 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 275 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 275 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.041442, 0.15238, 0.07491, 0.058162, 0.010012, 0.1182, 0.795, 0.01132, 0.79714, 0.0057045]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.539010 pJ
sum error= 147
Actual label: 6
Output voltages: [0.64601, 0.041321, 0.010223, 0.0035254, 0.17263, 0.49366, 0.79855, 0.013549, 0.37171, 0.0010668]
Predicted label: 6
Correct prediction
Energy consumption = 138.673025 pJ
sum error= 147
Actual label: 2
Output voltages: [0.4754, 0.018412, 0.79869, 0.024751, 0.058474, 0.0010719, 0.18079, 0.041613, 0.39143, 0.028271]
Predicted label: 2
Correct prediction
Energy consumption = 143.206780 pJ
sum error= 147
Actual label: 1
Output voltages: [0.027893, 0.79878, 0.036386, 0.031733, 0.33303, 0.0053941, 0.69367, 0.0020039, 0.49014, 0.022766]
Predicted label: 1
Correct prediction
Energy consumption = 145.770486 pJ
sum error= 147
Actual label: 6
Output voltages: [0.63597, 0.032621, 0.21755, 0.0012125, 0.23298, 0.0036223, 0.7984, 0.0060209, 0.14246, 0.012437]
Predicted label: 6
Correct prediction
Energy consumption = 144.060039 pJ
sum error= 147
Actual label: 9
Output voltages: [0.40651, 0.0099607, 0.030716, 0.015004, 0.14522, 0.02608, 0.0044994, 0.023304, 0.47644, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 154.478241 pJ
sum error= 147
Actual label: 3
Output voltages: [0.70418, 0.077094, 0.10732, 0.7987, 0.0058494, 0.29127, 0.47251, 0.022533, 0.038882, 0.0010659]
Predicted label: 3
Correct prediction
Energy consumption = 152.211569 pJ
sum error= 147
Actual label: 1
Output voltages: [0.030768, 0.79852, 0.28405, 0.037575, 0.019926, 0.0016835, 0.73589, 0.0012646, 0.052564, 0.043402]
Predicted label: 1
Correct prediction
Energy consumption = 159.525125 pJ
sum error= 147
Actual label: 8
Output voltages: [0.26448, 0.0032002, 0.026929, 0.70856, 0.0091478, 0.072855, 0.054324, 0.011915, 0.79879, 0.061645]
Predicted label: 8
Correct prediction
Energy consumption = 152.377595 pJ
sum error= 147
Actual label: 6
Output voltages: [0.043769, 0.035712, 0.1327, 0.0032615, 0.26559, 0.39244, 0.7987, 0.004109, 0.5529, 0.00458]
Predicted label: 6
Correct prediction
Energy consumption = 146.974523 pJ
sum error= 147
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 276 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 276 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 276 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.29984, 0.034589, 0.14818, 0.019096, 0.79608, 0.0010899, 0.0051284, 0.0068075, 0.040645, 0.6735]
Predicted label: 4
Wrong prediction!
Energy consumption = 163.702933 pJ
sum error= 148
Actual label: 0
Output voltages: [0.79567, 0.028589, 0.016125, 0.0042056, 0.037321, 0.0099185, 0.72547, 0.014904, 0.13343, 0.0051963]
Predicted label: 0
Correct prediction
Energy consumption = 151.304350 pJ
sum error= 148
Actual label: 6
Output voltages: [0.32912, 0.051628, 0.099718, 0.0024471, 0.4695, 0.41142, 0.79875, 0.0012222, 0.4568, 0.011059]
Predicted label: 6
Correct prediction
Energy consumption = 149.187012 pJ
sum error= 148
Actual label: 0
Output voltages: [0.79871, 0.15984, 0.023782, 0.0094741, 0.0066034, 0.0027813, 0.52428, 0.021981, 0.10691, 0.041249]
Predicted label: 0
Correct prediction
Energy consumption = 152.438051 pJ
sum error= 148
Actual label: 0
Output voltages: [0.79879, 0.035726, 0.27076, 0.10292, 0.026138, 0.008286, 0.20589, 0.02052, 0.36989, 0.039]
Predicted label: 0
Correct prediction
Energy consumption = 152.880554 pJ
sum error= 148
Actual label: 0
Output voltages: [0.79869, 0.02805, 0.030187, 0.02293, 0.010382, 0.0054926, 0.6371, 0.014578, 0.14609, 0.11147]
Predicted label: 0
Correct prediction
Energy consumption = 146.523611 pJ
sum error= 148
Actual label: 6
Output voltages: [0.10412, 0.21738, 0.13978, 0.0019361, 0.15335, 0.30649, 0.79863, 0.0038347, 0.30999, 0.0087287]
Predicted label: 6
Correct prediction
Energy consumption = 142.266747 pJ
sum error= 148
Actual label: 3
Output voltages: [0.063757, 0.024379, 0.22606, 0.79872, 0.01135, 0.0011136, 0.0056945, 0.001091, 0.5337, 0.12585]
Predicted label: 3
Correct prediction
Energy consumption = 149.183742 pJ
sum error= 148
Actual label: 5
Output voltages: [0.17104, 0.0016061, 0.011655, 0.35699, 0.018121, 0.79629, 0.014726, 0.020601, 0.76766, 0.27263]
Predicted label: 5
Correct prediction
Energy consumption = 139.944357 pJ
sum error= 148
Actual label: 9
Output voltages: [0.055549, 0.027938, 0.015449, 0.031198, 0.039163, 0.0014249, 0.0012112, 0.0022868, 0.68401, 0.79781]
Predicted label: 9
Correct prediction
Energy consumption = 150.505385 pJ
sum error= 148
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 277 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 277 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 277 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.025782, 0.0011002, 0.26456, 0.67428, 0.0010677, 0.40259, 0.0064356, 0.060336, 0.79607, 0.015773]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.064629 pJ
sum error= 149
Actual label: 4
Output voltages: [0.015132, 0.038534, 0.026951, 0.027319, 0.78615, 0.016596, 0.023556, 0.03023, 0.24813, 0.78532]
Predicted label: 4
Correct prediction
Energy consumption = 159.885952 pJ
sum error= 149
Actual label: 5
Output voltages: [0.0095678, 0.0070363, 0.0011224, 0.15724, 0.047539, 0.79869, 0.45611, 0.021799, 0.75913, 0.032523]
Predicted label: 5
Correct prediction
Energy consumption = 142.368903 pJ
sum error= 149
Actual label: 5
Output voltages: [0.042345, 0.0010913, 0.017242, 0.088885, 0.024497, 0.78125, 0.20904, 0.011078, 0.79646, 0.18169]
Predicted label: 8
Wrong prediction!
Energy consumption = 138.548620 pJ
sum error= 150
Actual label: 8
Output voltages: [0.093035, 0.031109, 0.10448, 0.035971, 0.02098, 0.11945, 0.026972, 0.0097978, 0.79878, 0.27792]
Predicted label: 8
Correct prediction
Energy consumption = 137.225522 pJ
sum error= 150
Actual label: 5
Output voltages: [0.0083064, 0.0010748, 0.0033994, 0.13712, 0.084613, 0.79865, 0.28389, 0.028082, 0.78415, 0.046287]
Predicted label: 5
Correct prediction
Energy consumption = 136.174557 pJ
sum error= 150
Actual label: 3
Output voltages: [0.19958, 0.051426, 0.031479, 0.7987, 0.0086977, 0.0051812, 0.003247, 0.0036775, 0.63203, 0.033495]
Predicted label: 3
Correct prediction
Energy consumption = 140.779452 pJ
sum error= 150
Actual label: 0
Output voltages: [0.79855, 0.055557, 0.0095216, 0.0092846, 0.070233, 0.03665, 0.77383, 0.13666, 0.065252, 0.028485]
Predicted label: 0
Correct prediction
Energy consumption = 154.664241 pJ
sum error= 150
Actual label: 4
Output voltages: [0.23478, 0.19799, 0.14626, 0.014576, 0.79677, 0.0011353, 0.39461, 0.14134, 0.0076631, 0.65127]
Predicted label: 4
Correct prediction
Energy consumption = 151.195073 pJ
sum error= 150
Actual label: 0
Output voltages: [0.79877, 0.047997, 0.013451, 0.0099109, 0.016758, 0.040037, 0.3525, 0.037046, 0.27632, 0.037597]
Predicted label: 0
Correct prediction
Energy consumption = 155.574730 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 278 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 278 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 278 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.6689, 0.0011033, 0.79362, 0.75049, 0.028297, 0.0025439, 0.013311, 0.010088, 0.78456, 0.16293]
Predicted label: 2
Correct prediction
Energy consumption = 151.902799 pJ
sum error= 150
Actual label: 9
Output voltages: [0.50117, 0.0030606, 0.017664, 0.040747, 0.31214, 0.045614, 0.021962, 0.036021, 0.30585, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 153.083570 pJ
sum error= 150
Actual label: 6
Output voltages: [0.046159, 0.0078361, 0.42552, 0.0043716, 0.039395, 0.37075, 0.79847, 0.0011298, 0.55389, 0.041841]
Predicted label: 6
Correct prediction
Energy consumption = 146.456174 pJ
sum error= 150
Actual label: 8
Output voltages: [0.027355, 0.01642, 0.056827, 0.51123, 0.0054484, 0.0091417, 0.01878, 0.0081361, 0.79879, 0.14032]
Predicted label: 8
Correct prediction
Energy consumption = 143.500310 pJ
sum error= 150
Actual label: 2
Output voltages: [0.32085, 0.4737, 0.79879, 0.012565, 0.053513, 0.001217, 0.02573, 0.50783, 0.46271, 0.0099665]
Predicted label: 2
Correct prediction
Energy consumption = 146.382262 pJ
sum error= 150
Actual label: 3
Output voltages: [0.31375, 0.015343, 0.038816, 0.79868, 0.016074, 0.019005, 0.0092346, 0.016386, 0.53696, 0.12712]
Predicted label: 3
Correct prediction
Energy consumption = 142.471483 pJ
sum error= 150
Actual label: 1
Output voltages: [0.23011, 0.79835, 0.031331, 0.079978, 0.0052852, 0.0032069, 0.7592, 0.018181, 0.028763, 0.16464]
Predicted label: 1
Correct prediction
Energy consumption = 160.266157 pJ
sum error= 150
Actual label: 2
Output voltages: [0.75355, 0.0054701, 0.79876, 0.55734, 0.011423, 0.0025771, 0.052418, 0.088964, 0.62997, 0.011606]
Predicted label: 2
Correct prediction
Energy consumption = 154.671815 pJ
sum error= 150
Actual label: 1
Output voltages: [0.019457, 0.79842, 0.0096503, 0.041002, 0.01339, 0.016657, 0.67012, 0.0023841, 0.3831, 0.036563]
Predicted label: 1
Correct prediction
Energy consumption = 162.462029 pJ
sum error= 150
Actual label: 1
Output voltages: [0.02339, 0.79723, 0.27332, 0.030624, 0.4661, 0.0011843, 0.088901, 0.0041321, 0.027888, 0.24162]
Predicted label: 1
Correct prediction
Energy consumption = 145.941671 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 279 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 279 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 279 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25439, 0.0018025, 0.0047983, 0.47111, 0.0042212, 0.79877, 0.2747, 0.032716, 0.76267, 0.0054565]
Predicted label: 5
Correct prediction
Energy consumption = 148.704435 pJ
sum error= 150
Actual label: 6
Output voltages: [0.28099, 0.1617, 0.23671, 0.0096416, 0.22013, 0.04455, 0.79878, 0.0012829, 0.44981, 0.017542]
Predicted label: 6
Correct prediction
Energy consumption = 150.345652 pJ
sum error= 150
Actual label: 9
Output voltages: [0.25508, 0.031071, 0.037287, 0.048329, 0.054498, 0.039234, 0.0098955, 0.039049, 0.39144, 0.7978]
Predicted label: 9
Correct prediction
Energy consumption = 150.168734 pJ
sum error= 150
Actual label: 8
Output voltages: [0.045556, 0.030166, 0.49556, 0.0066831, 0.095192, 0.0013643, 0.052592, 0.0014959, 0.79878, 0.55354]
Predicted label: 8
Correct prediction
Energy consumption = 140.151284 pJ
sum error= 150
Actual label: 0
Output voltages: [0.79878, 0.050628, 0.026187, 0.040154, 0.011661, 0.011092, 0.52663, 0.012201, 0.33932, 0.62963]
Predicted label: 0
Correct prediction
Energy consumption = 158.404782 pJ
sum error= 150
Actual label: 6
Output voltages: [0.032937, 0.13682, 0.25059, 0.0028071, 0.31238, 0.10026, 0.79864, 0.0015572, 0.60757, 0.018521]
Predicted label: 6
Correct prediction
Energy consumption = 147.117385 pJ
sum error= 150
Actual label: 6
Output voltages: [0.03261, 0.29423, 0.19839, 0.022346, 0.05385, 0.34302, 0.7987, 0.0067755, 0.73422, 0.0061119]
Predicted label: 6
Correct prediction
Energy consumption = 141.882745 pJ
sum error= 150
Actual label: 5
Output voltages: [0.067077, 0.0056056, 0.0015351, 0.56921, 0.15857, 0.79876, 0.04277, 0.030254, 0.45074, 0.32592]
Predicted label: 5
Correct prediction
Energy consumption = 148.147508 pJ
sum error= 150
Actual label: 5
Output voltages: [0.04091, 0.0010659, 0.0050957, 0.045826, 0.025811, 0.79879, 0.37324, 0.022004, 0.77993, 0.022319]
Predicted label: 5
Correct prediction
Energy consumption = 135.701951 pJ
sum error= 150
Actual label: 3
Output voltages: [0.50448, 0.0086485, 0.20608, 0.79872, 0.030001, 0.013793, 0.015599, 0.024162, 0.46, 0.011002]
Predicted label: 3
Correct prediction
Energy consumption = 137.609991 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 280 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 280 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 280 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.066377, 0.0057488, 0.24549, 0.38908, 0.0082997, 0.020814, 0.0037027, 0.013503, 0.79874, 0.11255]
Predicted label: 8
Correct prediction
Energy consumption = 157.236811 pJ
sum error= 150
Actual label: 6
Output voltages: [0.17984, 0.028951, 0.064188, 0.002913, 0.34486, 0.0729, 0.79879, 0.0014705, 0.43606, 0.014866]
Predicted label: 6
Correct prediction
Energy consumption = 143.660663 pJ
sum error= 150
Actual label: 2
Output voltages: [0.78838, 0.079956, 0.79878, 0.15382, 0.0033714, 0.0011306, 0.11088, 0.026489, 0.26195, 0.072088]
Predicted label: 2
Correct prediction
Energy consumption = 145.039073 pJ
sum error= 150
Actual label: 1
Output voltages: [0.011021, 0.79869, 0.0012668, 0.061438, 0.29953, 0.0045173, 0.013949, 0.0026836, 0.34752, 0.32479]
Predicted label: 1
Correct prediction
Energy consumption = 164.632944 pJ
sum error= 150
Actual label: 4
Output voltages: [0.0054455, 0.0038396, 0.034163, 0.010453, 0.79864, 0.0029387, 0.20982, 0.11325, 0.33382, 0.0045892]
Predicted label: 4
Correct prediction
Energy consumption = 150.845957 pJ
sum error= 150
Actual label: 5
Output voltages: [0.017597, 0.0042777, 0.0013347, 0.27749, 0.3054, 0.79865, 0.23131, 0.0016309, 0.49489, 0.2769]
Predicted label: 5
Correct prediction
Energy consumption = 144.469071 pJ
sum error= 150
Actual label: 4
Output voltages: [0.004814, 0.012849, 0.20084, 0.026861, 0.7986, 0.003767, 0.087592, 0.022913, 0.029251, 0.046804]
Predicted label: 4
Correct prediction
Energy consumption = 152.504135 pJ
sum error= 150
Actual label: 3
Output voltages: [0.65505, 0.018597, 0.040828, 0.79858, 0.046306, 0.012384, 0.01483, 0.0058505, 0.55581, 0.05581]
Predicted label: 3
Correct prediction
Energy consumption = 153.519424 pJ
sum error= 150
Actual label: 7
Output voltages: [0.30851, 0.042289, 0.0055636, 0.054179, 0.011891, 0.017164, 0.0010744, 0.79875, 0.35864, 0.51776]
Predicted label: 7
Correct prediction
Energy consumption = 159.105776 pJ
sum error= 150
Actual label: 8
Output voltages: [0.035602, 0.0058745, 0.016612, 0.096727, 0.085503, 0.057417, 0.22517, 0.010287, 0.79872, 0.038965]
Predicted label: 8
Correct prediction
Energy consumption = 149.763924 pJ
sum error= 150
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 281 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 281 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 281 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.41398, 0.0010829, 0.024939, 0.76134, 0.066608, 0.52863, 0.017139, 0.0089371, 0.66478, 0.14431]
Predicted label: 3
Wrong prediction!
Energy consumption = 155.073105 pJ
sum error= 151
Actual label: 0
Output voltages: [0.79877, 0.018644, 0.054236, 0.01975, 0.010938, 0.0064192, 0.70726, 0.023406, 0.12054, 0.14614]
Predicted label: 0
Correct prediction
Energy consumption = 138.737733 pJ
sum error= 151
Actual label: 9
Output voltages: [0.56697, 0.013121, 0.025218, 0.0016548, 0.71623, 0.0010748, 0.02193, 0.0085048, 0.053076, 0.78908]
Predicted label: 9
Correct prediction
Energy consumption = 158.762159 pJ
sum error= 151
Actual label: 3
Output voltages: [0.55663, 0.041267, 0.037129, 0.79877, 0.0019827, 0.012097, 0.066781, 0.026435, 0.32464, 0.0062569]
Predicted label: 3
Correct prediction
Energy consumption = 146.631772 pJ
sum error= 151
Actual label: 5
Output voltages: [0.19533, 0.0011508, 0.024427, 0.38048, 0.0029523, 0.79805, 0.038138, 0.010466, 0.7918, 0.063151]
Predicted label: 5
Correct prediction
Energy consumption = 144.936262 pJ
sum error= 151
Actual label: 1
Output voltages: [0.021204, 0.79876, 0.11046, 0.56352, 0.058736, 0.0349, 0.015975, 0.01181, 0.0050975, 0.28713]
Predicted label: 1
Correct prediction
Energy consumption = 163.087916 pJ
sum error= 151
Actual label: 1
Output voltages: [0.019218, 0.7987, 0.010185, 0.038024, 0.19107, 0.0064336, 0.59275, 0.0031716, 0.048754, 0.0092086]
Predicted label: 1
Correct prediction
Energy consumption = 154.056359 pJ
sum error= 151
Actual label: 0
Output voltages: [0.79871, 0.061482, 0.030879, 0.013178, 0.013509, 0.0031132, 0.70057, 0.025877, 0.11392, 0.046935]
Predicted label: 0
Correct prediction
Energy consumption = 150.849826 pJ
sum error= 151
Actual label: 4
Output voltages: [0.011202, 0.0069792, 0.10693, 0.020433, 0.79868, 0.034163, 0.018626, 0.0097484, 0.061746, 0.038549]
Predicted label: 4
Correct prediction
Energy consumption = 151.185242 pJ
sum error= 151
Actual label: 4
Output voltages: [0.0084682, 0.032782, 0.052266, 0.047017, 0.79863, 0.0079915, 0.18039, 0.19971, 0.028968, 0.010011]
Predicted label: 4
Correct prediction
Energy consumption = 142.736854 pJ
sum error= 151
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 282 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 282 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 282 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.019405, 0.022791, 0.23678, 0.043298, 0.021964, 0.0012344, 0.0014724, 0.79879, 0.28666, 0.03614]
Predicted label: 7
Correct prediction
Energy consumption = 147.271456 pJ
sum error= 151
Actual label: 0
Output voltages: [0.79824, 0.28449, 0.010478, 0.0091633, 0.03909, 0.023919, 0.76661, 0.012864, 0.036821, 0.025928]
Predicted label: 0
Correct prediction
Energy consumption = 154.081157 pJ
sum error= 151
Actual label: 1
Output voltages: [0.039631, 0.79847, 0.32259, 0.18692, 0.044691, 0.0042212, 0.1536, 0.13365, 0.0073876, 0.24293]
Predicted label: 1
Correct prediction
Energy consumption = 161.745122 pJ
sum error= 151
Actual label: 7
Output voltages: [0.0014318, 0.012729, 0.039495, 0.3977, 0.019844, 0.3888, 0.0012238, 0.64962, 0.51506, 0.16811]
Predicted label: 7
Correct prediction
Energy consumption = 146.051691 pJ
sum error= 151
Actual label: 0
Output voltages: [0.79879, 0.22483, 0.040177, 0.021354, 0.023122, 0.0059313, 0.61525, 0.018092, 0.20055, 0.38647]
Predicted label: 0
Correct prediction
Energy consumption = 163.612583 pJ
sum error= 151
Actual label: 1
Output voltages: [0.091795, 0.79866, 0.035466, 0.21152, 0.0013469, 0.0043225, 0.51934, 0.0022564, 0.19124, 0.049582]
Predicted label: 1
Correct prediction
Energy consumption = 157.786332 pJ
sum error= 151
Actual label: 6
Output voltages: [0.021678, 0.044926, 0.6656, 0.0030693, 0.045004, 0.049587, 0.79879, 0.0029116, 0.56212, 0.017069]
Predicted label: 6
Correct prediction
Energy consumption = 140.206654 pJ
sum error= 151
Actual label: 1
Output voltages: [0.17987, 0.79878, 0.011145, 0.010808, 0.27999, 0.0077651, 0.22912, 0.0012444, 0.37043, 0.72311]
Predicted label: 1
Correct prediction
Energy consumption = 164.627637 pJ
sum error= 151
Actual label: 4
Output voltages: [0.0027843, 0.0046995, 0.05981, 0.0065521, 0.79861, 0.018311, 0.059247, 0.21835, 0.29812, 0.0028444]
Predicted label: 4
Correct prediction
Energy consumption = 143.312298 pJ
sum error= 151
Actual label: 5
Output voltages: [0.010558, 0.0014837, 0.011891, 0.54088, 0.042341, 0.78605, 0.037836, 0.10929, 0.75321, 0.36796]
Predicted label: 5
Correct prediction
Energy consumption = 152.087439 pJ
sum error= 151
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 283 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 283 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 283 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.47853, 0.0023447, 0.00702, 0.0015448, 0.54915, 0.76926, 0.79864, 0.0020962, 0.34455, 0.063763]
Predicted label: 6
Correct prediction
Energy consumption = 142.545786 pJ
sum error= 151
Actual label: 6
Output voltages: [0.17611, 0.036125, 0.33627, 0.0083938, 0.077168, 0.27009, 0.79878, 0.001078, 0.63181, 0.063226]
Predicted label: 6
Correct prediction
Energy consumption = 142.499082 pJ
sum error= 151
Actual label: 5
Output voltages: [0.02242, 0.0011967, 0.0016689, 0.77839, 0.047976, 0.79879, 0.20091, 0.034438, 0.41821, 0.068352]
Predicted label: 5
Correct prediction
Energy consumption = 146.331729 pJ
sum error= 151
Actual label: 7
Output voltages: [0.45646, 0.1732, 0.0022852, 0.038968, 0.012031, 0.044448, 0.0010913, 0.79869, 0.4615, 0.13522]
Predicted label: 7
Correct prediction
Energy consumption = 153.979104 pJ
sum error= 151
Actual label: 8
Output voltages: [0.45041, 0.0040979, 0.21494, 0.57692, 0.017942, 0.0014709, 0.049032, 0.013678, 0.79024, 0.0052956]
Predicted label: 8
Correct prediction
Energy consumption = 156.668143 pJ
sum error= 151
Actual label: 4
Output voltages: [0.020108, 0.0034824, 0.057178, 0.045437, 0.7987, 0.0011608, 0.062867, 0.02817, 0.010264, 0.12008]
Predicted label: 4
Correct prediction
Energy consumption = 150.853815 pJ
sum error= 151
Actual label: 4
Output voltages: [0.015831, 0.0065382, 0.76886, 0.37954, 0.79523, 0.0011039, 0.004428, 0.0027806, 0.017836, 0.6232]
Predicted label: 4
Correct prediction
Energy consumption = 140.740588 pJ
sum error= 151
Actual label: 7
Output voltages: [0.07851, 0.18168, 0.64296, 0.058956, 0.0014398, 0.0011075, 0.001285, 0.79879, 0.67127, 0.070297]
Predicted label: 7
Correct prediction
Energy consumption = 150.002391 pJ
sum error= 151
Actual label: 2
Output voltages: [0.047837, 0.1982, 0.79878, 0.14153, 0.0026449, 0.00129, 0.37526, 0.025038, 0.44458, 0.0396]
Predicted label: 2
Correct prediction
Energy consumption = 145.729419 pJ
sum error= 151
Actual label: 5
Output voltages: [0.17256, 0.003959, 0.030836, 0.050113, 0.0040226, 0.79545, 0.087474, 0.0010945, 0.79483, 0.072329]
Predicted label: 5
Correct prediction
Energy consumption = 143.685103 pJ
sum error= 151
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 284 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 284 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 284 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.52926, 0.0172, 0.05386, 0.79863, 0.089333, 0.0057184, 0.0059376, 0.015459, 0.62424, 0.055479]
Predicted label: 3
Correct prediction
Energy consumption = 147.132531 pJ
sum error= 151
Actual label: 7
Output voltages: [0.01633, 0.13674, 0.49913, 0.030739, 0.017974, 0.0012429, 0.006061, 0.79876, 0.024066, 0.23022]
Predicted label: 7
Correct prediction
Energy consumption = 145.318510 pJ
sum error= 151
Actual label: 0
Output voltages: [0.79876, 0.048742, 0.006466, 0.040115, 0.0010663, 0.4152, 0.17223, 0.011639, 0.39962, 0.01374]
Predicted label: 0
Correct prediction
Energy consumption = 151.990395 pJ
sum error= 151
Actual label: 7
Output voltages: [0.2667, 0.016172, 0.77279, 0.028695, 0.0011792, 0.0011224, 0.0010685, 0.79816, 0.51614, 0.27065]
Predicted label: 7
Correct prediction
Energy consumption = 139.692933 pJ
sum error= 151
Actual label: 7
Output voltages: [0.18137, 0.087051, 0.24843, 0.048834, 0.001244, 0.0010705, 0.0011153, 0.79872, 0.55915, 0.11721]
Predicted label: 7
Correct prediction
Energy consumption = 145.210116 pJ
sum error= 151
Actual label: 9
Output voltages: [0.10829, 0.014489, 0.12094, 0.16862, 0.062385, 0.004348, 0.011967, 0.045946, 0.3382, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 142.134961 pJ
sum error= 151
Actual label: 6
Output voltages: [0.1723, 0.032844, 0.09332, 0.0022205, 0.17919, 0.32269, 0.79879, 0.0034381, 0.48073, 0.0012181]
Predicted label: 6
Correct prediction
Energy consumption = 151.128808 pJ
sum error= 151
Actual label: 4
Output voltages: [0.042765, 0.0077291, 0.0038814, 0.027926, 0.79879, 0.0013546, 0.0059827, 0.45565, 0.038231, 0.44566]
Predicted label: 4
Correct prediction
Energy consumption = 153.628792 pJ
sum error= 151
Actual label: 2
Output voltages: [0.01252, 0.25285, 0.7985, 0.21293, 0.001511, 0.0010994, 0.24456, 0.043289, 0.69391, 0.029285]
Predicted label: 2
Correct prediction
Energy consumption = 153.924909 pJ
sum error= 151
Actual label: 8
Output voltages: [0.041064, 0.018549, 0.026251, 0.037963, 0.042242, 0.20194, 0.016993, 0.012303, 0.7987, 0.01646]
Predicted label: 8
Correct prediction
Energy consumption = 146.173148 pJ
sum error= 151
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 285 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 285 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 285 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.3383, 0.0086729, 0.069016, 0.40605, 0.0010759, 0.78289, 0.66428, 0.0013557, 0.074972, 0.0017521]
Predicted label: 5
Correct prediction
Energy consumption = 148.728377 pJ
sum error= 151
Actual label: 7
Output voltages: [0.46209, 0.013639, 0.0086623, 0.068903, 0.23486, 0.017574, 0.0010951, 0.79872, 0.15494, 0.63497]
Predicted label: 7
Correct prediction
Energy consumption = 158.666316 pJ
sum error= 151
Actual label: 8
Output voltages: [0.035559, 0.13477, 0.04974, 0.20182, 0.0099468, 0.0085087, 0.026216, 0.032206, 0.79874, 0.12775]
Predicted label: 8
Correct prediction
Energy consumption = 155.822405 pJ
sum error= 151
Actual label: 3
Output voltages: [0.47911, 0.0048572, 0.33053, 0.79878, 0.003661, 0.0089297, 0.011054, 0.039428, 0.75174, 0.032441]
Predicted label: 3
Correct prediction
Energy consumption = 144.186135 pJ
sum error= 151
Actual label: 9
Output voltages: [0.039572, 0.0089012, 0.0057925, 0.015607, 0.035827, 0.0069223, 0.0011103, 0.026684, 0.75433, 0.7947]
Predicted label: 9
Correct prediction
Energy consumption = 145.600204 pJ
sum error= 151
Actual label: 5
Output voltages: [0.14644, 0.039065, 0.0011155, 0.62548, 0.037651, 0.79863, 0.33024, 0.035863, 0.35867, 0.0028498]
Predicted label: 5
Correct prediction
Energy consumption = 148.921838 pJ
sum error= 151
Actual label: 8
Output voltages: [0.031414, 0.019083, 0.017319, 0.28949, 0.0072206, 0.008664, 0.06139, 0.0044099, 0.79879, 0.090166]
Predicted label: 8
Correct prediction
Energy consumption = 151.877556 pJ
sum error= 151
Actual label: 9
Output voltages: [0.073162, 0.02807, 0.045128, 0.055102, 0.076665, 0.067063, 0.14448, 0.028422, 0.12203, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 155.509549 pJ
sum error= 151
Actual label: 9
Output voltages: [0.042175, 0.011609, 0.024753, 0.30586, 0.67272, 0.0047764, 0.0016244, 0.014743, 0.11281, 0.79645]
Predicted label: 9
Correct prediction
Energy consumption = 150.604490 pJ
sum error= 151
Actual label: 8
Output voltages: [0.018773, 0.022527, 0.16739, 0.16048, 0.0072266, 0.019548, 0.095591, 0.034159, 0.79878, 0.058004]
Predicted label: 8
Correct prediction
Energy consumption = 149.960380 pJ
sum error= 151
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 286 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 286 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 286 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.038142, 0.019742, 0.27525, 0.0010718, 0.042871, 0.2985, 0.79876, 0.0034056, 0.59663, 0.0018142]
Predicted label: 6
Correct prediction
Energy consumption = 152.144807 pJ
sum error= 151
Actual label: 2
Output voltages: [0.06725, 0.19461, 0.79877, 0.21309, 0.0054226, 0.0013338, 0.1465, 0.27493, 0.34359, 0.031675]
Predicted label: 2
Correct prediction
Energy consumption = 149.359881 pJ
sum error= 151
Actual label: 8
Output voltages: [0.11907, 0.19558, 0.0146, 0.28455, 0.0024967, 0.01546, 0.023063, 0.0020414, 0.79879, 0.43559]
Predicted label: 8
Correct prediction
Energy consumption = 152.330522 pJ
sum error= 151
Actual label: 9
Output voltages: [0.0031215, 0.020048, 0.057145, 0.037187, 0.79791, 0.012532, 0.035962, 0.0081661, 0.14215, 0.40756]
Predicted label: 4
Wrong prediction!
Energy consumption = 156.194205 pJ
sum error= 152
Actual label: 2
Output voltages: [0.39419, 0.023623, 0.79879, 0.12817, 0.0066065, 0.0011894, 0.22299, 0.16149, 0.5647, 0.043782]
Predicted label: 2
Correct prediction
Energy consumption = 145.762938 pJ
sum error= 152
Actual label: 3
Output voltages: [0.20944, 0.01935, 0.041357, 0.79862, 0.024929, 0.0034809, 0.025492, 0.042164, 0.59691, 0.050153]
Predicted label: 3
Correct prediction
Energy consumption = 139.975110 pJ
sum error= 152
Actual label: 6
Output voltages: [0.032405, 0.0069059, 0.033484, 0.006006, 0.25155, 0.7416, 0.79835, 0.0049957, 0.60081, 0.0010848]
Predicted label: 6
Correct prediction
Energy consumption = 151.086411 pJ
sum error= 152
Actual label: 1
Output voltages: [0.0022615, 0.79844, 0.055463, 0.029703, 0.023038, 0.018846, 0.6703, 0.0079781, 0.4267, 0.17191]
Predicted label: 1
Correct prediction
Energy consumption = 163.273331 pJ
sum error= 152
Actual label: 1
Output voltages: [0.032475, 0.79841, 0.017007, 0.086566, 0.017877, 0.004041, 0.6803, 0.0066868, 0.20339, 0.084504]
Predicted label: 1
Correct prediction
Energy consumption = 152.700495 pJ
sum error= 152
Actual label: 8
Output voltages: [0.023732, 0.020774, 0.22833, 0.035349, 0.022608, 0.021562, 0.031551, 0.010962, 0.79874, 0.096478]
Predicted label: 8
Correct prediction
Energy consumption = 145.226702 pJ
sum error= 152
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 287 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 287 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 287 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.28695, 0.015828, 0.27952, 0.27129, 0.037193, 0.051974, 0.020633, 0.044806, 0.14963, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 159.003591 pJ
sum error= 152
Actual label: 3
Output voltages: [0.14612, 0.014436, 0.044148, 0.79872, 0.024688, 0.019665, 0.013257, 0.0041155, 0.49385, 0.057967]
Predicted label: 3
Correct prediction
Energy consumption = 146.937987 pJ
sum error= 152
Actual label: 4
Output voltages: [0.01469, 0.0037657, 0.29134, 0.01158, 0.79874, 0.0041297, 0.012645, 0.014466, 0.07949, 0.29393]
Predicted label: 4
Correct prediction
Energy consumption = 155.559872 pJ
sum error= 152
Actual label: 0
Output voltages: [0.79878, 0.095396, 0.013014, 0.017426, 0.037073, 0.024936, 0.70998, 0.0052175, 0.050321, 0.029046]
Predicted label: 0
Correct prediction
Energy consumption = 158.829979 pJ
sum error= 152
Actual label: 7
Output voltages: [0.55229, 0.0037087, 0.26035, 0.29949, 0.0068824, 0.001066, 0.0011724, 0.79878, 0.36387, 0.026995]
Predicted label: 7
Correct prediction
Energy consumption = 156.583641 pJ
sum error= 152
Actual label: 9
Output voltages: [0.16928, 0.023622, 0.011059, 0.15643, 0.79843, 0.0012795, 0.0084865, 0.016652, 0.016779, 0.77218]
Predicted label: 4
Wrong prediction!
Energy consumption = 149.976425 pJ
sum error= 153
Actual label: 6
Output voltages: [0.17524, 0.0050845, 0.040674, 0.014964, 0.22512, 0.71176, 0.79768, 0.0010685, 0.51633, 0.11407]
Predicted label: 6
Correct prediction
Energy consumption = 150.476381 pJ
sum error= 153
Actual label: 4
Output voltages: [0.051328, 0.0010668, 0.043617, 0.04466, 0.77274, 0.0020449, 0.019518, 0.032346, 0.044939, 0.75693]
Predicted label: 4
Correct prediction
Energy consumption = 148.893262 pJ
sum error= 153
Actual label: 1
Output voltages: [0.027306, 0.79842, 0.037204, 0.1578, 0.0023183, 0.0058965, 0.60679, 0.0014023, 0.048502, 0.020474]
Predicted label: 1
Correct prediction
Energy consumption = 166.011243 pJ
sum error= 153
Actual label: 4
Output voltages: [0.10869, 0.0070433, 0.19271, 0.0047727, 0.79872, 0.0010856, 0.3189, 0.01076, 0.054484, 0.049232]
Predicted label: 4
Correct prediction
Energy consumption = 155.731373 pJ
sum error= 153
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 288 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 288 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 288 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0025743, 0.79858, 0.013193, 0.17348, 0.12491, 0.0012337, 0.65292, 0.022916, 0.30087, 0.065497]
Predicted label: 1
Correct prediction
Energy consumption = 165.653052 pJ
sum error= 153
Actual label: 3
Output voltages: [0.011708, 0.0011622, 0.041114, 0.79879, 0.039656, 0.047037, 0.055689, 0.0074852, 0.64273, 0.0067496]
Predicted label: 3
Correct prediction
Energy consumption = 142.766475 pJ
sum error= 153
Actual label: 4
Output voltages: [0.024336, 0.0010872, 0.62992, 0.10745, 0.79476, 0.01524, 0.0019442, 0.033832, 0.029683, 0.67665]
Predicted label: 4
Correct prediction
Energy consumption = 150.445518 pJ
sum error= 153
Actual label: 9
Output voltages: [0.26623, 0.0089038, 0.051224, 0.0088126, 0.025166, 0.017847, 0.0038211, 0.011293, 0.78663, 0.79246]
Predicted label: 9
Correct prediction
Energy consumption = 135.236316 pJ
sum error= 153
Actual label: 3
Output voltages: [0.15227, 0.0045423, 0.049059, 0.79877, 0.023274, 0.015131, 0.0077409, 0.0065155, 0.51564, 0.037518]
Predicted label: 3
Correct prediction
Energy consumption = 138.518748 pJ
sum error= 153
Actual label: 1
Output voltages: [0.001382, 0.79866, 0.10399, 0.011323, 0.0124, 0.027805, 0.32134, 0.004333, 0.57561, 0.026769]
Predicted label: 1
Correct prediction
Energy consumption = 154.110466 pJ
sum error= 153
Actual label: 4
Output voltages: [0.02038, 0.0049249, 0.024519, 0.0043753, 0.79871, 0.0013449, 0.037046, 0.021133, 0.46574, 0.026814]
Predicted label: 4
Correct prediction
Energy consumption = 158.940153 pJ
sum error= 153
Actual label: 7
Output voltages: [0.055449, 0.22776, 0.048338, 0.066875, 0.0010731, 0.0038659, 0.001192, 0.79879, 0.69143, 0.52431]
Predicted label: 7
Correct prediction
Energy consumption = 154.529016 pJ
sum error= 153
Actual label: 7
Output voltages: [0.37862, 0.1453, 0.74544, 0.021277, 0.0040153, 0.0013058, 0.0042176, 0.79879, 0.2473, 0.035832]
Predicted label: 7
Correct prediction
Energy consumption = 146.635852 pJ
sum error= 153
Actual label: 4
Output voltages: [0.0037825, 0.0086349, 0.26941, 0.026998, 0.79857, 0.011751, 0.063488, 0.031163, 0.033441, 0.052505]
Predicted label: 4
Correct prediction
Energy consumption = 156.600757 pJ
sum error= 153
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 289 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 289 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 289 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.19133, 0.031776, 0.61148, 0.28559, 0.0020996, 0.0012424, 0.0011435, 0.79833, 0.047189, 0.36578]
Predicted label: 7
Correct prediction
Energy consumption = 158.752347 pJ
sum error= 153
Actual label: 2
Output voltages: [0.1508, 0.19672, 0.78966, 0.45682, 0.012287, 0.0011255, 0.32976, 0.0010686, 0.79295, 0.42823]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.919833 pJ
sum error= 154
Actual label: 9
Output voltages: [0.19144, 0.0045593, 0.011478, 0.12878, 0.19248, 0.17529, 0.046391, 0.29684, 0.25632, 0.79103]
Predicted label: 9
Correct prediction
Energy consumption = 148.723441 pJ
sum error= 154
Actual label: 3
Output voltages: [0.44937, 0.046369, 0.025937, 0.79869, 0.0037311, 0.05932, 0.01906, 0.016771, 0.45591, 0.018217]
Predicted label: 3
Correct prediction
Energy consumption = 151.964982 pJ
sum error= 154
Actual label: 0
Output voltages: [0.77364, 0.031381, 0.086593, 0.0021873, 0.17484, 0.18833, 0.78633, 0.0028199, 0.28394, 0.0014081]
Predicted label: 6
Wrong prediction!
Energy consumption = 154.175682 pJ
sum error= 155
Actual label: 8
Output voltages: [0.013776, 0.021974, 0.066237, 0.082485, 0.0025785, 0.18359, 0.038354, 0.0057451, 0.79875, 0.080305]
Predicted label: 8
Correct prediction
Energy consumption = 151.622038 pJ
sum error= 155
Actual label: 8
Output voltages: [0.79593, 0.0035579, 0.011745, 0.0094405, 0.0020918, 0.26828, 0.52222, 0.0082071, 0.61421, 0.024485]
Predicted label: 0
Wrong prediction!
Energy consumption = 155.415759 pJ
sum error= 156
Actual label: 8
Output voltages: [0.041459, 0.02917, 0.47998, 0.020373, 0.017272, 0.0074013, 0.041771, 0.011871, 0.79875, 0.040248]
Predicted label: 8
Correct prediction
Energy consumption = 147.434585 pJ
sum error= 156
Actual label: 4
Output voltages: [0.0062631, 0.026404, 0.019872, 0.001735, 0.7987, 0.02112, 0.34583, 0.095362, 0.33554, 0.10075]
Predicted label: 4
Correct prediction
Energy consumption = 156.600714 pJ
sum error= 156
Actual label: 0
Output voltages: [0.79674, 0.017527, 0.10954, 0.0013081, 0.047188, 0.0023443, 0.65058, 0.031971, 0.020396, 0.16243]
Predicted label: 0
Correct prediction
Energy consumption = 156.694691 pJ
sum error= 156
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 290 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 290 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 290 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.024486, 0.0030551, 0.36993, 0.0027748, 0.79869, 0.0011285, 0.22425, 0.010663, 0.0278, 0.16495]
Predicted label: 4
Correct prediction
Energy consumption = 144.167707 pJ
sum error= 156
Actual label: 4
Output voltages: [0.0038605, 0.1699, 0.010431, 0.0035223, 0.79685, 0.0010667, 0.66854, 0.0010752, 0.29852, 0.034448]
Predicted label: 4
Correct prediction
Energy consumption = 147.978753 pJ
sum error= 156
Actual label: 1
Output voltages: [0.034563, 0.79861, 0.097051, 0.4587, 0.0025323, 0.0022756, 0.27844, 0.015862, 0.048526, 0.016127]
Predicted label: 1
Correct prediction
Energy consumption = 157.008484 pJ
sum error= 156
Actual label: 5
Output voltages: [0.020202, 0.0011511, 0.0024311, 0.4378, 0.07426, 0.79029, 0.056643, 0.021526, 0.78201, 0.045717]
Predicted label: 5
Correct prediction
Energy consumption = 146.099958 pJ
sum error= 156
Actual label: 2
Output voltages: [0.63682, 0.032865, 0.79871, 0.041295, 0.021836, 0.0011642, 0.26888, 0.051974, 0.32741, 0.048413]
Predicted label: 2
Correct prediction
Energy consumption = 147.103248 pJ
sum error= 156
Actual label: 8
Output voltages: [0.0034885, 0.53967, 0.065201, 0.026767, 0.018121, 0.0021297, 0.040543, 0.0090933, 0.79876, 0.53735]
Predicted label: 8
Correct prediction
Energy consumption = 148.316632 pJ
sum error= 156
Actual label: 3
Output voltages: [0.12177, 0.0054445, 0.037905, 0.79879, 0.03228, 0.055706, 0.013352, 0.031842, 0.74891, 0.029567]
Predicted label: 3
Correct prediction
Energy consumption = 145.479140 pJ
sum error= 156
Actual label: 4
Output voltages: [0.0024431, 0.009603, 0.61192, 0.015851, 0.79868, 0.0026904, 0.20103, 0.048325, 0.02242, 0.22885]
Predicted label: 4
Correct prediction
Energy consumption = 148.555147 pJ
sum error= 156
Actual label: 9
Output voltages: [0.16435, 0.022122, 0.055618, 0.22961, 0.11446, 0.016814, 0.022221, 0.0046741, 0.40597, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 148.671013 pJ
sum error= 156
Actual label: 5
Output voltages: [0.0595, 0.0035444, 0.0023898, 0.51865, 0.038513, 0.79862, 0.25646, 0.057755, 0.77982, 0.11091]
Predicted label: 5
Correct prediction
Energy consumption = 149.580942 pJ
sum error= 156
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 291 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 291 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 291 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.25375, 0.48737, 0.79867, 0.49065, 0.014397, 0.0012331, 0.046896, 0.088259, 0.24657, 0.12142]
Predicted label: 2
Correct prediction
Energy consumption = 152.144485 pJ
sum error= 156
Actual label: 8
Output voltages: [0.066998, 0.090287, 0.74753, 0.07207, 0.027413, 0.0017038, 0.35651, 0.0010669, 0.78902, 0.35681]
Predicted label: 8
Correct prediction
Energy consumption = 148.792900 pJ
sum error= 156
Actual label: 1
Output voltages: [0.022623, 0.79858, 0.032922, 0.092148, 0.017654, 0.0015404, 0.23368, 0.0059494, 0.67326, 0.030735]
Predicted label: 1
Correct prediction
Energy consumption = 159.465814 pJ
sum error= 156
Actual label: 5
Output voltages: [0.026404, 0.0019999, 0.0045907, 0.41302, 0.025067, 0.79879, 0.13424, 0.059535, 0.73661, 0.23339]
Predicted label: 5
Correct prediction
Energy consumption = 155.304786 pJ
sum error= 156
Actual label: 3
Output voltages: [0.17408, 0.075061, 0.031989, 0.7987, 0.0050235, 0.0041668, 0.0019737, 0.27269, 0.53844, 0.11544]
Predicted label: 3
Correct prediction
Energy consumption = 145.554168 pJ
sum error= 156
Actual label: 7
Output voltages: [0.035796, 0.68211, 0.54797, 0.38753, 0.004625, 0.0012412, 0.0028112, 0.75185, 0.652, 0.011734]
Predicted label: 7
Correct prediction
Energy consumption = 149.160243 pJ
sum error= 156
Actual label: 9
Output voltages: [0.23339, 0.017183, 0.0078006, 0.055787, 0.14094, 0.0096352, 0.0019151, 0.024248, 0.16909, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 154.977076 pJ
sum error= 156
Actual label: 4
Output voltages: [0.0090592, 0.045572, 0.082772, 0.049163, 0.79867, 0.0031152, 0.2095, 0.051025, 0.015317, 0.19135]
Predicted label: 4
Correct prediction
Energy consumption = 157.773693 pJ
sum error= 156
Actual label: 2
Output voltages: [0.56013, 0.0081359, 0.79878, 0.13353, 0.034316, 0.0010728, 0.10284, 0.21748, 0.53349, 0.0039731]
Predicted label: 2
Correct prediction
Energy consumption = 149.533429 pJ
sum error= 156
Actual label: 5
Output voltages: [0.025339, 0.0010941, 0.0012072, 0.24512, 0.15602, 0.79782, 0.20664, 0.05502, 0.60082, 0.29061]
Predicted label: 5
Correct prediction
Energy consumption = 145.411802 pJ
sum error= 156
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 292 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 292 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 292 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.019903, 0.022672, 0.23658, 0.0029619, 0.24147, 0.50215, 0.79874, 0.013258, 0.34361, 0.0062]
Predicted label: 6
Correct prediction
Energy consumption = 144.162179 pJ
sum error= 156
Actual label: 3
Output voltages: [0.67536, 0.012999, 0.76335, 0.75284, 0.0010662, 0.0022342, 0.027817, 0.030228, 0.78672, 0.004655]
Predicted label: 8
Wrong prediction!
Energy consumption = 151.991781 pJ
sum error= 157
Actual label: 5
Output voltages: [0.042759, 0.0011565, 0.0043568, 0.22652, 0.046211, 0.79768, 0.038762, 0.0045252, 0.7816, 0.096231]
Predicted label: 5
Correct prediction
Energy consumption = 145.085582 pJ
sum error= 157
Actual label: 9
Output voltages: [0.063213, 0.017191, 0.015658, 0.042685, 0.047879, 0.0021859, 0.006184, 0.037388, 0.40796, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 151.266240 pJ
sum error= 157
Actual label: 3
Output voltages: [0.080714, 0.019762, 0.054493, 0.79874, 0.0068932, 0.01693, 0.040734, 0.023386, 0.57011, 0.023248]
Predicted label: 3
Correct prediction
Energy consumption = 144.907361 pJ
sum error= 157
Actual label: 5
Output voltages: [0.044391, 0.0040331, 0.0011335, 0.1349, 0.33149, 0.7828, 0.76183, 0.0011557, 0.73932, 0.062563]
Predicted label: 5
Correct prediction
Energy consumption = 142.771135 pJ
sum error= 157
Actual label: 9
Output voltages: [0.44495, 0.036924, 0.0069626, 0.3331, 0.67963, 0.051248, 0.04616, 0.0054606, 0.058118, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 153.720663 pJ
sum error= 157
Actual label: 3
Output voltages: [0.031099, 0.023476, 0.79766, 0.54525, 0.026084, 0.0011099, 0.017815, 0.41912, 0.6004, 0.0032306]
Predicted label: 2
Wrong prediction!
Energy consumption = 153.220509 pJ
sum error= 158
Actual label: 1
Output voltages: [0.0086528, 0.79877, 0.34036, 0.036317, 0.056291, 0.0011298, 0.73908, 0.001716, 0.10275, 0.014632]
Predicted label: 1
Correct prediction
Energy consumption = 158.666841 pJ
sum error= 158
Actual label: 9
Output voltages: [0.66396, 0.0011283, 0.18886, 0.003724, 0.070718, 0.040737, 0.0010743, 0.41654, 0.36225, 0.78304]
Predicted label: 9
Correct prediction
Energy consumption = 152.860403 pJ
sum error= 158
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 293 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 293 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 293 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.78503, 0.0080128, 0.0010996, 0.46747, 0.22546, 0.79877, 0.037817, 0.0072218, 0.047827, 0.039991]
Predicted label: 5
Correct prediction
Energy consumption = 144.358179 pJ
sum error= 158
Actual label: 3
Output voltages: [0.13941, 0.062843, 0.054527, 0.79867, 0.01816, 0.0038591, 0.018487, 0.011924, 0.4408, 0.22155]
Predicted label: 3
Correct prediction
Energy consumption = 146.688574 pJ
sum error= 158
Actual label: 0
Output voltages: [0.79879, 0.041264, 0.34005, 0.013835, 0.0016005, 0.011423, 0.50515, 0.02138, 0.18472, 0.047066]
Predicted label: 0
Correct prediction
Energy consumption = 151.841770 pJ
sum error= 158
Actual label: 6
Output voltages: [0.055851, 0.15506, 0.43655, 0.0069527, 0.16525, 0.12805, 0.79871, 0.0014412, 0.37808, 0.030631]
Predicted label: 6
Correct prediction
Energy consumption = 144.700143 pJ
sum error= 158
Actual label: 9
Output voltages: [0.12867, 0.0080795, 0.010869, 0.042875, 0.013988, 0.039074, 0.0015083, 0.40348, 0.67833, 0.76555]
Predicted label: 9
Correct prediction
Energy consumption = 155.255534 pJ
sum error= 158
Actual label: 8
Output voltages: [0.01582, 0.12, 0.20464, 0.053952, 0.0081194, 0.022233, 0.035171, 0.035617, 0.79878, 0.19082]
Predicted label: 8
Correct prediction
Energy consumption = 147.024601 pJ
sum error= 158
Actual label: 4
Output voltages: [0.012795, 0.011749, 0.11858, 0.0067781, 0.79858, 0.023436, 0.050306, 0.030216, 0.030672, 0.33799]
Predicted label: 4
Correct prediction
Energy consumption = 152.952886 pJ
sum error= 158
Actual label: 0
Output voltages: [0.79873, 0.049625, 0.019023, 0.022866, 0.047695, 0.021026, 0.040232, 0.12576, 0.30119, 0.13404]
Predicted label: 0
Correct prediction
Energy consumption = 162.137506 pJ
sum error= 158
Actual label: 4
Output voltages: [0.30306, 0.0036452, 0.0091247, 0.0043013, 0.76913, 0.0010939, 0.51294, 0.0041248, 0.20977, 0.026689]
Predicted label: 4
Correct prediction
Energy consumption = 150.686903 pJ
sum error= 158
Actual label: 9
Output voltages: [0.55618, 0.027399, 0.001107, 0.65084, 0.66567, 0.63152, 0.0017873, 0.40753, 0.01689, 0.76704]
Predicted label: 9
Correct prediction
Energy consumption = 147.700144 pJ
sum error= 158
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 294 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 294 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 294 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.48971, 0.36596, 0.79843, 0.037018, 0.027816, 0.0013581, 0.58939, 0.035922, 0.39537, 0.043863]
Predicted label: 2
Correct prediction
Energy consumption = 145.929732 pJ
sum error= 158
Actual label: 9
Output voltages: [0.11813, 0.0011696, 0.018776, 0.0020245, 0.3804, 0.35895, 0.0083863, 0.04521, 0.67605, 0.78324]
Predicted label: 9
Correct prediction
Energy consumption = 152.957265 pJ
sum error= 158
Actual label: 0
Output voltages: [0.79874, 0.13195, 0.051564, 0.030867, 0.0047233, 0.0057726, 0.65403, 0.0074678, 0.14587, 0.10569]
Predicted label: 0
Correct prediction
Energy consumption = 158.655418 pJ
sum error= 158
Actual label: 1
Output voltages: [0.25098, 0.79857, 0.019945, 0.34489, 0.015044, 0.0055074, 0.59779, 0.002052, 0.44489, 0.027472]
Predicted label: 1
Correct prediction
Energy consumption = 158.233662 pJ
sum error= 158
Actual label: 0
Output voltages: [0.79879, 0.07261, 0.62897, 0.0042381, 0.018578, 0.0039109, 0.14646, 0.012731, 0.45682, 0.421]
Predicted label: 0
Correct prediction
Energy consumption = 156.675827 pJ
sum error= 158
Actual label: 3
Output voltages: [0.28179, 0.063501, 0.079196, 0.79876, 0.0019216, 0.0033509, 0.0010664, 0.72499, 0.03834, 0.67173]
Predicted label: 3
Correct prediction
Energy consumption = 147.841561 pJ
sum error= 158
Actual label: 1
Output voltages: [0.023688, 0.79233, 0.02948, 0.0044536, 0.19767, 0.039252, 0.36098, 0.0010778, 0.76309, 0.4361]
Predicted label: 1
Correct prediction
Energy consumption = 148.983426 pJ
sum error= 158
Actual label: 6
Output voltages: [0.11917, 0.044141, 0.12213, 0.0046901, 0.37503, 0.31641, 0.79868, 0.00182, 0.54516, 0.012364]
Predicted label: 6
Correct prediction
Energy consumption = 147.734246 pJ
sum error= 158
Actual label: 5
Output voltages: [0.11851, 0.0019018, 0.047808, 0.32814, 0.0015829, 0.79228, 0.11675, 0.001723, 0.78754, 0.022853]
Predicted label: 5
Correct prediction
Energy consumption = 144.092904 pJ
sum error= 158
Actual label: 8
Output voltages: [0.012611, 0.051398, 0.13369, 0.19512, 0.0029114, 0.032697, 0.031859, 0.015373, 0.79878, 0.05616]
Predicted label: 8
Correct prediction
Energy consumption = 144.466424 pJ
sum error= 158
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 295 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 295 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 295 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.012592, 0.79844, 0.040536, 0.020854, 0.0082889, 0.0025439, 0.56382, 0.0016539, 0.12322, 0.058964]
Predicted label: 1
Correct prediction
Energy consumption = 162.526554 pJ
sum error= 158
Actual label: 5
Output voltages: [0.02651, 0.0010738, 0.014345, 0.34331, 0.0018244, 0.7966, 0.35388, 0.0249, 0.77379, 0.019049]
Predicted label: 5
Correct prediction
Energy consumption = 153.432961 pJ
sum error= 158
Actual label: 3
Output voltages: [0.046574, 0.0010885, 0.037044, 0.77998, 0.44204, 0.75846, 0.018937, 0.015341, 0.65789, 0.019676]
Predicted label: 3
Correct prediction
Energy consumption = 143.630076 pJ
sum error= 158
Actual label: 3
Output voltages: [0.17404, 0.0029061, 0.015713, 0.78387, 0.011659, 0.74162, 0.005863, 0.028622, 0.79067, 0.012245]
Predicted label: 8
Wrong prediction!
Energy consumption = 137.593736 pJ
sum error= 159
Actual label: 0
Output voltages: [0.79706, 0.02514, 0.33983, 0.0089538, 0.0091257, 0.0081848, 0.71273, 0.045488, 0.44143, 0.011534]
Predicted label: 0
Correct prediction
Energy consumption = 149.664085 pJ
sum error= 159
Actual label: 3
Output voltages: [0.053532, 0.015405, 0.049994, 0.7987, 0.018962, 0.030698, 0.01874, 0.0014705, 0.48857, 0.078579]
Predicted label: 3
Correct prediction
Energy consumption = 148.432953 pJ
sum error= 159
Actual label: 5
Output voltages: [0.0032519, 0.0016453, 0.094392, 0.40952, 0.13376, 0.78776, 0.024184, 0.0016664, 0.79707, 0.1619]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.920400 pJ
sum error= 160
Actual label: 5
Output voltages: [0.26135, 0.0010751, 0.0031424, 0.20332, 0.010507, 0.79879, 0.46696, 0.03097, 0.59217, 0.0012821]
Predicted label: 5
Correct prediction
Energy consumption = 139.011860 pJ
sum error= 160
Actual label: 9
Output voltages: [0.23783, 0.0078954, 0.023433, 0.027898, 0.37624, 0.0061978, 0.031396, 0.0031352, 0.47112, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 151.252198 pJ
sum error= 160
Actual label: 2
Output voltages: [0.022495, 0.014607, 0.79879, 0.38346, 0.0029556, 0.0011371, 0.01232, 0.37391, 0.37974, 0.01497]
Predicted label: 2
Correct prediction
Energy consumption = 144.952175 pJ
sum error= 160
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 296 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 296 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 296 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0063967, 0.22746, 0.11697, 0.023952, 0.020441, 0.0022121, 0.024582, 0.0095013, 0.79878, 0.60784]
Predicted label: 8
Correct prediction
Energy consumption = 155.162152 pJ
sum error= 160
Actual label: 7
Output voltages: [0.44646, 0.027366, 0.49953, 0.78451, 0.0072481, 0.0015953, 0.0022254, 0.78581, 0.019923, 0.71734]
Predicted label: 7
Correct prediction
Energy consumption = 152.852512 pJ
sum error= 160
Actual label: 0
Output voltages: [0.79856, 0.040948, 0.026118, 0.014128, 0.020392, 0.00112, 0.75348, 0.0025018, 0.22114, 0.1308]
Predicted label: 0
Correct prediction
Energy consumption = 156.834149 pJ
sum error= 160
Actual label: 4
Output voltages: [0.01199, 0.0084906, 0.11508, 0.014742, 0.79858, 0.0032158, 0.26819, 0.053369, 0.024899, 0.017341]
Predicted label: 4
Correct prediction
Energy consumption = 149.725136 pJ
sum error= 160
Actual label: 9
Output voltages: [0.11885, 0.026617, 0.040187, 0.036794, 0.79019, 0.0032836, 0.027218, 0.0076533, 0.033458, 0.79585]
Predicted label: 9
Correct prediction
Energy consumption = 146.941063 pJ
sum error= 160
Actual label: 1
Output voltages: [0.014957, 0.79846, 0.038023, 0.030301, 0.010244, 0.0056382, 0.60341, 0.0041388, 0.32378, 0.03609]
Predicted label: 1
Correct prediction
Energy consumption = 166.820340 pJ
sum error= 160
Actual label: 9
Output voltages: [0.47815, 0.020675, 0.0013295, 0.1735, 0.74843, 0.22325, 0.11121, 0.0025516, 0.044924, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 161.882616 pJ
sum error= 160
Actual label: 7
Output voltages: [0.069577, 0.038276, 0.13764, 0.15978, 0.0046985, 0.0011039, 0.0010863, 0.7986, 0.16938, 0.29843]
Predicted label: 7
Correct prediction
Energy consumption = 154.716046 pJ
sum error= 160
Actual label: 7
Output voltages: [0.19477, 0.038628, 0.021193, 0.077531, 0.028372, 0.0041613, 0.0016566, 0.79879, 0.11818, 0.50599]
Predicted label: 7
Correct prediction
Energy consumption = 141.901148 pJ
sum error= 160
Actual label: 5
Output voltages: [0.32469, 0.001069, 0.020934, 0.18694, 0.019288, 0.79876, 0.4459, 0.073105, 0.73169, 0.0039629]
Predicted label: 5
Correct prediction
Energy consumption = 138.776402 pJ
sum error= 160
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 297 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 297 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 297 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.17371, 0.0010668, 0.0011297, 0.61472, 0.0016553, 0.77338, 0.016571, 0.15026, 0.74856, 0.047114]
Predicted label: 5
Correct prediction
Energy consumption = 148.401492 pJ
sum error= 160
Actual label: 2
Output voltages: [0.4859, 0.041877, 0.79875, 0.048009, 0.011173, 0.0012868, 0.21019, 0.1526, 0.45229, 0.023227]
Predicted label: 2
Correct prediction
Energy consumption = 149.310744 pJ
sum error= 160
Actual label: 0
Output voltages: [0.79711, 0.043855, 0.093944, 0.0036768, 0.052939, 0.003672, 0.79225, 0.11815, 0.13697, 0.021042]
Predicted label: 0
Correct prediction
Energy consumption = 144.938900 pJ
sum error= 160
Actual label: 9
Output voltages: [0.38458, 0.018456, 0.027315, 0.043435, 0.2228, 0.10334, 0.048374, 0.026067, 0.24961, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.796391 pJ
sum error= 160
Actual label: 1
Output voltages: [0.028994, 0.7985, 0.45072, 0.022053, 0.024579, 0.0015418, 0.62495, 0.0014611, 0.059107, 0.02544]
Predicted label: 1
Correct prediction
Energy consumption = 165.028679 pJ
sum error= 160
Actual label: 8
Output voltages: [0.35802, 0.016331, 0.68988, 0.0034936, 0.22437, 0.0012091, 0.050146, 0.0054653, 0.7986, 0.21073]
Predicted label: 8
Correct prediction
Energy consumption = 145.416281 pJ
sum error= 160
Actual label: 6
Output voltages: [0.40254, 0.01461, 0.019217, 0.028282, 0.27735, 0.70887, 0.79834, 0.0029604, 0.41107, 0.024608]
Predicted label: 6
Correct prediction
Energy consumption = 148.393727 pJ
sum error= 160
Actual label: 2
Output voltages: [0.58062, 0.018622, 0.79879, 0.29041, 0.029254, 0.0011554, 0.06513, 0.053739, 0.68808, 0.019202]
Predicted label: 2
Correct prediction
Energy consumption = 147.127165 pJ
sum error= 160
Actual label: 3
Output voltages: [0.37996, 0.15555, 0.051992, 0.7986, 0.014486, 0.047922, 0.032077, 0.043016, 0.6582, 0.074424]
Predicted label: 3
Correct prediction
Energy consumption = 147.938337 pJ
sum error= 160
Actual label: 9
Output voltages: [0.79645, 0.0074444, 0.013008, 0.0036488, 0.05568, 0.0011004, 0.027113, 0.35615, 0.30831, 0.73911]
Predicted label: 0
Wrong prediction!
Energy consumption = 154.871887 pJ
sum error= 161
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 298 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 298 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 298 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.48335, 0.011585, 0.033233, 0.039156, 0.045417, 0.29998, 0.79879, 0.0010974, 0.45152, 0.15837]
Predicted label: 6
Correct prediction
Energy consumption = 148.630992 pJ
sum error= 161
Actual label: 2
Output voltages: [0.30387, 0.036051, 0.79874, 0.39654, 0.0014696, 0.0010676, 0.35414, 0.032951, 0.51583, 0.017753]
Predicted label: 2
Correct prediction
Energy consumption = 145.896414 pJ
sum error= 161
Actual label: 1
Output voltages: [0.025547, 0.79856, 0.045742, 0.043702, 0.22193, 0.0025035, 0.53803, 0.0071024, 0.053808, 0.055933]
Predicted label: 1
Correct prediction
Energy consumption = 167.998828 pJ
sum error= 161
Actual label: 9
Output voltages: [0.63222, 0.0073786, 0.019596, 0.020137, 0.43328, 0.021774, 0.0049562, 0.015451, 0.35472, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 161.133961 pJ
sum error= 161
Actual label: 1
Output voltages: [0.020523, 0.79852, 0.3961, 0.66151, 0.02559, 0.0012284, 0.22925, 0.0056193, 0.024685, 0.27865]
Predicted label: 1
Correct prediction
Energy consumption = 162.578070 pJ
sum error= 161
Actual label: 3
Output voltages: [0.32813, 0.024847, 0.10367, 0.7986, 0.033472, 0.028873, 0.014195, 0.036583, 0.45292, 0.061463]
Predicted label: 3
Correct prediction
Energy consumption = 148.366324 pJ
sum error= 161
Actual label: 5
Output voltages: [0.04172, 0.0011023, 0.0011798, 0.18232, 0.152, 0.79796, 0.50386, 0.0013856, 0.77228, 0.019913]
Predicted label: 5
Correct prediction
Energy consumption = 138.693374 pJ
sum error= 161
Actual label: 5
Output voltages: [0.025272, 0.0021507, 0.0015367, 0.76294, 0.024539, 0.79756, 0.025863, 0.022739, 0.47458, 0.14048]
Predicted label: 5
Correct prediction
Energy consumption = 145.139771 pJ
sum error= 161
Actual label: 0
Output voltages: [0.79873, 0.17775, 0.12338, 0.044674, 0.047195, 0.021955, 0.35409, 0.1111, 0.41613, 0.039764]
Predicted label: 0
Correct prediction
Energy consumption = 158.653848 pJ
sum error= 161
Actual label: 3
Output voltages: [0.37726, 0.013934, 0.37265, 0.79876, 0.049948, 0.0076202, 0.004373, 0.0022641, 0.50221, 0.0028499]
Predicted label: 3
Correct prediction
Energy consumption = 148.560087 pJ
sum error= 161
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 299 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 299 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 299 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.022628, 0.034726, 0.056093, 0.022518, 0.0076983, 0.025624, 0.010002, 0.0015318, 0.79875, 0.63459]
Predicted label: 8
Correct prediction
Energy consumption = 152.802921 pJ
sum error= 161
Actual label: 3
Output voltages: [0.030675, 0.0070844, 0.0392, 0.79879, 0.13749, 0.11497, 0.010058, 0.034809, 0.33943, 0.33062]
Predicted label: 3
Correct prediction
Energy consumption = 146.094849 pJ
sum error= 161
Actual label: 3
Output voltages: [0.37239, 0.01592, 0.056207, 0.7986, 0.017422, 0.047836, 0.012979, 0.016704, 0.44292, 0.029621]
Predicted label: 3
Correct prediction
Energy consumption = 140.050105 pJ
sum error= 161
Actual label: 7
Output voltages: [0.40231, 0.031065, 0.77713, 0.029062, 0.0033651, 0.001104, 0.0010699, 0.79872, 0.11909, 0.061727]
Predicted label: 7
Correct prediction
Energy consumption = 148.305607 pJ
sum error= 161
Actual label: 6
Output voltages: [0.045036, 0.037937, 0.48769, 0.0019715, 0.52821, 0.13751, 0.79877, 0.0065271, 0.63625, 0.0017696]
Predicted label: 6
Correct prediction
Energy consumption = 154.935134 pJ
sum error= 161
Actual label: 6
Output voltages: [0.32572, 0.02996, 0.065656, 0.19134, 0.0013044, 0.56708, 0.74655, 0.0074305, 0.79726, 0.0036709]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.665743 pJ
sum error= 162
Actual label: 0
Output voltages: [0.79876, 0.31863, 0.018914, 0.014915, 0.010273, 0.041533, 0.29907, 0.017892, 0.053168, 0.15195]
Predicted label: 0
Correct prediction
Energy consumption = 143.195364 pJ
sum error= 162
Actual label: 1
Output voltages: [0.11492, 0.79842, 0.084591, 0.40676, 0.10692, 0.0078768, 0.40094, 0.0087671, 0.029187, 0.31442]
Predicted label: 1
Correct prediction
Energy consumption = 164.170478 pJ
sum error= 162
Actual label: 4
Output voltages: [0.010768, 0.011521, 0.10544, 0.007868, 0.79872, 0.021657, 0.075165, 0.02359, 0.035426, 0.13628]
Predicted label: 4
Correct prediction
Energy consumption = 151.185517 pJ
sum error= 162
Actual label: 0
Output voltages: [0.79862, 0.17715, 0.014956, 0.037989, 0.0068351, 0.050673, 0.74013, 0.023475, 0.17563, 0.013896]
Predicted label: 0
Correct prediction
Energy consumption = 149.861147 pJ
sum error= 162
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 300 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 300 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 300 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.027512, 0.021279, 0.025459, 0.10073, 0.086793, 0.73414, 0.79847, 0.0072574, 0.78119, 0.0015932]
Predicted label: 6
Correct prediction
Energy consumption = 155.655009 pJ
sum error= 162
Actual label: 9
Output voltages: [0.27096, 0.015436, 0.23311, 0.028631, 0.21049, 0.001744, 0.035917, 0.0015127, 0.67349, 0.79569]
Predicted label: 9
Correct prediction
Energy consumption = 147.990301 pJ
sum error= 162
Actual label: 8
Output voltages: [0.018795, 0.13051, 0.12679, 0.076644, 0.0047274, 0.0075102, 0.022572, 0.0049696, 0.79878, 0.43733]
Predicted label: 8
Correct prediction
Energy consumption = 150.859415 pJ
sum error= 162
Actual label: 1
Output voltages: [0.10215, 0.79849, 0.02452, 0.21698, 0.039479, 0.0052674, 0.051417, 0.029438, 0.22125, 0.50204]
Predicted label: 1
Correct prediction
Energy consumption = 161.656222 pJ
sum error= 162
Actual label: 2
Output voltages: [0.049893, 0.048526, 0.79534, 0.13754, 0.023499, 0.0011348, 0.030915, 0.062141, 0.75114, 0.011054]
Predicted label: 2
Correct prediction
Energy consumption = 150.372563 pJ
sum error= 162
Actual label: 9
Output voltages: [0.028754, 0.75375, 0.011062, 0.20727, 0.0053292, 0.22879, 0.069664, 0.0011209, 0.79528, 0.72881]
Predicted label: 8
Wrong prediction!
Energy consumption = 157.772809 pJ
sum error= 163
Actual label: 9
Output voltages: [0.60345, 0.014326, 0.020273, 0.048891, 0.32435, 0.0062241, 0.0064875, 0.011863, 0.14973, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 157.463451 pJ
sum error= 163
Actual label: 5
Output voltages: [0.006353, 0.0010938, 0.0071331, 0.058109, 0.0034835, 0.79177, 0.05714, 0.0021355, 0.79642, 0.0037364]
Predicted label: 8
Wrong prediction!
Energy consumption = 142.884998 pJ
sum error= 164
Actual label: 9
Output voltages: [0.26919, 0.0296, 0.024358, 0.04628, 0.083191, 0.042535, 0.016146, 0.026054, 0.45983, 0.79833]
Predicted label: 9
Correct prediction
Energy consumption = 147.349960 pJ
sum error= 164
Actual label: 7
Output voltages: [0.019881, 0.49363, 0.46215, 0.042297, 0.0020325, 0.0010892, 0.0010898, 0.79876, 0.36242, 0.19681]
Predicted label: 7
Correct prediction
Energy consumption = 149.717664 pJ
sum error= 164
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 301 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 301 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 301 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.015956, 0.029876, 0.2102, 0.79879, 0.0072776, 0.020387, 0.003201, 0.022324, 0.75522, 0.030457]
Predicted label: 3
Correct prediction
Energy consumption = 143.104590 pJ
sum error= 164
Actual label: 7
Output voltages: [0.33887, 0.044279, 0.0071046, 0.16215, 0.017165, 0.63036, 0.0013824, 0.79871, 0.049186, 0.37589]
Predicted label: 7
Correct prediction
Energy consumption = 148.965577 pJ
sum error= 164
Actual label: 8
Output voltages: [0.0029598, 0.10484, 0.03349, 0.13542, 0.013586, 0.0017749, 0.011276, 0.0039883, 0.78929, 0.75693]
Predicted label: 8
Correct prediction
Energy consumption = 151.359590 pJ
sum error= 164
Actual label: 0
Output voltages: [0.79879, 0.1482, 0.024855, 0.034536, 0.0042796, 0.083713, 0.43067, 0.001616, 0.24733, 0.2712]
Predicted label: 0
Correct prediction
Energy consumption = 148.922393 pJ
sum error= 164
Actual label: 1
Output voltages: [0.004231, 0.79862, 0.0084562, 0.029445, 0.025941, 0.15765, 0.7551, 0.017927, 0.075789, 0.013329]
Predicted label: 1
Correct prediction
Energy consumption = 160.354146 pJ
sum error= 164
Actual label: 3
Output voltages: [0.08396, 0.025997, 0.20848, 0.79871, 0.025656, 0.016459, 0.0072567, 0.0098142, 0.65275, 0.36007]
Predicted label: 3
Correct prediction
Energy consumption = 146.752656 pJ
sum error= 164
Actual label: 0
Output voltages: [0.79871, 0.058791, 0.016617, 0.022825, 0.039046, 0.02976, 0.55261, 0.095195, 0.2509, 0.016575]
Predicted label: 0
Correct prediction
Energy consumption = 146.298865 pJ
sum error= 164
Actual label: 4
Output voltages: [0.0055065, 0.011309, 0.065479, 0.047525, 0.79872, 0.0011892, 0.010587, 0.031119, 0.050569, 0.057221]
Predicted label: 4
Correct prediction
Energy consumption = 151.500544 pJ
sum error= 164
Actual label: 6
Output voltages: [0.29119, 0.030458, 0.13257, 0.0061254, 0.3349, 0.054685, 0.79879, 0.0021053, 0.64751, 0.0071942]
Predicted label: 6
Correct prediction
Energy consumption = 140.648818 pJ
sum error= 164
Actual label: 1
Output voltages: [0.0014919, 0.79863, 0.030506, 0.0056041, 0.033511, 0.0064018, 0.56993, 0.0049219, 0.50997, 0.015166]
Predicted label: 1
Correct prediction
Energy consumption = 155.997183 pJ
sum error= 164
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 302 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 302 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 302 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79863, 0.23101, 0.016337, 0.016609, 0.021237, 0.046393, 0.62555, 0.014347, 0.040917, 0.28875]
Predicted label: 0
Correct prediction
Energy consumption = 156.469981 pJ
sum error= 164
Actual label: 2
Output voltages: [0.70953, 0.042478, 0.79491, 0.21161, 0.0017024, 0.0012223, 0.039374, 0.60933, 0.37643, 0.012296]
Predicted label: 2
Correct prediction
Energy consumption = 147.291837 pJ
sum error= 164
Actual label: 5
Output voltages: [0.03717, 0.0011068, 0.0010784, 0.15211, 0.41639, 0.79773, 0.40331, 0.013679, 0.77199, 0.032563]
Predicted label: 5
Correct prediction
Energy consumption = 145.767675 pJ
sum error= 164
Actual label: 8
Output voltages: [0.051493, 0.0070681, 0.12313, 0.024176, 0.0067393, 0.7769, 0.25669, 0.0051114, 0.78933, 0.010761]
Predicted label: 8
Correct prediction
Energy consumption = 146.184872 pJ
sum error= 164
Actual label: 4
Output voltages: [0.034602, 0.0064537, 0.083314, 0.0010661, 0.79879, 0.004791, 0.20812, 0.010191, 0.36947, 0.048013]
Predicted label: 4
Correct prediction
Energy consumption = 152.985597 pJ
sum error= 164
Actual label: 4
Output voltages: [0.021681, 0.010676, 0.40187, 0.01169, 0.79858, 0.0065595, 0.073016, 0.020597, 0.028536, 0.24714]
Predicted label: 4
Correct prediction
Energy consumption = 148.105722 pJ
sum error= 164
Actual label: 1
Output voltages: [0.032347, 0.79879, 0.046681, 0.016591, 0.55333, 0.0014803, 0.25781, 0.0012407, 0.18945, 0.10891]
Predicted label: 1
Correct prediction
Energy consumption = 154.316291 pJ
sum error= 164
Actual label: 1
Output voltages: [0.004938, 0.79858, 0.13158, 0.011093, 0.0066491, 0.0041744, 0.48445, 0.023359, 0.42579, 0.0037542]
Predicted label: 1
Correct prediction
Energy consumption = 149.574103 pJ
sum error= 164
Actual label: 5
Output voltages: [0.20033, 0.001076, 0.0044031, 0.051618, 0.025896, 0.7986, 0.46045, 0.014496, 0.77822, 0.0056218]
Predicted label: 5
Correct prediction
Energy consumption = 146.654315 pJ
sum error= 164
Actual label: 4
Output voltages: [0.0019241, 0.018043, 0.10868, 0.010836, 0.79866, 0.001444, 0.023275, 0.036833, 0.080769, 0.026337]
Predicted label: 4
Correct prediction
Energy consumption = 154.094211 pJ
sum error= 164
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 303 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 303 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 303 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.77753, 0.038511, 0.049536, 0.024742, 0.04709, 0.001092, 0.52102, 0.034908, 0.70606, 0.052354]
Predicted label: 0
Wrong prediction!
Energy consumption = 158.611442 pJ
sum error= 165
Actual label: 6
Output voltages: [0.042925, 0.057567, 0.53384, 0.0010855, 0.15069, 0.033465, 0.79876, 0.0032422, 0.41938, 0.0076335]
Predicted label: 6
Correct prediction
Energy consumption = 140.029832 pJ
sum error= 165
Actual label: 0
Output voltages: [0.79879, 0.10802, 0.2876, 0.026176, 0.03421, 0.0093124, 0.2044, 0.0044955, 0.53633, 0.03246]
Predicted label: 0
Correct prediction
Energy consumption = 154.493522 pJ
sum error= 165
Actual label: 6
Output voltages: [0.52653, 0.037596, 0.11925, 0.011624, 0.16436, 0.15146, 0.79869, 0.001134, 0.31676, 0.046124]
Predicted label: 6
Correct prediction
Energy consumption = 151.172798 pJ
sum error= 165
Actual label: 9
Output voltages: [0.15047, 0.016653, 0.094664, 0.21257, 0.054676, 0.020812, 0.091797, 0.02925, 0.139, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 150.861399 pJ
sum error= 165
Actual label: 2
Output voltages: [0.098001, 0.010871, 0.79879, 0.17451, 0.12045, 0.001067, 0.026674, 0.050426, 0.22586, 0.046445]
Predicted label: 2
Correct prediction
Energy consumption = 142.420688 pJ
sum error= 165
Actual label: 6
Output voltages: [0.022936, 0.11683, 0.34802, 0.0014696, 0.31564, 0.1227, 0.79872, 0.0025023, 0.61021, 0.0061533]
Predicted label: 6
Correct prediction
Energy consumption = 152.159864 pJ
sum error= 165
Actual label: 2
Output voltages: [0.63749, 0.012388, 0.79879, 0.3031, 0.021672, 0.0010664, 0.28553, 0.2236, 0.3193, 0.017888]
Predicted label: 2
Correct prediction
Energy consumption = 145.589671 pJ
sum error= 165
Actual label: 7
Output voltages: [0.23486, 0.02605, 0.0013934, 0.025039, 0.27627, 0.013257, 0.0012785, 0.79872, 0.18996, 0.58337]
Predicted label: 7
Correct prediction
Energy consumption = 157.348167 pJ
sum error= 165
Actual label: 1
Output voltages: [0.0077689, 0.79869, 0.086936, 0.77594, 0.01196, 0.043372, 0.027741, 0.02379, 0.026412, 0.52201]
Predicted label: 1
Correct prediction
Energy consumption = 163.694480 pJ
sum error= 165
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 304 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 304 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 304 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.069205, 0.12138, 0.6779, 0.0044936, 0.0092277, 0.0012457, 0.0011301, 0.79863, 0.33534, 0.021255]
Predicted label: 7
Correct prediction
Energy consumption = 159.611043 pJ
sum error= 165
Actual label: 9
Output voltages: [0.15455, 0.019684, 0.047984, 0.046488, 0.037055, 0.040102, 0.015302, 0.22013, 0.51175, 0.79724]
Predicted label: 9
Correct prediction
Energy consumption = 154.198610 pJ
sum error= 165
Actual label: 4
Output voltages: [0.0012723, 0.027702, 0.045266, 0.0032336, 0.79879, 0.011727, 0.50836, 0.36517, 0.042515, 0.014707]
Predicted label: 4
Correct prediction
Energy consumption = 150.586233 pJ
sum error= 165
Actual label: 0
Output voltages: [0.79879, 0.11704, 0.037352, 0.0063913, 0.0093797, 0.010444, 0.37195, 0.012473, 0.073791, 0.061299]
Predicted label: 0
Correct prediction
Energy consumption = 153.753941 pJ
sum error= 165
Actual label: 0
Output voltages: [0.7987, 0.073053, 0.021474, 0.053286, 0.024932, 0.021543, 0.14706, 0.023406, 0.15683, 0.41619]
Predicted label: 0
Correct prediction
Energy consumption = 146.082695 pJ
sum error= 165
Actual label: 3
Output voltages: [0.40209, 0.025898, 0.020487, 0.79862, 0.013221, 0.015122, 0.022005, 0.0066662, 0.5394, 0.048506]
Predicted label: 3
Correct prediction
Energy consumption = 148.836461 pJ
sum error= 165
Actual label: 8
Output voltages: [0.019515, 0.066222, 0.058835, 0.048951, 0.027009, 0.0084399, 0.026082, 0.011488, 0.79877, 0.55385]
Predicted label: 8
Correct prediction
Energy consumption = 148.853695 pJ
sum error= 165
Actual label: 2
Output voltages: [0.29524, 0.14732, 0.79738, 0.4426, 0.016223, 0.0012743, 0.043985, 0.012296, 0.32978, 0.0054875]
Predicted label: 2
Correct prediction
Energy consumption = 154.184634 pJ
sum error= 165
Actual label: 2
Output voltages: [0.40296, 0.0023727, 0.79846, 0.12653, 0.01845, 0.0012246, 0.032993, 0.061463, 0.65178, 0.022082]
Predicted label: 2
Correct prediction
Energy consumption = 133.953625 pJ
sum error= 165
Actual label: 3
Output voltages: [0.32239, 0.010889, 0.043948, 0.7987, 0.01553, 0.13484, 0.018977, 0.009601, 0.64467, 0.049138]
Predicted label: 3
Correct prediction
Energy consumption = 141.475434 pJ
sum error= 165
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 305 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 305 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 305 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.021031, 0.79857, 0.15237, 0.080384, 0.2294, 0.001979, 0.51565, 0.0080088, 0.22842, 0.079339]
Predicted label: 1
Correct prediction
Energy consumption = 166.583335 pJ
sum error= 165
Actual label: 6
Output voltages: [0.054904, 0.038567, 0.039586, 0.013128, 0.21606, 0.092407, 0.79879, 0.0068168, 0.76341, 0.0026952]
Predicted label: 6
Correct prediction
Energy consumption = 142.997129 pJ
sum error= 165
Actual label: 0
Output voltages: [0.79879, 0.05681, 0.017195, 0.020826, 0.018703, 0.016255, 0.53974, 0.021213, 0.042599, 0.042839]
Predicted label: 0
Correct prediction
Energy consumption = 149.682880 pJ
sum error= 165
Actual label: 5
Output voltages: [0.0065569, 0.0010685, 0.01118, 0.2411, 0.26397, 0.79873, 0.15202, 0.017755, 0.71875, 0.388]
Predicted label: 5
Correct prediction
Energy consumption = 145.312186 pJ
sum error= 165
Actual label: 7
Output voltages: [0.22283, 0.039522, 0.1634, 0.0037625, 0.044038, 0.0014752, 0.0011415, 0.79865, 0.052438, 0.24608]
Predicted label: 7
Correct prediction
Energy consumption = 152.371830 pJ
sum error= 165
Actual label: 7
Output voltages: [0.22839, 0.30317, 0.055215, 0.35225, 0.0012661, 0.040042, 0.0010701, 0.78837, 0.79525, 0.13909]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.459206 pJ
sum error= 166
Actual label: 9
Output voltages: [0.21494, 0.014231, 0.01619, 0.19514, 0.022383, 0.030825, 0.01418, 0.16475, 0.57792, 0.79812]
Predicted label: 9
Correct prediction
Energy consumption = 146.126319 pJ
sum error= 166
Actual label: 2
Output voltages: [0.73529, 0.0018109, 0.79877, 0.24361, 0.01452, 0.0011294, 0.043855, 0.066649, 0.7389, 0.010345]
Predicted label: 2
Correct prediction
Energy consumption = 141.512527 pJ
sum error= 166
Actual label: 6
Output voltages: [0.46386, 0.075699, 0.046635, 0.002338, 0.26235, 0.40359, 0.79874, 0.029719, 0.19707, 0.016471]
Predicted label: 6
Correct prediction
Energy consumption = 143.760821 pJ
sum error= 166
Actual label: 7
Output voltages: [0.10924, 0.28926, 0.025527, 0.015558, 0.0090026, 0.0078291, 0.0010814, 0.796, 0.10927, 0.56924]
Predicted label: 7
Correct prediction
Energy consumption = 161.287511 pJ
sum error= 166
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 306 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 306 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 306 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.26696, 0.55262, 0.15982, 0.023595, 0.017119, 0.0032052, 0.0012015, 0.50682, 0.078142, 0.79396]
Predicted label: 9
Correct prediction
Energy consumption = 156.295921 pJ
sum error= 166
Actual label: 7
Output voltages: [0.067043, 0.015647, 0.25667, 0.32188, 0.0028145, 0.00111, 0.0016043, 0.79878, 0.06234, 0.1386]
Predicted label: 7
Correct prediction
Energy consumption = 143.472822 pJ
sum error= 166
Actual label: 8
Output voltages: [0.55704, 0.026654, 0.67002, 0.79402, 0.0010979, 0.0093121, 0.09656, 0.012972, 0.79391, 0.0014177]
Predicted label: 3
Wrong prediction!
Energy consumption = 146.099067 pJ
sum error= 167
Actual label: 6
Output voltages: [0.081862, 0.042971, 0.03066, 0.0045088, 0.15721, 0.25905, 0.79879, 0.026099, 0.74782, 0.0052281]
Predicted label: 6
Correct prediction
Energy consumption = 150.952244 pJ
sum error= 167
Actual label: 8
Output voltages: [0.024799, 0.020388, 0.11115, 0.16448, 0.0020054, 0.090684, 0.092908, 0.013592, 0.7987, 0.056196]
Predicted label: 8
Correct prediction
Energy consumption = 149.005824 pJ
sum error= 167
Actual label: 8
Output voltages: [0.025873, 0.11797, 0.018852, 0.29986, 0.0080935, 0.1575, 0.044253, 0.0011183, 0.79879, 0.59636]
Predicted label: 8
Correct prediction
Energy consumption = 144.389231 pJ
sum error= 167
Actual label: 4
Output voltages: [0.0026898, 0.0046515, 0.039125, 0.018341, 0.79878, 0.0096341, 0.040323, 0.019203, 0.071769, 0.015212]
Predicted label: 4
Correct prediction
Energy consumption = 153.733683 pJ
sum error= 167
Actual label: 6
Output voltages: [0.12404, 0.042594, 0.2419, 0.0033788, 0.10321, 0.36606, 0.79873, 0.0021993, 0.70342, 0.012395]
Predicted label: 6
Correct prediction
Energy consumption = 143.707330 pJ
sum error= 167
Actual label: 8
Output voltages: [0.064521, 0.03232, 0.18119, 0.76212, 0.0011218, 0.014328, 0.0011742, 0.2805, 0.79877, 0.033373]
Predicted label: 8
Correct prediction
Energy consumption = 149.949640 pJ
sum error= 167
Actual label: 4
Output voltages: [0.49051, 0.0012439, 0.37232, 0.0010675, 0.7825, 0.012248, 0.41396, 0.001073, 0.045921, 0.16234]
Predicted label: 4
Correct prediction
Energy consumption = 159.425335 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 307 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 307 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 307 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.03314, 0.79864, 0.53761, 0.18189, 0.067935, 0.0010678, 0.41328, 0.0064116, 0.13001, 0.045652]
Predicted label: 1
Correct prediction
Energy consumption = 170.152652 pJ
sum error= 167
Actual label: 2
Output voltages: [0.47741, 0.0056174, 0.79876, 0.10014, 0.037816, 0.0010871, 0.044675, 0.054157, 0.66678, 0.0071139]
Predicted label: 2
Correct prediction
Energy consumption = 140.562548 pJ
sum error= 167
Actual label: 8
Output voltages: [0.023745, 0.10914, 0.16477, 0.46582, 0.0053417, 0.014841, 0.012813, 0.02238, 0.79867, 0.054683]
Predicted label: 8
Correct prediction
Energy consumption = 148.834154 pJ
sum error= 167
Actual label: 1
Output voltages: [0.020919, 0.79463, 0.76581, 0.47401, 0.060706, 0.001079, 0.043715, 0.031324, 0.21474, 0.0019442]
Predicted label: 1
Correct prediction
Energy consumption = 147.772583 pJ
sum error= 167
Actual label: 3
Output voltages: [0.12077, 0.014046, 0.075374, 0.79871, 0.017089, 0.0069034, 0.0060653, 0.018458, 0.55647, 0.11383]
Predicted label: 3
Correct prediction
Energy consumption = 132.808556 pJ
sum error= 167
Actual label: 9
Output voltages: [0.5221, 0.0030406, 0.013137, 0.020259, 0.16141, 0.046607, 0.0084033, 0.040917, 0.4699, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 150.701743 pJ
sum error= 167
Actual label: 4
Output voltages: [0.0076629, 0.017863, 0.064054, 0.0043244, 0.79871, 0.003607, 0.11274, 0.058686, 0.13317, 0.020572]
Predicted label: 4
Correct prediction
Energy consumption = 148.160463 pJ
sum error= 167
Actual label: 0
Output voltages: [0.79875, 0.18654, 0.11534, 0.027115, 0.014931, 0.0096638, 0.74122, 0.0026302, 0.050603, 0.15008]
Predicted label: 0
Correct prediction
Energy consumption = 152.319084 pJ
sum error= 167
Actual label: 3
Output voltages: [0.16204, 0.039417, 0.1253, 0.79863, 0.018829, 0.00224, 0.067654, 0.069679, 0.50157, 0.1262]
Predicted label: 3
Correct prediction
Energy consumption = 153.528888 pJ
sum error= 167
Actual label: 7
Output voltages: [0.086153, 0.055295, 0.040827, 0.049204, 0.0017285, 0.0038505, 0.0010996, 0.79874, 0.52357, 0.34642]
Predicted label: 7
Correct prediction
Energy consumption = 152.063968 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 308 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 308 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 308 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23913, 0.03921, 0.16588, 0.79873, 0.023786, 0.0015, 0.0083991, 0.0078848, 0.73223, 0.024566]
Predicted label: 3
Correct prediction
Energy consumption = 147.722064 pJ
sum error= 167
Actual label: 2
Output voltages: [0.30447, 0.086898, 0.79878, 0.093176, 0.0050237, 0.0012971, 0.15055, 0.045199, 0.5004, 0.015837]
Predicted label: 2
Correct prediction
Energy consumption = 138.391773 pJ
sum error= 167
Actual label: 3
Output voltages: [0.73373, 0.015775, 0.24662, 0.79866, 0.018616, 0.023714, 0.009443, 0.034864, 0.58388, 0.020263]
Predicted label: 3
Correct prediction
Energy consumption = 145.148295 pJ
sum error= 167
Actual label: 3
Output voltages: [0.2333, 0.060973, 0.017375, 0.79868, 0.084118, 0.049535, 0.22412, 0.03013, 0.36632, 0.020652]
Predicted label: 3
Correct prediction
Energy consumption = 139.276630 pJ
sum error= 167
Actual label: 7
Output voltages: [0.11088, 0.032291, 0.028887, 0.026581, 0.02492, 0.011072, 0.0014873, 0.79866, 0.045654, 0.60909]
Predicted label: 7
Correct prediction
Energy consumption = 157.094277 pJ
sum error= 167
Actual label: 3
Output voltages: [0.14219, 0.013247, 0.50165, 0.79871, 0.029948, 0.0021469, 0.0090938, 0.0010805, 0.58142, 0.05231]
Predicted label: 3
Correct prediction
Energy consumption = 150.802046 pJ
sum error= 167
Actual label: 4
Output voltages: [0.0030027, 0.0067, 0.15511, 0.0089273, 0.79879, 0.0011654, 0.013059, 0.03426, 0.61394, 0.015803]
Predicted label: 4
Correct prediction
Energy consumption = 158.496160 pJ
sum error= 167
Actual label: 0
Output voltages: [0.79879, 0.036958, 0.038428, 0.034119, 0.023448, 0.0048589, 0.68918, 0.011047, 0.051557, 0.20789]
Predicted label: 0
Correct prediction
Energy consumption = 160.001897 pJ
sum error= 167
Actual label: 6
Output voltages: [0.03625, 0.03238, 0.13552, 0.0037984, 0.049062, 0.18899, 0.79876, 0.015939, 0.56335, 0.0051273]
Predicted label: 6
Correct prediction
Energy consumption = 149.386840 pJ
sum error= 167
Actual label: 2
Output voltages: [0.34681, 0.1059, 0.79879, 0.039246, 0.0058905, 0.0013204, 0.21616, 0.020653, 0.62303, 0.030957]
Predicted label: 2
Correct prediction
Energy consumption = 149.405546 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 309 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 309 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 309 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.026285, 0.036243, 0.0098348, 0.066629, 0.0028948, 0.56149, 0.012997, 0.062464, 0.065916]
Predicted label: 0
Correct prediction
Energy consumption = 163.986004 pJ
sum error= 167
Actual label: 8
Output voltages: [0.70046, 0.021757, 0.18927, 0.55635, 0.0065412, 0.017886, 0.020686, 0.0011017, 0.79743, 0.4755]
Predicted label: 8
Correct prediction
Energy consumption = 151.625075 pJ
sum error= 167
Actual label: 1
Output voltages: [0.090147, 0.79876, 0.44313, 0.080798, 0.38223, 0.0017024, 0.22987, 0.011617, 0.036514, 0.035653]
Predicted label: 1
Correct prediction
Energy consumption = 166.668756 pJ
sum error= 167
Actual label: 5
Output voltages: [0.019875, 0.001067, 0.0015369, 0.34674, 0.011508, 0.78142, 0.15077, 0.016938, 0.73193, 0.083896]
Predicted label: 5
Correct prediction
Energy consumption = 151.661049 pJ
sum error= 167
Actual label: 3
Output voltages: [0.31281, 0.036934, 0.036448, 0.79868, 0.0090724, 0.010377, 0.01313, 0.0099922, 0.47286, 0.10111]
Predicted label: 3
Correct prediction
Energy consumption = 143.219181 pJ
sum error= 167
Actual label: 5
Output voltages: [0.17888, 0.0018442, 0.0067512, 0.23701, 0.022111, 0.79879, 0.37564, 0.031283, 0.5649, 0.010065]
Predicted label: 5
Correct prediction
Energy consumption = 144.192829 pJ
sum error= 167
Actual label: 4
Output voltages: [0.01976, 0.0024471, 0.17343, 0.0039132, 0.79862, 0.0070326, 0.29957, 0.14762, 0.056416, 0.0049673]
Predicted label: 4
Correct prediction
Energy consumption = 151.356776 pJ
sum error= 167
Actual label: 1
Output voltages: [0.29857, 0.79875, 0.0018546, 0.015239, 0.74037, 0.0048088, 0.11808, 0.0012305, 0.44515, 0.19871]
Predicted label: 1
Correct prediction
Energy consumption = 155.828482 pJ
sum error= 167
Actual label: 7
Output voltages: [0.13496, 0.1369, 0.01229, 0.012237, 0.014738, 0.0052101, 0.0015974, 0.79869, 0.13827, 0.34919]
Predicted label: 7
Correct prediction
Energy consumption = 154.702348 pJ
sum error= 167
Actual label: 1
Output voltages: [0.017151, 0.79872, 0.45217, 0.044852, 0.041717, 0.0018189, 0.77318, 0.0029179, 0.22332, 0.013707]
Predicted label: 1
Correct prediction
Energy consumption = 153.438886 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 310 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 310 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 310 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.034165, 0.0020489, 0.0046759, 0.78839, 0.0046011, 0.79155, 0.042355, 0.037116, 0.69912, 0.0084265]
Predicted label: 5
Correct prediction
Energy consumption = 144.782516 pJ
sum error= 167
Actual label: 7
Output voltages: [0.43213, 0.011962, 0.034423, 0.036549, 0.032969, 0.015573, 0.001091, 0.79849, 0.30518, 0.24515]
Predicted label: 7
Correct prediction
Energy consumption = 149.882354 pJ
sum error= 167
Actual label: 5
Output voltages: [0.0028344, 0.02385, 0.0033089, 0.48484, 0.01451, 0.79874, 0.060678, 0.2208, 0.41893, 0.2935]
Predicted label: 5
Correct prediction
Energy consumption = 142.534647 pJ
sum error= 167
Actual label: 7
Output voltages: [0.033031, 0.40798, 0.28126, 0.12967, 0.075206, 0.0011174, 0.0010722, 0.79823, 0.021489, 0.33687]
Predicted label: 7
Correct prediction
Energy consumption = 153.355459 pJ
sum error= 167
Actual label: 3
Output voltages: [0.48402, 0.055706, 0.071246, 0.79863, 0.052306, 0.0028072, 0.024062, 0.025722, 0.56922, 0.040627]
Predicted label: 3
Correct prediction
Energy consumption = 150.304042 pJ
sum error= 167
Actual label: 2
Output voltages: [0.77796, 0.003173, 0.79814, 0.43144, 0.01348, 0.001153, 0.023895, 0.031489, 0.75205, 0.01317]
Predicted label: 2
Correct prediction
Energy consumption = 140.504717 pJ
sum error= 167
Actual label: 2
Output voltages: [0.74666, 0.038601, 0.78612, 0.26414, 0.0072178, 0.0011194, 0.51897, 0.0060165, 0.55329, 0.0076661]
Predicted label: 2
Correct prediction
Energy consumption = 138.576617 pJ
sum error= 167
Actual label: 7
Output voltages: [0.22168, 0.014171, 0.0021022, 0.038542, 0.10767, 0.16249, 0.0014935, 0.79873, 0.54649, 0.55328]
Predicted label: 7
Correct prediction
Energy consumption = 159.356780 pJ
sum error= 167
Actual label: 3
Output voltages: [0.37171, 0.032573, 0.061323, 0.79878, 0.0071443, 0.055212, 0.015466, 0.014387, 0.40062, 0.048098]
Predicted label: 3
Correct prediction
Energy consumption = 148.493923 pJ
sum error= 167
Actual label: 7
Output voltages: [0.21508, 0.74492, 0.27727, 0.34133, 0.0018781, 0.0013943, 0.0067026, 0.78189, 0.07263, 0.11438]
Predicted label: 7
Correct prediction
Energy consumption = 155.491078 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 311 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 311 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 311 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.71979, 0.0015581, 0.1187, 0.79878, 0.0012654, 0.039147, 0.062717, 0.13773, 0.38484, 0.0012106]
Predicted label: 3
Correct prediction
Energy consumption = 145.885881 pJ
sum error= 167
Actual label: 7
Output voltages: [0.048857, 0.40372, 0.18681, 0.0049806, 0.047322, 0.0010845, 0.0019828, 0.79877, 0.016629, 0.41701]
Predicted label: 7
Correct prediction
Energy consumption = 146.713986 pJ
sum error= 167
Actual label: 8
Output voltages: [0.22933, 0.0013637, 0.63483, 0.37771, 0.016974, 0.030545, 0.032033, 0.0075096, 0.79879, 0.1632]
Predicted label: 8
Correct prediction
Energy consumption = 155.082471 pJ
sum error= 167
Actual label: 5
Output voltages: [0.035691, 0.0011352, 0.0018144, 0.044858, 0.053659, 0.79855, 0.048464, 0.036808, 0.78348, 0.036558]
Predicted label: 5
Correct prediction
Energy consumption = 139.951906 pJ
sum error= 167
Actual label: 4
Output voltages: [0.020619, 0.044925, 0.52189, 0.062173, 0.79877, 0.0017666, 0.76648, 0.035977, 0.0010827, 0.030399]
Predicted label: 4
Correct prediction
Energy consumption = 156.606144 pJ
sum error= 167
Actual label: 5
Output voltages: [0.1112, 0.0011322, 0.0010659, 0.016737, 0.11278, 0.79874, 0.0071011, 0.24221, 0.63801, 0.11104]
Predicted label: 5
Correct prediction
Energy consumption = 141.148805 pJ
sum error= 167
Actual label: 2
Output voltages: [0.46311, 0.061912, 0.79867, 0.043929, 0.03422, 0.0012418, 0.3403, 0.027009, 0.39795, 0.045394]
Predicted label: 2
Correct prediction
Energy consumption = 146.098218 pJ
sum error= 167
Actual label: 5
Output voltages: [0.046788, 0.0035195, 0.0011699, 0.34106, 0.66204, 0.66784, 0.052699, 0.0038219, 0.037778, 0.5657]
Predicted label: 5
Correct prediction
Energy consumption = 146.406173 pJ
sum error= 167
Actual label: 6
Output voltages: [0.34656, 0.14293, 0.038376, 0.0047268, 0.25725, 0.67207, 0.79874, 0.0092558, 0.23303, 0.013801]
Predicted label: 6
Correct prediction
Energy consumption = 147.198268 pJ
sum error= 167
Actual label: 5
Output voltages: [0.025074, 0.0044432, 0.018731, 0.30378, 0.041094, 0.7966, 0.038502, 0.0043711, 0.77822, 0.23187]
Predicted label: 5
Correct prediction
Energy consumption = 141.376914 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 312 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 312 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 312 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.40369, 0.020455, 0.20595, 0.79876, 0.0078755, 0.0045934, 0.038739, 0.0022414, 0.60909, 0.03473]
Predicted label: 3
Correct prediction
Energy consumption = 146.555607 pJ
sum error= 167
Actual label: 6
Output voltages: [0.069861, 0.046787, 0.39933, 0.0010795, 0.27497, 0.023289, 0.79879, 0.017387, 0.18523, 0.0010958]
Predicted label: 6
Correct prediction
Energy consumption = 150.062795 pJ
sum error= 167
Actual label: 7
Output voltages: [0.038702, 0.020787, 0.67289, 0.059567, 0.040878, 0.0012497, 0.020621, 0.79871, 0.03195, 0.042254]
Predicted label: 7
Correct prediction
Energy consumption = 138.746563 pJ
sum error= 167
Actual label: 4
Output voltages: [0.013268, 0.024518, 0.07156, 0.0035312, 0.7986, 0.0017902, 0.069528, 0.012112, 0.036586, 0.1286]
Predicted label: 4
Correct prediction
Energy consumption = 159.912765 pJ
sum error= 167
Actual label: 1
Output voltages: [0.043899, 0.79858, 0.012828, 0.045357, 0.058153, 0.0012541, 0.63425, 0.012227, 0.052349, 0.13132]
Predicted label: 1
Correct prediction
Energy consumption = 161.723612 pJ
sum error= 167
Actual label: 7
Output voltages: [0.071525, 0.049616, 0.55281, 0.20158, 0.013863, 0.0011045, 0.001066, 0.79865, 0.24739, 0.29022]
Predicted label: 7
Correct prediction
Energy consumption = 152.033721 pJ
sum error= 167
Actual label: 1
Output voltages: [0.049569, 0.79849, 0.079402, 0.04918, 0.05477, 0.0021842, 0.69089, 0.0086732, 0.10688, 0.070474]
Predicted label: 1
Correct prediction
Energy consumption = 164.267183 pJ
sum error= 167
Actual label: 5
Output voltages: [0.091441, 0.0010836, 0.0037042, 0.32797, 0.018645, 0.79879, 0.068216, 0.21025, 0.78441, 0.073952]
Predicted label: 5
Correct prediction
Energy consumption = 154.501007 pJ
sum error= 167
Actual label: 2
Output voltages: [0.31366, 0.25953, 0.79879, 0.3626, 0.0060921, 0.0013208, 0.29519, 0.0069886, 0.25733, 0.023348]
Predicted label: 2
Correct prediction
Energy consumption = 150.076648 pJ
sum error= 167
Actual label: 3
Output voltages: [0.33558, 0.0027612, 0.5871, 0.79834, 0.0033693, 0.0010915, 0.018207, 0.0090592, 0.62467, 0.02056]
Predicted label: 3
Correct prediction
Energy consumption = 139.573546 pJ
sum error= 167
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 313 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 313 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 313 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.75075, 0.14631, 0.0039262, 0.044666, 0.0032282, 0.73666, 0.76954, 0.015867, 0.33818, 0.001365]
Predicted label: 6
Correct prediction
Energy consumption = 154.266388 pJ
sum error= 167
Actual label: 3
Output voltages: [0.034162, 0.0034303, 0.032387, 0.79868, 0.11168, 0.20372, 0.3033, 0.02155, 0.56506, 0.080118]
Predicted label: 3
Correct prediction
Energy consumption = 147.697099 pJ
sum error= 167
Actual label: 1
Output voltages: [0.064663, 0.77069, 0.75861, 0.39923, 0.0010974, 0.0010962, 0.3179, 0.012728, 0.36958, 0.0011702]
Predicted label: 1
Correct prediction
Energy consumption = 147.011498 pJ
sum error= 167
Actual label: 4
Output voltages: [0.0011766, 0.024543, 0.0056987, 0.0020667, 0.79536, 0.028872, 0.21973, 0.12273, 0.55071, 0.039344]
Predicted label: 4
Correct prediction
Energy consumption = 148.336643 pJ
sum error= 167
Actual label: 2
Output voltages: [0.53418, 0.0025189, 0.79879, 0.044198, 0.027942, 0.0010732, 0.050199, 0.037503, 0.509, 0.0065421]
Predicted label: 2
Correct prediction
Energy consumption = 145.808390 pJ
sum error= 167
Actual label: 6
Output voltages: [0.073437, 0.17741, 0.039418, 0.010701, 0.20617, 0.51839, 0.79874, 0.0034845, 0.44152, 0.0030671]
Predicted label: 6
Correct prediction
Energy consumption = 147.207242 pJ
sum error= 167
Actual label: 7
Output voltages: [0.029095, 0.001066, 0.0077639, 0.061232, 0.69147, 0.0188, 0.0010923, 0.68489, 0.72294, 0.043462]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.987171 pJ
sum error= 168
Actual label: 4
Output voltages: [0.0048862, 0.01066, 0.040974, 0.0012876, 0.79868, 0.0011726, 0.30168, 0.20469, 0.036384, 0.033873]
Predicted label: 4
Correct prediction
Energy consumption = 145.612979 pJ
sum error= 168
Actual label: 3
Output voltages: [0.71538, 0.16361, 0.065565, 0.7968, 0.0054973, 0.44395, 0.04055, 0.11646, 0.10785, 0.0011006]
Predicted label: 3
Correct prediction
Energy consumption = 153.174836 pJ
sum error= 168
Actual label: 8
Output voltages: [0.040345, 0.015306, 0.26549, 0.32842, 0.012749, 0.011808, 0.15213, 0.005083, 0.79878, 0.047868]
Predicted label: 8
Correct prediction
Energy consumption = 154.615723 pJ
sum error= 168
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 314 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 314 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 314 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79316, 0.13224, 0.17214, 0.039506, 0.0055406, 0.0016049, 0.52461, 0.021578, 0.52435, 0.019344]
Predicted label: 0
Correct prediction
Energy consumption = 159.752163 pJ
sum error= 168
Actual label: 6
Output voltages: [0.30262, 0.072287, 0.072504, 0.025669, 0.096404, 0.64365, 0.79876, 0.0030258, 0.47574, 0.071166]
Predicted label: 6
Correct prediction
Energy consumption = 150.767993 pJ
sum error= 168
Actual label: 2
Output voltages: [0.64897, 0.066235, 0.79873, 0.14685, 0.0060635, 0.001137, 0.35363, 0.069634, 0.76455, 0.032406]
Predicted label: 2
Correct prediction
Energy consumption = 143.595476 pJ
sum error= 168
Actual label: 1
Output voltages: [0.0098699, 0.79845, 0.092472, 0.59003, 0.0019141, 0.0013441, 0.027221, 0.040173, 0.066272, 0.18781]
Predicted label: 1
Correct prediction
Energy consumption = 159.559761 pJ
sum error= 168
Actual label: 6
Output voltages: [0.045849, 0.038543, 0.32117, 0.0011725, 0.19829, 0.061365, 0.79879, 0.0014001, 0.70716, 0.01393]
Predicted label: 6
Correct prediction
Energy consumption = 143.849341 pJ
sum error= 168
Actual label: 5
Output voltages: [0.012737, 0.0011131, 0.019848, 0.12877, 0.1987, 0.79744, 0.043176, 0.020938, 0.78486, 0.23897]
Predicted label: 5
Correct prediction
Energy consumption = 149.721728 pJ
sum error= 168
Actual label: 3
Output voltages: [0.072736, 0.031097, 0.060258, 0.79874, 0.012709, 0.0092041, 0.013089, 0.052949, 0.75045, 0.052643]
Predicted label: 3
Correct prediction
Energy consumption = 140.210653 pJ
sum error= 168
Actual label: 9
Output voltages: [0.33069, 0.022462, 0.0083624, 0.33371, 0.38421, 0.1044, 0.034267, 0.0022875, 0.16277, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 142.505177 pJ
sum error= 168
Actual label: 1
Output voltages: [0.056757, 0.79835, 0.076376, 0.044538, 0.04173, 0.006128, 0.48624, 0.0039853, 0.045241, 0.13408]
Predicted label: 1
Correct prediction
Energy consumption = 165.027587 pJ
sum error= 168
Actual label: 9
Output voltages: [0.49101, 0.008408, 0.0093109, 0.052758, 0.26464, 0.02283, 0.002033, 0.0088773, 0.30547, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 156.637036 pJ
sum error= 168
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 315 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 315 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 315 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.027948, 0.02043, 0.05679, 0.79872, 0.023885, 0.01813, 0.0082413, 0.029784, 0.67837, 0.023055]
Predicted label: 3
Correct prediction
Energy consumption = 146.155157 pJ
sum error= 168
Actual label: 2
Output voltages: [0.091007, 0.26385, 0.7985, 0.08469, 0.0045876, 0.0013987, 0.33739, 0.019012, 0.50054, 0.019511]
Predicted label: 2
Correct prediction
Energy consumption = 143.071022 pJ
sum error= 168
Actual label: 1
Output voltages: [0.0022259, 0.79858, 0.1013, 0.055934, 0.053054, 0.0010787, 0.37955, 0.006829, 0.29013, 0.026867]
Predicted label: 1
Correct prediction
Energy consumption = 159.004348 pJ
sum error= 168
Actual label: 8
Output voltages: [0.19749, 0.003193, 0.53118, 0.58095, 0.0025405, 0.0078003, 0.0050052, 0.011167, 0.79687, 0.2711]
Predicted label: 8
Correct prediction
Energy consumption = 156.151699 pJ
sum error= 168
Actual label: 4
Output voltages: [0.070076, 0.0069215, 0.20103, 0.0013143, 0.79874, 0.0037309, 0.28482, 0.28999, 0.008639, 0.06976]
Predicted label: 4
Correct prediction
Energy consumption = 155.748846 pJ
sum error= 168
Actual label: 4
Output voltages: [0.0031816, 0.012499, 0.03035, 0.023522, 0.79879, 0.0011241, 0.038125, 0.034729, 0.041338, 0.036437]
Predicted label: 4
Correct prediction
Energy consumption = 154.594604 pJ
sum error= 168
Actual label: 6
Output voltages: [0.051831, 0.03197, 0.40029, 0.0010694, 0.1474, 0.064647, 0.79879, 0.0035864, 0.56798, 0.0090858]
Predicted label: 6
Correct prediction
Energy consumption = 149.695178 pJ
sum error= 168
Actual label: 5
Output voltages: [0.41521, 0.014232, 0.0010687, 0.58703, 0.02189, 0.79879, 0.011044, 0.11265, 0.46511, 0.0066999]
Predicted label: 5
Correct prediction
Energy consumption = 150.962814 pJ
sum error= 168
Actual label: 8
Output voltages: [0.30059, 0.0087451, 0.34788, 0.27291, 0.013421, 0.0045609, 0.036459, 0.0010799, 0.79837, 0.46952]
Predicted label: 8
Correct prediction
Energy consumption = 151.102507 pJ
sum error= 168
Actual label: 6
Output voltages: [0.04258, 0.039446, 0.048748, 0.005064, 0.24738, 0.10238, 0.79877, 0.0033256, 0.75853, 0.0062784]
Predicted label: 6
Correct prediction
Energy consumption = 147.371909 pJ
sum error= 168
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 316 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 316 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 316 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.063441, 0.028683, 0.0022239, 0.1367, 0.65727, 0.2194, 0.059793, 0.0061387, 0.056151, 0.77567]
Predicted label: 9
Correct prediction
Energy consumption = 159.511381 pJ
sum error= 168
Actual label: 7
Output voltages: [0.29762, 0.39199, 0.55372, 0.014609, 0.0025144, 0.0011099, 0.00125, 0.79878, 0.11834, 0.068867]
Predicted label: 7
Correct prediction
Energy consumption = 156.569250 pJ
sum error= 168
Actual label: 7
Output voltages: [0.17018, 0.1441, 0.17421, 0.015029, 0.0015038, 0.001072, 0.0010889, 0.79875, 0.69611, 0.14321]
Predicted label: 7
Correct prediction
Energy consumption = 143.726775 pJ
sum error= 168
Actual label: 8
Output voltages: [0.0034369, 0.027668, 0.037516, 0.27946, 0.011037, 0.014351, 0.034239, 0.0072011, 0.79875, 0.24276]
Predicted label: 8
Correct prediction
Energy consumption = 147.506910 pJ
sum error= 168
Actual label: 6
Output voltages: [0.22961, 0.0095364, 0.32258, 0.0013413, 0.19087, 0.20024, 0.79867, 0.0031343, 0.37478, 0.0033175]
Predicted label: 6
Correct prediction
Energy consumption = 144.733135 pJ
sum error= 168
Actual label: 9
Output voltages: [0.28422, 0.050381, 0.047001, 0.11142, 0.048582, 0.10728, 0.0075419, 0.033113, 0.41286, 0.79828]
Predicted label: 9
Correct prediction
Energy consumption = 155.945869 pJ
sum error= 168
Actual label: 7
Output voltages: [0.021999, 0.18378, 0.78606, 0.43998, 0.02243, 0.0011842, 0.0078126, 0.75069, 0.74432, 0.012987]
Predicted label: 2
Wrong prediction!
Energy consumption = 147.212573 pJ
sum error= 169
Actual label: 3
Output voltages: [0.32983, 0.40262, 0.051542, 0.79857, 0.012306, 0.1822, 0.0049469, 0.034671, 0.35567, 0.0274]
Predicted label: 3
Correct prediction
Energy consumption = 152.046794 pJ
sum error= 169
Actual label: 9
Output voltages: [0.20598, 0.011263, 0.042239, 0.030204, 0.062728, 0.013389, 0.017993, 0.028858, 0.56693, 0.79829]
Predicted label: 9
Correct prediction
Energy consumption = 158.193469 pJ
sum error= 169
Actual label: 4
Output voltages: [0.0085308, 0.0049131, 0.35392, 0.0030094, 0.7987, 0.0013209, 0.27871, 0.032633, 0.032518, 0.027141]
Predicted label: 4
Correct prediction
Energy consumption = 152.606063 pJ
sum error= 169
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 317 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 317 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 317 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.095906, 0.045686, 0.0012842, 0.0054893, 0.027332, 0.30332, 0.020916, 0.28737, 0.055702]
Predicted label: 0
Correct prediction
Energy consumption = 157.082845 pJ
sum error= 169
Actual label: 5
Output voltages: [0.065816, 0.0011193, 0.021431, 0.75203, 0.0090295, 0.39075, 0.0075917, 0.013571, 0.78764, 0.03016]
Predicted label: 8
Wrong prediction!
Energy consumption = 154.534697 pJ
sum error= 170
Actual label: 4
Output voltages: [0.011834, 0.0070435, 0.37128, 0.04759, 0.7987, 0.013563, 0.029129, 0.0053333, 0.084688, 0.20924]
Predicted label: 4
Correct prediction
Energy consumption = 153.861825 pJ
sum error= 170
Actual label: 6
Output voltages: [0.12909, 0.22825, 0.4106, 0.007168, 0.65949, 0.44912, 0.79868, 0.0010661, 0.036091, 0.0012571]
Predicted label: 6
Correct prediction
Energy consumption = 150.341339 pJ
sum error= 170
Actual label: 4
Output voltages: [0.0038185, 0.012994, 0.20709, 0.015359, 0.79856, 0.0071692, 0.25128, 0.046746, 0.03491, 0.031668]
Predicted label: 4
Correct prediction
Energy consumption = 155.969246 pJ
sum error= 170
Actual label: 1
Output voltages: [0.044109, 0.79844, 0.038211, 0.27355, 0.011314, 0.0028329, 0.36462, 0.03214, 0.15553, 0.18931]
Predicted label: 1
Correct prediction
Energy consumption = 169.346095 pJ
sum error= 170
Actual label: 2
Output voltages: [0.52301, 0.06227, 0.79602, 0.10532, 0.027942, 0.0013099, 0.10151, 0.59438, 0.24479, 0.021545]
Predicted label: 2
Correct prediction
Energy consumption = 149.172158 pJ
sum error= 170
Actual label: 3
Output voltages: [0.36884, 0.18407, 0.095772, 0.79858, 0.045198, 0.0063227, 0.032292, 0.18646, 0.45231, 0.027404]
Predicted label: 3
Correct prediction
Energy consumption = 141.182896 pJ
sum error= 170
Actual label: 0
Output voltages: [0.75691, 0.0010671, 0.34965, 0.027055, 0.0088742, 0.25213, 0.55954, 0.0010661, 0.31211, 0.088367]
Predicted label: 0
Correct prediction
Energy consumption = 160.904305 pJ
sum error= 170
Actual label: 0
Output voltages: [0.79879, 0.02915, 0.015265, 0.0045846, 0.0091676, 0.020089, 0.4782, 0.0023092, 0.048882, 0.027994]
Predicted label: 0
Correct prediction
Energy consumption = 146.129002 pJ
sum error= 170
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 318 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 318 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 318 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.4419, 0.19466, 0.79878, 0.258, 0.013085, 0.0013215, 0.28998, 0.0073247, 0.28623, 0.022311]
Predicted label: 2
Correct prediction
Energy consumption = 151.097918 pJ
sum error= 170
Actual label: 6
Output voltages: [0.45074, 0.03401, 0.035318, 0.0031082, 0.18641, 0.3256, 0.79879, 0.0030857, 0.37901, 0.00906]
Predicted label: 6
Correct prediction
Energy consumption = 143.392543 pJ
sum error= 170
Actual label: 6
Output voltages: [0.38952, 0.0063246, 0.43154, 0.0010772, 0.47522, 0.043191, 0.79879, 0.0033712, 0.31443, 0.0082144]
Predicted label: 6
Correct prediction
Energy consumption = 132.668271 pJ
sum error= 170
Actual label: 5
Output voltages: [0.039717, 0.0012525, 0.00107, 0.51804, 0.038376, 0.79869, 0.66581, 0.015379, 0.77489, 0.013212]
Predicted label: 5
Correct prediction
Energy consumption = 148.008168 pJ
sum error= 170
Actual label: 7
Output voltages: [0.045494, 0.013136, 0.10159, 0.039272, 0.019626, 0.0010693, 0.0014111, 0.79854, 0.22865, 0.054365]
Predicted label: 7
Correct prediction
Energy consumption = 150.004659 pJ
sum error= 170
Actual label: 0
Output voltages: [0.79855, 0.093621, 0.030171, 0.02774, 0.046315, 0.004384, 0.75962, 0.0092898, 0.19973, 0.043966]
Predicted label: 0
Correct prediction
Energy consumption = 158.861160 pJ
sum error= 170
Actual label: 8
Output voltages: [0.361, 0.0094309, 0.49154, 0.41958, 0.015471, 0.0010734, 0.031315, 0.0017595, 0.79476, 0.46461]
Predicted label: 8
Correct prediction
Energy consumption = 157.131868 pJ
sum error= 170
Actual label: 6
Output voltages: [0.11492, 0.14873, 0.032028, 0.022381, 0.27957, 0.46389, 0.79869, 0.0030374, 0.39655, 0.031032]
Predicted label: 6
Correct prediction
Energy consumption = 152.867420 pJ
sum error= 170
Actual label: 4
Output voltages: [0.0011871, 0.013689, 0.52243, 0.036494, 0.79875, 0.0011181, 0.42362, 0.52845, 0.0034358, 0.085489]
Predicted label: 4
Correct prediction
Energy consumption = 150.757625 pJ
sum error= 170
Actual label: 7
Output voltages: [0.11668, 0.0015372, 0.054195, 0.04016, 0.017193, 0.0080792, 0.022595, 0.79866, 0.1229, 0.0028852]
Predicted label: 7
Correct prediction
Energy consumption = 133.981911 pJ
sum error= 170
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 319 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 319 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 319 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.43941, 0.025704, 0.022773, 0.31125, 0.21938, 0.015317, 0.011098, 0.014284, 0.16415, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 155.280880 pJ
sum error= 170
Actual label: 0
Output voltages: [0.79877, 0.060266, 0.027437, 0.15347, 0.039443, 0.01884, 0.45034, 0.036445, 0.16538, 0.012855]
Predicted label: 0
Correct prediction
Energy consumption = 161.450281 pJ
sum error= 170
Actual label: 7
Output voltages: [0.33478, 0.18847, 0.55436, 0.45203, 0.001093, 0.0011348, 0.0012278, 0.79817, 0.35101, 0.53142]
Predicted label: 7
Correct prediction
Energy consumption = 160.471067 pJ
sum error= 170
Actual label: 3
Output voltages: [0.38087, 0.01474, 0.56871, 0.79879, 0.013548, 0.0022765, 0.0021636, 0.0074999, 0.58974, 0.014915]
Predicted label: 3
Correct prediction
Energy consumption = 141.618032 pJ
sum error= 170
Actual label: 4
Output voltages: [0.0024989, 0.033295, 0.01381, 0.0088623, 0.79877, 0.0014072, 0.033353, 0.69797, 0.068033, 0.0013687]
Predicted label: 4
Correct prediction
Energy consumption = 150.129918 pJ
sum error= 170
Actual label: 2
Output voltages: [0.67577, 0.031372, 0.79876, 0.20328, 0.024041, 0.0011683, 0.30326, 0.042443, 0.66022, 0.03224]
Predicted label: 2
Correct prediction
Energy consumption = 151.800926 pJ
sum error= 170
Actual label: 1
Output voltages: [0.010026, 0.79879, 0.011717, 0.011794, 0.1104, 0.011324, 0.39777, 0.006128, 0.66304, 0.14846]
Predicted label: 1
Correct prediction
Energy consumption = 155.727800 pJ
sum error= 170
Actual label: 8
Output voltages: [0.030039, 0.037591, 0.25602, 0.015349, 0.070536, 0.0084123, 0.012829, 0.0083483, 0.79872, 0.10391]
Predicted label: 8
Correct prediction
Energy consumption = 144.298088 pJ
sum error= 170
Actual label: 8
Output voltages: [0.023854, 0.0065473, 0.18932, 0.10307, 0.0051325, 0.28308, 0.097435, 0.022089, 0.79875, 0.14954]
Predicted label: 8
Correct prediction
Energy consumption = 145.967427 pJ
sum error= 170
Actual label: 5
Output voltages: [0.021683, 0.001111, 0.0047952, 0.031216, 0.24839, 0.79867, 0.35105, 0.031251, 0.79683, 0.02741]
Predicted label: 5
Correct prediction
Energy consumption = 135.111278 pJ
sum error= 170
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 320 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 320 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 320 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.018665, 0.019182, 0.034931, 0.40498, 0.040785, 0.029317, 0.31434, 0.024901, 0.31889, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 152.689039 pJ
sum error= 170
Actual label: 2
Output voltages: [0.20564, 0.020565, 0.79878, 0.20648, 0.0057361, 0.0010724, 0.16941, 0.028897, 0.51828, 0.0088571]
Predicted label: 2
Correct prediction
Energy consumption = 150.901423 pJ
sum error= 170
Actual label: 7
Output voltages: [0.01235, 0.013284, 0.10121, 0.10201, 0.045655, 0.0018217, 0.0010764, 0.79874, 0.77296, 0.0090477]
Predicted label: 7
Correct prediction
Energy consumption = 141.550362 pJ
sum error= 170
Actual label: 1
Output voltages: [0.022428, 0.79848, 0.24897, 0.070667, 0.014163, 0.0011446, 0.30953, 0.0039684, 0.31963, 0.034903]
Predicted label: 1
Correct prediction
Energy consumption = 162.652779 pJ
sum error= 170
Actual label: 8
Output voltages: [0.03956, 0.039413, 0.13533, 0.095577, 0.0032688, 0.023297, 0.014488, 0.010868, 0.79869, 0.62581]
Predicted label: 8
Correct prediction
Energy consumption = 153.066819 pJ
sum error= 170
Actual label: 8
Output voltages: [0.31941, 0.01415, 0.010048, 0.35976, 0.0013439, 0.59559, 0.24511, 0.0026937, 0.79878, 0.017661]
Predicted label: 8
Correct prediction
Energy consumption = 150.595587 pJ
sum error= 170
Actual label: 8
Output voltages: [0.27555, 0.017046, 0.35806, 0.79831, 0.019453, 0.0014533, 0.0095887, 0.0054868, 0.79547, 0.0064946]
Predicted label: 3
Wrong prediction!
Energy consumption = 143.768287 pJ
sum error= 171
Actual label: 2
Output voltages: [0.56651, 0.0062782, 0.7973, 0.21756, 0.0091696, 0.0011753, 0.012071, 0.053161, 0.76337, 0.03254]
Predicted label: 2
Correct prediction
Energy consumption = 137.474339 pJ
sum error= 171
Actual label: 7
Output voltages: [0.069253, 0.0084746, 0.024771, 0.774, 0.0064763, 0.0089232, 0.0011202, 0.79635, 0.06497, 0.67418]
Predicted label: 7
Correct prediction
Energy consumption = 148.884282 pJ
sum error= 171
Actual label: 6
Output voltages: [0.056778, 0.046565, 0.034584, 0.017416, 0.15839, 0.34164, 0.79879, 0.0077623, 0.74717, 0.026051]
Predicted label: 6
Correct prediction
Energy consumption = 156.388714 pJ
sum error= 171
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 321 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 321 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 321 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79806, 0.024313, 0.31786, 0.025521, 0.017133, 0.0015086, 0.44428, 0.044624, 0.21292, 0.032306]
Predicted label: 0
Correct prediction
Energy consumption = 157.150624 pJ
sum error= 171
Actual label: 1
Output voltages: [0.045679, 0.79834, 0.17969, 0.054708, 0.3473, 0.001066, 0.55976, 0.001105, 0.060171, 0.033247]
Predicted label: 1
Correct prediction
Energy consumption = 152.726288 pJ
sum error= 171
Actual label: 2
Output voltages: [0.13349, 0.011324, 0.79874, 0.091958, 0.0052354, 0.0011868, 0.048149, 0.38213, 0.57721, 0.0076013]
Predicted label: 2
Correct prediction
Energy consumption = 142.139141 pJ
sum error= 171
Actual label: 7
Output voltages: [0.11076, 0.23704, 0.46984, 0.028416, 0.033794, 0.0012566, 0.0010665, 0.79864, 0.040387, 0.068127]
Predicted label: 7
Correct prediction
Energy consumption = 148.101226 pJ
sum error= 171
Actual label: 1
Output voltages: [0.010434, 0.79879, 0.54131, 0.0069214, 0.22321, 0.0010884, 0.42279, 0.0063237, 0.25179, 0.01421]
Predicted label: 1
Correct prediction
Energy consumption = 147.456595 pJ
sum error= 171
Actual label: 0
Output voltages: [0.79875, 0.042903, 0.054817, 0.0087207, 0.012397, 0.0043104, 0.62777, 0.007979, 0.047578, 0.049421]
Predicted label: 0
Correct prediction
Energy consumption = 151.163020 pJ
sum error= 171
Actual label: 8
Output voltages: [0.010912, 0.028915, 0.043467, 0.75896, 0.0013294, 0.07611, 0.0049339, 0.02175, 0.79879, 0.071882]
Predicted label: 8
Correct prediction
Energy consumption = 151.790594 pJ
sum error= 171
Actual label: 3
Output voltages: [0.66103, 0.010064, 0.2791, 0.7987, 0.022929, 0.0019509, 0.019575, 0.011661, 0.41265, 0.015912]
Predicted label: 3
Correct prediction
Energy consumption = 136.319242 pJ
sum error= 171
Actual label: 6
Output voltages: [0.26503, 0.0011254, 0.0015504, 0.011338, 0.037136, 0.79139, 0.76529, 0.001964, 0.78379, 0.016922]
Predicted label: 5
Wrong prediction!
Energy consumption = 143.205723 pJ
sum error= 172
Actual label: 0
Output voltages: [0.79836, 0.029112, 0.016189, 0.015469, 0.18266, 0.0059959, 0.66934, 0.0048099, 0.1872, 0.026211]
Predicted label: 0
Correct prediction
Energy consumption = 149.032591 pJ
sum error= 172
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 322 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 322 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 322 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.14181, 0.016452, 0.0019146, 0.73873, 0.022816, 0.79879, 0.0080183, 0.0023412, 0.76999, 0.052949]
Predicted label: 5
Correct prediction
Energy consumption = 147.591699 pJ
sum error= 172
Actual label: 3
Output voltages: [0.1656, 0.041827, 0.03607, 0.79865, 0.033453, 0.0041576, 0.011466, 0.035473, 0.62083, 0.033085]
Predicted label: 3
Correct prediction
Energy consumption = 142.900600 pJ
sum error= 172
Actual label: 6
Output voltages: [0.049217, 0.0052344, 0.25487, 0.061371, 0.014656, 0.19799, 0.79864, 0.0011576, 0.69683, 0.25881]
Predicted label: 6
Correct prediction
Energy consumption = 132.204064 pJ
sum error= 172
Actual label: 2
Output voltages: [0.36262, 0.043171, 0.79872, 0.10076, 0.020475, 0.0011878, 0.16397, 0.040102, 0.61169, 0.02881]
Predicted label: 2
Correct prediction
Energy consumption = 148.284993 pJ
sum error= 172
Actual label: 8
Output voltages: [0.0050355, 0.062759, 0.07768, 0.35965, 0.0011242, 0.031333, 0.020444, 0.0028034, 0.79879, 0.096372]
Predicted label: 8
Correct prediction
Energy consumption = 149.455043 pJ
sum error= 172
Actual label: 7
Output voltages: [0.057752, 0.26252, 0.15946, 0.65323, 0.0029738, 0.0012076, 0.0010941, 0.79869, 0.50403, 0.72024]
Predicted label: 7
Correct prediction
Energy consumption = 148.485618 pJ
sum error= 172
Actual label: 0
Output voltages: [0.79878, 0.15999, 0.008791, 0.018714, 0.021377, 0.046257, 0.63168, 0.012045, 0.028993, 0.1359]
Predicted label: 0
Correct prediction
Energy consumption = 159.590747 pJ
sum error= 172
Actual label: 1
Output voltages: [0.020252, 0.79866, 0.0011992, 0.01863, 0.041444, 0.31935, 0.56144, 0.15795, 0.33685, 0.0053532]
Predicted label: 1
Correct prediction
Energy consumption = 163.250512 pJ
sum error= 172
Actual label: 4
Output voltages: [0.0098857, 0.046318, 0.063101, 0.011336, 0.79872, 0.0017427, 0.44893, 0.031956, 0.026533, 0.38674]
Predicted label: 4
Correct prediction
Energy consumption = 161.604888 pJ
sum error= 172
Actual label: 2
Output voltages: [0.38045, 0.025395, 0.79742, 0.46384, 0.0068642, 0.0011288, 0.047107, 0.010397, 0.60361, 0.015375]
Predicted label: 2
Correct prediction
Energy consumption = 156.858084 pJ
sum error= 172
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 323 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 323 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 323 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.017159, 0.79848, 0.3845, 0.051771, 0.010594, 0.0011252, 0.44763, 0.0059779, 0.045725, 0.18326]
Predicted label: 1
Correct prediction
Energy consumption = 162.360196 pJ
sum error= 172
Actual label: 1
Output voltages: [0.027949, 0.79854, 0.038395, 0.3057, 0.010492, 0.0016175, 0.74591, 0.0019227, 0.05451, 0.029009]
Predicted label: 1
Correct prediction
Energy consumption = 150.309572 pJ
sum error= 172
Actual label: 4
Output voltages: [0.015725, 0.0083509, 0.35663, 0.016477, 0.79864, 0.0012016, 0.088926, 0.036931, 0.019408, 0.41626]
Predicted label: 4
Correct prediction
Energy consumption = 157.009806 pJ
sum error= 172
Actual label: 4
Output voltages: [0.0031748, 0.023742, 0.13882, 0.0056664, 0.79879, 0.0072733, 0.044295, 0.026621, 0.3678, 0.062614]
Predicted label: 4
Correct prediction
Energy consumption = 152.234414 pJ
sum error= 172
Actual label: 4
Output voltages: [0.0068828, 0.0035847, 0.17085, 0.0011277, 0.79855, 0.005517, 0.27999, 0.017439, 0.16528, 0.09437]
Predicted label: 4
Correct prediction
Energy consumption = 142.535711 pJ
sum error= 172
Actual label: 4
Output voltages: [0.021285, 0.029199, 0.041017, 0.012319, 0.79834, 0.048253, 0.26446, 0.023367, 0.055888, 0.77122]
Predicted label: 4
Correct prediction
Energy consumption = 146.352290 pJ
sum error= 172
Actual label: 7
Output voltages: [0.45842, 0.73219, 0.23401, 0.60044, 0.037795, 0.0012496, 0.0013637, 0.37796, 0.0014219, 0.36191]
Predicted label: 1
Wrong prediction!
Energy consumption = 160.711512 pJ
sum error= 173
Actual label: 1
Output voltages: [0.01701, 0.79846, 0.028709, 0.016225, 0.039146, 0.0028346, 0.35061, 0.019026, 0.011676, 0.19966]
Predicted label: 1
Correct prediction
Energy consumption = 151.159997 pJ
sum error= 173
Actual label: 6
Output voltages: [0.36325, 0.16688, 0.052399, 0.011213, 0.28207, 0.3233, 0.79879, 0.0016611, 0.31593, 0.024562]
Predicted label: 6
Correct prediction
Energy consumption = 150.828461 pJ
sum error= 173
Actual label: 2
Output voltages: [0.49803, 0.31553, 0.78688, 0.18203, 0.22133, 0.001234, 0.18754, 0.053743, 0.23478, 0.027252]
Predicted label: 2
Correct prediction
Energy consumption = 153.264621 pJ
sum error= 173
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 324 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 324 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 324 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.25, 0.001215, 0.02787, 0.13087, 0.033978, 0.025036, 0.0038038, 0.0047991, 0.68783, 0.78902]
Predicted label: 9
Correct prediction
Energy consumption = 158.117255 pJ
sum error= 173
Actual label: 9
Output voltages: [0.31365, 0.012347, 0.0195, 0.02615, 0.404, 0.029114, 0.04275, 0.13583, 0.21184, 0.79856]
Predicted label: 9
Correct prediction
Energy consumption = 152.123244 pJ
sum error= 173
Actual label: 0
Output voltages: [0.79805, 0.013336, 0.45355, 0.0037917, 0.0016563, 0.018658, 0.44191, 0.0091338, 0.2978, 0.0061592]
Predicted label: 0
Correct prediction
Energy consumption = 148.462908 pJ
sum error= 173
Actual label: 0
Output voltages: [0.79879, 0.04377, 0.03712, 0.046708, 0.019128, 0.0075495, 0.46164, 0.023925, 0.51033, 0.0224]
Predicted label: 0
Correct prediction
Energy consumption = 152.032561 pJ
sum error= 173
Actual label: 1
Output voltages: [0.0025888, 0.79853, 0.019876, 0.013089, 0.024493, 0.011718, 0.55026, 0.009413, 0.35921, 0.018305]
Predicted label: 1
Correct prediction
Energy consumption = 155.007991 pJ
sum error= 173
Actual label: 8
Output voltages: [0.022587, 0.14241, 0.1876, 0.33737, 0.051144, 0.03227, 0.027064, 0.0054253, 0.79879, 0.089566]
Predicted label: 8
Correct prediction
Energy consumption = 148.724237 pJ
sum error= 173
Actual label: 8
Output voltages: [0.33261, 0.029568, 0.054384, 0.73894, 0.0035865, 0.090453, 0.033681, 0.0010913, 0.79868, 0.36646]
Predicted label: 8
Correct prediction
Energy consumption = 148.549896 pJ
sum error= 173
Actual label: 4
Output voltages: [0.056205, 0.001081, 0.23952, 0.015474, 0.79879, 0.0011183, 0.020947, 0.05576, 0.026301, 0.51445]
Predicted label: 4
Correct prediction
Energy consumption = 160.520776 pJ
sum error= 173
Actual label: 3
Output voltages: [0.2075, 0.018333, 0.043591, 0.79861, 0.02933, 0.01698, 0.014649, 0.037572, 0.38753, 0.18193]
Predicted label: 3
Correct prediction
Energy consumption = 146.710318 pJ
sum error= 173
Actual label: 4
Output voltages: [0.0022162, 0.013609, 0.083323, 0.0043119, 0.79867, 0.011323, 0.092108, 0.2642, 0.21542, 0.0030791]
Predicted label: 4
Correct prediction
Energy consumption = 155.844741 pJ
sum error= 173
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 325 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 325 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 325 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.15583, 0.30109, 0.67195, 0.048468, 0.34251, 0.0073123, 0.74833, 0.0045363, 0.14416, 0.0016889]
Predicted label: 6
Wrong prediction!
Energy consumption = 149.245934 pJ
sum error= 174
Actual label: 0
Output voltages: [0.79472, 0.0091285, 0.17016, 0.052151, 0.034156, 0.026955, 0.69817, 0.0089336, 0.011428, 0.61106]
Predicted label: 0
Correct prediction
Energy consumption = 146.797691 pJ
sum error= 174
Actual label: 6
Output voltages: [0.029156, 0.20222, 0.42293, 0.017581, 0.078954, 0.14545, 0.79879, 0.001318, 0.76013, 0.011244]
Predicted label: 6
Correct prediction
Energy consumption = 144.652316 pJ
sum error= 174
Actual label: 1
Output voltages: [0.10185, 0.79852, 0.031211, 0.023185, 0.27246, 0.0074882, 0.42891, 0.002101, 0.054771, 0.038395]
Predicted label: 1
Correct prediction
Energy consumption = 160.233721 pJ
sum error= 174
Actual label: 6
Output voltages: [0.19872, 0.10413, 0.058222, 0.016332, 0.027431, 0.29409, 0.79788, 0.035834, 0.78313, 0.0092187]
Predicted label: 6
Correct prediction
Energy consumption = 149.698349 pJ
sum error= 174
Actual label: 1
Output voltages: [0.0092962, 0.79846, 0.13707, 0.02392, 0.043082, 0.01482, 0.48502, 0.0019056, 0.15554, 0.050356]
Predicted label: 1
Correct prediction
Energy consumption = 159.154464 pJ
sum error= 174
Actual label: 2
Output voltages: [0.52642, 0.05313, 0.79878, 0.20697, 0.021448, 0.0012334, 0.13472, 0.078515, 0.46318, 0.083441]
Predicted label: 2
Correct prediction
Energy consumption = 145.785923 pJ
sum error= 174
Actual label: 2
Output voltages: [0.13685, 0.19405, 0.79879, 0.044452, 0.024868, 0.0012766, 0.28292, 0.032072, 0.30205, 0.20514]
Predicted label: 2
Correct prediction
Energy consumption = 140.014607 pJ
sum error= 174
Actual label: 2
Output voltages: [0.44699, 0.038376, 0.79878, 0.25802, 0.025199, 0.0012784, 0.2444, 0.029292, 0.62142, 0.017509]
Predicted label: 2
Correct prediction
Energy consumption = 140.658175 pJ
sum error= 174
Actual label: 1
Output voltages: [0.0045163, 0.79873, 0.030024, 0.53398, 0.43128, 0.0015503, 0.016949, 0.059032, 0.053586, 0.056502]
Predicted label: 1
Correct prediction
Energy consumption = 160.046760 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 326 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 326 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 326 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.41599, 0.06713, 0.79879, 0.22169, 0.0041712, 0.0012514, 0.032149, 0.36048, 0.51531, 0.091857]
Predicted label: 2
Correct prediction
Energy consumption = 154.297760 pJ
sum error= 174
Actual label: 3
Output voltages: [0.60589, 0.011175, 0.037933, 0.79876, 0.015605, 0.017424, 0.0028955, 0.017172, 0.39106, 0.015679]
Predicted label: 3
Correct prediction
Energy consumption = 141.478364 pJ
sum error= 174
Actual label: 7
Output voltages: [0.040342, 0.01997, 0.46153, 0.15017, 0.014712, 0.0010686, 0.0010701, 0.79879, 0.32562, 0.16564]
Predicted label: 7
Correct prediction
Energy consumption = 136.550533 pJ
sum error= 174
Actual label: 8
Output voltages: [0.1121, 0.0015698, 0.11694, 0.01468, 0.03672, 0.0042564, 0.0046024, 0.12297, 0.79878, 0.052617]
Predicted label: 8
Correct prediction
Energy consumption = 149.835921 pJ
sum error= 174
Actual label: 1
Output voltages: [0.0078003, 0.79853, 0.025888, 0.10733, 0.0061971, 0.0011856, 0.75534, 0.0049938, 0.15438, 0.033405]
Predicted label: 1
Correct prediction
Energy consumption = 161.964139 pJ
sum error= 174
Actual label: 0
Output voltages: [0.79879, 0.10079, 0.10058, 0.015807, 0.017776, 0.010301, 0.40966, 0.017886, 0.1259, 0.027388]
Predicted label: 0
Correct prediction
Energy consumption = 152.800220 pJ
sum error= 174
Actual label: 0
Output voltages: [0.79867, 0.026865, 0.0059364, 0.10298, 0.027389, 0.032801, 0.63117, 0.035913, 0.16479, 0.037285]
Predicted label: 0
Correct prediction
Energy consumption = 142.931060 pJ
sum error= 174
Actual label: 2
Output voltages: [0.048178, 0.44714, 0.79879, 0.12442, 0.016386, 0.0014007, 0.055162, 0.1762, 0.036229, 0.083608]
Predicted label: 2
Correct prediction
Energy consumption = 151.581076 pJ
sum error= 174
Actual label: 1
Output voltages: [0.16771, 0.79844, 0.089864, 0.066697, 0.0070052, 0.0017575, 0.3978, 0.001621, 0.15309, 0.062125]
Predicted label: 1
Correct prediction
Energy consumption = 154.518223 pJ
sum error= 174
Actual label: 6
Output voltages: [0.73705, 0.15369, 0.055351, 0.015601, 0.032275, 0.3632, 0.79759, 0.0018295, 0.067074, 0.0050092]
Predicted label: 6
Correct prediction
Energy consumption = 152.554830 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 327 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 327 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 327 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.36524, 0.056877, 0.1062, 0.012848, 0.10512, 0.13023, 0.79878, 0.0013729, 0.55455, 0.012828]
Predicted label: 6
Correct prediction
Energy consumption = 154.014133 pJ
sum error= 174
Actual label: 0
Output voltages: [0.79853, 0.038052, 0.014498, 0.0033725, 0.042472, 0.0047637, 0.60045, 0.0091927, 0.018835, 0.17022]
Predicted label: 0
Correct prediction
Energy consumption = 151.730356 pJ
sum error= 174
Actual label: 1
Output voltages: [0.0081809, 0.79851, 0.0023103, 0.03552, 0.038255, 0.0047131, 0.59506, 0.0032043, 0.26766, 0.11617]
Predicted label: 1
Correct prediction
Energy consumption = 155.124498 pJ
sum error= 174
Actual label: 6
Output voltages: [0.20925, 0.0065083, 0.044789, 0.011693, 0.036658, 0.72148, 0.79819, 0.0010672, 0.5096, 0.043252]
Predicted label: 6
Correct prediction
Energy consumption = 148.592640 pJ
sum error= 174
Actual label: 2
Output voltages: [0.61512, 0.19122, 0.79778, 0.045731, 0.017911, 0.0012962, 0.34546, 0.33388, 0.22681, 0.0062666]
Predicted label: 2
Correct prediction
Energy consumption = 151.926202 pJ
sum error= 174
Actual label: 5
Output voltages: [0.080219, 0.0012859, 0.0010769, 0.74385, 0.029061, 0.79855, 0.017326, 0.05226, 0.73654, 0.014195]
Predicted label: 5
Correct prediction
Energy consumption = 152.827411 pJ
sum error= 174
Actual label: 1
Output voltages: [0.02627, 0.79836, 0.030962, 0.029801, 0.0068237, 0.0095787, 0.58655, 0.0083842, 0.070768, 0.064865]
Predicted label: 1
Correct prediction
Energy consumption = 168.075450 pJ
sum error= 174
Actual label: 7
Output voltages: [0.037221, 0.18718, 0.72106, 0.0086259, 0.01595, 0.0010751, 0.0010667, 0.79876, 0.68549, 0.018567]
Predicted label: 7
Correct prediction
Energy consumption = 140.985077 pJ
sum error= 174
Actual label: 4
Output voltages: [0.018219, 0.0067008, 0.22938, 0.0055449, 0.79865, 0.0021378, 0.15719, 0.02723, 0.037723, 0.51634]
Predicted label: 4
Correct prediction
Energy consumption = 159.628646 pJ
sum error= 174
Actual label: 8
Output voltages: [0.027441, 0.030994, 0.046351, 0.30504, 0.0013756, 0.010655, 0.010157, 0.0038829, 0.79879, 0.21963]
Predicted label: 8
Correct prediction
Energy consumption = 150.632855 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 328 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 328 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 328 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.23129, 0.57238, 0.79879, 0.021003, 0.0068291, 0.0013624, 0.046559, 0.39192, 0.15266, 0.012213]
Predicted label: 2
Correct prediction
Energy consumption = 149.809231 pJ
sum error= 174
Actual label: 1
Output voltages: [0.0042518, 0.79857, 0.035001, 0.037214, 0.026104, 0.0031268, 0.68943, 0.035855, 0.38748, 0.015435]
Predicted label: 1
Correct prediction
Energy consumption = 160.537203 pJ
sum error= 174
Actual label: 4
Output voltages: [0.025225, 0.013505, 0.11748, 0.0081842, 0.79864, 0.001066, 0.049359, 0.11825, 0.025958, 0.18249]
Predicted label: 4
Correct prediction
Energy consumption = 152.921059 pJ
sum error= 174
Actual label: 3
Output voltages: [0.49199, 0.016347, 0.045574, 0.79861, 0.011563, 0.056042, 0.015857, 0.034495, 0.61024, 0.036529]
Predicted label: 3
Correct prediction
Energy consumption = 151.697662 pJ
sum error= 174
Actual label: 8
Output voltages: [0.16259, 0.0029313, 0.3957, 0.0082033, 0.015791, 0.0043438, 0.017579, 0.0092114, 0.79874, 0.30662]
Predicted label: 8
Correct prediction
Energy consumption = 150.566929 pJ
sum error= 174
Actual label: 3
Output voltages: [0.64865, 0.017309, 0.14381, 0.7987, 0.0036319, 0.0076154, 0.011454, 0.03416, 0.57693, 0.0035117]
Predicted label: 3
Correct prediction
Energy consumption = 144.845438 pJ
sum error= 174
Actual label: 9
Output voltages: [0.27967, 0.033309, 0.035027, 0.35157, 0.18564, 0.016748, 0.02059, 0.047798, 0.11214, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 154.497175 pJ
sum error= 174
Actual label: 9
Output voltages: [0.73308, 0.0013729, 0.13455, 0.0079527, 0.3674, 0.0050109, 0.014507, 0.0027971, 0.15416, 0.79862]
Predicted label: 9
Correct prediction
Energy consumption = 143.135881 pJ
sum error= 174
Actual label: 4
Output voltages: [0.48331, 0.0096556, 0.21076, 0.0036197, 0.79828, 0.0010801, 0.3816, 0.0016998, 0.022311, 0.60238]
Predicted label: 4
Correct prediction
Energy consumption = 141.517614 pJ
sum error= 174
Actual label: 8
Output voltages: [0.0511, 0.028229, 0.027038, 0.061981, 0.0068306, 0.022576, 0.0017998, 0.032912, 0.79702, 0.65837]
Predicted label: 8
Correct prediction
Energy consumption = 152.563467 pJ
sum error= 174
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 329 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 329 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 329 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.017636, 0.0075019, 0.031688, 0.78388, 0.0055292, 0.10653, 0.0040941, 0.10028, 0.79845, 0.50407]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.293260 pJ
sum error= 175
Actual label: 4
Output voltages: [0.0078041, 0.040634, 0.22818, 0.0021867, 0.79867, 0.0094043, 0.18246, 0.026841, 0.045335, 0.38751]
Predicted label: 4
Correct prediction
Energy consumption = 151.865517 pJ
sum error= 175
Actual label: 7
Output voltages: [0.26219, 0.027001, 0.01448, 0.018313, 0.015289, 0.010613, 0.0011079, 0.79874, 0.39825, 0.48901]
Predicted label: 7
Correct prediction
Energy consumption = 155.550269 pJ
sum error= 175
Actual label: 2
Output voltages: [0.26016, 0.039566, 0.79872, 0.056579, 0.021777, 0.0012487, 0.3575, 0.021082, 0.49682, 0.036149]
Predicted label: 2
Correct prediction
Energy consumption = 148.383955 pJ
sum error= 175
Actual label: 7
Output voltages: [0.25747, 0.018298, 0.72779, 0.031567, 0.033682, 0.0013225, 0.016598, 0.7984, 0.045466, 0.031796]
Predicted label: 7
Correct prediction
Energy consumption = 139.970717 pJ
sum error= 175
Actual label: 5
Output voltages: [0.033007, 0.0010675, 0.0079416, 0.30495, 0.014266, 0.79839, 0.040064, 0.048915, 0.75365, 0.29762]
Predicted label: 5
Correct prediction
Energy consumption = 142.442189 pJ
sum error= 175
Actual label: 7
Output voltages: [0.75737, 0.0042398, 0.55523, 0.12253, 0.0051309, 0.0010859, 0.053137, 0.79733, 0.13456, 0.4873]
Predicted label: 7
Correct prediction
Energy consumption = 152.036234 pJ
sum error= 175
Actual label: 0
Output voltages: [0.79861, 0.034774, 0.037755, 0.013154, 0.025684, 0.0046847, 0.76347, 0.013339, 0.21865, 0.080534]
Predicted label: 0
Correct prediction
Energy consumption = 145.972228 pJ
sum error= 175
Actual label: 4
Output voltages: [0.01342, 0.0092107, 0.031947, 0.0096397, 0.79858, 0.0029192, 0.12341, 0.010643, 0.15145, 0.025747]
Predicted label: 4
Correct prediction
Energy consumption = 148.978736 pJ
sum error= 175
Actual label: 3
Output voltages: [0.028759, 0.0073588, 0.060671, 0.79874, 0.049583, 0.016172, 0.033403, 0.021516, 0.47026, 0.20292]
Predicted label: 3
Correct prediction
Energy consumption = 150.812526 pJ
sum error= 175
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 330 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 330 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 330 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.060065, 0.012491, 0.21966, 0.79879, 0.06427, 0.035294, 0.28321, 0.010644, 0.34164, 0.011676]
Predicted label: 3
Correct prediction
Energy consumption = 151.521963 pJ
sum error= 175
Actual label: 2
Output voltages: [0.44, 0.74667, 0.79455, 0.065372, 0.0050431, 0.0012518, 0.18015, 0.019402, 0.21402, 0.018415]
Predicted label: 2
Correct prediction
Energy consumption = 152.752811 pJ
sum error= 175
Actual label: 6
Output voltages: [0.15297, 0.031566, 0.44683, 0.0029941, 0.17842, 0.046811, 0.79878, 0.0087617, 0.27949, 0.003641]
Predicted label: 6
Correct prediction
Energy consumption = 142.249380 pJ
sum error= 175
Actual label: 7
Output voltages: [0.30206, 0.0080255, 0.0084205, 0.013908, 0.024791, 0.0069068, 0.001068, 0.79877, 0.24601, 0.41724]
Predicted label: 7
Correct prediction
Energy consumption = 160.859294 pJ
sum error= 175
Actual label: 6
Output voltages: [0.069249, 0.14078, 0.20472, 0.018078, 0.19073, 0.29039, 0.79879, 0.0033184, 0.3799, 0.0049565]
Predicted label: 6
Correct prediction
Energy consumption = 152.425428 pJ
sum error= 175
Actual label: 0
Output voltages: [0.79867, 0.013402, 0.028697, 0.27385, 0.022867, 0.011227, 0.37943, 0.13706, 0.46381, 0.2659]
Predicted label: 0
Correct prediction
Energy consumption = 157.101429 pJ
sum error= 175
Actual label: 0
Output voltages: [0.79866, 0.066063, 0.20552, 0.0068146, 0.022317, 0.0013505, 0.51761, 0.0039774, 0.13992, 0.095767]
Predicted label: 0
Correct prediction
Energy consumption = 145.522115 pJ
sum error= 175
Actual label: 6
Output voltages: [0.041364, 0.023859, 0.1627, 0.010992, 0.081182, 0.076851, 0.79879, 0.0074814, 0.51796, 0.018397]
Predicted label: 6
Correct prediction
Energy consumption = 140.336260 pJ
sum error= 175
Actual label: 7
Output voltages: [0.55301, 0.042169, 0.64624, 0.02418, 0.010871, 0.0010743, 0.0011703, 0.79866, 0.083062, 0.028886]
Predicted label: 7
Correct prediction
Energy consumption = 146.902820 pJ
sum error= 175
Actual label: 7
Output voltages: [0.031701, 0.45423, 0.37669, 0.035319, 0.0026441, 0.001083, 0.0011031, 0.79867, 0.245, 0.048008]
Predicted label: 7
Correct prediction
Energy consumption = 141.934722 pJ
sum error= 175
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 331 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 331 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 331 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.19871, 0.030948, 0.014861, 0.009847, 0.0097252, 0.55055, 0.0048545, 0.075886, 0.045154]
Predicted label: 0
Correct prediction
Energy consumption = 156.361179 pJ
sum error= 175
Actual label: 5
Output voltages: [0.023294, 0.001169, 0.0010691, 0.34195, 0.35243, 0.79872, 0.035494, 0.0016802, 0.13738, 0.20651]
Predicted label: 5
Correct prediction
Energy consumption = 142.992398 pJ
sum error= 175
Actual label: 5
Output voltages: [0.015413, 0.0010987, 0.015651, 0.48454, 0.02383, 0.79866, 0.14332, 0.11774, 0.70259, 0.30027]
Predicted label: 5
Correct prediction
Energy consumption = 141.844152 pJ
sum error= 175
Actual label: 8
Output voltages: [0.02544, 0.025924, 0.31998, 0.038405, 0.021059, 0.040098, 0.0296, 0.014433, 0.79874, 0.53606]
Predicted label: 8
Correct prediction
Energy consumption = 147.630241 pJ
sum error= 175
Actual label: 1
Output voltages: [0.02003, 0.79868, 0.17846, 0.021598, 0.044036, 0.001174, 0.60823, 0.0099824, 0.38329, 0.0076701]
Predicted label: 1
Correct prediction
Energy consumption = 166.558259 pJ
sum error= 175
Actual label: 0
Output voltages: [0.79768, 0.06338, 0.0055735, 0.016457, 0.020245, 0.062116, 0.66565, 0.0089232, 0.41395, 0.013344]
Predicted label: 0
Correct prediction
Energy consumption = 150.366932 pJ
sum error= 175
Actual label: 7
Output voltages: [0.001098, 0.029204, 0.11041, 0.0065335, 0.43948, 0.0012711, 0.015808, 0.79874, 0.23401, 0.018198]
Predicted label: 7
Correct prediction
Energy consumption = 154.702890 pJ
sum error= 175
Actual label: 0
Output voltages: [0.79879, 0.020568, 0.022374, 0.0070045, 0.16109, 0.014848, 0.77517, 0.033304, 0.10953, 0.024465]
Predicted label: 0
Correct prediction
Energy consumption = 160.196004 pJ
sum error= 175
Actual label: 2
Output voltages: [0.033496, 0.054201, 0.79759, 0.51854, 0.0035295, 0.0012512, 0.23591, 0.036517, 0.70175, 0.016094]
Predicted label: 2
Correct prediction
Energy consumption = 144.473166 pJ
sum error= 175
Actual label: 8
Output voltages: [0.039531, 0.011025, 0.046182, 0.12626, 0.004264, 0.0089082, 0.020769, 0.016076, 0.79872, 0.37946]
Predicted label: 8
Correct prediction
Energy consumption = 155.331810 pJ
sum error= 175
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 332 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 332 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 332 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0012122, 0.79866, 0.004299, 0.016863, 0.34144, 0.014288, 0.33583, 0.0053689, 0.50908, 0.136]
Predicted label: 1
Correct prediction
Energy consumption = 159.601089 pJ
sum error= 175
Actual label: 5
Output voltages: [0.031657, 0.0020803, 0.049576, 0.42587, 0.0075441, 0.72798, 0.013808, 0.0072092, 0.79843, 0.03167]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.972421 pJ
sum error= 176
Actual label: 0
Output voltages: [0.79871, 0.20435, 0.028598, 0.029951, 0.038026, 0.024695, 0.22791, 0.020388, 0.17793, 0.34743]
Predicted label: 0
Correct prediction
Energy consumption = 155.254321 pJ
sum error= 176
Actual label: 8
Output voltages: [0.20561, 0.022309, 0.16905, 0.6295, 0.0063764, 0.048109, 0.029916, 0.0058578, 0.79874, 0.01966]
Predicted label: 8
Correct prediction
Energy consumption = 150.707496 pJ
sum error= 176
Actual label: 8
Output voltages: [0.026818, 0.023988, 0.045547, 0.25566, 0.0010725, 0.062942, 0.0046753, 0.00537, 0.79878, 0.058495]
Predicted label: 8
Correct prediction
Energy consumption = 145.216584 pJ
sum error= 176
Actual label: 0
Output voltages: [0.79847, 0.040545, 0.021359, 0.0076614, 0.0076122, 0.0074079, 0.7517, 0.012006, 0.15178, 0.086212]
Predicted label: 0
Correct prediction
Energy consumption = 157.389600 pJ
sum error= 176
Actual label: 3
Output voltages: [0.72627, 0.020729, 0.026113, 0.79869, 0.0019524, 0.045571, 0.0081633, 0.019514, 0.36027, 0.0089394]
Predicted label: 3
Correct prediction
Energy consumption = 142.367957 pJ
sum error= 176
Actual label: 2
Output voltages: [0.32358, 0.10044, 0.79879, 0.16273, 0.018172, 0.0013009, 0.45411, 0.020041, 0.48583, 0.026543]
Predicted label: 2
Correct prediction
Energy consumption = 145.972666 pJ
sum error= 176
Actual label: 7
Output voltages: [0.32809, 0.034086, 0.76653, 0.001942, 0.017196, 0.001132, 0.0012045, 0.79879, 0.60381, 0.0028976]
Predicted label: 7
Correct prediction
Energy consumption = 145.994802 pJ
sum error= 176
Actual label: 7
Output voltages: [0.2135, 0.0059458, 0.72813, 0.25156, 0.08874, 0.001359, 0.0027264, 0.78586, 0.21057, 0.13508]
Predicted label: 7
Correct prediction
Energy consumption = 144.744319 pJ
sum error= 176
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 333 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 333 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 333 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.74422, 0.037488, 0.74222, 0.79379, 0.0010692, 0.015474, 0.020585, 0.0011709, 0.74202, 0.04347]
Predicted label: 3
Wrong prediction!
Energy consumption = 145.906412 pJ
sum error= 177
Actual label: 6
Output voltages: [0.046575, 0.032905, 0.23467, 0.003924, 0.20428, 0.12298, 0.79876, 0.00131, 0.63403, 0.045279]
Predicted label: 6
Correct prediction
Energy consumption = 146.962593 pJ
sum error= 177
Actual label: 4
Output voltages: [0.0020054, 0.0058332, 0.1332, 0.018982, 0.79868, 0.001577, 0.21784, 0.065552, 0.16827, 0.030155]
Predicted label: 4
Correct prediction
Energy consumption = 154.053141 pJ
sum error= 177
Actual label: 7
Output voltages: [0.23897, 0.0038846, 0.097917, 0.65705, 0.71782, 0.0010683, 0.0010776, 0.42265, 0.0059101, 0.71211]
Predicted label: 4
Wrong prediction!
Energy consumption = 144.513010 pJ
sum error= 178
Actual label: 5
Output voltages: [0.03058, 0.0014083, 0.0015137, 0.43933, 0.034475, 0.79847, 0.042569, 0.028761, 0.66774, 0.50091]
Predicted label: 5
Correct prediction
Energy consumption = 146.316141 pJ
sum error= 178
Actual label: 5
Output voltages: [0.053947, 0.0030711, 0.0010762, 0.27237, 0.13746, 0.79871, 0.46632, 0.0072051, 0.74139, 0.0054805]
Predicted label: 5
Correct prediction
Energy consumption = 132.083660 pJ
sum error= 178
Actual label: 5
Output voltages: [0.06237, 0.0022679, 0.0011015, 0.03213, 0.29563, 0.78407, 0.004287, 0.75937, 0.42444, 0.4411]
Predicted label: 5
Correct prediction
Energy consumption = 145.641233 pJ
sum error= 178
Actual label: 2
Output voltages: [0.047106, 0.040188, 0.79879, 0.031584, 0.012403, 0.0010778, 0.12669, 0.45138, 0.59136, 0.26437]
Predicted label: 2
Correct prediction
Energy consumption = 150.336763 pJ
sum error= 178
Actual label: 9
Output voltages: [0.067191, 0.013199, 0.01846, 0.10952, 0.1491, 0.077587, 0.038398, 0.023159, 0.42296, 0.79662]
Predicted label: 9
Correct prediction
Energy consumption = 159.179576 pJ
sum error= 178
Actual label: 2
Output voltages: [0.13021, 0.39096, 0.79879, 0.029513, 0.023977, 0.001372, 0.1541, 0.044696, 0.26381, 0.043644]
Predicted label: 2
Correct prediction
Energy consumption = 151.743925 pJ
sum error= 178
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 334 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 334 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 334 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.09705, 0.086605, 0.016403, 0.33852, 0.0011758, 0.32627, 0.008942, 0.0033375, 0.79874, 0.35521]
Predicted label: 8
Correct prediction
Energy consumption = 153.950220 pJ
sum error= 178
Actual label: 4
Output voltages: [0.019139, 0.020256, 0.167, 0.0079754, 0.79868, 0.0032469, 0.036722, 0.022417, 0.037938, 0.009199]
Predicted label: 4
Correct prediction
Energy consumption = 142.892625 pJ
sum error= 178
Actual label: 6
Output voltages: [0.044746, 0.0050552, 0.35979, 0.015421, 0.036509, 0.1047, 0.79875, 0.0011271, 0.60618, 0.20256]
Predicted label: 6
Correct prediction
Energy consumption = 147.120092 pJ
sum error= 178
Actual label: 8
Output voltages: [0.053802, 0.031116, 0.77487, 0.026654, 0.011878, 0.0012663, 0.03933, 0.0055273, 0.79874, 0.26131]
Predicted label: 8
Correct prediction
Energy consumption = 144.889790 pJ
sum error= 178
Actual label: 6
Output voltages: [0.76958, 0.025006, 0.0014294, 0.044593, 0.12489, 0.42885, 0.79326, 0.019668, 0.56335, 0.020865]
Predicted label: 6
Correct prediction
Energy consumption = 152.242285 pJ
sum error= 178
Actual label: 5
Output voltages: [0.061898, 0.0010659, 0.0029438, 0.03804, 0.011565, 0.79873, 0.28193, 0.21119, 0.77652, 0.0065675]
Predicted label: 5
Correct prediction
Energy consumption = 137.628291 pJ
sum error= 178
Actual label: 0
Output voltages: [0.79848, 0.056708, 0.33269, 0.0060716, 0.0072988, 0.002216, 0.22076, 0.02512, 0.43995, 0.07009]
Predicted label: 0
Correct prediction
Energy consumption = 155.341219 pJ
sum error= 178
Actual label: 0
Output voltages: [0.78596, 0.010305, 0.3946, 0.001861, 0.014456, 0.018855, 0.7359, 0.014166, 0.74365, 0.0117]
Predicted label: 0
Correct prediction
Energy consumption = 146.601585 pJ
sum error= 178
Actual label: 8
Output voltages: [0.037797, 0.022741, 0.40549, 0.24981, 0.0068995, 0.023607, 0.0068596, 0.013543, 0.79861, 0.38376]
Predicted label: 8
Correct prediction
Energy consumption = 144.736899 pJ
sum error= 178
Actual label: 7
Output voltages: [0.020253, 0.0043286, 0.16008, 0.42789, 0.0020256, 0.0017689, 0.0010662, 0.79879, 0.3529, 0.5053]
Predicted label: 7
Correct prediction
Energy consumption = 146.342301 pJ
sum error= 178
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 335 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 335 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 335 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.21435, 0.052455, 0.13786, 0.0039365, 0.40155, 0.43722, 0.79864, 0.0025035, 0.45395, 0.010922]
Predicted label: 6
Correct prediction
Energy consumption = 149.245913 pJ
sum error= 178
Actual label: 1
Output voltages: [0.13799, 0.79878, 0.57735, 0.0079607, 0.39531, 0.0011083, 0.31635, 0.001908, 0.03703, 0.023007]
Predicted label: 1
Correct prediction
Energy consumption = 151.951682 pJ
sum error= 178
Actual label: 7
Output voltages: [0.22679, 0.0022874, 0.063328, 0.70785, 0.20975, 0.0010661, 0.0010851, 0.76831, 0.67556, 0.12992]
Predicted label: 7
Correct prediction
Energy consumption = 148.082772 pJ
sum error= 178
Actual label: 1
Output voltages: [0.0078145, 0.79861, 0.13051, 0.035873, 0.26031, 0.025447, 0.02553, 0.010846, 0.018987, 0.19457]
Predicted label: 1
Correct prediction
Energy consumption = 163.164799 pJ
sum error= 178
Actual label: 1
Output voltages: [0.0049994, 0.79857, 0.060382, 0.086012, 0.051403, 0.003184, 0.5687, 0.0041215, 0.26128, 0.03388]
Predicted label: 1
Correct prediction
Energy consumption = 155.620912 pJ
sum error= 178
Actual label: 2
Output voltages: [0.3651, 0.035804, 0.79867, 0.057346, 0.010126, 0.001066, 0.040029, 0.34528, 0.50904, 0.01337]
Predicted label: 2
Correct prediction
Energy consumption = 139.712048 pJ
sum error= 178
Actual label: 7
Output voltages: [0.36324, 0.042701, 0.0011307, 0.40433, 0.023846, 0.019878, 0.001082, 0.79878, 0.29079, 0.62552]
Predicted label: 7
Correct prediction
Energy consumption = 156.678246 pJ
sum error= 178
Actual label: 4
Output voltages: [0.034681, 0.0027218, 0.029467, 0.011989, 0.7985, 0.0064188, 0.10118, 0.03505, 0.042922, 0.12836]
Predicted label: 4
Correct prediction
Energy consumption = 150.807679 pJ
sum error= 178
Actual label: 0
Output voltages: [0.79155, 0.063524, 0.019298, 0.012503, 0.0012054, 0.016268, 0.15775, 0.061226, 0.77835, 0.0033561]
Predicted label: 0
Correct prediction
Energy consumption = 158.986872 pJ
sum error= 178
Actual label: 0
Output voltages: [0.79879, 0.013052, 0.022322, 0.0018834, 0.027241, 0.010733, 0.65804, 0.0066748, 0.068074, 0.035764]
Predicted label: 0
Correct prediction
Energy consumption = 149.737953 pJ
sum error= 178
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 336 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 336 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 336 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.041848, 0.039205, 0.059956, 0.045314, 0.013295, 0.0076368, 0.0010688, 0.79854, 0.04363, 0.31044]
Predicted label: 7
Correct prediction
Energy consumption = 152.162025 pJ
sum error= 178
Actual label: 7
Output voltages: [0.75734, 0.010906, 0.55477, 0.042511, 0.0069004, 0.0011066, 0.0010886, 0.79847, 0.23506, 0.013746]
Predicted label: 7
Correct prediction
Energy consumption = 135.897538 pJ
sum error= 178
Actual label: 6
Output voltages: [0.2567, 0.028563, 0.053868, 0.034331, 0.30669, 0.39674, 0.79877, 0.0011396, 0.69175, 0.019364]
Predicted label: 6
Correct prediction
Energy consumption = 149.812537 pJ
sum error= 178
Actual label: 3
Output voltages: [0.28891, 0.017845, 0.036883, 0.79866, 0.010588, 0.017863, 0.0244, 0.017028, 0.34203, 0.037583]
Predicted label: 3
Correct prediction
Energy consumption = 154.844037 pJ
sum error= 178
Actual label: 8
Output voltages: [0.049972, 0.036291, 0.33615, 0.27363, 0.012172, 0.036768, 0.013774, 0.030353, 0.79861, 0.12848]
Predicted label: 8
Correct prediction
Energy consumption = 140.095668 pJ
sum error= 178
Actual label: 6
Output voltages: [0.62583, 0.6353, 0.010731, 0.15951, 0.016682, 0.61602, 0.79876, 0.003927, 0.18909, 0.0064066]
Predicted label: 6
Correct prediction
Energy consumption = 147.321933 pJ
sum error= 178
Actual label: 4
Output voltages: [0.027028, 0.015164, 0.26579, 0.037649, 0.79872, 0.0011466, 0.29223, 0.011612, 0.013083, 0.0078805]
Predicted label: 4
Correct prediction
Energy consumption = 155.745451 pJ
sum error= 178
Actual label: 2
Output voltages: [0.57056, 0.015629, 0.79879, 0.11501, 0.006746, 0.0011169, 0.060985, 0.029176, 0.72969, 0.01864]
Predicted label: 2
Correct prediction
Energy consumption = 147.579108 pJ
sum error= 178
Actual label: 0
Output voltages: [0.79823, 0.021572, 0.031738, 0.030968, 0.024337, 0.09102, 0.75593, 0.033471, 0.091728, 0.042494]
Predicted label: 0
Correct prediction
Energy consumption = 154.737643 pJ
sum error= 178
Actual label: 9
Output voltages: [0.038854, 0.45276, 0.0011532, 0.040875, 0.023617, 0.0014521, 0.0010707, 0.32462, 0.64634, 0.79175]
Predicted label: 9
Correct prediction
Energy consumption = 158.819080 pJ
sum error= 178
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 337 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 337 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 337 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0052531, 0.015266, 0.29803, 0.0118, 0.79859, 0.0031083, 0.056767, 0.082934, 0.019295, 0.11413]
Predicted label: 4
Correct prediction
Energy consumption = 152.371513 pJ
sum error= 178
Actual label: 0
Output voltages: [0.79876, 0.056591, 0.024382, 0.010291, 0.024819, 0.018958, 0.58002, 0.0081077, 0.059294, 0.032066]
Predicted label: 0
Correct prediction
Energy consumption = 154.448926 pJ
sum error= 178
Actual label: 5
Output voltages: [0.070521, 0.0010985, 0.0010664, 0.25409, 0.19172, 0.79879, 0.18839, 0.040989, 0.73127, 0.054732]
Predicted label: 5
Correct prediction
Energy consumption = 147.804998 pJ
sum error= 178
Actual label: 7
Output voltages: [0.28781, 0.014049, 0.012699, 0.19876, 0.015122, 0.0055622, 0.0010659, 0.79866, 0.19498, 0.72819]
Predicted label: 7
Correct prediction
Energy consumption = 146.301286 pJ
sum error= 178
Actual label: 8
Output voltages: [0.039627, 0.031595, 0.23814, 0.088075, 0.0125, 0.0076009, 0.021048, 0.0019718, 0.79878, 0.33981]
Predicted label: 8
Correct prediction
Energy consumption = 146.665350 pJ
sum error= 178
Actual label: 2
Output voltages: [0.029939, 0.23839, 0.79799, 0.26297, 0.0064581, 0.0011414, 0.12709, 0.0013053, 0.47026, 0.11112]
Predicted label: 2
Correct prediction
Energy consumption = 140.248257 pJ
sum error= 178
Actual label: 7
Output voltages: [0.025729, 0.6299, 0.038613, 0.0017471, 0.013471, 0.0012039, 0.0050562, 0.79877, 0.21604, 0.27086]
Predicted label: 7
Correct prediction
Energy consumption = 161.797461 pJ
sum error= 178
Actual label: 4
Output voltages: [0.0041492, 0.0081605, 0.0073116, 0.026051, 0.79879, 0.02118, 0.28993, 0.026644, 0.038466, 0.027065]
Predicted label: 4
Correct prediction
Energy consumption = 149.896137 pJ
sum error= 178
Actual label: 7
Output voltages: [0.084276, 0.010403, 0.024244, 0.26078, 0.043537, 0.019605, 0.0010664, 0.79864, 0.36518, 0.49596]
Predicted label: 7
Correct prediction
Energy consumption = 146.989722 pJ
sum error= 178
Actual label: 1
Output voltages: [0.017856, 0.79843, 0.028567, 0.36294, 0.0065164, 0.020562, 0.64877, 0.019552, 0.014175, 0.34529]
Predicted label: 1
Correct prediction
Energy consumption = 161.010084 pJ
sum error= 178
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 338 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 338 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 338 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.015785, 0.79861, 0.12677, 0.086126, 0.0089222, 0.0012181, 0.76059, 0.0062767, 0.27975, 0.020348]
Predicted label: 1
Correct prediction
Energy consumption = 163.944721 pJ
sum error= 178
Actual label: 3
Output voltages: [0.042749, 0.1592, 0.30066, 0.79871, 0.019538, 0.0012745, 0.0017273, 0.0089499, 0.53796, 0.066718]
Predicted label: 3
Correct prediction
Energy consumption = 146.553600 pJ
sum error= 178
Actual label: 6
Output voltages: [0.048236, 0.038465, 0.053644, 0.0095981, 0.22093, 0.25534, 0.79865, 0.0051588, 0.75556, 0.027579]
Predicted label: 6
Correct prediction
Energy consumption = 151.208778 pJ
sum error= 178
Actual label: 6
Output voltages: [0.051929, 0.038218, 0.034799, 0.037047, 0.04244, 0.44104, 0.79879, 0.011853, 0.72483, 0.017268]
Predicted label: 6
Correct prediction
Energy consumption = 144.326813 pJ
sum error= 178
Actual label: 2
Output voltages: [0.64125, 0.049055, 0.6953, 0.4032, 0.020749, 0.0013238, 0.77539, 0.35136, 0.50937, 0.0010673]
Predicted label: 6
Wrong prediction!
Energy consumption = 146.799112 pJ
sum error= 179
Actual label: 9
Output voltages: [0.37042, 0.0018792, 0.096326, 0.043848, 0.081488, 0.0064029, 0.022262, 0.030392, 0.035909, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 148.248018 pJ
sum error= 179
Actual label: 1
Output voltages: [0.0061358, 0.79856, 0.04322, 0.01274, 0.015499, 0.0040997, 0.6365, 0.0067707, 0.35815, 0.0061237]
Predicted label: 1
Correct prediction
Energy consumption = 160.017119 pJ
sum error= 179
Actual label: 9
Output voltages: [0.26474, 0.032971, 0.037288, 0.1146, 0.094571, 0.019108, 0.0061173, 0.040627, 0.38301, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.291788 pJ
sum error= 179
Actual label: 4
Output voltages: [0.027868, 0.029182, 0.031339, 0.038321, 0.79876, 0.0085882, 0.045588, 0.0056622, 0.1128, 0.43535]
Predicted label: 4
Correct prediction
Energy consumption = 145.568246 pJ
sum error= 179
Actual label: 8
Output voltages: [0.40422, 0.012193, 0.17801, 0.1425, 0.0073302, 0.039936, 0.0034691, 0.0020844, 0.79876, 0.17021]
Predicted label: 8
Correct prediction
Energy consumption = 147.326715 pJ
sum error= 179
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 339 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 339 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 339 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.43367, 0.025065, 0.048935, 0.79863, 0.013099, 0.025645, 0.020261, 0.018454, 0.53245, 0.2313]
Predicted label: 3
Correct prediction
Energy consumption = 149.630358 pJ
sum error= 179
Actual label: 6
Output voltages: [0.16612, 0.02793, 0.27671, 0.0010665, 0.18253, 0.17939, 0.79877, 0.003958, 0.7279, 0.0042239]
Predicted label: 6
Correct prediction
Energy consumption = 148.900583 pJ
sum error= 179
Actual label: 9
Output voltages: [0.30893, 0.0080382, 0.019602, 0.0091003, 0.42373, 0.14178, 0.022699, 0.02772, 0.067524, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 146.381441 pJ
sum error= 179
Actual label: 5
Output voltages: [0.040982, 0.0015179, 0.001511, 0.10336, 0.030205, 0.79878, 0.41804, 0.024068, 0.74618, 0.028794]
Predicted label: 5
Correct prediction
Energy consumption = 149.015768 pJ
sum error= 179
Actual label: 9
Output voltages: [0.39299, 0.0010844, 0.4396, 0.023851, 0.46474, 0.031873, 0.0049716, 0.043995, 0.039301, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 151.463981 pJ
sum error= 179
Actual label: 6
Output voltages: [0.12342, 0.042809, 0.1687, 0.00273, 0.29724, 0.42987, 0.79868, 0.0021692, 0.37951, 0.017664]
Predicted label: 6
Correct prediction
Energy consumption = 149.902333 pJ
sum error= 179
Actual label: 2
Output voltages: [0.46233, 0.30158, 0.79876, 0.028533, 0.027534, 0.0013567, 0.079786, 0.03586, 0.2054, 0.03428]
Predicted label: 2
Correct prediction
Energy consumption = 146.377840 pJ
sum error= 179
Actual label: 4
Output voltages: [0.0081915, 0.019306, 0.043649, 0.0027106, 0.79868, 0.0039535, 0.19033, 0.34123, 0.030534, 0.028366]
Predicted label: 4
Correct prediction
Energy consumption = 154.167922 pJ
sum error= 179
Actual label: 6
Output voltages: [0.3037, 0.23231, 0.025242, 0.028632, 0.026572, 0.08106, 0.79878, 0.0034219, 0.6375, 0.015625]
Predicted label: 6
Correct prediction
Energy consumption = 156.446427 pJ
sum error= 179
Actual label: 7
Output voltages: [0.49322, 0.049156, 0.02395, 0.01565, 0.027252, 0.02053, 0.014443, 0.79857, 0.13147, 0.22087]
Predicted label: 7
Correct prediction
Energy consumption = 154.503436 pJ
sum error= 179
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 340 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 340 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 340 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.038544, 0.015278, 0.1045, 0.065499, 0.009042, 0.007102, 0.001069, 0.79859, 0.38352, 0.48376]
Predicted label: 7
Correct prediction
Energy consumption = 158.750332 pJ
sum error= 179
Actual label: 0
Output voltages: [0.79879, 0.050438, 0.35615, 0.0070862, 0.0056877, 0.0022593, 0.30207, 0.010239, 0.16581, 0.064127]
Predicted label: 0
Correct prediction
Energy consumption = 143.388062 pJ
sum error= 179
Actual label: 6
Output voltages: [0.058436, 0.34233, 0.16245, 0.0031573, 0.039574, 0.20174, 0.79868, 0.0020746, 0.63196, 0.0070774]
Predicted label: 6
Correct prediction
Energy consumption = 140.816235 pJ
sum error= 179
Actual label: 6
Output voltages: [0.19398, 0.018535, 0.30111, 0.0069917, 0.5127, 0.091603, 0.79875, 0.0032698, 0.57814, 0.0072626]
Predicted label: 6
Correct prediction
Energy consumption = 140.197520 pJ
sum error= 179
Actual label: 9
Output voltages: [0.17086, 0.019791, 0.032261, 0.054931, 0.18994, 0.0028669, 0.28268, 0.019419, 0.043991, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 148.309849 pJ
sum error= 179
Actual label: 4
Output voltages: [0.053176, 0.0011179, 0.045027, 0.0023796, 0.79878, 0.0010989, 0.0023641, 0.12912, 0.027964, 0.4298]
Predicted label: 4
Correct prediction
Energy consumption = 143.248832 pJ
sum error= 179
Actual label: 8
Output voltages: [0.0060293, 0.19933, 0.052187, 0.23039, 0.0021382, 0.01962, 0.0028029, 0.11015, 0.79876, 0.065089]
Predicted label: 8
Correct prediction
Energy consumption = 146.662318 pJ
sum error= 179
Actual label: 3
Output voltages: [0.33371, 0.036319, 0.041704, 0.79864, 0.047047, 0.015118, 0.028771, 0.012388, 0.54115, 0.30694]
Predicted label: 3
Correct prediction
Energy consumption = 151.206444 pJ
sum error= 179
Actual label: 5
Output voltages: [0.045296, 0.0010663, 0.0049935, 0.35851, 0.20814, 0.79871, 0.21399, 0.045304, 0.77248, 0.017912]
Predicted label: 5
Correct prediction
Energy consumption = 143.564706 pJ
sum error= 179
Actual label: 3
Output voltages: [0.49141, 0.0053088, 0.049322, 0.79872, 0.019777, 0.0040228, 0.007722, 0.0072131, 0.58451, 0.024428]
Predicted label: 3
Correct prediction
Energy consumption = 143.573631 pJ
sum error= 179
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 341 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 341 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 341 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.1826, 0.0065537, 0.2416, 0.0083995, 0.79864, 0.0071747, 0.050833, 0.053854, 0.031403, 0.53778]
Predicted label: 4
Correct prediction
Energy consumption = 160.304394 pJ
sum error= 179
Actual label: 9
Output voltages: [0.26622, 0.0031995, 0.014436, 0.036656, 0.029085, 0.02305, 0.001962, 0.39328, 0.73353, 0.79088]
Predicted label: 9
Correct prediction
Energy consumption = 150.559554 pJ
sum error= 179
Actual label: 0
Output voltages: [0.78544, 0.17228, 0.15982, 0.0034422, 0.0023352, 0.0011524, 0.53067, 0.32501, 0.12891, 0.46714]
Predicted label: 0
Correct prediction
Energy consumption = 148.850700 pJ
sum error= 179
Actual label: 0
Output voltages: [0.7987, 0.045126, 0.026623, 0.017644, 0.011497, 0.041595, 0.045097, 0.013731, 0.15536, 0.034056]
Predicted label: 0
Correct prediction
Energy consumption = 147.748306 pJ
sum error= 179
Actual label: 5
Output voltages: [0.044132, 0.0016564, 0.046434, 0.45434, 0.0071001, 0.79167, 0.10214, 0.0083542, 0.79717, 0.052593]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.534933 pJ
sum error= 180
Actual label: 2
Output voltages: [0.33793, 0.041534, 0.79874, 0.46926, 0.010008, 0.0011517, 0.010855, 0.49212, 0.53756, 0.021799]
Predicted label: 2
Correct prediction
Energy consumption = 150.516162 pJ
sum error= 180
Actual label: 5
Output voltages: [0.016573, 0.017817, 0.0035683, 0.50464, 0.035659, 0.79726, 0.18587, 0.018564, 0.42326, 0.42679]
Predicted label: 5
Correct prediction
Energy consumption = 143.233342 pJ
sum error= 180
Actual label: 0
Output voltages: [0.79877, 0.12198, 0.050177, 0.016467, 0.029023, 0.0080396, 0.28496, 0.0041256, 0.11296, 0.42109]
Predicted label: 0
Correct prediction
Energy consumption = 158.427046 pJ
sum error= 180
Actual label: 7
Output voltages: [0.26343, 0.63925, 0.034924, 0.60343, 0.0032955, 0.0017992, 0.001092, 0.79817, 0.090757, 0.47758]
Predicted label: 7
Correct prediction
Energy consumption = 160.259667 pJ
sum error= 180
Actual label: 1
Output voltages: [0.0043616, 0.79855, 0.06852, 0.034713, 0.02125, 0.0035018, 0.62931, 0.0087933, 0.25711, 0.029685]
Predicted label: 1
Correct prediction
Energy consumption = 156.476721 pJ
sum error= 180
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 342 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 342 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 342 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.033815, 0.79856, 0.048019, 0.020751, 0.13545, 0.0026622, 0.57288, 0.0087652, 0.19207, 0.045132]
Predicted label: 1
Correct prediction
Energy consumption = 162.097548 pJ
sum error= 180
Actual label: 1
Output voltages: [0.042158, 0.79851, 0.048229, 0.049757, 0.2496, 0.0063447, 0.36672, 0.0034019, 0.20395, 0.055973]
Predicted label: 1
Correct prediction
Energy consumption = 151.440103 pJ
sum error= 180
Actual label: 6
Output voltages: [0.60745, 0.19603, 0.27465, 0.0038356, 0.032037, 0.026971, 0.79216, 0.0012269, 0.54043, 0.0017507]
Predicted label: 6
Correct prediction
Energy consumption = 149.601981 pJ
sum error= 180
Actual label: 7
Output voltages: [0.10957, 0.037274, 0.03678, 0.10198, 0.01904, 0.013763, 0.0011302, 0.79878, 0.099987, 0.51039]
Predicted label: 7
Correct prediction
Energy consumption = 149.847360 pJ
sum error= 180
Actual label: 6
Output voltages: [0.018751, 0.03302, 0.26967, 0.013036, 0.12149, 0.2448, 0.79879, 0.003301, 0.75134, 0.030245]
Predicted label: 6
Correct prediction
Energy consumption = 154.927006 pJ
sum error= 180
Actual label: 7
Output voltages: [0.62844, 0.0014909, 0.76753, 0.47286, 0.0017678, 0.0010812, 0.0011537, 0.79753, 0.60731, 0.035886]
Predicted label: 7
Correct prediction
Energy consumption = 154.353977 pJ
sum error= 180
Actual label: 9
Output voltages: [0.12387, 0.01024, 0.024177, 0.029362, 0.21252, 0.028255, 0.0026807, 0.019293, 0.5725, 0.7978]
Predicted label: 9
Correct prediction
Energy consumption = 143.878624 pJ
sum error= 180
Actual label: 6
Output voltages: [0.077874, 0.036563, 0.36141, 0.002587, 0.25894, 0.10432, 0.79878, 0.0019929, 0.50823, 0.0038303]
Predicted label: 6
Correct prediction
Energy consumption = 151.161067 pJ
sum error= 180
Actual label: 6
Output voltages: [0.3819, 0.023472, 0.072881, 0.0021551, 0.36614, 0.23719, 0.79877, 0.011334, 0.72357, 0.0043622]
Predicted label: 6
Correct prediction
Energy consumption = 139.428307 pJ
sum error= 180
Actual label: 4
Output voltages: [0.002865, 0.0018732, 0.069781, 0.027691, 0.79875, 0.0024861, 0.017103, 0.026486, 0.49676, 0.00483]
Predicted label: 4
Correct prediction
Energy consumption = 148.781083 pJ
sum error= 180
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 343 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 343 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 343 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.072268, 0.79872, 0.028583, 0.016571, 0.013754, 0.0010659, 0.024373, 0.14981, 0.41511, 0.11008]
Predicted label: 1
Correct prediction
Energy consumption = 165.010094 pJ
sum error= 180
Actual label: 4
Output voltages: [0.012033, 0.010284, 0.054629, 0.0018758, 0.79868, 0.017533, 0.049954, 0.29061, 0.23433, 0.00358]
Predicted label: 4
Correct prediction
Energy consumption = 153.166309 pJ
sum error= 180
Actual label: 3
Output voltages: [0.41913, 0.032747, 0.12377, 0.79878, 0.0026338, 0.43671, 0.003494, 0.052108, 0.67503, 0.0038089]
Predicted label: 3
Correct prediction
Energy consumption = 155.269787 pJ
sum error= 180
Actual label: 1
Output voltages: [0.026538, 0.79858, 0.063413, 0.042499, 0.044399, 0.0030456, 0.7452, 0.0011213, 0.065925, 0.081531]
Predicted label: 1
Correct prediction
Energy consumption = 157.504337 pJ
sum error= 180
Actual label: 1
Output voltages: [0.042196, 0.79846, 0.0018549, 0.089147, 0.035506, 0.0053906, 0.65848, 0.013071, 0.17497, 0.083963]
Predicted label: 1
Correct prediction
Energy consumption = 149.539547 pJ
sum error= 180
Actual label: 2
Output voltages: [0.53386, 0.016524, 0.79869, 0.090639, 0.022787, 0.0011149, 0.025626, 0.033481, 0.33181, 0.0060149]
Predicted label: 2
Correct prediction
Energy consumption = 147.924175 pJ
sum error= 180
Actual label: 2
Output voltages: [0.40836, 0.55443, 0.79739, 0.042117, 0.0022689, 0.0012979, 0.10235, 0.55312, 0.27182, 0.039249]
Predicted label: 2
Correct prediction
Energy consumption = 138.586296 pJ
sum error= 180
Actual label: 4
Output voltages: [0.015286, 0.0029599, 0.18085, 0.031371, 0.79875, 0.0011111, 0.0031944, 0.032991, 0.41937, 0.043768]
Predicted label: 4
Correct prediction
Energy consumption = 160.925733 pJ
sum error= 180
Actual label: 1
Output voltages: [0.014796, 0.79855, 0.32884, 0.017622, 0.014162, 0.0014744, 0.52764, 0.0095036, 0.33517, 0.015536]
Predicted label: 1
Correct prediction
Energy consumption = 161.077632 pJ
sum error= 180
Actual label: 0
Output voltages: [0.79865, 0.055369, 0.10921, 0.037471, 0.081784, 0.0069071, 0.67331, 0.010604, 0.46086, 0.022355]
Predicted label: 0
Correct prediction
Energy consumption = 160.897722 pJ
sum error= 180
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 344 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 344 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 344 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.030731, 0.032278, 0.20012, 0.35832, 0.016757, 0.0065051, 0.022652, 0.0025266, 0.79875, 0.25055]
Predicted label: 8
Correct prediction
Energy consumption = 150.093746 pJ
sum error= 180
Actual label: 7
Output voltages: [0.26126, 0.0071734, 0.72099, 0.0026789, 0.0010691, 0.0021657, 0.0013188, 0.79829, 0.7509, 0.042973]
Predicted label: 7
Correct prediction
Energy consumption = 141.091553 pJ
sum error= 180
Actual label: 6
Output voltages: [0.089859, 0.030952, 0.038517, 0.0030922, 0.16689, 0.42411, 0.79878, 0.0033106, 0.72088, 0.019492]
Predicted label: 6
Correct prediction
Energy consumption = 152.668228 pJ
sum error= 180
Actual label: 3
Output voltages: [0.53005, 0.038174, 0.17045, 0.79866, 0.016276, 0.013238, 0.035981, 0.036323, 0.44133, 0.026645]
Predicted label: 3
Correct prediction
Energy consumption = 144.258916 pJ
sum error= 180
Actual label: 4
Output voltages: [0.012253, 0.035874, 0.04589, 0.0037445, 0.79879, 0.0012483, 0.27898, 0.071952, 0.035347, 0.017533]
Predicted label: 4
Correct prediction
Energy consumption = 149.498649 pJ
sum error= 180
Actual label: 0
Output voltages: [0.79876, 0.11454, 0.025258, 0.01147, 0.0088452, 0.019672, 0.38541, 0.0080164, 0.044152, 0.050575]
Predicted label: 0
Correct prediction
Energy consumption = 157.385532 pJ
sum error= 180
Actual label: 0
Output voltages: [0.79826, 0.024071, 0.37581, 0.032657, 0.045648, 0.0033618, 0.28863, 0.0023452, 0.52927, 0.51348]
Predicted label: 0
Correct prediction
Energy consumption = 146.193238 pJ
sum error= 180
Actual label: 6
Output voltages: [0.35936, 0.035921, 0.33483, 0.001072, 0.73909, 0.019699, 0.79734, 0.0012585, 0.34871, 0.0015825]
Predicted label: 6
Correct prediction
Energy consumption = 142.213138 pJ
sum error= 180
Actual label: 3
Output voltages: [0.77721, 0.0013828, 0.35571, 0.79879, 0.024297, 0.0062209, 0.020154, 0.013557, 0.32286, 0.012221]
Predicted label: 3
Correct prediction
Energy consumption = 140.920784 pJ
sum error= 180
Actual label: 3
Output voltages: [0.24831, 0.038002, 0.043548, 0.79869, 0.0086301, 0.013019, 0.01948, 0.016099, 0.3885, 0.064433]
Predicted label: 3
Correct prediction
Energy consumption = 135.900485 pJ
sum error= 180
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 345 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 345 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 345 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79841, 0.049245, 0.028232, 0.058399, 0.004255, 0.011463, 0.58479, 0.15698, 0.48641, 0.11992]
Predicted label: 0
Correct prediction
Energy consumption = 155.329699 pJ
sum error= 180
Actual label: 7
Output voltages: [0.27848, 0.0016883, 0.029446, 0.48427, 0.010886, 0.23855, 0.001198, 0.68606, 0.23547, 0.75504]
Predicted label: 9
Wrong prediction!
Energy consumption = 156.976347 pJ
sum error= 181
Actual label: 1
Output voltages: [0.35212, 0.79879, 0.70962, 0.051785, 0.23095, 0.0012437, 0.085164, 0.035367, 0.0044582, 0.047618]
Predicted label: 1
Correct prediction
Energy consumption = 165.917052 pJ
sum error= 181
Actual label: 7
Output voltages: [0.28239, 0.23774, 0.50691, 0.449, 0.0010742, 0.0011171, 0.0049061, 0.79593, 0.75526, 0.43924]
Predicted label: 7
Correct prediction
Energy consumption = 158.014633 pJ
sum error= 181
Actual label: 1
Output voltages: [0.038293, 0.79849, 0.11595, 0.16488, 0.051298, 0.0017747, 0.46537, 0.0025988, 0.14531, 0.069492]
Predicted label: 1
Correct prediction
Energy consumption = 160.878891 pJ
sum error= 181
Actual label: 1
Output voltages: [0.1143, 0.79839, 0.030419, 0.14515, 0.0030314, 0.0031728, 0.49554, 0.0061375, 0.31073, 0.053371]
Predicted label: 1
Correct prediction
Energy consumption = 147.633899 pJ
sum error= 181
Actual label: 3
Output voltages: [0.042971, 0.0027867, 0.014342, 0.7978, 0.13463, 0.53413, 0.021559, 0.031467, 0.79353, 0.10318]
Predicted label: 3
Correct prediction
Energy consumption = 144.740107 pJ
sum error= 181
Actual label: 1
Output voltages: [0.081591, 0.79869, 0.02408, 0.27839, 0.0020019, 0.003435, 0.76305, 0.0013514, 0.22699, 0.0097718]
Predicted label: 1
Correct prediction
Energy consumption = 159.605866 pJ
sum error= 181
Actual label: 0
Output voltages: [0.79864, 0.12775, 0.054394, 0.023766, 0.0016019, 0.0093918, 0.70488, 0.017149, 0.064532, 0.047644]
Predicted label: 0
Correct prediction
Energy consumption = 151.243341 pJ
sum error= 181
Actual label: 9
Output voltages: [0.61681, 0.0010965, 0.077415, 0.0022866, 0.34359, 0.0057306, 0.0021057, 0.071525, 0.031561, 0.79577]
Predicted label: 9
Correct prediction
Energy consumption = 150.347334 pJ
sum error= 181
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 346 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 346 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 346 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.19732, 0.0071375, 0.045008, 0.032562, 0.28756, 0.0013145, 0.40018, 0.0016547, 0.13786, 0.78587]
Predicted label: 9
Correct prediction
Energy consumption = 153.562481 pJ
sum error= 181
Actual label: 7
Output voltages: [0.29384, 0.030123, 0.57684, 0.14048, 0.0024398, 0.0011803, 0.0011469, 0.79876, 0.73308, 0.24571]
Predicted label: 7
Correct prediction
Energy consumption = 147.311464 pJ
sum error= 181
Actual label: 5
Output voltages: [0.034226, 0.0038051, 0.0098543, 0.21828, 0.013875, 0.79859, 0.1558, 0.013907, 0.76444, 0.029069]
Predicted label: 5
Correct prediction
Energy consumption = 140.629017 pJ
sum error= 181
Actual label: 4
Output voltages: [0.0048466, 0.0035149, 0.07479, 0.018939, 0.79861, 0.0011282, 0.015283, 0.037779, 0.080739, 0.022465]
Predicted label: 4
Correct prediction
Energy consumption = 153.772675 pJ
sum error= 181
Actual label: 1
Output voltages: [0.43396, 0.79596, 0.69835, 0.20834, 0.25861, 0.0011593, 0.025135, 0.0011979, 0.057456, 0.054667]
Predicted label: 1
Correct prediction
Energy consumption = 158.465368 pJ
sum error= 181
Actual label: 4
Output voltages: [0.040809, 0.024595, 0.1835, 0.048924, 0.79872, 0.012277, 0.047325, 0.036179, 0.016876, 0.33572]
Predicted label: 4
Correct prediction
Energy consumption = 151.689863 pJ
sum error= 181
Actual label: 8
Output voltages: [0.012661, 0.007029, 0.015947, 0.20308, 0.0040406, 0.030412, 0.056728, 0.0018114, 0.79879, 0.31455]
Predicted label: 8
Correct prediction
Energy consumption = 149.059163 pJ
sum error= 181
Actual label: 9
Output voltages: [0.043774, 0.033599, 0.020268, 0.022612, 0.01564, 0.0012546, 0.0012611, 0.020712, 0.67017, 0.79848]
Predicted label: 9
Correct prediction
Energy consumption = 147.243409 pJ
sum error= 181
Actual label: 5
Output voltages: [0.021287, 0.0010861, 0.0036317, 0.21062, 0.036133, 0.7872, 0.37407, 0.005965, 0.77249, 0.18145]
Predicted label: 5
Correct prediction
Energy consumption = 144.703538 pJ
sum error= 181
Actual label: 3
Output voltages: [0.091951, 0.025424, 0.064398, 0.79869, 0.023114, 0.0033638, 0.0099099, 0.018667, 0.43068, 0.12615]
Predicted label: 3
Correct prediction
Energy consumption = 143.784801 pJ
sum error= 181
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 347 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 347 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 347 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.053684, 0.0010959, 0.012493, 0.19291, 0.026271, 0.79879, 0.29956, 0.018508, 0.75897, 0.030562]
Predicted label: 5
Correct prediction
Energy consumption = 153.424826 pJ
sum error= 181
Actual label: 1
Output voltages: [0.17487, 0.79878, 0.0021646, 0.073645, 0.74622, 0.0018104, 0.024347, 0.0014129, 0.20753, 0.3389]
Predicted label: 1
Correct prediction
Energy consumption = 170.105137 pJ
sum error= 181
Actual label: 9
Output voltages: [0.37117, 0.0022832, 0.02131, 0.0062151, 0.36682, 0.083563, 0.023088, 0.034944, 0.28101, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 153.329064 pJ
sum error= 181
Actual label: 8
Output voltages: [0.44188, 0.019297, 0.42541, 0.27154, 0.0021787, 0.0097256, 0.0040705, 0.0043229, 0.79879, 0.63681]
Predicted label: 8
Correct prediction
Energy consumption = 147.688631 pJ
sum error= 181
Actual label: 2
Output voltages: [0.375, 0.74789, 0.79868, 0.078039, 0.059837, 0.0014643, 0.13224, 0.023859, 0.024699, 0.016222]
Predicted label: 2
Correct prediction
Energy consumption = 150.248456 pJ
sum error= 181
Actual label: 3
Output voltages: [0.33425, 0.029998, 0.12306, 0.79875, 0.0010688, 0.014446, 0.0010753, 0.65425, 0.44069, 0.34397]
Predicted label: 3
Correct prediction
Energy consumption = 140.688147 pJ
sum error= 181
Actual label: 3
Output voltages: [0.054725, 0.062514, 0.11533, 0.79878, 0.0028436, 0.0043826, 0.0051276, 0.0073356, 0.48236, 0.035946]
Predicted label: 3
Correct prediction
Energy consumption = 137.905925 pJ
sum error= 181
Actual label: 9
Output voltages: [0.33028, 0.02488, 0.0268, 0.038588, 0.21537, 0.032946, 0.0033392, 0.015197, 0.50425, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 141.306052 pJ
sum error= 181
Actual label: 9
Output voltages: [0.049879, 0.011714, 0.046222, 0.043087, 0.017641, 0.027665, 0.015409, 0.04651, 0.54277, 0.79761]
Predicted label: 9
Correct prediction
Energy consumption = 143.649238 pJ
sum error= 181
Actual label: 0
Output voltages: [0.79876, 0.34788, 0.068093, 0.0080605, 0.010553, 0.0051061, 0.28287, 0.0054104, 0.04742, 0.2114]
Predicted label: 0
Correct prediction
Energy consumption = 147.516335 pJ
sum error= 181
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 348 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 348 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 348 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0052435, 0.79868, 0.22362, 0.23328, 0.2028, 0.0012116, 0.66392, 0.0038097, 0.16865, 0.024069]
Predicted label: 1
Correct prediction
Energy consumption = 165.349045 pJ
sum error= 181
Actual label: 0
Output voltages: [0.79878, 0.051465, 0.024402, 0.01355, 0.074789, 0.0060159, 0.76743, 0.0097823, 0.14077, 0.1331]
Predicted label: 0
Correct prediction
Energy consumption = 155.815019 pJ
sum error= 181
Actual label: 2
Output voltages: [0.38363, 0.57255, 0.79877, 0.057943, 0.014733, 0.0012704, 0.076606, 0.038008, 0.056816, 0.023658]
Predicted label: 2
Correct prediction
Energy consumption = 147.865587 pJ
sum error= 181
Actual label: 9
Output voltages: [0.44924, 0.002033, 0.078472, 0.16263, 0.2415, 0.0071346, 0.016785, 0.11023, 0.086643, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 147.908080 pJ
sum error= 181
Actual label: 3
Output voltages: [0.13832, 0.0079042, 0.10094, 0.79876, 0.02772, 0.0021137, 0.0039687, 0.0085722, 0.7561, 0.01559]
Predicted label: 3
Correct prediction
Energy consumption = 139.494127 pJ
sum error= 181
Actual label: 9
Output voltages: [0.36016, 0.0011154, 0.034201, 0.01395, 0.45805, 0.012557, 0.0055976, 0.050036, 0.45068, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 151.547822 pJ
sum error= 181
Actual label: 3
Output voltages: [0.59185, 0.014311, 0.011511, 0.79861, 0.020009, 0.046914, 0.022541, 0.02479, 0.61861, 0.061029]
Predicted label: 3
Correct prediction
Energy consumption = 145.035159 pJ
sum error= 181
Actual label: 3
Output voltages: [0.51157, 0.046319, 0.050278, 0.79867, 0.016085, 0.0059223, 0.020544, 0.010599, 0.5553, 0.10175]
Predicted label: 3
Correct prediction
Energy consumption = 137.143730 pJ
sum error= 181
Actual label: 6
Output voltages: [0.048907, 0.0021311, 0.17024, 0.0010663, 0.35295, 0.17682, 0.79849, 0.0010662, 0.73733, 0.0062315]
Predicted label: 6
Correct prediction
Energy consumption = 145.609679 pJ
sum error= 181
Actual label: 2
Output voltages: [0.1343, 0.11713, 0.79878, 0.025224, 0.010362, 0.0012727, 0.15051, 0.011522, 0.57126, 0.03158]
Predicted label: 2
Correct prediction
Energy consumption = 143.756903 pJ
sum error= 181
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 349 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 349 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 349 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0018838, 0.047092, 0.13052, 0.0078354, 0.79879, 0.042851, 0.12239, 0.2914, 0.10933, 0.19499]
Predicted label: 4
Correct prediction
Energy consumption = 161.697793 pJ
sum error= 181
Actual label: 9
Output voltages: [0.56521, 0.018852, 0.021112, 0.070993, 0.22396, 0.074528, 0.016524, 0.0287, 0.0202, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.763830 pJ
sum error= 181
Actual label: 8
Output voltages: [0.62728, 0.020891, 0.086394, 0.45533, 0.0035395, 0.015293, 0.076114, 0.001067, 0.79506, 0.53648]
Predicted label: 8
Correct prediction
Energy consumption = 159.797115 pJ
sum error= 181
Actual label: 3
Output voltages: [0.27472, 0.016291, 0.037627, 0.79872, 0.022234, 0.0036245, 0.019318, 0.011781, 0.60465, 0.03693]
Predicted label: 3
Correct prediction
Energy consumption = 140.602434 pJ
sum error= 181
Actual label: 7
Output voltages: [0.0664, 0.09498, 0.77641, 0.22327, 0.0016224, 0.0010721, 0.0050114, 0.79867, 0.30765, 0.42268]
Predicted label: 7
Correct prediction
Energy consumption = 152.695867 pJ
sum error= 181
Actual label: 4
Output voltages: [0.0048824, 0.011157, 0.25218, 0.012215, 0.79857, 0.0024467, 0.046305, 0.0209, 0.039158, 0.049197]
Predicted label: 4
Correct prediction
Energy consumption = 159.645270 pJ
sum error= 181
Actual label: 0
Output voltages: [0.79877, 0.04047, 0.020852, 0.026435, 0.022331, 0.0098227, 0.71859, 0.014031, 0.11439, 0.34543]
Predicted label: 0
Correct prediction
Energy consumption = 158.575072 pJ
sum error= 181
Actual label: 4
Output voltages: [0.017932, 0.0070469, 0.039621, 0.010638, 0.79853, 0.0017442, 0.14033, 0.035685, 0.056737, 0.038616]
Predicted label: 4
Correct prediction
Energy consumption = 156.929196 pJ
sum error= 181
Actual label: 7
Output voltages: [0.41896, 0.037095, 0.073284, 0.00461, 0.0023105, 0.0091105, 0.005826, 0.79877, 0.065212, 0.68588]
Predicted label: 7
Correct prediction
Energy consumption = 160.256225 pJ
sum error= 181
Actual label: 8
Output voltages: [0.041994, 0.21271, 0.11348, 0.025923, 0.042513, 0.0068074, 0.10457, 0.019017, 0.79869, 0.29879]
Predicted label: 8
Correct prediction
Energy consumption = 152.414208 pJ
sum error= 181
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 350 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 350 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 350 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.016738, 0.0048154, 0.16179, 0.0054553, 0.79868, 0.011114, 0.041247, 0.022369, 0.13964, 0.051843]
Predicted label: 4
Correct prediction
Energy consumption = 157.494893 pJ
sum error= 181
Actual label: 9
Output voltages: [0.60601, 0.0040288, 0.013646, 0.0077421, 0.29692, 0.02707, 0.0057354, 0.26582, 0.15663, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 154.103078 pJ
sum error= 181
Actual label: 8
Output voltages: [0.0026403, 0.043054, 0.031721, 0.17548, 0.012582, 0.028427, 0.024964, 0.0040014, 0.79879, 0.40644]
Predicted label: 8
Correct prediction
Energy consumption = 148.999659 pJ
sum error= 181
Actual label: 9
Output voltages: [0.0017504, 0.64525, 0.04983, 0.0011464, 0.59465, 0.0018568, 0.030898, 0.0031937, 0.33604, 0.48383]
Predicted label: 1
Wrong prediction!
Energy consumption = 154.489156 pJ
sum error= 182
Actual label: 9
Output voltages: [0.13898, 0.031877, 0.0033982, 0.39754, 0.24845, 0.0012032, 0.0020342, 0.0011748, 0.3088, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 144.206661 pJ
sum error= 182
Actual label: 7
Output voltages: [0.12239, 0.29248, 0.3491, 0.51915, 0.0010696, 0.0021154, 0.0010663, 0.79878, 0.44105, 0.76936]
Predicted label: 7
Correct prediction
Energy consumption = 154.311365 pJ
sum error= 182
Actual label: 5
Output voltages: [0.054664, 0.0010675, 0.0010948, 0.20469, 0.2251, 0.79879, 0.56597, 0.015492, 0.72547, 0.037911]
Predicted label: 5
Correct prediction
Energy consumption = 146.580545 pJ
sum error= 182
Actual label: 9
Output voltages: [0.30811, 0.01729, 0.011683, 0.030961, 0.027782, 0.038912, 0.028596, 0.042092, 0.29955, 0.79692]
Predicted label: 9
Correct prediction
Energy consumption = 146.246956 pJ
sum error= 182
Actual label: 2
Output voltages: [0.4847, 0.16518, 0.79873, 0.13166, 0.019399, 0.0012551, 0.36118, 0.036015, 0.51199, 0.034624]
Predicted label: 2
Correct prediction
Energy consumption = 152.295843 pJ
sum error= 182
Actual label: 8
Output voltages: [0.032591, 0.023146, 0.22024, 0.10614, 0.0013075, 0.048391, 0.040705, 0.017861, 0.79879, 0.22891]
Predicted label: 8
Correct prediction
Energy consumption = 148.765701 pJ
sum error= 182
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 351 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 351 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 351 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.32395, 0.18408, 0.79879, 0.13089, 0.014032, 0.0013469, 0.34053, 0.01589, 0.39092, 0.038192]
Predicted label: 2
Correct prediction
Energy consumption = 152.928423 pJ
sum error= 182
Actual label: 2
Output voltages: [0.69938, 0.03813, 0.79774, 0.4137, 0.0013017, 0.0011577, 0.0099423, 0.33285, 0.45137, 0.027893]
Predicted label: 2
Correct prediction
Energy consumption = 139.419874 pJ
sum error= 182
Actual label: 0
Output voltages: [0.79857, 0.067164, 0.014028, 0.018065, 0.033485, 0.003364, 0.42623, 0.028019, 0.42519, 0.42349]
Predicted label: 0
Correct prediction
Energy consumption = 155.641220 pJ
sum error= 182
Actual label: 2
Output voltages: [0.274, 0.030628, 0.79875, 0.09246, 0.0063242, 0.0011604, 0.044635, 0.2916, 0.56689, 0.035917]
Predicted label: 2
Correct prediction
Energy consumption = 147.392937 pJ
sum error= 182
Actual label: 2
Output voltages: [0.28588, 0.12531, 0.79876, 0.1624, 0.01162, 0.0012016, 0.28794, 0.023375, 0.72392, 0.026824]
Predicted label: 2
Correct prediction
Energy consumption = 137.450957 pJ
sum error= 182
Actual label: 3
Output voltages: [0.2534, 0.0043139, 0.053058, 0.79871, 0.028703, 0.023604, 0.020043, 0.0063559, 0.43538, 0.058457]
Predicted label: 3
Correct prediction
Energy consumption = 148.505296 pJ
sum error= 182
Actual label: 8
Output voltages: [0.047016, 0.019793, 0.021112, 0.74263, 0.0012746, 0.016937, 0.050152, 0.0017652, 0.79837, 0.23677]
Predicted label: 8
Correct prediction
Energy consumption = 145.792420 pJ
sum error= 182
Actual label: 4
Output voltages: [0.014589, 0.13357, 0.10298, 0.0028242, 0.79872, 0.27925, 0.23672, 0.033076, 0.049334, 0.2539]
Predicted label: 4
Correct prediction
Energy consumption = 155.731682 pJ
sum error= 182
Actual label: 6
Output voltages: [0.14417, 0.12895, 0.16481, 0.0061949, 0.17766, 0.39426, 0.79869, 0.0021976, 0.39326, 0.043017]
Predicted label: 6
Correct prediction
Energy consumption = 149.289556 pJ
sum error= 182
Actual label: 8
Output voltages: [0.052252, 0.020401, 0.03503, 0.55352, 0.0036279, 0.059711, 0.19045, 0.0063313, 0.79878, 0.16818]
Predicted label: 8
Correct prediction
Energy consumption = 150.713684 pJ
sum error= 182
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 352 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 352 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 352 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.010552, 0.012394, 0.031269, 0.001761, 0.78306, 0.063392, 0.73802, 0.048105, 0.53614, 0.20898]
Predicted label: 4
Wrong prediction!
Energy consumption = 137.712387 pJ
sum error= 183
Actual label: 8
Output voltages: [0.18068, 0.010881, 0.093704, 0.18511, 0.0057872, 0.40013, 0.011929, 0.0014807, 0.79876, 0.36668]
Predicted label: 8
Correct prediction
Energy consumption = 147.232137 pJ
sum error= 183
Actual label: 2
Output voltages: [0.30122, 0.5214, 0.79879, 0.060689, 0.016724, 0.0012118, 0.21084, 0.0043371, 0.42821, 0.12939]
Predicted label: 2
Correct prediction
Energy consumption = 152.353694 pJ
sum error= 183
Actual label: 4
Output voltages: [0.06164, 0.030314, 0.056679, 0.010713, 0.79875, 0.0010682, 0.066279, 0.13133, 0.010841, 0.073712]
Predicted label: 4
Correct prediction
Energy consumption = 164.074466 pJ
sum error= 183
Actual label: 6
Output voltages: [0.027709, 0.017874, 0.1272, 0.012404, 0.18166, 0.07441, 0.79879, 0.0040774, 0.60572, 0.013905]
Predicted label: 6
Correct prediction
Energy consumption = 144.018306 pJ
sum error= 183
Actual label: 7
Output voltages: [0.17687, 0.0025185, 0.76925, 0.028981, 0.0047167, 0.0010927, 0.0010672, 0.79879, 0.76808, 0.061327]
Predicted label: 7
Correct prediction
Energy consumption = 140.905881 pJ
sum error= 183
Actual label: 9
Output voltages: [0.28168, 0.012081, 0.022737, 0.05961, 0.49445, 0.018857, 0.037415, 0.0023527, 0.19541, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.454516 pJ
sum error= 183
Actual label: 3
Output voltages: [0.19799, 0.013336, 0.068752, 0.79875, 0.024879, 0.0092388, 0.26403, 0.013064, 0.31551, 0.016605]
Predicted label: 3
Correct prediction
Energy consumption = 148.725551 pJ
sum error= 183
Actual label: 3
Output voltages: [0.28492, 0.0064418, 0.050946, 0.79866, 0.043327, 0.027334, 0.034194, 0.013223, 0.50078, 0.11454]
Predicted label: 3
Correct prediction
Energy consumption = 135.633763 pJ
sum error= 183
Actual label: 9
Output voltages: [0.2317, 0.0010666, 0.015248, 0.019172, 0.24976, 0.029014, 0.0050596, 0.70081, 0.41345, 0.79532]
Predicted label: 9
Correct prediction
Energy consumption = 156.613864 pJ
sum error= 183
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 353 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 353 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 353 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.045189, 0.037655, 0.046628, 0.0034821, 0.79879, 0.0049502, 0.48125, 0.0062657, 0.006962, 0.27035]
Predicted label: 4
Correct prediction
Energy consumption = 165.032871 pJ
sum error= 183
Actual label: 3
Output voltages: [0.20335, 0.040825, 0.018205, 0.79871, 0.0076225, 0.027138, 0.017256, 0.0036575, 0.66374, 0.042132]
Predicted label: 3
Correct prediction
Energy consumption = 146.162942 pJ
sum error= 183
Actual label: 1
Output voltages: [0.024084, 0.79868, 0.076965, 0.77946, 0.0011204, 0.13235, 0.17186, 0.1758, 0.025356, 0.013549]
Predicted label: 1
Correct prediction
Energy consumption = 161.087230 pJ
sum error= 183
Actual label: 4
Output voltages: [0.15713, 0.001356, 0.41659, 0.15054, 0.79837, 0.0095102, 0.011768, 0.10006, 0.013415, 0.31391]
Predicted label: 4
Correct prediction
Energy consumption = 150.300235 pJ
sum error= 183
Actual label: 4
Output voltages: [0.035463, 0.032425, 0.050926, 0.0011557, 0.79879, 0.024689, 0.55442, 0.037155, 0.53416, 0.006384]
Predicted label: 4
Correct prediction
Energy consumption = 146.054164 pJ
sum error= 183
Actual label: 7
Output voltages: [0.42605, 0.035317, 0.0014104, 0.0050144, 0.044674, 0.20663, 0.0010706, 0.7987, 0.14672, 0.1399]
Predicted label: 7
Correct prediction
Energy consumption = 154.168059 pJ
sum error= 183
Actual label: 0
Output voltages: [0.79877, 0.25516, 0.023543, 0.065612, 0.01064, 0.0021716, 0.76132, 0.0063441, 0.15054, 0.25276]
Predicted label: 0
Correct prediction
Energy consumption = 154.631938 pJ
sum error= 183
Actual label: 5
Output voltages: [0.030055, 0.0015254, 0.010764, 0.45051, 0.0056355, 0.78996, 0.013295, 0.0025647, 0.79154, 0.013172]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.269081 pJ
sum error= 184
Actual label: 9
Output voltages: [0.55219, 0.0065861, 0.092777, 0.013597, 0.060992, 0.0083885, 0.0018992, 0.034481, 0.49954, 0.79703]
Predicted label: 9
Correct prediction
Energy consumption = 153.720046 pJ
sum error= 184
Actual label: 6
Output voltages: [0.33643, 0.040763, 0.30322, 0.0038413, 0.30586, 0.054353, 0.79873, 0.0010917, 0.49111, 0.059702]
Predicted label: 6
Correct prediction
Energy consumption = 150.748665 pJ
sum error= 184
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 354 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 354 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 354 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79849, 0.0067826, 0.045807, 0.010164, 0.0064691, 0.0062021, 0.3711, 0.0098497, 0.11554, 0.27986]
Predicted label: 0
Correct prediction
Energy consumption = 141.510556 pJ
sum error= 184
Actual label: 4
Output voltages: [0.0087323, 0.0019664, 0.27814, 0.0084885, 0.79864, 0.012137, 0.053398, 0.072594, 0.047927, 0.041098]
Predicted label: 4
Correct prediction
Energy consumption = 152.081137 pJ
sum error= 184
Actual label: 4
Output voltages: [0.0071506, 0.025776, 0.50679, 0.0016386, 0.79868, 0.0056029, 0.23263, 0.0055667, 0.056007, 0.24457]
Predicted label: 4
Correct prediction
Energy consumption = 140.888778 pJ
sum error= 184
Actual label: 4
Output voltages: [0.0087163, 0.010837, 0.08144, 0.0062221, 0.79871, 0.20305, 0.41383, 0.044152, 0.049469, 0.015053]
Predicted label: 4
Correct prediction
Energy consumption = 136.947390 pJ
sum error= 184
Actual label: 4
Output voltages: [0.0042586, 0.02343, 0.146, 0.0076597, 0.79879, 0.0013492, 0.10296, 0.14232, 0.036429, 0.018377]
Predicted label: 4
Correct prediction
Energy consumption = 140.360200 pJ
sum error= 184
Actual label: 6
Output voltages: [0.05395, 0.14728, 0.3379, 0.0032944, 0.18292, 0.27087, 0.79869, 0.0021678, 0.25323, 0.032705]
Predicted label: 6
Correct prediction
Energy consumption = 149.139240 pJ
sum error= 184
Actual label: 1
Output voltages: [0.023984, 0.79835, 0.16149, 0.061761, 0.01985, 0.0053054, 0.46816, 0.0032771, 0.1608, 0.1792]
Predicted label: 1
Correct prediction
Energy consumption = 162.011773 pJ
sum error= 184
Actual label: 2
Output voltages: [0.57383, 0.0030548, 0.79878, 0.50279, 0.0014743, 0.0010664, 0.052049, 0.13488, 0.61892, 0.0068601]
Predicted label: 2
Correct prediction
Energy consumption = 145.597817 pJ
sum error= 184
Actual label: 3
Output voltages: [0.45615, 0.011309, 0.098653, 0.79864, 0.020034, 0.019416, 0.009525, 0.012812, 0.58936, 0.027555]
Predicted label: 3
Correct prediction
Energy consumption = 139.915693 pJ
sum error= 184
Actual label: 3
Output voltages: [0.52258, 0.0012864, 0.71031, 0.68814, 0.0028374, 0.0010949, 0.01728, 0.047047, 0.78681, 0.0029948]
Predicted label: 8
Wrong prediction!
Energy consumption = 137.362750 pJ
sum error= 185
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 355 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 355 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 355 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.23175, 0.05281, 0.0088322, 0.32315, 0.027935, 0.77714, 0.79879, 0.0021847, 0.49389, 0.030948]
Predicted label: 6
Correct prediction
Energy consumption = 152.546847 pJ
sum error= 185
Actual label: 4
Output voltages: [0.0033077, 0.0045741, 0.12741, 0.076643, 0.79872, 0.0010659, 0.033458, 0.03191, 0.033045, 0.02283]
Predicted label: 4
Correct prediction
Energy consumption = 153.372582 pJ
sum error= 185
Actual label: 5
Output voltages: [0.33133, 0.0011651, 0.0011648, 0.56401, 0.051864, 0.79879, 0.082391, 0.03072, 0.68101, 0.039736]
Predicted label: 5
Correct prediction
Energy consumption = 147.152299 pJ
sum error= 185
Actual label: 9
Output voltages: [0.34475, 0.019301, 0.011299, 0.12244, 0.070674, 0.0073416, 0.017875, 0.022674, 0.25357, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.475542 pJ
sum error= 185
Actual label: 6
Output voltages: [0.06062, 0.028884, 0.064592, 0.0078561, 0.51763, 0.25901, 0.79877, 0.0023924, 0.6564, 0.0036752]
Predicted label: 6
Correct prediction
Energy consumption = 153.768238 pJ
sum error= 185
Actual label: 8
Output voltages: [0.1864, 0.049942, 0.35303, 0.61891, 0.0018003, 0.050659, 0.027358, 0.0035795, 0.79875, 0.063573]
Predicted label: 8
Correct prediction
Energy consumption = 151.376075 pJ
sum error= 185
Actual label: 5
Output voltages: [0.19513, 0.0011727, 0.0010677, 0.038777, 0.022036, 0.79867, 0.35927, 0.052176, 0.77868, 0.0068503]
Predicted label: 5
Correct prediction
Energy consumption = 139.773061 pJ
sum error= 185
Actual label: 6
Output voltages: [0.23, 0.20073, 0.034321, 0.0061782, 0.018158, 0.03345, 0.7958, 0.0046904, 0.68749, 0.0012074]
Predicted label: 6
Correct prediction
Energy consumption = 151.427661 pJ
sum error= 185
Actual label: 5
Output voltages: [0.79878, 0.0014843, 0.012277, 0.14541, 0.020035, 0.026774, 0.32995, 0.0557, 0.0087789, 0.038746]
Predicted label: 0
Wrong prediction!
Energy consumption = 152.591860 pJ
sum error= 186
Actual label: 8
Output voltages: [0.68267, 0.29383, 0.0033049, 0.72469, 0.0010665, 0.64883, 0.45923, 0.013089, 0.74317, 0.0010729]
Predicted label: 8
Correct prediction
Energy consumption = 143.011852 pJ
sum error= 186
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 356 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 356 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 356 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.024299, 0.015224, 0.25049, 0.0025076, 0.16155, 0.27698, 0.79877, 0.0084332, 0.6439, 0.0021014]
Predicted label: 6
Correct prediction
Energy consumption = 148.766981 pJ
sum error= 186
Actual label: 4
Output voltages: [0.014977, 0.0013582, 0.07829, 0.030174, 0.79871, 0.0010826, 0.0079974, 0.018325, 0.55206, 0.041697]
Predicted label: 4
Correct prediction
Energy consumption = 164.377795 pJ
sum error= 186
Actual label: 1
Output voltages: [0.0019658, 0.79868, 0.04368, 0.0062616, 0.030167, 0.0083573, 0.72187, 0.017185, 0.72732, 0.0048528]
Predicted label: 1
Correct prediction
Energy consumption = 153.554852 pJ
sum error= 186
Actual label: 8
Output voltages: [0.061099, 0.005138, 0.011112, 0.49365, 0.0035715, 0.12986, 0.0023087, 0.0072307, 0.79878, 0.053227]
Predicted label: 8
Correct prediction
Energy consumption = 145.474167 pJ
sum error= 186
Actual label: 6
Output voltages: [0.39244, 0.030467, 0.0057843, 0.015473, 0.2856, 0.15819, 0.79832, 0.0042293, 0.70142, 0.0032877]
Predicted label: 6
Correct prediction
Energy consumption = 148.439707 pJ
sum error= 186
Actual label: 5
Output voltages: [0.1022, 0.0010818, 0.013911, 0.47721, 0.0086152, 0.79862, 0.1303, 0.02056, 0.78729, 0.014426]
Predicted label: 5
Correct prediction
Energy consumption = 146.665559 pJ
sum error= 186
Actual label: 2
Output voltages: [0.50883, 0.29143, 0.79879, 0.033197, 0.027063, 0.0013575, 0.42436, 0.045979, 0.29168, 0.040063]
Predicted label: 2
Correct prediction
Energy consumption = 153.898497 pJ
sum error= 186
Actual label: 8
Output voltages: [0.094023, 0.012954, 0.02773, 0.0068966, 0.059521, 0.70748, 0.046592, 0.035682, 0.79677, 0.0076804]
Predicted label: 8
Correct prediction
Energy consumption = 147.527982 pJ
sum error= 186
Actual label: 4
Output voltages: [0.013538, 0.050241, 0.47216, 0.017088, 0.79877, 0.0010741, 0.45293, 0.023289, 0.0097967, 0.13082]
Predicted label: 4
Correct prediction
Energy consumption = 156.665517 pJ
sum error= 186
Actual label: 5
Output voltages: [0.077966, 0.0012852, 0.0052521, 0.36929, 0.020637, 0.79869, 0.073138, 0.21882, 0.77271, 0.015622]
Predicted label: 5
Correct prediction
Energy consumption = 146.723996 pJ
sum error= 186
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 357 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 357 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 357 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.13896, 0.0048211, 0.015026, 0.57614, 0.0078549, 0.79776, 0.14751, 0.0031126, 0.79024, 0.029596]
Predicted label: 5
Correct prediction
Energy consumption = 147.725527 pJ
sum error= 186
Actual label: 4
Output voltages: [0.010815, 0.051172, 0.028492, 0.062993, 0.79811, 0.043261, 0.20246, 0.010632, 0.0099445, 0.38845]
Predicted label: 4
Correct prediction
Energy consumption = 150.139861 pJ
sum error= 186
Actual label: 7
Output voltages: [0.039204, 0.021911, 0.44929, 0.085374, 0.0016368, 0.0011203, 0.0010945, 0.79878, 0.59479, 0.09528]
Predicted label: 7
Correct prediction
Energy consumption = 151.637268 pJ
sum error= 186
Actual label: 7
Output voltages: [0.043161, 0.0016701, 0.7347, 0.25856, 0.059441, 0.0012933, 0.0010871, 0.76574, 0.37755, 0.01437]
Predicted label: 7
Correct prediction
Energy consumption = 140.263174 pJ
sum error= 186
Actual label: 0
Output voltages: [0.79879, 0.042001, 0.043268, 0.017623, 0.0057925, 0.0047827, 0.57875, 0.0067871, 0.14453, 0.62128]
Predicted label: 0
Correct prediction
Energy consumption = 156.434129 pJ
sum error= 186
Actual label: 7
Output voltages: [0.039219, 0.0099079, 0.22808, 0.032275, 0.0050298, 0.0018221, 0.0010724, 0.79869, 0.6935, 0.22022]
Predicted label: 7
Correct prediction
Energy consumption = 133.781319 pJ
sum error= 186
Actual label: 8
Output voltages: [0.0071155, 0.032149, 0.01818, 0.12093, 0.0036552, 0.023626, 0.0064313, 0.012172, 0.79879, 0.4107]
Predicted label: 8
Correct prediction
Energy consumption = 146.194119 pJ
sum error= 186
Actual label: 2
Output voltages: [0.31413, 0.050368, 0.79879, 0.16032, 0.014453, 0.0012307, 0.21933, 0.012404, 0.56964, 0.0223]
Predicted label: 2
Correct prediction
Energy consumption = 144.472676 pJ
sum error= 186
Actual label: 2
Output voltages: [0.75095, 0.65572, 0.79742, 0.023616, 0.0022284, 0.0013821, 0.31642, 0.37614, 0.072071, 0.030744]
Predicted label: 2
Correct prediction
Energy consumption = 136.848385 pJ
sum error= 186
Actual label: 3
Output voltages: [0.69559, 0.024588, 0.085382, 0.7987, 0.0061932, 0.0073577, 0.026036, 0.009629, 0.4435, 0.030127]
Predicted label: 3
Correct prediction
Energy consumption = 141.895533 pJ
sum error= 186
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 358 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 358 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 358 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.26722, 0.3451, 0.5845, 0.32389, 0.0010716, 0.0010885, 0.0010666, 0.79879, 0.63903, 0.061832]
Predicted label: 7
Correct prediction
Energy consumption = 153.198802 pJ
sum error= 186
Actual label: 0
Output voltages: [0.79808, 0.17552, 0.042927, 0.046172, 0.01448, 0.002059, 0.69234, 0.026577, 0.072472, 0.40716]
Predicted label: 0
Correct prediction
Energy consumption = 155.649554 pJ
sum error= 186
Actual label: 1
Output voltages: [0.046211, 0.79869, 0.015447, 0.1829, 0.082379, 0.0064095, 0.072577, 0.0030061, 0.020872, 0.20157]
Predicted label: 1
Correct prediction
Energy consumption = 161.312200 pJ
sum error= 186
Actual label: 8
Output voltages: [0.020697, 0.35849, 0.01732, 0.51308, 0.0014742, 0.04329, 0.0020689, 0.031067, 0.79876, 0.26331]
Predicted label: 8
Correct prediction
Energy consumption = 148.198935 pJ
sum error= 186
Actual label: 0
Output voltages: [0.79877, 0.042092, 0.0097488, 0.0082365, 0.031316, 0.022693, 0.27837, 0.020515, 0.028787, 0.035639]
Predicted label: 0
Correct prediction
Energy consumption = 152.175879 pJ
sum error= 186
Actual label: 7
Output voltages: [0.18559, 0.025959, 0.10185, 0.27165, 0.0058044, 0.0011832, 0.0010764, 0.79879, 0.051085, 0.54723]
Predicted label: 7
Correct prediction
Energy consumption = 159.488654 pJ
sum error= 186
Actual label: 1
Output voltages: [0.022538, 0.79867, 0.14622, 0.11914, 0.018355, 0.0013007, 0.34989, 0.0010691, 0.39374, 0.090164]
Predicted label: 1
Correct prediction
Energy consumption = 157.550855 pJ
sum error= 186
Actual label: 9
Output voltages: [0.065702, 0.0059188, 0.021203, 0.070529, 0.023717, 0.014097, 0.0011463, 0.43968, 0.6396, 0.78395]
Predicted label: 9
Correct prediction
Energy consumption = 152.764230 pJ
sum error= 186
Actual label: 8
Output voltages: [0.0391, 0.023095, 0.087263, 0.62415, 0.0010718, 0.34159, 0.025409, 0.001824, 0.79876, 0.13553]
Predicted label: 8
Correct prediction
Energy consumption = 148.788562 pJ
sum error= 186
Actual label: 7
Output voltages: [0.1249, 0.037687, 0.03062, 0.17251, 0.0087046, 0.0031833, 0.0010675, 0.79855, 0.043109, 0.39783]
Predicted label: 7
Correct prediction
Energy consumption = 159.197841 pJ
sum error= 186
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 359 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 359 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 359 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.22131, 0.0028152, 0.0011321, 0.69124, 0.037303, 0.7987, 0.14621, 0.037221, 0.77182, 0.14716]
Predicted label: 5
Correct prediction
Energy consumption = 151.841712 pJ
sum error= 186
Actual label: 5
Output voltages: [0.22661, 0.0011482, 0.03387, 0.080158, 0.0056447, 0.70911, 0.0042958, 0.029486, 0.79358, 0.52478]
Predicted label: 8
Wrong prediction!
Energy consumption = 136.452562 pJ
sum error= 187
Actual label: 9
Output voltages: [0.2757, 0.010249, 0.33003, 0.085746, 0.0075557, 0.036924, 0.0017733, 0.76514, 0.30282, 0.77933]
Predicted label: 9
Correct prediction
Energy consumption = 149.554487 pJ
sum error= 187
Actual label: 1
Output voltages: [0.051349, 0.79876, 0.038498, 0.0042449, 0.34711, 0.0018697, 0.41269, 0.0011009, 0.067497, 0.16428]
Predicted label: 1
Correct prediction
Energy consumption = 154.172652 pJ
sum error= 187
Actual label: 7
Output voltages: [0.28094, 0.17288, 0.0085191, 0.032288, 0.0026093, 0.0014056, 0.0011836, 0.79879, 0.15809, 0.28643]
Predicted label: 7
Correct prediction
Energy consumption = 154.060338 pJ
sum error= 187
Actual label: 5
Output voltages: [0.038189, 0.0010679, 0.0010659, 0.061218, 0.14897, 0.79879, 0.16387, 0.0051358, 0.76887, 0.0084204]
Predicted label: 5
Correct prediction
Energy consumption = 138.757736 pJ
sum error= 187
Actual label: 4
Output voltages: [0.003507, 0.0043551, 0.19071, 0.001459, 0.79864, 0.0044169, 0.057271, 0.10327, 0.14087, 0.048457]
Predicted label: 4
Correct prediction
Energy consumption = 152.214082 pJ
sum error= 187
Actual label: 9
Output voltages: [0.38252, 0.044481, 0.31399, 0.797, 0.022605, 0.20451, 0.01964, 0.0028147, 0.44106, 0.03275]
Predicted label: 3
Wrong prediction!
Energy consumption = 162.536668 pJ
sum error= 188
Actual label: 1
Output voltages: [0.021002, 0.78483, 0.076608, 0.034186, 0.55048, 0.0017492, 0.0085368, 0.0028156, 0.036712, 0.041943]
Predicted label: 1
Correct prediction
Energy consumption = 152.627923 pJ
sum error= 188
Actual label: 2
Output voltages: [0.66949, 0.46208, 0.79516, 0.15608, 0.011328, 0.0011915, 0.017877, 0.323, 0.050504, 0.025878]
Predicted label: 2
Correct prediction
Energy consumption = 149.227229 pJ
sum error= 188
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 360 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 360 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 360 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.62045, 0.16379, 0.79867, 0.067529, 0.012231, 0.0012503, 0.32048, 0.037771, 0.46544, 0.018929]
Predicted label: 2
Correct prediction
Energy consumption = 150.063861 pJ
sum error= 188
Actual label: 1
Output voltages: [0.15687, 0.46117, 0.030315, 0.0030038, 0.42423, 0.27307, 0.79314, 0.0010892, 0.21955, 0.00239]
Predicted label: 6
Wrong prediction!
Energy consumption = 158.981668 pJ
sum error= 189
Actual label: 6
Output voltages: [0.05772, 0.16663, 0.096387, 0.0073329, 0.26972, 0.25303, 0.79865, 0.0020097, 0.44966, 0.012002]
Predicted label: 6
Correct prediction
Energy consumption = 141.702169 pJ
sum error= 189
Actual label: 6
Output voltages: [0.074849, 0.18345, 0.52583, 0.001265, 0.081514, 0.07778, 0.79872, 0.0037572, 0.61591, 0.0042207]
Predicted label: 6
Correct prediction
Energy consumption = 134.905361 pJ
sum error= 189
Actual label: 7
Output voltages: [0.7984, 0.0013574, 0.24908, 0.018973, 0.0051028, 0.045051, 0.15932, 0.79864, 0.30618, 0.001093]
Predicted label: 7
Correct prediction
Energy consumption = 141.382416 pJ
sum error= 189
Actual label: 1
Output voltages: [0.032768, 0.79872, 0.055689, 0.0036008, 0.042597, 0.0010936, 0.34024, 0.0010701, 0.22726, 0.018022]
Predicted label: 1
Correct prediction
Energy consumption = 161.452233 pJ
sum error= 189
Actual label: 1
Output voltages: [0.0080173, 0.79868, 0.013847, 0.010878, 0.032564, 0.0053973, 0.73508, 0.0028668, 0.74149, 0.019287]
Predicted label: 1
Correct prediction
Energy consumption = 150.458919 pJ
sum error= 189
Actual label: 4
Output voltages: [0.026103, 0.0030063, 0.17079, 0.013916, 0.79816, 0.0013724, 0.0079508, 0.0014966, 0.035022, 0.73735]
Predicted label: 4
Correct prediction
Energy consumption = 162.602419 pJ
sum error= 189
Actual label: 0
Output voltages: [0.79878, 0.084174, 0.039028, 0.019917, 0.0065438, 0.0083107, 0.2839, 0.014318, 0.034015, 0.1188]
Predicted label: 0
Correct prediction
Energy consumption = 154.384389 pJ
sum error= 189
Actual label: 7
Output voltages: [0.035951, 0.045367, 0.27535, 0.13572, 0.0012776, 0.0010806, 0.0011355, 0.79879, 0.17025, 0.23815]
Predicted label: 7
Correct prediction
Energy consumption = 148.806625 pJ
sum error= 189
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 361 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 361 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 361 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0018879, 0.015215, 0.31813, 0.015536, 0.79855, 0.0029108, 0.17234, 0.041218, 0.033732, 0.11338]
Predicted label: 4
Correct prediction
Energy consumption = 150.642889 pJ
sum error= 189
Actual label: 2
Output voltages: [0.40198, 0.051563, 0.79874, 0.04215, 0.0056403, 0.0012875, 0.13165, 0.20638, 0.49869, 0.026092]
Predicted label: 2
Correct prediction
Energy consumption = 153.757504 pJ
sum error= 189
Actual label: 4
Output voltages: [0.01254, 0.048942, 0.062772, 0.0069259, 0.79878, 0.014996, 0.34272, 0.24271, 0.14723, 0.047666]
Predicted label: 4
Correct prediction
Energy consumption = 155.913448 pJ
sum error= 189
Actual label: 0
Output voltages: [0.79878, 0.022928, 0.10999, 0.026737, 0.021023, 0.008937, 0.083263, 0.047345, 0.30696, 0.033477]
Predicted label: 0
Correct prediction
Energy consumption = 159.606619 pJ
sum error= 189
Actual label: 6
Output voltages: [0.38615, 0.014993, 0.11101, 0.0017825, 0.024113, 0.019519, 0.79733, 0.0049703, 0.34817, 0.124]
Predicted label: 6
Correct prediction
Energy consumption = 141.088248 pJ
sum error= 189
Actual label: 4
Output voltages: [0.033264, 0.034907, 0.037406, 0.0077561, 0.79879, 0.0010814, 0.49628, 0.087878, 0.048294, 0.030698]
Predicted label: 4
Correct prediction
Energy consumption = 150.955704 pJ
sum error= 189
Actual label: 7
Output voltages: [0.034614, 0.27921, 0.16935, 0.05474, 0.0078146, 0.0011114, 0.0011006, 0.79862, 0.3186, 0.053427]
Predicted label: 7
Correct prediction
Energy consumption = 150.621535 pJ
sum error= 189
Actual label: 6
Output voltages: [0.23006, 0.36432, 0.30095, 0.046511, 0.057054, 0.30507, 0.79879, 0.013122, 0.69975, 0.0019854]
Predicted label: 6
Correct prediction
Energy consumption = 150.752786 pJ
sum error= 189
Actual label: 9
Output voltages: [0.080986, 0.0098521, 0.035412, 0.019416, 0.018966, 0.014719, 0.0015823, 0.35585, 0.69858, 0.79453]
Predicted label: 9
Correct prediction
Energy consumption = 152.518252 pJ
sum error= 189
Actual label: 5
Output voltages: [0.21212, 0.0024908, 0.001094, 0.74208, 0.023366, 0.79801, 0.041079, 0.0043862, 0.72631, 0.019659]
Predicted label: 5
Correct prediction
Energy consumption = 142.648533 pJ
sum error= 189
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 362 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 362 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 362 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.3556, 0.003671, 0.02537, 0.79876, 0.017706, 0.077324, 0.0055591, 0.025933, 0.55626, 0.029348]
Predicted label: 3
Correct prediction
Energy consumption = 146.524726 pJ
sum error= 189
Actual label: 4
Output voltages: [0.014618, 0.012191, 0.28662, 0.0166, 0.79868, 0.0054004, 0.19947, 0.13869, 0.065581, 0.024772]
Predicted label: 4
Correct prediction
Energy consumption = 153.347063 pJ
sum error= 189
Actual label: 6
Output voltages: [0.057094, 0.053116, 0.4171, 0.001207, 0.3431, 0.031174, 0.79873, 0.0014274, 0.32913, 0.0073671]
Predicted label: 6
Correct prediction
Energy consumption = 146.133349 pJ
sum error= 189
Actual label: 5
Output voltages: [0.36957, 0.030688, 0.0011244, 0.57418, 0.047921, 0.79874, 0.34233, 0.0060522, 0.27352, 0.033273]
Predicted label: 5
Correct prediction
Energy consumption = 150.584284 pJ
sum error= 189
Actual label: 0
Output voltages: [0.79846, 0.034073, 0.038372, 0.014197, 0.0035816, 0.0019072, 0.72389, 0.028793, 0.3079, 0.034662]
Predicted label: 0
Correct prediction
Energy consumption = 147.111495 pJ
sum error= 189
Actual label: 1
Output voltages: [0.025244, 0.79849, 0.010318, 0.060157, 0.0018465, 0.0041922, 0.77165, 0.010381, 0.45036, 0.027986]
Predicted label: 1
Correct prediction
Energy consumption = 157.853732 pJ
sum error= 189
Actual label: 8
Output voltages: [0.097783, 0.057886, 0.10126, 0.79875, 0.0034295, 0.0080502, 0.01225, 0.0028504, 0.79417, 0.12545]
Predicted label: 3
Wrong prediction!
Energy consumption = 154.924323 pJ
sum error= 190
Actual label: 8
Output voltages: [0.030289, 0.03834, 0.3733, 0.0177, 0.094057, 0.0038727, 0.060219, 0.010715, 0.79879, 0.38485]
Predicted label: 8
Correct prediction
Energy consumption = 145.746789 pJ
sum error= 190
Actual label: 2
Output voltages: [0.43455, 0.0048894, 0.79873, 0.145, 0.040581, 0.0012074, 0.21123, 0.15899, 0.57477, 0.029799]
Predicted label: 2
Correct prediction
Energy consumption = 143.566739 pJ
sum error= 190
Actual label: 8
Output voltages: [0.54015, 0.0075379, 0.21617, 0.41124, 0.0036326, 0.016773, 0.024169, 0.0010815, 0.79874, 0.1546]
Predicted label: 8
Correct prediction
Energy consumption = 148.240040 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 363 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 363 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 363 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.5732, 0.014834, 0.4327, 0.79872, 0.037567, 0.030541, 0.0046963, 0.036197, 0.7103, 0.043068]
Predicted label: 3
Correct prediction
Energy consumption = 145.805665 pJ
sum error= 190
Actual label: 5
Output voltages: [0.04116, 0.0011754, 0.015061, 0.40566, 0.007483, 0.79872, 0.11219, 0.041756, 0.76564, 0.052462]
Predicted label: 5
Correct prediction
Energy consumption = 140.582343 pJ
sum error= 190
Actual label: 7
Output voltages: [0.089692, 0.097463, 0.0032871, 0.10619, 0.0011715, 0.0035396, 0.0011588, 0.7964, 0.66447, 0.74914]
Predicted label: 7
Correct prediction
Energy consumption = 152.962765 pJ
sum error= 190
Actual label: 8
Output voltages: [0.0082699, 0.037936, 0.17637, 0.19688, 0.001302, 0.04866, 0.022818, 0.0077604, 0.79875, 0.043743]
Predicted label: 8
Correct prediction
Energy consumption = 150.658308 pJ
sum error= 190
Actual label: 0
Output voltages: [0.78612, 0.056618, 0.24108, 0.026913, 0.012609, 0.001066, 0.52945, 0.044512, 0.15839, 0.43189]
Predicted label: 0
Correct prediction
Energy consumption = 158.169750 pJ
sum error= 190
Actual label: 8
Output voltages: [0.42653, 0.02171, 0.32099, 0.10602, 0.04524, 0.0012823, 0.21799, 0.001091, 0.79812, 0.11918]
Predicted label: 8
Correct prediction
Energy consumption = 150.381021 pJ
sum error= 190
Actual label: 5
Output voltages: [0.0023703, 0.0024044, 0.014023, 0.26108, 0.06235, 0.79423, 0.26008, 0.019951, 0.72169, 0.32014]
Predicted label: 5
Correct prediction
Energy consumption = 139.909604 pJ
sum error= 190
Actual label: 7
Output voltages: [0.036227, 0.27985, 0.2515, 0.018717, 0.013889, 0.0010748, 0.0011567, 0.7987, 0.084677, 0.024664]
Predicted label: 7
Correct prediction
Energy consumption = 156.514081 pJ
sum error= 190
Actual label: 1
Output voltages: [0.0082614, 0.79879, 0.58796, 0.084936, 0.14443, 0.0010802, 0.72226, 0.0013259, 0.038617, 0.0091679]
Predicted label: 1
Correct prediction
Energy consumption = 155.421116 pJ
sum error= 190
Actual label: 1
Output voltages: [0.0024896, 0.79857, 0.10378, 0.48974, 0.032872, 0.0026207, 0.48955, 0.089662, 0.085985, 0.014228]
Predicted label: 1
Correct prediction
Energy consumption = 155.528530 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 364 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 364 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 364 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.25873, 0.26717, 0.012823, 0.011376, 0.0017769, 0.45126, 0.010365, 0.14361, 0.46485]
Predicted label: 0
Correct prediction
Energy consumption = 155.431748 pJ
sum error= 190
Actual label: 1
Output voltages: [0.074393, 0.79846, 0.60516, 0.48054, 0.0083068, 0.0016599, 0.16917, 0.015056, 0.016329, 0.31173]
Predicted label: 1
Correct prediction
Energy consumption = 163.881003 pJ
sum error= 190
Actual label: 3
Output voltages: [0.12226, 0.020137, 0.024887, 0.79865, 0.017458, 0.0045944, 0.011013, 0.02092, 0.56637, 0.044195]
Predicted label: 3
Correct prediction
Energy consumption = 145.729396 pJ
sum error= 190
Actual label: 7
Output voltages: [0.55033, 0.17494, 0.40763, 0.44486, 0.0011137, 0.0010733, 0.00112, 0.79876, 0.561, 0.0088004]
Predicted label: 7
Correct prediction
Energy consumption = 153.882332 pJ
sum error= 190
Actual label: 8
Output voltages: [0.14297, 0.078057, 0.36179, 0.1114, 0.023084, 0.10136, 0.013311, 0.0066477, 0.79869, 0.1246]
Predicted label: 8
Correct prediction
Energy consumption = 145.231992 pJ
sum error= 190
Actual label: 5
Output voltages: [0.022993, 0.0035, 0.0084502, 0.23187, 0.033364, 0.79879, 0.3513, 0.037004, 0.61713, 0.029611]
Predicted label: 5
Correct prediction
Energy consumption = 150.858438 pJ
sum error= 190
Actual label: 0
Output voltages: [0.79534, 0.11738, 0.010703, 0.035693, 0.13232, 0.001066, 0.7472, 0.0019627, 0.33108, 0.068203]
Predicted label: 0
Correct prediction
Energy consumption = 155.459945 pJ
sum error= 190
Actual label: 7
Output voltages: [0.016787, 0.017684, 0.088908, 0.76554, 0.021165, 0.012875, 0.0010866, 0.79844, 0.33758, 0.34326]
Predicted label: 7
Correct prediction
Energy consumption = 158.935904 pJ
sum error= 190
Actual label: 1
Output voltages: [0.024834, 0.79845, 0.046408, 0.036912, 0.021971, 0.0039475, 0.5042, 0.0032422, 0.22708, 0.036319]
Predicted label: 1
Correct prediction
Energy consumption = 163.051907 pJ
sum error= 190
Actual label: 1
Output voltages: [0.030039, 0.79846, 0.077344, 0.026265, 0.0020941, 0.0014734, 0.70775, 0.005083, 0.30826, 0.10322]
Predicted label: 1
Correct prediction
Energy consumption = 149.304794 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 365 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 365 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 365 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79855, 0.085161, 0.32251, 0.025108, 0.0077087, 0.0011434, 0.56431, 0.010103, 0.12969, 0.16261]
Predicted label: 0
Correct prediction
Energy consumption = 157.999930 pJ
sum error= 190
Actual label: 1
Output voltages: [0.05545, 0.79845, 0.06535, 0.32777, 0.074969, 0.0036253, 0.44643, 0.0078409, 0.02281, 0.21158]
Predicted label: 1
Correct prediction
Energy consumption = 164.127843 pJ
sum error= 190
Actual label: 1
Output voltages: [0.013513, 0.79856, 0.022366, 0.041528, 0.021186, 0.0012082, 0.72456, 0.012205, 0.33777, 0.020426]
Predicted label: 1
Correct prediction
Energy consumption = 152.179021 pJ
sum error= 190
Actual label: 4
Output voltages: [0.026587, 0.024343, 0.34593, 0.005912, 0.79877, 0.0010697, 0.19715, 0.16365, 0.013928, 0.50586]
Predicted label: 4
Correct prediction
Energy consumption = 159.121903 pJ
sum error= 190
Actual label: 5
Output voltages: [0.2554, 0.042581, 0.0060744, 0.17532, 0.018652, 0.78976, 0.75793, 0.0013858, 0.74569, 0.024179]
Predicted label: 5
Correct prediction
Energy consumption = 161.561708 pJ
sum error= 190
Actual label: 2
Output voltages: [0.41928, 0.4711, 0.79879, 0.068845, 0.023387, 0.0013483, 0.37555, 0.029864, 0.28003, 0.18524]
Predicted label: 2
Correct prediction
Energy consumption = 155.208076 pJ
sum error= 190
Actual label: 7
Output voltages: [0.057053, 0.012068, 0.028032, 0.75551, 0.022865, 0.023129, 0.0011628, 0.79872, 0.27516, 0.47609]
Predicted label: 7
Correct prediction
Energy consumption = 146.629143 pJ
sum error= 190
Actual label: 6
Output voltages: [0.09708, 0.18127, 0.3548, 0.0012662, 0.49758, 0.087844, 0.79872, 0.0011854, 0.025514, 0.027343]
Predicted label: 6
Correct prediction
Energy consumption = 154.065196 pJ
sum error= 190
Actual label: 2
Output voltages: [0.14813, 0.55315, 0.79879, 0.077602, 0.0098152, 0.0012698, 0.090014, 0.066038, 0.22117, 0.029208]
Predicted label: 2
Correct prediction
Energy consumption = 153.493101 pJ
sum error= 190
Actual label: 3
Output voltages: [0.22146, 0.012865, 0.045746, 0.79863, 0.026131, 0.016493, 0.01306, 0.044439, 0.48527, 0.21485]
Predicted label: 3
Correct prediction
Energy consumption = 138.603071 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 366 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 366 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 366 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79866, 0.041404, 0.023845, 0.0064987, 0.0020685, 0.0025276, 0.63767, 0.01722, 0.2214, 0.03611]
Predicted label: 0
Correct prediction
Energy consumption = 154.799217 pJ
sum error= 190
Actual label: 2
Output voltages: [0.4278, 0.098744, 0.79861, 0.46169, 0.020046, 0.0011079, 0.079121, 0.037263, 0.41393, 0.0099201]
Predicted label: 2
Correct prediction
Energy consumption = 146.370640 pJ
sum error= 190
Actual label: 8
Output voltages: [0.31812, 0.0088369, 0.097987, 0.055254, 0.030626, 0.020491, 0.38809, 0.0011042, 0.79862, 0.0027909]
Predicted label: 8
Correct prediction
Energy consumption = 142.292194 pJ
sum error= 190
Actual label: 5
Output voltages: [0.0097376, 0.0036119, 0.0013751, 0.25317, 0.010292, 0.79547, 0.050671, 0.055856, 0.50373, 0.39695]
Predicted label: 5
Correct prediction
Energy consumption = 150.464560 pJ
sum error= 190
Actual label: 9
Output voltages: [0.051792, 0.02463, 0.068018, 0.17996, 0.064106, 0.0097977, 0.037663, 0.017556, 0.53078, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 144.178764 pJ
sum error= 190
Actual label: 6
Output voltages: [0.32172, 0.0084938, 0.27658, 0.0013021, 0.22018, 0.097969, 0.79874, 0.0044818, 0.43496, 0.026394]
Predicted label: 6
Correct prediction
Energy consumption = 144.583502 pJ
sum error= 190
Actual label: 9
Output voltages: [0.062037, 0.014584, 0.02384, 0.037634, 0.040835, 0.037134, 0.012288, 0.24173, 0.5285, 0.79341]
Predicted label: 9
Correct prediction
Energy consumption = 153.015478 pJ
sum error= 190
Actual label: 7
Output voltages: [0.58224, 0.032226, 0.15522, 0.021856, 0.011456, 0.0010935, 0.0030043, 0.79871, 0.30108, 0.027999]
Predicted label: 7
Correct prediction
Energy consumption = 153.459459 pJ
sum error= 190
Actual label: 2
Output voltages: [0.55345, 0.0054267, 0.79879, 0.2166, 0.045636, 0.0010825, 0.035183, 0.17704, 0.46759, 0.011528]
Predicted label: 2
Correct prediction
Energy consumption = 142.633042 pJ
sum error= 190
Actual label: 1
Output voltages: [0.023061, 0.79851, 0.0092237, 0.068879, 0.041931, 0.017619, 0.21854, 0.0075941, 0.065149, 0.35623]
Predicted label: 1
Correct prediction
Energy consumption = 164.147656 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 367 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 367 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 367 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.4468, 0.010137, 0.37447, 0.79869, 0.036231, 0.0093364, 0.0094704, 0.025485, 0.71031, 0.036159]
Predicted label: 3
Correct prediction
Energy consumption = 141.638603 pJ
sum error= 190
Actual label: 6
Output voltages: [0.45135, 0.02869, 0.06043, 0.029225, 0.30893, 0.73885, 0.79879, 0.001971, 0.56926, 0.010765]
Predicted label: 6
Correct prediction
Energy consumption = 150.717769 pJ
sum error= 190
Actual label: 4
Output voltages: [0.001184, 0.0079161, 0.043123, 0.0042074, 0.79872, 0.0013344, 0.42458, 0.17443, 0.03673, 0.025098]
Predicted label: 4
Correct prediction
Energy consumption = 146.281188 pJ
sum error= 190
Actual label: 1
Output voltages: [0.012573, 0.79861, 0.029625, 0.35465, 0.44601, 0.0020379, 0.24436, 0.021374, 0.079501, 0.15982]
Predicted label: 1
Correct prediction
Energy consumption = 168.607729 pJ
sum error= 190
Actual label: 8
Output voltages: [0.024107, 0.0016691, 0.015685, 0.2164, 0.0022918, 0.70419, 0.018214, 0.0027641, 0.79856, 0.057939]
Predicted label: 8
Correct prediction
Energy consumption = 147.861886 pJ
sum error= 190
Actual label: 2
Output voltages: [0.70054, 0.010383, 0.79875, 0.066999, 0.034474, 0.0010694, 0.040496, 0.11024, 0.58744, 0.013606]
Predicted label: 2
Correct prediction
Energy consumption = 145.790848 pJ
sum error= 190
Actual label: 4
Output voltages: [0.010881, 0.010439, 0.28386, 0.019299, 0.79866, 0.0024542, 0.090835, 0.0315, 0.17477, 0.040611]
Predicted label: 4
Correct prediction
Energy consumption = 151.941282 pJ
sum error= 190
Actual label: 0
Output voltages: [0.79879, 0.057684, 0.020006, 0.11651, 0.013263, 0.15974, 0.7383, 0.068984, 0.28404, 0.023408]
Predicted label: 0
Correct prediction
Energy consumption = 152.539877 pJ
sum error= 190
Actual label: 5
Output voltages: [0.070948, 0.0010873, 0.036999, 0.10211, 0.0029954, 0.79843, 0.13561, 0.01867, 0.79246, 0.01188]
Predicted label: 5
Correct prediction
Energy consumption = 142.845117 pJ
sum error= 190
Actual label: 1
Output voltages: [0.01899, 0.79858, 0.0018, 0.03868, 0.33918, 0.005777, 0.31165, 0.0028468, 0.30368, 0.25612]
Predicted label: 1
Correct prediction
Energy consumption = 165.970638 pJ
sum error= 190
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 368 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 368 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 368 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79858, 0.037813, 0.032526, 0.1994, 0.0031742, 0.29132, 0.034258, 0.026924, 0.13447, 0.017679]
Predicted label: 0
Correct prediction
Energy consumption = 152.183526 pJ
sum error= 190
Actual label: 2
Output voltages: [0.10435, 0.0028314, 0.75841, 0.78146, 0.0020736, 0.0072264, 0.012154, 0.0014411, 0.77782, 0.001909]
Predicted label: 3
Wrong prediction!
Energy consumption = 137.668996 pJ
sum error= 191
Actual label: 2
Output voltages: [0.75318, 0.0017702, 0.79839, 0.17879, 0.0069987, 0.0010744, 0.028725, 0.10017, 0.52746, 0.0085164]
Predicted label: 2
Correct prediction
Energy consumption = 139.280971 pJ
sum error= 191
Actual label: 6
Output voltages: [0.05196, 0.30799, 0.42614, 0.001953, 0.33126, 0.16918, 0.79866, 0.0044792, 0.16399, 0.0082208]
Predicted label: 6
Correct prediction
Energy consumption = 155.321737 pJ
sum error= 191
Actual label: 4
Output voltages: [0.0213, 0.0048668, 0.15659, 0.022, 0.79866, 0.0028597, 0.17578, 0.062067, 0.020252, 0.098722]
Predicted label: 4
Correct prediction
Energy consumption = 149.645945 pJ
sum error= 191
Actual label: 4
Output voltages: [0.035598, 0.013295, 0.53999, 0.0097446, 0.79875, 0.0011545, 0.25726, 0.090302, 0.023302, 0.023892]
Predicted label: 4
Correct prediction
Energy consumption = 144.930560 pJ
sum error= 191
Actual label: 3
Output voltages: [0.16005, 0.038176, 0.030517, 0.79878, 0.0028124, 0.0028986, 0.01006, 0.016201, 0.78449, 0.027828]
Predicted label: 3
Correct prediction
Energy consumption = 154.101456 pJ
sum error= 191
Actual label: 9
Output voltages: [0.15374, 0.023277, 0.032865, 0.20961, 0.27225, 0.024094, 0.046163, 0.0020362, 0.30462, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 143.891695 pJ
sum error= 191
Actual label: 6
Output voltages: [0.34604, 0.51509, 0.012536, 0.040188, 0.015184, 0.41865, 0.79879, 0.018102, 0.69828, 0.0012048]
Predicted label: 6
Correct prediction
Energy consumption = 160.330525 pJ
sum error= 191
Actual label: 1
Output voltages: [0.0095155, 0.79842, 0.023004, 0.089447, 0.038967, 0.004894, 0.47857, 0.075905, 0.13614, 0.029273]
Predicted label: 1
Correct prediction
Energy consumption = 163.053333 pJ
sum error= 191
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 369 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 369 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 369 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.3516, 0.076543, 0.044877, 0.010883, 0.55271, 0.43518, 0.79879, 0.002652, 0.50192, 0.0034187]
Predicted label: 6
Correct prediction
Energy consumption = 151.959197 pJ
sum error= 191
Actual label: 5
Output voltages: [0.019646, 0.0011012, 0.0025872, 0.10642, 0.043637, 0.79695, 0.094743, 0.028073, 0.79669, 0.038751]
Predicted label: 5
Correct prediction
Energy consumption = 137.172825 pJ
sum error= 191
Actual label: 7
Output voltages: [0.2079, 0.018862, 0.056002, 0.1101, 0.028845, 0.03987, 0.0011082, 0.79845, 0.16143, 0.44791]
Predicted label: 7
Correct prediction
Energy consumption = 149.486758 pJ
sum error= 191
Actual label: 9
Output voltages: [0.057772, 0.002836, 0.018455, 0.016551, 0.45871, 0.001123, 0.002975, 0.036103, 0.28924, 0.7975]
Predicted label: 9
Correct prediction
Energy consumption = 152.420624 pJ
sum error= 191
Actual label: 2
Output voltages: [0.21686, 0.4998, 0.79879, 0.037634, 0.014566, 0.0012403, 0.066547, 0.0074725, 0.18098, 0.076844]
Predicted label: 2
Correct prediction
Energy consumption = 147.260585 pJ
sum error= 191
Actual label: 0
Output voltages: [0.79871, 0.027637, 0.04418, 0.0033261, 0.012997, 0.0013057, 0.55375, 0.12515, 0.16384, 0.07999]
Predicted label: 0
Correct prediction
Energy consumption = 146.521699 pJ
sum error= 191
Actual label: 2
Output voltages: [0.22019, 0.093464, 0.79879, 0.041756, 0.0085321, 0.0013787, 0.23071, 0.019988, 0.44236, 0.029938]
Predicted label: 2
Correct prediction
Energy consumption = 142.536313 pJ
sum error= 191
Actual label: 6
Output voltages: [0.36819, 0.042656, 0.037585, 0.018295, 0.25489, 0.51156, 0.79871, 0.0011511, 0.44736, 0.028038]
Predicted label: 6
Correct prediction
Energy consumption = 148.392308 pJ
sum error= 191
Actual label: 0
Output voltages: [0.79878, 0.19219, 0.074404, 0.024874, 0.02035, 0.0077465, 0.44193, 0.023586, 0.080469, 0.33196]
Predicted label: 0
Correct prediction
Energy consumption = 152.304856 pJ
sum error= 191
Actual label: 1
Output voltages: [0.046203, 0.79855, 0.27665, 0.042703, 0.027913, 0.0016991, 0.47908, 0.001594, 0.24567, 0.028284]
Predicted label: 1
Correct prediction
Energy consumption = 165.516184 pJ
sum error= 191
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 370 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 370 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 370 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0073988, 0.0051369, 0.041724, 0.057753, 0.79872, 0.001075, 0.021604, 0.016854, 0.04718, 0.015257]
Predicted label: 4
Correct prediction
Energy consumption = 157.901579 pJ
sum error= 191
Actual label: 3
Output voltages: [0.70692, 0.01347, 0.13789, 0.79872, 0.0064616, 0.010853, 0.012524, 0.013356, 0.45152, 0.048219]
Predicted label: 3
Correct prediction
Energy consumption = 150.093621 pJ
sum error= 191
Actual label: 5
Output voltages: [0.0019239, 0.0011531, 0.0029352, 0.7885, 0.6671, 0.77277, 0.1119, 0.03218, 0.064434, 0.060914]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.345641 pJ
sum error= 192
Actual label: 2
Output voltages: [0.13682, 0.7469, 0.7925, 0.20771, 0.034202, 0.0013285, 0.037603, 0.021295, 0.032548, 0.026373]
Predicted label: 2
Correct prediction
Energy consumption = 153.578330 pJ
sum error= 192
Actual label: 8
Output voltages: [0.017468, 0.21702, 0.03585, 0.12284, 0.0026014, 0.023163, 0.012983, 0.021473, 0.79879, 0.3002]
Predicted label: 8
Correct prediction
Energy consumption = 149.767886 pJ
sum error= 192
Actual label: 8
Output voltages: [0.21647, 0.038772, 0.65027, 0.053177, 0.0013592, 0.03208, 0.051661, 0.032176, 0.79874, 0.02269]
Predicted label: 8
Correct prediction
Energy consumption = 142.097012 pJ
sum error= 192
Actual label: 0
Output voltages: [0.79853, 0.017497, 0.071997, 0.00348, 0.0040637, 0.0025999, 0.27459, 0.025309, 0.42966, 0.044394]
Predicted label: 0
Correct prediction
Energy consumption = 151.669508 pJ
sum error= 192
Actual label: 8
Output voltages: [0.00327, 0.037272, 0.13403, 0.02016, 0.013017, 0.0067046, 0.054082, 0.042636, 0.79878, 0.29837]
Predicted label: 8
Correct prediction
Energy consumption = 150.662477 pJ
sum error= 192
Actual label: 8
Output voltages: [0.17613, 0.0024006, 0.20598, 0.034919, 0.0087135, 0.13374, 0.031842, 0.015485, 0.79878, 0.25199]
Predicted label: 8
Correct prediction
Energy consumption = 142.190386 pJ
sum error= 192
Actual label: 9
Output voltages: [0.46981, 0.02446, 0.010542, 0.014014, 0.029061, 0.026655, 0.0017633, 0.61971, 0.16583, 0.7941]
Predicted label: 9
Correct prediction
Energy consumption = 152.738537 pJ
sum error= 192
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 371 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 371 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 371 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79161, 0.050974, 0.4428, 0.0012407, 0.001223, 0.0010743, 0.24046, 0.012564, 0.51415, 0.15629]
Predicted label: 0
Correct prediction
Energy consumption = 153.084834 pJ
sum error= 192
Actual label: 9
Output voltages: [0.091364, 0.029307, 0.037354, 0.051461, 0.26265, 0.01544, 0.003548, 0.018858, 0.39769, 0.79865]
Predicted label: 9
Correct prediction
Energy consumption = 154.938594 pJ
sum error= 192
Actual label: 6
Output voltages: [0.14116, 0.023841, 0.16993, 0.0019725, 0.27858, 0.13608, 0.79868, 0.0068373, 0.40608, 0.024241]
Predicted label: 6
Correct prediction
Energy consumption = 142.997008 pJ
sum error= 192
Actual label: 7
Output voltages: [0.16186, 0.0095173, 0.64095, 0.19229, 0.0012698, 0.0010811, 0.007002, 0.79868, 0.31258, 0.054904]
Predicted label: 7
Correct prediction
Energy consumption = 147.462220 pJ
sum error= 192
Actual label: 6
Output voltages: [0.06796, 0.053426, 0.032818, 0.012585, 0.06412, 0.76274, 0.79879, 0.018624, 0.47224, 0.0055913]
Predicted label: 6
Correct prediction
Energy consumption = 150.653728 pJ
sum error= 192
Actual label: 3
Output voltages: [0.13944, 0.0065657, 0.64521, 0.79823, 0.0048103, 0.0010714, 0.0050327, 0.011247, 0.33718, 0.24919]
Predicted label: 3
Correct prediction
Energy consumption = 148.497412 pJ
sum error= 192
Actual label: 9
Output voltages: [0.21454, 0.0015126, 0.013919, 0.11114, 0.040546, 0.019244, 0.002624, 0.003485, 0.70458, 0.77671]
Predicted label: 9
Correct prediction
Energy consumption = 146.863184 pJ
sum error= 192
Actual label: 3
Output voltages: [0.37946, 0.03448, 0.039624, 0.79859, 0.017745, 0.018518, 0.017606, 0.026785, 0.43785, 0.10101]
Predicted label: 3
Correct prediction
Energy consumption = 141.574844 pJ
sum error= 192
Actual label: 4
Output voltages: [0.0057862, 0.0013841, 0.043337, 0.013798, 0.7925, 0.0016502, 0.001066, 0.0041118, 0.42904, 0.32395]
Predicted label: 4
Correct prediction
Energy consumption = 148.430294 pJ
sum error= 192
Actual label: 7
Output voltages: [0.068088, 0.064447, 0.30785, 0.054766, 0.0038913, 0.0010664, 0.002364, 0.79859, 0.039165, 0.32874]
Predicted label: 7
Correct prediction
Energy consumption = 158.692398 pJ
sum error= 192
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 372 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 372 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 372 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.12935, 0.0038026, 0.023125, 0.77334, 0.0057293, 0.047943, 0.0010861, 0.79819, 0.23359, 0.7397]
Predicted label: 7
Correct prediction
Energy consumption = 154.951334 pJ
sum error= 192
Actual label: 7
Output voltages: [0.35462, 0.65369, 0.071502, 0.75255, 0.0026126, 0.0010683, 0.0021074, 0.78766, 0.017292, 0.39189]
Predicted label: 7
Correct prediction
Energy consumption = 153.187789 pJ
sum error= 192
Actual label: 4
Output voltages: [0.12047, 0.0019074, 0.29667, 0.0022968, 0.79879, 0.0034471, 0.014284, 0.33708, 0.031469, 0.59455]
Predicted label: 4
Correct prediction
Energy consumption = 155.644773 pJ
sum error= 192
Actual label: 9
Output voltages: [0.75956, 0.010574, 0.026321, 0.032698, 0.0038608, 0.0094305, 0.4232, 0.0039913, 0.12695, 0.77101]
Predicted label: 9
Correct prediction
Energy consumption = 150.252253 pJ
sum error= 192
Actual label: 0
Output voltages: [0.79874, 0.029887, 0.015146, 0.018405, 0.015845, 0.022338, 0.41719, 0.019177, 0.36802, 0.03499]
Predicted label: 0
Correct prediction
Energy consumption = 142.930867 pJ
sum error= 192
Actual label: 6
Output voltages: [0.031909, 0.08117, 0.056385, 0.037394, 0.26164, 0.47042, 0.79867, 0.032901, 0.47104, 0.012112]
Predicted label: 6
Correct prediction
Energy consumption = 148.021766 pJ
sum error= 192
Actual label: 4
Output voltages: [0.016862, 0.031109, 0.031002, 0.059872, 0.79878, 0.0011012, 0.001079, 0.031566, 0.004639, 0.68965]
Predicted label: 4
Correct prediction
Energy consumption = 154.876394 pJ
sum error= 192
Actual label: 8
Output voltages: [0.22741, 0.0011756, 0.009842, 0.60727, 0.19626, 0.21365, 0.01722, 0.0011153, 0.78441, 0.218]
Predicted label: 8
Correct prediction
Energy consumption = 147.475122 pJ
sum error= 192
Actual label: 4
Output voltages: [0.0085989, 0.0024053, 0.066513, 0.029192, 0.79879, 0.0044405, 0.015905, 0.032082, 0.035587, 0.5675]
Predicted label: 4
Correct prediction
Energy consumption = 155.125452 pJ
sum error= 192
Actual label: 2
Output voltages: [0.72451, 0.0035279, 0.79837, 0.39091, 0.016864, 0.0010841, 0.11548, 0.19939, 0.72301, 0.039309]
Predicted label: 2
Correct prediction
Energy consumption = 152.087442 pJ
sum error= 192
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 373 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 373 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 373 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.4041, 0.0014432, 0.021734, 0.15919, 0.020924, 0.15798, 0.0010884, 0.79878, 0.51459, 0.68929]
Predicted label: 7
Correct prediction
Energy consumption = 157.620033 pJ
sum error= 192
Actual label: 2
Output voltages: [0.63502, 0.015681, 0.7983, 0.38863, 0.006704, 0.0012028, 0.013208, 0.068116, 0.38323, 0.0055887]
Predicted label: 2
Correct prediction
Energy consumption = 146.017894 pJ
sum error= 192
Actual label: 8
Output voltages: [0.031878, 0.43486, 0.047217, 0.61484, 0.0012928, 0.021396, 0.037659, 0.013061, 0.79879, 0.043514]
Predicted label: 8
Correct prediction
Energy consumption = 151.952208 pJ
sum error= 192
Actual label: 1
Output voltages: [0.075079, 0.7987, 0.19505, 0.023762, 0.66901, 0.0024084, 0.15332, 0.013214, 0.036746, 0.0052362]
Predicted label: 1
Correct prediction
Energy consumption = 153.571489 pJ
sum error= 192
Actual label: 0
Output voltages: [0.79758, 0.020341, 0.0088334, 0.032417, 0.0041021, 0.21743, 0.55214, 0.0034022, 0.16681, 0.11259]
Predicted label: 0
Correct prediction
Energy consumption = 158.066947 pJ
sum error= 192
Actual label: 0
Output voltages: [0.79878, 0.06049, 0.017405, 0.023309, 0.0049832, 0.083361, 0.34508, 0.011996, 0.28594, 0.28265]
Predicted label: 0
Correct prediction
Energy consumption = 145.760636 pJ
sum error= 192
Actual label: 7
Output voltages: [0.038235, 0.78678, 0.17148, 0.38355, 0.00107, 0.0011422, 0.0011846, 0.78111, 0.037589, 0.024955]
Predicted label: 1
Wrong prediction!
Energy consumption = 159.432095 pJ
sum error= 193
Actual label: 8
Output voltages: [0.0076203, 0.0038877, 0.01897, 0.062918, 0.028287, 0.062066, 0.044697, 0.0091674, 0.79879, 0.0054184]
Predicted label: 8
Correct prediction
Energy consumption = 141.759160 pJ
sum error= 193
Actual label: 3
Output voltages: [0.58838, 0.19549, 0.14863, 0.79879, 0.0012106, 0.03815, 0.29852, 0.060596, 0.044983, 0.0019306]
Predicted label: 3
Correct prediction
Energy consumption = 145.705172 pJ
sum error= 193
Actual label: 3
Output voltages: [0.53877, 0.023236, 0.030635, 0.7986, 0.004013, 0.040774, 0.031025, 0.04661, 0.63792, 0.080103]
Predicted label: 3
Correct prediction
Energy consumption = 137.860719 pJ
sum error= 193
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 374 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 374 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 374 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.59862, 0.056359, 0.0035286, 0.79879, 0.0014342, 0.036293, 0.0093007, 0.05743, 0.51467, 0.0022356]
Predicted label: 3
Correct prediction
Energy consumption = 148.442710 pJ
sum error= 193
Actual label: 1
Output voltages: [0.015531, 0.79856, 0.023911, 0.13894, 0.06068, 0.0054999, 0.64693, 0.0027275, 0.049149, 0.17078]
Predicted label: 1
Correct prediction
Energy consumption = 160.275899 pJ
sum error= 193
Actual label: 3
Output voltages: [0.0026674, 0.038776, 0.092606, 0.79389, 0.0058894, 0.0010693, 0.0066488, 0.027477, 0.6869, 0.47149]
Predicted label: 3
Correct prediction
Energy consumption = 152.706403 pJ
sum error= 193
Actual label: 7
Output voltages: [0.043842, 0.024788, 0.080364, 0.029462, 0.0015027, 0.0022818, 0.0011915, 0.79878, 0.74868, 0.42948]
Predicted label: 7
Correct prediction
Energy consumption = 144.587575 pJ
sum error= 193
Actual label: 6
Output voltages: [0.29708, 0.026348, 0.016158, 0.0025517, 0.14224, 0.33287, 0.79768, 0.017642, 0.76921, 0.003484]
Predicted label: 6
Correct prediction
Energy consumption = 142.622825 pJ
sum error= 193
Actual label: 1
Output voltages: [0.12564, 0.79866, 0.03307, 0.42187, 0.023807, 0.004697, 0.15642, 0.0010976, 0.38263, 0.23482]
Predicted label: 1
Correct prediction
Energy consumption = 163.827886 pJ
sum error= 193
Actual label: 3
Output voltages: [0.049825, 0.022454, 0.060479, 0.79864, 0.017473, 0.010058, 0.017842, 0.24037, 0.44779, 0.21185]
Predicted label: 3
Correct prediction
Energy consumption = 147.463704 pJ
sum error= 193
Actual label: 1
Output voltages: [0.0035277, 0.79869, 0.025211, 0.081515, 0.021767, 0.04868, 0.031217, 0.034339, 0.42078, 0.083284]
Predicted label: 1
Correct prediction
Energy consumption = 160.817295 pJ
sum error= 193
Actual label: 6
Output voltages: [0.16036, 0.080834, 0.028, 0.084923, 0.025733, 0.14174, 0.79866, 0.010539, 0.63567, 0.0052928]
Predicted label: 6
Correct prediction
Energy consumption = 149.266119 pJ
sum error= 193
Actual label: 6
Output voltages: [0.77364, 0.015753, 0.033476, 0.0026129, 0.02681, 0.0038254, 0.78805, 0.0039588, 0.1318, 0.059933]
Predicted label: 6
Correct prediction
Energy consumption = 156.452162 pJ
sum error= 193
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 375 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 375 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 375 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.042286, 0.0011318, 0.011064, 0.13852, 0.025368, 0.79628, 0.036779, 0.003445, 0.78741, 0.042641]
Predicted label: 5
Correct prediction
Energy consumption = 138.855920 pJ
sum error= 193
Actual label: 7
Output voltages: [0.0079428, 0.25749, 0.30421, 0.064078, 0.002203, 0.0010838, 0.00399, 0.79598, 0.73513, 0.025981]
Predicted label: 7
Correct prediction
Energy consumption = 145.394976 pJ
sum error= 193
Actual label: 4
Output voltages: [0.018014, 0.001471, 0.21331, 0.0071001, 0.79858, 0.0010877, 0.55758, 0.033708, 0.031552, 0.047297]
Predicted label: 4
Correct prediction
Energy consumption = 153.364061 pJ
sum error= 193
Actual label: 7
Output voltages: [0.041122, 0.11106, 0.62588, 0.23478, 0.0024033, 0.0010887, 0.0011157, 0.79879, 0.38661, 0.28305]
Predicted label: 7
Correct prediction
Energy consumption = 152.520967 pJ
sum error= 193
Actual label: 5
Output voltages: [0.0068868, 0.0011116, 0.0048131, 0.31681, 0.17433, 0.79852, 0.14725, 0.039015, 0.77156, 0.15219]
Predicted label: 5
Correct prediction
Energy consumption = 144.704807 pJ
sum error= 193
Actual label: 9
Output voltages: [0.32996, 0.055062, 0.42206, 0.017966, 0.57365, 0.0016206, 0.013476, 0.014921, 0.22259, 0.77655]
Predicted label: 9
Correct prediction
Energy consumption = 157.324404 pJ
sum error= 193
Actual label: 5
Output voltages: [0.21893, 0.0011132, 0.0020156, 0.434, 0.0085298, 0.79879, 0.014026, 0.35247, 0.78124, 0.10485]
Predicted label: 5
Correct prediction
Energy consumption = 147.005699 pJ
sum error= 193
Actual label: 8
Output voltages: [0.23919, 0.019248, 0.041373, 0.59623, 0.0024726, 0.05403, 0.30309, 0.0015315, 0.79685, 0.01501]
Predicted label: 8
Correct prediction
Energy consumption = 136.098127 pJ
sum error= 193
Actual label: 4
Output voltages: [0.011562, 0.011811, 0.093659, 0.024535, 0.79878, 0.0038577, 0.070094, 0.045063, 0.2656, 0.010815]
Predicted label: 4
Correct prediction
Energy consumption = 153.882886 pJ
sum error= 193
Actual label: 9
Output voltages: [0.25093, 0.040793, 0.051816, 0.29783, 0.35146, 0.16151, 0.13507, 0.026307, 0.11617, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 151.361050 pJ
sum error= 193
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 376 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 376 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 376 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.30583, 0.010935, 0.014967, 0.026882, 0.33927, 0.013033, 0.0012694, 0.0097052, 0.41955, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 153.787693 pJ
sum error= 193
Actual label: 1
Output voltages: [0.05378, 0.79852, 0.0079153, 0.066623, 0.0044463, 0.0013996, 0.69235, 0.010121, 0.081451, 0.054707]
Predicted label: 1
Correct prediction
Energy consumption = 164.100530 pJ
sum error= 193
Actual label: 6
Output voltages: [0.12017, 0.089052, 0.03101, 0.33271, 0.013578, 0.26014, 0.79346, 0.0021404, 0.79875, 0.0010694]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.287029 pJ
sum error= 194
Actual label: 5
Output voltages: [0.038739, 0.0068408, 0.036333, 0.30963, 0.017824, 0.79876, 0.12057, 0.0040566, 0.77336, 0.015625]
Predicted label: 5
Correct prediction
Energy consumption = 136.278459 pJ
sum error= 194
Actual label: 0
Output voltages: [0.79868, 0.15263, 0.027417, 0.01023, 0.0011255, 0.036664, 0.37854, 0.043531, 0.32578, 0.021366]
Predicted label: 0
Correct prediction
Energy consumption = 148.597282 pJ
sum error= 194
Actual label: 1
Output voltages: [0.019293, 0.79844, 0.037627, 0.29061, 0.033355, 0.0040871, 0.4396, 0.0056814, 0.021881, 0.44372]
Predicted label: 1
Correct prediction
Energy consumption = 162.462387 pJ
sum error= 194
Actual label: 3
Output voltages: [0.4879, 0.003014, 0.22591, 0.79877, 0.029295, 0.14162, 0.01796, 0.0037175, 0.42838, 0.01967]
Predicted label: 3
Correct prediction
Energy consumption = 145.279925 pJ
sum error= 194
Actual label: 7
Output voltages: [0.062361, 0.06177, 0.79723, 0.2224, 0.0012277, 0.0013327, 0.0017483, 0.65959, 0.75875, 0.048394]
Predicted label: 2
Wrong prediction!
Energy consumption = 138.500983 pJ
sum error= 195
Actual label: 0
Output voltages: [0.79874, 0.0089694, 0.26509, 0.0087771, 0.048709, 0.0089156, 0.17008, 0.024745, 0.66998, 0.053146]
Predicted label: 0
Correct prediction
Energy consumption = 143.396181 pJ
sum error= 195
Actual label: 3
Output voltages: [0.047325, 0.24529, 0.033256, 0.79865, 0.0019036, 0.001901, 0.0026271, 0.023089, 0.24871, 0.3346]
Predicted label: 3
Correct prediction
Energy consumption = 141.177532 pJ
sum error= 195
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 377 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 377 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 377 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0083904, 0.021753, 0.13654, 0.023841, 0.7987, 0.0014409, 0.27268, 0.32286, 0.030328, 0.056828]
Predicted label: 4
Correct prediction
Energy consumption = 156.093605 pJ
sum error= 195
Actual label: 8
Output voltages: [0.046893, 0.0049568, 0.29367, 0.03576, 0.010174, 0.10989, 0.029858, 0.013518, 0.79875, 0.45447]
Predicted label: 8
Correct prediction
Energy consumption = 150.453419 pJ
sum error= 195
Actual label: 2
Output voltages: [0.24195, 0.01258, 0.79862, 0.3099, 0.0015002, 0.0012764, 0.030351, 0.65066, 0.754, 0.046482]
Predicted label: 2
Correct prediction
Energy consumption = 143.760520 pJ
sum error= 195
Actual label: 2
Output voltages: [0.252, 0.11876, 0.79873, 0.038152, 0.010227, 0.0012995, 0.18807, 0.0028763, 0.21617, 0.027488]
Predicted label: 2
Correct prediction
Energy consumption = 132.065644 pJ
sum error= 195
Actual label: 0
Output voltages: [0.79879, 0.032484, 0.010851, 0.01983, 0.012647, 0.019448, 0.58706, 0.039711, 0.1317, 0.19033]
Predicted label: 0
Correct prediction
Energy consumption = 153.912839 pJ
sum error= 195
Actual label: 2
Output voltages: [0.62992, 0.029204, 0.79868, 0.0842, 0.050602, 0.0011451, 0.20103, 0.15059, 0.40919, 0.027847]
Predicted label: 2
Correct prediction
Energy consumption = 137.734921 pJ
sum error= 195
Actual label: 5
Output voltages: [0.0096692, 0.0020385, 0.0064359, 0.12788, 0.0061367, 0.79472, 0.035699, 0.0088032, 0.77075, 0.022839]
Predicted label: 5
Correct prediction
Energy consumption = 148.937195 pJ
sum error= 195
Actual label: 1
Output voltages: [0.028943, 0.7987, 0.0012894, 0.37419, 0.0050293, 0.06111, 0.24267, 0.0027762, 0.2483, 0.16736]
Predicted label: 1
Correct prediction
Energy consumption = 163.760755 pJ
sum error= 195
Actual label: 5
Output voltages: [0.78086, 0.0090449, 0.40373, 0.52751, 0.0011354, 0.44192, 0.18979, 0.050349, 0.7387, 0.0067369]
Predicted label: 0
Wrong prediction!
Energy consumption = 150.954772 pJ
sum error= 196
Actual label: 1
Output voltages: [0.037523, 0.79838, 0.10258, 0.21484, 0.12726, 0.0091198, 0.35046, 0.02817, 0.0059227, 0.39874]
Predicted label: 1
Correct prediction
Energy consumption = 165.673142 pJ
sum error= 196
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 378 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 378 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 378 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.038549, 0.0064627, 0.16438, 0.011319, 0.69902, 0.34745, 0.78354, 0.0014381, 0.59515, 0.001647]
Predicted label: 6
Wrong prediction!
Energy consumption = 155.848269 pJ
sum error= 197
Actual label: 8
Output voltages: [0.045605, 0.079644, 0.19219, 0.74011, 0.012991, 0.0035729, 0.11064, 0.0048339, 0.79738, 0.17007]
Predicted label: 8
Correct prediction
Energy consumption = 162.489347 pJ
sum error= 197
Actual label: 8
Output voltages: [0.23319, 0.0010769, 0.78793, 0.38771, 0.0064075, 0.0020662, 0.0041116, 0.12157, 0.7969, 0.005667]
Predicted label: 8
Correct prediction
Energy consumption = 149.094768 pJ
sum error= 197
Actual label: 9
Output voltages: [0.4408, 0.0094694, 0.014709, 0.070696, 0.28407, 0.20238, 0.046008, 0.045182, 0.028162, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 152.212927 pJ
sum error= 197
Actual label: 1
Output voltages: [0.011715, 0.79845, 0.062074, 0.055862, 0.025095, 0.0016842, 0.70042, 0.002316, 0.061778, 0.19005]
Predicted label: 1
Correct prediction
Energy consumption = 159.139267 pJ
sum error= 197
Actual label: 2
Output voltages: [0.26312, 0.5531, 0.79877, 0.014694, 0.0026304, 0.0013276, 0.040102, 0.39528, 0.29711, 0.031896]
Predicted label: 2
Correct prediction
Energy consumption = 149.260664 pJ
sum error= 197
Actual label: 1
Output voltages: [0.16762, 0.79863, 0.15561, 0.17386, 0.0076542, 0.0024016, 0.039767, 0.0094454, 0.054782, 0.038615]
Predicted label: 1
Correct prediction
Energy consumption = 154.618870 pJ
sum error= 197
Actual label: 3
Output voltages: [0.34416, 0.0084875, 0.56852, 0.79689, 0.0074038, 0.0015711, 0.0074737, 0.007395, 0.76863, 0.02659]
Predicted label: 3
Correct prediction
Energy consumption = 150.211311 pJ
sum error= 197
Actual label: 5
Output voltages: [0.1635, 0.0013531, 0.0042444, 0.23033, 0.026031, 0.79877, 0.037569, 0.028101, 0.77786, 0.06274]
Predicted label: 5
Correct prediction
Energy consumption = 141.437223 pJ
sum error= 197
Actual label: 1
Output voltages: [0.0073979, 0.79853, 0.04827, 0.099941, 0.048693, 0.0059285, 0.41933, 0.010428, 0.29973, 0.081324]
Predicted label: 1
Correct prediction
Energy consumption = 163.778306 pJ
sum error= 197
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 379 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 379 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 379 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7985, 0.17778, 0.021873, 0.014774, 0.011621, 0.032244, 0.69309, 0.0098846, 0.38814, 0.062989]
Predicted label: 0
Correct prediction
Energy consumption = 149.350310 pJ
sum error= 197
Actual label: 9
Output voltages: [0.59039, 0.0046611, 0.018032, 0.015369, 0.21395, 0.027249, 0.027417, 0.023112, 0.02245, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 147.375145 pJ
sum error= 197
Actual label: 4
Output voltages: [0.054796, 0.0085965, 0.22242, 0.014551, 0.79871, 0.020646, 0.11355, 0.1118, 0.027405, 0.16462]
Predicted label: 4
Correct prediction
Energy consumption = 150.335015 pJ
sum error= 197
Actual label: 4
Output voltages: [0.0045467, 0.011307, 0.60533, 0.034534, 0.79867, 0.0012252, 0.24872, 0.11628, 0.013664, 0.20416]
Predicted label: 4
Correct prediction
Energy consumption = 147.195148 pJ
sum error= 197
Actual label: 8
Output voltages: [0.01254, 0.24692, 0.014053, 0.045791, 0.0031897, 0.018022, 0.0047899, 0.042553, 0.79879, 0.51486]
Predicted label: 8
Correct prediction
Energy consumption = 150.333458 pJ
sum error= 197
Actual label: 3
Output voltages: [0.021651, 0.078635, 0.098136, 0.79876, 0.035271, 0.0035065, 0.0042012, 0.31864, 0.47804, 0.09041]
Predicted label: 3
Correct prediction
Energy consumption = 141.897595 pJ
sum error= 197
Actual label: 2
Output voltages: [0.022192, 0.74812, 0.78021, 0.19904, 0.0047278, 0.0013436, 0.45476, 0.0014878, 0.40799, 0.061952]
Predicted label: 2
Correct prediction
Energy consumption = 148.480265 pJ
sum error= 197
Actual label: 5
Output voltages: [0.033555, 0.0012483, 0.0017672, 0.36051, 0.020172, 0.79875, 0.072149, 0.022487, 0.71393, 0.092542]
Predicted label: 5
Correct prediction
Energy consumption = 151.108324 pJ
sum error= 197
Actual label: 9
Output voltages: [0.3566, 0.0093731, 0.027213, 0.011211, 0.070561, 0.0028527, 0.0015738, 0.015067, 0.69921, 0.7964]
Predicted label: 9
Correct prediction
Energy consumption = 148.235840 pJ
sum error= 197
Actual label: 7
Output voltages: [0.50378, 0.050724, 0.76967, 0.4645, 0.0010943, 0.0012215, 0.0017668, 0.78618, 0.53824, 0.035417]
Predicted label: 7
Correct prediction
Energy consumption = 142.235658 pJ
sum error= 197
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 380 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 380 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 380 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.054903, 0.035171, 0.027136, 0.19219, 0.037592, 0.39112, 0.79296, 0.024024, 0.79335, 0.0012805]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.016662 pJ
sum error= 198
Actual label: 6
Output voltages: [0.19193, 0.20847, 0.22394, 0.0079886, 0.36653, 0.1629, 0.79878, 0.0010659, 0.1227, 0.0086394]
Predicted label: 6
Correct prediction
Energy consumption = 151.909172 pJ
sum error= 198
Actual label: 2
Output voltages: [0.37665, 0.016956, 0.79873, 0.084929, 0.0059642, 0.0011832, 0.044447, 0.12687, 0.67349, 0.0090736]
Predicted label: 2
Correct prediction
Energy consumption = 146.771856 pJ
sum error= 198
Actual label: 0
Output voltages: [0.79812, 0.021673, 0.076988, 0.01249, 0.030093, 0.0013336, 0.57407, 0.015468, 0.033828, 0.52626]
Predicted label: 0
Correct prediction
Energy consumption = 158.338014 pJ
sum error= 198
Actual label: 0
Output voltages: [0.79877, 0.35187, 0.027813, 0.039157, 0.0012079, 0.030346, 0.53423, 0.018276, 0.31886, 0.18812]
Predicted label: 0
Correct prediction
Energy consumption = 144.844961 pJ
sum error= 198
Actual label: 0
Output voltages: [0.79878, 0.033087, 0.023436, 0.0090647, 0.035288, 0.012218, 0.73689, 0.031579, 0.037133, 0.3019]
Predicted label: 0
Correct prediction
Energy consumption = 149.390242 pJ
sum error= 198
Actual label: 5
Output voltages: [0.011514, 0.024907, 0.001272, 0.14817, 0.464, 0.77128, 0.047403, 0.40421, 0.66555, 0.12341]
Predicted label: 5
Correct prediction
Energy consumption = 148.831769 pJ
sum error= 198
Actual label: 8
Output voltages: [0.030176, 0.020033, 0.36895, 0.034078, 0.0093622, 0.01487, 0.011469, 0.023837, 0.79862, 0.025435]
Predicted label: 8
Correct prediction
Energy consumption = 140.933500 pJ
sum error= 198
Actual label: 7
Output voltages: [0.13529, 0.29752, 0.50285, 0.74966, 0.0010759, 0.0028634, 0.0012891, 0.0076638, 0.77637, 0.42145]
Predicted label: 8
Wrong prediction!
Energy consumption = 137.763235 pJ
sum error= 199
Actual label: 1
Output voltages: [0.042471, 0.7986, 0.0014629, 0.031914, 0.35701, 0.0076102, 0.34431, 0.0054195, 0.027568, 0.058226]
Predicted label: 1
Correct prediction
Energy consumption = 154.693176 pJ
sum error= 199
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 381 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 381 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 381 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.042795, 0.0010672, 0.0018823, 0.42772, 0.02168, 0.7987, 0.12294, 0.019528, 0.72636, 0.22838]
Predicted label: 5
Correct prediction
Energy consumption = 144.974264 pJ
sum error= 199
Actual label: 2
Output voltages: [0.54534, 0.0030125, 0.70689, 0.78779, 0.022822, 0.0011263, 0.01684, 0.032027, 0.52661, 0.0042791]
Predicted label: 3
Wrong prediction!
Energy consumption = 148.048531 pJ
sum error= 200
Actual label: 3
Output voltages: [0.71441, 0.019033, 0.14994, 0.79873, 0.041459, 0.018753, 0.0036564, 0.012608, 0.3939, 0.012135]
Predicted label: 3
Correct prediction
Energy consumption = 138.855695 pJ
sum error= 200
Actual label: 8
Output voltages: [0.22908, 0.0135, 0.33494, 0.068678, 0.0059868, 0.6211, 0.029925, 0.032525, 0.79875, 0.012256]
Predicted label: 8
Correct prediction
Energy consumption = 148.134746 pJ
sum error= 200
Actual label: 5
Output voltages: [0.03991, 0.0010761, 0.0031888, 0.2263, 0.0076387, 0.79719, 0.1561, 0.0090117, 0.78738, 0.049733]
Predicted label: 5
Correct prediction
Energy consumption = 139.839806 pJ
sum error= 200
Actual label: 1
Output voltages: [0.0021452, 0.79856, 0.089455, 0.074246, 0.027665, 0.0013145, 0.29401, 0.0028803, 0.39674, 0.044122]
Predicted label: 1
Correct prediction
Energy consumption = 166.015243 pJ
sum error= 200
Actual label: 8
Output voltages: [0.033985, 0.026413, 0.034965, 0.36594, 0.023588, 0.39402, 0.10735, 0.055247, 0.79875, 0.014831]
Predicted label: 8
Correct prediction
Energy consumption = 152.169720 pJ
sum error= 200
Actual label: 2
Output voltages: [0.24884, 0.016606, 0.79874, 0.036073, 0.45428, 0.0010755, 0.080622, 0.18767, 0.48978, 0.0037967]
Predicted label: 2
Correct prediction
Energy consumption = 142.115545 pJ
sum error= 200
Actual label: 0
Output voltages: [0.74326, 0.025371, 0.72049, 0.0052625, 0.014121, 0.0014984, 0.79162, 0.0011492, 0.59849, 0.20982]
Predicted label: 6
Wrong prediction!
Energy consumption = 143.493811 pJ
sum error= 201
Actual label: 4
Output voltages: [0.01792, 0.0022537, 0.024152, 0.0048869, 0.79875, 0.019167, 0.40462, 0.027188, 0.050661, 0.023864]
Predicted label: 4
Correct prediction
Energy consumption = 153.192345 pJ
sum error= 201
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 382 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 382 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 382 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.75771, 0.0018882, 0.22474, 0.015466, 0.05266, 0.0064872, 0.046032, 0.0010722, 0.20706, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 146.436344 pJ
sum error= 201
Actual label: 9
Output voltages: [0.0031157, 0.0042777, 0.058348, 0.06447, 0.79804, 0.037573, 0.23052, 0.012928, 0.028073, 0.74356]
Predicted label: 4
Wrong prediction!
Energy consumption = 144.262497 pJ
sum error= 202
Actual label: 6
Output voltages: [0.05608, 0.14479, 0.24612, 0.0069904, 0.078216, 0.27074, 0.7987, 0.005382, 0.42151, 0.010828]
Predicted label: 6
Correct prediction
Energy consumption = 142.528175 pJ
sum error= 202
Actual label: 2
Output voltages: [0.50719, 0.10257, 0.79869, 0.045164, 0.023958, 0.0011229, 0.22974, 0.031277, 0.27584, 0.017962]
Predicted label: 2
Correct prediction
Energy consumption = 146.038313 pJ
sum error= 202
Actual label: 3
Output voltages: [0.055123, 0.034674, 0.041673, 0.79876, 0.0030535, 0.0018141, 0.0097681, 0.064555, 0.44861, 0.069412]
Predicted label: 3
Correct prediction
Energy consumption = 138.787771 pJ
sum error= 202
Actual label: 3
Output voltages: [0.13778, 0.0047353, 0.014948, 0.79866, 0.31219, 0.45742, 0.34367, 0.019634, 0.48578, 0.054503]
Predicted label: 3
Correct prediction
Energy consumption = 139.209350 pJ
sum error= 202
Actual label: 5
Output voltages: [0.018234, 0.001081, 0.0013397, 0.03172, 0.17079, 0.79877, 0.43637, 0.019822, 0.78438, 0.024292]
Predicted label: 5
Correct prediction
Energy consumption = 143.918536 pJ
sum error= 202
Actual label: 6
Output voltages: [0.42197, 0.038496, 0.28639, 0.0011087, 0.033594, 0.024044, 0.79874, 0.0012807, 0.32615, 0.023948]
Predicted label: 6
Correct prediction
Energy consumption = 144.394592 pJ
sum error= 202
Actual label: 4
Output voltages: [0.0036225, 0.0084869, 0.33211, 0.028551, 0.79864, 0.015136, 0.16798, 0.042962, 0.087647, 0.040014]
Predicted label: 4
Correct prediction
Energy consumption = 155.906588 pJ
sum error= 202
Actual label: 8
Output voltages: [0.036328, 0.0090968, 0.046941, 0.17287, 0.0014155, 0.041121, 0.0089222, 0.0042585, 0.79878, 0.2651]
Predicted label: 8
Correct prediction
Energy consumption = 147.700228 pJ
sum error= 202
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 383 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 383 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 383 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79874, 0.02373, 0.013471, 0.030668, 0.020859, 0.04353, 0.28837, 0.01048, 0.17394, 0.042183]
Predicted label: 0
Correct prediction
Energy consumption = 160.170703 pJ
sum error= 202
Actual label: 9
Output voltages: [0.029554, 0.0039504, 0.17482, 0.056283, 0.079572, 0.0027007, 0.0021271, 0.010102, 0.78602, 0.69972]
Predicted label: 8
Wrong prediction!
Energy consumption = 159.409730 pJ
sum error= 203
Actual label: 2
Output voltages: [0.65145, 0.060084, 0.79878, 0.076109, 0.0074835, 0.0012994, 0.38347, 0.28635, 0.47713, 0.1448]
Predicted label: 2
Correct prediction
Energy consumption = 147.214911 pJ
sum error= 203
Actual label: 8
Output voltages: [0.01336, 0.14796, 0.1791, 0.74627, 0.0025773, 0.0010663, 0.016407, 0.31644, 0.79867, 0.018284]
Predicted label: 8
Correct prediction
Energy consumption = 152.846781 pJ
sum error= 203
Actual label: 3
Output voltages: [0.34846, 0.011849, 0.58219, 0.79833, 0.015739, 0.0011252, 0.0059429, 0.001489, 0.63285, 0.021651]
Predicted label: 3
Correct prediction
Energy consumption = 142.625055 pJ
sum error= 203
Actual label: 6
Output voltages: [0.33409, 0.045923, 0.32547, 0.013487, 0.3993, 0.30547, 0.79874, 0.0045019, 0.18967, 0.045594]
Predicted label: 6
Correct prediction
Energy consumption = 148.485506 pJ
sum error= 203
Actual label: 7
Output voltages: [0.038292, 0.0093458, 0.001166, 0.13023, 0.53739, 0.76456, 0.002814, 0.79379, 0.53151, 0.39819]
Predicted label: 7
Correct prediction
Energy consumption = 157.299916 pJ
sum error= 203
Actual label: 5
Output voltages: [0.058381, 0.0017948, 0.0010676, 0.55475, 0.027422, 0.79867, 0.050644, 0.1348, 0.77344, 0.019467]
Predicted label: 5
Correct prediction
Energy consumption = 142.723113 pJ
sum error= 203
Actual label: 7
Output voltages: [0.0030162, 0.0066397, 0.015392, 0.31459, 0.25949, 0.0038994, 0.0021256, 0.17007, 0.67977, 0.41271]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.744637 pJ
sum error= 204
Actual label: 2
Output voltages: [0.037561, 0.042425, 0.79839, 0.26468, 0.023067, 0.0011988, 0.091984, 0.0036546, 0.74971, 0.086981]
Predicted label: 2
Correct prediction
Energy consumption = 144.934414 pJ
sum error= 204
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 384 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 384 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 384 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.63695, 0.0028075, 0.32664, 0.0093932, 0.43974, 0.015695, 0.047425, 0.010696, 0.026734, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 154.502806 pJ
sum error= 204
Actual label: 4
Output voltages: [0.0035702, 0.082771, 0.1227, 0.0062896, 0.79861, 0.041439, 0.28127, 0.032677, 0.031315, 0.1045]
Predicted label: 4
Correct prediction
Energy consumption = 150.554736 pJ
sum error= 204
Actual label: 9
Output voltages: [0.17895, 0.015249, 0.018869, 0.006308, 0.40443, 0.025868, 0.012992, 0.015918, 0.46286, 0.79817]
Predicted label: 9
Correct prediction
Energy consumption = 146.359056 pJ
sum error= 204
Actual label: 1
Output voltages: [0.044067, 0.79853, 0.17142, 0.22871, 0.012416, 0.0010891, 0.29995, 0.011395, 0.19279, 0.032897]
Predicted label: 1
Correct prediction
Energy consumption = 168.092538 pJ
sum error= 204
Actual label: 2
Output voltages: [0.47579, 0.050171, 0.79876, 0.38992, 0.023361, 0.0011759, 0.038784, 0.39246, 0.16777, 0.029534]
Predicted label: 2
Correct prediction
Energy consumption = 146.310571 pJ
sum error= 204
Actual label: 8
Output voltages: [0.038723, 0.043016, 0.49939, 0.068424, 0.022867, 0.024476, 0.034245, 0.0055087, 0.79873, 0.14971]
Predicted label: 8
Correct prediction
Energy consumption = 149.538378 pJ
sum error= 204
Actual label: 6
Output voltages: [0.33706, 0.39547, 0.31044, 0.001116, 0.23064, 0.13956, 0.79854, 0.008821, 0.020688, 0.19756]
Predicted label: 6
Correct prediction
Energy consumption = 160.511571 pJ
sum error= 204
Actual label: 0
Output voltages: [0.79818, 0.20396, 0.35924, 0.057084, 0.0012942, 0.0088271, 0.23051, 0.07012, 0.3152, 0.017872]
Predicted label: 0
Correct prediction
Energy consumption = 149.496242 pJ
sum error= 204
Actual label: 7
Output voltages: [0.25114, 0.0046629, 0.64473, 0.73971, 0.24773, 0.001192, 0.002964, 0.72479, 0.52436, 0.057933]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.468170 pJ
sum error= 205
Actual label: 0
Output voltages: [0.79854, 0.066963, 0.011766, 0.0023434, 0.0040012, 0.1553, 0.35853, 0.0026747, 0.33966, 0.28083]
Predicted label: 0
Correct prediction
Energy consumption = 152.229815 pJ
sum error= 205
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 385 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 385 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 385 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.0024902, 0.042869, 0.15951, 0.0038142, 0.79843, 0.011302, 0.17846, 0.0045728, 0.052495, 0.757]
Predicted label: 4
Wrong prediction!
Energy consumption = 155.865081 pJ
sum error= 206
Actual label: 1
Output voltages: [0.06772, 0.79841, 0.010961, 0.024392, 0.040967, 0.066517, 0.60066, 0.01768, 0.15382, 0.045154]
Predicted label: 1
Correct prediction
Energy consumption = 165.424232 pJ
sum error= 206
Actual label: 1
Output voltages: [0.25127, 0.79872, 0.036066, 0.087728, 0.23357, 0.02809, 0.39539, 0.0016957, 0.032975, 0.024243]
Predicted label: 1
Correct prediction
Energy consumption = 147.715540 pJ
sum error= 206
Actual label: 6
Output voltages: [0.27164, 0.073456, 0.21451, 0.058775, 0.019625, 0.6442, 0.77919, 0.0011344, 0.75693, 0.0031372]
Predicted label: 6
Correct prediction
Energy consumption = 146.122582 pJ
sum error= 206
Actual label: 7
Output voltages: [0.060574, 0.018482, 0.042026, 0.36329, 0.0035448, 0.012087, 0.0012443, 0.79879, 0.30633, 0.73364]
Predicted label: 7
Correct prediction
Energy consumption = 155.058532 pJ
sum error= 206
Actual label: 5
Output voltages: [0.040071, 0.017672, 0.0012749, 0.037898, 0.029837, 0.79864, 0.13316, 0.0047706, 0.79162, 0.0014455]
Predicted label: 5
Correct prediction
Energy consumption = 151.031930 pJ
sum error= 206
Actual label: 9
Output voltages: [0.13714, 0.0015323, 0.0046323, 0.44664, 0.079497, 0.08869, 0.0011834, 0.64583, 0.18182, 0.66481]
Predicted label: 9
Correct prediction
Energy consumption = 157.624699 pJ
sum error= 206
Actual label: 9
Output voltages: [0.058041, 0.012513, 0.0382, 0.036249, 0.01502, 0.0024164, 0.0063436, 0.075176, 0.73975, 0.7963]
Predicted label: 9
Correct prediction
Energy consumption = 146.686502 pJ
sum error= 206
Actual label: 1
Output voltages: [0.027587, 0.79855, 0.038756, 0.0067085, 0.25737, 0.017166, 0.52067, 0.0037205, 0.46648, 0.048997]
Predicted label: 1
Correct prediction
Energy consumption = 157.263201 pJ
sum error= 206
Actual label: 9
Output voltages: [0.19426, 0.00138, 0.61181, 0.33538, 0.61573, 0.0017932, 0.0050821, 0.013048, 0.03642, 0.79284]
Predicted label: 9
Correct prediction
Energy consumption = 152.609753 pJ
sum error= 206
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 386 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 386 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 386 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.020761, 0.0010942, 0.01287, 0.061205, 0.033016, 0.79823, 0.4109, 0.022455, 0.79296, 0.023767]
Predicted label: 5
Correct prediction
Energy consumption = 141.716502 pJ
sum error= 206
Actual label: 9
Output voltages: [0.30836, 0.012671, 0.044846, 0.089715, 0.054814, 0.01943, 0.0018053, 0.071967, 0.11743, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 157.341667 pJ
sum error= 206
Actual label: 2
Output voltages: [0.53089, 0.43959, 0.79818, 0.17236, 0.0067899, 0.0013081, 0.028244, 0.26086, 0.020124, 0.02565]
Predicted label: 2
Correct prediction
Energy consumption = 148.591900 pJ
sum error= 206
Actual label: 5
Output voltages: [0.0085814, 0.0010659, 0.0061136, 0.068222, 0.019171, 0.79692, 0.50346, 0.0013641, 0.79307, 0.030798]
Predicted label: 5
Correct prediction
Energy consumption = 155.258301 pJ
sum error= 206
Actual label: 0
Output voltages: [0.79871, 0.031802, 0.028411, 0.031274, 0.048022, 0.015998, 0.69793, 0.041553, 0.33861, 0.02476]
Predicted label: 0
Correct prediction
Energy consumption = 151.103992 pJ
sum error= 206
Actual label: 4
Output voltages: [0.0085037, 0.0028296, 0.18774, 0.033235, 0.79863, 0.0063611, 0.1177, 0.043782, 0.050202, 0.051126]
Predicted label: 4
Correct prediction
Energy consumption = 159.696840 pJ
sum error= 206
Actual label: 1
Output voltages: [0.021795, 0.7986, 0.001394, 0.061006, 0.016689, 0.019817, 0.20425, 0.019866, 0.052818, 0.21292]
Predicted label: 1
Correct prediction
Energy consumption = 166.205401 pJ
sum error= 206
Actual label: 0
Output voltages: [0.79878, 0.033664, 0.098809, 0.01202, 0.0064812, 0.027321, 0.65616, 0.021743, 0.26981, 0.0094097]
Predicted label: 0
Correct prediction
Energy consumption = 150.664213 pJ
sum error= 206
Actual label: 8
Output voltages: [0.0076112, 0.13784, 0.12594, 0.24683, 0.0039633, 0.0080767, 0.020782, 0.012741, 0.79873, 0.16484]
Predicted label: 8
Correct prediction
Energy consumption = 151.716076 pJ
sum error= 206
Actual label: 9
Output voltages: [0.014751, 0.0057377, 0.054172, 0.13869, 0.79878, 0.0051822, 0.0048858, 0.015506, 0.038889, 0.42036]
Predicted label: 4
Wrong prediction!
Energy consumption = 149.357501 pJ
sum error= 207
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 387 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 387 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 387 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79861, 0.053924, 0.037168, 0.019024, 0.0087538, 0.0016479, 0.51456, 0.019536, 0.10793, 0.10206]
Predicted label: 0
Correct prediction
Energy consumption = 147.699208 pJ
sum error= 207
Actual label: 8
Output voltages: [0.0375, 0.016338, 0.31827, 0.058598, 0.0017089, 0.019737, 0.01231, 0.060949, 0.79877, 0.041946]
Predicted label: 8
Correct prediction
Energy consumption = 148.681631 pJ
sum error= 207
Actual label: 9
Output voltages: [0.29031, 0.012713, 0.031279, 0.17284, 0.24856, 0.01072, 0.0074815, 0.010954, 0.16613, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 152.646347 pJ
sum error= 207
Actual label: 8
Output voltages: [0.080918, 0.029355, 0.71217, 0.042879, 0.011555, 0.017649, 0.18248, 0.0070641, 0.79879, 0.1172]
Predicted label: 8
Correct prediction
Energy consumption = 141.335623 pJ
sum error= 207
Actual label: 9
Output voltages: [0.27674, 0.060583, 0.032715, 0.14857, 0.10312, 0.0098564, 0.003566, 0.014691, 0.34125, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.189422 pJ
sum error= 207
Actual label: 4
Output voltages: [0.0014956, 0.0066037, 0.31123, 0.0098486, 0.79865, 0.020134, 0.18315, 0.015732, 0.060091, 0.14623]
Predicted label: 4
Correct prediction
Energy consumption = 143.426788 pJ
sum error= 207
Actual label: 2
Output voltages: [0.60732, 0.48541, 0.79581, 0.1918, 0.0052323, 0.0011515, 0.49905, 0.02756, 0.62336, 0.0045303]
Predicted label: 2
Correct prediction
Energy consumption = 154.013312 pJ
sum error= 207
Actual label: 5
Output voltages: [0.30372, 0.0010911, 0.0011414, 0.58638, 0.020831, 0.79872, 0.039372, 0.053127, 0.65673, 0.026014]
Predicted label: 5
Correct prediction
Energy consumption = 140.357804 pJ
sum error= 207
Actual label: 7
Output voltages: [0.12276, 0.30415, 0.031207, 0.047457, 0.0013085, 0.0026995, 0.0011127, 0.79879, 0.40979, 0.65562]
Predicted label: 7
Correct prediction
Energy consumption = 160.338849 pJ
sum error= 207
Actual label: 9
Output voltages: [0.77437, 0.0016006, 0.044424, 0.32004, 0.57794, 0.038575, 0.0086614, 0.0087846, 0.021765, 0.77217]
Predicted label: 0
Wrong prediction!
Energy consumption = 148.285111 pJ
sum error= 208
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 388 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 388 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 388 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.013419, 0.030672, 0.2037, 0.023894, 0.01286, 0.022592, 0.029441, 0.0014687, 0.79875, 0.4151]
Predicted label: 8
Correct prediction
Energy consumption = 150.721154 pJ
sum error= 208
Actual label: 9
Output voltages: [0.16058, 0.0023963, 0.023681, 0.016346, 0.013381, 0.067563, 0.0089383, 0.075749, 0.66641, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 153.429085 pJ
sum error= 208
Actual label: 8
Output voltages: [0.019468, 0.018501, 0.031784, 0.21288, 0.0069222, 0.095857, 0.013701, 0.0036876, 0.79875, 0.31678]
Predicted label: 8
Correct prediction
Energy consumption = 148.625689 pJ
sum error= 208
Actual label: 0
Output voltages: [0.79879, 0.017602, 0.10455, 0.0047169, 0.018315, 0.032585, 0.3225, 0.021872, 0.020595, 0.012564]
Predicted label: 0
Correct prediction
Energy consumption = 149.586168 pJ
sum error= 208
Actual label: 9
Output voltages: [0.6329, 0.0067634, 0.30744, 0.018427, 0.022345, 0.005876, 0.038087, 0.0044747, 0.23814, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 145.182881 pJ
sum error= 208
Actual label: 9
Output voltages: [0.52507, 0.0023137, 0.26597, 0.036286, 0.4291, 0.023531, 0.017457, 0.0080898, 0.21505, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 141.052797 pJ
sum error= 208
Actual label: 6
Output voltages: [0.050053, 0.32321, 0.16598, 0.016748, 0.095354, 0.27475, 0.79862, 0.0014805, 0.15855, 0.042065]
Predicted label: 6
Correct prediction
Energy consumption = 144.914572 pJ
sum error= 208
Actual label: 8
Output voltages: [0.021543, 0.023269, 0.1318, 0.44026, 0.0050104, 0.02493, 0.30084, 0.0036776, 0.79877, 0.11054]
Predicted label: 8
Correct prediction
Energy consumption = 151.437053 pJ
sum error= 208
Actual label: 9
Output voltages: [0.41672, 0.01511, 0.16969, 0.02777, 0.47474, 0.026207, 0.054251, 0.002666, 0.05049, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 155.445648 pJ
sum error= 208
Actual label: 9
Output voltages: [0.29775, 0.025918, 0.0074576, 0.032468, 0.13717, 0.015382, 0.024578, 0.013866, 0.59279, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 136.642519 pJ
sum error= 208
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 389 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 389 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 389 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.37378, 0.0010883, 0.0010676, 0.64985, 0.02669, 0.7977, 0.056156, 0.0015278, 0.78176, 0.0042634]
Predicted label: 5
Correct prediction
Energy consumption = 144.232105 pJ
sum error= 208
Actual label: 9
Output voltages: [0.21958, 0.018316, 0.013447, 0.026255, 0.039401, 0.010265, 0.001088, 0.0086669, 0.63146, 0.79815]
Predicted label: 9
Correct prediction
Energy consumption = 151.350818 pJ
sum error= 208
Actual label: 8
Output voltages: [0.0068265, 0.02585, 0.17572, 0.20391, 0.010404, 0.033002, 0.12737, 0.020287, 0.79874, 0.032243]
Predicted label: 8
Correct prediction
Energy consumption = 145.223628 pJ
sum error= 208
Actual label: 5
Output voltages: [0.56482, 0.002156, 0.01467, 0.37313, 0.039583, 0.62129, 0.79364, 0.0051128, 0.020228, 0.028984]
Predicted label: 6
Wrong prediction!
Energy consumption = 149.791546 pJ
sum error= 209
Actual label: 1
Output voltages: [0.025324, 0.79869, 0.020763, 0.45153, 0.011894, 0.0010856, 0.25876, 0.0034831, 0.5474, 0.28911]
Predicted label: 1
Correct prediction
Energy consumption = 162.725873 pJ
sum error= 209
Actual label: 0
Output voltages: [0.79757, 0.15479, 0.031935, 0.19753, 0.022371, 0.017791, 0.71798, 0.030552, 0.59194, 0.03224]
Predicted label: 0
Correct prediction
Energy consumption = 156.316825 pJ
sum error= 209
Actual label: 3
Output voltages: [0.20575, 0.033816, 0.064243, 0.79865, 0.007862, 0.008518, 0.0045564, 0.13376, 0.44154, 0.19585]
Predicted label: 3
Correct prediction
Energy consumption = 143.300858 pJ
sum error= 209
Actual label: 3
Output voltages: [0.033302, 0.41763, 0.299, 0.79879, 0.0057446, 0.0012248, 0.0062972, 0.091455, 0.20984, 0.025931]
Predicted label: 3
Correct prediction
Energy consumption = 146.886921 pJ
sum error= 209
Actual label: 5
Output voltages: [0.015759, 0.0010742, 0.010735, 0.42421, 0.020487, 0.79676, 0.0055802, 0.067797, 0.77167, 0.22637]
Predicted label: 5
Correct prediction
Energy consumption = 143.256511 pJ
sum error= 209
Actual label: 2
Output voltages: [0.27723, 0.002321, 0.78062, 0.74524, 0.0087946, 0.0012115, 0.040906, 0.04241, 0.69999, 0.023252]
Predicted label: 2
Correct prediction
Energy consumption = 151.875959 pJ
sum error= 209
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 390 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 390 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 390 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.025298, 0.79862, 0.016559, 0.16745, 0.10772, 0.0025111, 0.5613, 0.0010663, 0.33706, 0.12386]
Predicted label: 1
Correct prediction
Energy consumption = 167.477947 pJ
sum error= 209
Actual label: 6
Output voltages: [0.26036, 0.10331, 0.27512, 0.0013009, 0.14492, 0.22737, 0.79874, 0.0064133, 0.30107, 0.012034]
Predicted label: 6
Correct prediction
Energy consumption = 145.680943 pJ
sum error= 209
Actual label: 5
Output voltages: [0.024041, 0.0011015, 0.030291, 0.55619, 0.063722, 0.79564, 0.05213, 0.016137, 0.79293, 0.048024]
Predicted label: 5
Correct prediction
Energy consumption = 143.153217 pJ
sum error= 209
Actual label: 0
Output voltages: [0.79876, 0.041009, 0.027883, 0.018586, 0.076874, 0.0087015, 0.63588, 0.016048, 0.048086, 0.14713]
Predicted label: 0
Correct prediction
Energy consumption = 155.394180 pJ
sum error= 209
Actual label: 2
Output voltages: [0.19964, 0.022701, 0.79879, 0.13429, 0.016337, 0.0013275, 0.16061, 0.24446, 0.6096, 0.053367]
Predicted label: 2
Correct prediction
Energy consumption = 149.081331 pJ
sum error= 209
Actual label: 8
Output voltages: [0.0065148, 0.014649, 0.037985, 0.75313, 0.0036572, 0.0033303, 0.024405, 0.017098, 0.79772, 0.058728]
Predicted label: 8
Correct prediction
Energy consumption = 148.471740 pJ
sum error= 209
Actual label: 1
Output voltages: [0.021146, 0.76359, 0.50235, 0.79765, 0.0018835, 0.0046192, 0.022788, 0.010627, 0.059353, 0.015368]
Predicted label: 3
Wrong prediction!
Energy consumption = 145.082435 pJ
sum error= 210
Actual label: 5
Output voltages: [0.050832, 0.0020918, 0.0013885, 0.32647, 0.02171, 0.79869, 0.35995, 0.081319, 0.67522, 0.015941]
Predicted label: 5
Correct prediction
Energy consumption = 141.674760 pJ
sum error= 210
Actual label: 6
Output voltages: [0.073134, 0.029593, 0.2259, 0.0049485, 0.29502, 0.15232, 0.79876, 0.0039625, 0.6448, 0.018222]
Predicted label: 6
Correct prediction
Energy consumption = 145.443730 pJ
sum error= 210
Actual label: 2
Output voltages: [0.23449, 0.54913, 0.7974, 0.016073, 0.0021705, 0.0012481, 0.012425, 0.7814, 0.29543, 0.028833]
Predicted label: 2
Correct prediction
Energy consumption = 152.115665 pJ
sum error= 210
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 391 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 391 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 391 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.72839, 0.02312, 0.036748, 0.79861, 0.027181, 0.018831, 0.015239, 0.011644, 0.4476, 0.12087]
Predicted label: 3
Correct prediction
Energy consumption = 148.324103 pJ
sum error= 210
Actual label: 0
Output voltages: [0.7987, 0.028461, 0.049841, 0.019235, 0.040289, 0.017673, 0.44708, 0.035259, 0.023026, 0.1629]
Predicted label: 0
Correct prediction
Energy consumption = 141.057376 pJ
sum error= 210
Actual label: 2
Output voltages: [0.19431, 0.0060655, 0.79867, 0.041585, 0.066742, 0.0012013, 0.068011, 0.05578, 0.36756, 0.0061707]
Predicted label: 2
Correct prediction
Energy consumption = 140.135139 pJ
sum error= 210
Actual label: 2
Output voltages: [0.714, 0.0022049, 0.79859, 0.056223, 0.022102, 0.0010774, 0.014465, 0.028986, 0.51638, 0.023874]
Predicted label: 2
Correct prediction
Energy consumption = 135.548641 pJ
sum error= 210
Actual label: 6
Output voltages: [0.019548, 0.035964, 0.21279, 0.0020299, 0.20342, 0.17926, 0.7987, 0.011683, 0.37316, 0.0048599]
Predicted label: 6
Correct prediction
Energy consumption = 137.876873 pJ
sum error= 210
Actual label: 4
Output voltages: [0.021956, 0.020499, 0.1639, 0.015713, 0.79875, 0.0010909, 0.043822, 0.034517, 0.017262, 0.02754]
Predicted label: 4
Correct prediction
Energy consumption = 151.275721 pJ
sum error= 210
Actual label: 3
Output voltages: [0.03797, 0.022497, 0.024328, 0.79875, 0.040921, 0.0019346, 0.005774, 0.0086662, 0.71627, 0.26778]
Predicted label: 3
Correct prediction
Energy consumption = 144.471461 pJ
sum error= 210
Actual label: 5
Output voltages: [0.1729, 0.0011246, 0.0076939, 0.52463, 0.010676, 0.79066, 0.28293, 0.036037, 0.77394, 0.011673]
Predicted label: 5
Correct prediction
Energy consumption = 143.242723 pJ
sum error= 210
Actual label: 5
Output voltages: [0.46032, 0.001066, 0.0030646, 0.33729, 0.024541, 0.79424, 0.0054213, 0.0014634, 0.7475, 0.11095]
Predicted label: 5
Correct prediction
Energy consumption = 137.589683 pJ
sum error= 210
Actual label: 1
Output voltages: [0.013168, 0.79848, 0.1626, 0.2672, 0.043376, 0.022057, 0.52169, 0.0095357, 0.26122, 0.039466]
Predicted label: 1
Correct prediction
Energy consumption = 172.497403 pJ
sum error= 210
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 392 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 392 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 392 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.036288, 0.019815, 0.12462, 0.0066953, 0.019949, 0.0014343, 0.0042194, 0.79858, 0.25394, 0.31265]
Predicted label: 7
Correct prediction
Energy consumption = 152.129027 pJ
sum error= 210
Actual label: 2
Output voltages: [0.25823, 0.05231, 0.79851, 0.5299, 0.034279, 0.0011934, 0.014587, 0.015091, 0.69338, 0.02012]
Predicted label: 2
Correct prediction
Energy consumption = 152.358275 pJ
sum error= 210
Actual label: 1
Output voltages: [0.027064, 0.79855, 0.039327, 0.019872, 0.40132, 0.0024217, 0.76757, 0.0010709, 0.22381, 0.01173]
Predicted label: 1
Correct prediction
Energy consumption = 156.374061 pJ
sum error= 210
Actual label: 6
Output voltages: [0.070851, 0.051702, 0.044062, 0.0022201, 0.2028, 0.38781, 0.79878, 0.011135, 0.44383, 0.0013858]
Predicted label: 6
Correct prediction
Energy consumption = 149.078773 pJ
sum error= 210
Actual label: 9
Output voltages: [0.71755, 0.021449, 0.044939, 0.27308, 0.089443, 0.041894, 0.0041157, 0.52066, 0.15572, 0.78657]
Predicted label: 9
Correct prediction
Energy consumption = 159.957506 pJ
sum error= 210
Actual label: 1
Output voltages: [0.025365, 0.79875, 0.28061, 0.015605, 0.41364, 0.0019707, 0.23618, 0.031569, 0.30787, 0.014331]
Predicted label: 1
Correct prediction
Energy consumption = 144.680693 pJ
sum error= 210
Actual label: 9
Output voltages: [0.011416, 0.007437, 0.0014337, 0.55367, 0.33001, 0.39037, 0.007191, 0.0011762, 0.59791, 0.72751]
Predicted label: 9
Correct prediction
Energy consumption = 161.631713 pJ
sum error= 210
Actual label: 9
Output voltages: [0.5891, 0.0071488, 0.0063484, 0.11599, 0.59154, 0.021939, 0.0093857, 0.016975, 0.29737, 0.79789]
Predicted label: 9
Correct prediction
Energy consumption = 148.146666 pJ
sum error= 210
Actual label: 5
Output voltages: [0.45778, 0.0074704, 0.014958, 0.42053, 0.0017273, 0.79692, 0.12014, 0.0011684, 0.57864, 0.065652]
Predicted label: 5
Correct prediction
Energy consumption = 153.208947 pJ
sum error= 210
Actual label: 5
Output voltages: [0.2611, 0.0014657, 0.015352, 0.40494, 0.0033428, 0.79879, 0.22202, 0.039671, 0.76591, 0.058931]
Predicted label: 5
Correct prediction
Energy consumption = 137.145790 pJ
sum error= 210
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 393 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 393 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 393 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.027064, 0.79854, 0.015353, 0.21162, 0.038567, 0.0013023, 0.52335, 0.0021566, 0.15395, 0.174]
Predicted label: 1
Correct prediction
Energy consumption = 163.753693 pJ
sum error= 210
Actual label: 6
Output voltages: [0.031251, 0.04188, 0.2896, 0.011273, 0.06727, 0.18469, 0.79877, 0.0058437, 0.65067, 0.0029767]
Predicted label: 6
Correct prediction
Energy consumption = 150.499232 pJ
sum error= 210
Actual label: 2
Output voltages: [0.6645, 0.0074416, 0.79878, 0.27368, 0.014807, 0.0010725, 0.029653, 0.030763, 0.60756, 0.0043241]
Predicted label: 2
Correct prediction
Energy consumption = 150.641772 pJ
sum error= 210
Actual label: 2
Output voltages: [0.51581, 0.16064, 0.79878, 0.32857, 0.013037, 0.001204, 0.26991, 0.054062, 0.25272, 0.029847]
Predicted label: 2
Correct prediction
Energy consumption = 139.405568 pJ
sum error= 210
Actual label: 8
Output voltages: [0.012493, 0.015021, 0.033789, 0.111, 0.0080273, 0.096014, 0.0185, 0.0017926, 0.79875, 0.30318]
Predicted label: 8
Correct prediction
Energy consumption = 149.954280 pJ
sum error= 210
Actual label: 6
Output voltages: [0.036691, 0.017735, 0.25634, 0.0013967, 0.34909, 0.52665, 0.79876, 0.0012727, 0.34913, 0.0015331]
Predicted label: 6
Correct prediction
Energy consumption = 150.749627 pJ
sum error= 210
Actual label: 7
Output voltages: [0.023598, 0.0032233, 0.72974, 0.31875, 0.012633, 0.0010784, 0.0042668, 0.79872, 0.47551, 0.012127]
Predicted label: 7
Correct prediction
Energy consumption = 145.957942 pJ
sum error= 210
Actual label: 1
Output voltages: [0.0048324, 0.79878, 0.0030297, 0.062137, 0.074279, 0.45245, 0.46849, 0.06848, 0.054963, 0.013915]
Predicted label: 1
Correct prediction
Energy consumption = 166.931497 pJ
sum error= 210
Actual label: 4
Output voltages: [0.020403, 0.020281, 0.18269, 0.025113, 0.79865, 0.0031129, 0.035895, 0.0069973, 0.020728, 0.30975]
Predicted label: 4
Correct prediction
Energy consumption = 162.398918 pJ
sum error= 210
Actual label: 6
Output voltages: [0.43117, 0.015133, 0.060204, 0.0010745, 0.39129, 0.0065709, 0.79877, 0.0060418, 0.044628, 0.39036]
Predicted label: 6
Correct prediction
Energy consumption = 144.141694 pJ
sum error= 210
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 394 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 394 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 394 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.034895, 0.17431, 0.031435, 0.0022243, 0.014077, 0.64697, 0.034321, 0.45175, 0.018615]
Predicted label: 0
Correct prediction
Energy consumption = 144.115459 pJ
sum error= 210
Actual label: 4
Output voltages: [0.24796, 0.38637, 0.4926, 0.002229, 0.64776, 0.010986, 0.79377, 0.0032314, 0.2255, 0.001163]
Predicted label: 6
Wrong prediction!
Energy consumption = 142.151438 pJ
sum error= 211
Actual label: 0
Output voltages: [0.78723, 0.034164, 0.014608, 0.0011039, 0.025733, 0.0059807, 0.76129, 0.019819, 0.19319, 0.14673]
Predicted label: 0
Correct prediction
Energy consumption = 148.937038 pJ
sum error= 211
Actual label: 3
Output voltages: [0.003647, 0.0014075, 0.0084981, 0.79339, 0.61924, 0.55151, 0.33294, 0.015256, 0.51369, 0.0010706]
Predicted label: 3
Correct prediction
Energy consumption = 149.542643 pJ
sum error= 211
Actual label: 3
Output voltages: [0.14483, 0.012079, 0.023911, 0.79871, 0.010317, 0.011545, 0.014907, 0.0054221, 0.52203, 0.053392]
Predicted label: 3
Correct prediction
Energy consumption = 135.666941 pJ
sum error= 211
Actual label: 2
Output voltages: [0.36335, 0.025196, 0.79873, 0.066914, 0.015095, 0.0010776, 0.043961, 0.015209, 0.34716, 0.018338]
Predicted label: 2
Correct prediction
Energy consumption = 149.047208 pJ
sum error= 211
Actual label: 2
Output voltages: [0.21324, 0.2365, 0.79722, 0.047639, 0.0091863, 0.0012188, 0.34639, 0.012238, 0.65935, 0.037212]
Predicted label: 2
Correct prediction
Energy consumption = 144.341866 pJ
sum error= 211
Actual label: 3
Output voltages: [0.47446, 0.025859, 0.10484, 0.79861, 0.026013, 0.02012, 0.012976, 0.030562, 0.6019, 0.035201]
Predicted label: 3
Correct prediction
Energy consumption = 141.384473 pJ
sum error= 211
Actual label: 6
Output voltages: [0.34565, 0.065695, 0.3284, 0.0010663, 0.097169, 0.19198, 0.79878, 0.0014237, 0.44503, 0.0049285]
Predicted label: 6
Correct prediction
Energy consumption = 149.485337 pJ
sum error= 211
Actual label: 8
Output voltages: [0.18077, 0.045345, 0.15673, 0.2307, 0.10901, 0.01705, 0.20917, 0.021911, 0.79866, 0.034807]
Predicted label: 8
Correct prediction
Energy consumption = 153.255752 pJ
sum error= 211
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 395 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 395 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 395 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.093152, 0.0015978, 0.0080716, 0.2776, 0.053452, 0.0010673, 0.0011064, 0.4411, 0.55677, 0.78244]
Predicted label: 9
Correct prediction
Energy consumption = 161.857306 pJ
sum error= 211
Actual label: 8
Output voltages: [0.67658, 0.0029838, 0.15332, 0.37772, 0.028923, 0.0011597, 0.0010997, 0.036894, 0.78389, 0.29414]
Predicted label: 8
Correct prediction
Energy consumption = 148.691770 pJ
sum error= 211
Actual label: 5
Output voltages: [0.24227, 0.0051983, 0.0010689, 0.54145, 0.024997, 0.79867, 0.48477, 0.0023539, 0.31031, 0.04473]
Predicted label: 5
Correct prediction
Energy consumption = 154.607725 pJ
sum error= 211
Actual label: 3
Output voltages: [0.33251, 0.013463, 0.45144, 0.79867, 0.036581, 0.010496, 0.012627, 0.039121, 0.19245, 0.04408]
Predicted label: 3
Correct prediction
Energy consumption = 139.945742 pJ
sum error= 211
Actual label: 8
Output voltages: [0.053951, 0.022424, 0.2307, 0.017538, 0.011824, 0.013908, 0.0074672, 0.035594, 0.79505, 0.77245]
Predicted label: 8
Correct prediction
Energy consumption = 151.046375 pJ
sum error= 211
Actual label: 5
Output voltages: [0.10791, 0.0044948, 0.0027079, 0.12045, 0.017192, 0.79878, 0.38855, 0.018782, 0.64683, 0.0074427]
Predicted label: 5
Correct prediction
Energy consumption = 147.582820 pJ
sum error= 211
Actual label: 4
Output voltages: [0.0022978, 0.013376, 0.2933, 0.0077224, 0.79861, 0.0022994, 0.091482, 0.021809, 0.032342, 0.057983]
Predicted label: 4
Correct prediction
Energy consumption = 151.007483 pJ
sum error= 211
Actual label: 5
Output voltages: [0.099149, 0.0014529, 0.0066281, 0.50242, 0.02761, 0.79879, 0.30429, 0.085207, 0.70766, 0.26436]
Predicted label: 5
Correct prediction
Energy consumption = 149.692325 pJ
sum error= 211
Actual label: 2
Output voltages: [0.26326, 0.009616, 0.79786, 0.29365, 0.035804, 0.0012179, 0.043774, 0.028121, 0.6625, 0.062317]
Predicted label: 2
Correct prediction
Energy consumption = 151.478113 pJ
sum error= 211
Actual label: 0
Output voltages: [0.79879, 0.062611, 0.030333, 0.02366, 0.081911, 0.0028559, 0.6725, 0.012515, 0.031188, 0.24724]
Predicted label: 0
Correct prediction
Energy consumption = 153.685754 pJ
sum error= 211
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 396 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 396 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 396 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.033795, 0.0017127, 0.0012092, 0.39177, 0.012469, 0.79718, 0.24554, 0.0015307, 0.76489, 0.0055982]
Predicted label: 5
Correct prediction
Energy consumption = 146.887408 pJ
sum error= 211
Actual label: 6
Output voltages: [0.22794, 0.0010668, 0.0062792, 0.0052686, 0.087497, 0.63482, 0.77661, 0.0018585, 0.78782, 0.0092603]
Predicted label: 8
Wrong prediction!
Energy consumption = 137.994093 pJ
sum error= 212
Actual label: 3
Output voltages: [0.29575, 0.003351, 0.33676, 0.7987, 0.027877, 0.011042, 0.057864, 0.015051, 0.75741, 0.017793]
Predicted label: 3
Correct prediction
Energy consumption = 139.519744 pJ
sum error= 212
Actual label: 2
Output voltages: [0.52823, 0.021919, 0.79874, 0.1832, 0.01857, 0.0011125, 0.036594, 0.070301, 0.54505, 0.0072726]
Predicted label: 2
Correct prediction
Energy consumption = 145.351265 pJ
sum error= 212
Actual label: 8
Output voltages: [0.0088996, 0.055623, 0.080065, 0.026073, 0.0063263, 0.0057043, 0.015096, 0.017463, 0.79879, 0.45189]
Predicted label: 8
Correct prediction
Energy consumption = 147.033137 pJ
sum error= 212
Actual label: 3
Output voltages: [0.46202, 0.022379, 0.070562, 0.79869, 0.067626, 0.0027691, 0.032328, 0.017233, 0.59546, 0.018723]
Predicted label: 3
Correct prediction
Energy consumption = 145.716173 pJ
sum error= 212
Actual label: 9
Output voltages: [0.12334, 0.001309, 0.041675, 0.088857, 0.035437, 0.038041, 0.0021911, 0.11048, 0.2276, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 147.483561 pJ
sum error= 212
Actual label: 9
Output voltages: [0.31878, 0.029895, 0.036631, 0.10892, 0.12712, 0.023304, 0.1472, 0.0030632, 0.23166, 0.79864]
Predicted label: 9
Correct prediction
Energy consumption = 144.507453 pJ
sum error= 212
Actual label: 5
Output voltages: [0.0036033, 0.0012279, 0.040591, 0.37653, 0.15653, 0.77996, 0.043731, 0.003403, 0.77416, 0.040499]
Predicted label: 5
Correct prediction
Energy consumption = 147.790301 pJ
sum error= 212
Actual label: 7
Output voltages: [0.29598, 0.74103, 0.028361, 0.46574, 0.0012153, 0.0010837, 0.001216, 0.78299, 0.1751, 0.17587]
Predicted label: 7
Correct prediction
Energy consumption = 161.030452 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 397 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 397 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 397 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.36057, 0.025233, 0.007292, 0.033248, 0.044843, 0.002813, 0.0012051, 0.0083726, 0.49803, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 159.633385 pJ
sum error= 212
Actual label: 4
Output voltages: [0.012869, 0.005763, 0.24132, 0.0016537, 0.79878, 0.0032626, 0.46893, 0.14158, 0.067319, 0.011926]
Predicted label: 4
Correct prediction
Energy consumption = 146.235262 pJ
sum error= 212
Actual label: 6
Output voltages: [0.28043, 0.011345, 0.1489, 0.001397, 0.26349, 0.20819, 0.79879, 0.0026261, 0.73709, 0.01078]
Predicted label: 6
Correct prediction
Energy consumption = 146.275839 pJ
sum error= 212
Actual label: 7
Output voltages: [0.16705, 0.31399, 0.18501, 0.078329, 0.0022638, 0.0010964, 0.0022678, 0.79871, 0.029309, 0.62897]
Predicted label: 7
Correct prediction
Energy consumption = 161.679360 pJ
sum error= 212
Actual label: 1
Output voltages: [0.099097, 0.79834, 0.054657, 0.38543, 0.050964, 0.0024845, 0.075053, 0.31218, 0.022221, 0.17667]
Predicted label: 1
Correct prediction
Energy consumption = 161.084902 pJ
sum error= 212
Actual label: 3
Output voltages: [0.7227, 0.0025392, 0.38979, 0.79856, 0.014328, 0.0018535, 0.042862, 0.013162, 0.40509, 0.0056541]
Predicted label: 3
Correct prediction
Energy consumption = 146.925046 pJ
sum error= 212
Actual label: 7
Output voltages: [0.050076, 0.7149, 0.0606, 0.38489, 0.002185, 0.0012251, 0.0012031, 0.7984, 0.093886, 0.057763]
Predicted label: 7
Correct prediction
Energy consumption = 156.583360 pJ
sum error= 212
Actual label: 3
Output voltages: [0.40476, 0.025421, 0.14122, 0.79864, 0.027559, 0.0042141, 0.018955, 0.050063, 0.32052, 0.042764]
Predicted label: 3
Correct prediction
Energy consumption = 145.157725 pJ
sum error= 212
Actual label: 6
Output voltages: [0.37883, 0.052232, 0.024518, 0.0061747, 0.15848, 0.61832, 0.79878, 0.0052008, 0.33704, 0.024457]
Predicted label: 6
Correct prediction
Energy consumption = 155.510648 pJ
sum error= 212
Actual label: 6
Output voltages: [0.03353, 0.16139, 0.076906, 0.011604, 0.14645, 0.35448, 0.79875, 0.015724, 0.69813, 0.0095697]
Predicted label: 6
Correct prediction
Energy consumption = 136.971822 pJ
sum error= 212
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 398 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 398 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 398 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.11551, 0.33179, 0.035882, 0.0013748, 0.0094976, 0.3617, 0.062211, 0.066496, 0.029778]
Predicted label: 0
Correct prediction
Energy consumption = 151.396610 pJ
sum error= 212
Actual label: 9
Output voltages: [0.26463, 0.020554, 0.051248, 0.14986, 0.18309, 0.0036074, 0.056167, 0.024658, 0.06456, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 152.267059 pJ
sum error= 212
Actual label: 0
Output voltages: [0.79871, 0.029641, 0.0030008, 0.014975, 0.031482, 0.47433, 0.18775, 0.027229, 0.13314, 0.38121]
Predicted label: 0
Correct prediction
Energy consumption = 156.680903 pJ
sum error= 212
Actual label: 1
Output voltages: [0.18794, 0.79879, 0.022584, 0.069431, 0.43566, 0.0011918, 0.47534, 0.010741, 0.031721, 0.013667]
Predicted label: 1
Correct prediction
Energy consumption = 160.178971 pJ
sum error= 212
Actual label: 9
Output voltages: [0.027967, 0.012565, 0.010247, 0.028481, 0.037677, 0.0071439, 0.0012542, 0.017246, 0.76461, 0.79762]
Predicted label: 9
Correct prediction
Energy consumption = 152.167583 pJ
sum error= 212
Actual label: 9
Output voltages: [0.028369, 0.0031374, 0.14258, 0.355, 0.78815, 0.0010659, 0.0019604, 0.022789, 0.021853, 0.75879]
Predicted label: 4
Wrong prediction!
Energy consumption = 149.588993 pJ
sum error= 213
Actual label: 2
Output voltages: [0.43351, 0.34495, 0.79597, 0.050035, 0.021909, 0.0012671, 0.31616, 0.0055455, 0.63361, 0.038865]
Predicted label: 2
Correct prediction
Energy consumption = 150.590193 pJ
sum error= 213
Actual label: 8
Output voltages: [0.062244, 0.15909, 0.21596, 0.52007, 0.010963, 0.01039, 0.063898, 0.0032938, 0.79877, 0.4031]
Predicted label: 8
Correct prediction
Energy consumption = 151.797140 pJ
sum error= 213
Actual label: 8
Output voltages: [0.1794, 0.017536, 0.0026069, 0.50516, 0.013434, 0.28443, 0.031096, 0.0010751, 0.79872, 0.41449]
Predicted label: 8
Correct prediction
Energy consumption = 145.246076 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79869, 0.040754, 0.15645, 0.015816, 0.021183, 0.0011704, 0.44611, 0.033948, 0.19975, 0.055876]
Predicted label: 0
Correct prediction
Energy consumption = 149.557910 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 399 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 399 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 399 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.2112, 0.79871, 0.25073, 0.021567, 0.046851, 0.0010757, 0.072676, 0.013983, 0.33344, 0.032477]
Predicted label: 1
Correct prediction
Energy consumption = 164.816719 pJ
sum error= 213
Actual label: 6
Output voltages: [0.050293, 0.079957, 0.34017, 0.0011389, 0.30101, 0.12341, 0.79872, 0.0013986, 0.52436, 0.010152]
Predicted label: 6
Correct prediction
Energy consumption = 154.118896 pJ
sum error= 213
Actual label: 9
Output voltages: [0.28977, 0.0070391, 0.022054, 0.33106, 0.021849, 0.056624, 0.0082058, 0.23481, 0.28607, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 157.892602 pJ
sum error= 213
Actual label: 7
Output voltages: [0.22373, 0.096289, 0.097625, 0.034351, 0.024084, 0.0011163, 0.0013665, 0.79862, 0.043463, 0.1248]
Predicted label: 7
Correct prediction
Energy consumption = 153.155381 pJ
sum error= 213
Actual label: 5
Output voltages: [0.032929, 0.0016029, 0.011713, 0.069958, 0.0071922, 0.79879, 0.40374, 0.24608, 0.79262, 0.0032438]
Predicted label: 5
Correct prediction
Energy consumption = 148.499271 pJ
sum error= 213
Actual label: 3
Output voltages: [0.18033, 0.0024664, 0.048716, 0.79877, 0.027398, 0.40718, 0.018588, 0.012204, 0.46909, 0.032139]
Predicted label: 3
Correct prediction
Energy consumption = 138.945337 pJ
sum error= 213
Actual label: 4
Output voltages: [0.028783, 0.001181, 0.50164, 0.00188, 0.79861, 0.0025364, 0.032904, 0.14273, 0.028552, 0.22159]
Predicted label: 4
Correct prediction
Energy consumption = 150.233607 pJ
sum error= 213
Actual label: 7
Output voltages: [0.028878, 0.0049886, 0.0041072, 0.58562, 0.0079973, 0.043875, 0.0011012, 0.79878, 0.26815, 0.1251]
Predicted label: 7
Correct prediction
Energy consumption = 147.604253 pJ
sum error= 213
Actual label: 4
Output voltages: [0.012856, 0.0096696, 0.29584, 0.0024478, 0.79879, 0.0018899, 0.65264, 0.022706, 0.15605, 0.0036342]
Predicted label: 4
Correct prediction
Energy consumption = 149.105076 pJ
sum error= 213
Actual label: 9
Output voltages: [0.36255, 0.012862, 0.040497, 0.54746, 0.076267, 0.065162, 0.0081546, 0.039692, 0.086964, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 154.381817 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 400 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 400 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 400 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.24318, 0.0015511, 0.25328, 0.018539, 0.23913, 0.18375, 0.026964, 0.0014375, 0.55723, 0.79866]
Predicted label: 9
Correct prediction
Energy consumption = 154.427585 pJ
sum error= 213
Actual label: 4
Output voltages: [0.011078, 0.003679, 0.04434, 0.037567, 0.79877, 0.0051014, 0.037061, 0.46739, 0.059768, 0.095106]
Predicted label: 4
Correct prediction
Energy consumption = 143.515134 pJ
sum error= 213
Actual label: 3
Output voltages: [0.0247, 0.050866, 0.075841, 0.79683, 0.0032913, 0.12747, 0.014758, 0.0010866, 0.75201, 0.032298]
Predicted label: 3
Correct prediction
Energy consumption = 146.030245 pJ
sum error= 213
Actual label: 6
Output voltages: [0.089308, 0.034339, 0.12407, 0.0025333, 0.15288, 0.063042, 0.79879, 0.0062899, 0.75145, 0.013284]
Predicted label: 6
Correct prediction
Energy consumption = 144.042961 pJ
sum error= 213
Actual label: 3
Output voltages: [0.469, 0.018004, 0.067095, 0.79871, 0.0063945, 0.01432, 0.07273, 0.032601, 0.46013, 0.037345]
Predicted label: 3
Correct prediction
Energy consumption = 146.920574 pJ
sum error= 213
Actual label: 1
Output voltages: [0.0019969, 0.79867, 0.044602, 0.28201, 0.020353, 0.0010756, 0.032204, 0.047015, 0.48056, 0.078454]
Predicted label: 1
Correct prediction
Energy consumption = 162.775707 pJ
sum error= 213
Actual label: 1
Output voltages: [0.0077633, 0.79843, 0.028998, 0.25475, 0.054147, 0.0014403, 0.17721, 0.14579, 0.066172, 0.094035]
Predicted label: 1
Correct prediction
Energy consumption = 156.879006 pJ
sum error= 213
Actual label: 7
Output voltages: [0.23379, 0.082258, 0.00125, 0.54626, 0.061853, 0.022302, 0.0012161, 0.78912, 0.24933, 0.17165]
Predicted label: 7
Correct prediction
Energy consumption = 156.368059 pJ
sum error= 213
Actual label: 6
Output voltages: [0.044096, 0.16242, 0.36682, 0.0030515, 0.44269, 0.071138, 0.79866, 0.0015612, 0.57211, 0.018348]
Predicted label: 6
Correct prediction
Energy consumption = 146.782731 pJ
sum error= 213
Actual label: 9
Output voltages: [0.45221, 0.059714, 0.021935, 0.19111, 0.28633, 0.01396, 0.0065348, 0.11755, 0.049099, 0.79744]
Predicted label: 9
Correct prediction
Energy consumption = 164.107550 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 401 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 401 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 401 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.027457, 0.79856, 0.24538, 0.033308, 0.051803, 0.0013031, 0.26253, 0.0012398, 0.071819, 0.067667]
Predicted label: 1
Correct prediction
Energy consumption = 162.867025 pJ
sum error= 213
Actual label: 8
Output voltages: [0.13852, 0.012472, 0.027804, 0.39314, 0.0086848, 0.039177, 0.0055473, 0.001459, 0.79875, 0.42307]
Predicted label: 8
Correct prediction
Energy consumption = 150.122822 pJ
sum error= 213
Actual label: 4
Output voltages: [0.0082044, 0.017219, 0.32539, 0.025726, 0.7986, 0.04736, 0.031711, 0.38747, 0.03216, 0.25136]
Predicted label: 4
Correct prediction
Energy consumption = 149.596156 pJ
sum error= 213
Actual label: 1
Output voltages: [0.023691, 0.79876, 0.52107, 0.34915, 0.68563, 0.0056773, 0.035073, 0.014997, 0.37493, 0.021494]
Predicted label: 1
Correct prediction
Energy consumption = 153.042738 pJ
sum error= 213
Actual label: 1
Output voltages: [0.0034067, 0.79862, 0.18051, 0.15101, 0.013901, 0.0010808, 0.055995, 0.012666, 0.1992, 0.050282]
Predicted label: 1
Correct prediction
Energy consumption = 158.635182 pJ
sum error= 213
Actual label: 9
Output voltages: [0.6857, 0.014488, 0.017065, 0.047113, 0.56053, 0.011453, 0.002167, 0.0010981, 0.10591, 0.796]
Predicted label: 9
Correct prediction
Energy consumption = 149.542482 pJ
sum error= 213
Actual label: 9
Output voltages: [0.27572, 0.033794, 0.023592, 0.031107, 0.11872, 0.023338, 0.002892, 0.013587, 0.47023, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 138.164691 pJ
sum error= 213
Actual label: 4
Output voltages: [0.0014613, 0.037484, 0.0017464, 0.1117, 0.71154, 0.10389, 0.36359, 0.0045062, 0.29015, 0.60628]
Predicted label: 4
Correct prediction
Energy consumption = 140.721334 pJ
sum error= 213
Actual label: 3
Output voltages: [0.49725, 0.099583, 0.31072, 0.79879, 0.0012019, 0.037588, 0.0037029, 0.14673, 0.48454, 0.0052573]
Predicted label: 3
Correct prediction
Energy consumption = 146.566324 pJ
sum error= 213
Actual label: 6
Output voltages: [0.26421, 0.046395, 0.049478, 0.0075564, 0.20094, 0.32896, 0.79879, 0.003445, 0.62839, 0.0047693]
Predicted label: 6
Correct prediction
Energy consumption = 149.521998 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 402 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 402 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 402 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.037595, 0.018771, 0.037683, 0.023139, 0.01697, 0.063717, 0.018268, 0.017085, 0.79867, 0.030072]
Predicted label: 8
Correct prediction
Energy consumption = 152.924556 pJ
sum error= 213
Actual label: 1
Output voltages: [0.013335, 0.79857, 0.28849, 0.052615, 0.0032177, 0.0012314, 0.57737, 0.0021294, 0.15702, 0.030587]
Predicted label: 1
Correct prediction
Energy consumption = 161.701850 pJ
sum error= 213
Actual label: 6
Output voltages: [0.037837, 0.010727, 0.23778, 0.002154, 0.21362, 0.32557, 0.79879, 0.0010935, 0.55156, 0.032765]
Predicted label: 6
Correct prediction
Energy consumption = 147.993071 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79877, 0.10273, 0.0045817, 0.015578, 0.010832, 0.079469, 0.18896, 0.014872, 0.04683, 0.14595]
Predicted label: 0
Correct prediction
Energy consumption = 151.286592 pJ
sum error= 213
Actual label: 4
Output voltages: [0.0028593, 0.026785, 0.030697, 0.021833, 0.79867, 0.0014045, 0.028654, 0.15778, 0.026221, 0.022252]
Predicted label: 4
Correct prediction
Energy consumption = 154.005372 pJ
sum error= 213
Actual label: 1
Output voltages: [0.021369, 0.79856, 0.13965, 0.15973, 0.10813, 0.014201, 0.59039, 0.0026858, 0.026744, 0.20356]
Predicted label: 1
Correct prediction
Energy consumption = 159.588838 pJ
sum error= 213
Actual label: 3
Output voltages: [0.18166, 0.025943, 0.042294, 0.7987, 0.015603, 0.013831, 0.0094313, 0.0091852, 0.54653, 0.039087]
Predicted label: 3
Correct prediction
Energy consumption = 147.505226 pJ
sum error= 213
Actual label: 7
Output voltages: [0.02162, 0.42101, 0.0096811, 0.012935, 0.33911, 0.0010787, 0.0016388, 0.79777, 0.019786, 0.66095]
Predicted label: 7
Correct prediction
Energy consumption = 155.102096 pJ
sum error= 213
Actual label: 7
Output voltages: [0.2307, 0.032371, 0.010285, 0.025669, 0.0039468, 0.012202, 0.001103, 0.79873, 0.18725, 0.26154]
Predicted label: 7
Correct prediction
Energy consumption = 148.782666 pJ
sum error= 213
Actual label: 4
Output voltages: [0.011763, 0.0069097, 0.18083, 0.021438, 0.79358, 0.0011359, 0.0012146, 0.017059, 0.19833, 0.60929]
Predicted label: 4
Correct prediction
Energy consumption = 147.893652 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 403 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 403 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 403 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.30778, 0.034984, 0.019557, 0.035638, 0.028192, 0.0084936, 0.0091422, 0.035802, 0.27572, 0.79848]
Predicted label: 9
Correct prediction
Energy consumption = 152.449616 pJ
sum error= 213
Actual label: 5
Output voltages: [0.060074, 0.0013016, 0.0019188, 0.60657, 0.022927, 0.79824, 0.2865, 0.024899, 0.77409, 0.28608]
Predicted label: 5
Correct prediction
Energy consumption = 147.690796 pJ
sum error= 213
Actual label: 1
Output voltages: [0.0015524, 0.79876, 0.0038153, 0.019279, 0.046279, 0.0066087, 0.7554, 0.011313, 0.67148, 0.01629]
Predicted label: 1
Correct prediction
Energy consumption = 160.245463 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79873, 0.15219, 0.22722, 0.012541, 0.00214, 0.0016843, 0.4944, 0.010041, 0.068899, 0.17832]
Predicted label: 0
Correct prediction
Energy consumption = 150.567223 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79861, 0.026743, 0.31264, 0.043272, 0.027207, 0.010087, 0.049982, 0.14485, 0.060825, 0.026513]
Predicted label: 0
Correct prediction
Energy consumption = 145.019598 pJ
sum error= 213
Actual label: 1
Output voltages: [0.029801, 0.79868, 0.44939, 0.071344, 0.0027114, 0.0011336, 0.26454, 0.0092836, 0.26005, 0.054315]
Predicted label: 1
Correct prediction
Energy consumption = 164.825127 pJ
sum error= 213
Actual label: 1
Output voltages: [0.010593, 0.79855, 0.15927, 0.036844, 0.017092, 0.001127, 0.65595, 0.0016745, 0.084387, 0.039179]
Predicted label: 1
Correct prediction
Energy consumption = 149.627192 pJ
sum error= 213
Actual label: 6
Output voltages: [0.44861, 0.31372, 0.0055306, 0.23045, 0.0027131, 0.24291, 0.79708, 0.038456, 0.78507, 0.0015762]
Predicted label: 6
Correct prediction
Energy consumption = 152.473674 pJ
sum error= 213
Actual label: 2
Output voltages: [0.2993, 0.30037, 0.79879, 0.12677, 0.0096525, 0.0013603, 0.30397, 0.022883, 0.30144, 0.032845]
Predicted label: 2
Correct prediction
Energy consumption = 150.389394 pJ
sum error= 213
Actual label: 1
Output voltages: [0.013232, 0.7985, 0.060473, 0.046634, 0.038557, 0.0015471, 0.59908, 0.0039257, 0.31733, 0.033912]
Predicted label: 1
Correct prediction
Energy consumption = 157.667044 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 404 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 404 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 404 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.55648, 0.0050117, 0.031801, 0.01173, 0.37809, 0.022178, 0.0095592, 0.043785, 0.29826, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 156.951165 pJ
sum error= 213
Actual label: 8
Output voltages: [0.33931, 0.0076725, 0.046972, 0.16365, 0.017966, 0.27176, 0.011076, 0.022345, 0.79864, 0.022581]
Predicted label: 8
Correct prediction
Energy consumption = 149.384486 pJ
sum error= 213
Actual label: 4
Output voltages: [0.024911, 0.0099579, 0.27027, 0.0015724, 0.79876, 0.0013698, 0.47207, 0.16885, 0.043904, 0.17547]
Predicted label: 4
Correct prediction
Energy consumption = 155.726496 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79879, 0.022908, 0.01972, 0.0060919, 0.0049921, 0.092718, 0.35679, 0.019175, 0.10869, 0.09463]
Predicted label: 0
Correct prediction
Energy consumption = 157.536765 pJ
sum error= 213
Actual label: 3
Output voltages: [0.43639, 0.019572, 0.0016794, 0.79844, 0.006999, 0.66323, 0.06156, 0.56365, 0.36025, 0.0011567]
Predicted label: 3
Correct prediction
Energy consumption = 151.315244 pJ
sum error= 213
Actual label: 6
Output voltages: [0.12496, 0.033582, 0.29814, 0.0031914, 0.024302, 0.55502, 0.79871, 0.0011482, 0.58895, 0.010855]
Predicted label: 6
Correct prediction
Energy consumption = 138.420041 pJ
sum error= 213
Actual label: 4
Output voltages: [0.0072698, 0.032262, 0.076088, 0.010484, 0.79866, 0.0010827, 0.2363, 0.024978, 0.020735, 0.14573]
Predicted label: 4
Correct prediction
Energy consumption = 154.842673 pJ
sum error= 213
Actual label: 9
Output voltages: [0.35519, 0.047548, 0.042684, 0.2622, 0.033021, 0.032854, 0.0082486, 0.045922, 0.24341, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 152.828443 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79871, 0.37003, 0.33772, 0.0427, 0.0036118, 0.013137, 0.18401, 0.0073867, 0.13104, 0.31096]
Predicted label: 0
Correct prediction
Energy consumption = 150.266307 pJ
sum error= 213
Actual label: 7
Output voltages: [0.21709, 0.042787, 0.14502, 0.044961, 0.0012989, 0.01192, 0.0011566, 0.79867, 0.3526, 0.43243]
Predicted label: 7
Correct prediction
Energy consumption = 154.579413 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 405 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 405 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 405 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0081642, 0.79839, 0.027101, 0.13978, 0.014914, 0.008614, 0.7766, 0.0048624, 0.038227, 0.23941]
Predicted label: 1
Correct prediction
Energy consumption = 167.854920 pJ
sum error= 213
Actual label: 6
Output voltages: [0.65429, 0.039965, 0.040167, 0.0015671, 0.057679, 0.045038, 0.79878, 0.0046419, 0.10445, 0.054118]
Predicted label: 6
Correct prediction
Energy consumption = 155.576983 pJ
sum error= 213
Actual label: 5
Output voltages: [0.041975, 0.001095, 0.0010673, 0.37506, 0.068557, 0.79826, 0.28995, 0.0068556, 0.74127, 0.053923]
Predicted label: 5
Correct prediction
Energy consumption = 149.347238 pJ
sum error= 213
Actual label: 7
Output voltages: [0.21793, 0.0095715, 0.004172, 0.019135, 0.026053, 0.0056016, 0.001135, 0.79873, 0.53572, 0.20155]
Predicted label: 7
Correct prediction
Energy consumption = 157.559427 pJ
sum error= 213
Actual label: 5
Output voltages: [0.026137, 0.0010831, 0.0012088, 0.69526, 0.015378, 0.79562, 0.20747, 0.057323, 0.48123, 0.04398]
Predicted label: 5
Correct prediction
Energy consumption = 147.271493 pJ
sum error= 213
Actual label: 2
Output voltages: [0.59532, 0.015008, 0.79768, 0.35903, 0.0035815, 0.0011388, 0.16164, 0.024573, 0.76535, 0.004999]
Predicted label: 2
Correct prediction
Energy consumption = 145.035272 pJ
sum error= 213
Actual label: 5
Output voltages: [0.0061959, 0.0096184, 0.0018897, 0.23003, 0.042637, 0.79842, 0.029573, 0.018266, 0.75335, 0.26911]
Predicted label: 5
Correct prediction
Energy consumption = 149.467950 pJ
sum error= 213
Actual label: 1
Output voltages: [0.16144, 0.79843, 0.063708, 0.28272, 0.0031598, 0.0050515, 0.15709, 0.0043358, 0.58862, 0.029967]
Predicted label: 1
Correct prediction
Energy consumption = 159.360021 pJ
sum error= 213
Actual label: 8
Output voltages: [0.098942, 0.017633, 0.027817, 0.3125, 0.001877, 0.27178, 0.0017292, 0.0014618, 0.79872, 0.26228]
Predicted label: 8
Correct prediction
Energy consumption = 150.319237 pJ
sum error= 213
Actual label: 5
Output voltages: [0.030956, 0.0010699, 0.034657, 0.11403, 0.031155, 0.79481, 0.021397, 0.11915, 0.76508, 0.24206]
Predicted label: 5
Correct prediction
Energy consumption = 144.071997 pJ
sum error= 213
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 406 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 406 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 406 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0060031, 0.010116, 0.3014, 0.03577, 0.79867, 0.001712, 0.22944, 0.19526, 0.030375, 0.35183]
Predicted label: 4
Correct prediction
Energy consumption = 155.140936 pJ
sum error= 213
Actual label: 7
Output voltages: [0.087034, 0.04539, 0.036059, 0.007053, 0.020094, 0.001411, 0.0011124, 0.79879, 0.31303, 0.4153]
Predicted label: 7
Correct prediction
Energy consumption = 149.295180 pJ
sum error= 213
Actual label: 0
Output voltages: [0.79877, 0.050206, 0.05407, 0.029394, 0.010282, 0.004688, 0.36778, 0.0075908, 0.19506, 0.082469]
Predicted label: 0
Correct prediction
Energy consumption = 150.909790 pJ
sum error= 213
Actual label: 6
Output voltages: [0.53073, 0.002509, 0.0031734, 0.049164, 0.018133, 0.79073, 0.7968, 0.0040172, 0.63335, 0.010053]
Predicted label: 6
Correct prediction
Energy consumption = 144.216829 pJ
sum error= 213
Actual label: 7
Output voltages: [0.096395, 0.058971, 0.23632, 0.0095938, 0.010316, 0.0011212, 0.0010787, 0.79866, 0.4215, 0.096015]
Predicted label: 7
Correct prediction
Energy consumption = 155.457908 pJ
sum error= 213
Actual label: 0
Output voltages: [0.76179, 0.037698, 0.66024, 0.75396, 0.0011736, 0.015683, 0.76796, 0.091949, 0.25624, 0.025523]
Predicted label: 6
Wrong prediction!
Energy consumption = 148.310492 pJ
sum error= 214
Actual label: 2
Output voltages: [0.37133, 0.055728, 0.79874, 0.11851, 0.019174, 0.001246, 0.31739, 0.059503, 0.66264, 0.043871]
Predicted label: 2
Correct prediction
Energy consumption = 142.085321 pJ
sum error= 214
Actual label: 5
Output voltages: [0.027667, 0.013161, 0.0029667, 0.70125, 0.018816, 0.79879, 0.050808, 0.032946, 0.75859, 0.063782]
Predicted label: 5
Correct prediction
Energy consumption = 142.692798 pJ
sum error= 214
Actual label: 8
Output voltages: [0.65573, 0.002339, 0.17788, 0.37034, 0.0053498, 0.052692, 0.28871, 0.0099122, 0.7987, 0.053752]
Predicted label: 8
Correct prediction
Energy consumption = 151.073633 pJ
sum error= 214
Actual label: 1
Output voltages: [0.03331, 0.79843, 0.02696, 0.18471, 0.35661, 0.010224, 0.31471, 0.022522, 0.021812, 0.15205]
Predicted label: 1
Correct prediction
Energy consumption = 167.765473 pJ
sum error= 214
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 407 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 407 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 407 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.35306, 0.03388, 0.02932, 0.025284, 0.042714, 0.23367, 0.0045444, 0.019419, 0.45035]
Predicted label: 0
Correct prediction
Energy consumption = 157.835117 pJ
sum error= 214
Actual label: 4
Output voltages: [0.14642, 0.030625, 0.044722, 0.024333, 0.79873, 0.0021876, 0.2531, 0.1128, 0.015502, 0.016671]
Predicted label: 4
Correct prediction
Energy consumption = 154.176261 pJ
sum error= 214
Actual label: 5
Output voltages: [0.13645, 0.0022192, 0.001066, 0.53432, 0.017361, 0.79876, 0.086367, 0.028215, 0.76818, 0.04361]
Predicted label: 5
Correct prediction
Energy consumption = 154.199440 pJ
sum error= 214
Actual label: 7
Output voltages: [0.23685, 0.007131, 0.023625, 0.20332, 0.014341, 0.0070888, 0.0011413, 0.7987, 0.52949, 0.53409]
Predicted label: 7
Correct prediction
Energy consumption = 154.321320 pJ
sum error= 214
Actual label: 1
Output voltages: [0.034601, 0.79841, 0.0092543, 0.08643, 0.20385, 0.0099016, 0.092053, 0.019202, 0.047765, 0.36062]
Predicted label: 1
Correct prediction
Energy consumption = 160.291426 pJ
sum error= 214
Actual label: 8
Output voltages: [0.79053, 0.0095452, 0.044691, 0.55859, 0.0019006, 0.028593, 0.25696, 0.017775, 0.79366, 0.027029]
Predicted label: 8
Correct prediction
Energy consumption = 157.995415 pJ
sum error= 214
Actual label: 5
Output voltages: [0.31305, 0.0026054, 0.02965, 0.090734, 0.018189, 0.7787, 0.52072, 0.0019365, 0.43952, 0.045451]
Predicted label: 5
Correct prediction
Energy consumption = 150.681501 pJ
sum error= 214
Actual label: 1
Output voltages: [0.0013696, 0.79876, 0.3291, 0.64757, 0.073453, 0.011651, 0.018868, 0.16254, 0.0031381, 0.0091781]
Predicted label: 1
Correct prediction
Energy consumption = 165.240793 pJ
sum error= 214
Actual label: 9
Output voltages: [0.32503, 0.0026893, 0.78512, 0.51579, 0.020147, 0.0011105, 0.0031306, 0.27012, 0.77116, 0.016014]
Predicted label: 2
Wrong prediction!
Energy consumption = 145.324167 pJ
sum error= 215
Actual label: 0
Output voltages: [0.79879, 0.13187, 0.0033496, 0.022691, 0.013714, 0.050735, 0.59725, 0.015476, 0.076668, 0.40074]
Predicted label: 0
Correct prediction
Energy consumption = 156.531808 pJ
sum error= 215
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 408 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 408 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 408 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79861, 0.31284, 0.15125, 0.0022503, 0.014748, 0.0017214, 0.41109, 0.016129, 0.52541, 0.14256]
Predicted label: 0
Correct prediction
Energy consumption = 160.997770 pJ
sum error= 215
Actual label: 6
Output voltages: [0.087816, 0.0073055, 0.013324, 0.026896, 0.14529, 0.42442, 0.78971, 0.025119, 0.79682, 0.023297]
Predicted label: 8
Wrong prediction!
Energy consumption = 140.975571 pJ
sum error= 216
Actual label: 0
Output voltages: [0.79871, 0.018026, 0.044319, 0.016449, 0.023646, 0.43514, 0.21013, 0.0018586, 0.22985, 0.059661]
Predicted label: 0
Correct prediction
Energy consumption = 148.506453 pJ
sum error= 216
Actual label: 7
Output voltages: [0.066522, 0.048637, 0.17056, 0.02587, 0.0015341, 0.0012719, 0.0010733, 0.79861, 0.33612, 0.1847]
Predicted label: 7
Correct prediction
Energy consumption = 151.250333 pJ
sum error= 216
Actual label: 3
Output voltages: [0.19932, 0.052062, 0.017986, 0.79869, 0.0053228, 0.0027893, 0.010682, 0.027285, 0.3527, 0.24953]
Predicted label: 3
Correct prediction
Energy consumption = 147.385991 pJ
sum error= 216
Actual label: 1
Output voltages: [0.049121, 0.79836, 0.13522, 0.19431, 0.0066216, 0.007329, 0.37296, 0.025005, 0.42508, 0.047405]
Predicted label: 1
Correct prediction
Energy consumption = 158.999857 pJ
sum error= 216
Actual label: 8
Output voltages: [0.032272, 0.0054254, 0.13866, 0.01655, 0.023838, 0.33768, 0.080591, 0.047538, 0.79878, 0.0050383]
Predicted label: 8
Correct prediction
Energy consumption = 151.552617 pJ
sum error= 216
Actual label: 3
Output voltages: [0.21845, 0.0030408, 0.24892, 0.79869, 0.039175, 0.0023579, 0.0022794, 0.0048804, 0.72745, 0.021198]
Predicted label: 3
Correct prediction
Energy consumption = 145.512344 pJ
sum error= 216
Actual label: 9
Output voltages: [0.1028, 0.044571, 0.050674, 0.038198, 0.062552, 0.011219, 0.0065359, 0.00922, 0.51831, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 150.372376 pJ
sum error= 216
Actual label: 7
Output voltages: [0.045427, 0.03472, 0.60057, 0.011263, 0.0010803, 0.0039927, 0.001137, 0.79877, 0.77701, 0.035026]
Predicted label: 7
Correct prediction
Energy consumption = 147.188569 pJ
sum error= 216
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 409 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 409 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 409 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79868, 0.13413, 0.025809, 0.045666, 0.027588, 0.012097, 0.70682, 0.012356, 0.043063, 0.054695]
Predicted label: 0
Correct prediction
Energy consumption = 160.600933 pJ
sum error= 216
Actual label: 0
Output voltages: [0.79864, 0.05848, 0.065879, 0.014144, 0.0011739, 0.0036108, 0.58225, 0.046788, 0.29838, 0.033869]
Predicted label: 0
Correct prediction
Energy consumption = 146.646853 pJ
sum error= 216
Actual label: 8
Output voltages: [0.025102, 0.12359, 0.044429, 0.047563, 0.0020474, 0.08784, 0.38862, 0.046258, 0.79878, 0.0091998]
Predicted label: 8
Correct prediction
Energy consumption = 153.151895 pJ
sum error= 216
Actual label: 9
Output voltages: [0.26341, 0.01194, 0.052041, 0.02119, 0.78634, 0.040052, 0.19703, 0.048493, 0.012323, 0.77509]
Predicted label: 4
Wrong prediction!
Energy consumption = 148.785352 pJ
sum error= 217
Actual label: 5
Output voltages: [0.20418, 0.0010843, 0.01609, 0.52752, 0.0013695, 0.79749, 0.032364, 0.055937, 0.76656, 0.055007]
Predicted label: 5
Correct prediction
Energy consumption = 144.546430 pJ
sum error= 217
Actual label: 9
Output voltages: [0.52827, 0.0016417, 0.0074231, 0.018144, 0.065279, 0.078283, 0.0052483, 0.12514, 0.57097, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 149.799578 pJ
sum error= 217
Actual label: 8
Output voltages: [0.002134, 0.14737, 0.20898, 0.077157, 0.015674, 0.068282, 0.01922, 0.092183, 0.79866, 0.051655]
Predicted label: 8
Correct prediction
Energy consumption = 138.110266 pJ
sum error= 217
Actual label: 3
Output voltages: [0.59439, 0.020838, 0.26183, 0.79868, 0.12517, 0.0013901, 0.010789, 0.040359, 0.4567, 0.019502]
Predicted label: 3
Correct prediction
Energy consumption = 146.796572 pJ
sum error= 217
Actual label: 2
Output voltages: [0.43882, 0.049116, 0.79879, 0.045538, 0.029236, 0.001129, 0.055246, 0.09004, 0.42259, 0.03686]
Predicted label: 2
Correct prediction
Energy consumption = 139.503112 pJ
sum error= 217
Actual label: 7
Output voltages: [0.26613, 0.025968, 0.77972, 0.029047, 0.0018478, 0.0011535, 0.0011263, 0.79875, 0.56504, 0.20155]
Predicted label: 7
Correct prediction
Energy consumption = 136.487182 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 410 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 410 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 410 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.23358, 0.02104, 0.79874, 0.44584, 0.0065588, 0.0012811, 0.16488, 0.024746, 0.54441, 0.0079753]
Predicted label: 2
Correct prediction
Energy consumption = 142.295136 pJ
sum error= 217
Actual label: 9
Output voltages: [0.27271, 0.0060174, 0.065173, 0.012518, 0.12721, 0.019441, 0.0026349, 0.1121, 0.62572, 0.7951]
Predicted label: 9
Correct prediction
Energy consumption = 153.738162 pJ
sum error= 217
Actual label: 7
Output voltages: [0.31816, 0.015848, 0.0010708, 0.62741, 0.32849, 0.039761, 0.0027882, 0.75416, 0.014134, 0.73019]
Predicted label: 7
Correct prediction
Energy consumption = 147.557969 pJ
sum error= 217
Actual label: 2
Output voltages: [0.24049, 0.22358, 0.79879, 0.39887, 0.022498, 0.0012986, 0.14746, 0.056416, 0.17899, 0.041798]
Predicted label: 2
Correct prediction
Energy consumption = 146.707248 pJ
sum error= 217
Actual label: 1
Output voltages: [0.023991, 0.79867, 0.044143, 0.10328, 0.036625, 0.0012113, 0.44885, 0.0018595, 0.42239, 0.15675]
Predicted label: 1
Correct prediction
Energy consumption = 157.584407 pJ
sum error= 217
Actual label: 1
Output voltages: [0.015379, 0.79856, 0.022146, 0.044812, 0.065871, 0.0065909, 0.5544, 0.0020461, 0.45427, 0.1207]
Predicted label: 1
Correct prediction
Energy consumption = 146.537340 pJ
sum error= 217
Actual label: 3
Output voltages: [0.09542, 0.055421, 0.16498, 0.79871, 0.017767, 0.0024071, 0.0081116, 0.0038843, 0.75246, 0.053866]
Predicted label: 3
Correct prediction
Energy consumption = 143.081038 pJ
sum error= 217
Actual label: 7
Output voltages: [0.010883, 0.029141, 0.7396, 0.28821, 0.015703, 0.0010904, 0.016577, 0.79875, 0.20117, 0.04409]
Predicted label: 7
Correct prediction
Energy consumption = 143.137185 pJ
sum error= 217
Actual label: 5
Output voltages: [0.052043, 0.0016577, 0.002282, 0.46299, 0.028845, 0.79873, 0.039947, 0.010049, 0.54939, 0.026207]
Predicted label: 5
Correct prediction
Energy consumption = 148.993793 pJ
sum error= 217
Actual label: 3
Output voltages: [0.4977, 0.016917, 0.073542, 0.79876, 0.0013334, 0.015166, 0.029279, 0.020823, 0.33098, 0.025057]
Predicted label: 3
Correct prediction
Energy consumption = 144.987283 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 411 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 411 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 411 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.023414, 0.79877, 0.001073, 0.016377, 0.51215, 0.008503, 0.29387, 0.0071438, 0.2973, 0.14755]
Predicted label: 1
Correct prediction
Energy consumption = 160.660348 pJ
sum error= 217
Actual label: 9
Output voltages: [0.052052, 0.0014978, 0.53432, 0.018677, 0.0972, 0.017861, 0.35554, 0.0015603, 0.57475, 0.77323]
Predicted label: 9
Correct prediction
Energy consumption = 152.218146 pJ
sum error= 217
Actual label: 8
Output voltages: [0.18875, 0.0034006, 0.50486, 0.054368, 0.0069024, 0.028314, 0.025297, 0.018279, 0.79878, 0.041734]
Predicted label: 8
Correct prediction
Energy consumption = 142.528396 pJ
sum error= 217
Actual label: 2
Output voltages: [0.54955, 0.55714, 0.79874, 0.32403, 0.018354, 0.0013662, 0.26261, 0.036196, 0.066126, 0.018985]
Predicted label: 2
Correct prediction
Energy consumption = 153.181148 pJ
sum error= 217
Actual label: 2
Output voltages: [0.052168, 0.50275, 0.79855, 0.064915, 0.0014721, 0.0011314, 0.018379, 0.50638, 0.26843, 0.057208]
Predicted label: 2
Correct prediction
Energy consumption = 142.357911 pJ
sum error= 217
Actual label: 2
Output voltages: [0.47883, 0.0074121, 0.79879, 0.25854, 0.010218, 0.0011928, 0.015277, 0.18541, 0.67872, 0.0076257]
Predicted label: 2
Correct prediction
Energy consumption = 144.208215 pJ
sum error= 217
Actual label: 8
Output voltages: [0.40605, 0.0084614, 0.33599, 0.19659, 0.012904, 0.04706, 0.4531, 0.0011637, 0.78417, 0.50852]
Predicted label: 8
Correct prediction
Energy consumption = 152.756536 pJ
sum error= 217
Actual label: 8
Output voltages: [0.022659, 0.011732, 0.37641, 0.041374, 0.036984, 0.0068895, 0.020453, 0.0011308, 0.7982, 0.64424]
Predicted label: 8
Correct prediction
Energy consumption = 138.984842 pJ
sum error= 217
Actual label: 5
Output voltages: [0.012849, 0.0010913, 0.0072558, 0.35778, 0.025331, 0.79194, 0.27321, 0.0031912, 0.7552, 0.046338]
Predicted label: 5
Correct prediction
Energy consumption = 133.552159 pJ
sum error= 217
Actual label: 7
Output voltages: [0.03899, 0.53013, 0.41745, 0.055129, 0.0046239, 0.0011754, 0.0011531, 0.79873, 0.036389, 0.19391]
Predicted label: 7
Correct prediction
Energy consumption = 153.898222 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 412 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 412 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 412 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.77999, 0.030593, 0.048325, 0.79876, 0.0010739, 0.33079, 0.0012535, 0.15656, 0.14227, 0.0029544]
Predicted label: 3
Correct prediction
Energy consumption = 148.276229 pJ
sum error= 217
Actual label: 8
Output voltages: [0.23298, 0.037303, 0.2217, 0.28854, 0.019217, 0.0044742, 0.038565, 0.0021204, 0.79879, 0.23057]
Predicted label: 8
Correct prediction
Energy consumption = 151.671296 pJ
sum error= 217
Actual label: 9
Output voltages: [0.31831, 0.0017288, 0.0071985, 0.01736, 0.22286, 0.3633, 0.0049538, 0.24534, 0.20705, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 152.302771 pJ
sum error= 217
Actual label: 8
Output voltages: [0.051749, 0.0072582, 0.17743, 0.74391, 0.0010664, 0.023132, 0.0075903, 0.019469, 0.79757, 0.35968]
Predicted label: 8
Correct prediction
Energy consumption = 150.758023 pJ
sum error= 217
Actual label: 8
Output voltages: [0.1839, 0.0065626, 0.2852, 0.7485, 0.0030983, 0.0047153, 0.0049311, 0.0011515, 0.7863, 0.19006]
Predicted label: 8
Correct prediction
Energy consumption = 153.933217 pJ
sum error= 217
Actual label: 6
Output voltages: [0.051065, 0.037237, 0.1597, 0.0031903, 0.25728, 0.25846, 0.79875, 0.0017583, 0.55237, 0.0046716]
Predicted label: 6
Correct prediction
Energy consumption = 139.476187 pJ
sum error= 217
Actual label: 8
Output voltages: [0.043765, 0.025108, 0.48673, 0.44173, 0.0045138, 0.0010691, 0.0046065, 0.029289, 0.79679, 0.059776]
Predicted label: 8
Correct prediction
Energy consumption = 158.547336 pJ
sum error= 217
Actual label: 2
Output voltages: [0.46496, 0.055671, 0.79878, 0.13395, 0.016198, 0.0013023, 0.26296, 0.036854, 0.5223, 0.051189]
Predicted label: 2
Correct prediction
Energy consumption = 146.643272 pJ
sum error= 217
Actual label: 3
Output voltages: [0.16542, 0.006669, 0.091895, 0.7987, 0.33756, 0.038922, 0.027572, 0.057244, 0.38573, 0.10282]
Predicted label: 3
Correct prediction
Energy consumption = 139.948397 pJ
sum error= 217
Actual label: 9
Output voltages: [0.40802, 0.046782, 0.0041641, 0.37708, 0.26134, 0.016777, 0.01791, 0.0035701, 0.028382, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.354359 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 413 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 413 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 413 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.04777, 0.014117, 0.36351, 0.04018, 0.0014689, 0.0015869, 0.0012134, 0.79879, 0.78587, 0.063619]
Predicted label: 7
Correct prediction
Energy consumption = 157.667905 pJ
sum error= 217
Actual label: 5
Output voltages: [0.045066, 0.0046438, 0.0018286, 0.46222, 0.0015288, 0.79878, 0.049488, 0.018072, 0.79393, 0.0024641]
Predicted label: 5
Correct prediction
Energy consumption = 150.023776 pJ
sum error= 217
Actual label: 6
Output voltages: [0.094152, 0.056222, 0.23265, 0.0016971, 0.25083, 0.11839, 0.79874, 0.0049787, 0.62163, 0.0076676]
Predicted label: 6
Correct prediction
Energy consumption = 143.592066 pJ
sum error= 217
Actual label: 2
Output voltages: [0.23191, 0.030193, 0.79864, 0.029781, 0.027211, 0.0010661, 0.051401, 0.0083578, 0.49906, 0.021797]
Predicted label: 2
Correct prediction
Energy consumption = 139.767853 pJ
sum error= 217
Actual label: 9
Output voltages: [0.25745, 0.014464, 0.022053, 0.044685, 0.44476, 0.0012477, 0.032728, 0.0013715, 0.40157, 0.79726]
Predicted label: 9
Correct prediction
Energy consumption = 156.110138 pJ
sum error= 217
Actual label: 2
Output voltages: [0.45435, 0.045011, 0.79721, 0.12777, 0.012015, 0.0012622, 0.097141, 0.53233, 0.26507, 0.019662]
Predicted label: 2
Correct prediction
Energy consumption = 152.192699 pJ
sum error= 217
Actual label: 8
Output voltages: [0.058146, 0.027991, 0.74452, 0.038657, 0.017026, 0.001425, 0.10374, 0.0021498, 0.79879, 0.25129]
Predicted label: 8
Correct prediction
Energy consumption = 145.698551 pJ
sum error= 217
Actual label: 8
Output voltages: [0.007654, 0.041725, 0.023867, 0.042321, 0.015646, 0.048491, 0.48324, 0.015337, 0.79875, 0.03552]
Predicted label: 8
Correct prediction
Energy consumption = 151.960035 pJ
sum error= 217
Actual label: 1
Output voltages: [0.02926, 0.7986, 0.036077, 0.025783, 0.039642, 0.0016548, 0.57628, 0.0044206, 0.24499, 0.053728]
Predicted label: 1
Correct prediction
Energy consumption = 157.832802 pJ
sum error= 217
Actual label: 6
Output voltages: [0.1951, 0.02357, 0.24758, 0.0035351, 0.32891, 0.29879, 0.79879, 0.0013523, 0.56006, 0.028769]
Predicted label: 6
Correct prediction
Energy consumption = 138.350368 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 414 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 414 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 414 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.28602, 0.013522, 0.43552, 0.050868, 0.017338, 0.0040972, 0.028685, 0.0023582, 0.79879, 0.37709]
Predicted label: 8
Correct prediction
Energy consumption = 154.484626 pJ
sum error= 217
Actual label: 8
Output voltages: [0.013693, 0.036328, 0.2654, 0.024013, 0.01284, 0.019939, 0.012042, 0.025076, 0.79874, 0.27064]
Predicted label: 8
Correct prediction
Energy consumption = 148.295468 pJ
sum error= 217
Actual label: 7
Output voltages: [0.37339, 0.02334, 0.27265, 0.13515, 0.00174, 0.0053775, 0.0011639, 0.79875, 0.36032, 0.48231]
Predicted label: 7
Correct prediction
Energy consumption = 137.106607 pJ
sum error= 217
Actual label: 9
Output voltages: [0.32645, 0.02993, 0.014885, 0.038355, 0.37031, 0.002217, 0.0012653, 0.022792, 0.15709, 0.79843]
Predicted label: 9
Correct prediction
Energy consumption = 156.163069 pJ
sum error= 217
Actual label: 1
Output voltages: [0.0088345, 0.7984, 0.101, 0.089527, 0.015597, 0.0017084, 0.50355, 0.0043706, 0.14262, 0.1332]
Predicted label: 1
Correct prediction
Energy consumption = 159.195731 pJ
sum error= 217
Actual label: 8
Output voltages: [0.29871, 0.032578, 0.25481, 0.67377, 0.0011346, 0.23966, 0.036418, 0.0012629, 0.79879, 0.25908]
Predicted label: 8
Correct prediction
Energy consumption = 156.570998 pJ
sum error= 217
Actual label: 0
Output voltages: [0.79856, 0.01871, 0.0043293, 0.17805, 0.0091202, 0.29309, 0.65823, 0.020499, 0.23662, 0.027093]
Predicted label: 0
Correct prediction
Energy consumption = 150.785518 pJ
sum error= 217
Actual label: 1
Output voltages: [0.20274, 0.79855, 0.63953, 0.031692, 0.32721, 0.0010728, 0.29727, 0.014837, 0.016571, 0.22404]
Predicted label: 1
Correct prediction
Energy consumption = 161.043274 pJ
sum error= 217
Actual label: 7
Output voltages: [0.048447, 0.21905, 0.78786, 0.28123, 0.01586, 0.001275, 0.0026601, 0.79711, 0.08964, 0.17866]
Predicted label: 7
Correct prediction
Energy consumption = 144.470821 pJ
sum error= 217
Actual label: 2
Output voltages: [0.67881, 0.0092616, 0.79872, 0.52173, 0.013711, 0.0010724, 0.035278, 0.15254, 0.66122, 0.017577]
Predicted label: 2
Correct prediction
Energy consumption = 145.370324 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 415 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 415 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 415 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.11673, 0.040765, 0.011953, 0.016222, 0.010356, 0.5959, 0.015704, 0.044093, 0.034399]
Predicted label: 0
Correct prediction
Energy consumption = 148.606242 pJ
sum error= 217
Actual label: 7
Output voltages: [0.74719, 0.025847, 0.0038639, 0.019835, 0.026739, 0.060148, 0.0014969, 0.79879, 0.11211, 0.20133]
Predicted label: 7
Correct prediction
Energy consumption = 151.223801 pJ
sum error= 217
Actual label: 5
Output voltages: [0.042282, 0.33203, 0.0010684, 0.0092067, 0.0068983, 0.79867, 0.20068, 0.054346, 0.52421, 0.081113]
Predicted label: 5
Correct prediction
Energy consumption = 145.785029 pJ
sum error= 217
Actual label: 1
Output voltages: [0.036482, 0.79854, 0.048613, 0.033912, 0.036707, 0.0013217, 0.497, 0.0014541, 0.21996, 0.049424]
Predicted label: 1
Correct prediction
Energy consumption = 164.448096 pJ
sum error= 217
Actual label: 9
Output voltages: [0.76381, 0.0011235, 0.064983, 0.014933, 0.42303, 0.012492, 0.0091794, 0.0073235, 0.15201, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 143.779822 pJ
sum error= 217
Actual label: 0
Output voltages: [0.79876, 0.32955, 0.010843, 0.008191, 0.012057, 0.029398, 0.48773, 0.0069801, 0.21957, 0.24777]
Predicted label: 0
Correct prediction
Energy consumption = 148.499576 pJ
sum error= 217
Actual label: 2
Output voltages: [0.041003, 0.31795, 0.78841, 0.75211, 0.016817, 0.0011956, 0.031055, 0.02861, 0.60071, 0.1535]
Predicted label: 2
Correct prediction
Energy consumption = 155.403251 pJ
sum error= 217
Actual label: 0
Output voltages: [0.79821, 0.051583, 0.043208, 0.018281, 0.038127, 0.0011302, 0.6929, 0.014284, 0.44385, 0.049164]
Predicted label: 0
Correct prediction
Energy consumption = 145.426161 pJ
sum error= 217
Actual label: 9
Output voltages: [0.29237, 0.0036581, 0.0056722, 0.043951, 0.31329, 0.58386, 0.027598, 0.33483, 0.35193, 0.78693]
Predicted label: 9
Correct prediction
Energy consumption = 143.725091 pJ
sum error= 217
Actual label: 8
Output voltages: [0.23691, 0.0020946, 0.40033, 0.39691, 0.021052, 0.016014, 0.002449, 0.043932, 0.79854, 0.27186]
Predicted label: 8
Correct prediction
Energy consumption = 156.679299 pJ
sum error= 217
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 416 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 416 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 416 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.25078, 0.089431, 0.14121, 0.0012856, 0.04892, 0.058399, 0.79879, 0.002675, 0.50002, 0.0086798]
Predicted label: 6
Correct prediction
Energy consumption = 150.319912 pJ
sum error= 217
Actual label: 2
Output voltages: [0.27457, 0.05478, 0.79866, 0.08393, 0.024731, 0.0010668, 0.050423, 0.03587, 0.43739, 0.016558]
Predicted label: 2
Correct prediction
Energy consumption = 145.274653 pJ
sum error= 217
Actual label: 3
Output voltages: [0.12712, 0.023266, 0.07016, 0.79867, 0.021265, 0.0032932, 0.010112, 0.024515, 0.5668, 0.05846]
Predicted label: 3
Correct prediction
Energy consumption = 140.069830 pJ
sum error= 217
Actual label: 9
Output voltages: [0.7881, 0.016657, 0.0019035, 0.46874, 0.043755, 0.041425, 0.014127, 0.034028, 0.4975, 0.77492]
Predicted label: 0
Wrong prediction!
Energy consumption = 145.651405 pJ
sum error= 218
Actual label: 3
Output voltages: [0.073291, 0.0027371, 0.078143, 0.79878, 0.20069, 0.01694, 0.01562, 0.020933, 0.73919, 0.037039]
Predicted label: 3
Correct prediction
Energy consumption = 138.831067 pJ
sum error= 218
Actual label: 8
Output voltages: [0.4811, 0.5851, 0.097775, 0.017224, 0.0010725, 0.014419, 0.67154, 0.0062133, 0.77705, 0.029183]
Predicted label: 8
Correct prediction
Energy consumption = 155.573061 pJ
sum error= 218
Actual label: 0
Output voltages: [0.78287, 0.3408, 0.26497, 0.010263, 0.0011814, 0.0032371, 0.61507, 0.077506, 0.68242, 0.052821]
Predicted label: 0
Correct prediction
Energy consumption = 156.761761 pJ
sum error= 218
Actual label: 2
Output voltages: [0.33583, 0.0011592, 0.79879, 0.24992, 0.0079298, 0.0010994, 0.033663, 0.42853, 0.79309, 0.016722]
Predicted label: 2
Correct prediction
Energy consumption = 144.902469 pJ
sum error= 218
Actual label: 1
Output voltages: [0.26715, 0.79872, 0.013366, 0.35326, 0.0026305, 0.011168, 0.75219, 0.0052971, 0.29243, 0.0082696]
Predicted label: 1
Correct prediction
Energy consumption = 156.200009 pJ
sum error= 218
Actual label: 1
Output voltages: [0.0012078, 0.7986, 0.04885, 0.085334, 0.011354, 0.0014795, 0.77309, 0.038329, 0.13004, 0.014738]
Predicted label: 1
Correct prediction
Energy consumption = 146.278630 pJ
sum error= 218
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 417 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 417 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 417 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0052965, 0.79878, 0.22132, 0.19464, 0.031141, 0.044985, 0.28026, 0.012635, 0.47871, 0.018134]
Predicted label: 1
Correct prediction
Energy consumption = 163.637613 pJ
sum error= 218
Actual label: 1
Output voltages: [0.023378, 0.79877, 0.20141, 0.23605, 0.017845, 0.0010734, 0.23724, 0.001176, 0.33752, 0.073674]
Predicted label: 1
Correct prediction
Energy consumption = 147.353722 pJ
sum error= 218
Actual label: 4
Output voltages: [0.0025629, 0.021695, 0.07403, 0.014704, 0.79873, 0.0011232, 0.061728, 0.049109, 0.04471, 0.14103]
Predicted label: 4
Correct prediction
Energy consumption = 155.041411 pJ
sum error= 218
Actual label: 2
Output voltages: [0.057019, 0.018378, 0.7987, 0.5158, 0.45806, 0.0011342, 0.026404, 0.044305, 0.25479, 0.11109]
Predicted label: 2
Correct prediction
Energy consumption = 144.372728 pJ
sum error= 218
Actual label: 9
Output voltages: [0.13857, 0.020533, 0.033081, 0.020024, 0.20118, 0.020079, 0.0024672, 0.010775, 0.47032, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 155.312042 pJ
sum error= 218
Actual label: 7
Output voltages: [0.0858, 0.23798, 0.42797, 0.2048, 0.0050584, 0.0011796, 0.0010666, 0.79869, 0.30506, 0.30868]
Predicted label: 7
Correct prediction
Energy consumption = 152.383932 pJ
sum error= 218
Actual label: 2
Output voltages: [0.015683, 0.026789, 0.094008, 0.0020779, 0.001075, 0.024886, 0.059052, 0.55596, 0.79848, 0.08044]
Predicted label: 8
Wrong prediction!
Energy consumption = 139.429393 pJ
sum error= 219
Actual label: 5
Output voltages: [0.014611, 0.0011029, 0.0025947, 0.13764, 0.60503, 0.79879, 0.19924, 0.0038169, 0.45726, 0.040789]
Predicted label: 5
Correct prediction
Energy consumption = 149.435290 pJ
sum error= 219
Actual label: 1
Output voltages: [0.059586, 0.79879, 0.028824, 0.023974, 0.21687, 0.018274, 0.7894, 0.0024519, 0.27188, 0.014641]
Predicted label: 1
Correct prediction
Energy consumption = 152.297294 pJ
sum error= 219
Actual label: 1
Output voltages: [0.024808, 0.79846, 0.32731, 0.25323, 0.040494, 0.0011685, 0.60484, 0.0030538, 0.070463, 0.32979]
Predicted label: 1
Correct prediction
Energy consumption = 159.039942 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 418 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 418 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 418 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.61924, 0.1197, 0.79542, 0.073423, 0.0092633, 0.0011379, 0.50078, 0.0041397, 0.46753, 0.0041264]
Predicted label: 2
Correct prediction
Energy consumption = 151.193948 pJ
sum error= 219
Actual label: 1
Output voltages: [0.013961, 0.79873, 0.3091, 0.028459, 0.025262, 0.0012584, 0.77062, 0.0082834, 0.27361, 0.056958]
Predicted label: 1
Correct prediction
Energy consumption = 160.732758 pJ
sum error= 219
Actual label: 9
Output voltages: [0.34066, 0.013463, 0.026416, 0.03019, 0.14555, 0.033054, 0.018324, 0.043099, 0.40459, 0.79758]
Predicted label: 9
Correct prediction
Energy consumption = 155.892932 pJ
sum error= 219
Actual label: 9
Output voltages: [0.15424, 0.0034638, 0.01421, 0.16186, 0.40958, 0.24658, 0.018793, 0.017779, 0.068478, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 145.370591 pJ
sum error= 219
Actual label: 9
Output voltages: [0.48374, 0.014569, 0.030854, 0.15757, 0.38185, 0.011018, 0.0067161, 0.065933, 0.25573, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 150.416714 pJ
sum error= 219
Actual label: 1
Output voltages: [0.025583, 0.79833, 0.013847, 0.010489, 0.33752, 0.0040868, 0.25426, 0.0069994, 0.40635, 0.035528]
Predicted label: 1
Correct prediction
Energy consumption = 148.016483 pJ
sum error= 219
Actual label: 0
Output voltages: [0.79807, 0.14317, 0.30674, 0.019889, 0.013978, 0.0011923, 0.36449, 0.004998, 0.39766, 0.024514]
Predicted label: 0
Correct prediction
Energy consumption = 154.399373 pJ
sum error= 219
Actual label: 2
Output voltages: [0.016066, 0.0022933, 0.79632, 0.31746, 0.001651, 0.0012072, 0.029007, 0.53613, 0.39436, 0.03793]
Predicted label: 2
Correct prediction
Energy consumption = 139.562873 pJ
sum error= 219
Actual label: 0
Output voltages: [0.79827, 0.18485, 0.055979, 0.0076456, 0.0018079, 0.0011157, 0.30879, 0.019687, 0.1521, 0.1125]
Predicted label: 0
Correct prediction
Energy consumption = 145.374358 pJ
sum error= 219
Actual label: 2
Output voltages: [0.67317, 0.018232, 0.79879, 0.24575, 0.0018235, 0.0011619, 0.031662, 0.30836, 0.68412, 0.0081003]
Predicted label: 2
Correct prediction
Energy consumption = 142.977764 pJ
sum error= 219
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 419 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 419 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 419 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.045682, 0.79852, 0.16622, 0.5814, 0.028392, 0.0011475, 0.19425, 0.040192, 0.031701, 0.14542]
Predicted label: 1
Correct prediction
Energy consumption = 167.070840 pJ
sum error= 219
Actual label: 1
Output voltages: [0.017965, 0.79845, 0.016904, 0.087188, 0.17782, 0.013423, 0.33078, 0.026969, 0.066426, 0.15306]
Predicted label: 1
Correct prediction
Energy consumption = 159.173975 pJ
sum error= 219
Actual label: 4
Output voltages: [0.011387, 0.011969, 0.19255, 0.0085305, 0.7986, 0.0064716, 0.23017, 0.080057, 0.034101, 0.019345]
Predicted label: 4
Correct prediction
Energy consumption = 157.036283 pJ
sum error= 219
Actual label: 6
Output voltages: [0.32134, 0.21898, 0.39221, 0.0010911, 0.047895, 0.10536, 0.79878, 0.0025719, 0.36225, 0.0044695]
Predicted label: 6
Correct prediction
Energy consumption = 151.567644 pJ
sum error= 219
Actual label: 4
Output voltages: [0.22952, 0.0036764, 0.1176, 0.023546, 0.79854, 0.0013756, 0.0018396, 0.14037, 0.0080483, 0.7631]
Predicted label: 4
Correct prediction
Energy consumption = 155.966810 pJ
sum error= 219
Actual label: 1
Output voltages: [0.20094, 0.79855, 0.039161, 0.3566, 0.037816, 0.0014068, 0.15547, 0.0051754, 0.020942, 0.66156]
Predicted label: 1
Correct prediction
Energy consumption = 161.236276 pJ
sum error= 219
Actual label: 5
Output voltages: [0.31709, 0.001069, 0.01063, 0.77546, 0.0086681, 0.77522, 0.017528, 0.098176, 0.42114, 0.16051]
Predicted label: 3
Wrong prediction!
Energy consumption = 152.377435 pJ
sum error= 220
Actual label: 4
Output voltages: [0.0085981, 0.019939, 0.11029, 0.0067657, 0.79875, 0.0035931, 0.66097, 0.037733, 0.038359, 0.40793]
Predicted label: 4
Correct prediction
Energy consumption = 155.469380 pJ
sum error= 220
Actual label: 9
Output voltages: [0.41556, 0.026983, 0.012299, 0.067642, 0.25631, 0.012702, 0.0015854, 0.01987, 0.27362, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 145.648797 pJ
sum error= 220
Actual label: 7
Output voltages: [0.034251, 0.19002, 0.0071645, 0.021171, 0.40447, 0.0024242, 0.0010709, 0.77768, 0.0011528, 0.76682]
Predicted label: 7
Correct prediction
Energy consumption = 148.336936 pJ
sum error= 220
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 420 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 420 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 420 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37502, 0.36233, 0.0039953, 0.041166, 0.011917, 0.017585, 0.0018621, 0.79871, 0.094713, 0.35905]
Predicted label: 7
Correct prediction
Energy consumption = 157.251120 pJ
sum error= 220
Actual label: 1
Output voltages: [0.19119, 0.7819, 0.0010883, 0.0010909, 0.22375, 0.0041509, 0.019547, 0.79342, 0.077149, 0.41888]
Predicted label: 7
Wrong prediction!
Energy consumption = 152.398315 pJ
sum error= 221
Actual label: 5
Output voltages: [0.026186, 0.0011124, 0.0050274, 0.16977, 0.010827, 0.79729, 0.35532, 0.0065326, 0.73432, 0.040912]
Predicted label: 5
Correct prediction
Energy consumption = 145.275437 pJ
sum error= 221
Actual label: 6
Output voltages: [0.20466, 0.020965, 0.15655, 0.0013761, 0.32916, 0.042696, 0.79879, 0.0065838, 0.666, 0.0092052]
Predicted label: 6
Correct prediction
Energy consumption = 151.501945 pJ
sum error= 221
Actual label: 2
Output voltages: [0.33135, 0.028527, 0.79877, 0.26517, 0.011033, 0.0011074, 0.36365, 0.026824, 0.54102, 0.020034]
Predicted label: 2
Correct prediction
Energy consumption = 150.645914 pJ
sum error= 221
Actual label: 2
Output voltages: [0.76117, 0.56745, 0.79248, 0.0010792, 0.013386, 0.0011795, 0.48014, 0.028774, 0.4898, 0.054225]
Predicted label: 2
Correct prediction
Energy consumption = 153.276963 pJ
sum error= 221
Actual label: 2
Output voltages: [0.69377, 0.02188, 0.79878, 0.23528, 0.012438, 0.0010831, 0.087492, 0.043881, 0.59326, 0.028263]
Predicted label: 2
Correct prediction
Energy consumption = 147.254727 pJ
sum error= 221
Actual label: 8
Output voltages: [0.073243, 0.065866, 0.78319, 0.14461, 0.019928, 0.0010671, 0.28634, 0.0018523, 0.78907, 0.026091]
Predicted label: 8
Correct prediction
Energy consumption = 136.773125 pJ
sum error= 221
Actual label: 0
Output voltages: [0.79736, 0.031135, 0.22447, 0.0060418, 0.0012208, 0.0014304, 0.64689, 0.009483, 0.13344, 0.030631]
Predicted label: 0
Correct prediction
Energy consumption = 145.414066 pJ
sum error= 221
Actual label: 6
Output voltages: [0.056981, 0.0027106, 0.036323, 0.0087582, 0.36957, 0.16419, 0.79868, 0.0013044, 0.77732, 0.023772]
Predicted label: 6
Correct prediction
Energy consumption = 143.640888 pJ
sum error= 221
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 421 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 421 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 421 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.6237, 0.015452, 0.017404, 0.077522, 0.1806, 0.026963, 0.014707, 0.016983, 0.098749, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 156.195102 pJ
sum error= 221
Actual label: 6
Output voltages: [0.26408, 0.0011611, 0.0044843, 0.063164, 0.029457, 0.6822, 0.72304, 0.03558, 0.77205, 0.0059928]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.277993 pJ
sum error= 222
Actual label: 1
Output voltages: [0.023924, 0.79855, 0.70948, 0.50485, 0.035965, 0.001154, 0.020942, 0.061664, 0.0025256, 0.051586]
Predicted label: 1
Correct prediction
Energy consumption = 149.728508 pJ
sum error= 222
Actual label: 9
Output voltages: [0.3701, 0.0026561, 0.015271, 0.037929, 0.34291, 0.0073556, 0.006691, 0.042869, 0.61853, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 158.919177 pJ
sum error= 222
Actual label: 7
Output voltages: [0.32796, 0.022725, 0.014622, 0.021056, 0.099438, 0.01483, 0.0011034, 0.79856, 0.18878, 0.16232]
Predicted label: 7
Correct prediction
Energy consumption = 152.458307 pJ
sum error= 222
Actual label: 7
Output voltages: [0.016089, 0.0018423, 0.26128, 0.63141, 0.043533, 0.0018578, 0.0011472, 0.79877, 0.74055, 0.075566]
Predicted label: 7
Correct prediction
Energy consumption = 138.810584 pJ
sum error= 222
Actual label: 1
Output voltages: [0.0043021, 0.79866, 0.0097977, 0.0086438, 0.010162, 0.0047707, 0.61913, 0.0056595, 0.65325, 0.023936]
Predicted label: 1
Correct prediction
Energy consumption = 158.045334 pJ
sum error= 222
Actual label: 4
Output voltages: [0.01811, 0.004745, 0.10631, 0.025171, 0.79856, 0.051883, 0.04472, 0.032043, 0.092123, 0.20787]
Predicted label: 4
Correct prediction
Energy consumption = 158.846938 pJ
sum error= 222
Actual label: 8
Output voltages: [0.027067, 0.071701, 0.31117, 0.093959, 0.010732, 0.028497, 0.33758, 0.016303, 0.79879, 0.051401]
Predicted label: 8
Correct prediction
Energy consumption = 147.611485 pJ
sum error= 222
Actual label: 5
Output voltages: [0.019444, 0.003932, 0.0046265, 0.45511, 0.031647, 0.79845, 0.11425, 0.019306, 0.65658, 0.21797]
Predicted label: 5
Correct prediction
Energy consumption = 142.983094 pJ
sum error= 222
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 422 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 422 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 422 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.32359, 0.008919, 0.068061, 0.79872, 0.022865, 0.082345, 0.029508, 0.010575, 0.54771, 0.16268]
Predicted label: 3
Correct prediction
Energy consumption = 152.340531 pJ
sum error= 222
Actual label: 4
Output voltages: [0.034195, 0.035044, 0.034464, 0.18371, 0.79873, 0.011781, 0.035346, 0.0030298, 0.011602, 0.36778]
Predicted label: 4
Correct prediction
Energy consumption = 148.452003 pJ
sum error= 222
Actual label: 3
Output voltages: [0.44389, 0.0067495, 0.38982, 0.79879, 0.0043371, 0.0019646, 0.011485, 0.0017657, 0.41734, 0.016614]
Predicted label: 3
Correct prediction
Energy consumption = 147.360127 pJ
sum error= 222
Actual label: 4
Output voltages: [0.0052965, 0.0012599, 0.43412, 0.0013159, 0.79855, 0.013493, 0.21748, 0.011858, 0.33186, 0.062255]
Predicted label: 4
Correct prediction
Energy consumption = 145.372651 pJ
sum error= 222
Actual label: 9
Output voltages: [0.19723, 0.10448, 0.0056851, 0.021672, 0.021972, 0.0015546, 0.0010711, 0.79841, 0.016525, 0.75272]
Predicted label: 7
Wrong prediction!
Energy consumption = 157.732238 pJ
sum error= 223
Actual label: 7
Output voltages: [0.053357, 0.0086091, 0.36794, 0.39201, 0.028449, 0.0058337, 0.0010871, 0.79879, 0.40357, 0.23493]
Predicted label: 7
Correct prediction
Energy consumption = 142.629049 pJ
sum error= 223
Actual label: 5
Output voltages: [0.028857, 0.0015378, 0.016766, 0.67388, 0.017996, 0.79879, 0.041904, 0.35846, 0.75872, 0.11342]
Predicted label: 5
Correct prediction
Energy consumption = 138.569339 pJ
sum error= 223
Actual label: 0
Output voltages: [0.79877, 0.032951, 0.029612, 0.018801, 0.039875, 0.0014415, 0.76136, 0.004202, 0.075953, 0.42535]
Predicted label: 0
Correct prediction
Energy consumption = 159.136736 pJ
sum error= 223
Actual label: 7
Output voltages: [0.012849, 0.018325, 0.65918, 0.045189, 0.02476, 0.0010834, 0.0012981, 0.79879, 0.23279, 0.14102]
Predicted label: 7
Correct prediction
Energy consumption = 145.679383 pJ
sum error= 223
Actual label: 4
Output voltages: [0.0025887, 0.010572, 0.26119, 0.036828, 0.79866, 0.0046763, 0.036237, 0.023701, 0.042267, 0.043858]
Predicted label: 4
Correct prediction
Energy consumption = 152.435321 pJ
sum error= 223
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 423 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 423 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 423 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.14592, 0.021479, 0.68553, 0.014296, 0.021813, 0.001066, 0.52814, 0.0021478, 0.79812, 0.17172]
Predicted label: 8
Correct prediction
Energy consumption = 145.986584 pJ
sum error= 223
Actual label: 8
Output voltages: [0.0066767, 0.045996, 0.2121, 0.042448, 0.0075002, 0.0097934, 0.035974, 0.027833, 0.79872, 0.20962]
Predicted label: 8
Correct prediction
Energy consumption = 139.120788 pJ
sum error= 223
Actual label: 1
Output voltages: [0.0217, 0.79838, 0.0056004, 0.22389, 0.0068543, 0.018143, 0.51823, 0.029044, 0.31912, 0.072928]
Predicted label: 1
Correct prediction
Energy consumption = 161.416175 pJ
sum error= 223
Actual label: 5
Output voltages: [0.05812, 0.0011771, 0.0012233, 0.10807, 0.031207, 0.79879, 0.13788, 0.031719, 0.78496, 0.025196]
Predicted label: 5
Correct prediction
Energy consumption = 153.364136 pJ
sum error= 223
Actual label: 3
Output voltages: [0.22314, 0.020262, 0.038022, 0.79864, 0.029427, 0.0052633, 0.016861, 0.029751, 0.70811, 0.059794]
Predicted label: 3
Correct prediction
Energy consumption = 143.475802 pJ
sum error= 223
Actual label: 9
Output voltages: [0.63869, 0.0060236, 0.024938, 0.055915, 0.14549, 0.10199, 0.0080699, 0.036348, 0.10768, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 145.284902 pJ
sum error= 223
Actual label: 5
Output voltages: [0.011894, 0.0010662, 0.0017375, 0.26644, 0.16792, 0.79877, 0.22863, 0.019307, 0.77708, 0.011159]
Predicted label: 5
Correct prediction
Energy consumption = 138.600680 pJ
sum error= 223
Actual label: 9
Output voltages: [0.70959, 0.021311, 0.021864, 0.19102, 0.54543, 0.0072679, 0.017921, 0.0069804, 0.029295, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 148.418349 pJ
sum error= 223
Actual label: 7
Output voltages: [0.27911, 0.0025187, 0.071877, 0.72706, 0.010211, 0.0010767, 0.0010824, 0.76713, 0.71174, 0.35464]
Predicted label: 7
Correct prediction
Energy consumption = 142.804823 pJ
sum error= 223
Actual label: 6
Output voltages: [0.033745, 0.0065815, 0.018117, 0.034989, 0.28693, 0.37162, 0.79819, 0.0010771, 0.76892, 0.052115]
Predicted label: 6
Correct prediction
Energy consumption = 149.444106 pJ
sum error= 223
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 424 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 424 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 424 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.21923, 0.0023026, 0.02209, 0.50034, 0.18458, 0.0051559, 0.0030607, 0.035036, 0.14192, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 156.772690 pJ
sum error= 223
Actual label: 0
Output voltages: [0.79878, 0.032016, 0.033161, 0.010138, 0.014712, 0.030106, 0.76111, 0.006739, 0.088701, 0.044015]
Predicted label: 0
Correct prediction
Energy consumption = 154.986911 pJ
sum error= 223
Actual label: 3
Output voltages: [0.24266, 0.018978, 0.021412, 0.79871, 0.013646, 0.030451, 0.02427, 0.0035151, 0.57943, 0.055505]
Predicted label: 3
Correct prediction
Energy consumption = 145.343867 pJ
sum error= 223
Actual label: 6
Output voltages: [0.20813, 0.053994, 0.03256, 0.010194, 0.033098, 0.33447, 0.79878, 0.014839, 0.6637, 0.033953]
Predicted label: 6
Correct prediction
Energy consumption = 150.872157 pJ
sum error= 223
Actual label: 3
Output voltages: [0.24524, 0.073655, 0.21728, 0.7987, 0.032776, 0.0032755, 0.021754, 0.036291, 0.20065, 0.059052]
Predicted label: 3
Correct prediction
Energy consumption = 149.206529 pJ
sum error= 223
Actual label: 9
Output voltages: [0.091583, 0.0046125, 0.058414, 0.021843, 0.31843, 0.033321, 0.093207, 0.069022, 0.17167, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 150.692395 pJ
sum error= 223
Actual label: 8
Output voltages: [0.030972, 0.03052, 0.11979, 0.067597, 0.0099481, 0.041483, 0.0061258, 0.0043752, 0.79879, 0.52875]
Predicted label: 8
Correct prediction
Energy consumption = 148.768774 pJ
sum error= 223
Actual label: 2
Output voltages: [0.31096, 0.035763, 0.79876, 0.08266, 0.013623, 0.0012238, 0.15194, 0.040107, 0.4688, 0.022385]
Predicted label: 2
Correct prediction
Energy consumption = 151.587621 pJ
sum error= 223
Actual label: 2
Output voltages: [0.26085, 0.78184, 0.31458, 0.0010677, 0.33417, 0.0011013, 0.2359, 0.033398, 0.43996, 0.06736]
Predicted label: 1
Wrong prediction!
Energy consumption = 161.920832 pJ
sum error= 224
Actual label: 1
Output voltages: [0.0097576, 0.79836, 0.10108, 0.045105, 0.01978, 0.0093343, 0.56691, 0.0089765, 0.15821, 0.1314]
Predicted label: 1
Correct prediction
Energy consumption = 158.275077 pJ
sum error= 224
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 425 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 425 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 425 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.42104, 0.043495, 0.79874, 0.10906, 0.014514, 0.0011715, 0.046273, 0.062376, 0.39392, 0.048323]
Predicted label: 2
Correct prediction
Energy consumption = 150.342118 pJ
sum error= 224
Actual label: 8
Output voltages: [0.010028, 0.51118, 0.10632, 0.20231, 0.0025119, 0.0096642, 0.013648, 0.28267, 0.79867, 0.045505]
Predicted label: 8
Correct prediction
Energy consumption = 152.491633 pJ
sum error= 224
Actual label: 6
Output voltages: [0.10421, 0.03027, 0.10878, 0.0069732, 0.30108, 0.28508, 0.79873, 0.0039243, 0.69939, 0.016182]
Predicted label: 6
Correct prediction
Energy consumption = 153.355030 pJ
sum error= 224
Actual label: 8
Output voltages: [0.020039, 0.01055, 0.44815, 0.015855, 0.029781, 0.029725, 0.089267, 0.0021448, 0.79879, 0.077115]
Predicted label: 8
Correct prediction
Energy consumption = 146.493772 pJ
sum error= 224
Actual label: 5
Output voltages: [0.012574, 0.0023757, 0.0012801, 0.57618, 0.012783, 0.79877, 0.027569, 0.06652, 0.68067, 0.038704]
Predicted label: 5
Correct prediction
Energy consumption = 151.383544 pJ
sum error= 224
Actual label: 5
Output voltages: [0.49363, 0.0020942, 0.040066, 0.13585, 0.0011009, 0.78532, 0.72939, 0.039925, 0.36435, 0.003379]
Predicted label: 5
Correct prediction
Energy consumption = 142.299065 pJ
sum error= 224
Actual label: 3
Output voltages: [0.77819, 0.011392, 0.45724, 0.79763, 0.0011845, 0.022964, 0.27564, 0.037814, 0.020827, 0.02029]
Predicted label: 3
Correct prediction
Energy consumption = 143.543542 pJ
sum error= 224
Actual label: 9
Output voltages: [0.26654, 0.009605, 0.04307, 0.049981, 0.10507, 0.070556, 0.040889, 0.031065, 0.11435, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 155.051463 pJ
sum error= 224
Actual label: 4
Output voltages: [0.0036857, 0.025287, 0.13672, 0.01198, 0.79869, 0.0010804, 0.18829, 0.040976, 0.0333, 0.33476]
Predicted label: 4
Correct prediction
Energy consumption = 156.693894 pJ
sum error= 224
Actual label: 9
Output voltages: [0.67749, 0.16672, 0.0017208, 0.26426, 0.76093, 0.27199, 0.045146, 0.014924, 0.03589, 0.7985]
Predicted label: 9
Correct prediction
Energy consumption = 151.633117 pJ
sum error= 224
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 426 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 426 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 426 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.59283, 0.6935, 0.79877, 0.025346, 0.0047494, 0.001315, 0.037871, 0.27272, 0.1573, 0.037513]
Predicted label: 2
Correct prediction
Energy consumption = 150.800772 pJ
sum error= 224
Actual label: 5
Output voltages: [0.0013572, 0.0010698, 0.006194, 0.49972, 0.12477, 0.7887, 0.26986, 0.01098, 0.7421, 0.072835]
Predicted label: 5
Correct prediction
Energy consumption = 145.171408 pJ
sum error= 224
Actual label: 1
Output voltages: [0.024154, 0.79879, 0.16002, 0.046685, 0.339, 0.0010878, 0.40786, 0.0043616, 0.039267, 0.065307]
Predicted label: 1
Correct prediction
Energy consumption = 156.495413 pJ
sum error= 224
Actual label: 5
Output voltages: [0.042609, 0.0028847, 0.0025177, 0.5462, 0.016504, 0.79872, 0.026805, 0.030134, 0.76954, 0.046125]
Predicted label: 5
Correct prediction
Energy consumption = 149.127584 pJ
sum error= 224
Actual label: 1
Output voltages: [0.10195, 0.79853, 0.35902, 0.24511, 0.087224, 0.00516, 0.46147, 0.0068643, 0.020388, 0.11309]
Predicted label: 1
Correct prediction
Energy consumption = 169.750060 pJ
sum error= 224
Actual label: 4
Output voltages: [0.4432, 0.72923, 0.0010663, 0.31868, 0.73712, 0.0011555, 0.029608, 0.039107, 0.027502, 0.3664]
Predicted label: 4
Correct prediction
Energy consumption = 160.603996 pJ
sum error= 224
Actual label: 4
Output voltages: [0.0048832, 0.0049681, 0.068925, 0.022155, 0.79871, 0.0024565, 0.041079, 0.19896, 0.27902, 0.0051204]
Predicted label: 4
Correct prediction
Energy consumption = 149.444863 pJ
sum error= 224
Actual label: 1
Output voltages: [0.005721, 0.79852, 0.015522, 0.040219, 0.032356, 0.0059576, 0.67358, 0.01351, 0.38174, 0.026316]
Predicted label: 1
Correct prediction
Energy consumption = 157.453559 pJ
sum error= 224
Actual label: 4
Output voltages: [0.0038165, 0.0042176, 0.021396, 0.15143, 0.78863, 0.53626, 0.21919, 0.0034727, 0.065699, 0.4331]
Predicted label: 4
Correct prediction
Energy consumption = 150.324394 pJ
sum error= 224
Actual label: 4
Output voltages: [0.50345, 0.0018072, 0.04703, 0.0010714, 0.79833, 0.0043856, 0.65963, 0.016751, 0.19061, 0.015483]
Predicted label: 4
Correct prediction
Energy consumption = 147.058636 pJ
sum error= 224
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 427 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 427 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 427 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.25448, 0.0069614, 0.19466, 0.79874, 0.033146, 0.17607, 0.0019826, 0.0072749, 0.65168, 0.017065]
Predicted label: 3
Correct prediction
Energy consumption = 147.119746 pJ
sum error= 224
Actual label: 5
Output voltages: [0.25394, 0.0084942, 0.0039996, 0.79869, 0.010435, 0.7299, 0.040269, 0.028794, 0.68088, 0.36549]
Predicted label: 3
Wrong prediction!
Energy consumption = 147.900035 pJ
sum error= 225
Actual label: 9
Output voltages: [0.53132, 0.0022514, 0.14533, 0.61285, 0.098177, 0.031538, 0.0016811, 0.49262, 0.27113, 0.79589]
Predicted label: 9
Correct prediction
Energy consumption = 147.885066 pJ
sum error= 225
Actual label: 1
Output voltages: [0.033666, 0.79852, 0.059618, 0.23833, 0.03352, 0.0012265, 0.047388, 0.0055191, 0.21226, 0.077326]
Predicted label: 1
Correct prediction
Energy consumption = 166.243204 pJ
sum error= 225
Actual label: 2
Output voltages: [0.30006, 0.042974, 0.79876, 0.15692, 0.019588, 0.0012885, 0.31277, 0.031691, 0.49107, 0.022492]
Predicted label: 2
Correct prediction
Energy consumption = 151.892640 pJ
sum error= 225
Actual label: 2
Output voltages: [0.43033, 0.022304, 0.79877, 0.048037, 0.0069631, 0.0011567, 0.023132, 0.19872, 0.46387, 0.010079]
Predicted label: 2
Correct prediction
Energy consumption = 134.342789 pJ
sum error= 225
Actual label: 3
Output voltages: [0.061004, 0.0053311, 0.27946, 0.79876, 0.16381, 0.090739, 0.042056, 0.010223, 0.29665, 0.2394]
Predicted label: 3
Correct prediction
Energy consumption = 144.951026 pJ
sum error= 225
Actual label: 3
Output voltages: [0.43781, 0.0089349, 0.027965, 0.79877, 0.0083532, 0.01851, 0.037027, 0.018689, 0.26128, 0.015106]
Predicted label: 3
Correct prediction
Energy consumption = 137.470530 pJ
sum error= 225
Actual label: 0
Output voltages: [0.79879, 0.35508, 0.030793, 0.014947, 0.014981, 0.014641, 0.47133, 0.010992, 0.040213, 0.15797]
Predicted label: 0
Correct prediction
Energy consumption = 153.529738 pJ
sum error= 225
Actual label: 2
Output voltages: [0.4147, 0.013127, 0.79859, 0.64437, 0.020455, 0.0011049, 0.022327, 0.026778, 0.47944, 0.082615]
Predicted label: 2
Correct prediction
Energy consumption = 143.759745 pJ
sum error= 225
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 428 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 428 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 428 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.08807, 0.057336, 0.3202, 0.014227, 0.71608, 0.0041767, 0.0014598, 0.0024634, 0.054242, 0.79748]
Predicted label: 9
Correct prediction
Energy consumption = 152.420477 pJ
sum error= 225
Actual label: 0
Output voltages: [0.79869, 0.055884, 0.20562, 0.032728, 0.015749, 0.001254, 0.51961, 0.009922, 0.13663, 0.14288]
Predicted label: 0
Correct prediction
Energy consumption = 156.459213 pJ
sum error= 225
Actual label: 0
Output voltages: [0.79825, 0.25185, 0.015807, 0.0093693, 0.003959, 0.0024736, 0.6396, 0.075125, 0.12199, 0.067534]
Predicted label: 0
Correct prediction
Energy consumption = 133.702945 pJ
sum error= 225
Actual label: 9
Output voltages: [0.22742, 0.023238, 0.023965, 0.24359, 0.2331, 0.1282, 0.052046, 0.033147, 0.051639, 0.79839]
Predicted label: 9
Correct prediction
Energy consumption = 147.356416 pJ
sum error= 225
Actual label: 9
Output voltages: [0.014061, 0.0010669, 0.0058574, 0.43135, 0.74388, 0.25004, 0.021029, 0.0093201, 0.23484, 0.36206]
Predicted label: 4
Wrong prediction!
Energy consumption = 155.598335 pJ
sum error= 226
Actual label: 6
Output voltages: [0.25812, 0.011445, 0.036581, 0.0094631, 0.055889, 0.49658, 0.79871, 0.0011951, 0.55725, 0.067612]
Predicted label: 6
Correct prediction
Energy consumption = 148.847798 pJ
sum error= 226
Actual label: 0
Output voltages: [0.79872, 0.057978, 0.084982, 0.038325, 0.0037843, 0.020867, 0.056591, 0.018602, 0.26532, 0.031657]
Predicted label: 0
Correct prediction
Energy consumption = 150.426498 pJ
sum error= 226
Actual label: 9
Output voltages: [0.64719, 0.0010713, 0.20715, 0.0094822, 0.22414, 0.0054736, 0.033329, 0.016647, 0.57056, 0.79544]
Predicted label: 9
Correct prediction
Energy consumption = 151.101825 pJ
sum error= 226
Actual label: 3
Output voltages: [0.23593, 0.025023, 0.025138, 0.79863, 0.015127, 0.0098235, 0.01102, 0.015455, 0.533, 0.06082]
Predicted label: 3
Correct prediction
Energy consumption = 152.256270 pJ
sum error= 226
Actual label: 2
Output voltages: [0.17681, 0.039673, 0.79875, 0.0059981, 0.0038627, 0.0013091, 0.06783, 0.74532, 0.51896, 0.014439]
Predicted label: 2
Correct prediction
Energy consumption = 137.651963 pJ
sum error= 226
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 429 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 429 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 429 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0054822, 0.0027817, 0.03533, 0.041247, 0.01622, 0.21711, 0.075774, 0.0095978, 0.79876, 0.064737]
Predicted label: 8
Correct prediction
Energy consumption = 153.554781 pJ
sum error= 226
Actual label: 4
Output voltages: [0.020439, 0.022129, 0.027592, 0.003, 0.79874, 0.0023628, 0.40403, 0.031539, 0.14244, 0.1706]
Predicted label: 4
Correct prediction
Energy consumption = 155.055544 pJ
sum error= 226
Actual label: 1
Output voltages: [0.057132, 0.79847, 0.037985, 0.030895, 0.019622, 0.0015333, 0.56125, 0.0014883, 0.3746, 0.073031]
Predicted label: 1
Correct prediction
Energy consumption = 165.530681 pJ
sum error= 226
Actual label: 9
Output voltages: [0.11207, 0.016105, 0.031473, 0.060674, 0.40683, 0.031729, 0.38781, 0.007433, 0.083669, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 157.553215 pJ
sum error= 226
Actual label: 9
Output voltages: [0.56842, 0.01183, 0.0011157, 0.60957, 0.27664, 0.77799, 0.0046622, 0.20551, 0.039246, 0.79209]
Predicted label: 9
Correct prediction
Energy consumption = 142.453755 pJ
sum error= 226
Actual label: 7
Output voltages: [0.023643, 0.078817, 0.092422, 0.12937, 0.0050364, 0.0011121, 0.0016304, 0.79878, 0.17562, 0.51754]
Predicted label: 7
Correct prediction
Energy consumption = 156.497999 pJ
sum error= 226
Actual label: 2
Output voltages: [0.022723, 0.23909, 0.79879, 0.1995, 0.026927, 0.0010869, 0.48608, 0.0084086, 0.48429, 0.05808]
Predicted label: 2
Correct prediction
Energy consumption = 151.575023 pJ
sum error= 226
Actual label: 7
Output voltages: [0.13376, 0.74602, 0.16507, 0.4524, 0.0010704, 0.0010662, 0.0011512, 0.79878, 0.53451, 0.11305]
Predicted label: 7
Correct prediction
Energy consumption = 152.817919 pJ
sum error= 226
Actual label: 9
Output voltages: [0.27718, 0.0089254, 0.052493, 0.61874, 0.014992, 0.23154, 0.0059775, 0.13188, 0.16817, 0.79863]
Predicted label: 9
Correct prediction
Energy consumption = 144.456916 pJ
sum error= 226
Actual label: 9
Output voltages: [0.10596, 0.017376, 0.020555, 0.038796, 0.50324, 0.0011607, 0.0019643, 0.0038493, 0.4753, 0.78856]
Predicted label: 9
Correct prediction
Energy consumption = 151.130144 pJ
sum error= 226
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 430 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 430 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 430 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.37604, 0.067134, 0.0010979, 0.76269, 0.0010828, 0.77891, 0.68908, 0.0010834, 0.76611, 0.011386]
Predicted label: 5
Correct prediction
Energy consumption = 152.520433 pJ
sum error= 226
Actual label: 9
Output voltages: [0.26403, 0.0070758, 0.052578, 0.017861, 0.23542, 0.1788, 0.026358, 0.044937, 0.15765, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 150.922863 pJ
sum error= 226
Actual label: 5
Output voltages: [0.14899, 0.001069, 0.0011244, 0.10069, 0.13827, 0.79834, 0.31049, 0.0018884, 0.51895, 0.023571]
Predicted label: 5
Correct prediction
Energy consumption = 132.719358 pJ
sum error= 226
Actual label: 1
Output voltages: [0.038951, 0.79872, 0.002344, 0.014766, 0.14951, 0.0072822, 0.34896, 0.020252, 0.028432, 0.030813]
Predicted label: 1
Correct prediction
Energy consumption = 154.259326 pJ
sum error= 226
Actual label: 1
Output voltages: [0.0022823, 0.79845, 0.079795, 0.018889, 0.0051208, 0.013437, 0.53519, 0.02811, 0.46266, 0.0072122]
Predicted label: 1
Correct prediction
Energy consumption = 148.603098 pJ
sum error= 226
Actual label: 8
Output voltages: [0.19656, 0.03581, 0.74641, 0.01857, 0.011292, 0.0012414, 0.033958, 0.0012532, 0.79868, 0.26587]
Predicted label: 8
Correct prediction
Energy consumption = 140.002749 pJ
sum error= 226
Actual label: 3
Output voltages: [0.04281, 0.33777, 0.0075084, 0.79832, 0.0010675, 0.038975, 0.0010772, 0.52285, 0.78173, 0.13746]
Predicted label: 3
Correct prediction
Energy consumption = 140.536119 pJ
sum error= 226
Actual label: 5
Output voltages: [0.21132, 0.0018402, 0.001348, 0.63705, 0.02369, 0.79878, 0.46398, 0.011927, 0.72964, 0.022189]
Predicted label: 5
Correct prediction
Energy consumption = 147.257326 pJ
sum error= 226
Actual label: 1
Output voltages: [0.034941, 0.79869, 0.014637, 0.015661, 0.014973, 0.0090546, 0.70792, 0.0045448, 0.45252, 0.007009]
Predicted label: 1
Correct prediction
Energy consumption = 157.920565 pJ
sum error= 226
Actual label: 9
Output voltages: [0.3519, 0.011638, 0.051951, 0.015612, 0.18469, 0.0075682, 0.0034171, 0.0083653, 0.43388, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 153.978820 pJ
sum error= 226
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 431 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 431 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 431 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.24518, 0.0079999, 0.0010756, 0.21904, 0.0083465, 0.79873, 0.18666, 0.098613, 0.7748, 0.0010672]
Predicted label: 5
Correct prediction
Energy consumption = 152.209118 pJ
sum error= 226
Actual label: 3
Output voltages: [0.35854, 0.0078087, 0.13711, 0.79876, 0.19451, 0.21357, 0.033032, 0.0030324, 0.62121, 0.043268]
Predicted label: 3
Correct prediction
Energy consumption = 147.939267 pJ
sum error= 226
Actual label: 5
Output voltages: [0.059308, 0.0036864, 0.0010712, 0.33219, 0.0044797, 0.79877, 0.17455, 0.030468, 0.69361, 0.0011024]
Predicted label: 5
Correct prediction
Energy consumption = 146.882353 pJ
sum error= 226
Actual label: 4
Output voltages: [0.0013818, 0.039898, 0.0057252, 0.0011075, 0.79836, 0.0014542, 0.073718, 0.039565, 0.39854, 0.22699]
Predicted label: 4
Correct prediction
Energy consumption = 147.245727 pJ
sum error= 226
Actual label: 9
Output voltages: [0.097405, 0.04236, 0.035562, 0.35624, 0.030631, 0.0010955, 0.0020626, 0.040542, 0.50012, 0.7975]
Predicted label: 9
Correct prediction
Energy consumption = 156.443310 pJ
sum error= 226
Actual label: 5
Output voltages: [0.035803, 0.0010684, 0.002125, 0.75053, 0.043021, 0.79756, 0.25193, 0.024588, 0.54963, 0.087481]
Predicted label: 5
Correct prediction
Energy consumption = 142.543327 pJ
sum error= 226
Actual label: 9
Output voltages: [0.21753, 0.030006, 0.025393, 0.34857, 0.29863, 0.0018881, 0.0011237, 0.026338, 0.13921, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 150.617792 pJ
sum error= 226
Actual label: 3
Output voltages: [0.48895, 0.043659, 0.0017876, 0.79707, 0.0016152, 0.30024, 0.001168, 0.074292, 0.59271, 0.061802]
Predicted label: 3
Correct prediction
Energy consumption = 143.642207 pJ
sum error= 226
Actual label: 1
Output voltages: [0.010073, 0.79867, 0.0091958, 0.03251, 0.010081, 0.0064899, 0.5204, 0.0049708, 0.3528, 0.046937]
Predicted label: 1
Correct prediction
Energy consumption = 151.360795 pJ
sum error= 226
Actual label: 9
Output voltages: [0.72097, 0.0014146, 0.028929, 0.025229, 0.42997, 0.024777, 0.0032579, 0.037863, 0.046136, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 162.250387 pJ
sum error= 226
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 432 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 432 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 432 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79781, 0.052673, 0.11057, 0.013613, 0.0085207, 0.0011724, 0.62351, 0.013812, 0.33443, 0.30359]
Predicted label: 0
Correct prediction
Energy consumption = 147.931126 pJ
sum error= 226
Actual label: 9
Output voltages: [0.3618, 0.036769, 0.031974, 0.48401, 0.011043, 0.027132, 0.012435, 0.016654, 0.21162, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 153.117925 pJ
sum error= 226
Actual label: 7
Output voltages: [0.10991, 0.06092, 0.02885, 0.022139, 0.028266, 0.0023449, 0.0019418, 0.79853, 0.16665, 0.067083]
Predicted label: 7
Correct prediction
Energy consumption = 157.943434 pJ
sum error= 226
Actual label: 5
Output voltages: [0.038966, 0.02527, 0.0027426, 0.61681, 0.0040177, 0.79876, 0.033267, 0.0014972, 0.62322, 0.0097561]
Predicted label: 5
Correct prediction
Energy consumption = 145.664326 pJ
sum error= 226
Actual label: 4
Output voltages: [0.0039451, 0.0026811, 0.17799, 0.020452, 0.7986, 0.0028116, 0.039305, 0.042306, 0.049339, 0.14252]
Predicted label: 4
Correct prediction
Energy consumption = 157.551783 pJ
sum error= 226
Actual label: 9
Output voltages: [0.16382, 0.0042557, 0.017442, 0.0058612, 0.042852, 0.0036159, 0.0010928, 0.024575, 0.67396, 0.79778]
Predicted label: 9
Correct prediction
Energy consumption = 148.969115 pJ
sum error= 226
Actual label: 2
Output voltages: [0.54114, 0.037786, 0.79864, 0.30445, 0.026455, 0.0011883, 0.046496, 0.27426, 0.0966, 0.014928]
Predicted label: 2
Correct prediction
Energy consumption = 153.624271 pJ
sum error= 226
Actual label: 0
Output voltages: [0.79865, 0.046061, 0.020384, 0.69763, 0.0010825, 0.59245, 0.029571, 0.0012792, 0.09937, 0.13537]
Predicted label: 0
Correct prediction
Energy consumption = 149.505066 pJ
sum error= 226
Actual label: 1
Output voltages: [0.0034764, 0.79852, 0.088904, 0.12485, 0.020304, 0.0026059, 0.64239, 0.00645, 0.045457, 0.058663]
Predicted label: 1
Correct prediction
Energy consumption = 166.752337 pJ
sum error= 226
Actual label: 0
Output voltages: [0.79864, 0.0094105, 0.21285, 0.0013435, 0.0013158, 0.0080936, 0.21627, 0.0078363, 0.3961, 0.0055358]
Predicted label: 0
Correct prediction
Energy consumption = 157.245889 pJ
sum error= 226
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 433 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 433 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 433 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.013369, 0.0010704, 0.018794, 0.061815, 0.0022413, 0.47509, 0.033357, 0.0011186, 0.79584, 0.12865]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.741708 pJ
sum error= 227
Actual label: 1
Output voltages: [0.043066, 0.79845, 0.097842, 0.016711, 0.25846, 0.0087017, 0.25116, 0.015597, 0.0076125, 0.34524]
Predicted label: 1
Correct prediction
Energy consumption = 165.307374 pJ
sum error= 227
Actual label: 4
Output voltages: [0.012146, 0.0068238, 0.18249, 0.0041696, 0.79871, 0.0010868, 0.037395, 0.040399, 0.027621, 0.137]
Predicted label: 4
Correct prediction
Energy consumption = 157.383734 pJ
sum error= 227
Actual label: 9
Output voltages: [0.048686, 0.017044, 0.0038006, 0.6011, 0.70118, 0.025327, 0.0052259, 0.35634, 0.0084857, 0.7899]
Predicted label: 9
Correct prediction
Energy consumption = 154.754470 pJ
sum error= 227
Actual label: 3
Output voltages: [0.46487, 0.0186, 0.016388, 0.79875, 0.051793, 0.29539, 0.025637, 0.045526, 0.36866, 0.01985]
Predicted label: 3
Correct prediction
Energy consumption = 147.397420 pJ
sum error= 227
Actual label: 3
Output voltages: [0.014538, 0.1849, 0.19803, 0.79863, 0.04018, 0.014487, 0.0021666, 0.089647, 0.49197, 0.44418]
Predicted label: 3
Correct prediction
Energy consumption = 140.418404 pJ
sum error= 227
Actual label: 6
Output voltages: [0.16058, 0.047651, 0.28389, 0.0083361, 0.49766, 0.23961, 0.79868, 0.0022766, 0.41145, 0.020497]
Predicted label: 6
Correct prediction
Energy consumption = 152.238592 pJ
sum error= 227
Actual label: 1
Output voltages: [0.018041, 0.79853, 0.046329, 0.15718, 0.042896, 0.0054721, 0.25264, 0.0018502, 0.46576, 0.09024]
Predicted label: 1
Correct prediction
Energy consumption = 161.905392 pJ
sum error= 227
Actual label: 5
Output voltages: [0.49537, 0.001066, 0.0027287, 0.57126, 0.010908, 0.79879, 0.044964, 0.1075, 0.78122, 0.15411]
Predicted label: 5
Correct prediction
Energy consumption = 152.029018 pJ
sum error= 227
Actual label: 2
Output voltages: [0.53906, 0.38709, 0.79874, 0.031117, 0.017945, 0.0013039, 0.31256, 0.1002, 0.31985, 0.066065]
Predicted label: 2
Correct prediction
Energy consumption = 155.886629 pJ
sum error= 227
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 434 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 434 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 434 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.13011, 0.0012686, 0.0050051, 0.50615, 0.011436, 0.79875, 0.025598, 0.29532, 0.76979, 0.03917]
Predicted label: 5
Correct prediction
Energy consumption = 150.049586 pJ
sum error= 227
Actual label: 2
Output voltages: [0.48368, 0.0021396, 0.78757, 0.64081, 0.016162, 0.0012441, 0.015863, 0.041847, 0.70226, 0.033384]
Predicted label: 2
Correct prediction
Energy consumption = 147.671131 pJ
sum error= 227
Actual label: 2
Output voltages: [0.42273, 0.038948, 0.79876, 0.063923, 0.024365, 0.0012865, 0.33939, 0.05396, 0.57401, 0.039402]
Predicted label: 2
Correct prediction
Energy consumption = 138.382988 pJ
sum error= 227
Actual label: 0
Output voltages: [0.78813, 0.023362, 0.1134, 0.17083, 0.0051741, 0.0020399, 0.037248, 0.0026068, 0.78756, 0.041327]
Predicted label: 0
Correct prediction
Energy consumption = 152.624429 pJ
sum error= 227
Actual label: 9
Output voltages: [0.076495, 0.0010924, 0.042385, 0.39369, 0.050792, 0.010943, 0.029995, 0.3798, 0.038735, 0.79711]
Predicted label: 9
Correct prediction
Energy consumption = 145.364073 pJ
sum error= 227
Actual label: 2
Output voltages: [0.41879, 0.033292, 0.79867, 0.033795, 0.027609, 0.001066, 0.036848, 0.024872, 0.44897, 0.0040372]
Predicted label: 2
Correct prediction
Energy consumption = 144.737347 pJ
sum error= 227
Actual label: 6
Output voltages: [0.045485, 0.026015, 0.44236, 0.0010868, 0.36478, 0.57294, 0.79876, 0.0032394, 0.19323, 0.0025785]
Predicted label: 6
Correct prediction
Energy consumption = 145.347936 pJ
sum error= 227
Actual label: 6
Output voltages: [0.062595, 0.029422, 0.041651, 0.0022714, 0.26913, 0.19714, 0.79876, 0.0015626, 0.73735, 0.0021773]
Predicted label: 6
Correct prediction
Energy consumption = 142.842441 pJ
sum error= 227
Actual label: 0
Output voltages: [0.79871, 0.087277, 0.046763, 0.027975, 0.01221, 0.0018838, 0.69565, 0.011912, 0.30581, 0.03434]
Predicted label: 0
Correct prediction
Energy consumption = 141.441989 pJ
sum error= 227
Actual label: 1
Output voltages: [0.017187, 0.79866, 0.0041403, 0.23248, 0.23661, 0.0022644, 0.67401, 0.0011289, 0.6573, 0.14977]
Predicted label: 1
Correct prediction
Energy consumption = 160.596041 pJ
sum error= 227
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 435 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 435 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 435 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.06512, 0.023952, 0.72751, 0.76787, 0.0016106, 0.018751, 0.010265, 0.0045177, 0.79879, 0.010128]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.829648 pJ
sum error= 228
Actual label: 0
Output voltages: [0.7987, 0.045455, 0.021836, 0.11927, 0.0063028, 0.04917, 0.20812, 0.014243, 0.030108, 0.034308]
Predicted label: 0
Correct prediction
Energy consumption = 150.987507 pJ
sum error= 228
Actual label: 3
Output voltages: [0.041676, 0.022632, 0.020209, 0.79863, 0.025683, 0.0082283, 0.0099705, 0.020783, 0.54169, 0.15847]
Predicted label: 3
Correct prediction
Energy consumption = 143.364894 pJ
sum error= 228
Actual label: 0
Output voltages: [0.79879, 0.026164, 0.034527, 0.017743, 0.045917, 0.014734, 0.30315, 0.00594, 0.12211, 0.036745]
Predicted label: 0
Correct prediction
Energy consumption = 162.235343 pJ
sum error= 228
Actual label: 2
Output voltages: [0.49787, 0.38486, 0.79878, 0.02374, 0.012797, 0.0013981, 0.25434, 0.089318, 0.18771, 0.035842]
Predicted label: 2
Correct prediction
Energy consumption = 149.373276 pJ
sum error= 228
Actual label: 5
Output voltages: [0.0082754, 0.0013368, 0.0065532, 0.58051, 0.065147, 0.7962, 0.15622, 0.029264, 0.73638, 0.40746]
Predicted label: 5
Correct prediction
Energy consumption = 145.196580 pJ
sum error= 228
Actual label: 5
Output voltages: [0.1277, 0.0011262, 0.019021, 0.5165, 0.01261, 0.78615, 0.23011, 0.010135, 0.78793, 0.034458]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.204877 pJ
sum error= 229
Actual label: 7
Output voltages: [0.67654, 0.12684, 0.022663, 0.48579, 0.0162, 0.036871, 0.0011129, 0.79871, 0.023018, 0.2088]
Predicted label: 7
Correct prediction
Energy consumption = 158.218634 pJ
sum error= 229
Actual label: 9
Output voltages: [0.22116, 0.010952, 0.0034951, 0.19711, 0.075357, 0.0023328, 0.001158, 0.0084328, 0.50372, 0.79723]
Predicted label: 9
Correct prediction
Energy consumption = 152.388815 pJ
sum error= 229
Actual label: 5
Output voltages: [0.11259, 0.0072053, 0.0020195, 0.21316, 0.014672, 0.79821, 0.045298, 0.26119, 0.29954, 0.36446]
Predicted label: 5
Correct prediction
Energy consumption = 152.162835 pJ
sum error= 229
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 436 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 436 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 436 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.25392, 0.00131, 0.001077, 0.78842, 0.14088, 0.78408, 0.045005, 0.0022787, 0.4646, 0.22475]
Predicted label: 3
Wrong prediction!
Energy consumption = 155.812726 pJ
sum error= 230
Actual label: 0
Output voltages: [0.79867, 0.020146, 0.033095, 0.016085, 0.037028, 0.015129, 0.48103, 0.091035, 0.10255, 0.071788]
Predicted label: 0
Correct prediction
Energy consumption = 159.178342 pJ
sum error= 230
Actual label: 8
Output voltages: [0.041964, 0.01829, 0.41096, 0.36111, 0.0034875, 0.033592, 0.10209, 0.028134, 0.79877, 0.053583]
Predicted label: 8
Correct prediction
Energy consumption = 151.876590 pJ
sum error= 230
Actual label: 9
Output voltages: [0.030587, 0.0015821, 0.0095175, 0.049459, 0.043046, 0.6805, 0.01254, 0.08739, 0.38714, 0.79001]
Predicted label: 9
Correct prediction
Energy consumption = 144.171976 pJ
sum error= 230
Actual label: 5
Output voltages: [0.17042, 0.002941, 0.0011577, 0.47235, 0.012233, 0.7967, 0.048445, 0.0013689, 0.77241, 0.0037531]
Predicted label: 5
Correct prediction
Energy consumption = 137.115413 pJ
sum error= 230
Actual label: 0
Output voltages: [0.79868, 0.11719, 0.19377, 0.012268, 0.0078869, 0.0013205, 0.67076, 0.018674, 0.048243, 0.52155]
Predicted label: 0
Correct prediction
Energy consumption = 155.292621 pJ
sum error= 230
Actual label: 3
Output voltages: [0.17439, 0.017078, 0.19597, 0.79868, 0.029303, 0.020584, 0.0080248, 0.014943, 0.58866, 0.064369]
Predicted label: 3
Correct prediction
Energy consumption = 144.450503 pJ
sum error= 230
Actual label: 2
Output voltages: [0.60604, 0.1409, 0.79869, 0.23534, 0.04031, 0.0012913, 0.03458, 0.11903, 0.13275, 0.022412]
Predicted label: 2
Correct prediction
Energy consumption = 139.498381 pJ
sum error= 230
Actual label: 5
Output voltages: [0.11583, 0.0010809, 0.01662, 0.48462, 0.001291, 0.79866, 0.12906, 0.22005, 0.77742, 0.0034938]
Predicted label: 5
Correct prediction
Energy consumption = 149.975367 pJ
sum error= 230
Actual label: 9
Output voltages: [0.49185, 0.010164, 0.027559, 0.029627, 0.78535, 0.0010839, 0.0011272, 0.0020921, 0.13545, 0.79814]
Predicted label: 9
Correct prediction
Energy consumption = 141.951614 pJ
sum error= 230
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 437 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 437 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 437 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7987, 0.23251, 0.058943, 0.046685, 0.12085, 0.022221, 0.4487, 0.032059, 0.18249, 0.017128]
Predicted label: 0
Correct prediction
Energy consumption = 160.269798 pJ
sum error= 230
Actual label: 8
Output voltages: [0.019802, 0.25968, 0.039956, 0.36754, 0.0011241, 0.043708, 0.0025841, 0.011076, 0.79876, 0.053951]
Predicted label: 8
Correct prediction
Energy consumption = 156.482988 pJ
sum error= 230
Actual label: 8
Output voltages: [0.030778, 0.040416, 0.36899, 0.043241, 0.017768, 0.013593, 0.053667, 0.017352, 0.7987, 0.06394]
Predicted label: 8
Correct prediction
Energy consumption = 138.915236 pJ
sum error= 230
Actual label: 4
Output voltages: [0.0024202, 0.0060625, 0.30726, 0.0027325, 0.79872, 0.0013621, 0.55181, 0.1203, 0.052887, 0.21609]
Predicted label: 4
Correct prediction
Energy consumption = 153.854626 pJ
sum error= 230
Actual label: 5
Output voltages: [0.051882, 0.0010661, 0.0061819, 0.24626, 0.0095233, 0.79875, 0.10761, 0.2098, 0.75163, 0.21588]
Predicted label: 5
Correct prediction
Energy consumption = 146.560256 pJ
sum error= 230
Actual label: 8
Output voltages: [0.026715, 0.044897, 0.38435, 0.29958, 0.0014641, 0.034713, 0.15458, 0.021889, 0.79871, 0.010826]
Predicted label: 8
Correct prediction
Energy consumption = 149.291709 pJ
sum error= 230
Actual label: 8
Output voltages: [0.018335, 0.095153, 0.006915, 0.40943, 0.010371, 0.03973, 0.0015145, 0.0042631, 0.79879, 0.30839]
Predicted label: 8
Correct prediction
Energy consumption = 143.818784 pJ
sum error= 230
Actual label: 4
Output voltages: [0.0049823, 0.012335, 0.053378, 0.017029, 0.79868, 0.0011336, 0.061079, 0.073992, 0.024497, 0.025288]
Predicted label: 4
Correct prediction
Energy consumption = 153.702496 pJ
sum error= 230
Actual label: 5
Output voltages: [0.074761, 0.0010981, 0.0071516, 0.28426, 0.010917, 0.79852, 0.16597, 0.015485, 0.75847, 0.040324]
Predicted label: 5
Correct prediction
Energy consumption = 143.864130 pJ
sum error= 230
Actual label: 4
Output voltages: [0.010549, 0.010906, 0.27577, 0.02787, 0.79866, 0.0038162, 0.12848, 0.18262, 0.022445, 0.047121]
Predicted label: 4
Correct prediction
Energy consumption = 155.059234 pJ
sum error= 230
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 438 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 438 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 438 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0061222, 0.0044885, 0.044029, 0.38732, 0.0030819, 0.13627, 0.58108, 0.0010699, 0.79425, 0.020901]
Predicted label: 8
Correct prediction
Energy consumption = 151.225871 pJ
sum error= 230
Actual label: 5
Output voltages: [0.021247, 0.001066, 0.005589, 0.31197, 0.033456, 0.79681, 0.045112, 0.031208, 0.77541, 0.047305]
Predicted label: 5
Correct prediction
Energy consumption = 141.045310 pJ
sum error= 230
Actual label: 4
Output voltages: [0.09833, 0.0096039, 0.030043, 0.019833, 0.79879, 0.0011485, 0.0064874, 0.057452, 0.0083767, 0.65422]
Predicted label: 4
Correct prediction
Energy consumption = 150.077807 pJ
sum error= 230
Actual label: 9
Output voltages: [0.57612, 0.001099, 0.018956, 0.23125, 0.41233, 0.0019561, 0.0013733, 0.054575, 0.11083, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 147.551527 pJ
sum error= 230
Actual label: 2
Output voltages: [0.047939, 0.79626, 0.77263, 0.33798, 0.12891, 0.001077, 0.6445, 0.001956, 0.069513, 0.022686]
Predicted label: 1
Wrong prediction!
Energy consumption = 156.147865 pJ
sum error= 231
Actual label: 2
Output voltages: [0.436, 0.33981, 0.79878, 0.24959, 0.012263, 0.0013164, 0.29407, 0.035181, 0.48808, 0.13146]
Predicted label: 2
Correct prediction
Energy consumption = 138.725564 pJ
sum error= 231
Actual label: 1
Output voltages: [0.012464, 0.7987, 0.0047673, 0.020172, 0.055589, 0.0016343, 0.46782, 0.0012745, 0.6046, 0.017647]
Predicted label: 1
Correct prediction
Energy consumption = 158.368071 pJ
sum error= 231
Actual label: 2
Output voltages: [0.032976, 0.45576, 0.79868, 0.038946, 0.054596, 0.0011198, 0.017182, 0.040221, 0.23737, 0.0054248]
Predicted label: 2
Correct prediction
Energy consumption = 144.700212 pJ
sum error= 231
Actual label: 6
Output voltages: [0.19943, 0.19603, 0.27012, 0.022504, 0.14184, 0.29595, 0.79869, 0.0022756, 0.25243, 0.070186]
Predicted label: 6
Correct prediction
Energy consumption = 145.316349 pJ
sum error= 231
Actual label: 8
Output voltages: [0.0046049, 0.31517, 0.048395, 0.3499, 0.0035842, 0.0054337, 0.14644, 0.022098, 0.79874, 0.066084]
Predicted label: 8
Correct prediction
Energy consumption = 155.906506 pJ
sum error= 231
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 439 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 439 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 439 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.030244, 0.019401, 0.71742, 0.034563, 0.015478, 0.0030566, 0.041683, 0.017004, 0.79874, 0.1593]
Predicted label: 8
Correct prediction
Energy consumption = 154.143638 pJ
sum error= 231
Actual label: 7
Output voltages: [0.2801, 0.03571, 0.0095542, 0.0010815, 0.098372, 0.014054, 0.0048046, 0.7986, 0.08239, 0.20486]
Predicted label: 7
Correct prediction
Energy consumption = 152.122533 pJ
sum error= 231
Actual label: 0
Output voltages: [0.79874, 0.091348, 0.039819, 0.0018075, 0.014872, 0.0040106, 0.57925, 0.0020094, 0.037284, 0.13253]
Predicted label: 0
Correct prediction
Energy consumption = 147.236377 pJ
sum error= 231
Actual label: 3
Output voltages: [0.7114, 0.016698, 0.29588, 0.79878, 0.0012493, 0.083432, 0.0053602, 0.019128, 0.37895, 0.00131]
Predicted label: 3
Correct prediction
Energy consumption = 153.242043 pJ
sum error= 231
Actual label: 6
Output voltages: [0.14271, 0.023725, 0.39542, 0.0013482, 0.42755, 0.13441, 0.79879, 0.001203, 0.29926, 0.0028731]
Predicted label: 6
Correct prediction
Energy consumption = 146.877345 pJ
sum error= 231
Actual label: 6
Output voltages: [0.04866, 0.089786, 0.23695, 0.0010833, 0.54344, 0.16456, 0.79879, 0.0011281, 0.26283, 0.0065303]
Predicted label: 6
Correct prediction
Energy consumption = 141.756093 pJ
sum error= 231
Actual label: 4
Output voltages: [0.024848, 0.073419, 0.034344, 0.049962, 0.79879, 0.004585, 0.087343, 0.0036467, 0.036231, 0.02251]
Predicted label: 4
Correct prediction
Energy consumption = 154.217740 pJ
sum error= 231
Actual label: 3
Output voltages: [0.13443, 0.017399, 0.038264, 0.79867, 0.16032, 0.077202, 0.051262, 0.022432, 0.61205, 0.027661]
Predicted label: 3
Correct prediction
Energy consumption = 145.899649 pJ
sum error= 231
Actual label: 8
Output voltages: [0.019694, 0.01147, 0.033291, 0.39942, 0.0092877, 0.02407, 0.0097682, 0.038481, 0.79878, 0.10982]
Predicted label: 8
Correct prediction
Energy consumption = 141.828948 pJ
sum error= 231
Actual label: 8
Output voltages: [0.32905, 0.019978, 0.15392, 0.45459, 0.02121, 0.019832, 0.38931, 0.0014039, 0.79775, 0.054081]
Predicted label: 8
Correct prediction
Energy consumption = 151.381618 pJ
sum error= 231
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 440 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 440 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 440 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.018655, 0.67688, 0.64537, 0.035001, 0.1376, 0.0012192, 0.002772, 0.71656, 0.018915, 0.28552]
Predicted label: 7
Correct prediction
Energy consumption = 152.764018 pJ
sum error= 231
Actual label: 2
Output voltages: [0.56778, 0.029856, 0.78146, 0.78897, 0.0051431, 0.0011136, 0.023578, 0.22831, 0.75133, 0.017193]
Predicted label: 3
Wrong prediction!
Energy consumption = 151.194091 pJ
sum error= 232
Actual label: 2
Output voltages: [0.19366, 0.24303, 0.79879, 0.044299, 0.017272, 0.0013963, 0.05001, 0.044462, 0.15473, 0.036098]
Predicted label: 2
Correct prediction
Energy consumption = 139.861815 pJ
sum error= 232
Actual label: 0
Output voltages: [0.798, 0.0033266, 0.26102, 0.017653, 0.012218, 0.011292, 0.4536, 0.0067892, 0.64124, 0.35851]
Predicted label: 0
Correct prediction
Energy consumption = 147.598656 pJ
sum error= 232
Actual label: 0
Output voltages: [0.79879, 0.026846, 0.011954, 0.0063553, 0.039394, 0.012773, 0.70916, 0.0058695, 0.042562, 0.13888]
Predicted label: 0
Correct prediction
Energy consumption = 149.173965 pJ
sum error= 232
Actual label: 9
Output voltages: [0.09882, 0.0014608, 0.032422, 0.014885, 0.77246, 0.0022445, 0.022692, 0.021558, 0.058596, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 156.869812 pJ
sum error= 232
Actual label: 3
Output voltages: [0.30107, 0.052098, 0.055203, 0.79866, 0.0058099, 0.0047283, 0.0055854, 0.0066068, 0.64171, 0.042413]
Predicted label: 3
Correct prediction
Energy consumption = 139.493039 pJ
sum error= 232
Actual label: 9
Output voltages: [0.11568, 0.0055068, 0.011023, 0.094273, 0.12191, 0.0076675, 0.003801, 0.025201, 0.69697, 0.7984]
Predicted label: 9
Correct prediction
Energy consumption = 144.295386 pJ
sum error= 232
Actual label: 9
Output voltages: [0.053706, 0.0095325, 0.1083, 0.13729, 0.054195, 0.0096178, 0.17282, 0.012179, 0.1125, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 144.413303 pJ
sum error= 232
Actual label: 1
Output voltages: [0.012987, 0.79855, 0.040541, 0.13995, 0.025499, 0.0014379, 0.62188, 0.01342, 0.19809, 0.020436]
Predicted label: 1
Correct prediction
Energy consumption = 160.383403 pJ
sum error= 232
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 441 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 441 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 441 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.24152, 0.020387, 0.026944, 0.02603, 0.14586, 0.020311, 0.0024435, 0.023842, 0.58955, 0.79836]
Predicted label: 9
Correct prediction
Energy consumption = 150.051230 pJ
sum error= 232
Actual label: 8
Output voltages: [0.014714, 0.022214, 0.065447, 0.10071, 0.0028571, 0.030507, 0.023784, 0.011174, 0.7987, 0.08262]
Predicted label: 8
Correct prediction
Energy consumption = 143.524891 pJ
sum error= 232
Actual label: 6
Output voltages: [0.029058, 0.048992, 0.30248, 0.0016208, 0.20582, 0.06755, 0.79877, 0.0042433, 0.66837, 0.0027696]
Predicted label: 6
Correct prediction
Energy consumption = 147.183213 pJ
sum error= 232
Actual label: 6
Output voltages: [0.065815, 0.40287, 0.033509, 0.050005, 0.020607, 0.11288, 0.79878, 0.0049511, 0.68212, 0.0030988]
Predicted label: 6
Correct prediction
Energy consumption = 145.844578 pJ
sum error= 232
Actual label: 4
Output voltages: [0.0021155, 0.0047926, 0.22533, 0.010522, 0.79868, 0.0020298, 0.23483, 0.037146, 0.068971, 0.025749]
Predicted label: 4
Correct prediction
Energy consumption = 152.775782 pJ
sum error= 232
Actual label: 2
Output voltages: [0.75261, 0.031383, 0.79878, 0.20443, 0.0041179, 0.0010765, 0.067111, 0.053096, 0.32205, 0.072918]
Predicted label: 2
Correct prediction
Energy consumption = 148.387096 pJ
sum error= 232
Actual label: 6
Output voltages: [0.051287, 0.17602, 0.29372, 0.0011034, 0.34036, 0.2178, 0.79869, 0.0012776, 0.4626, 0.005999]
Predicted label: 6
Correct prediction
Energy consumption = 148.705796 pJ
sum error= 232
Actual label: 9
Output voltages: [0.19656, 0.033563, 0.027208, 0.32242, 0.022951, 0.011153, 0.022301, 0.12264, 0.17183, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 158.428061 pJ
sum error= 232
Actual label: 2
Output voltages: [0.44893, 0.0063127, 0.79826, 0.33919, 0.014388, 0.0011827, 0.16897, 0.13668, 0.59808, 0.029988]
Predicted label: 2
Correct prediction
Energy consumption = 145.408300 pJ
sum error= 232
Actual label: 8
Output voltages: [0.042499, 0.020935, 0.018228, 0.182, 0.015798, 0.69541, 0.17049, 0.074591, 0.79877, 0.019725]
Predicted label: 8
Correct prediction
Energy consumption = 151.224358 pJ
sum error= 232
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 442 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 442 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 442 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.19669, 0.0018056, 0.0066545, 0.39194, 0.0015446, 0.79879, 0.03181, 0.18335, 0.74582, 0.035241]
Predicted label: 5
Correct prediction
Energy consumption = 149.721636 pJ
sum error= 232
Actual label: 4
Output voltages: [0.029128, 0.0052391, 0.14452, 0.015618, 0.79857, 0.0013706, 0.25626, 0.023202, 0.034965, 0.067771]
Predicted label: 4
Correct prediction
Energy consumption = 154.352275 pJ
sum error= 232
Actual label: 5
Output voltages: [0.033649, 0.0015261, 0.007066, 0.45395, 0.015842, 0.7987, 0.191, 0.15507, 0.76109, 0.33131]
Predicted label: 5
Correct prediction
Energy consumption = 150.094873 pJ
sum error= 232
Actual label: 7
Output voltages: [0.013196, 0.0025275, 0.032291, 0.38289, 0.015475, 0.0041157, 0.0011142, 0.79879, 0.35482, 0.27307]
Predicted label: 7
Correct prediction
Energy consumption = 146.699652 pJ
sum error= 232
Actual label: 9
Output voltages: [0.41682, 0.037383, 0.016918, 0.30868, 0.34025, 0.011155, 0.04523, 0.018134, 0.040399, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.169505 pJ
sum error= 232
Actual label: 9
Output voltages: [0.18354, 0.028439, 0.016564, 0.018073, 0.79207, 0.001388, 0.064096, 0.004483, 0.0176, 0.79101]
Predicted label: 4
Wrong prediction!
Energy consumption = 143.764381 pJ
sum error= 233
Actual label: 9
Output voltages: [0.2223, 0.0045204, 0.016876, 0.0055709, 0.26894, 0.002741, 0.0035496, 0.0090944, 0.56058, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 144.537385 pJ
sum error= 233
Actual label: 2
Output voltages: [0.22293, 0.22068, 0.79868, 0.058549, 0.002125, 0.0013474, 0.10567, 0.013288, 0.40603, 0.031956]
Predicted label: 2
Correct prediction
Energy consumption = 156.936288 pJ
sum error= 233
Actual label: 1
Output voltages: [0.011154, 0.79847, 0.0089123, 0.047798, 0.010591, 0.0080619, 0.75479, 0.016616, 0.28611, 0.020252]
Predicted label: 1
Correct prediction
Energy consumption = 159.007716 pJ
sum error= 233
Actual label: 8
Output voltages: [0.33157, 0.0016481, 0.17354, 0.046183, 0.0088885, 0.14426, 0.24036, 0.0011678, 0.76136, 0.067616]
Predicted label: 8
Correct prediction
Energy consumption = 154.008459 pJ
sum error= 233
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 443 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 443 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 443 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.49049, 0.015508, 0.14183, 0.79875, 0.026752, 0.0019297, 0.030927, 0.0088031, 0.51962, 0.018869]
Predicted label: 3
Correct prediction
Energy consumption = 145.386600 pJ
sum error= 233
Actual label: 4
Output voltages: [0.0025242, 0.018017, 0.027449, 0.022468, 0.79856, 0.0022872, 0.14723, 0.16397, 0.078693, 0.053572]
Predicted label: 4
Correct prediction
Energy consumption = 157.798865 pJ
sum error= 233
Actual label: 0
Output voltages: [0.79879, 0.040473, 0.01848, 0.052549, 0.02935, 0.015914, 0.66574, 0.027944, 0.2618, 0.042455]
Predicted label: 0
Correct prediction
Energy consumption = 156.873586 pJ
sum error= 233
Actual label: 7
Output voltages: [0.16508, 0.0066932, 0.037424, 0.62034, 0.67618, 0.0014635, 0.0011176, 0.78829, 0.27898, 0.0018334]
Predicted label: 7
Correct prediction
Energy consumption = 157.858049 pJ
sum error= 233
Actual label: 8
Output voltages: [0.0088566, 0.29217, 0.036442, 0.13783, 0.0021388, 0.016042, 0.0079278, 0.032532, 0.79871, 0.45247]
Predicted label: 8
Correct prediction
Energy consumption = 149.198341 pJ
sum error= 233
Actual label: 3
Output voltages: [0.032562, 0.030183, 0.27292, 0.79856, 0.0010908, 0.0011619, 0.0069402, 0.44465, 0.32923, 0.61967]
Predicted label: 3
Correct prediction
Energy consumption = 148.062035 pJ
sum error= 233
Actual label: 9
Output voltages: [0.049001, 0.029883, 0.07379, 0.051778, 0.04412, 0.020175, 0.020503, 0.036974, 0.6231, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 146.367350 pJ
sum error= 233
Actual label: 3
Output voltages: [0.75775, 0.0099202, 0.2794, 0.79874, 0.006923, 0.00448, 0.049306, 0.010122, 0.37909, 0.021278]
Predicted label: 3
Correct prediction
Energy consumption = 159.557538 pJ
sum error= 233
Actual label: 4
Output voltages: [0.030309, 0.0059323, 0.29363, 0.056434, 0.79864, 0.001066, 0.0052532, 0.0010665, 0.047053, 0.48781]
Predicted label: 4
Correct prediction
Energy consumption = 141.709303 pJ
sum error= 233
Actual label: 6
Output voltages: [0.47618, 0.01207, 0.066768, 0.0011092, 0.40681, 0.012944, 0.79812, 0.0012077, 0.2217, 0.035008]
Predicted label: 6
Correct prediction
Energy consumption = 155.290628 pJ
sum error= 233
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 444 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 444 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 444 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.1362, 0.0011194, 0.0099249, 0.53378, 0.0014831, 0.79796, 0.041058, 0.11661, 0.76175, 0.047152]
Predicted label: 5
Correct prediction
Energy consumption = 146.830107 pJ
sum error= 233
Actual label: 6
Output voltages: [0.27313, 0.046964, 0.19239, 0.0011009, 0.17733, 0.036514, 0.79879, 0.0010684, 0.29781, 0.0081102]
Predicted label: 6
Correct prediction
Energy consumption = 149.209404 pJ
sum error= 233
Actual label: 2
Output voltages: [0.20513, 0.57309, 0.79877, 0.2631, 0.015015, 0.001205, 0.38484, 0.0091467, 0.16921, 0.080867]
Predicted label: 2
Correct prediction
Energy consumption = 145.960856 pJ
sum error= 233
Actual label: 3
Output voltages: [0.17723, 0.78918, 0.51338, 0.70152, 0.0034968, 0.0010827, 0.0095556, 0.01688, 0.31728, 0.0046849]
Predicted label: 1
Wrong prediction!
Energy consumption = 149.885428 pJ
sum error= 234
Actual label: 9
Output voltages: [0.44109, 0.013098, 0.13306, 0.029981, 0.28226, 0.021234, 0.012578, 0.0056248, 0.2126, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 157.281167 pJ
sum error= 234
Actual label: 2
Output voltages: [0.26677, 0.11109, 0.79876, 0.34185, 0.028931, 0.0011109, 0.024209, 0.047929, 0.22838, 0.11384]
Predicted label: 2
Correct prediction
Energy consumption = 145.664377 pJ
sum error= 234
Actual label: 6
Output voltages: [0.12056, 0.10446, 0.057776, 0.0011214, 0.14612, 0.18035, 0.79875, 0.0010664, 0.21385, 0.017532]
Predicted label: 6
Correct prediction
Energy consumption = 147.536073 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79875, 0.05216, 0.028002, 0.016446, 0.017739, 0.0024361, 0.60184, 0.027807, 0.43108, 0.27024]
Predicted label: 0
Correct prediction
Energy consumption = 151.275663 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79876, 0.041707, 0.15711, 0.036586, 0.0016688, 0.0041414, 0.42761, 0.014281, 0.04474, 0.047914]
Predicted label: 0
Correct prediction
Energy consumption = 143.519208 pJ
sum error= 234
Actual label: 6
Output voltages: [0.6409, 0.026261, 0.024683, 0.0086283, 0.15667, 0.27301, 0.79802, 0.008795, 0.48872, 0.0048433]
Predicted label: 6
Correct prediction
Energy consumption = 141.362565 pJ
sum error= 234
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 445 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 445 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 445 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.033291, 0.79845, 0.010995, 0.25896, 0.035416, 0.0058273, 0.28617, 0.14876, 0.064016, 0.060299]
Predicted label: 1
Correct prediction
Energy consumption = 167.124261 pJ
sum error= 234
Actual label: 2
Output voltages: [0.15994, 0.23683, 0.79853, 0.040622, 0.015663, 0.0012072, 0.072015, 0.38437, 0.40943, 0.029183]
Predicted label: 2
Correct prediction
Energy consumption = 149.537337 pJ
sum error= 234
Actual label: 8
Output voltages: [0.054251, 0.044645, 0.49497, 0.1006, 0.0080793, 0.00195, 0.041148, 0.0050662, 0.79879, 0.023381]
Predicted label: 8
Correct prediction
Energy consumption = 147.522394 pJ
sum error= 234
Actual label: 7
Output voltages: [0.037903, 0.11141, 0.39287, 0.05903, 0.0037383, 0.0011733, 0.0012169, 0.79878, 0.71929, 0.038733]
Predicted label: 7
Correct prediction
Energy consumption = 149.262035 pJ
sum error= 234
Actual label: 9
Output voltages: [0.64185, 0.0012306, 0.045254, 0.0062983, 0.10355, 0.0052729, 0.00116, 0.0027463, 0.74618, 0.77829]
Predicted label: 9
Correct prediction
Energy consumption = 146.548434 pJ
sum error= 234
Actual label: 8
Output voltages: [0.37652, 0.029952, 0.40827, 0.0091408, 0.2892, 0.0011648, 0.19475, 0.0012399, 0.79857, 0.26659]
Predicted label: 8
Correct prediction
Energy consumption = 137.950002 pJ
sum error= 234
Actual label: 2
Output voltages: [0.39492, 0.0808, 0.7987, 0.096051, 0.015073, 0.0012658, 0.3458, 0.011293, 0.71487, 0.030707]
Predicted label: 2
Correct prediction
Energy consumption = 150.953430 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79876, 0.022122, 0.02409, 0.0071331, 0.039724, 0.014617, 0.73323, 0.0047959, 0.19398, 0.12777]
Predicted label: 0
Correct prediction
Energy consumption = 154.471822 pJ
sum error= 234
Actual label: 4
Output voltages: [0.010223, 0.01743, 0.25122, 0.0092352, 0.79864, 0.0011586, 0.017063, 0.021793, 0.035547, 0.2351]
Predicted label: 4
Correct prediction
Energy consumption = 156.829752 pJ
sum error= 234
Actual label: 7
Output voltages: [0.094012, 0.028729, 0.15274, 0.2696, 0.0045707, 0.0011347, 0.0010666, 0.79863, 0.20071, 0.2756]
Predicted label: 7
Correct prediction
Energy consumption = 156.014662 pJ
sum error= 234
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 446 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 446 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 446 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.062508, 0.2324, 0.34416, 0.75428, 0.010607, 0.0013751, 0.0010773, 0.79534, 0.013999, 0.4336]
Predicted label: 7
Correct prediction
Energy consumption = 163.368083 pJ
sum error= 234
Actual label: 5
Output voltages: [0.010562, 0.015272, 0.0014495, 0.52682, 0.01579, 0.79822, 0.062225, 0.029517, 0.60728, 0.24146]
Predicted label: 5
Correct prediction
Energy consumption = 148.293956 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79062, 0.097027, 0.016195, 0.0091576, 0.025403, 0.021866, 0.76851, 0.018552, 0.034488, 0.27255]
Predicted label: 0
Correct prediction
Energy consumption = 155.691478 pJ
sum error= 234
Actual label: 5
Output voltages: [0.020182, 0.001124, 0.026108, 0.48127, 0.3673, 0.79212, 0.22222, 0.016392, 0.67356, 0.032833]
Predicted label: 5
Correct prediction
Energy consumption = 144.457483 pJ
sum error= 234
Actual label: 6
Output voltages: [0.34858, 0.21581, 0.29284, 0.0043902, 0.085748, 0.093478, 0.79879, 0.0011003, 0.44469, 0.013955]
Predicted label: 6
Correct prediction
Energy consumption = 144.865150 pJ
sum error= 234
Actual label: 4
Output voltages: [0.22807, 0.060869, 0.51861, 0.10849, 0.79849, 0.0012199, 0.059749, 0.55996, 0.0028099, 0.37602]
Predicted label: 4
Correct prediction
Energy consumption = 144.589268 pJ
sum error= 234
Actual label: 6
Output voltages: [0.19162, 0.024758, 0.26124, 0.004096, 0.50043, 0.2058, 0.79878, 0.0062364, 0.6905, 0.0058629]
Predicted label: 6
Correct prediction
Energy consumption = 148.411814 pJ
sum error= 234
Actual label: 7
Output voltages: [0.026839, 0.0097587, 0.031076, 0.0040386, 0.061048, 0.0016766, 0.0012401, 0.79877, 0.69234, 0.044383]
Predicted label: 7
Correct prediction
Energy consumption = 160.712547 pJ
sum error= 234
Actual label: 4
Output voltages: [0.00192, 0.02784, 0.037434, 0.024202, 0.79876, 0.0015806, 0.041489, 0.13779, 0.12421, 0.0027131]
Predicted label: 4
Correct prediction
Energy consumption = 147.485442 pJ
sum error= 234
Actual label: 3
Output voltages: [0.33402, 0.12269, 0.05515, 0.79866, 0.0016769, 0.048611, 0.026409, 0.014978, 0.41011, 0.045982]
Predicted label: 3
Correct prediction
Energy consumption = 151.685248 pJ
sum error= 234
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 447 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 447 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 447 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.038331, 0.038868, 0.014713, 0.019653, 0.0053573, 0.33846, 0.16276, 0.3515, 0.064034]
Predicted label: 0
Correct prediction
Energy consumption = 160.372950 pJ
sum error= 234
Actual label: 7
Output voltages: [0.54658, 0.0091132, 0.22305, 0.0087156, 0.012234, 0.0010802, 0.001162, 0.79878, 0.6228, 0.20682]
Predicted label: 7
Correct prediction
Energy consumption = 153.907057 pJ
sum error= 234
Actual label: 5
Output voltages: [0.02868, 0.0011462, 0.004114, 0.015035, 0.039709, 0.79813, 0.51745, 0.005062, 0.78898, 0.014875]
Predicted label: 5
Correct prediction
Energy consumption = 151.291773 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79878, 0.037686, 0.038918, 0.0343, 0.036408, 0.0089528, 0.55305, 0.017057, 0.34926, 0.050707]
Predicted label: 0
Correct prediction
Energy consumption = 154.765340 pJ
sum error= 234
Actual label: 7
Output voltages: [0.39226, 0.0274, 0.16902, 0.15031, 0.015527, 0.001066, 0.0013528, 0.79869, 0.43815, 0.21544]
Predicted label: 7
Correct prediction
Energy consumption = 155.987787 pJ
sum error= 234
Actual label: 4
Output voltages: [0.0075577, 0.0070376, 0.32773, 0.023371, 0.79856, 0.0026153, 0.29301, 0.19924, 0.038297, 0.16415]
Predicted label: 4
Correct prediction
Energy consumption = 146.726295 pJ
sum error= 234
Actual label: 2
Output voltages: [0.10987, 0.32888, 0.79876, 0.028356, 0.018328, 0.0014576, 0.32052, 0.028942, 0.30406, 0.052821]
Predicted label: 2
Correct prediction
Energy consumption = 149.780915 pJ
sum error= 234
Actual label: 0
Output voltages: [0.79845, 0.33547, 0.012568, 0.016716, 0.018219, 0.0437, 0.76635, 0.032252, 0.074847, 0.02216]
Predicted label: 0
Correct prediction
Energy consumption = 162.012391 pJ
sum error= 234
Actual label: 8
Output voltages: [0.040727, 0.025354, 0.086702, 0.054495, 0.022389, 0.0063471, 0.09499, 0.0082538, 0.79876, 0.18549]
Predicted label: 8
Correct prediction
Energy consumption = 150.993796 pJ
sum error= 234
Actual label: 9
Output voltages: [0.38349, 0.054833, 0.015922, 0.42254, 0.14234, 0.0023922, 0.0012901, 0.33646, 0.01499, 0.79831]
Predicted label: 9
Correct prediction
Energy consumption = 154.775992 pJ
sum error= 234
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 448 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 448 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 448 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3881, 0.0049257, 0.0041268, 0.042514, 0.034107, 0.035296, 0.0011132, 0.2644, 0.67257, 0.78424]
Predicted label: 9
Correct prediction
Energy consumption = 153.769323 pJ
sum error= 234
Actual label: 4
Output voltages: [0.0030425, 0.030223, 0.043309, 0.17114, 0.79877, 0.0010763, 0.0057318, 0.041331, 0.014147, 0.20026]
Predicted label: 4
Correct prediction
Energy consumption = 140.261218 pJ
sum error= 234
Actual label: 2
Output voltages: [0.7215, 0.0011286, 0.79633, 0.62819, 0.0042087, 0.0010712, 0.0028322, 0.036467, 0.6288, 0.021835]
Predicted label: 2
Correct prediction
Energy consumption = 147.953555 pJ
sum error= 234
Actual label: 4
Output voltages: [0.15923, 0.0025836, 0.74243, 0.0012393, 0.74778, 0.0011797, 0.0022685, 0.046814, 0.27779, 0.7344]
Predicted label: 4
Correct prediction
Energy consumption = 155.255759 pJ
sum error= 234
Actual label: 6
Output voltages: [0.19082, 0.028367, 0.035206, 0.0085044, 0.29059, 0.52983, 0.79879, 0.0069187, 0.60038, 0.0037782]
Predicted label: 6
Correct prediction
Energy consumption = 148.823878 pJ
sum error= 234
Actual label: 7
Output voltages: [0.41192, 0.032501, 0.030897, 0.035088, 0.012868, 0.0012848, 0.0012264, 0.79871, 0.64398, 0.056402]
Predicted label: 7
Correct prediction
Energy consumption = 156.620382 pJ
sum error= 234
Actual label: 8
Output voltages: [0.032815, 0.013101, 0.047999, 0.079838, 0.011868, 0.18215, 0.038225, 0.0031092, 0.79877, 0.037283]
Predicted label: 8
Correct prediction
Energy consumption = 149.621146 pJ
sum error= 234
Actual label: 7
Output voltages: [0.061969, 0.073355, 0.59067, 0.13524, 0.0013351, 0.0012147, 0.001895, 0.77749, 0.7911, 0.12353]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.637006 pJ
sum error= 235
Actual label: 6
Output voltages: [0.23634, 0.026512, 0.16577, 0.0022094, 0.43632, 0.143, 0.79876, 0.0011345, 0.45376, 0.0040217]
Predicted label: 6
Correct prediction
Energy consumption = 148.364947 pJ
sum error= 235
Actual label: 9
Output voltages: [0.049786, 0.013418, 0.034834, 0.40782, 0.0090225, 0.0048066, 0.0014558, 0.022288, 0.5351, 0.7978]
Predicted label: 9
Correct prediction
Energy consumption = 154.069030 pJ
sum error= 235
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 449 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 449 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 449 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.022606, 0.018196, 0.029329, 0.0072103, 0.79873, 0.0041743, 0.35425, 0.028828, 0.052471, 0.024358]
Predicted label: 4
Correct prediction
Energy consumption = 158.742868 pJ
sum error= 235
Actual label: 1
Output voltages: [0.009067, 0.79877, 0.15703, 0.17141, 0.045947, 0.0037361, 0.22725, 0.0014217, 0.0077741, 0.054024]
Predicted label: 1
Correct prediction
Energy consumption = 153.569430 pJ
sum error= 235
Actual label: 3
Output voltages: [0.037536, 0.025896, 0.037641, 0.79864, 0.022253, 0.010171, 0.0086906, 0.20045, 0.71173, 0.031492]
Predicted label: 3
Correct prediction
Energy consumption = 147.577366 pJ
sum error= 235
Actual label: 7
Output voltages: [0.17399, 0.30049, 0.62734, 0.016428, 0.0052432, 0.0013096, 0.0029691, 0.79879, 0.048132, 0.040575]
Predicted label: 7
Correct prediction
Energy consumption = 149.320005 pJ
sum error= 235
Actual label: 3
Output voltages: [0.22523, 0.01181, 0.022937, 0.79871, 0.07435, 0.72547, 0.01378, 0.0068979, 0.26942, 0.0018538]
Predicted label: 3
Correct prediction
Energy consumption = 151.783121 pJ
sum error= 235
Actual label: 0
Output voltages: [0.79874, 0.045799, 0.032217, 0.011404, 0.014154, 0.013368, 0.14459, 0.01341, 0.22929, 0.053637]
Predicted label: 0
Correct prediction
Energy consumption = 156.974039 pJ
sum error= 235
Actual label: 8
Output voltages: [0.045661, 0.025472, 0.25366, 0.025006, 0.019281, 0.013147, 0.012107, 0.0017609, 0.79871, 0.26947]
Predicted label: 8
Correct prediction
Energy consumption = 149.840650 pJ
sum error= 235
Actual label: 8
Output voltages: [0.0075675, 0.062145, 0.26158, 0.019636, 0.046371, 0.0013076, 0.0025794, 0.74965, 0.79878, 0.024276]
Predicted label: 8
Correct prediction
Energy consumption = 141.310837 pJ
sum error= 235
Actual label: 7
Output voltages: [0.052299, 0.042043, 0.29541, 0.14079, 0.049108, 0.0011027, 0.015601, 0.50649, 0.7986, 0.004676]
Predicted label: 8
Wrong prediction!
Energy consumption = 138.718950 pJ
sum error= 236
Actual label: 6
Output voltages: [0.12339, 0.15458, 0.23817, 0.0010684, 0.03397, 0.32805, 0.79873, 0.019017, 0.50174, 0.0083633]
Predicted label: 6
Correct prediction
Energy consumption = 153.970630 pJ
sum error= 236
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 450 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 450 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 450 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.43398, 0.42913, 0.0078883, 0.021954, 0.33879, 0.0011182, 0.0010701, 0.0016503, 0.087573, 0.795]
Predicted label: 9
Correct prediction
Energy consumption = 164.486903 pJ
sum error= 236
Actual label: 3
Output voltages: [0.76939, 0.016545, 0.060309, 0.79872, 0.016382, 0.12916, 0.003239, 0.033464, 0.45745, 0.075177]
Predicted label: 3
Correct prediction
Energy consumption = 144.360364 pJ
sum error= 236
Actual label: 9
Output voltages: [0.53376, 0.0033024, 0.069815, 0.015281, 0.21832, 0.0017318, 0.0010913, 0.061133, 0.39462, 0.79618]
Predicted label: 9
Correct prediction
Energy consumption = 145.721121 pJ
sum error= 236
Actual label: 2
Output voltages: [0.45635, 0.69475, 0.7959, 0.21866, 0.010402, 0.0013272, 0.26927, 0.017207, 0.10941, 0.038178]
Predicted label: 2
Correct prediction
Energy consumption = 158.635286 pJ
sum error= 236
Actual label: 2
Output voltages: [0.048521, 0.06637, 0.79879, 0.099322, 0.023414, 0.0011411, 0.025386, 0.49369, 0.47669, 0.0068898]
Predicted label: 2
Correct prediction
Energy consumption = 136.070776 pJ
sum error= 236
Actual label: 9
Output voltages: [0.091288, 0.0017966, 0.009962, 0.44479, 0.42172, 0.21997, 0.0010683, 0.40175, 0.068464, 0.7922]
Predicted label: 9
Correct prediction
Energy consumption = 156.854336 pJ
sum error= 236
Actual label: 2
Output voltages: [0.484, 0.0020843, 0.79026, 0.62952, 0.001515, 0.001066, 0.012991, 0.030236, 0.49879, 0.0096256]
Predicted label: 2
Correct prediction
Energy consumption = 146.972507 pJ
sum error= 236
Actual label: 1
Output voltages: [0.029291, 0.79788, 0.72074, 0.0090676, 0.0035474, 0.0010718, 0.021162, 0.34668, 0.45213, 0.039183]
Predicted label: 1
Correct prediction
Energy consumption = 149.470093 pJ
sum error= 236
Actual label: 8
Output voltages: [0.10074, 0.0080509, 0.29003, 0.27242, 0.0067515, 0.035438, 0.0078638, 0.018943, 0.79864, 0.025424]
Predicted label: 8
Correct prediction
Energy consumption = 151.575086 pJ
sum error= 236
Actual label: 3
Output voltages: [0.086537, 0.17345, 0.50507, 0.79875, 0.025769, 0.0010904, 0.0031311, 0.0053817, 0.39166, 0.30128]
Predicted label: 3
Correct prediction
Energy consumption = 149.625391 pJ
sum error= 236
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 451 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 451 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 451 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.34722, 0.013427, 0.79877, 0.016712, 0.0146, 0.0011821, 0.053042, 0.056089, 0.48478, 0.026455]
Predicted label: 2
Correct prediction
Energy consumption = 151.360672 pJ
sum error= 236
Actual label: 9
Output voltages: [0.052365, 0.0016272, 0.31804, 0.074932, 0.7918, 0.0011169, 0.0011687, 0.021286, 0.014696, 0.76589]
Predicted label: 4
Wrong prediction!
Energy consumption = 149.789083 pJ
sum error= 237
Actual label: 6
Output voltages: [0.020455, 0.034708, 0.056778, 0.014372, 0.28979, 0.15947, 0.79878, 0.0043448, 0.73557, 0.0044868]
Predicted label: 6
Correct prediction
Energy consumption = 143.712417 pJ
sum error= 237
Actual label: 8
Output voltages: [0.056061, 0.0010681, 0.13488, 0.4406, 0.0010793, 0.62945, 0.014816, 0.0026143, 0.79838, 0.032155]
Predicted label: 8
Correct prediction
Energy consumption = 145.670518 pJ
sum error= 237
Actual label: 4
Output voltages: [0.011712, 0.0028138, 0.20922, 0.030703, 0.79874, 0.0011601, 0.0089117, 0.0058904, 0.37106, 0.043817]
Predicted label: 4
Correct prediction
Energy consumption = 149.895972 pJ
sum error= 237
Actual label: 0
Output voltages: [0.79879, 0.0057674, 0.097718, 0.0029211, 0.040491, 0.0020492, 0.034583, 0.19486, 0.55962, 0.043954]
Predicted label: 0
Correct prediction
Energy consumption = 150.949261 pJ
sum error= 237
Actual label: 1
Output voltages: [0.0049783, 0.79861, 0.007293, 0.049021, 0.002185, 0.01591, 0.40544, 0.018449, 0.36751, 0.011301]
Predicted label: 1
Correct prediction
Energy consumption = 160.020055 pJ
sum error= 237
Actual label: 2
Output voltages: [0.59439, 0.014327, 0.79877, 0.22344, 0.034301, 0.0010922, 0.030748, 0.032818, 0.62887, 0.019242]
Predicted label: 2
Correct prediction
Energy consumption = 150.102961 pJ
sum error= 237
Actual label: 8
Output voltages: [0.013947, 0.051183, 0.034003, 0.23498, 0.0013551, 0.0097746, 0.0063703, 0.019975, 0.79874, 0.14179]
Predicted label: 8
Correct prediction
Energy consumption = 143.775511 pJ
sum error= 237
Actual label: 4
Output voltages: [0.0042613, 0.015268, 0.040962, 0.026742, 0.79875, 0.0011319, 0.031244, 0.027929, 0.014225, 0.081815]
Predicted label: 4
Correct prediction
Energy consumption = 159.969929 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 452 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 452 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 452 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.076648, 0.0010661, 0.0011121, 0.027307, 0.074441, 0.79335, 0.014506, 0.0066727, 0.7634, 0.080041]
Predicted label: 5
Correct prediction
Energy consumption = 154.572609 pJ
sum error= 237
Actual label: 2
Output voltages: [0.48887, 0.38443, 0.79875, 0.23307, 0.0016042, 0.0012538, 0.036749, 0.49711, 0.048011, 0.17242]
Predicted label: 2
Correct prediction
Energy consumption = 142.096952 pJ
sum error= 237
Actual label: 7
Output voltages: [0.20776, 0.044525, 0.010064, 0.15742, 0.0027739, 0.0041354, 0.0010799, 0.79879, 0.54631, 0.66471]
Predicted label: 7
Correct prediction
Energy consumption = 151.031492 pJ
sum error= 237
Actual label: 8
Output voltages: [0.045191, 0.048279, 0.022033, 0.28895, 0.0079669, 0.10032, 0.022077, 0.034663, 0.79879, 0.031163]
Predicted label: 8
Correct prediction
Energy consumption = 151.794165 pJ
sum error= 237
Actual label: 1
Output voltages: [0.037985, 0.79862, 0.039185, 0.080227, 0.02517, 0.0013767, 0.7494, 0.0038865, 0.11921, 0.038097]
Predicted label: 1
Correct prediction
Energy consumption = 161.891985 pJ
sum error= 237
Actual label: 1
Output voltages: [0.025495, 0.79843, 0.062248, 0.079156, 0.0034722, 0.001269, 0.47316, 0.004328, 0.43057, 0.044955]
Predicted label: 1
Correct prediction
Energy consumption = 152.774814 pJ
sum error= 237
Actual label: 3
Output voltages: [0.30872, 0.045988, 0.30149, 0.79877, 0.020697, 0.001067, 0.0015894, 0.0074505, 0.54863, 0.0061872]
Predicted label: 3
Correct prediction
Energy consumption = 149.150860 pJ
sum error= 237
Actual label: 0
Output voltages: [0.79879, 0.062486, 0.046002, 0.0078345, 0.011832, 0.0053012, 0.36558, 0.12986, 0.039067, 0.058835]
Predicted label: 0
Correct prediction
Energy consumption = 154.681547 pJ
sum error= 237
Actual label: 3
Output voltages: [0.029073, 0.0037206, 0.32868, 0.79879, 0.05486, 0.13999, 0.079754, 0.0016937, 0.19396, 0.15711]
Predicted label: 3
Correct prediction
Energy consumption = 147.619876 pJ
sum error= 237
Actual label: 5
Output voltages: [0.040302, 0.0015276, 0.0011237, 0.40347, 0.0075748, 0.79876, 0.11186, 0.021326, 0.58566, 0.013925]
Predicted label: 5
Correct prediction
Energy consumption = 138.031914 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 453 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 453 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 453 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.45017, 0.23232, 0.0017406, 0.35619, 0.0020795, 0.0084938, 0.0011641, 0.79852, 0.24708, 0.75842]
Predicted label: 7
Correct prediction
Energy consumption = 152.160831 pJ
sum error= 237
Actual label: 0
Output voltages: [0.79826, 0.022339, 0.069616, 0.0039143, 0.021439, 0.0093057, 0.57648, 0.021247, 0.10347, 0.063682]
Predicted label: 0
Correct prediction
Energy consumption = 152.754304 pJ
sum error= 237
Actual label: 3
Output voltages: [0.16539, 0.0094965, 0.042947, 0.79869, 0.019548, 0.030077, 0.0090524, 0.045383, 0.55473, 0.044575]
Predicted label: 3
Correct prediction
Energy consumption = 148.911864 pJ
sum error= 237
Actual label: 1
Output voltages: [0.014535, 0.79849, 0.02828, 0.027674, 0.013502, 0.0021275, 0.74863, 0.0012877, 0.23671, 0.055945]
Predicted label: 1
Correct prediction
Energy consumption = 167.162456 pJ
sum error= 237
Actual label: 9
Output voltages: [0.033115, 0.011829, 0.0022955, 0.12826, 0.016793, 0.014391, 0.0020027, 0.52477, 0.52501, 0.78696]
Predicted label: 9
Correct prediction
Energy consumption = 155.757031 pJ
sum error= 237
Actual label: 3
Output voltages: [0.19546, 0.064704, 0.055293, 0.79856, 0.0052394, 0.017065, 0.0052264, 0.090963, 0.41814, 0.048664]
Predicted label: 3
Correct prediction
Energy consumption = 141.680907 pJ
sum error= 237
Actual label: 6
Output voltages: [0.42594, 0.001097, 0.011633, 0.013884, 0.027714, 0.79376, 0.79464, 0.0016306, 0.67665, 0.024728]
Predicted label: 6
Correct prediction
Energy consumption = 153.804946 pJ
sum error= 237
Actual label: 3
Output voltages: [0.32829, 0.036735, 0.34094, 0.79865, 0.055162, 0.0017495, 0.032565, 0.017381, 0.45333, 0.06953]
Predicted label: 3
Correct prediction
Energy consumption = 146.316871 pJ
sum error= 237
Actual label: 1
Output voltages: [0.0089675, 0.7986, 0.18634, 0.6929, 0.020753, 0.002554, 0.59923, 0.19382, 0.0079056, 0.12918]
Predicted label: 1
Correct prediction
Energy consumption = 156.425044 pJ
sum error= 237
Actual label: 7
Output voltages: [0.19982, 0.14114, 0.33773, 0.021528, 0.0019608, 0.0010876, 0.0010933, 0.79861, 0.58817, 0.018394]
Predicted label: 7
Correct prediction
Energy consumption = 153.563530 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 454 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 454 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 454 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.51954, 0.007786, 0.62898, 0.4683, 0.0022326, 0.0010673, 0.0010909, 0.7878, 0.77329, 0.19583]
Predicted label: 7
Correct prediction
Energy consumption = 149.302806 pJ
sum error= 237
Actual label: 3
Output voltages: [0.091543, 0.04496, 0.042415, 0.79875, 0.0056535, 0.0028988, 0.012024, 0.01747, 0.50969, 0.049089]
Predicted label: 3
Correct prediction
Energy consumption = 132.605849 pJ
sum error= 237
Actual label: 0
Output voltages: [0.79879, 0.054533, 0.027592, 0.015436, 0.013715, 0.014591, 0.45693, 0.0092737, 0.036642, 0.021844]
Predicted label: 0
Correct prediction
Energy consumption = 151.536323 pJ
sum error= 237
Actual label: 8
Output voltages: [0.026776, 0.030258, 0.034721, 0.016421, 0.014785, 0.0048677, 0.0075445, 0.0016452, 0.79876, 0.37862]
Predicted label: 8
Correct prediction
Energy consumption = 149.369772 pJ
sum error= 237
Actual label: 4
Output voltages: [0.0012116, 0.1145, 0.050861, 0.0057181, 0.79878, 0.0023092, 0.44569, 0.39347, 0.028359, 0.047432]
Predicted label: 4
Correct prediction
Energy consumption = 149.177149 pJ
sum error= 237
Actual label: 8
Output voltages: [0.035148, 0.080854, 0.13757, 0.14967, 0.012194, 0.011028, 0.044388, 0.010973, 0.79863, 0.19763]
Predicted label: 8
Correct prediction
Energy consumption = 151.616099 pJ
sum error= 237
Actual label: 2
Output voltages: [0.52789, 0.19198, 0.79879, 0.020917, 0.0065152, 0.0013737, 0.22997, 0.097496, 0.32105, 0.013174]
Predicted label: 2
Correct prediction
Energy consumption = 141.770176 pJ
sum error= 237
Actual label: 6
Output voltages: [0.051253, 0.0052601, 0.26702, 0.0010784, 0.61072, 0.011265, 0.79654, 0.0010885, 0.35211, 0.02265]
Predicted label: 6
Correct prediction
Energy consumption = 137.038998 pJ
sum error= 237
Actual label: 5
Output voltages: [0.46537, 0.0069717, 0.0021629, 0.30295, 0.011608, 0.79879, 0.7589, 0.0098058, 0.5232, 0.010377]
Predicted label: 5
Correct prediction
Energy consumption = 139.579539 pJ
sum error= 237
Actual label: 2
Output voltages: [0.51427, 0.33721, 0.79875, 0.04637, 0.016963, 0.0012656, 0.20146, 0.054999, 0.31471, 0.043094]
Predicted label: 2
Correct prediction
Energy consumption = 154.962547 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 455 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 455 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 455 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33405, 0.0026076, 0.016605, 0.37701, 0.13972, 0.12638, 0.018085, 0.067566, 0.26077, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 162.093790 pJ
sum error= 237
Actual label: 7
Output voltages: [0.28734, 0.0045401, 0.052171, 0.0010836, 0.059383, 0.036229, 0.0010834, 0.79863, 0.37853, 0.013467]
Predicted label: 7
Correct prediction
Energy consumption = 149.687059 pJ
sum error= 237
Actual label: 3
Output voltages: [0.54199, 0.0087464, 0.029781, 0.79875, 0.0033098, 0.048143, 0.005071, 0.18957, 0.63449, 0.031728]
Predicted label: 3
Correct prediction
Energy consumption = 148.855670 pJ
sum error= 237
Actual label: 9
Output voltages: [0.5516, 0.016455, 0.011034, 0.044283, 0.3098, 0.031317, 0.011243, 0.010287, 0.47006, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 149.249079 pJ
sum error= 237
Actual label: 0
Output voltages: [0.79225, 0.0030569, 0.041013, 0.001334, 0.0033494, 0.045473, 0.57273, 0.0098536, 0.24912, 0.05183]
Predicted label: 0
Correct prediction
Energy consumption = 148.237073 pJ
sum error= 237
Actual label: 9
Output voltages: [0.1736, 0.0019554, 0.011531, 0.16465, 0.33853, 0.0073452, 0.0011007, 0.015049, 0.13819, 0.79512]
Predicted label: 9
Correct prediction
Energy consumption = 153.828266 pJ
sum error= 237
Actual label: 9
Output voltages: [0.021704, 0.02639, 0.15627, 0.0060033, 0.30593, 0.0061911, 0.014347, 0.0049581, 0.24278, 0.79804]
Predicted label: 9
Correct prediction
Energy consumption = 141.834260 pJ
sum error= 237
Actual label: 6
Output voltages: [0.17773, 0.23844, 0.13115, 0.0087189, 0.11159, 0.45221, 0.79868, 0.018372, 0.26641, 0.014422]
Predicted label: 6
Correct prediction
Energy consumption = 150.437169 pJ
sum error= 237
Actual label: 4
Output voltages: [0.053305, 0.016805, 0.14608, 0.0011184, 0.79872, 0.0044912, 0.78491, 0.017855, 0.18193, 0.024571]
Predicted label: 4
Correct prediction
Energy consumption = 141.382517 pJ
sum error= 237
Actual label: 2
Output voltages: [0.66799, 0.01749, 0.79876, 0.22052, 0.031841, 0.0011248, 0.043025, 0.036024, 0.56165, 0.032012]
Predicted label: 2
Correct prediction
Energy consumption = 152.942968 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 456 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 456 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 456 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.11751, 0.016406, 0.13432, 0.045661, 0.066692, 0.023981, 0.040807, 0.095905, 0.32157, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 152.879835 pJ
sum error= 237
Actual label: 7
Output voltages: [0.23312, 0.11538, 0.014651, 0.31273, 0.029344, 0.072611, 0.0010733, 0.79865, 0.044427, 0.37572]
Predicted label: 7
Correct prediction
Energy consumption = 153.297260 pJ
sum error= 237
Actual label: 2
Output voltages: [0.3462, 0.0010978, 0.79404, 0.29478, 0.027485, 0.0011295, 0.01923, 0.036017, 0.7553, 0.021439]
Predicted label: 2
Correct prediction
Energy consumption = 149.146179 pJ
sum error= 237
Actual label: 1
Output voltages: [0.16026, 0.79876, 0.63026, 0.0047607, 0.10745, 0.0011222, 0.19956, 0.016268, 0.038994, 0.033732]
Predicted label: 1
Correct prediction
Energy consumption = 157.845485 pJ
sum error= 237
Actual label: 1
Output voltages: [0.012139, 0.79878, 0.078567, 0.019016, 0.40777, 0.0089147, 0.73146, 0.0010667, 0.17625, 0.063378]
Predicted label: 1
Correct prediction
Energy consumption = 149.649387 pJ
sum error= 237
Actual label: 6
Output voltages: [0.12192, 0.060711, 0.0065271, 0.047768, 0.27201, 0.71619, 0.79872, 0.033362, 0.74656, 0.0010866]
Predicted label: 6
Correct prediction
Energy consumption = 154.100360 pJ
sum error= 237
Actual label: 7
Output voltages: [0.057672, 0.011471, 0.78309, 0.084564, 0.0082041, 0.0012729, 0.0010878, 0.79867, 0.72799, 0.036532]
Predicted label: 7
Correct prediction
Energy consumption = 149.684942 pJ
sum error= 237
Actual label: 4
Output voltages: [0.052885, 0.0028193, 0.014947, 0.098585, 0.76473, 0.001167, 0.0010841, 0.012867, 0.16154, 0.70001]
Predicted label: 4
Correct prediction
Energy consumption = 158.043669 pJ
sum error= 237
Actual label: 7
Output voltages: [0.038456, 0.17248, 0.63823, 0.016604, 0.014687, 0.0011951, 0.0010769, 0.7985, 0.069125, 0.40072]
Predicted label: 7
Correct prediction
Energy consumption = 151.877326 pJ
sum error= 237
Actual label: 5
Output voltages: [0.03707, 0.0011062, 0.0013129, 0.23325, 0.071522, 0.7973, 0.22809, 0.064778, 0.79388, 0.025082]
Predicted label: 5
Correct prediction
Energy consumption = 145.588905 pJ
sum error= 237
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 457 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 457 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 457 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.54923, 0.018197, 0.016085, 0.043329, 0.55365, 0.013669, 0.0023876, 0.0011529, 0.25697, 0.79751]
Predicted label: 9
Correct prediction
Energy consumption = 142.618818 pJ
sum error= 237
Actual label: 6
Output voltages: [0.62998, 0.018686, 0.5239, 0.30285, 0.024694, 0.0023207, 0.49901, 0.0012174, 0.79809, 0.04923]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.611886 pJ
sum error= 238
Actual label: 8
Output voltages: [0.05361, 0.026537, 0.12385, 0.070119, 0.015288, 0.01216, 0.03779, 0.0098139, 0.79876, 0.087278]
Predicted label: 8
Correct prediction
Energy consumption = 145.778078 pJ
sum error= 238
Actual label: 2
Output voltages: [0.66505, 0.39609, 0.79878, 0.017374, 0.0017748, 0.0012287, 0.096415, 0.43632, 0.44724, 0.042825]
Predicted label: 2
Correct prediction
Energy consumption = 143.276003 pJ
sum error= 238
Actual label: 1
Output voltages: [0.016913, 0.79866, 0.1562, 0.19833, 0.024345, 0.0044465, 0.72421, 0.0016837, 0.60989, 0.2047]
Predicted label: 1
Correct prediction
Energy consumption = 159.476781 pJ
sum error= 238
Actual label: 4
Output voltages: [0.75272, 0.0020643, 0.76433, 0.026635, 0.47746, 0.0011177, 0.32366, 0.0079791, 0.01173, 0.47402]
Predicted label: 2
Wrong prediction!
Energy consumption = 155.703830 pJ
sum error= 239
Actual label: 4
Output voltages: [0.0090428, 0.0091732, 0.31416, 0.004451, 0.79862, 0.0011254, 0.03646, 0.022499, 0.021346, 0.32091]
Predicted label: 4
Correct prediction
Energy consumption = 153.411897 pJ
sum error= 239
Actual label: 5
Output voltages: [0.19532, 0.008285, 0.0015638, 0.03496, 0.023015, 0.79868, 0.069299, 0.23943, 0.7897, 0.0014753]
Predicted label: 5
Correct prediction
Energy consumption = 150.199083 pJ
sum error= 239
Actual label: 7
Output voltages: [0.21541, 0.44943, 0.016511, 0.16104, 0.18247, 0.0033101, 0.001078, 0.73092, 0.0014819, 0.76736]
Predicted label: 9
Wrong prediction!
Energy consumption = 160.740404 pJ
sum error= 240
Actual label: 6
Output voltages: [0.010552, 0.022715, 0.029034, 0.0235, 0.059948, 0.17799, 0.79861, 0.00358, 0.75735, 0.011376]
Predicted label: 6
Correct prediction
Energy consumption = 155.337203 pJ
sum error= 240
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 458 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 458 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 458 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.050375, 0.79863, 0.029072, 0.016762, 0.1082, 0.0013105, 0.40998, 0.0023989, 0.05804, 0.049021]
Predicted label: 1
Correct prediction
Energy consumption = 161.672199 pJ
sum error= 240
Actual label: 3
Output voltages: [0.43177, 0.025553, 0.21048, 0.79866, 0.018845, 0.031181, 0.0098237, 0.017582, 0.62499, 0.03904]
Predicted label: 3
Correct prediction
Energy consumption = 150.182100 pJ
sum error= 240
Actual label: 2
Output voltages: [0.052491, 0.19237, 0.79831, 0.17371, 0.045331, 0.0012142, 0.17985, 0.02755, 0.44356, 0.014729]
Predicted label: 2
Correct prediction
Energy consumption = 153.653430 pJ
sum error= 240
Actual label: 5
Output voltages: [0.33861, 0.0011694, 0.0069759, 0.052059, 0.034569, 0.79861, 0.31947, 0.11485, 0.71378, 0.019305]
Predicted label: 5
Correct prediction
Energy consumption = 143.757510 pJ
sum error= 240
Actual label: 9
Output voltages: [0.29137, 0.028105, 0.027341, 0.026996, 0.060715, 0.014138, 0.24965, 0.013903, 0.23991, 0.79865]
Predicted label: 9
Correct prediction
Energy consumption = 144.734374 pJ
sum error= 240
Actual label: 9
Output voltages: [0.18512, 0.025421, 0.0020718, 0.35864, 0.43178, 0.038457, 0.12684, 0.029597, 0.02286, 0.79747]
Predicted label: 9
Correct prediction
Energy consumption = 138.835022 pJ
sum error= 240
Actual label: 3
Output voltages: [0.405, 0.03127, 0.088337, 0.79874, 0.023295, 0.020418, 0.016836, 0.0054124, 0.68837, 0.12734]
Predicted label: 3
Correct prediction
Energy consumption = 148.780953 pJ
sum error= 240
Actual label: 6
Output voltages: [0.032608, 0.028417, 0.08399, 0.0021238, 0.48182, 0.2707, 0.79875, 0.0011341, 0.55303, 0.011627]
Predicted label: 6
Correct prediction
Energy consumption = 149.541601 pJ
sum error= 240
Actual label: 1
Output voltages: [0.0030403, 0.79851, 0.34537, 0.65417, 0.0042209, 0.001302, 0.42924, 0.071312, 0.048737, 0.020661]
Predicted label: 1
Correct prediction
Energy consumption = 165.480375 pJ
sum error= 240
Actual label: 1
Output voltages: [0.036997, 0.79862, 0.0072403, 0.025651, 0.39457, 0.0043923, 0.54265, 0.0075824, 0.22208, 0.062622]
Predicted label: 1
Correct prediction
Energy consumption = 148.356755 pJ
sum error= 240
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 459 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 459 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 459 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0040418, 0.0089764, 0.057107, 0.025577, 0.79868, 0.0010827, 0.08404, 0.056698, 0.0067715, 0.040959]
Predicted label: 4
Correct prediction
Energy consumption = 160.040616 pJ
sum error= 240
Actual label: 6
Output voltages: [0.08231, 0.002566, 0.20697, 0.0010689, 0.60679, 0.051448, 0.79879, 0.0010701, 0.56619, 0.0046983]
Predicted label: 6
Correct prediction
Energy consumption = 142.526465 pJ
sum error= 240
Actual label: 9
Output voltages: [0.6225, 0.0038204, 0.010699, 0.28348, 0.68066, 0.028344, 0.0087754, 0.022645, 0.036791, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 143.499406 pJ
sum error= 240
Actual label: 7
Output voltages: [0.24792, 0.11067, 0.03472, 0.50921, 0.0015559, 0.003594, 0.0011466, 0.79878, 0.019195, 0.60509]
Predicted label: 7
Correct prediction
Energy consumption = 151.197607 pJ
sum error= 240
Actual label: 2
Output voltages: [0.74115, 0.46603, 0.79869, 0.051844, 0.0028305, 0.0013763, 0.077785, 0.14286, 0.20003, 0.10072]
Predicted label: 2
Correct prediction
Energy consumption = 142.507120 pJ
sum error= 240
Actual label: 1
Output voltages: [0.010108, 0.79854, 0.039891, 0.080574, 0.02732, 0.0023026, 0.27482, 0.0031049, 0.30711, 0.046919]
Predicted label: 1
Correct prediction
Energy consumption = 153.072323 pJ
sum error= 240
Actual label: 5
Output voltages: [0.20299, 0.0011182, 0.007472, 0.15327, 0.048178, 0.79879, 0.019238, 0.033913, 0.77623, 0.10589]
Predicted label: 5
Correct prediction
Energy consumption = 146.153360 pJ
sum error= 240
Actual label: 1
Output voltages: [0.035648, 0.79848, 0.28873, 0.033332, 0.14702, 0.0051293, 0.40732, 0.0084943, 0.053193, 0.029398]
Predicted label: 1
Correct prediction
Energy consumption = 166.818966 pJ
sum error= 240
Actual label: 4
Output voltages: [0.034236, 0.0053132, 0.35292, 0.024104, 0.79876, 0.0015289, 0.087406, 0.090799, 0.0052553, 0.52477]
Predicted label: 4
Correct prediction
Energy consumption = 156.943218 pJ
sum error= 240
Actual label: 6
Output voltages: [0.63702, 0.037964, 0.028994, 0.010022, 0.49846, 0.71865, 0.79879, 0.0043292, 0.52774, 0.0011342]
Predicted label: 6
Correct prediction
Energy consumption = 153.058356 pJ
sum error= 240
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 460 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 460 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 460 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.26965, 0.031634, 0.04497, 0.79853, 0.016803, 0.023515, 0.014209, 0.032375, 0.56659, 0.036112]
Predicted label: 3
Correct prediction
Energy consumption = 147.589591 pJ
sum error= 240
Actual label: 8
Output voltages: [0.0031751, 0.038257, 0.054862, 0.61531, 0.43103, 0.0034344, 0.028933, 0.20078, 0.79599, 0.022473]
Predicted label: 8
Correct prediction
Energy consumption = 141.682671 pJ
sum error= 240
Actual label: 1
Output voltages: [0.022046, 0.79871, 0.395, 0.031689, 0.11575, 0.0010717, 0.62092, 0.01327, 0.15114, 0.012405]
Predicted label: 1
Correct prediction
Energy consumption = 157.506223 pJ
sum error= 240
Actual label: 1
Output voltages: [0.039155, 0.79843, 0.095708, 0.4117, 0.05739, 0.03359, 0.18742, 0.34835, 0.014608, 0.029457]
Predicted label: 1
Correct prediction
Energy consumption = 160.117034 pJ
sum error= 240
Actual label: 0
Output voltages: [0.79667, 0.02641, 0.035707, 0.0080972, 0.0082826, 0.0092112, 0.76694, 0.043377, 0.089871, 0.035304]
Predicted label: 0
Correct prediction
Energy consumption = 150.600620 pJ
sum error= 240
Actual label: 3
Output voltages: [0.32844, 0.036384, 0.030978, 0.79865, 0.011088, 0.012224, 0.0080512, 0.014775, 0.46991, 0.18713]
Predicted label: 3
Correct prediction
Energy consumption = 147.552513 pJ
sum error= 240
Actual label: 1
Output voltages: [0.060103, 0.79877, 0.042961, 0.033426, 0.045803, 0.0010783, 0.65499, 0.0043744, 0.18756, 0.035069]
Predicted label: 1
Correct prediction
Energy consumption = 157.281701 pJ
sum error= 240
Actual label: 6
Output voltages: [0.16446, 0.042138, 0.024308, 0.017674, 0.33461, 0.13307, 0.79879, 0.015705, 0.76157, 0.0016657]
Predicted label: 6
Correct prediction
Energy consumption = 149.749291 pJ
sum error= 240
Actual label: 8
Output voltages: [0.39448, 0.0074824, 0.24856, 0.36224, 0.017072, 0.0017699, 0.042767, 0.0010911, 0.79818, 0.03518]
Predicted label: 8
Correct prediction
Energy consumption = 144.441419 pJ
sum error= 240
Actual label: 4
Output voltages: [0.0018393, 0.010278, 0.080047, 0.0073896, 0.79874, 0.0011176, 0.052174, 0.043609, 0.024564, 0.028407]
Predicted label: 4
Correct prediction
Energy consumption = 148.702192 pJ
sum error= 240
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 461 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 461 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 461 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.066156, 0.0033621, 0.017094, 0.035864, 0.33428, 0.0073127, 0.0050335, 0.11563, 0.2175, 0.79781]
Predicted label: 9
Correct prediction
Energy consumption = 155.919025 pJ
sum error= 240
Actual label: 0
Output voltages: [0.79877, 0.13292, 0.02857, 0.013747, 0.019343, 0.013484, 0.5814, 0.010774, 0.088381, 0.053529]
Predicted label: 0
Correct prediction
Energy consumption = 147.501862 pJ
sum error= 240
Actual label: 7
Output voltages: [0.14414, 0.035145, 0.014678, 0.074612, 0.0085178, 0.0011038, 0.0010659, 0.79879, 0.42386, 0.53202]
Predicted label: 7
Correct prediction
Energy consumption = 151.287445 pJ
sum error= 240
Actual label: 3
Output voltages: [0.38332, 0.0075738, 0.065904, 0.79871, 0.014296, 0.19921, 0.0033982, 0.026325, 0.70471, 0.060876]
Predicted label: 3
Correct prediction
Energy consumption = 144.189358 pJ
sum error= 240
Actual label: 0
Output voltages: [0.79879, 0.0087317, 0.047722, 0.05832, 0.0014075, 0.049255, 0.33773, 0.042436, 0.039372, 0.036231]
Predicted label: 0
Correct prediction
Energy consumption = 140.273484 pJ
sum error= 240
Actual label: 2
Output voltages: [0.69599, 0.03446, 0.74516, 0.095667, 0.77047, 0.0011245, 0.16689, 0.024817, 0.21554, 0.057103]
Predicted label: 4
Wrong prediction!
Energy consumption = 141.062200 pJ
sum error= 241
Actual label: 9
Output voltages: [0.18395, 0.02666, 0.022573, 0.54125, 0.074181, 0.42633, 0.097241, 0.12235, 0.48949, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 156.345662 pJ
sum error= 241
Actual label: 0
Output voltages: [0.79868, 0.029218, 0.028473, 0.1454, 0.0023675, 0.13675, 0.55267, 0.05438, 0.36143, 0.025981]
Predicted label: 0
Correct prediction
Energy consumption = 140.499308 pJ
sum error= 241
Actual label: 6
Output voltages: [0.036751, 0.11885, 0.32143, 0.0010829, 0.28581, 0.041836, 0.79876, 0.0011627, 0.39219, 0.0041453]
Predicted label: 6
Correct prediction
Energy consumption = 137.711096 pJ
sum error= 241
Actual label: 6
Output voltages: [0.12369, 0.029492, 0.013653, 0.18722, 0.087772, 0.31933, 0.78847, 0.0027038, 0.79459, 0.016326]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.454834 pJ
sum error= 242
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 462 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 462 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 462 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.17307, 0.008837, 0.19139, 0.0011201, 0.31699, 0.029789, 0.79855, 0.0031891, 0.69861, 0.0011599]
Predicted label: 6
Correct prediction
Energy consumption = 139.567447 pJ
sum error= 242
Actual label: 3
Output voltages: [0.14214, 0.0068442, 0.31445, 0.79876, 0.082139, 0.25705, 0.023151, 0.0061458, 0.40042, 0.01239]
Predicted label: 3
Correct prediction
Energy consumption = 145.907658 pJ
sum error= 242
Actual label: 6
Output voltages: [0.36421, 0.012672, 0.0048647, 0.023081, 0.19864, 0.50396, 0.79879, 0.001068, 0.25845, 0.037806]
Predicted label: 6
Correct prediction
Energy consumption = 145.126358 pJ
sum error= 242
Actual label: 7
Output voltages: [0.27876, 0.02502, 0.014644, 0.077913, 0.008761, 0.025649, 0.0011108, 0.79861, 0.12451, 0.37448]
Predicted label: 7
Correct prediction
Energy consumption = 155.911504 pJ
sum error= 242
Actual label: 7
Output voltages: [0.05013, 0.063178, 0.26784, 0.070602, 0.0050354, 0.0010931, 0.001654, 0.79868, 0.032363, 0.47545]
Predicted label: 7
Correct prediction
Energy consumption = 145.266542 pJ
sum error= 242
Actual label: 2
Output voltages: [0.027588, 0.047109, 0.79864, 0.34411, 0.0087401, 0.0013464, 0.09481, 0.12026, 0.5396, 0.012406]
Predicted label: 2
Correct prediction
Energy consumption = 141.073772 pJ
sum error= 242
Actual label: 8
Output voltages: [0.017203, 0.029707, 0.36951, 0.031118, 0.055794, 0.013773, 0.015233, 0.0075385, 0.79879, 0.027172]
Predicted label: 8
Correct prediction
Energy consumption = 144.095398 pJ
sum error= 242
Actual label: 6
Output voltages: [0.025699, 0.043037, 0.5203, 0.0010906, 0.618, 0.034701, 0.79878, 0.0011119, 0.19592, 0.0059264]
Predicted label: 6
Correct prediction
Energy consumption = 144.559733 pJ
sum error= 242
Actual label: 0
Output voltages: [0.79879, 0.22712, 0.017813, 0.0025524, 0.025736, 0.034439, 0.54345, 0.0090549, 0.11126, 0.050796]
Predicted label: 0
Correct prediction
Energy consumption = 148.284298 pJ
sum error= 242
Actual label: 8
Output voltages: [0.0082552, 0.023599, 0.25868, 0.016524, 0.014926, 0.0039624, 0.027413, 0.013699, 0.79875, 0.40549]
Predicted label: 8
Correct prediction
Energy consumption = 146.211650 pJ
sum error= 242
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 463 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 463 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 463 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.30814, 0.021892, 0.033641, 0.79869, 0.0094115, 0.019862, 0.032155, 0.0030096, 0.48861, 0.13231]
Predicted label: 3
Correct prediction
Energy consumption = 149.770773 pJ
sum error= 242
Actual label: 0
Output voltages: [0.79876, 0.026242, 0.016249, 0.012636, 0.029023, 0.0041564, 0.5994, 0.0080279, 0.048236, 0.054869]
Predicted label: 0
Correct prediction
Energy consumption = 157.722898 pJ
sum error= 242
Actual label: 2
Output voltages: [0.42845, 0.0034072, 0.7987, 0.056167, 0.040706, 0.0010677, 0.035765, 0.16201, 0.59443, 0.0031951]
Predicted label: 2
Correct prediction
Energy consumption = 146.630483 pJ
sum error= 242
Actual label: 9
Output voltages: [0.51305, 0.0037619, 0.035957, 0.063704, 0.07523, 0.0071393, 0.0054952, 0.52588, 0.21008, 0.79537]
Predicted label: 9
Correct prediction
Energy consumption = 157.622299 pJ
sum error= 242
Actual label: 8
Output voltages: [0.0090738, 0.017159, 0.043933, 0.32009, 0.0090559, 0.22167, 0.006743, 0.002681, 0.79879, 0.25291]
Predicted label: 8
Correct prediction
Energy consumption = 152.336166 pJ
sum error= 242
Actual label: 3
Output voltages: [0.5473, 0.012349, 0.019785, 0.79859, 0.0048281, 0.25597, 0.045688, 0.061534, 0.34794, 0.0036987]
Predicted label: 3
Correct prediction
Energy consumption = 148.218345 pJ
sum error= 242
Actual label: 2
Output voltages: [0.082292, 0.30174, 0.79865, 0.057778, 0.024648, 0.0011784, 0.18636, 0.034785, 0.15352, 0.30667]
Predicted label: 2
Correct prediction
Energy consumption = 141.681114 pJ
sum error= 242
Actual label: 5
Output voltages: [0.12645, 0.0010661, 0.01676, 0.053163, 0.007029, 0.79634, 0.095493, 0.02058, 0.77332, 0.044368]
Predicted label: 5
Correct prediction
Energy consumption = 146.078379 pJ
sum error= 242
Actual label: 3
Output voltages: [0.27217, 0.00311, 0.02023, 0.79827, 0.020068, 0.60618, 0.016921, 0.086736, 0.56684, 0.0018029]
Predicted label: 3
Correct prediction
Energy consumption = 138.586193 pJ
sum error= 242
Actual label: 8
Output voltages: [0.16798, 0.0014267, 0.0066658, 0.0086443, 0.23615, 0.02903, 0.0045121, 0.059406, 0.69853, 0.78712]
Predicted label: 9
Wrong prediction!
Energy consumption = 156.771512 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 464 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 464 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 464 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.019495, 0.044819, 0.050023, 0.54749, 0.0020693, 0.0079789, 0.031654, 0.016832, 0.79878, 0.079923]
Predicted label: 8
Correct prediction
Energy consumption = 153.706350 pJ
sum error= 243
Actual label: 0
Output voltages: [0.79863, 0.13595, 0.0057411, 0.019857, 0.02019, 0.032613, 0.21481, 0.0090763, 0.25574, 0.037006]
Predicted label: 0
Correct prediction
Energy consumption = 156.245315 pJ
sum error= 243
Actual label: 0
Output voltages: [0.79876, 0.038662, 0.014811, 0.012598, 0.046706, 0.015656, 0.73763, 0.02452, 0.13436, 0.17135]
Predicted label: 0
Correct prediction
Energy consumption = 148.089100 pJ
sum error= 243
Actual label: 1
Output voltages: [0.017201, 0.79879, 0.0048449, 0.29796, 0.16653, 0.0011518, 0.0087668, 0.017249, 0.52425, 0.33476]
Predicted label: 1
Correct prediction
Energy consumption = 159.708005 pJ
sum error= 243
Actual label: 9
Output voltages: [0.061062, 0.01882, 0.019873, 0.029185, 0.16574, 0.017498, 0.0025921, 0.0049871, 0.54295, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 145.738582 pJ
sum error= 243
Actual label: 5
Output voltages: [0.03068, 0.0011644, 0.0043473, 0.018794, 0.028201, 0.79469, 0.2495, 0.0047683, 0.78931, 0.026168]
Predicted label: 5
Correct prediction
Energy consumption = 145.789967 pJ
sum error= 243
Actual label: 1
Output voltages: [0.022837, 0.7984, 0.0014098, 0.23866, 0.026644, 0.00297, 0.20835, 0.014685, 0.19028, 0.2799]
Predicted label: 1
Correct prediction
Energy consumption = 164.652207 pJ
sum error= 243
Actual label: 3
Output voltages: [0.14227, 0.038602, 0.14818, 0.79857, 0.056721, 0.023306, 0.013503, 0.36422, 0.42728, 0.053532]
Predicted label: 3
Correct prediction
Energy consumption = 152.810860 pJ
sum error= 243
Actual label: 9
Output voltages: [0.25897, 0.017422, 0.032816, 0.043814, 0.053753, 0.019706, 0.0028862, 0.18546, 0.4818, 0.79598]
Predicted label: 9
Correct prediction
Energy consumption = 148.954119 pJ
sum error= 243
Actual label: 6
Output voltages: [0.024791, 0.29046, 0.075032, 0.0082693, 0.090243, 0.18176, 0.79867, 0.0094574, 0.6935, 0.0084951]
Predicted label: 6
Correct prediction
Energy consumption = 152.554668 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 465 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 465 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 465 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79875, 0.046528, 0.090171, 0.017324, 0.0016502, 0.020529, 0.66357, 0.015462, 0.41131, 0.016615]
Predicted label: 0
Correct prediction
Energy consumption = 145.682265 pJ
sum error= 243
Actual label: 1
Output voltages: [0.016382, 0.79836, 0.20233, 0.053388, 0.028612, 0.014693, 0.65642, 0.021609, 0.18823, 0.073181]
Predicted label: 1
Correct prediction
Energy consumption = 163.410588 pJ
sum error= 243
Actual label: 4
Output voltages: [0.010909, 0.0056296, 0.21456, 0.0018304, 0.79843, 0.011809, 0.081635, 0.18302, 0.04706, 0.23506]
Predicted label: 4
Correct prediction
Energy consumption = 150.755889 pJ
sum error= 243
Actual label: 1
Output voltages: [0.010659, 0.79866, 0.035534, 0.0043358, 0.021555, 0.025796, 0.59948, 0.067096, 0.67191, 0.0043449]
Predicted label: 1
Correct prediction
Energy consumption = 165.315377 pJ
sum error= 243
Actual label: 7
Output voltages: [0.039008, 0.0086463, 0.28168, 0.043384, 0.40813, 0.0010861, 0.0035031, 0.79872, 0.032993, 0.063076]
Predicted label: 7
Correct prediction
Energy consumption = 141.743180 pJ
sum error= 243
Actual label: 1
Output voltages: [0.035782, 0.79862, 0.0024759, 0.40417, 0.38712, 0.10016, 0.31337, 0.0031089, 0.031578, 0.43734]
Predicted label: 1
Correct prediction
Energy consumption = 165.113577 pJ
sum error= 243
Actual label: 2
Output voltages: [0.080109, 0.0045132, 0.79877, 0.12002, 0.020636, 0.0011433, 0.014793, 0.54266, 0.33612, 0.01291]
Predicted label: 2
Correct prediction
Energy consumption = 138.806626 pJ
sum error= 243
Actual label: 3
Output voltages: [0.02396, 0.21604, 0.15889, 0.79868, 0.0026111, 0.001093, 0.0032795, 0.012972, 0.39074, 0.02803]
Predicted label: 3
Correct prediction
Energy consumption = 142.050670 pJ
sum error= 243
Actual label: 7
Output voltages: [0.01475, 0.012736, 0.76817, 0.046323, 0.015261, 0.0011224, 0.0017453, 0.79836, 0.45847, 0.23513]
Predicted label: 7
Correct prediction
Energy consumption = 143.878678 pJ
sum error= 243
Actual label: 9
Output voltages: [0.23766, 0.0025206, 0.11396, 0.1255, 0.201, 0.006699, 0.011317, 0.02887, 0.045993, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 149.908320 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 466 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 466 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 466 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.066077, 0.012258, 0.36028, 0.35814, 0.18352, 0.0010684, 0.0010777, 0.79877, 0.20227, 0.24328]
Predicted label: 7
Correct prediction
Energy consumption = 154.139746 pJ
sum error= 243
Actual label: 4
Output voltages: [0.010667, 0.01098, 0.55149, 0.014794, 0.79867, 0.0012445, 0.14398, 0.21768, 0.016429, 0.16952]
Predicted label: 4
Correct prediction
Energy consumption = 152.180641 pJ
sum error= 243
Actual label: 9
Output voltages: [0.29209, 0.0029111, 0.014532, 0.2295, 0.020327, 0.022521, 0.0010679, 0.75172, 0.68212, 0.78002]
Predicted label: 9
Correct prediction
Energy consumption = 143.690324 pJ
sum error= 243
Actual label: 9
Output voltages: [0.55676, 0.012185, 0.0035718, 0.38925, 0.5964, 0.053069, 0.018423, 0.0068335, 0.18002, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 151.878490 pJ
sum error= 243
Actual label: 3
Output voltages: [0.35291, 0.0081412, 0.051021, 0.79873, 0.057433, 0.52696, 0.056261, 0.020979, 0.42319, 0.032169]
Predicted label: 3
Correct prediction
Energy consumption = 150.733817 pJ
sum error= 243
Actual label: 9
Output voltages: [0.015412, 0.052548, 0.40779, 0.25317, 0.26165, 0.006091, 0.0012877, 0.0025313, 0.073408, 0.78987]
Predicted label: 9
Correct prediction
Energy consumption = 151.329079 pJ
sum error= 243
Actual label: 2
Output voltages: [0.27784, 0.13421, 0.79877, 0.054021, 0.0068642, 0.0013123, 0.1432, 0.0056803, 0.48139, 0.037315]
Predicted label: 2
Correct prediction
Energy consumption = 143.886382 pJ
sum error= 243
Actual label: 8
Output voltages: [0.038176, 0.030386, 0.14175, 0.231, 0.0064554, 0.015653, 0.012022, 0.00182, 0.79867, 0.14817]
Predicted label: 8
Correct prediction
Energy consumption = 140.615316 pJ
sum error= 243
Actual label: 2
Output voltages: [0.069342, 0.033061, 0.7791, 0.51233, 0.078924, 0.0011433, 0.026082, 0.039291, 0.5214, 0.0065758]
Predicted label: 2
Correct prediction
Energy consumption = 146.829899 pJ
sum error= 243
Actual label: 7
Output voltages: [0.082046, 0.033905, 0.058565, 0.08023, 0.015594, 0.015708, 0.001066, 0.79862, 0.32815, 0.60628]
Predicted label: 7
Correct prediction
Energy consumption = 155.405481 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 467 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 467 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 467 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.080165, 0.79871, 0.45506, 0.11121, 0.28776, 0.001066, 0.53267, 0.0069069, 0.11326, 0.029712]
Predicted label: 1
Correct prediction
Energy consumption = 162.662490 pJ
sum error= 243
Actual label: 8
Output voltages: [0.40416, 0.0068078, 0.036246, 0.73877, 0.0040749, 0.29449, 0.03814, 0.0030715, 0.79879, 0.29874]
Predicted label: 8
Correct prediction
Energy consumption = 153.233893 pJ
sum error= 243
Actual label: 0
Output voltages: [0.79876, 0.049976, 0.0093553, 0.026682, 0.02146, 0.025657, 0.52039, 0.025693, 0.20411, 0.10706]
Predicted label: 0
Correct prediction
Energy consumption = 154.090494 pJ
sum error= 243
Actual label: 9
Output voltages: [0.28675, 0.035609, 0.0054375, 0.035743, 0.36378, 0.15525, 0.041361, 0.0025787, 0.22538, 0.79805]
Predicted label: 9
Correct prediction
Energy consumption = 146.956982 pJ
sum error= 243
Actual label: 1
Output voltages: [0.01846, 0.79879, 0.10088, 0.011651, 0.04527, 0.0054209, 0.7845, 0.0028346, 0.47899, 0.02113]
Predicted label: 1
Correct prediction
Energy consumption = 154.710533 pJ
sum error= 243
Actual label: 0
Output voltages: [0.79879, 0.26734, 0.01565, 0.048201, 0.011102, 0.031995, 0.64309, 0.12348, 0.16801, 0.20866]
Predicted label: 0
Correct prediction
Energy consumption = 161.188132 pJ
sum error= 243
Actual label: 1
Output voltages: [0.014419, 0.79845, 0.038096, 0.071214, 0.0044948, 0.0034971, 0.7593, 0.012372, 0.45156, 0.034143]
Predicted label: 1
Correct prediction
Energy consumption = 162.294967 pJ
sum error= 243
Actual label: 7
Output voltages: [0.026261, 0.4056, 0.55317, 0.018848, 0.014428, 0.0011213, 0.001093, 0.79874, 0.20107, 0.035083]
Predicted label: 7
Correct prediction
Energy consumption = 157.154480 pJ
sum error= 243
Actual label: 7
Output voltages: [0.22296, 0.0323, 0.022846, 0.65281, 0.0033076, 0.0024736, 0.0011276, 0.79871, 0.25593, 0.64458]
Predicted label: 7
Correct prediction
Energy consumption = 148.716713 pJ
sum error= 243
Actual label: 9
Output voltages: [0.39846, 0.0088598, 0.0021818, 0.35218, 0.11939, 0.38844, 0.009001, 0.20769, 0.37171, 0.79551]
Predicted label: 9
Correct prediction
Energy consumption = 137.323635 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 468 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 468 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 468 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.036572, 0.10882, 0.21197, 0.0059683, 0.38998, 0.39586, 0.79867, 0.0060553, 0.3285, 0.018075]
Predicted label: 6
Correct prediction
Energy consumption = 141.687029 pJ
sum error= 243
Actual label: 9
Output voltages: [0.50958, 0.0011686, 0.40092, 0.010051, 0.18457, 0.0035821, 0.044554, 0.013564, 0.058565, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 152.163964 pJ
sum error= 243
Actual label: 9
Output voltages: [0.33871, 0.010403, 0.016652, 0.034687, 0.13013, 0.014666, 0.0030129, 0.11756, 0.38296, 0.79821]
Predicted label: 9
Correct prediction
Energy consumption = 148.752635 pJ
sum error= 243
Actual label: 9
Output voltages: [0.19993, 0.0039078, 0.056925, 0.01142, 0.14599, 0.0016467, 0.0052398, 0.049648, 0.53928, 0.79847]
Predicted label: 9
Correct prediction
Energy consumption = 143.977141 pJ
sum error= 243
Actual label: 2
Output voltages: [0.09586, 0.027861, 0.79869, 0.049431, 0.0020224, 0.001066, 0.040395, 0.43024, 0.67975, 0.0077407]
Predicted label: 2
Correct prediction
Energy consumption = 148.360988 pJ
sum error= 243
Actual label: 1
Output voltages: [0.0011085, 0.7987, 0.51383, 0.54754, 0.30481, 0.0031551, 0.042552, 0.043297, 0.057962, 0.25554]
Predicted label: 1
Correct prediction
Energy consumption = 163.391874 pJ
sum error= 243
Actual label: 6
Output voltages: [0.44069, 0.31042, 0.21003, 0.0012499, 0.0115, 0.014075, 0.79736, 0.0010689, 0.20517, 0.032751]
Predicted label: 6
Correct prediction
Energy consumption = 153.984033 pJ
sum error= 243
Actual label: 1
Output voltages: [0.033245, 0.79876, 0.38081, 0.37594, 0.039492, 0.001073, 0.69865, 0.015243, 0.027499, 0.03737]
Predicted label: 1
Correct prediction
Energy consumption = 165.224888 pJ
sum error= 243
Actual label: 3
Output voltages: [0.07552, 0.0062679, 0.0426, 0.79873, 0.046354, 0.013856, 0.03225, 0.021164, 0.7687, 0.058894]
Predicted label: 3
Correct prediction
Energy consumption = 144.611097 pJ
sum error= 243
Actual label: 5
Output voltages: [0.022406, 0.0013384, 0.0064221, 0.22965, 0.1749, 0.79878, 0.51478, 0.0072554, 0.75354, 0.017089]
Predicted label: 5
Correct prediction
Energy consumption = 139.047299 pJ
sum error= 243
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 469 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 469 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 469 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.56297, 0.0016248, 0.73427, 0.61688, 0.016279, 0.0015468, 0.0050459, 0.73299, 0.070712, 0.30971]
Predicted label: 2
Wrong prediction!
Energy consumption = 154.687472 pJ
sum error= 244
Actual label: 1
Output voltages: [0.047941, 0.79871, 0.30913, 0.031653, 0.012301, 0.0011021, 0.65603, 0.001067, 0.10602, 0.027213]
Predicted label: 1
Correct prediction
Energy consumption = 164.951113 pJ
sum error= 244
Actual label: 9
Output voltages: [0.77474, 0.01877, 0.0096684, 0.22842, 0.32946, 0.12316, 0.010205, 0.0036489, 0.098699, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 157.468506 pJ
sum error= 244
Actual label: 7
Output voltages: [0.33614, 0.014329, 0.014392, 0.052246, 0.086841, 0.28781, 0.0010718, 0.79877, 0.032958, 0.75217]
Predicted label: 7
Correct prediction
Energy consumption = 149.362545 pJ
sum error= 244
Actual label: 6
Output voltages: [0.026871, 0.13332, 0.37431, 0.0010789, 0.24255, 0.135, 0.79872, 0.0013851, 0.27494, 0.0028929]
Predicted label: 6
Correct prediction
Energy consumption = 152.115387 pJ
sum error= 244
Actual label: 4
Output voltages: [0.0022076, 0.015582, 0.14501, 0.018656, 0.79879, 0.0017279, 0.016296, 0.023281, 0.2847, 0.0093892]
Predicted label: 4
Correct prediction
Energy consumption = 155.150128 pJ
sum error= 244
Actual label: 5
Output voltages: [0.02499, 0.008281, 0.004437, 0.64383, 0.0082256, 0.79866, 0.029866, 0.048931, 0.74798, 0.038273]
Predicted label: 5
Correct prediction
Energy consumption = 145.453282 pJ
sum error= 244
Actual label: 7
Output voltages: [0.61038, 0.0083358, 0.28787, 0.038504, 0.024851, 0.001153, 0.0011222, 0.79874, 0.23495, 0.038003]
Predicted label: 7
Correct prediction
Energy consumption = 154.082001 pJ
sum error= 244
Actual label: 6
Output voltages: [0.26939, 0.03923, 0.34494, 0.002037, 0.16131, 0.3122, 0.79876, 0.004363, 0.31494, 0.0092882]
Predicted label: 6
Correct prediction
Energy consumption = 146.878864 pJ
sum error= 244
Actual label: 6
Output voltages: [0.10566, 0.50287, 0.048366, 0.022192, 0.011926, 0.28309, 0.79879, 0.021217, 0.65294, 0.0025162]
Predicted label: 6
Correct prediction
Energy consumption = 147.370119 pJ
sum error= 244
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 470 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 470 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 470 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.22835, 0.040953, 0.022295, 0.047021, 0.2151, 0.019238, 0.0040716, 0.02009, 0.08705, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 157.720673 pJ
sum error= 244
Actual label: 9
Output voltages: [0.27775, 0.001934, 0.0049641, 0.043074, 0.041379, 0.027639, 0.0011473, 0.050611, 0.63503, 0.79804]
Predicted label: 9
Correct prediction
Energy consumption = 147.684554 pJ
sum error= 244
Actual label: 6
Output voltages: [0.02848, 0.010868, 0.13344, 0.024899, 0.020763, 0.70464, 0.79427, 0.001073, 0.60779, 0.0066557]
Predicted label: 6
Correct prediction
Energy consumption = 149.593336 pJ
sum error= 244
Actual label: 3
Output voltages: [0.30551, 0.019918, 0.018399, 0.79878, 0.006477, 0.050784, 0.048085, 0.049613, 0.46505, 0.0011666]
Predicted label: 3
Correct prediction
Energy consumption = 145.448507 pJ
sum error= 244
Actual label: 6
Output voltages: [0.030677, 0.044833, 0.01531, 0.020478, 0.19613, 0.4217, 0.79879, 0.0099354, 0.62731, 0.0054627]
Predicted label: 6
Correct prediction
Energy consumption = 144.693632 pJ
sum error= 244
Actual label: 2
Output voltages: [0.43532, 0.19035, 0.79872, 0.10008, 0.041734, 0.0012187, 0.39656, 0.0091741, 0.40333, 0.14023]
Predicted label: 2
Correct prediction
Energy consumption = 149.998955 pJ
sum error= 244
Actual label: 9
Output voltages: [0.040515, 0.0058564, 0.051707, 0.02301, 0.757, 0.0025992, 0.0061601, 0.025475, 0.048124, 0.79702]
Predicted label: 9
Correct prediction
Energy consumption = 147.514178 pJ
sum error= 244
Actual label: 8
Output voltages: [0.01091, 0.031647, 0.28947, 0.044584, 0.016683, 0.025189, 0.022475, 0.0149, 0.79877, 0.34766]
Predicted label: 8
Correct prediction
Energy consumption = 149.759018 pJ
sum error= 244
Actual label: 1
Output voltages: [0.0058731, 0.79848, 0.043713, 0.20039, 0.032275, 0.0017609, 0.75723, 0.015714, 0.085901, 0.051219]
Predicted label: 1
Correct prediction
Energy consumption = 165.078661 pJ
sum error= 244
Actual label: 2
Output voltages: [0.47268, 0.0061039, 0.79879, 0.024555, 0.029707, 0.001078, 0.22873, 0.078573, 0.77084, 0.0056689]
Predicted label: 2
Correct prediction
Energy consumption = 148.296345 pJ
sum error= 244
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 471 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 471 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 471 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.18364, 0.3234, 0.79877, 0.3618, 0.0013467, 0.0012655, 0.22001, 0.01262, 0.63005, 0.018961]
Predicted label: 2
Correct prediction
Energy consumption = 149.819633 pJ
sum error= 244
Actual label: 5
Output voltages: [0.055957, 0.0015317, 0.046355, 0.033607, 0.0012764, 0.75933, 0.016174, 0.0010659, 0.7951, 0.13292]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.751853 pJ
sum error= 245
Actual label: 5
Output voltages: [0.030432, 0.0011652, 0.0021534, 0.039689, 0.059077, 0.79304, 0.031367, 0.14664, 0.7268, 0.21784]
Predicted label: 5
Correct prediction
Energy consumption = 141.730076 pJ
sum error= 245
Actual label: 2
Output voltages: [0.11451, 0.0012488, 0.79513, 0.49005, 0.002772, 0.0027147, 0.4123, 0.026486, 0.74443, 0.001131]
Predicted label: 2
Correct prediction
Energy consumption = 139.410270 pJ
sum error= 245
Actual label: 3
Output voltages: [0.69855, 0.020681, 0.031192, 0.79864, 0.002573, 0.046612, 0.0099373, 0.044113, 0.41972, 0.018757]
Predicted label: 3
Correct prediction
Energy consumption = 143.269836 pJ
sum error= 245
Actual label: 7
Output voltages: [0.12508, 0.024104, 0.022674, 0.32249, 0.011922, 0.010382, 0.0010668, 0.79859, 0.10006, 0.41953]
Predicted label: 7
Correct prediction
Energy consumption = 149.828907 pJ
sum error= 245
Actual label: 2
Output voltages: [0.04311, 0.041888, 0.79872, 0.22518, 0.029132, 0.0011739, 0.17647, 0.027626, 0.59677, 0.027528]
Predicted label: 2
Correct prediction
Energy consumption = 151.943412 pJ
sum error= 245
Actual label: 1
Output voltages: [0.010594, 0.79855, 0.033696, 0.0142, 0.04022, 0.0052215, 0.71626, 0.013494, 0.23245, 0.016928]
Predicted label: 1
Correct prediction
Energy consumption = 159.247154 pJ
sum error= 245
Actual label: 0
Output voltages: [0.79878, 0.061967, 0.039996, 0.0095724, 0.0076739, 0.0082207, 0.3954, 0.016651, 0.24303, 0.018662]
Predicted label: 0
Correct prediction
Energy consumption = 154.344889 pJ
sum error= 245
Actual label: 1
Output voltages: [0.016469, 0.7984, 0.0056069, 0.15672, 0.036895, 0.0022452, 0.46881, 0.030495, 0.16412, 0.27387]
Predicted label: 1
Correct prediction
Energy consumption = 161.810021 pJ
sum error= 245
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 472 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 472 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 472 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.034608, 0.41537, 0.033046, 0.022691, 0.0012605, 0.33702, 0.042522, 0.19729, 0.30899]
Predicted label: 0
Correct prediction
Energy consumption = 160.775981 pJ
sum error= 245
Actual label: 4
Output voltages: [0.0043113, 0.0095906, 0.16062, 0.021224, 0.79875, 0.012444, 0.2155, 0.011385, 0.013491, 0.51103]
Predicted label: 4
Correct prediction
Energy consumption = 148.440674 pJ
sum error= 245
Actual label: 5
Output voltages: [0.41541, 0.0011242, 0.0030314, 0.31436, 0.0055762, 0.79874, 0.41801, 0.36339, 0.69894, 0.0095481]
Predicted label: 5
Correct prediction
Energy consumption = 136.602997 pJ
sum error= 245
Actual label: 2
Output voltages: [0.047679, 0.012394, 0.77828, 0.34897, 0.0042287, 0.0011806, 0.01068, 0.50554, 0.76448, 0.0078125]
Predicted label: 2
Correct prediction
Energy consumption = 145.541278 pJ
sum error= 245
Actual label: 8
Output voltages: [0.3782, 0.0035744, 0.049104, 0.22644, 0.017459, 0.032875, 0.29824, 0.0010898, 0.79853, 0.0031934]
Predicted label: 8
Correct prediction
Energy consumption = 151.671556 pJ
sum error= 245
Actual label: 2
Output voltages: [0.26731, 0.16261, 0.79878, 0.082662, 0.015854, 0.0012572, 0.045021, 0.40676, 0.38658, 0.055093]
Predicted label: 2
Correct prediction
Energy consumption = 150.720990 pJ
sum error= 245
Actual label: 8
Output voltages: [0.002967, 0.34288, 0.17607, 0.18547, 0.015964, 0.010505, 0.07894, 0.064281, 0.79868, 0.30038]
Predicted label: 8
Correct prediction
Energy consumption = 154.947206 pJ
sum error= 245
Actual label: 3
Output voltages: [0.1504, 0.028366, 0.10406, 0.79867, 0.053241, 0.0013843, 0.0091455, 0.043682, 0.54852, 0.044764]
Predicted label: 3
Correct prediction
Energy consumption = 147.372004 pJ
sum error= 245
Actual label: 5
Output voltages: [0.22144, 0.0012282, 0.0011965, 0.63588, 0.13577, 0.79879, 0.27464, 0.003174, 0.65772, 0.015228]
Predicted label: 5
Correct prediction
Energy consumption = 137.098674 pJ
sum error= 245
Actual label: 1
Output voltages: [0.034063, 0.79878, 0.03357, 0.21759, 0.03014, 0.0012455, 0.042483, 0.0010665, 0.31646, 0.049172]
Predicted label: 1
Correct prediction
Energy consumption = 160.524857 pJ
sum error= 245
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 473 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 473 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 473 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.52076, 0.27098, 0.0079664, 0.1147, 0.0078071, 0.0089967, 0.001089, 0.79868, 0.12242, 0.19487]
Predicted label: 7
Correct prediction
Energy consumption = 156.673447 pJ
sum error= 245
Actual label: 8
Output voltages: [0.096573, 0.34865, 0.67302, 0.060301, 0.0097379, 0.001118, 0.017323, 0.17411, 0.79775, 0.020783]
Predicted label: 8
Correct prediction
Energy consumption = 149.796556 pJ
sum error= 245
Actual label: 1
Output voltages: [0.0027388, 0.79855, 0.0069985, 0.052072, 0.015134, 0.0056498, 0.51633, 0.018196, 0.16485, 0.020907]
Predicted label: 1
Correct prediction
Energy consumption = 154.997260 pJ
sum error= 245
Actual label: 1
Output voltages: [0.0070718, 0.79877, 0.0010712, 0.0065112, 0.44845, 0.025628, 0.61266, 0.012958, 0.030533, 0.011039]
Predicted label: 1
Correct prediction
Energy consumption = 146.702915 pJ
sum error= 245
Actual label: 2
Output voltages: [0.34884, 0.030212, 0.79875, 0.055258, 0.017908, 0.0012811, 0.3691, 0.035929, 0.64795, 0.029661]
Predicted label: 2
Correct prediction
Energy consumption = 147.553301 pJ
sum error= 245
Actual label: 9
Output voltages: [0.29882, 0.0033529, 0.035631, 0.077434, 0.10407, 0.010904, 0.0046689, 0.69718, 0.31904, 0.79766]
Predicted label: 9
Correct prediction
Energy consumption = 148.750251 pJ
sum error= 245
Actual label: 7
Output voltages: [0.032969, 0.043653, 0.74055, 0.023892, 0.028358, 0.0013767, 0.0024415, 0.79624, 0.42232, 0.018412]
Predicted label: 7
Correct prediction
Energy consumption = 146.040268 pJ
sum error= 245
Actual label: 8
Output voltages: [0.13947, 0.035859, 0.16416, 0.016623, 0.0046718, 0.064796, 0.74768, 0.0030303, 0.79601, 0.0082643]
Predicted label: 8
Correct prediction
Energy consumption = 146.967167 pJ
sum error= 245
Actual label: 4
Output voltages: [0.0060806, 0.11978, 0.010011, 0.043671, 0.79851, 0.0017002, 0.40158, 0.061869, 0.008422, 0.020465]
Predicted label: 4
Correct prediction
Energy consumption = 152.236911 pJ
sum error= 245
Actual label: 0
Output voltages: [0.78804, 0.0010944, 0.25365, 0.0010679, 0.22858, 0.003094, 0.53698, 0.016957, 0.0066419, 0.27392]
Predicted label: 0
Correct prediction
Energy consumption = 140.732936 pJ
sum error= 245
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 474 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 474 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 474 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.05169, 0.013012, 0.0035291, 0.79687, 0.062528, 0.74007, 0.019228, 0.15953, 0.052932, 0.16747]
Predicted label: 3
Correct prediction
Energy consumption = 158.022401 pJ
sum error= 245
Actual label: 0
Output voltages: [0.79577, 0.037569, 0.017541, 0.0043218, 0.13883, 0.0087458, 0.77594, 0.012168, 0.16096, 0.022632]
Predicted label: 0
Correct prediction
Energy consumption = 155.695670 pJ
sum error= 245
Actual label: 7
Output voltages: [0.018008, 0.020085, 0.4381, 0.031585, 0.056827, 0.001162, 0.001232, 0.79876, 0.03824, 0.056526]
Predicted label: 7
Correct prediction
Energy consumption = 150.500388 pJ
sum error= 245
Actual label: 8
Output voltages: [0.29628, 0.0042386, 0.17137, 0.66086, 0.0010678, 0.30471, 0.59749, 0.0011064, 0.7841, 0.079968]
Predicted label: 8
Correct prediction
Energy consumption = 148.706316 pJ
sum error= 245
Actual label: 8
Output voltages: [0.13292, 0.096435, 0.17842, 0.7573, 0.00727, 0.011676, 0.062307, 0.0051664, 0.79879, 0.11411]
Predicted label: 8
Correct prediction
Energy consumption = 156.274162 pJ
sum error= 245
Actual label: 4
Output voltages: [0.0054916, 0.010634, 0.56258, 0.16378, 0.79876, 0.0018159, 0.14947, 0.16583, 0.021219, 0.37195]
Predicted label: 4
Correct prediction
Energy consumption = 154.174421 pJ
sum error= 245
Actual label: 7
Output voltages: [0.41251, 0.0063762, 0.0010793, 0.026425, 0.25986, 0.10114, 0.0010682, 0.79878, 0.32259, 0.54503]
Predicted label: 7
Correct prediction
Energy consumption = 156.151009 pJ
sum error= 245
Actual label: 7
Output voltages: [0.46109, 0.019749, 0.03497, 0.24993, 0.016377, 0.0048897, 0.00111, 0.79874, 0.72478, 0.59064]
Predicted label: 7
Correct prediction
Energy consumption = 143.307837 pJ
sum error= 245
Actual label: 8
Output voltages: [0.025813, 0.0080691, 0.041699, 0.12285, 0.014441, 0.027573, 0.017821, 0.01819, 0.79879, 0.31138]
Predicted label: 8
Correct prediction
Energy consumption = 139.762346 pJ
sum error= 245
Actual label: 5
Output voltages: [0.07041, 0.0010688, 0.0013711, 0.38268, 0.030702, 0.79865, 0.062788, 0.015463, 0.77185, 0.14411]
Predicted label: 5
Correct prediction
Energy consumption = 146.162194 pJ
sum error= 245
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 475 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 475 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 475 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.25514, 0.0018616, 0.57509, 0.2473, 0.02395, 0.010248, 0.032133, 0.01405, 0.79878, 0.23537]
Predicted label: 8
Correct prediction
Energy consumption = 155.284232 pJ
sum error= 245
Actual label: 4
Output voltages: [0.043598, 0.021495, 0.094285, 0.0056223, 0.79877, 0.0034471, 0.7442, 0.066816, 0.0065595, 0.029053]
Predicted label: 4
Correct prediction
Energy consumption = 157.143770 pJ
sum error= 245
Actual label: 9
Output voltages: [0.38703, 0.015132, 0.040561, 0.016743, 0.73149, 0.045491, 0.017891, 0.01542, 0.17285, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 154.337577 pJ
sum error= 245
Actual label: 8
Output voltages: [0.010505, 0.16032, 0.040579, 0.22998, 0.0018469, 0.0079339, 0.0070302, 0.035263, 0.79876, 0.13463]
Predicted label: 8
Correct prediction
Energy consumption = 152.862221 pJ
sum error= 245
Actual label: 1
Output voltages: [0.039177, 0.79861, 0.10017, 0.026615, 0.039024, 0.0011092, 0.45561, 0.0017007, 0.039693, 0.038021]
Predicted label: 1
Correct prediction
Energy consumption = 163.749288 pJ
sum error= 245
Actual label: 3
Output voltages: [0.59317, 0.28642, 0.27662, 0.79875, 0.041512, 0.033442, 0.0078622, 0.13884, 0.26782, 0.0089298]
Predicted label: 3
Correct prediction
Energy consumption = 153.465952 pJ
sum error= 245
Actual label: 8
Output voltages: [0.021781, 0.046694, 0.45014, 0.069103, 0.0087518, 0.026592, 0.021591, 0.029035, 0.79875, 0.080786]
Predicted label: 8
Correct prediction
Energy consumption = 150.259878 pJ
sum error= 245
Actual label: 0
Output voltages: [0.79861, 0.058168, 0.10662, 0.0085647, 0.012436, 0.0013884, 0.68387, 0.015705, 0.075484, 0.38679]
Predicted label: 0
Correct prediction
Energy consumption = 154.565792 pJ
sum error= 245
Actual label: 3
Output voltages: [0.17969, 0.028799, 0.14277, 0.79866, 0.015451, 0.012179, 0.0033926, 0.031911, 0.78279, 0.01331]
Predicted label: 3
Correct prediction
Energy consumption = 147.644537 pJ
sum error= 245
Actual label: 1
Output voltages: [0.025115, 0.79871, 0.0042902, 0.051738, 0.72421, 0.0010793, 0.039327, 0.029167, 0.028602, 0.048885]
Predicted label: 1
Correct prediction
Energy consumption = 155.905209 pJ
sum error= 245
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 476 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 476 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 476 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.10748, 0.274, 0.019993, 0.37967, 0.0094455, 0.0010939, 0.0011046, 0.79867, 0.043301, 0.76689]
Predicted label: 7
Correct prediction
Energy consumption = 161.688662 pJ
sum error= 245
Actual label: 9
Output voltages: [0.30382, 0.12274, 0.11373, 0.013395, 0.044294, 0.0011906, 0.0041345, 0.01465, 0.79311, 0.77016]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.271993 pJ
sum error= 246
Actual label: 5
Output voltages: [0.012023, 0.0010697, 0.035763, 0.44912, 0.033794, 0.79748, 0.033136, 0.013092, 0.77667, 0.093632]
Predicted label: 5
Correct prediction
Energy consumption = 146.157693 pJ
sum error= 246
Actual label: 5
Output voltages: [0.066785, 0.010736, 0.0012701, 0.055665, 0.0039502, 0.79735, 0.78006, 0.0019738, 0.60375, 0.0010858]
Predicted label: 5
Correct prediction
Energy consumption = 140.117791 pJ
sum error= 246
Actual label: 1
Output voltages: [0.047585, 0.79838, 0.012443, 0.0686, 0.053352, 0.0098812, 0.47053, 0.0051657, 0.21038, 0.064156]
Predicted label: 1
Correct prediction
Energy consumption = 167.076629 pJ
sum error= 246
Actual label: 6
Output voltages: [0.35497, 0.48051, 0.34281, 0.012677, 0.053906, 0.153, 0.7987, 0.0016311, 0.19537, 0.028299]
Predicted label: 6
Correct prediction
Energy consumption = 144.409575 pJ
sum error= 246
Actual label: 5
Output voltages: [0.15081, 0.0010792, 0.0097469, 0.42183, 0.0064987, 0.79878, 0.142, 0.047473, 0.77322, 0.046867]
Predicted label: 5
Correct prediction
Energy consumption = 140.417113 pJ
sum error= 246
Actual label: 7
Output voltages: [0.29306, 0.005326, 0.033159, 0.43189, 0.0027511, 0.0080899, 0.0012059, 0.79877, 0.6266, 0.451]
Predicted label: 7
Correct prediction
Energy consumption = 146.192770 pJ
sum error= 246
Actual label: 4
Output voltages: [0.0096377, 0.012051, 0.062648, 0.00158, 0.79876, 0.014379, 0.57387, 0.053447, 0.26779, 0.018505]
Predicted label: 4
Correct prediction
Energy consumption = 149.522299 pJ
sum error= 246
Actual label: 9
Output voltages: [0.4854, 0.0034764, 0.010261, 0.066091, 0.14534, 0.0018386, 0.0015865, 0.12061, 0.33021, 0.79717]
Predicted label: 9
Correct prediction
Energy consumption = 148.326587 pJ
sum error= 246
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 477 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 477 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 477 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.16425, 0.031789, 0.054448, 0.79867, 0.013407, 0.01552, 0.01538, 0.010536, 0.51511, 0.11154]
Predicted label: 3
Correct prediction
Energy consumption = 143.767932 pJ
sum error= 246
Actual label: 5
Output voltages: [0.043108, 0.0031975, 0.026494, 0.055438, 0.010335, 0.79607, 0.036565, 0.0010909, 0.7693, 0.021597]
Predicted label: 5
Correct prediction
Energy consumption = 151.803205 pJ
sum error= 246
Actual label: 4
Output voltages: [0.01073, 0.012072, 0.040292, 0.0065036, 0.79878, 0.011634, 0.13106, 0.099301, 0.34411, 0.036908]
Predicted label: 4
Correct prediction
Energy consumption = 152.449678 pJ
sum error= 246
Actual label: 7
Output voltages: [0.30231, 0.1732, 0.057132, 0.64798, 0.0013801, 0.0014806, 0.0010879, 0.79875, 0.24917, 0.33847]
Predicted label: 7
Correct prediction
Energy consumption = 162.594185 pJ
sum error= 246
Actual label: 1
Output voltages: [0.0073178, 0.79859, 0.023964, 0.05264, 0.030986, 0.0011287, 0.54373, 0.0027836, 0.43192, 0.19692]
Predicted label: 1
Correct prediction
Energy consumption = 159.904193 pJ
sum error= 246
Actual label: 2
Output voltages: [0.53017, 0.22293, 0.79591, 0.16155, 0.03053, 0.0013274, 0.53684, 0.10862, 0.37926, 0.011836]
Predicted label: 2
Correct prediction
Energy consumption = 144.591153 pJ
sum error= 246
Actual label: 0
Output voltages: [0.79873, 0.028287, 0.035649, 0.0068826, 0.008186, 0.0015971, 0.74056, 0.02062, 0.27684, 0.086416]
Predicted label: 0
Correct prediction
Energy consumption = 139.784297 pJ
sum error= 246
Actual label: 8
Output voltages: [0.044159, 0.071675, 0.016893, 0.75836, 0.0012814, 0.071104, 0.41592, 0.011276, 0.79879, 0.0099301]
Predicted label: 8
Correct prediction
Energy consumption = 153.919100 pJ
sum error= 246
Actual label: 1
Output voltages: [0.0029628, 0.7985, 0.028245, 0.10559, 0.019881, 0.0088041, 0.056557, 0.013852, 0.020189, 0.22191]
Predicted label: 1
Correct prediction
Energy consumption = 157.753221 pJ
sum error= 246
Actual label: 6
Output voltages: [0.093147, 0.014923, 0.38517, 0.0014352, 0.27001, 0.2078, 0.79878, 0.0062517, 0.5957, 0.0091413]
Predicted label: 6
Correct prediction
Energy consumption = 148.946861 pJ
sum error= 246
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 478 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 478 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 478 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79705, 0.11267, 0.093196, 0.021326, 0.035534, 0.0048107, 0.77205, 0.010658, 0.33899, 0.016878]
Predicted label: 0
Correct prediction
Energy consumption = 159.812505 pJ
sum error= 246
Actual label: 7
Output voltages: [0.064289, 0.15799, 0.37882, 0.17336, 0.002078, 0.0010828, 0.0011687, 0.79877, 0.73425, 0.19695]
Predicted label: 7
Correct prediction
Energy consumption = 151.464245 pJ
sum error= 246
Actual label: 3
Output voltages: [0.12664, 0.019831, 0.019882, 0.79875, 0.0082991, 0.0081297, 0.010294, 0.051994, 0.50658, 0.052525]
Predicted label: 3
Correct prediction
Energy consumption = 143.509898 pJ
sum error= 246
Actual label: 4
Output voltages: [0.0015274, 0.030378, 0.058415, 0.041227, 0.79879, 0.0018658, 0.29106, 0.027671, 0.025093, 0.34081]
Predicted label: 4
Correct prediction
Energy consumption = 145.502072 pJ
sum error= 246
Actual label: 7
Output voltages: [0.18257, 0.017027, 0.037891, 0.10134, 0.0041845, 0.0099094, 0.0011386, 0.79872, 0.3077, 0.53546]
Predicted label: 7
Correct prediction
Energy consumption = 152.331270 pJ
sum error= 246
Actual label: 3
Output voltages: [0.016155, 0.013855, 0.14709, 0.79492, 0.0018497, 0.004514, 0.001415, 0.15448, 0.79112, 0.052752]
Predicted label: 3
Correct prediction
Energy consumption = 142.148580 pJ
sum error= 246
Actual label: 9
Output voltages: [0.52796, 0.025465, 0.008548, 0.24398, 0.44658, 0.021761, 0.020208, 0.0062238, 0.28271, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 142.497066 pJ
sum error= 246
Actual label: 6
Output voltages: [0.10681, 0.093737, 0.055207, 0.0076456, 0.19681, 0.20957, 0.79879, 0.0022437, 0.48658, 0.0035308]
Predicted label: 6
Correct prediction
Energy consumption = 153.862154 pJ
sum error= 246
Actual label: 0
Output voltages: [0.79812, 0.052032, 0.0030169, 0.029462, 0.05381, 0.25524, 0.7446, 0.044848, 0.022982, 0.26442]
Predicted label: 0
Correct prediction
Energy consumption = 150.623976 pJ
sum error= 246
Actual label: 8
Output voltages: [0.065318, 0.018298, 0.13492, 0.17287, 0.001545, 0.73009, 0.08979, 0.0067791, 0.79879, 0.01731]
Predicted label: 8
Correct prediction
Energy consumption = 149.982583 pJ
sum error= 246
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 479 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 479 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 479 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.11051, 0.040407, 0.10445, 0.0011013, 0.18071, 0.33226, 0.79877, 0.010605, 0.54093, 0.010469]
Predicted label: 6
Correct prediction
Energy consumption = 151.358486 pJ
sum error= 246
Actual label: 4
Output voltages: [0.038726, 0.1087, 0.0023554, 0.37466, 0.79876, 0.0094502, 0.030005, 0.027547, 0.01639, 0.14754]
Predicted label: 4
Correct prediction
Energy consumption = 152.140630 pJ
sum error= 246
Actual label: 8
Output voltages: [0.010666, 0.038751, 0.32814, 0.026682, 0.0080381, 0.019465, 0.017963, 0.024437, 0.79878, 0.53065]
Predicted label: 8
Correct prediction
Energy consumption = 152.765496 pJ
sum error= 246
Actual label: 7
Output voltages: [0.19198, 0.040958, 0.39203, 0.016847, 0.0016627, 0.0082861, 0.0011782, 0.79869, 0.64889, 0.35531]
Predicted label: 7
Correct prediction
Energy consumption = 145.513305 pJ
sum error= 246
Actual label: 7
Output voltages: [0.12209, 0.0049168, 0.0012228, 0.0096494, 0.28458, 0.017143, 0.0010719, 0.79866, 0.24728, 0.20447]
Predicted label: 7
Correct prediction
Energy consumption = 154.158926 pJ
sum error= 246
Actual label: 9
Output voltages: [0.18528, 0.038788, 0.023995, 0.06818, 0.076049, 0.027462, 0.034951, 0.027133, 0.66857, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 137.430323 pJ
sum error= 246
Actual label: 3
Output voltages: [0.13642, 0.27889, 0.24462, 0.79865, 0.0081958, 0.018144, 0.0063532, 0.17562, 0.57447, 0.062277]
Predicted label: 3
Correct prediction
Energy consumption = 152.300593 pJ
sum error= 246
Actual label: 8
Output voltages: [0.0085249, 0.2493, 0.20448, 0.029565, 0.019248, 0.0042995, 0.019521, 0.037729, 0.7987, 0.29526]
Predicted label: 8
Correct prediction
Energy consumption = 145.653521 pJ
sum error= 246
Actual label: 6
Output voltages: [0.12489, 0.031598, 0.015076, 0.043662, 0.070256, 0.54573, 0.79621, 0.015908, 0.79727, 0.0021067]
Predicted label: 8
Wrong prediction!
Energy consumption = 151.731588 pJ
sum error= 247
Actual label: 9
Output voltages: [0.35246, 0.034925, 0.01082, 0.45846, 0.18813, 0.012397, 0.0096972, 0.041909, 0.15052, 0.79464]
Predicted label: 9
Correct prediction
Energy consumption = 152.363866 pJ
sum error= 247
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 480 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 480 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 480 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37223, 0.0021975, 0.0054991, 0.39432, 0.004896, 0.036505, 0.0012049, 0.79875, 0.60997, 0.62847]
Predicted label: 7
Correct prediction
Energy consumption = 152.662112 pJ
sum error= 247
Actual label: 2
Output voltages: [0.035613, 0.36358, 0.7972, 0.17143, 0.31601, 0.0010687, 0.26076, 0.02551, 0.38946, 0.13262]
Predicted label: 2
Correct prediction
Energy consumption = 149.958196 pJ
sum error= 247
Actual label: 3
Output voltages: [0.11542, 0.0057809, 0.013308, 0.79861, 0.020793, 0.29559, 0.008847, 0.0025748, 0.42712, 0.027654]
Predicted label: 3
Correct prediction
Energy consumption = 148.323161 pJ
sum error= 247
Actual label: 4
Output voltages: [0.0083251, 0.0075139, 0.039424, 0.00583, 0.79854, 0.0017613, 0.035079, 0.10465, 0.044241, 0.0050119]
Predicted label: 4
Correct prediction
Energy consumption = 152.645825 pJ
sum error= 247
Actual label: 0
Output voltages: [0.79877, 0.081902, 0.043986, 0.014627, 0.0056287, 0.0097963, 0.55343, 0.0072303, 0.4209, 0.015668]
Predicted label: 0
Correct prediction
Energy consumption = 152.700195 pJ
sum error= 247
Actual label: 2
Output voltages: [0.52925, 0.37375, 0.79879, 0.025901, 0.025956, 0.0013572, 0.41351, 0.26614, 0.27348, 0.038557]
Predicted label: 2
Correct prediction
Energy consumption = 148.980361 pJ
sum error= 247
Actual label: 1
Output voltages: [0.052746, 0.79853, 0.23901, 0.040514, 0.027112, 0.0012982, 0.61682, 0.0010683, 0.028831, 0.072134]
Predicted label: 1
Correct prediction
Energy consumption = 156.168412 pJ
sum error= 247
Actual label: 8
Output voltages: [0.77801, 0.011841, 0.035059, 0.6521, 0.0044571, 0.0014523, 0.19815, 0.0010783, 0.7538, 0.47574]
Predicted label: 0
Wrong prediction!
Energy consumption = 154.290692 pJ
sum error= 248
Actual label: 3
Output voltages: [0.014845, 0.012206, 0.0060472, 0.79344, 0.012253, 0.71204, 0.037325, 0.21148, 0.59675, 0.030635]
Predicted label: 3
Correct prediction
Energy consumption = 146.229389 pJ
sum error= 248
Actual label: 5
Output voltages: [0.0089777, 0.0011159, 0.001086, 0.04773, 0.2807, 0.79855, 0.22977, 0.01021, 0.69045, 0.034188]
Predicted label: 5
Correct prediction
Energy consumption = 139.780187 pJ
sum error= 248
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 481 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 481 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 481 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.0043375, 0.01138, 0.0014251, 0.32167, 0.013436, 0.79876, 0.10994, 0.031043, 0.65182, 0.077922]
Predicted label: 5
Correct prediction
Energy consumption = 150.491665 pJ
sum error= 248
Actual label: 7
Output voltages: [0.16782, 0.047264, 0.035351, 0.35906, 0.0077925, 0.0089659, 0.0010671, 0.79856, 0.19394, 0.41026]
Predicted label: 7
Correct prediction
Energy consumption = 152.432266 pJ
sum error= 248
Actual label: 2
Output voltages: [0.43513, 0.15717, 0.79873, 0.13845, 0.017855, 0.0013084, 0.26373, 0.029141, 0.30894, 0.03542]
Predicted label: 2
Correct prediction
Energy consumption = 152.494309 pJ
sum error= 248
Actual label: 4
Output voltages: [0.014947, 0.007931, 0.34337, 0.0011198, 0.79878, 0.0021284, 0.14982, 0.0045268, 0.12961, 0.018354]
Predicted label: 4
Correct prediction
Energy consumption = 145.988182 pJ
sum error= 248
Actual label: 6
Output voltages: [0.79103, 0.0015071, 0.059144, 0.0040178, 0.072723, 0.0039088, 0.68035, 0.0066201, 0.41708, 0.024154]
Predicted label: 0
Wrong prediction!
Energy consumption = 159.686817 pJ
sum error= 249
Actual label: 7
Output voltages: [0.31037, 0.047312, 0.016844, 0.19411, 0.0069875, 0.0058956, 0.0011545, 0.79875, 0.26517, 0.51554]
Predicted label: 7
Correct prediction
Energy consumption = 152.141768 pJ
sum error= 249
Actual label: 2
Output voltages: [0.42461, 0.0025527, 0.52569, 0.78642, 0.027069, 0.028108, 0.46698, 0.0067894, 0.11502, 0.0028429]
Predicted label: 3
Wrong prediction!
Energy consumption = 146.758241 pJ
sum error= 250
Actual label: 8
Output voltages: [0.042621, 0.030064, 0.34127, 0.19831, 0.0047138, 0.12249, 0.040006, 0.027355, 0.79877, 0.41635]
Predicted label: 8
Correct prediction
Energy consumption = 157.815043 pJ
sum error= 250
Actual label: 3
Output voltages: [0.14947, 0.031021, 0.046467, 0.79867, 0.028239, 0.0035824, 0.0092879, 0.011631, 0.5457, 0.1219]
Predicted label: 3
Correct prediction
Energy consumption = 139.018586 pJ
sum error= 250
Actual label: 0
Output voltages: [0.79874, 0.045458, 0.1541, 0.01123, 0.027707, 0.0057102, 0.14523, 0.018744, 0.38903, 0.1522]
Predicted label: 0
Correct prediction
Energy consumption = 152.781389 pJ
sum error= 250
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 482 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 482 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 482 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.010408, 0.026742, 0.017193, 0.097111, 0.0031544, 0.11685, 0.0017267, 0.019122, 0.79878, 0.465]
Predicted label: 8
Correct prediction
Energy consumption = 152.646334 pJ
sum error= 250
Actual label: 7
Output voltages: [0.30984, 0.01438, 0.0076009, 0.022887, 0.047384, 0.060781, 0.0010838, 0.79852, 0.36586, 0.36074]
Predicted label: 7
Correct prediction
Energy consumption = 152.055314 pJ
sum error= 250
Actual label: 8
Output voltages: [0.036371, 0.032959, 0.080069, 0.43408, 0.0028282, 0.0082436, 0.042727, 0.0014651, 0.79879, 0.23468]
Predicted label: 8
Correct prediction
Energy consumption = 152.454585 pJ
sum error= 250
Actual label: 9
Output voltages: [0.035408, 0.0014796, 0.056026, 0.0064548, 0.79076, 0.012772, 0.76861, 0.0012842, 0.2144, 0.12768]
Predicted label: 4
Wrong prediction!
Energy consumption = 147.663123 pJ
sum error= 251
Actual label: 0
Output voltages: [0.7923, 0.053054, 0.039201, 0.14372, 0.03842, 0.0048594, 0.71001, 0.019677, 0.54004, 0.014293]
Predicted label: 0
Correct prediction
Energy consumption = 158.046308 pJ
sum error= 251
Actual label: 8
Output voltages: [0.047903, 0.015735, 0.076187, 0.37477, 0.0034697, 0.0012392, 0.0052143, 0.0025137, 0.78193, 0.53951]
Predicted label: 8
Correct prediction
Energy consumption = 154.264775 pJ
sum error= 251
Actual label: 4
Output voltages: [0.00341, 0.14035, 0.051084, 0.010961, 0.79867, 0.0010666, 0.013867, 0.053183, 0.017018, 0.67904]
Predicted label: 4
Correct prediction
Energy consumption = 153.504600 pJ
sum error= 251
Actual label: 4
Output voltages: [0.0027438, 0.011573, 0.02397, 0.0011609, 0.79878, 0.0032795, 0.021494, 0.045726, 0.51784, 0.020397]
Predicted label: 4
Correct prediction
Energy consumption = 142.862404 pJ
sum error= 251
Actual label: 5
Output voltages: [0.04935, 0.0010895, 0.006214, 0.21323, 0.11225, 0.79785, 0.099891, 0.14915, 0.69655, 0.53669]
Predicted label: 5
Correct prediction
Energy consumption = 149.964455 pJ
sum error= 251
Actual label: 8
Output voltages: [0.049116, 0.041847, 0.033487, 0.0085592, 0.031128, 0.045441, 0.025687, 0.33534, 0.79876, 0.051025]
Predicted label: 8
Correct prediction
Energy consumption = 149.231323 pJ
sum error= 251
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 483 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 483 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 483 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.044249, 0.0010683, 0.0017881, 0.30533, 0.13781, 0.79852, 0.078986, 0.018095, 0.77626, 0.20664]
Predicted label: 5
Correct prediction
Energy consumption = 142.643760 pJ
sum error= 251
Actual label: 6
Output voltages: [0.34375, 0.021838, 0.17221, 0.0054153, 0.21511, 0.21559, 0.79856, 0.0019792, 0.67146, 0.0086528]
Predicted label: 6
Correct prediction
Energy consumption = 145.316543 pJ
sum error= 251
Actual label: 6
Output voltages: [0.15267, 0.03833, 0.25772, 0.001627, 0.35508, 0.14129, 0.79869, 0.0014638, 0.54249, 0.017033]
Predicted label: 6
Correct prediction
Energy consumption = 143.237924 pJ
sum error= 251
Actual label: 3
Output voltages: [0.12897, 0.001649, 0.61298, 0.79867, 0.0079806, 0.0018271, 0.009108, 0.015308, 0.76585, 0.0047597]
Predicted label: 3
Correct prediction
Energy consumption = 141.715091 pJ
sum error= 251
Actual label: 0
Output voltages: [0.79879, 0.0011815, 0.12268, 0.021902, 0.0023553, 0.17204, 0.41248, 0.0059962, 0.19621, 0.30438]
Predicted label: 0
Correct prediction
Energy consumption = 141.856926 pJ
sum error= 251
Actual label: 9
Output voltages: [0.26162, 0.0082548, 0.018182, 0.020486, 0.017695, 0.025315, 0.0055753, 0.084833, 0.70986, 0.79391]
Predicted label: 9
Correct prediction
Energy consumption = 148.334019 pJ
sum error= 251
Actual label: 3
Output voltages: [0.34639, 0.010839, 0.20006, 0.79872, 0.03295, 0.030856, 0.011978, 0.028249, 0.53836, 0.20773]
Predicted label: 3
Correct prediction
Energy consumption = 144.589092 pJ
sum error= 251
Actual label: 7
Output voltages: [0.11206, 0.011748, 0.76547, 0.16443, 0.018308, 0.0011745, 0.0010681, 0.79822, 0.78428, 0.29279]
Predicted label: 7
Correct prediction
Energy consumption = 149.652611 pJ
sum error= 251
Actual label: 6
Output voltages: [0.5438, 0.047512, 0.0014992, 0.50863, 0.0018126, 0.78079, 0.77996, 0.053698, 0.74484, 0.0024808]
Predicted label: 5
Wrong prediction!
Energy consumption = 144.410010 pJ
sum error= 252
Actual label: 8
Output voltages: [0.12188, 0.035124, 0.34881, 0.68226, 0.001541, 0.01411, 0.043877, 0.015078, 0.79877, 0.080368]
Predicted label: 8
Correct prediction
Energy consumption = 145.628789 pJ
sum error= 252
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 484 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 484 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 484 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.63141, 0.0054851, 0.031505, 0.011684, 0.057763, 0.0028167, 0.0037852, 0.098462, 0.39455, 0.79839]
Predicted label: 9
Correct prediction
Energy consumption = 149.855929 pJ
sum error= 252
Actual label: 3
Output voltages: [0.44726, 0.024079, 0.32828, 0.79876, 0.0059886, 0.0018259, 0.0082552, 0.0049846, 0.74454, 0.09522]
Predicted label: 3
Correct prediction
Energy consumption = 149.339751 pJ
sum error= 252
Actual label: 4
Output voltages: [0.043918, 0.0065104, 0.35006, 0.031718, 0.79873, 0.026538, 0.024792, 0.016108, 0.028403, 0.57102]
Predicted label: 4
Correct prediction
Energy consumption = 152.819944 pJ
sum error= 252
Actual label: 9
Output voltages: [0.33085, 0.023825, 0.044746, 0.037916, 0.06005, 0.032433, 0.0031061, 0.048147, 0.40401, 0.79821]
Predicted label: 9
Correct prediction
Energy consumption = 147.031187 pJ
sum error= 252
Actual label: 5
Output voltages: [0.30941, 0.0016586, 0.0010756, 0.10255, 0.021015, 0.79861, 0.034518, 0.035928, 0.71286, 0.0086282]
Predicted label: 5
Correct prediction
Energy consumption = 147.390777 pJ
sum error= 252
Actual label: 8
Output voltages: [0.0035137, 0.12174, 0.044208, 0.12419, 0.001329, 0.0050507, 0.014956, 0.016327, 0.79879, 0.26547]
Predicted label: 8
Correct prediction
Energy consumption = 149.164055 pJ
sum error= 252
Actual label: 9
Output voltages: [0.31297, 0.001625, 0.26394, 0.020384, 0.25485, 0.015688, 0.0019857, 0.27141, 0.30713, 0.79709]
Predicted label: 9
Correct prediction
Energy consumption = 157.887325 pJ
sum error= 252
Actual label: 1
Output voltages: [0.038895, 0.79858, 0.1166, 0.12458, 0.023824, 0.0078438, 0.60421, 0.0012147, 0.033614, 0.049687]
Predicted label: 1
Correct prediction
Energy consumption = 163.145306 pJ
sum error= 252
Actual label: 2
Output voltages: [0.26655, 0.19462, 0.79872, 0.050436, 0.02762, 0.0012505, 0.23625, 0.029351, 0.58275, 0.13529]
Predicted label: 2
Correct prediction
Energy consumption = 146.324568 pJ
sum error= 252
Actual label: 8
Output voltages: [0.033308, 0.044235, 0.023022, 0.31831, 0.013105, 0.0036085, 0.09141, 0.011087, 0.79879, 0.27397]
Predicted label: 8
Correct prediction
Energy consumption = 150.430304 pJ
sum error= 252
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 485 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 485 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 485 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.011345, 0.046632, 0.11747, 0.070245, 0.0096253, 0.0025926, 0.029801, 0.042721, 0.79876, 0.26898]
Predicted label: 8
Correct prediction
Energy consumption = 153.149017 pJ
sum error= 252
Actual label: 6
Output voltages: [0.43001, 0.075895, 0.020913, 0.031047, 0.54313, 0.040328, 0.79879, 0.0021702, 0.52602, 0.018755]
Predicted label: 6
Correct prediction
Energy consumption = 153.742446 pJ
sum error= 252
Actual label: 8
Output voltages: [0.032204, 0.0017023, 0.29021, 0.05444, 0.0044057, 0.45176, 0.43666, 0.0014088, 0.79865, 0.016327]
Predicted label: 8
Correct prediction
Energy consumption = 144.384442 pJ
sum error= 252
Actual label: 1
Output voltages: [0.0044981, 0.79866, 0.0037222, 0.039489, 0.02294, 0.0011212, 0.53104, 0.0064439, 0.66892, 0.02977]
Predicted label: 1
Correct prediction
Energy consumption = 158.974631 pJ
sum error= 252
Actual label: 3
Output voltages: [0.38697, 0.0015382, 0.0095425, 0.79877, 0.0033827, 0.52152, 0.0011381, 0.18121, 0.43502, 0.0043977]
Predicted label: 3
Correct prediction
Energy consumption = 151.633567 pJ
sum error= 252
Actual label: 7
Output voltages: [0.3897, 0.0031528, 0.023352, 0.55138, 0.014653, 0.012586, 0.0012719, 0.7987, 0.47119, 0.55135]
Predicted label: 7
Correct prediction
Energy consumption = 141.211742 pJ
sum error= 252
Actual label: 9
Output voltages: [0.43174, 0.0064036, 0.012422, 0.050753, 0.047868, 0.012729, 0.0040416, 0.19258, 0.41794, 0.79688]
Predicted label: 9
Correct prediction
Energy consumption = 142.741493 pJ
sum error= 252
Actual label: 0
Output voltages: [0.79879, 0.031754, 0.16504, 0.028743, 0.003841, 0.023142, 0.1407, 0.013695, 0.5346, 0.27507]
Predicted label: 0
Correct prediction
Energy consumption = 154.708241 pJ
sum error= 252
Actual label: 1
Output voltages: [0.0091404, 0.79842, 0.21786, 0.19815, 0.032206, 0.0015567, 0.20811, 0.016624, 0.29252, 0.033475]
Predicted label: 1
Correct prediction
Energy consumption = 165.240922 pJ
sum error= 252
Actual label: 1
Output voltages: [0.013021, 0.79852, 0.0075995, 0.019048, 0.047414, 0.0059437, 0.3068, 0.0051318, 0.5766, 0.045169]
Predicted label: 1
Correct prediction
Energy consumption = 148.594774 pJ
sum error= 252
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 486 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 486 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 486 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.25451, 0.0022725, 0.036303, 0.1947, 0.73443, 0.0014983, 0.0015209, 0.0055629, 0.45929, 0.74741]
Predicted label: 9
Wrong prediction!
Energy consumption = 149.365655 pJ
sum error= 253
Actual label: 7
Output voltages: [0.62439, 0.086321, 0.19158, 0.76718, 0.0011095, 0.0010873, 0.0015377, 0.78907, 0.75342, 0.046591]
Predicted label: 7
Correct prediction
Energy consumption = 157.725682 pJ
sum error= 253
Actual label: 0
Output voltages: [0.79875, 0.03705, 0.2314, 0.011557, 0.020741, 0.0036498, 0.15894, 0.022265, 0.044449, 0.19533]
Predicted label: 0
Correct prediction
Energy consumption = 148.162809 pJ
sum error= 253
Actual label: 8
Output voltages: [0.016861, 0.093385, 0.081696, 0.097048, 0.0096089, 0.012087, 0.017759, 0.0017245, 0.79879, 0.517]
Predicted label: 8
Correct prediction
Energy consumption = 150.951117 pJ
sum error= 253
Actual label: 1
Output voltages: [0.038446, 0.79835, 0.020434, 0.064978, 0.021562, 0.0047464, 0.30997, 0.078312, 0.12865, 0.044247]
Predicted label: 1
Correct prediction
Energy consumption = 163.547801 pJ
sum error= 253
Actual label: 7
Output voltages: [0.19471, 0.047022, 0.40039, 0.032513, 0.0012618, 0.0010747, 0.001085, 0.79878, 0.76225, 0.060971]
Predicted label: 7
Correct prediction
Energy consumption = 147.529759 pJ
sum error= 253
Actual label: 4
Output voltages: [0.019995, 0.016626, 0.068024, 0.046406, 0.7987, 0.01726, 0.048978, 0.036462, 0.033994, 0.43598]
Predicted label: 4
Correct prediction
Energy consumption = 157.147543 pJ
sum error= 253
Actual label: 5
Output voltages: [0.0346, 0.0021971, 0.0083713, 0.52111, 0.035731, 0.79879, 0.54426, 0.017525, 0.61246, 0.14988]
Predicted label: 5
Correct prediction
Energy consumption = 147.239049 pJ
sum error= 253
Actual label: 7
Output voltages: [0.052312, 0.029709, 0.60426, 0.12854, 0.0059325, 0.0010674, 0.001119, 0.79878, 0.52171, 0.46231]
Predicted label: 7
Correct prediction
Energy consumption = 148.749037 pJ
sum error= 253
Actual label: 1
Output voltages: [0.0059321, 0.79851, 0.063774, 0.041051, 0.023821, 0.0015476, 0.74649, 0.0042876, 0.10655, 0.083499]
Predicted label: 1
Correct prediction
Energy consumption = 159.685963 pJ
sum error= 253
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 487 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 487 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 487 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.5005, 0.070593, 0.79869, 0.0308, 0.049324, 0.0011419, 0.42491, 0.031321, 0.55917, 0.032796]
Predicted label: 2
Correct prediction
Energy consumption = 152.292679 pJ
sum error= 253
Actual label: 1
Output voltages: [0.025599, 0.79852, 0.010367, 0.14006, 0.0011825, 0.0013589, 0.26414, 0.0049314, 0.50274, 0.047678]
Predicted label: 1
Correct prediction
Energy consumption = 166.318694 pJ
sum error= 253
Actual label: 1
Output voltages: [0.021496, 0.79864, 0.0012244, 0.027548, 0.32453, 0.025879, 0.67115, 0.01082, 0.034945, 0.03475]
Predicted label: 1
Correct prediction
Energy consumption = 151.439351 pJ
sum error= 253
Actual label: 3
Output voltages: [0.048593, 0.017369, 0.091663, 0.79873, 0.0078798, 0.01182, 0.0064574, 0.061736, 0.58107, 0.094632]
Predicted label: 3
Correct prediction
Energy consumption = 154.938200 pJ
sum error= 253
Actual label: 9
Output voltages: [0.76522, 0.0045325, 0.15177, 0.020041, 0.0025457, 0.026067, 0.7487, 0.0030394, 0.015713, 0.75966]
Predicted label: 0
Wrong prediction!
Energy consumption = 152.522284 pJ
sum error= 254
Actual label: 6
Output voltages: [0.24417, 0.072288, 0.22845, 0.0085054, 0.41897, 0.21326, 0.79868, 0.0016293, 0.3659, 0.020638]
Predicted label: 6
Correct prediction
Energy consumption = 146.907813 pJ
sum error= 254
Actual label: 2
Output voltages: [0.37637, 0.034576, 0.79425, 0.061171, 0.64972, 0.0016332, 0.65301, 0.51439, 0.0061867, 0.0014428]
Predicted label: 2
Correct prediction
Energy consumption = 145.974792 pJ
sum error= 254
Actual label: 1
Output voltages: [0.056593, 0.7985, 0.051558, 0.041991, 0.033551, 0.0056306, 0.73708, 0.0021328, 0.056969, 0.094733]
Predicted label: 1
Correct prediction
Energy consumption = 166.699863 pJ
sum error= 254
Actual label: 2
Output voltages: [0.38079, 0.0011461, 0.79597, 0.51532, 0.0010693, 0.01081, 0.017223, 0.090762, 0.77448, 0.0026851]
Predicted label: 2
Correct prediction
Energy consumption = 147.453302 pJ
sum error= 254
Actual label: 8
Output voltages: [0.0022067, 0.022259, 0.018548, 0.026857, 0.37722, 0.03867, 0.73991, 0.0023852, 0.79712, 0.045468]
Predicted label: 8
Correct prediction
Energy consumption = 148.301436 pJ
sum error= 254
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 488 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 488 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 488 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7663, 0.016727, 0.040469, 0.025958, 0.0051813, 0.0014927, 0.32913, 0.0042934, 0.63055, 0.033252]
Predicted label: 0
Correct prediction
Energy consumption = 160.576785 pJ
sum error= 254
Actual label: 7
Output voltages: [0.43906, 0.010345, 0.25718, 0.095681, 0.010334, 0.0015443, 0.0011231, 0.79874, 0.76179, 0.45077]
Predicted label: 7
Correct prediction
Energy consumption = 135.048893 pJ
sum error= 254
Actual label: 6
Output voltages: [0.0070053, 0.061604, 0.50236, 0.022958, 0.039936, 0.23938, 0.79877, 0.0015558, 0.7657, 0.027727]
Predicted label: 6
Correct prediction
Energy consumption = 146.794411 pJ
sum error= 254
Actual label: 6
Output voltages: [0.20594, 0.039832, 0.1915, 0.0013485, 0.43523, 0.30497, 0.79874, 0.0018087, 0.32389, 0.012234]
Predicted label: 6
Correct prediction
Energy consumption = 138.850996 pJ
sum error= 254
Actual label: 9
Output voltages: [0.25046, 0.014697, 0.050937, 0.015824, 0.18146, 0.017589, 0.004343, 0.01753, 0.59996, 0.79664]
Predicted label: 9
Correct prediction
Energy consumption = 153.794941 pJ
sum error= 254
Actual label: 3
Output voltages: [0.043708, 0.053067, 0.028802, 0.79879, 0.0019347, 0.048645, 0.0074646, 0.0014604, 0.70348, 0.045265]
Predicted label: 3
Correct prediction
Energy consumption = 144.439069 pJ
sum error= 254
Actual label: 7
Output voltages: [0.25623, 0.6556, 0.38598, 0.4316, 0.0010698, 0.0010826, 0.0029889, 0.79823, 0.7457, 0.082707]
Predicted label: 7
Correct prediction
Energy consumption = 154.767408 pJ
sum error= 254
Actual label: 0
Output voltages: [0.79879, 0.041355, 0.24628, 0.0071368, 0.016764, 0.02388, 0.10243, 0.043407, 0.68529, 0.15593]
Predicted label: 0
Correct prediction
Energy consumption = 157.916679 pJ
sum error= 254
Actual label: 5
Output voltages: [0.45425, 0.0010699, 0.0056855, 0.041789, 0.010537, 0.79879, 0.24533, 0.083533, 0.69909, 0.0019081]
Predicted label: 5
Correct prediction
Energy consumption = 147.308842 pJ
sum error= 254
Actual label: 2
Output voltages: [0.36528, 0.26344, 0.79848, 0.42486, 0.011249, 0.0013172, 0.06282, 0.0034547, 0.32671, 0.013713]
Predicted label: 2
Correct prediction
Energy consumption = 143.517618 pJ
sum error= 254
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 489 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 489 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 489 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.23718, 0.0023854, 0.37243, 0.47162, 0.010528, 0.012306, 0.17103, 0.010106, 0.7987, 0.0035621]
Predicted label: 8
Correct prediction
Energy consumption = 149.348658 pJ
sum error= 254
Actual label: 0
Output voltages: [0.79878, 0.049895, 0.038795, 0.0086145, 0.0079085, 0.0018847, 0.38394, 0.02381, 0.048927, 0.048067]
Predicted label: 0
Correct prediction
Energy consumption = 146.879623 pJ
sum error= 254
Actual label: 5
Output voltages: [0.02243, 0.0010661, 0.0015944, 0.13165, 0.14638, 0.79842, 0.060733, 0.0070389, 0.78174, 0.034821]
Predicted label: 5
Correct prediction
Energy consumption = 141.642276 pJ
sum error= 254
Actual label: 4
Output voltages: [0.081319, 0.017829, 0.32413, 0.021288, 0.79879, 0.0019298, 0.014516, 0.21413, 0.016282, 0.71293]
Predicted label: 4
Correct prediction
Energy consumption = 158.635024 pJ
sum error= 254
Actual label: 3
Output voltages: [0.089268, 0.021042, 0.041069, 0.79866, 0.024339, 0.034113, 0.011586, 0.064212, 0.69726, 0.075461]
Predicted label: 3
Correct prediction
Energy consumption = 145.749601 pJ
sum error= 254
Actual label: 8
Output voltages: [0.038378, 0.034392, 0.32623, 0.024861, 0.032567, 0.0098482, 0.026869, 0.0028224, 0.79875, 0.20851]
Predicted label: 8
Correct prediction
Energy consumption = 146.053164 pJ
sum error= 254
Actual label: 4
Output voltages: [0.017407, 0.036145, 0.038938, 0.0056763, 0.7986, 0.0021293, 0.3847, 0.18145, 0.058699, 0.16259]
Predicted label: 4
Correct prediction
Energy consumption = 144.101332 pJ
sum error= 254
Actual label: 6
Output voltages: [0.18061, 0.14977, 0.1964, 0.025611, 0.036107, 0.39578, 0.79876, 0.0021134, 0.47537, 0.11143]
Predicted label: 6
Correct prediction
Energy consumption = 152.150453 pJ
sum error= 254
Actual label: 6
Output voltages: [0.21641, 0.06221, 0.064452, 0.0090053, 0.075629, 0.31754, 0.79872, 0.0049179, 0.40336, 0.0079237]
Predicted label: 6
Correct prediction
Energy consumption = 143.659242 pJ
sum error= 254
Actual label: 2
Output voltages: [0.12973, 0.07482, 0.79872, 0.034701, 0.0034931, 0.0011162, 0.069355, 0.064383, 0.58068, 0.019826]
Predicted label: 2
Correct prediction
Energy consumption = 151.992069 pJ
sum error= 254
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 490 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 490 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 490 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.11066, 0.44471, 0.39942, 0.039761, 0.0023585, 0.0011078, 0.0049603, 0.79846, 0.18281, 0.20644]
Predicted label: 7
Correct prediction
Energy consumption = 149.522735 pJ
sum error= 254
Actual label: 9
Output voltages: [0.18455, 0.017913, 0.021505, 0.015726, 0.065658, 0.025038, 0.0062, 0.018476, 0.44316, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 142.294945 pJ
sum error= 254
Actual label: 5
Output voltages: [0.029165, 0.0017897, 0.0011198, 0.48937, 0.012832, 0.79662, 0.017611, 0.0019057, 0.64109, 0.09296]
Predicted label: 5
Correct prediction
Energy consumption = 143.198189 pJ
sum error= 254
Actual label: 1
Output voltages: [0.044729, 0.79838, 0.26155, 0.18617, 0.018175, 0.0011796, 0.73454, 0.0016082, 0.039292, 0.27659]
Predicted label: 1
Correct prediction
Energy consumption = 163.221874 pJ
sum error= 254
Actual label: 3
Output voltages: [0.25187, 0.016828, 0.14781, 0.79877, 0.015482, 0.0016406, 0.0040094, 0.0029234, 0.53671, 0.045838]
Predicted label: 3
Correct prediction
Energy consumption = 150.257450 pJ
sum error= 254
Actual label: 2
Output voltages: [0.40615, 0.15297, 0.79874, 0.10122, 0.017699, 0.0013154, 0.21784, 0.026399, 0.40949, 0.057768]
Predicted label: 2
Correct prediction
Energy consumption = 138.376808 pJ
sum error= 254
Actual label: 4
Output voltages: [0.0052804, 0.026832, 0.099015, 0.013486, 0.79876, 0.00139, 0.3104, 0.15483, 0.034606, 0.034313]
Predicted label: 4
Correct prediction
Energy consumption = 158.491140 pJ
sum error= 254
Actual label: 3
Output voltages: [0.20917, 0.18246, 0.047664, 0.79873, 0.0011769, 0.008117, 0.0021989, 0.27297, 0.088962, 0.24829]
Predicted label: 3
Correct prediction
Energy consumption = 151.698661 pJ
sum error= 254
Actual label: 6
Output voltages: [0.17487, 0.17696, 0.0414, 0.015707, 0.29493, 0.44571, 0.79877, 0.0030077, 0.57663, 0.0085822]
Predicted label: 6
Correct prediction
Energy consumption = 151.864244 pJ
sum error= 254
Actual label: 1
Output voltages: [0.019772, 0.79861, 0.016674, 0.049566, 0.42771, 0.011878, 0.70801, 0.0011019, 0.0051102, 0.16326]
Predicted label: 1
Correct prediction
Energy consumption = 159.310344 pJ
sum error= 254
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 491 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 491 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 491 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.21826, 0.013799, 0.058711, 0.029371, 0.17559, 0.037452, 0.050326, 0.084544, 0.46547, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.490256 pJ
sum error= 254
Actual label: 4
Output voltages: [0.27472, 0.034039, 0.14831, 0.017602, 0.77034, 0.0012365, 0.034548, 0.0012011, 0.1861, 0.79598]
Predicted label: 9
Wrong prediction!
Energy consumption = 146.863109 pJ
sum error= 255
Actual label: 4
Output voltages: [0.0058291, 0.008113, 0.064628, 0.0034913, 0.79862, 0.0015592, 0.11422, 0.082486, 0.081664, 0.024373]
Predicted label: 4
Correct prediction
Energy consumption = 153.777503 pJ
sum error= 255
Actual label: 7
Output voltages: [0.12628, 0.026848, 0.030764, 0.042514, 0.012111, 0.001932, 0.0018212, 0.79875, 0.055049, 0.32381]
Predicted label: 7
Correct prediction
Energy consumption = 155.739328 pJ
sum error= 255
Actual label: 6
Output voltages: [0.028722, 0.034196, 0.30154, 0.0026982, 0.040619, 0.070372, 0.79877, 0.0016641, 0.64681, 0.010543]
Predicted label: 6
Correct prediction
Energy consumption = 148.076990 pJ
sum error= 255
Actual label: 5
Output voltages: [0.033028, 0.0011379, 0.0044909, 0.17071, 0.018429, 0.7884, 0.056264, 0.019319, 0.78089, 0.077858]
Predicted label: 5
Correct prediction
Energy consumption = 143.782530 pJ
sum error= 255
Actual label: 4
Output voltages: [0.0022423, 0.018465, 0.24199, 0.0096689, 0.79868, 0.0056037, 0.20987, 0.088299, 0.043817, 0.033835]
Predicted label: 4
Correct prediction
Energy consumption = 155.381380 pJ
sum error= 255
Actual label: 1
Output voltages: [0.014542, 0.79855, 0.20965, 0.0076047, 0.0022878, 0.0032762, 0.45687, 0.0019056, 0.43448, 0.017127]
Predicted label: 1
Correct prediction
Energy consumption = 161.574417 pJ
sum error= 255
Actual label: 9
Output voltages: [0.55583, 0.0024293, 0.038189, 0.016488, 0.13666, 0.0031015, 0.022666, 0.043991, 0.38726, 0.79086]
Predicted label: 9
Correct prediction
Energy consumption = 157.645282 pJ
sum error= 255
Actual label: 9
Output voltages: [0.29023, 0.0066464, 0.05178, 0.029536, 0.11107, 0.0073346, 0.01435, 0.040287, 0.30172, 0.79844]
Predicted label: 9
Correct prediction
Energy consumption = 147.130406 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 492 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 492 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 492 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.477, 0.0068088, 0.79851, 0.21578, 0.021318, 0.0011988, 0.0398, 0.14838, 0.48054, 0.014566]
Predicted label: 2
Correct prediction
Energy consumption = 149.753058 pJ
sum error= 255
Actual label: 7
Output voltages: [0.38677, 0.36214, 0.40983, 0.1973, 0.023444, 0.0010812, 0.0010694, 0.79879, 0.0241, 0.2757]
Predicted label: 7
Correct prediction
Energy consumption = 147.026430 pJ
sum error= 255
Actual label: 8
Output voltages: [0.052192, 0.027974, 0.17939, 0.46733, 0.0011968, 0.054468, 0.019356, 0.0079372, 0.79876, 0.43623]
Predicted label: 8
Correct prediction
Energy consumption = 154.946450 pJ
sum error= 255
Actual label: 0
Output voltages: [0.79864, 0.010777, 0.051357, 0.01681, 0.010339, 0.01043, 0.64435, 0.0079915, 0.1755, 0.035827]
Predicted label: 0
Correct prediction
Energy consumption = 143.605949 pJ
sum error= 255
Actual label: 1
Output voltages: [0.13416, 0.79861, 0.74942, 0.028096, 0.012294, 0.0011163, 0.28991, 0.00398, 0.019019, 0.057769]
Predicted label: 1
Correct prediction
Energy consumption = 159.221842 pJ
sum error= 255
Actual label: 3
Output voltages: [0.54375, 0.015381, 0.036455, 0.79873, 0.031687, 0.019152, 0.024637, 0.043553, 0.16341, 0.0048008]
Predicted label: 3
Correct prediction
Energy consumption = 150.835958 pJ
sum error= 255
Actual label: 6
Output voltages: [0.27476, 0.035633, 0.045603, 0.010546, 0.48514, 0.11698, 0.79875, 0.0012833, 0.52607, 0.018754]
Predicted label: 6
Correct prediction
Energy consumption = 145.920321 pJ
sum error= 255
Actual label: 1
Output voltages: [0.071408, 0.79865, 0.34736, 0.14194, 0.056087, 0.0010781, 0.347, 0.0010676, 0.19101, 0.15473]
Predicted label: 1
Correct prediction
Energy consumption = 161.451001 pJ
sum error= 255
Actual label: 3
Output voltages: [0.32831, 0.09291, 0.02339, 0.79863, 0.0018926, 0.0037406, 0.0027155, 0.44256, 0.53874, 0.034086]
Predicted label: 3
Correct prediction
Energy consumption = 150.277582 pJ
sum error= 255
Actual label: 4
Output voltages: [0.023272, 0.0076349, 0.30471, 0.0047526, 0.79868, 0.0010776, 0.13657, 0.014477, 0.014029, 0.02559]
Predicted label: 4
Correct prediction
Energy consumption = 153.820719 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 493 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 493 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 493 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.025803, 0.79859, 0.068453, 0.065909, 0.018127, 0.0099434, 0.42158, 0.0010887, 0.019465, 0.030398]
Predicted label: 1
Correct prediction
Energy consumption = 159.410429 pJ
sum error= 255
Actual label: 1
Output voltages: [0.03539, 0.79858, 0.34357, 0.059021, 0.34701, 0.0033497, 0.60487, 0.0011258, 0.063414, 0.2664]
Predicted label: 1
Correct prediction
Energy consumption = 155.119176 pJ
sum error= 255
Actual label: 1
Output voltages: [0.25376, 0.79868, 0.0050802, 0.038328, 0.1718, 0.016825, 0.6806, 0.0098753, 0.020667, 0.023456]
Predicted label: 1
Correct prediction
Energy consumption = 150.247375 pJ
sum error= 255
Actual label: 5
Output voltages: [0.023331, 0.003618, 0.013673, 0.48575, 0.015242, 0.79871, 0.53359, 0.041754, 0.5443, 0.028326]
Predicted label: 5
Correct prediction
Energy consumption = 151.805078 pJ
sum error= 255
Actual label: 6
Output voltages: [0.59254, 0.019084, 0.036672, 0.0060472, 0.28759, 0.74807, 0.79872, 0.0010663, 0.21164, 0.044015]
Predicted label: 6
Correct prediction
Energy consumption = 146.798271 pJ
sum error= 255
Actual label: 0
Output voltages: [0.79877, 0.091374, 0.031966, 0.027189, 0.039113, 0.010635, 0.76725, 0.017058, 0.26158, 0.045323]
Predicted label: 0
Correct prediction
Energy consumption = 152.023463 pJ
sum error= 255
Actual label: 7
Output voltages: [0.085233, 0.2089, 0.58462, 0.013738, 0.0073472, 0.0011981, 0.0010677, 0.79869, 0.36323, 0.48027]
Predicted label: 7
Correct prediction
Energy consumption = 149.652722 pJ
sum error= 255
Actual label: 0
Output voltages: [0.79879, 0.11173, 0.59199, 0.019758, 0.0010683, 0.002954, 0.14608, 0.028315, 0.19216, 0.020754]
Predicted label: 0
Correct prediction
Energy consumption = 150.782677 pJ
sum error= 255
Actual label: 7
Output voltages: [0.24122, 0.22905, 0.027212, 0.65206, 0.0011304, 0.0010665, 0.0010713, 0.79876, 0.044839, 0.060846]
Predicted label: 7
Correct prediction
Energy consumption = 157.059570 pJ
sum error= 255
Actual label: 2
Output voltages: [0.26341, 0.28026, 0.7971, 0.25974, 0.0012996, 0.0013846, 0.0158, 0.3662, 0.53002, 0.0021596]
Predicted label: 2
Correct prediction
Energy consumption = 151.672559 pJ
sum error= 255
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 494 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 494 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 494 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23541, 0.011965, 0.11972, 0.79878, 0.012376, 0.014279, 0.045927, 0.023502, 0.55888, 0.015135]
Predicted label: 3
Correct prediction
Energy consumption = 147.266816 pJ
sum error= 255
Actual label: 2
Output voltages: [0.75048, 0.0021443, 0.79729, 0.46916, 0.0039493, 0.0010873, 0.12587, 0.12218, 0.66619, 0.0026767]
Predicted label: 2
Correct prediction
Energy consumption = 139.741608 pJ
sum error= 255
Actual label: 5
Output voltages: [0.020763, 0.0013494, 0.0017113, 0.75151, 0.054933, 0.79668, 0.038606, 0.052856, 0.51701, 0.26903]
Predicted label: 5
Correct prediction
Energy consumption = 145.045250 pJ
sum error= 255
Actual label: 2
Output voltages: [0.27319, 0.0035724, 0.7952, 0.38576, 0.010669, 0.001099, 0.021186, 0.7093, 0.7982, 0.0068062]
Predicted label: 8
Wrong prediction!
Energy consumption = 142.410907 pJ
sum error= 256
Actual label: 2
Output voltages: [0.54145, 0.014186, 0.79861, 0.45714, 0.01144, 0.0010717, 0.40737, 0.12373, 0.59842, 0.008756]
Predicted label: 2
Correct prediction
Energy consumption = 138.222472 pJ
sum error= 256
Actual label: 9
Output voltages: [0.41512, 0.015253, 0.03533, 0.037139, 0.044696, 0.030908, 0.0085072, 0.14291, 0.2561, 0.79817]
Predicted label: 9
Correct prediction
Energy consumption = 159.139463 pJ
sum error= 256
Actual label: 4
Output voltages: [0.0072367, 0.0039857, 0.12492, 0.066389, 0.79873, 0.0010714, 0.011063, 0.011202, 0.14961, 0.038074]
Predicted label: 4
Correct prediction
Energy consumption = 143.901316 pJ
sum error= 256
Actual label: 9
Output voltages: [0.11999, 0.021376, 0.015512, 0.03975, 0.11425, 0.005432, 0.02219, 0.018753, 0.34953, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 150.450958 pJ
sum error= 256
Actual label: 8
Output voltages: [0.0079241, 0.037147, 0.047625, 0.22786, 0.013225, 0.0037627, 0.030158, 0.012767, 0.79876, 0.04817]
Predicted label: 8
Correct prediction
Energy consumption = 154.425933 pJ
sum error= 256
Actual label: 1
Output voltages: [0.016887, 0.79853, 0.021869, 0.29372, 0.050169, 0.026723, 0.6079, 0.0016997, 0.027515, 0.2096]
Predicted label: 1
Correct prediction
Energy consumption = 166.860202 pJ
sum error= 256
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 495 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 495 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 495 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.61514, 0.018176, 0.79852, 0.45769, 0.0085173, 0.0011309, 0.19346, 0.042322, 0.74658, 0.032517]
Predicted label: 2
Correct prediction
Energy consumption = 158.272104 pJ
sum error= 256
Actual label: 1
Output voltages: [0.024929, 0.79532, 0.36792, 0.039182, 0.59679, 0.0011581, 0.023144, 0.19047, 0.031028, 0.012258]
Predicted label: 1
Correct prediction
Energy consumption = 150.982497 pJ
sum error= 256
Actual label: 6
Output voltages: [0.16677, 0.0022367, 0.0075168, 0.015228, 0.088403, 0.77469, 0.79049, 0.0011666, 0.73082, 0.0062033]
Predicted label: 6
Correct prediction
Energy consumption = 152.868308 pJ
sum error= 256
Actual label: 1
Output voltages: [0.018819, 0.79837, 0.049649, 0.1936, 0.0098909, 0.0065953, 0.63978, 0.016755, 0.36404, 0.25616]
Predicted label: 1
Correct prediction
Energy consumption = 161.952607 pJ
sum error= 256
Actual label: 2
Output voltages: [0.33735, 0.099141, 0.79879, 0.13555, 0.0096159, 0.0012614, 0.22535, 0.0087436, 0.59654, 0.034435]
Predicted label: 2
Correct prediction
Energy consumption = 150.943308 pJ
sum error= 256
Actual label: 7
Output voltages: [0.42257, 0.18605, 0.012666, 0.094448, 0.025493, 0.013246, 0.0011753, 0.79868, 0.32544, 0.61544]
Predicted label: 7
Correct prediction
Energy consumption = 157.360341 pJ
sum error= 256
Actual label: 8
Output voltages: [0.039399, 0.0045703, 0.042782, 0.044643, 0.78224, 0.027836, 0.082232, 0.0069097, 0.76339, 0.066527]
Predicted label: 4
Wrong prediction!
Energy consumption = 152.523844 pJ
sum error= 257
Actual label: 0
Output voltages: [0.79878, 0.062743, 0.012121, 0.014209, 0.0059281, 0.006408, 0.59239, 0.017256, 0.14137, 0.052487]
Predicted label: 0
Correct prediction
Energy consumption = 146.131225 pJ
sum error= 257
Actual label: 0
Output voltages: [0.79859, 0.060836, 0.065293, 0.012869, 0.0080742, 0.0014277, 0.74536, 0.022341, 0.15733, 0.13325]
Predicted label: 0
Correct prediction
Energy consumption = 141.558380 pJ
sum error= 257
Actual label: 0
Output voltages: [0.79875, 0.045011, 0.088304, 0.027664, 0.034271, 0.060334, 0.20707, 0.04483, 0.31088, 0.32137]
Predicted label: 0
Correct prediction
Energy consumption = 154.122549 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 496 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 496 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 496 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.10696, 0.0011817, 0.015697, 0.049963, 0.029552, 0.20912, 0.052885, 0.0060572, 0.79876, 0.001392]
Predicted label: 8
Correct prediction
Energy consumption = 154.145585 pJ
sum error= 257
Actual label: 2
Output voltages: [0.56199, 0.25246, 0.79874, 0.083271, 0.012924, 0.0012231, 0.38574, 0.035272, 0.67889, 0.10106]
Predicted label: 2
Correct prediction
Energy consumption = 146.750509 pJ
sum error= 257
Actual label: 2
Output voltages: [0.5288, 0.21116, 0.78595, 0.27632, 0.026666, 0.001374, 0.52115, 0.031413, 0.40944, 0.010804]
Predicted label: 2
Correct prediction
Energy consumption = 135.136049 pJ
sum error= 257
Actual label: 9
Output voltages: [0.27766, 0.0031426, 0.017132, 0.2217, 0.1054, 0.019973, 0.0011473, 0.028989, 0.51062, 0.79608]
Predicted label: 9
Correct prediction
Energy consumption = 150.810489 pJ
sum error= 257
Actual label: 2
Output voltages: [0.44582, 0.21351, 0.79791, 0.62284, 0.023875, 0.0011046, 0.050253, 0.0037086, 0.60114, 0.12489]
Predicted label: 2
Correct prediction
Energy consumption = 154.284368 pJ
sum error= 257
Actual label: 2
Output voltages: [0.37644, 0.08141, 0.79877, 0.26408, 0.020313, 0.0012219, 0.49135, 0.023418, 0.54645, 0.05285]
Predicted label: 2
Correct prediction
Energy consumption = 141.827581 pJ
sum error= 257
Actual label: 7
Output voltages: [0.009653, 0.062947, 0.013704, 0.53969, 0.0034106, 0.0017549, 0.0010665, 0.78499, 0.77543, 0.43156]
Predicted label: 7
Correct prediction
Energy consumption = 140.260155 pJ
sum error= 257
Actual label: 9
Output voltages: [0.23714, 0.034469, 0.038397, 0.092774, 0.042729, 0.0093966, 0.16431, 0.02211, 0.12583, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 143.929504 pJ
sum error= 257
Actual label: 9
Output voltages: [0.46972, 0.0016433, 0.31152, 0.026853, 0.22497, 0.012636, 0.15303, 0.0051657, 0.20984, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 137.033709 pJ
sum error= 257
Actual label: 2
Output voltages: [0.46663, 0.093631, 0.79876, 0.053587, 0.0068028, 0.0013191, 0.10768, 0.14571, 0.44415, 0.24094]
Predicted label: 2
Correct prediction
Energy consumption = 153.562470 pJ
sum error= 257
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 497 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 497 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 497 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.040832, 0.15737, 0.16067, 0.056847, 0.0042817, 0.0011159, 0.0015248, 0.79878, 0.050128, 0.44081]
Predicted label: 7
Correct prediction
Energy consumption = 157.272461 pJ
sum error= 257
Actual label: 5
Output voltages: [0.0028629, 0.0010688, 0.0058001, 0.78523, 0.086481, 0.76628, 0.027698, 0.13103, 0.40041, 0.044123]
Predicted label: 3
Wrong prediction!
Energy consumption = 151.029072 pJ
sum error= 258
Actual label: 1
Output voltages: [0.019525, 0.7986, 0.0034651, 0.0091224, 0.34667, 0.030165, 0.49208, 0.0074419, 0.052285, 0.10684]
Predicted label: 1
Correct prediction
Energy consumption = 163.841272 pJ
sum error= 258
Actual label: 3
Output voltages: [0.34328, 0.035858, 0.092837, 0.79869, 0.0076076, 0.0091195, 0.0069874, 0.014317, 0.67653, 0.021817]
Predicted label: 3
Correct prediction
Energy consumption = 150.867643 pJ
sum error= 258
Actual label: 4
Output voltages: [0.020467, 0.0023418, 0.55196, 0.022651, 0.79869, 0.0010742, 0.19851, 0.07048, 0.010937, 0.026299]
Predicted label: 4
Correct prediction
Energy consumption = 147.555087 pJ
sum error= 258
Actual label: 9
Output voltages: [0.37875, 0.014585, 0.014531, 0.25433, 0.3744, 0.017552, 0.049967, 0.036643, 0.12416, 0.79714]
Predicted label: 9
Correct prediction
Energy consumption = 146.439246 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0097587, 0.011992, 0.13709, 0.02249, 0.79867, 0.0014409, 0.066501, 0.18317, 0.017566, 0.056439]
Predicted label: 4
Correct prediction
Energy consumption = 152.296930 pJ
sum error= 258
Actual label: 1
Output voltages: [0.1183, 0.79843, 0.11012, 0.20984, 0.0091608, 0.0015544, 0.64166, 0.0011061, 0.045857, 0.12188]
Predicted label: 1
Correct prediction
Energy consumption = 166.120688 pJ
sum error= 258
Actual label: 8
Output voltages: [0.018051, 0.38412, 0.18212, 0.035749, 0.013819, 0.0010714, 0.0026247, 0.016008, 0.79866, 0.48467]
Predicted label: 8
Correct prediction
Energy consumption = 150.595331 pJ
sum error= 258
Actual label: 5
Output voltages: [0.050131, 0.0013831, 0.0020899, 0.57655, 0.034144, 0.79873, 0.060309, 0.042554, 0.7593, 0.19922]
Predicted label: 5
Correct prediction
Energy consumption = 139.486114 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 498 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 498 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 498 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.27814, 0.040759, 0.26067, 0.0023141, 0.23205, 0.22601, 0.79876, 0.0053183, 0.44899, 0.0046357]
Predicted label: 6
Correct prediction
Energy consumption = 154.942815 pJ
sum error= 258
Actual label: 2
Output voltages: [0.32367, 0.031121, 0.79879, 0.12206, 0.03195, 0.0011967, 0.23174, 0.011696, 0.67716, 0.025977]
Predicted label: 2
Correct prediction
Energy consumption = 147.666387 pJ
sum error= 258
Actual label: 8
Output voltages: [0.43481, 0.0092866, 0.74538, 0.035707, 0.0089812, 0.0028176, 0.013801, 0.0025419, 0.79828, 0.51398]
Predicted label: 8
Correct prediction
Energy consumption = 145.414597 pJ
sum error= 258
Actual label: 3
Output voltages: [0.54973, 0.0059486, 0.24907, 0.79877, 0.025153, 0.025834, 0.001949, 0.029482, 0.6867, 0.03869]
Predicted label: 3
Correct prediction
Energy consumption = 145.447299 pJ
sum error= 258
Actual label: 1
Output voltages: [0.043396, 0.79852, 0.023109, 0.037597, 0.17821, 0.021683, 0.37279, 0.0020629, 0.007321, 0.47378]
Predicted label: 1
Correct prediction
Energy consumption = 161.219600 pJ
sum error= 258
Actual label: 2
Output voltages: [0.12783, 0.073607, 0.79875, 0.55906, 0.12936, 0.001154, 0.052226, 0.094842, 0.015652, 0.010764]
Predicted label: 2
Correct prediction
Energy consumption = 140.524194 pJ
sum error= 258
Actual label: 8
Output voltages: [0.021779, 0.014224, 0.12141, 0.07003, 0.018428, 0.02598, 0.15355, 0.0016219, 0.79879, 0.22839]
Predicted label: 8
Correct prediction
Energy consumption = 149.793507 pJ
sum error= 258
Actual label: 4
Output voltages: [0.011936, 0.015669, 0.017169, 0.0068533, 0.79875, 0.0010795, 0.39215, 0.094254, 0.0088248, 0.0055556]
Predicted label: 4
Correct prediction
Energy consumption = 148.841330 pJ
sum error= 258
Actual label: 9
Output voltages: [0.28505, 0.0077941, 0.032516, 0.016448, 0.077463, 0.012936, 0.0045758, 0.028606, 0.71688, 0.79687]
Predicted label: 9
Correct prediction
Energy consumption = 154.085031 pJ
sum error= 258
Actual label: 9
Output voltages: [0.38861, 0.0011823, 0.026796, 0.0046387, 0.10821, 0.016141, 0.0020088, 0.371, 0.65787, 0.79451]
Predicted label: 9
Correct prediction
Energy consumption = 144.124214 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 499 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 499 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 499 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.097906, 0.040839, 0.42606, 0.79875, 0.01123, 0.001311, 0.021832, 0.0013915, 0.74896, 0.13312]
Predicted label: 3
Correct prediction
Energy consumption = 149.865202 pJ
sum error= 258
Actual label: 7
Output voltages: [0.21811, 0.043892, 0.041039, 0.19305, 0.0027529, 0.0092022, 0.0012708, 0.79879, 0.31503, 0.49882]
Predicted label: 7
Correct prediction
Energy consumption = 155.228912 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79793, 0.029631, 0.042208, 0.0014903, 0.0076602, 0.0256, 0.62076, 0.0068628, 0.033511, 0.21882]
Predicted label: 0
Correct prediction
Energy consumption = 153.369747 pJ
sum error= 258
Actual label: 7
Output voltages: [0.02185, 0.051338, 0.016957, 0.052071, 0.0086398, 0.0051408, 0.0011073, 0.79879, 0.12693, 0.34281]
Predicted label: 7
Correct prediction
Energy consumption = 152.157522 pJ
sum error= 258
Actual label: 7
Output voltages: [0.0233, 0.14512, 0.05142, 0.0038437, 0.016638, 0.0012382, 0.0011459, 0.79878, 0.11598, 0.39533]
Predicted label: 7
Correct prediction
Energy consumption = 144.030761 pJ
sum error= 258
Actual label: 2
Output voltages: [0.46134, 0.64945, 0.78214, 0.19215, 0.0013371, 0.0012401, 0.3493, 0.0064784, 0.17855, 0.0049503]
Predicted label: 2
Correct prediction
Energy consumption = 153.166279 pJ
sum error= 258
Actual label: 3
Output voltages: [0.41384, 0.0018299, 0.025117, 0.79878, 0.026195, 0.16071, 0.030998, 0.010519, 0.69963, 0.018231]
Predicted label: 3
Correct prediction
Energy consumption = 147.026924 pJ
sum error= 258
Actual label: 2
Output voltages: [0.72931, 0.001906, 0.79606, 0.37745, 0.036441, 0.0010817, 0.074962, 0.031695, 0.75608, 0.021266]
Predicted label: 2
Correct prediction
Energy consumption = 142.331917 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0042505, 0.012731, 0.017533, 0.0086049, 0.79872, 0.001066, 0.032923, 0.056763, 0.055254, 0.039145]
Predicted label: 4
Correct prediction
Energy consumption = 157.289175 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79869, 0.18476, 0.076508, 0.017833, 0.0072888, 0.042911, 0.3479, 0.021002, 0.029077, 0.042374]
Predicted label: 0
Correct prediction
Energy consumption = 156.309939 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 500 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 500 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 500 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.28204, 0.012753, 0.53236, 0.79879, 0.058159, 0.022727, 0.01642, 0.002074, 0.72057, 0.0071958]
Predicted label: 3
Correct prediction
Energy consumption = 144.369039 pJ
sum error= 258
Actual label: 9
Output voltages: [0.035941, 0.0068843, 0.068672, 0.050086, 0.071893, 0.034409, 0.0092564, 0.038967, 0.62009, 0.79206]
Predicted label: 9
Correct prediction
Energy consumption = 152.833160 pJ
sum error= 258
Actual label: 9
Output voltages: [0.2688, 0.026737, 0.0097004, 0.1047, 0.34203, 0.0047887, 0.0022636, 0.0031572, 0.18971, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 137.290303 pJ
sum error= 258
Actual label: 8
Output voltages: [0.011565, 0.02379, 0.07559, 0.021984, 0.014485, 0.017439, 0.02834, 0.022391, 0.79875, 0.13074]
Predicted label: 8
Correct prediction
Energy consumption = 139.644977 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0013289, 0.0034385, 0.099652, 0.0030006, 0.79866, 0.0014446, 0.26535, 0.076984, 0.098501, 0.017755]
Predicted label: 4
Correct prediction
Energy consumption = 151.944790 pJ
sum error= 258
Actual label: 1
Output voltages: [0.024443, 0.79852, 0.13886, 0.0064715, 0.19949, 0.0052202, 0.32326, 0.032466, 0.039789, 0.025757]
Predicted label: 1
Correct prediction
Energy consumption = 157.115820 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79628, 0.16534, 0.038478, 0.03547, 0.027102, 0.0057372, 0.78903, 0.0084699, 0.15968, 0.048484]
Predicted label: 0
Correct prediction
Energy consumption = 145.001197 pJ
sum error= 258
Actual label: 6
Output voltages: [0.093385, 0.02621, 0.29155, 0.0010703, 0.3848, 0.047592, 0.79879, 0.0032228, 0.25177, 0.002922]
Predicted label: 6
Correct prediction
Energy consumption = 136.774786 pJ
sum error= 258
Actual label: 0
Output voltages: [0.7987, 0.03899, 0.041753, 0.014558, 0.0047744, 0.019784, 0.54405, 0.10767, 0.13701, 0.030446]
Predicted label: 0
Correct prediction
Energy consumption = 136.267126 pJ
sum error= 258
Actual label: 9
Output voltages: [0.23792, 0.012482, 0.014881, 0.028967, 0.4304, 0.028351, 0.01962, 0.012288, 0.089993, 0.79449]
Predicted label: 9
Correct prediction
Energy consumption = 144.477550 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 501 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 501 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 501 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.099416, 0.037971, 0.29646, 0.0028111, 0.32925, 0.043044, 0.79879, 0.0015704, 0.31949, 0.002329]
Predicted label: 6
Correct prediction
Energy consumption = 149.978225 pJ
sum error= 258
Actual label: 8
Output voltages: [0.017832, 0.028418, 0.032643, 0.29258, 0.0020859, 0.30141, 0.0026783, 0.017754, 0.79874, 0.022429]
Predicted label: 8
Correct prediction
Energy consumption = 146.402339 pJ
sum error= 258
Actual label: 6
Output voltages: [0.048355, 0.1359, 0.42819, 0.0012892, 0.19179, 0.14477, 0.79875, 0.003726, 0.27947, 0.0022181]
Predicted label: 6
Correct prediction
Energy consumption = 150.442188 pJ
sum error= 258
Actual label: 1
Output voltages: [0.0058223, 0.79876, 0.09748, 0.043178, 0.019377, 0.0011578, 0.59799, 0.0029296, 0.14311, 0.0080826]
Predicted label: 1
Correct prediction
Energy consumption = 156.687862 pJ
sum error= 258
Actual label: 1
Output voltages: [0.0010668, 0.79866, 0.0085426, 0.022021, 0.17671, 0.0037701, 0.47171, 0.0032179, 0.56986, 0.057691]
Predicted label: 1
Correct prediction
Energy consumption = 152.443833 pJ
sum error= 258
Actual label: 9
Output voltages: [0.10128, 0.006325, 0.034766, 0.40315, 0.19079, 0.02452, 0.011853, 0.022874, 0.58161, 0.77069]
Predicted label: 9
Correct prediction
Energy consumption = 152.880806 pJ
sum error= 258
Actual label: 8
Output voltages: [0.018901, 0.031442, 0.21069, 0.17184, 0.010018, 0.12777, 0.026823, 0.0024952, 0.79879, 0.29537]
Predicted label: 8
Correct prediction
Energy consumption = 141.161855 pJ
sum error= 258
Actual label: 9
Output voltages: [0.092488, 0.032339, 0.019437, 0.3881, 0.070085, 0.037607, 0.086911, 0.07063, 0.058213, 0.79834]
Predicted label: 9
Correct prediction
Energy consumption = 149.270948 pJ
sum error= 258
Actual label: 2
Output voltages: [0.48849, 0.0054542, 0.79874, 0.050224, 0.028092, 0.0010659, 0.032997, 0.068894, 0.44102, 0.0036323]
Predicted label: 2
Correct prediction
Energy consumption = 145.107764 pJ
sum error= 258
Actual label: 3
Output voltages: [0.26667, 0.037179, 0.36278, 0.79877, 0.016925, 0.022154, 0.0041824, 0.025694, 0.75395, 0.020793]
Predicted label: 3
Correct prediction
Energy consumption = 145.145889 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 502 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 502 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 502 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.031956, 0.0012051, 0.0011079, 0.5153, 0.041325, 0.79876, 0.25455, 0.025107, 0.70272, 0.17314]
Predicted label: 5
Correct prediction
Energy consumption = 154.044781 pJ
sum error= 258
Actual label: 5
Output voltages: [0.20605, 0.0010974, 0.0010778, 0.4175, 0.027914, 0.79866, 0.090883, 0.02767, 0.60205, 0.042715]
Predicted label: 5
Correct prediction
Energy consumption = 133.865378 pJ
sum error= 258
Actual label: 9
Output voltages: [0.088026, 0.017812, 0.025555, 0.029779, 0.059709, 0.049181, 0.02162, 0.034761, 0.532, 0.79841]
Predicted label: 9
Correct prediction
Energy consumption = 146.167378 pJ
sum error= 258
Actual label: 4
Output voltages: [0.005963, 0.0087167, 0.020406, 0.017358, 0.7987, 0.0012854, 0.28911, 0.13047, 0.072146, 0.0069506]
Predicted label: 4
Correct prediction
Energy consumption = 147.894518 pJ
sum error= 258
Actual label: 2
Output voltages: [0.58332, 0.08319, 0.79872, 0.37416, 0.017785, 0.001205, 0.12933, 0.042586, 0.4374, 0.034581]
Predicted label: 2
Correct prediction
Energy consumption = 151.184477 pJ
sum error= 258
Actual label: 1
Output voltages: [0.038687, 0.79877, 0.24577, 0.01075, 0.63108, 0.0018432, 0.17026, 0.0024772, 0.033281, 0.029419]
Predicted label: 1
Correct prediction
Energy consumption = 153.314021 pJ
sum error= 258
Actual label: 9
Output voltages: [0.31906, 0.01137, 0.013274, 0.15729, 0.33822, 0.0085, 0.0012156, 0.0098836, 0.4006, 0.79745]
Predicted label: 9
Correct prediction
Energy consumption = 153.733076 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0031641, 0.0018277, 0.028059, 0.029398, 0.79878, 0.0010861, 0.038189, 0.05197, 0.15981, 0.008413]
Predicted label: 4
Correct prediction
Energy consumption = 148.202892 pJ
sum error= 258
Actual label: 3
Output voltages: [0.21469, 0.028246, 0.04117, 0.79856, 0.021453, 0.022491, 0.012686, 0.028974, 0.58836, 0.073968]
Predicted label: 3
Correct prediction
Energy consumption = 141.733397 pJ
sum error= 258
Actual label: 9
Output voltages: [0.36588, 0.015535, 0.011038, 0.12382, 0.12236, 0.018246, 0.006172, 0.079072, 0.35637, 0.79854]
Predicted label: 9
Correct prediction
Energy consumption = 147.852412 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 503 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 503 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 503 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.097281, 0.015994, 0.22156, 0.0010735, 0.59863, 0.057781, 0.79872, 0.0014501, 0.59692, 0.013383]
Predicted label: 6
Correct prediction
Energy consumption = 145.855928 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79862, 0.027836, 0.37211, 0.015027, 0.028465, 0.0010756, 0.38968, 0.034862, 0.24587, 0.04162]
Predicted label: 0
Correct prediction
Energy consumption = 141.054498 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0039129, 0.0091864, 0.11364, 0.010842, 0.79854, 0.0033882, 0.054826, 0.046346, 0.056922, 0.024784]
Predicted label: 4
Correct prediction
Energy consumption = 151.312497 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79873, 0.057754, 0.075254, 0.017724, 0.029544, 0.0049275, 0.14731, 0.012818, 0.23551, 0.025729]
Predicted label: 0
Correct prediction
Energy consumption = 149.542045 pJ
sum error= 258
Actual label: 6
Output voltages: [0.050776, 0.064473, 0.05609, 0.005145, 0.18821, 0.35276, 0.79869, 0.0021338, 0.60236, 0.0061254]
Predicted label: 6
Correct prediction
Energy consumption = 146.046265 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79407, 0.03513, 0.032951, 0.0092558, 0.012147, 0.0018106, 0.77675, 0.0075462, 0.31553, 0.036308]
Predicted label: 0
Correct prediction
Energy consumption = 135.647471 pJ
sum error= 258
Actual label: 1
Output voltages: [0.028902, 0.79861, 0.32442, 0.0035208, 0.040194, 0.0032587, 0.60317, 0.0087073, 0.06149, 0.011934]
Predicted label: 1
Correct prediction
Energy consumption = 154.795466 pJ
sum error= 258
Actual label: 2
Output voltages: [0.27887, 0.024664, 0.79879, 0.054455, 0.011516, 0.0011272, 0.037174, 0.26732, 0.72845, 0.0010976]
Predicted label: 2
Correct prediction
Energy consumption = 147.701393 pJ
sum error= 258
Actual label: 3
Output voltages: [0.40308, 0.0012064, 0.27196, 0.79759, 0.013147, 0.30925, 0.0096202, 0.0021723, 0.77756, 0.0073597]
Predicted label: 3
Correct prediction
Energy consumption = 140.495876 pJ
sum error= 258
Actual label: 4
Output voltages: [0.016009, 0.0062653, 0.097885, 0.04025, 0.79868, 0.012751, 0.022371, 0.019239, 0.051927, 0.021614]
Predicted label: 4
Correct prediction
Energy consumption = 149.412805 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 504 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 504 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 504 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.076475, 0.11587, 0.37938, 0.01005, 0.036599, 0.0010659, 0.0011383, 0.79877, 0.052394, 0.50952]
Predicted label: 7
Correct prediction
Energy consumption = 147.599380 pJ
sum error= 258
Actual label: 8
Output voltages: [0.036999, 0.026775, 0.041193, 0.37498, 0.0029357, 0.033378, 0.0057272, 0.0019939, 0.79872, 0.23019]
Predicted label: 8
Correct prediction
Energy consumption = 144.044037 pJ
sum error= 258
Actual label: 9
Output voltages: [0.029791, 0.0055448, 0.013147, 0.34081, 0.016563, 0.0032288, 0.0014063, 0.40495, 0.69175, 0.78647]
Predicted label: 9
Correct prediction
Energy consumption = 144.632708 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79877, 0.097084, 0.025268, 0.013023, 0.0019195, 0.011615, 0.55328, 0.036614, 0.44292, 0.027625]
Predicted label: 0
Correct prediction
Energy consumption = 141.842584 pJ
sum error= 258
Actual label: 1
Output voltages: [0.028699, 0.79865, 0.54913, 0.019412, 0.069343, 0.0012181, 0.72112, 0.0040085, 0.22103, 0.030597]
Predicted label: 1
Correct prediction
Energy consumption = 162.714824 pJ
sum error= 258
Actual label: 2
Output voltages: [0.46029, 0.033789, 0.79878, 0.14206, 0.015531, 0.0013024, 0.14016, 0.08604, 0.39179, 0.034162]
Predicted label: 2
Correct prediction
Energy consumption = 145.406689 pJ
sum error= 258
Actual label: 3
Output voltages: [0.31566, 0.0012028, 0.081631, 0.79879, 0.053153, 0.20663, 0.03602, 0.0082369, 0.51633, 0.0040936]
Predicted label: 3
Correct prediction
Energy consumption = 142.132401 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0037237, 0.0027736, 0.21125, 0.024947, 0.79876, 0.0042529, 0.018837, 0.041661, 0.3619, 0.016877]
Predicted label: 4
Correct prediction
Energy consumption = 144.862637 pJ
sum error= 258
Actual label: 7
Output voltages: [0.017037, 0.23589, 0.57321, 0.032054, 0.0080042, 0.0010786, 0.0010957, 0.79878, 0.33799, 0.17446]
Predicted label: 7
Correct prediction
Energy consumption = 142.537272 pJ
sum error= 258
Actual label: 8
Output voltages: [0.019585, 0.0035591, 0.026267, 0.25264, 0.0017396, 0.25207, 0.025194, 0.0047072, 0.79879, 0.039771]
Predicted label: 8
Correct prediction
Energy consumption = 143.637755 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 505 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 505 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 505 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33071, 0.014047, 0.020427, 0.060726, 0.048976, 0.043388, 0.003249, 0.045789, 0.52474, 0.79823]
Predicted label: 9
Correct prediction
Energy consumption = 152.208368 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79879, 0.023562, 0.014917, 0.0056604, 0.0060299, 0.011001, 0.68289, 0.014683, 0.25621, 0.020007]
Predicted label: 0
Correct prediction
Energy consumption = 141.792327 pJ
sum error= 258
Actual label: 1
Output voltages: [0.0064199, 0.79879, 0.019743, 0.052062, 0.21434, 0.0012283, 0.15289, 0.024115, 0.35141, 0.074314]
Predicted label: 1
Correct prediction
Energy consumption = 161.564798 pJ
sum error= 258
Actual label: 2
Output voltages: [0.166, 0.030364, 0.79877, 0.019586, 0.0053466, 0.001066, 0.098445, 0.015576, 0.76177, 0.022326]
Predicted label: 2
Correct prediction
Energy consumption = 137.059283 pJ
sum error= 258
Actual label: 3
Output voltages: [0.3145, 0.0017079, 0.21536, 0.79879, 0.17665, 0.03641, 0.0034822, 0.0011592, 0.52801, 0.022615]
Predicted label: 3
Correct prediction
Energy consumption = 138.988998 pJ
sum error= 258
Actual label: 4
Output voltages: [0.020804, 0.0019924, 0.10892, 0.02051, 0.79864, 0.0014651, 0.13223, 0.072998, 0.034233, 0.010941]
Predicted label: 4
Correct prediction
Energy consumption = 135.619758 pJ
sum error= 258
Actual label: 5
Output voltages: [0.30963, 0.0012386, 0.0011252, 0.19608, 0.045132, 0.79867, 0.64304, 0.023034, 0.77583, 0.0033136]
Predicted label: 5
Correct prediction
Energy consumption = 139.068326 pJ
sum error= 258
Actual label: 6
Output voltages: [0.11067, 0.31833, 0.22418, 0.0030569, 0.059771, 0.20279, 0.79868, 0.0014122, 0.36394, 0.0098909]
Predicted label: 6
Correct prediction
Energy consumption = 145.618233 pJ
sum error= 258
Actual label: 7
Output voltages: [0.03313, 0.20416, 0.61242, 0.03897, 0.0094868, 0.0010862, 0.0010693, 0.79879, 0.27041, 0.25841]
Predicted label: 7
Correct prediction
Energy consumption = 149.351491 pJ
sum error= 258
Actual label: 8
Output voltages: [0.0032558, 0.034427, 0.11674, 0.085126, 0.0036743, 0.05042, 0.020553, 0.021014, 0.79869, 0.20469]
Predicted label: 8
Correct prediction
Energy consumption = 145.591379 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 506 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 506 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 506 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.27346, 0.014051, 0.019331, 0.029756, 0.041757, 0.12079, 0.011119, 0.077265, 0.63762, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 143.427169 pJ
sum error= 258
Actual label: 8
Output voltages: [0.020014, 0.036625, 0.10745, 0.036823, 0.014809, 0.16695, 0.034491, 0.21781, 0.79855, 0.021896]
Predicted label: 8
Correct prediction
Energy consumption = 149.371189 pJ
sum error= 258
Actual label: 3
Output voltages: [0.044383, 0.039601, 0.060124, 0.79829, 0.0034589, 0.033138, 0.011428, 0.0011819, 0.76738, 0.27045]
Predicted label: 3
Correct prediction
Energy consumption = 143.065671 pJ
sum error= 258
Actual label: 4
Output voltages: [0.015583, 0.041993, 0.034481, 0.0040436, 0.79875, 0.0025733, 0.04404, 0.18645, 0.043947, 0.006033]
Predicted label: 4
Correct prediction
Energy consumption = 150.626256 pJ
sum error= 258
Actual label: 7
Output voltages: [0.081886, 0.13079, 0.67769, 0.02177, 0.0043549, 0.0011941, 0.0012411, 0.79878, 0.26831, 0.053085]
Predicted label: 7
Correct prediction
Energy consumption = 147.008742 pJ
sum error= 258
Actual label: 8
Output voltages: [0.06623, 0.0026437, 0.036728, 0.053041, 0.01341, 0.068631, 0.2493, 0.001066, 0.79875, 0.15475]
Predicted label: 8
Correct prediction
Energy consumption = 155.483135 pJ
sum error= 258
Actual label: 6
Output voltages: [0.28099, 0.010539, 0.022504, 0.018851, 0.17508, 0.2933, 0.79877, 0.0011493, 0.3726, 0.0093479]
Predicted label: 6
Correct prediction
Energy consumption = 143.814730 pJ
sum error= 258
Actual label: 3
Output voltages: [0.30394, 0.0010696, 0.64289, 0.78724, 0.010256, 0.0011425, 0.017012, 0.01754, 0.77043, 0.024342]
Predicted label: 3
Correct prediction
Energy consumption = 144.696807 pJ
sum error= 258
Actual label: 4
Output voltages: [0.035428, 0.29458, 0.0060221, 0.28074, 0.79831, 0.0010988, 0.075843, 0.032851, 0.084937, 0.21876]
Predicted label: 4
Correct prediction
Energy consumption = 150.276499 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79873, 0.1668, 0.046529, 0.024571, 0.0037827, 0.0020708, 0.62018, 0.031904, 0.2349, 0.020786]
Predicted label: 0
Correct prediction
Energy consumption = 145.054340 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 507 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 507 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 507 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.43534, 0.028951, 0.011282, 0.14989, 0.58334, 0.044834, 0.035564, 0.0057845, 0.038954, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 152.151156 pJ
sum error= 258
Actual label: 7
Output voltages: [0.11798, 0.016559, 0.027477, 0.042579, 0.018243, 0.0032493, 0.0010722, 0.79856, 0.053344, 0.23624]
Predicted label: 7
Correct prediction
Energy consumption = 147.214962 pJ
sum error= 258
Actual label: 1
Output voltages: [0.037434, 0.79877, 0.2861, 0.029222, 0.41029, 0.0010932, 0.037322, 0.0087052, 0.015303, 0.038459]
Predicted label: 1
Correct prediction
Energy consumption = 154.805064 pJ
sum error= 258
Actual label: 9
Output voltages: [0.1033, 0.014341, 0.026719, 0.34474, 0.16095, 0.010173, 0.0010765, 0.029237, 0.51293, 0.79765]
Predicted label: 9
Correct prediction
Energy consumption = 150.165517 pJ
sum error= 258
Actual label: 3
Output voltages: [0.056779, 0.00397, 0.027344, 0.79879, 0.17212, 0.45538, 0.020867, 0.0092016, 0.77245, 0.048401]
Predicted label: 3
Correct prediction
Energy consumption = 143.747315 pJ
sum error= 258
Actual label: 8
Output voltages: [0.012233, 0.034471, 0.24995, 0.083115, 0.0072749, 0.068257, 0.012599, 0.028894, 0.79873, 0.072455]
Predicted label: 8
Correct prediction
Energy consumption = 141.159350 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0022552, 0.010571, 0.039273, 0.020236, 0.79864, 0.002533, 0.28267, 0.37244, 0.035802, 0.0041144]
Predicted label: 4
Correct prediction
Energy consumption = 148.873006 pJ
sum error= 258
Actual label: 7
Output voltages: [0.15058, 0.25774, 0.74996, 0.015808, 0.0113, 0.0011106, 0.0010664, 0.79868, 0.44938, 0.051244]
Predicted label: 7
Correct prediction
Energy consumption = 145.357385 pJ
sum error= 258
Actual label: 3
Output voltages: [0.23979, 0.0018645, 0.26607, 0.79876, 0.045165, 0.15052, 0.0027875, 0.0031542, 0.76056, 0.0066597]
Predicted label: 3
Correct prediction
Energy consumption = 142.261962 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79879, 0.023229, 0.041611, 0.01837, 0.014668, 0.006875, 0.48832, 0.016922, 0.081507, 0.045398]
Predicted label: 0
Correct prediction
Energy consumption = 148.161413 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 508 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 508 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 508 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.4421, 0.036509, 0.030402, 0.20448, 0.18085, 0.063571, 0.021933, 0.056389, 0.67484, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 150.962358 pJ
sum error= 258
Actual label: 1
Output voltages: [0.0031536, 0.79866, 0.034813, 0.038837, 0.063243, 0.0010778, 0.35137, 0.0067989, 0.20141, 0.1253]
Predicted label: 1
Correct prediction
Energy consumption = 163.427247 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0025267, 0.0066242, 0.090292, 0.072601, 0.79872, 0.001135, 0.019355, 0.027989, 0.12062, 0.039781]
Predicted label: 4
Correct prediction
Energy consumption = 143.405226 pJ
sum error= 258
Actual label: 5
Output voltages: [0.12742, 0.0031656, 0.0026133, 0.21727, 0.041191, 0.79865, 0.46651, 0.020003, 0.78267, 0.0016424]
Predicted label: 5
Correct prediction
Energy consumption = 141.719719 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0032592, 0.0155, 0.20331, 0.031133, 0.79871, 0.0015242, 0.02031, 0.032883, 0.14749, 0.029137]
Predicted label: 4
Correct prediction
Energy consumption = 147.781653 pJ
sum error= 258
Actual label: 6
Output voltages: [0.18764, 0.030333, 0.24894, 0.0021214, 0.4632, 0.12519, 0.79875, 0.0014927, 0.44101, 0.012082]
Predicted label: 6
Correct prediction
Energy consumption = 147.840481 pJ
sum error= 258
Actual label: 2
Output voltages: [0.23125, 0.0068122, 0.79845, 0.080672, 0.14357, 0.0012163, 0.030209, 0.0077503, 0.72336, 0.047966]
Predicted label: 2
Correct prediction
Energy consumption = 144.521578 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79872, 0.052694, 0.012597, 0.022802, 0.0078995, 0.01403, 0.34033, 0.030124, 0.1832, 0.028446]
Predicted label: 0
Correct prediction
Energy consumption = 142.825436 pJ
sum error= 258
Actual label: 6
Output voltages: [0.44652, 0.022014, 0.31716, 0.0015832, 0.26926, 0.025737, 0.79844, 0.0011588, 0.57008, 0.010266]
Predicted label: 6
Correct prediction
Energy consumption = 137.195264 pJ
sum error= 258
Actual label: 2
Output voltages: [0.035872, 0.15797, 0.79877, 0.20977, 0.02325, 0.0011311, 0.060344, 0.033989, 0.62776, 0.044602]
Predicted label: 2
Correct prediction
Energy consumption = 142.132997 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 509 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 509 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 509 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.011891, 0.79721, 0.0025523, 0.0047238, 0.78736, 0.0011186, 0.22915, 0.0011018, 0.062454, 0.49869]
Predicted label: 1
Correct prediction
Energy consumption = 155.926714 pJ
sum error= 258
Actual label: 1
Output voltages: [0.044462, 0.79878, 0.026458, 0.012054, 0.77013, 0.001681, 0.3193, 0.0010661, 0.029123, 0.37359]
Predicted label: 1
Correct prediction
Energy consumption = 139.871709 pJ
sum error= 258
Actual label: 1
Output voltages: [0.040117, 0.79879, 0.090319, 0.030542, 0.22768, 0.0011348, 0.27265, 0.0010735, 0.056972, 0.21775]
Predicted label: 1
Correct prediction
Energy consumption = 148.032015 pJ
sum error= 258
Actual label: 1
Output voltages: [0.028969, 0.79872, 0.22367, 0.021097, 0.28513, 0.0011518, 0.27919, 0.023859, 0.017523, 0.19762]
Predicted label: 1
Correct prediction
Energy consumption = 148.059775 pJ
sum error= 258
Actual label: 7
Output voltages: [0.053656, 0.041525, 0.038216, 0.017721, 0.010036, 0.0013164, 0.0010758, 0.79856, 0.21565, 0.073295]
Predicted label: 7
Correct prediction
Energy consumption = 147.275014 pJ
sum error= 258
Actual label: 2
Output voltages: [0.49099, 0.022489, 0.79861, 0.021407, 0.0057066, 0.0011513, 0.043386, 0.0669, 0.41443, 0.01328]
Predicted label: 2
Correct prediction
Energy consumption = 139.423429 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0057696, 0.017541, 0.040538, 0.0341, 0.79869, 0.0063858, 0.032763, 0.038441, 0.048749, 0.0036228]
Predicted label: 4
Correct prediction
Energy consumption = 147.181901 pJ
sum error= 258
Actual label: 7
Output voltages: [0.65164, 0.031329, 0.01345, 0.035152, 0.14962, 0.039425, 0.0010994, 0.79845, 0.22789, 0.12093]
Predicted label: 7
Correct prediction
Energy consumption = 149.800867 pJ
sum error= 258
Actual label: 5
Output voltages: [0.035454, 0.054248, 0.0010672, 0.47991, 0.028423, 0.79858, 0.14804, 0.0052752, 0.4106, 0.0065512]
Predicted label: 5
Correct prediction
Energy consumption = 147.313471 pJ
sum error= 258
Actual label: 2
Output voltages: [0.14754, 0.07819, 0.79861, 0.034373, 0.031492, 0.0011054, 0.053194, 0.016928, 0.42572, 0.02697]
Predicted label: 2
Correct prediction
Energy consumption = 151.284309 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 510 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 510 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 510 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.24367, 0.015492, 0.0035589, 0.21123, 0.38695, 0.0030116, 0.0051775, 0.0012262, 0.31556, 0.79521]
Predicted label: 9
Correct prediction
Energy consumption = 153.753999 pJ
sum error= 258
Actual label: 4
Output voltages: [0.02767, 0.0079761, 0.056377, 0.057861, 0.79879, 0.0011146, 0.010194, 0.018864, 0.044639, 0.036637]
Predicted label: 4
Correct prediction
Energy consumption = 146.480209 pJ
sum error= 258
Actual label: 5
Output voltages: [0.19905, 0.0011411, 0.0010661, 0.477, 0.024751, 0.79878, 0.48632, 0.017697, 0.75889, 0.0027558]
Predicted label: 5
Correct prediction
Energy consumption = 145.449301 pJ
sum error= 258
Actual label: 8
Output voltages: [0.0019782, 0.1632, 0.052408, 0.040746, 0.0061276, 0.052815, 0.011804, 0.066238, 0.79858, 0.033802]
Predicted label: 8
Correct prediction
Energy consumption = 135.034344 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0066339, 0.016098, 0.070628, 0.016869, 0.79864, 0.0072781, 0.17695, 0.26326, 0.022042, 0.013539]
Predicted label: 4
Correct prediction
Energy consumption = 150.955241 pJ
sum error= 258
Actual label: 2
Output voltages: [0.14797, 0.027138, 0.79879, 0.10193, 0.020376, 0.0011573, 0.10298, 0.27697, 0.46917, 0.015001]
Predicted label: 2
Correct prediction
Energy consumption = 142.336253 pJ
sum error= 258
Actual label: 9
Output voltages: [0.20744, 0.02596, 0.015972, 0.17417, 0.12212, 0.021843, 0.0058464, 0.033593, 0.55284, 0.79823]
Predicted label: 9
Correct prediction
Energy consumption = 146.060912 pJ
sum error= 258
Actual label: 7
Output voltages: [0.030108, 0.27428, 0.46798, 0.0092437, 0.025209, 0.0010713, 0.0010707, 0.79861, 0.13444, 0.040881]
Predicted label: 7
Correct prediction
Energy consumption = 144.691494 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79872, 0.026415, 0.026264, 0.014282, 0.016953, 0.01375, 0.54626, 0.0326, 0.23095, 0.028337]
Predicted label: 0
Correct prediction
Energy consumption = 143.727133 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79788, 0.18153, 0.30576, 0.014054, 0.0027347, 0.0011034, 0.39448, 0.022345, 0.39137, 0.04434]
Predicted label: 0
Correct prediction
Energy consumption = 135.994105 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 511 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 511 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 511 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.040682, 0.58572, 0.46229, 0.042463, 0.030251, 0.0010772, 0.0012002, 0.79876, 0.02181, 0.05747]
Predicted label: 7
Correct prediction
Energy consumption = 149.358516 pJ
sum error= 258
Actual label: 5
Output voltages: [0.43807, 0.0011016, 0.0011362, 0.52533, 0.039714, 0.79865, 0.2619, 0.025628, 0.66536, 0.025194]
Predicted label: 5
Correct prediction
Energy consumption = 139.924774 pJ
sum error= 258
Actual label: 1
Output voltages: [0.16442, 0.79875, 0.1648, 0.036908, 0.36525, 0.0011695, 0.59751, 0.0011014, 0.028769, 0.045699]
Predicted label: 1
Correct prediction
Energy consumption = 155.059794 pJ
sum error= 258
Actual label: 1
Output voltages: [0.015337, 0.79874, 0.034044, 0.03581, 0.7404, 0.0011317, 0.25457, 0.0015903, 0.0058583, 0.034546]
Predicted label: 1
Correct prediction
Energy consumption = 144.788093 pJ
sum error= 258
Actual label: 7
Output voltages: [0.72629, 0.017307, 0.075264, 0.010334, 0.10027, 0.0010918, 0.0011511, 0.79875, 0.086944, 0.2637]
Predicted label: 7
Correct prediction
Energy consumption = 157.483147 pJ
sum error= 258
Actual label: 6
Output voltages: [0.26774, 0.054366, 0.04565, 0.019082, 0.30199, 0.27437, 0.79879, 0.0010902, 0.42718, 0.032533]
Predicted label: 6
Correct prediction
Energy consumption = 149.845868 pJ
sum error= 258
Actual label: 6
Output voltages: [0.1919, 0.026823, 0.22235, 0.0011492, 0.47114, 0.24999, 0.7987, 0.0011882, 0.42811, 0.0080384]
Predicted label: 6
Correct prediction
Energy consumption = 133.233056 pJ
sum error= 258
Actual label: 6
Output voltages: [0.16016, 0.29698, 0.38741, 0.0029808, 0.31881, 0.029392, 0.79875, 0.0010786, 0.4484, 0.020581]
Predicted label: 6
Correct prediction
Energy consumption = 134.988568 pJ
sum error= 258
Actual label: 8
Output voltages: [0.021896, 0.011831, 0.034263, 0.45245, 0.0014572, 0.3803, 0.031119, 0.011249, 0.79879, 0.1201]
Predicted label: 8
Correct prediction
Energy consumption = 148.074636 pJ
sum error= 258
Actual label: 2
Output voltages: [0.16879, 0.27434, 0.79879, 0.24818, 0.017793, 0.0011752, 0.041549, 0.002811, 0.25416, 0.13153]
Predicted label: 2
Correct prediction
Energy consumption = 147.276715 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 512 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 512 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 512 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.039291, 0.073667, 0.79876, 0.43594, 0.019539, 0.0010889, 0.069745, 0.013257, 0.57004, 0.014822]
Predicted label: 2
Correct prediction
Energy consumption = 148.751285 pJ
sum error= 258
Actual label: 7
Output voltages: [0.029402, 0.21856, 0.034014, 0.0022736, 0.61608, 0.0010844, 0.0012021, 0.79717, 0.055617, 0.20595]
Predicted label: 7
Correct prediction
Energy consumption = 150.929567 pJ
sum error= 258
Actual label: 7
Output voltages: [0.079067, 0.41171, 0.44928, 0.011878, 0.0024353, 0.0011342, 0.0010681, 0.79869, 0.21803, 0.056375]
Predicted label: 7
Correct prediction
Energy consumption = 138.894725 pJ
sum error= 258
Actual label: 4
Output voltages: [0.0040958, 0.010572, 0.10527, 0.017493, 0.79864, 0.010743, 0.18107, 0.54482, 0.028732, 0.00415]
Predicted label: 4
Correct prediction
Energy consumption = 150.290166 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79871, 0.039307, 0.030311, 0.016119, 0.015365, 0.011814, 0.45012, 0.021786, 0.061402, 0.10542]
Predicted label: 0
Correct prediction
Energy consumption = 145.939456 pJ
sum error= 258
Actual label: 2
Output voltages: [0.10597, 0.15126, 0.79868, 0.014171, 0.012675, 0.0011724, 0.051211, 0.25936, 0.52191, 0.017493]
Predicted label: 2
Correct prediction
Energy consumption = 141.818046 pJ
sum error= 258
Actual label: 4
Output voltages: [0.040335, 0.02584, 0.3977, 0.10877, 0.79878, 0.0010661, 0.077155, 0.042225, 0.0064846, 0.043212]
Predicted label: 4
Correct prediction
Energy consumption = 149.027359 pJ
sum error= 258
Actual label: 2
Output voltages: [0.22418, 0.092997, 0.79862, 0.033825, 0.0057976, 0.0010777, 0.013605, 0.66012, 0.72053, 0.0096352]
Predicted label: 2
Correct prediction
Energy consumption = 141.775771 pJ
sum error= 258
Actual label: 1
Output voltages: [0.029194, 0.79868, 0.1494, 0.024386, 0.094506, 0.0010857, 0.42029, 0.0062889, 0.033472, 0.024491]
Predicted label: 1
Correct prediction
Energy consumption = 156.221762 pJ
sum error= 258
Actual label: 8
Output voltages: [0.016851, 0.016349, 0.023261, 0.31359, 0.0016555, 0.22957, 0.012449, 0.0011708, 0.79878, 0.080162]
Predicted label: 8
Correct prediction
Energy consumption = 152.428654 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 513 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 513 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 513 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.19651, 0.0020764, 0.018274, 0.082803, 0.35547, 0.0029219, 0.0011033, 0.05011, 0.49586, 0.79801]
Predicted label: 9
Correct prediction
Energy consumption = 150.371730 pJ
sum error= 258
Actual label: 6
Output voltages: [0.11436, 0.047602, 0.10691, 0.013057, 0.18755, 0.23922, 0.79877, 0.0049021, 0.68455, 0.032987]
Predicted label: 6
Correct prediction
Energy consumption = 150.930631 pJ
sum error= 258
Actual label: 1
Output voltages: [0.062361, 0.79879, 0.24128, 0.0032548, 0.65195, 0.0026738, 0.52249, 0.0011615, 0.5468, 0.36537]
Predicted label: 1
Correct prediction
Energy consumption = 153.964385 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79879, 0.04581, 0.08154, 0.018075, 0.0073328, 0.0031195, 0.54203, 0.019123, 0.11926, 0.040827]
Predicted label: 0
Correct prediction
Energy consumption = 144.538958 pJ
sum error= 258
Actual label: 5
Output voltages: [0.38505, 0.001066, 0.0011135, 0.04035, 0.0143, 0.79874, 0.57393, 0.027183, 0.63508, 0.0024987]
Predicted label: 5
Correct prediction
Energy consumption = 136.104320 pJ
sum error= 258
Actual label: 9
Output voltages: [0.26989, 0.0057973, 0.032829, 0.059498, 0.23794, 0.02807, 0.0087897, 0.083624, 0.34803, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 141.450466 pJ
sum error= 258
Actual label: 6
Output voltages: [0.46355, 0.27323, 0.25516, 0.027631, 0.12676, 0.021567, 0.79869, 0.0011821, 0.5656, 0.007216]
Predicted label: 6
Correct prediction
Energy consumption = 150.358308 pJ
sum error= 258
Actual label: 9
Output voltages: [0.31851, 0.011839, 0.036464, 0.012939, 0.044523, 0.027632, 0.0012861, 0.040402, 0.63675, 0.79852]
Predicted label: 9
Correct prediction
Energy consumption = 148.462938 pJ
sum error= 258
Actual label: 8
Output voltages: [0.097794, 0.0040608, 0.019244, 0.032627, 0.013007, 0.6168, 0.028913, 0.0034895, 0.79879, 0.0228]
Predicted label: 8
Correct prediction
Energy consumption = 144.471799 pJ
sum error= 258
Actual label: 0
Output voltages: [0.79805, 0.041307, 0.030325, 0.0271, 0.023067, 0.0017732, 0.67573, 0.017847, 0.17462, 0.044927]
Predicted label: 0
Correct prediction
Energy consumption = 146.470354 pJ
sum error= 258
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 514 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 514 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 514 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.055996, 0.0011831, 0.10701, 0.58445, 0.0057731, 0.041215, 0.040937, 0.0010663, 0.77138, 0.010411]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.556002 pJ
sum error= 259
Actual label: 0
Output voltages: [0.79862, 0.032315, 0.027022, 0.030179, 0.035354, 0.0029178, 0.62583, 0.018327, 0.54368, 0.034828]
Predicted label: 0
Correct prediction
Energy consumption = 142.413624 pJ
sum error= 259
Actual label: 8
Output voltages: [0.0016571, 0.098014, 0.30401, 0.17263, 0.0063347, 0.014184, 0.0024003, 0.14229, 0.79879, 0.021639]
Predicted label: 8
Correct prediction
Energy consumption = 146.942538 pJ
sum error= 259
Actual label: 3
Output voltages: [0.26428, 0.0010954, 0.13788, 0.79846, 0.0086789, 0.32546, 0.0081421, 0.016149, 0.72141, 0.0075692]
Predicted label: 3
Correct prediction
Energy consumption = 139.783146 pJ
sum error= 259
Actual label: 9
Output voltages: [0.35265, 0.0051662, 0.010512, 0.060227, 0.42979, 0.0047467, 0.0027281, 0.016896, 0.53721, 0.79507]
Predicted label: 9
Correct prediction
Energy consumption = 145.664427 pJ
sum error= 259
Actual label: 6
Output voltages: [0.72152, 0.034863, 0.020928, 0.0038108, 0.048753, 0.0204, 0.79868, 0.0034966, 0.28013, 0.016153]
Predicted label: 6
Correct prediction
Energy consumption = 142.256285 pJ
sum error= 259
Actual label: 3
Output voltages: [0.15115, 0.0071152, 0.19042, 0.79878, 0.049814, 0.29669, 0.025042, 0.010625, 0.74438, 0.03328]
Predicted label: 3
Correct prediction
Energy consumption = 147.156330 pJ
sum error= 259
Actual label: 0
Output voltages: [0.79873, 0.053754, 0.027011, 0.029923, 0.013425, 0.03187, 0.45692, 0.031453, 0.1434, 0.026641]
Predicted label: 0
Correct prediction
Energy consumption = 143.714341 pJ
sum error= 259
Actual label: 1
Output voltages: [0.010005, 0.79879, 0.041328, 0.0092105, 0.3314, 0.00258, 0.76757, 0.0011085, 0.21947, 0.11741]
Predicted label: 1
Correct prediction
Energy consumption = 159.006631 pJ
sum error= 259
Actual label: 2
Output voltages: [0.39036, 0.053986, 0.79879, 0.16063, 0.024135, 0.0012115, 0.40204, 0.025573, 0.76489, 0.030167]
Predicted label: 2
Correct prediction
Energy consumption = 144.597894 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 515 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 515 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 515 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36944, 0.006077, 0.36988, 0.79872, 0.050182, 0.026381, 0.011475, 0.018761, 0.62115, 0.093912]
Predicted label: 3
Correct prediction
Energy consumption = 150.061467 pJ
sum error= 259
Actual label: 4
Output voltages: [0.0072319, 0.0060058, 0.055139, 0.032443, 0.79872, 0.0019753, 0.17172, 0.17535, 0.17198, 0.023164]
Predicted label: 4
Correct prediction
Energy consumption = 158.942119 pJ
sum error= 259
Actual label: 5
Output voltages: [0.032229, 0.0010676, 0.0013642, 0.40309, 0.20524, 0.79824, 0.042344, 0.019564, 0.77237, 0.01647]
Predicted label: 5
Correct prediction
Energy consumption = 137.094625 pJ
sum error= 259
Actual label: 6
Output voltages: [0.057222, 0.070333, 0.39009, 0.0012213, 0.18203, 0.19756, 0.7987, 0.0037713, 0.51607, 0.0073992]
Predicted label: 6
Correct prediction
Energy consumption = 139.048323 pJ
sum error= 259
Actual label: 7
Output voltages: [0.11632, 0.078749, 0.62957, 0.15859, 0.0019665, 0.0010819, 0.0010793, 0.79879, 0.23696, 0.13247]
Predicted label: 7
Correct prediction
Energy consumption = 158.979016 pJ
sum error= 259
Actual label: 0
Output voltages: [0.79859, 0.024147, 0.064935, 0.0054844, 0.017483, 0.0013287, 0.71529, 0.013047, 0.097869, 0.086502]
Predicted label: 0
Correct prediction
Energy consumption = 138.910966 pJ
sum error= 259
Actual label: 1
Output voltages: [0.010241, 0.79858, 0.028088, 0.042359, 0.024796, 0.0010765, 0.75963, 0.0091581, 0.22728, 0.048423]
Predicted label: 1
Correct prediction
Energy consumption = 155.041921 pJ
sum error= 259
Actual label: 2
Output voltages: [0.31512, 0.31166, 0.79877, 0.41963, 0.022534, 0.0013509, 0.27388, 0.0054141, 0.24166, 0.028249]
Predicted label: 2
Correct prediction
Energy consumption = 148.253488 pJ
sum error= 259
Actual label: 3
Output voltages: [0.40388, 0.0093177, 0.20155, 0.79878, 0.0073195, 0.040021, 0.014796, 0.0088689, 0.31881, 0.030441]
Predicted label: 3
Correct prediction
Energy consumption = 134.820740 pJ
sum error= 259
Actual label: 4
Output voltages: [0.0024838, 0.017007, 0.36681, 0.001121, 0.79861, 0.0012332, 0.038283, 0.038439, 0.17607, 0.48715]
Predicted label: 4
Correct prediction
Energy consumption = 152.908661 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 516 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 516 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 516 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.095189, 0.0010812, 0.0011303, 0.43855, 0.12816, 0.79869, 0.20375, 0.0097138, 0.63692, 0.024458]
Predicted label: 5
Correct prediction
Energy consumption = 141.738025 pJ
sum error= 259
Actual label: 6
Output voltages: [0.045063, 0.033796, 0.24236, 0.0018904, 0.31948, 0.1717, 0.79872, 0.0080906, 0.38596, 0.0085132]
Predicted label: 6
Correct prediction
Energy consumption = 141.343055 pJ
sum error= 259
Actual label: 7
Output voltages: [0.41643, 0.35805, 0.018131, 0.04027, 0.0013986, 0.0037932, 0.008742, 0.78878, 0.027928, 0.55295]
Predicted label: 7
Correct prediction
Energy consumption = 158.952097 pJ
sum error= 259
Actual label: 8
Output voltages: [0.018215, 0.0042082, 0.15014, 0.037585, 0.0038747, 0.20782, 0.0086096, 0.0060109, 0.79876, 0.044127]
Predicted label: 8
Correct prediction
Energy consumption = 142.887027 pJ
sum error= 259
Actual label: 9
Output voltages: [0.24706, 0.012173, 0.020106, 0.044255, 0.046669, 0.0031456, 0.0041956, 0.0089695, 0.63488, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 142.355249 pJ
sum error= 259
Actual label: 0
Output voltages: [0.7955, 0.20067, 0.13652, 0.00933, 0.0026177, 0.0093531, 0.66924, 0.027866, 0.65813, 0.009425]
Predicted label: 0
Correct prediction
Energy consumption = 139.877846 pJ
sum error= 259
Actual label: 1
Output voltages: [0.19381, 0.79879, 0.010737, 0.012584, 0.41799, 0.0017139, 0.41317, 0.0030349, 0.32245, 0.040534]
Predicted label: 1
Correct prediction
Energy consumption = 154.791996 pJ
sum error= 259
Actual label: 2
Output voltages: [0.56498, 0.036535, 0.79878, 0.43809, 0.0014301, 0.0011292, 0.023732, 0.037836, 0.67403, 0.0085737]
Predicted label: 2
Correct prediction
Energy consumption = 142.325732 pJ
sum error= 259
Actual label: 3
Output voltages: [0.1952, 0.027597, 0.057068, 0.79863, 0.036405, 0.0054252, 0.013627, 0.021639, 0.62493, 0.072397]
Predicted label: 3
Correct prediction
Energy consumption = 137.512291 pJ
sum error= 259
Actual label: 4
Output voltages: [0.012463, 0.026139, 0.076706, 0.020013, 0.7987, 0.0063698, 0.31717, 0.14353, 0.074023, 0.010184]
Predicted label: 4
Correct prediction
Energy consumption = 159.426351 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 517 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 517 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 517 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.029572, 0.0011867, 0.0012101, 0.67382, 0.13272, 0.79818, 0.054328, 0.041535, 0.70675, 0.026706]
Predicted label: 5
Correct prediction
Energy consumption = 142.408558 pJ
sum error= 259
Actual label: 6
Output voltages: [0.059792, 0.11925, 0.33629, 0.0015631, 0.1983, 0.11514, 0.79872, 0.0030605, 0.36302, 0.006431]
Predicted label: 6
Correct prediction
Energy consumption = 139.920167 pJ
sum error= 259
Actual label: 7
Output voltages: [0.091566, 0.039623, 0.099048, 0.28978, 0.0096853, 0.017395, 0.0011398, 0.79847, 0.053873, 0.20007]
Predicted label: 7
Correct prediction
Energy consumption = 154.508935 pJ
sum error= 259
Actual label: 8
Output voltages: [0.024516, 0.0098655, 0.12331, 0.031804, 0.0048577, 0.20786, 0.20297, 0.01182, 0.79846, 0.019871]
Predicted label: 8
Correct prediction
Energy consumption = 148.211949 pJ
sum error= 259
Actual label: 5
Output voltages: [0.018233, 0.0010847, 0.014947, 0.10954, 0.0093588, 0.7984, 0.011374, 0.057032, 0.79451, 0.026919]
Predicted label: 5
Correct prediction
Energy consumption = 143.554191 pJ
sum error= 259
Actual label: 4
Output voltages: [0.0113, 0.021586, 0.039702, 0.017778, 0.79877, 0.0010678, 0.14807, 0.093332, 0.03858, 0.046431]
Predicted label: 4
Correct prediction
Energy consumption = 160.693796 pJ
sum error= 259
Actual label: 8
Output voltages: [0.030995, 0.029794, 0.32086, 0.008681, 0.73564, 0.014883, 0.03454, 0.010398, 0.79638, 0.0030185]
Predicted label: 8
Correct prediction
Energy consumption = 136.938606 pJ
sum error= 259
Actual label: 7
Output voltages: [0.31614, 0.33336, 0.15039, 0.045556, 0.0029381, 0.0026604, 0.0017075, 0.79877, 0.072532, 0.14703]
Predicted label: 7
Correct prediction
Energy consumption = 155.613628 pJ
sum error= 259
Actual label: 4
Output voltages: [0.0035245, 0.010259, 0.18448, 0.011872, 0.79866, 0.0010662, 0.044186, 0.036949, 0.016183, 0.2403]
Predicted label: 4
Correct prediction
Energy consumption = 158.879136 pJ
sum error= 259
Actual label: 7
Output voltages: [0.18041, 0.0089756, 0.019592, 0.40125, 0.018347, 0.011405, 0.0011128, 0.79871, 0.38488, 0.57852]
Predicted label: 7
Correct prediction
Energy consumption = 150.447618 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 518 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 518 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 518 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.14828, 0.024163, 0.13317, 0.32109, 0.0010724, 0.0041696, 0.0010659, 0.79865, 0.050195, 0.089471]
Predicted label: 7
Correct prediction
Energy consumption = 156.390223 pJ
sum error= 259
Actual label: 3
Output voltages: [0.04847, 0.027053, 0.2977, 0.79867, 0.039428, 0.019998, 0.0065821, 0.029844, 0.73366, 0.018656]
Predicted label: 3
Correct prediction
Energy consumption = 137.272304 pJ
sum error= 259
Actual label: 9
Output voltages: [0.36848, 0.0018693, 0.020232, 0.19338, 0.28617, 0.0016128, 0.0010672, 0.029349, 0.38071, 0.79598]
Predicted label: 9
Correct prediction
Energy consumption = 147.012793 pJ
sum error= 259
Actual label: 8
Output voltages: [0.0086828, 0.0045347, 0.022375, 0.012526, 0.24514, 0.055014, 0.019643, 0.025982, 0.79875, 0.0086735]
Predicted label: 8
Correct prediction
Energy consumption = 147.409797 pJ
sum error= 259
Actual label: 8
Output voltages: [0.0043503, 0.025123, 0.012508, 0.14079, 0.014961, 0.099675, 0.0075051, 0.014622, 0.79878, 0.043733]
Predicted label: 8
Correct prediction
Energy consumption = 140.580482 pJ
sum error= 259
Actual label: 3
Output voltages: [0.14404, 0.009522, 0.05578, 0.79869, 0.025643, 0.11975, 0.017894, 0.021589, 0.75792, 0.01651]
Predicted label: 3
Correct prediction
Energy consumption = 133.834294 pJ
sum error= 259
Actual label: 1
Output voltages: [0.027398, 0.79854, 0.48086, 0.039519, 0.029705, 0.001084, 0.43229, 0.0033595, 0.17574, 0.04537]
Predicted label: 1
Correct prediction
Energy consumption = 159.640527 pJ
sum error= 259
Actual label: 5
Output voltages: [0.050924, 0.0010672, 0.0014717, 0.54898, 0.18016, 0.79854, 0.040381, 0.052493, 0.75695, 0.020676]
Predicted label: 5
Correct prediction
Energy consumption = 142.749112 pJ
sum error= 259
Actual label: 8
Output voltages: [0.021329, 0.0042469, 0.0055262, 0.051402, 0.010555, 0.35399, 0.065098, 0.021099, 0.79872, 0.013532]
Predicted label: 8
Correct prediction
Energy consumption = 139.659723 pJ
sum error= 259
Actual label: 2
Output voltages: [0.1291, 0.20441, 0.79879, 0.14654, 0.0060642, 0.00114, 0.087633, 0.0014004, 0.66333, 0.037354]
Predicted label: 2
Correct prediction
Energy consumption = 143.408154 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 519 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 519 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 519 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.19309, 0.078381, 0.75793, 0.060831, 0.010807, 0.0010659, 0.001068, 0.79875, 0.093194, 0.28056]
Predicted label: 7
Correct prediction
Energy consumption = 151.238497 pJ
sum error= 259
Actual label: 4
Output voltages: [0.022771, 0.0032901, 0.10391, 0.0026016, 0.79866, 0.018372, 0.039942, 0.05561, 0.068748, 0.025732]
Predicted label: 4
Correct prediction
Energy consumption = 155.459723 pJ
sum error= 259
Actual label: 2
Output voltages: [0.59863, 0.028718, 0.79878, 0.1809, 0.0076763, 0.0013005, 0.065775, 0.091919, 0.63547, 0.015232]
Predicted label: 2
Correct prediction
Energy consumption = 148.010661 pJ
sum error= 259
Actual label: 1
Output voltages: [0.010396, 0.79858, 0.019854, 0.025541, 0.025921, 0.0024964, 0.74872, 0.0050685, 0.41071, 0.04445]
Predicted label: 1
Correct prediction
Energy consumption = 153.188695 pJ
sum error= 259
Actual label: 5
Output voltages: [0.032635, 0.0011709, 0.0014017, 0.35565, 0.24073, 0.79647, 0.26885, 0.0038439, 0.77442, 0.016214]
Predicted label: 5
Correct prediction
Energy consumption = 147.212561 pJ
sum error= 259
Actual label: 4
Output voltages: [0.017012, 0.0022262, 0.30503, 0.023805, 0.79867, 0.010732, 0.57442, 0.035081, 0.012767, 0.02438]
Predicted label: 4
Correct prediction
Energy consumption = 153.623635 pJ
sum error= 259
Actual label: 5
Output voltages: [0.027492, 0.0012784, 0.001072, 0.29535, 0.33907, 0.79805, 0.47099, 0.0014692, 0.76485, 0.045966]
Predicted label: 5
Correct prediction
Energy consumption = 140.280202 pJ
sum error= 259
Actual label: 5
Output voltages: [0.052031, 0.0010946, 0.0010692, 0.28031, 0.47677, 0.79869, 0.27488, 0.010046, 0.78508, 0.031754]
Predicted label: 5
Correct prediction
Energy consumption = 126.736783 pJ
sum error= 259
Actual label: 8
Output voltages: [0.0030661, 0.030382, 0.023714, 0.018429, 0.077175, 0.036669, 0.031166, 0.019323, 0.79877, 0.017518]
Predicted label: 8
Correct prediction
Energy consumption = 138.521495 pJ
sum error= 259
Actual label: 6
Output voltages: [0.2961, 0.048702, 0.56818, 0.0010698, 0.52149, 0.0033975, 0.79872, 0.0020176, 0.011873, 0.060498]
Predicted label: 6
Correct prediction
Energy consumption = 144.576241 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 520 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 520 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 520 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0079689, 0.0039254, 0.085678, 0.04041, 0.7987, 0.014065, 0.18011, 0.034672, 0.061398, 0.0563]
Predicted label: 4
Correct prediction
Energy consumption = 157.150161 pJ
sum error= 259
Actual label: 4
Output voltages: [0.37875, 0.0052609, 0.040528, 0.0073325, 0.74726, 0.0012694, 0.73461, 0.0010677, 0.0333, 0.7433]
Predicted label: 4
Correct prediction
Energy consumption = 152.063308 pJ
sum error= 259
Actual label: 4
Output voltages: [0.0023654, 0.01849, 0.15969, 0.0094805, 0.79855, 0.012678, 0.11326, 0.045291, 0.043356, 0.033371]
Predicted label: 4
Correct prediction
Energy consumption = 146.103320 pJ
sum error= 259
Actual label: 1
Output voltages: [0.13352, 0.79872, 0.54585, 0.4345, 0.22871, 0.0012807, 0.0047166, 0.015467, 0.036782, 0.073412]
Predicted label: 1
Correct prediction
Energy consumption = 165.959501 pJ
sum error= 259
Actual label: 8
Output voltages: [0.0074619, 0.084646, 0.1131, 0.23629, 0.0011117, 0.030949, 0.018635, 0.03897, 0.79874, 0.065193]
Predicted label: 8
Correct prediction
Energy consumption = 142.015212 pJ
sum error= 259
Actual label: 7
Output voltages: [0.039581, 0.063996, 0.75339, 0.023714, 0.0090777, 0.0010688, 0.001066, 0.7987, 0.43453, 0.37021]
Predicted label: 7
Correct prediction
Energy consumption = 144.561318 pJ
sum error= 259
Actual label: 5
Output voltages: [0.033323, 0.001082, 0.0010933, 0.34158, 0.17154, 0.79827, 0.47519, 0.028378, 0.68105, 0.038664]
Predicted label: 5
Correct prediction
Energy consumption = 142.525455 pJ
sum error= 259
Actual label: 5
Output voltages: [0.012807, 0.001066, 0.0013128, 0.053696, 0.32337, 0.79865, 0.42829, 0.0025378, 0.77416, 0.084124]
Predicted label: 5
Correct prediction
Energy consumption = 128.854964 pJ
sum error= 259
Actual label: 1
Output voltages: [0.02366, 0.79861, 0.050219, 0.0067551, 0.05095, 0.021089, 0.75684, 0.016029, 0.3859, 0.014934]
Predicted label: 1
Correct prediction
Energy consumption = 153.993651 pJ
sum error= 259
Actual label: 8
Output voltages: [0.12356, 0.0057146, 0.016452, 0.053925, 0.0081915, 0.33614, 0.45899, 0.0056398, 0.79874, 0.011168]
Predicted label: 8
Correct prediction
Energy consumption = 142.833815 pJ
sum error= 259
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 521 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 521 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 521 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.050776, 0.0011757, 0.038255, 0.27256, 0.036208, 0.3613, 0.001121, 0.67426, 0.63506, 0.59395]
Predicted label: 7
Wrong prediction!
Energy consumption = 153.947605 pJ
sum error= 260
Actual label: 1
Output voltages: [0.021757, 0.79844, 0.05464, 0.18609, 0.031556, 0.0024944, 0.48784, 0.027048, 0.062382, 0.068809]
Predicted label: 1
Correct prediction
Energy consumption = 168.458615 pJ
sum error= 260
Actual label: 3
Output voltages: [0.1206, 0.012993, 0.32085, 0.79879, 0.0067861, 0.0012317, 0.011158, 0.010167, 0.78036, 0.0074841]
Predicted label: 3
Correct prediction
Energy consumption = 145.418615 pJ
sum error= 260
Actual label: 6
Output voltages: [0.049371, 0.0098143, 0.10437, 0.0015817, 0.4978, 0.059325, 0.79877, 0.0010763, 0.72597, 0.0050875]
Predicted label: 6
Correct prediction
Energy consumption = 145.938003 pJ
sum error= 260
Actual label: 3
Output voltages: [0.042541, 0.018818, 0.19551, 0.79878, 0.023404, 0.010428, 0.0027545, 0.011477, 0.7414, 0.023106]
Predicted label: 3
Correct prediction
Energy consumption = 147.589619 pJ
sum error= 260
Actual label: 3
Output voltages: [0.031143, 0.025763, 0.11189, 0.79875, 0.021242, 0.0059944, 0.0071927, 0.01594, 0.75369, 0.086882]
Predicted label: 3
Correct prediction
Energy consumption = 128.528532 pJ
sum error= 260
Actual label: 2
Output voltages: [0.464, 0.038841, 0.79876, 0.22712, 0.0088504, 0.0011578, 0.1532, 0.022953, 0.7485, 0.018001]
Predicted label: 2
Correct prediction
Energy consumption = 140.110983 pJ
sum error= 260
Actual label: 2
Output voltages: [0.12662, 0.029575, 0.78625, 0.73175, 0.0012766, 0.0011076, 0.11132, 0.0018417, 0.71868, 0.027792]
Predicted label: 2
Correct prediction
Energy consumption = 136.386514 pJ
sum error= 260
Actual label: 6
Output voltages: [0.04239, 0.027275, 0.20675, 0.0010665, 0.56485, 0.067957, 0.79878, 0.0013462, 0.1718, 0.014209]
Predicted label: 6
Correct prediction
Energy consumption = 145.066637 pJ
sum error= 260
Actual label: 9
Output voltages: [0.30521, 0.024784, 0.011329, 0.041923, 0.044714, 0.022032, 0.0016522, 0.0053608, 0.59714, 0.7981]
Predicted label: 9
Correct prediction
Energy consumption = 148.858553 pJ
sum error= 260
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 522 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 522 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 522 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.35293, 0.010684, 0.027661, 0.024354, 0.2094, 0.018657, 0.0059243, 0.0098216, 0.56354, 0.79866]
Predicted label: 9
Correct prediction
Energy consumption = 158.019385 pJ
sum error= 260
Actual label: 6
Output voltages: [0.63131, 0.012614, 0.34742, 0.001066, 0.63577, 0.0017219, 0.79418, 0.0016043, 0.020826, 0.16534]
Predicted label: 6
Correct prediction
Energy consumption = 145.818333 pJ
sum error= 260
Actual label: 5
Output voltages: [0.038508, 0.0010959, 0.0012151, 0.053033, 0.17815, 0.79841, 0.39659, 0.020522, 0.78491, 0.067207]
Predicted label: 5
Correct prediction
Energy consumption = 139.979932 pJ
sum error= 260
Actual label: 5
Output voltages: [0.029511, 0.0010826, 0.0036445, 0.19374, 0.081932, 0.79848, 0.50808, 0.022682, 0.78882, 0.0027999]
Predicted label: 5
Correct prediction
Energy consumption = 127.709370 pJ
sum error= 260
Actual label: 3
Output voltages: [0.11152, 0.0057505, 0.044749, 0.79879, 0.03677, 0.1267, 0.0041936, 0.0027682, 0.76088, 0.038685]
Predicted label: 3
Correct prediction
Energy consumption = 136.577084 pJ
sum error= 260
Actual label: 3
Output voltages: [0.075174, 0.0095407, 0.15914, 0.79876, 0.10598, 0.026685, 0.01772, 0.016757, 0.78257, 0.042377]
Predicted label: 3
Correct prediction
Energy consumption = 129.737998 pJ
sum error= 260
Actual label: 8
Output voltages: [0.0032101, 0.012004, 0.070668, 0.057882, 0.014852, 0.041976, 0.091548, 0.011222, 0.79871, 0.043571]
Predicted label: 8
Correct prediction
Energy consumption = 134.716530 pJ
sum error= 260
Actual label: 1
Output voltages: [0.015685, 0.79871, 0.28334, 0.047676, 0.14414, 0.0010664, 0.746, 0.0045284, 0.19994, 0.0084519]
Predicted label: 1
Correct prediction
Energy consumption = 158.471355 pJ
sum error= 260
Actual label: 6
Output voltages: [0.14832, 0.03592, 0.013248, 0.0010717, 0.79093, 0.15737, 0.74411, 0.026084, 0.0053055, 0.003208]
Predicted label: 4
Wrong prediction!
Energy consumption = 151.183921 pJ
sum error= 261
Actual label: 5
Output voltages: [0.052722, 0.0018839, 0.0010859, 0.67486, 0.030462, 0.79875, 0.065886, 0.013383, 0.6443, 0.040719]
Predicted label: 5
Correct prediction
Energy consumption = 149.783060 pJ
sum error= 261
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 523 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 523 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 523 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.046626, 0.032081, 0.21241, 0.0030633, 0.40326, 0.24695, 0.79876, 0.0013598, 0.76323, 0.0084028]
Predicted label: 6
Correct prediction
Energy consumption = 150.960855 pJ
sum error= 261
Actual label: 8
Output voltages: [0.0070163, 0.029215, 0.037961, 0.02876, 0.21385, 0.21797, 0.1332, 0.052989, 0.79863, 0.029006]
Predicted label: 8
Correct prediction
Energy consumption = 142.496734 pJ
sum error= 261
Actual label: 1
Output voltages: [0.013525, 0.79854, 0.020091, 0.031566, 0.02326, 0.0032931, 0.44922, 0.0061449, 0.19445, 0.031202]
Predicted label: 1
Correct prediction
Energy consumption = 149.557641 pJ
sum error= 261
Actual label: 9
Output voltages: [0.1636, 0.019732, 0.028229, 0.18065, 0.25853, 0.022837, 0.014967, 0.037118, 0.21678, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 158.835754 pJ
sum error= 261
Actual label: 7
Output voltages: [0.23035, 0.11681, 0.49243, 0.044587, 0.0027083, 0.0010946, 0.001068, 0.7987, 0.21273, 0.13863]
Predicted label: 7
Correct prediction
Energy consumption = 152.367040 pJ
sum error= 261
Actual label: 6
Output voltages: [0.067317, 0.030424, 0.16653, 0.0026014, 0.67254, 0.027803, 0.79877, 0.001066, 0.32347, 0.023689]
Predicted label: 6
Correct prediction
Energy consumption = 144.775101 pJ
sum error= 261
Actual label: 8
Output voltages: [0.0023363, 0.012935, 0.05883, 0.12708, 0.015741, 0.52135, 0.39853, 0.044035, 0.79877, 0.0061943]
Predicted label: 8
Correct prediction
Energy consumption = 153.057536 pJ
sum error= 261
Actual label: 3
Output voltages: [0.13957, 0.0097546, 0.47632, 0.79879, 0.0072222, 0.0010888, 0.01537, 0.016855, 0.76789, 0.0072518]
Predicted label: 3
Correct prediction
Energy consumption = 144.588164 pJ
sum error= 261
Actual label: 7
Output voltages: [0.69656, 0.0026668, 0.47016, 0.076681, 0.0058531, 0.0011537, 0.0010754, 0.79874, 0.087814, 0.026777]
Predicted label: 7
Correct prediction
Energy consumption = 145.977440 pJ
sum error= 261
Actual label: 4
Output voltages: [0.0099017, 0.0093222, 0.042614, 0.0068897, 0.79868, 0.0019663, 0.026675, 0.047546, 0.054758, 0.01483]
Predicted label: 4
Correct prediction
Energy consumption = 148.857199 pJ
sum error= 261
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 524 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 524 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 524 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.21943, 0.051712, 0.032449, 0.62575, 0.0013456, 0.0027556, 0.0019135, 0.79601, 0.011979, 0.28621]
Predicted label: 7
Correct prediction
Energy consumption = 160.803613 pJ
sum error= 261
Actual label: 0
Output voltages: [0.79878, 0.21009, 0.057529, 0.018568, 0.0051234, 0.0050781, 0.61064, 0.0071245, 0.075924, 0.10509]
Predicted label: 0
Correct prediction
Energy consumption = 146.353710 pJ
sum error= 261
Actual label: 9
Output voltages: [0.074092, 0.0012514, 0.028306, 0.052368, 0.017861, 0.038752, 0.0022528, 0.71141, 0.56199, 0.77344]
Predicted label: 9
Correct prediction
Energy consumption = 147.361199 pJ
sum error= 261
Actual label: 0
Output voltages: [0.79875, 0.047075, 0.022778, 0.017084, 0.0055569, 0.01186, 0.57326, 0.007748, 0.059032, 0.20192]
Predicted label: 0
Correct prediction
Energy consumption = 134.589573 pJ
sum error= 261
Actual label: 0
Output voltages: [0.7978, 0.0028204, 0.010944, 0.040006, 0.024634, 0.050356, 0.76169, 0.0014785, 0.047892, 0.58277]
Predicted label: 0
Correct prediction
Energy consumption = 131.783294 pJ
sum error= 261
Actual label: 3
Output voltages: [0.23175, 0.051532, 0.1657, 0.7986, 0.0087259, 0.020135, 0.0045107, 0.20166, 0.39715, 0.21837]
Predicted label: 3
Correct prediction
Energy consumption = 146.749227 pJ
sum error= 261
Actual label: 7
Output voltages: [0.045832, 0.076503, 0.7936, 0.05367, 0.0034237, 0.0012245, 0.0042556, 0.77978, 0.43324, 0.75095]
Predicted label: 2
Wrong prediction!
Energy consumption = 145.875558 pJ
sum error= 262
Actual label: 9
Output voltages: [0.52262, 0.021712, 0.0078472, 0.21074, 0.40782, 0.0021272, 0.001096, 0.0016553, 0.247, 0.79824]
Predicted label: 9
Correct prediction
Energy consumption = 147.398416 pJ
sum error= 262
Actual label: 3
Output voltages: [0.15621, 0.010759, 0.099806, 0.79868, 0.043194, 0.018174, 0.003666, 0.012223, 0.75185, 0.019924]
Predicted label: 3
Correct prediction
Energy consumption = 140.762307 pJ
sum error= 262
Actual label: 0
Output voltages: [0.79877, 0.10083, 0.018385, 0.018795, 0.019547, 0.0049258, 0.73131, 0.0094758, 0.27584, 0.043724]
Predicted label: 0
Correct prediction
Energy consumption = 146.605883 pJ
sum error= 262
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 525 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 525 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 525 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.037825, 0.0064863, 0.79878, 0.48097, 0.0065083, 0.0010751, 0.015855, 0.02733, 0.78127, 0.0069762]
Predicted label: 2
Correct prediction
Energy consumption = 136.319418 pJ
sum error= 262
Actual label: 0
Output voltages: [0.79876, 0.027301, 0.059109, 0.017755, 0.0086202, 0.017227, 0.41441, 0.032555, 0.026231, 0.065329]
Predicted label: 0
Correct prediction
Energy consumption = 141.183970 pJ
sum error= 262
Actual label: 1
Output voltages: [0.017296, 0.79874, 0.027196, 0.052639, 0.39721, 0.0014933, 0.41173, 0.023183, 0.04114, 0.014644]
Predicted label: 1
Correct prediction
Energy consumption = 151.743184 pJ
sum error= 262
Actual label: 0
Output voltages: [0.79609, 0.037562, 0.611, 0.019069, 0.0074611, 0.0010816, 0.46871, 0.023393, 0.45995, 0.022874]
Predicted label: 0
Correct prediction
Energy consumption = 147.613041 pJ
sum error= 262
Actual label: 1
Output voltages: [0.059498, 0.79876, 0.11587, 0.024396, 0.44122, 0.0022419, 0.73948, 0.0011242, 0.037562, 0.035146]
Predicted label: 1
Correct prediction
Energy consumption = 148.516480 pJ
sum error= 262
Actual label: 0
Output voltages: [0.79586, 0.29599, 0.19856, 0.019929, 0.0063974, 0.043594, 0.74975, 0.011082, 0.3651, 0.006713]
Predicted label: 0
Correct prediction
Energy consumption = 154.021031 pJ
sum error= 262
Actual label: 4
Output voltages: [0.014258, 0.0063752, 0.31695, 0.0078973, 0.79869, 0.0024731, 0.11635, 0.032659, 0.014933, 0.058087]
Predicted label: 4
Correct prediction
Energy consumption = 153.290321 pJ
sum error= 262
Actual label: 0
Output voltages: [0.79879, 0.015786, 0.050268, 0.016129, 0.021119, 0.0037574, 0.09281, 0.027404, 0.57222, 0.011418]
Predicted label: 0
Correct prediction
Energy consumption = 150.836636 pJ
sum error= 262
Actual label: 1
Output voltages: [0.18747, 0.7979, 0.11835, 0.001338, 0.73349, 0.010986, 0.2366, 0.0010946, 0.24088, 0.13956]
Predicted label: 1
Correct prediction
Energy consumption = 147.550883 pJ
sum error= 262
Actual label: 0
Output voltages: [0.7986, 0.039188, 0.018659, 0.015265, 0.019029, 0.021917, 0.20017, 0.020713, 0.04081, 0.024788]
Predicted label: 0
Correct prediction
Energy consumption = 144.976175 pJ
sum error= 262
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 526 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 526 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 526 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.034484, 0.0081933, 0.22416, 0.0013046, 0.79855, 0.0011258, 0.037995, 0.019611, 0.56936, 0.016048]
Predicted label: 4
Correct prediction
Energy consumption = 142.173224 pJ
sum error= 262
Actual label: 7
Output voltages: [0.032032, 0.053476, 0.78926, 0.012536, 0.0039661, 0.0011442, 0.0010716, 0.79879, 0.33715, 0.29246]
Predicted label: 7
Correct prediction
Energy consumption = 150.792116 pJ
sum error= 262
Actual label: 9
Output voltages: [0.4021, 0.015748, 0.019202, 0.049728, 0.23759, 0.0071033, 0.0010815, 0.014275, 0.37761, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 148.511961 pJ
sum error= 262
Actual label: 6
Output voltages: [0.053159, 0.024039, 0.23583, 0.0010743, 0.33987, 0.11342, 0.79877, 0.001708, 0.3892, 0.0030083]
Predicted label: 6
Correct prediction
Energy consumption = 144.135967 pJ
sum error= 262
Actual label: 2
Output voltages: [0.47657, 0.039623, 0.79879, 0.24516, 0.027875, 0.0011202, 0.31005, 0.0088357, 0.74827, 0.093741]
Predicted label: 2
Correct prediction
Energy consumption = 143.356602 pJ
sum error= 262
Actual label: 6
Output voltages: [0.032324, 0.003632, 0.1357, 0.0012505, 0.61691, 0.010347, 0.79877, 0.0010665, 0.38664, 0.010904]
Predicted label: 6
Correct prediction
Energy consumption = 137.720943 pJ
sum error= 262
Actual label: 2
Output voltages: [0.37876, 0.3516, 0.79829, 0.54946, 0.011643, 0.0011249, 0.16664, 0.0035831, 0.53255, 0.050713]
Predicted label: 2
Correct prediction
Energy consumption = 150.579859 pJ
sum error= 262
Actual label: 2
Output voltages: [0.4733, 0.02019, 0.79877, 0.42131, 0.0032607, 0.001066, 0.048803, 0.052707, 0.76919, 0.026339]
Predicted label: 2
Correct prediction
Energy consumption = 131.961369 pJ
sum error= 262
Actual label: 9
Output voltages: [0.033719, 0.0010709, 0.042447, 0.031755, 0.026294, 0.027127, 0.0011485, 0.33302, 0.79442, 0.78129]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.959432 pJ
sum error= 263
Actual label: 9
Output voltages: [0.4617, 0.0018739, 0.21435, 0.0043328, 0.35061, 0.0020167, 0.0011745, 0.028883, 0.66229, 0.78879]
Predicted label: 9
Correct prediction
Energy consumption = 139.964086 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 527 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 527 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 527 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.027808, 0.020783, 0.015333, 0.051073, 0.020861, 0.65188, 0.012523, 0.16789, 0.061713]
Predicted label: 0
Correct prediction
Energy consumption = 157.059729 pJ
sum error= 263
Actual label: 1
Output voltages: [0.028463, 0.7986, 0.31186, 0.060968, 0.023329, 0.0011374, 0.72119, 0.006855, 0.11673, 0.011971]
Predicted label: 1
Correct prediction
Energy consumption = 157.141263 pJ
sum error= 263
Actual label: 2
Output voltages: [0.58197, 0.017393, 0.79872, 0.3026, 0.0063283, 0.0011777, 0.007334, 0.043654, 0.56308, 0.0018044]
Predicted label: 2
Correct prediction
Energy consumption = 146.674466 pJ
sum error= 263
Actual label: 3
Output voltages: [0.36384, 0.0044478, 0.061649, 0.79869, 0.033792, 0.039019, 0.073145, 0.032954, 0.54854, 0.16113]
Predicted label: 3
Correct prediction
Energy consumption = 149.136338 pJ
sum error= 263
Actual label: 4
Output voltages: [0.0073736, 0.01673, 0.13819, 0.0075821, 0.79869, 0.014933, 0.18278, 0.30394, 0.089544, 0.0040117]
Predicted label: 4
Correct prediction
Energy consumption = 152.667664 pJ
sum error= 263
Actual label: 5
Output voltages: [0.064073, 0.0040608, 0.01625, 0.58751, 0.020337, 0.7985, 0.064692, 0.02359, 0.74889, 0.28981]
Predicted label: 5
Correct prediction
Energy consumption = 152.089390 pJ
sum error= 263
Actual label: 6
Output voltages: [0.18736, 0.025713, 0.10502, 0.0063295, 0.36174, 0.21112, 0.79871, 0.0012915, 0.56221, 0.010162]
Predicted label: 6
Correct prediction
Energy consumption = 144.435853 pJ
sum error= 263
Actual label: 7
Output voltages: [0.13859, 0.026874, 0.3935, 0.047609, 0.007559, 0.0010716, 0.001576, 0.7987, 0.24737, 0.025405]
Predicted label: 7
Correct prediction
Energy consumption = 158.972498 pJ
sum error= 263
Actual label: 8
Output voltages: [0.079228, 0.13449, 0.31452, 0.0038631, 0.0082611, 0.0012747, 0.026644, 0.018565, 0.79768, 0.5537]
Predicted label: 8
Correct prediction
Energy consumption = 140.035956 pJ
sum error= 263
Actual label: 9
Output voltages: [0.27244, 0.005368, 0.023963, 0.015546, 0.16992, 0.016543, 0.0017711, 0.074418, 0.65489, 0.79684]
Predicted label: 9
Correct prediction
Energy consumption = 143.496671 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 528 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 528 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 528 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79405, 0.02572, 0.039492, 0.018684, 0.039844, 0.0025829, 0.75224, 0.0045115, 0.36934, 0.030572]
Predicted label: 0
Correct prediction
Energy consumption = 158.183856 pJ
sum error= 263
Actual label: 1
Output voltages: [0.026507, 0.79878, 0.21524, 0.016512, 0.41392, 0.0010801, 0.34689, 0.00459, 0.045929, 0.083299]
Predicted label: 1
Correct prediction
Energy consumption = 157.072059 pJ
sum error= 263
Actual label: 2
Output voltages: [0.72108, 0.01302, 0.79879, 0.074262, 0.039884, 0.0010661, 0.04794, 0.048894, 0.56829, 0.015278]
Predicted label: 2
Correct prediction
Energy consumption = 143.815090 pJ
sum error= 263
Actual label: 3
Output voltages: [0.03473, 0.013655, 0.30183, 0.79619, 0.012891, 0.0092407, 0.013167, 0.0097752, 0.77697, 0.24763]
Predicted label: 3
Correct prediction
Energy consumption = 142.439645 pJ
sum error= 263
Actual label: 4
Output voltages: [0.032967, 0.018642, 0.095612, 0.0039283, 0.79866, 0.0027493, 0.099499, 0.042628, 0.032962, 0.01201]
Predicted label: 4
Correct prediction
Energy consumption = 149.476887 pJ
sum error= 263
Actual label: 5
Output voltages: [0.038439, 0.001066, 0.0024171, 0.12858, 0.083423, 0.79875, 0.14096, 0.016286, 0.78123, 0.24162]
Predicted label: 5
Correct prediction
Energy consumption = 144.242535 pJ
sum error= 263
Actual label: 6
Output voltages: [0.041945, 0.028677, 0.091673, 0.020542, 0.2487, 0.36747, 0.79879, 0.0020658, 0.76418, 0.006717]
Predicted label: 6
Correct prediction
Energy consumption = 149.409974 pJ
sum error= 263
Actual label: 7
Output voltages: [0.54429, 0.19415, 0.016734, 0.12099, 0.010567, 0.019138, 0.0010772, 0.79865, 0.66304, 0.24068]
Predicted label: 7
Correct prediction
Energy consumption = 158.439454 pJ
sum error= 263
Actual label: 8
Output voltages: [0.3202, 0.012457, 0.5804, 0.0011039, 0.023219, 0.0011441, 0.0080565, 0.015924, 0.79621, 0.42237]
Predicted label: 8
Correct prediction
Energy consumption = 142.024535 pJ
sum error= 263
Actual label: 9
Output voltages: [0.35656, 0.00827, 0.021055, 0.026317, 0.060632, 0.035573, 0.0014492, 0.12552, 0.58138, 0.79682]
Predicted label: 9
Correct prediction
Energy consumption = 148.892898 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 529 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 529 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 529 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79858, 0.037962, 0.22966, 0.0023517, 0.0086532, 0.0012194, 0.56278, 0.0067699, 0.31266, 0.20574]
Predicted label: 0
Correct prediction
Energy consumption = 154.868826 pJ
sum error= 263
Actual label: 1
Output voltages: [0.0015144, 0.79878, 0.090031, 0.029039, 0.18502, 0.0011633, 0.48496, 0.0014376, 0.41584, 0.050085]
Predicted label: 1
Correct prediction
Energy consumption = 155.286105 pJ
sum error= 263
Actual label: 2
Output voltages: [0.585, 0.0013931, 0.79879, 0.28452, 0.0053879, 0.0013681, 0.022256, 0.12491, 0.57442, 0.0037335]
Predicted label: 2
Correct prediction
Energy consumption = 141.209537 pJ
sum error= 263
Actual label: 3
Output voltages: [0.63264, 0.013426, 0.16518, 0.7987, 0.061791, 0.0059145, 0.024956, 0.0085256, 0.63889, 0.055257]
Predicted label: 3
Correct prediction
Energy consumption = 141.758970 pJ
sum error= 263
Actual label: 4
Output voltages: [0.0087954, 0.0052053, 0.081715, 0.01599, 0.79866, 0.0045013, 0.16244, 0.076413, 0.031998, 0.010471]
Predicted label: 4
Correct prediction
Energy consumption = 152.840452 pJ
sum error= 263
Actual label: 5
Output voltages: [0.0219, 0.0012551, 0.022551, 0.26793, 0.026186, 0.79825, 0.037037, 0.025378, 0.78867, 0.045426]
Predicted label: 5
Correct prediction
Energy consumption = 150.230727 pJ
sum error= 263
Actual label: 6
Output voltages: [0.04566, 0.039369, 0.28189, 0.0013495, 0.15339, 0.074121, 0.79876, 0.0025028, 0.75356, 0.010532]
Predicted label: 6
Correct prediction
Energy consumption = 148.721377 pJ
sum error= 263
Actual label: 7
Output voltages: [0.25755, 0.020002, 0.35701, 0.059302, 0.0099835, 0.0011563, 0.0010841, 0.79869, 0.27144, 0.029325]
Predicted label: 7
Correct prediction
Energy consumption = 152.090647 pJ
sum error= 263
Actual label: 8
Output voltages: [0.069673, 0.16435, 0.49272, 0.01238, 0.021108, 0.0016422, 0.013019, 0.0048025, 0.79878, 0.22749]
Predicted label: 8
Correct prediction
Energy consumption = 140.831343 pJ
sum error= 263
Actual label: 9
Output voltages: [0.12063, 0.009517, 0.028668, 0.029353, 0.038656, 0.062473, 0.0022543, 0.064939, 0.73913, 0.79405]
Predicted label: 9
Correct prediction
Energy consumption = 146.375369 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 530 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 530 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 530 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.051328, 0.54749, 0.23589, 0.1383, 0.0081828, 0.0025523, 0.13623, 0.0036664, 0.79873, 0.41879]
Predicted label: 8
Correct prediction
Energy consumption = 157.712008 pJ
sum error= 263
Actual label: 0
Output voltages: [0.79794, 0.39688, 0.18717, 0.017221, 0.0045203, 0.0014182, 0.70188, 0.039192, 0.3701, 0.15397]
Predicted label: 0
Correct prediction
Energy consumption = 156.551513 pJ
sum error= 263
Actual label: 5
Output voltages: [0.01505, 0.0010847, 0.0050264, 0.45822, 0.023892, 0.78279, 0.020417, 0.027759, 0.69035, 0.1945]
Predicted label: 5
Correct prediction
Energy consumption = 148.820527 pJ
sum error= 263
Actual label: 6
Output voltages: [0.1555, 0.017693, 0.11786, 0.0046063, 0.48229, 0.50813, 0.79878, 0.0060934, 0.70185, 0.0027138]
Predicted label: 6
Correct prediction
Energy consumption = 147.767591 pJ
sum error= 263
Actual label: 6
Output voltages: [0.23813, 0.08665, 0.04425, 0.03962, 0.23242, 0.33456, 0.79878, 0.0059961, 0.65299, 0.028175]
Predicted label: 6
Correct prediction
Energy consumption = 141.377199 pJ
sum error= 263
Actual label: 0
Output voltages: [0.79879, 0.055217, 0.039753, 0.035232, 0.0161, 0.005033, 0.51745, 0.032209, 0.0564, 0.17673]
Predicted label: 0
Correct prediction
Energy consumption = 146.695533 pJ
sum error= 263
Actual label: 8
Output voltages: [0.015155, 0.11331, 0.15117, 0.14734, 0.0046637, 0.033128, 0.0138, 0.00629, 0.79872, 0.14232]
Predicted label: 8
Correct prediction
Energy consumption = 142.505964 pJ
sum error= 263
Actual label: 0
Output voltages: [0.79871, 0.22431, 0.15264, 0.018416, 0.11448, 0.01381, 0.30194, 0.017242, 0.44815, 0.077063]
Predicted label: 0
Correct prediction
Energy consumption = 152.073571 pJ
sum error= 263
Actual label: 2
Output voltages: [0.6542, 0.0010825, 0.79771, 0.73535, 0.0021585, 0.0011305, 0.0073172, 0.060557, 0.63613, 0.0093774]
Predicted label: 2
Correct prediction
Energy consumption = 139.087282 pJ
sum error= 263
Actual label: 3
Output voltages: [0.74402, 0.01803, 0.038561, 0.79869, 0.014509, 0.011837, 0.0068754, 0.0072316, 0.48579, 0.020947]
Predicted label: 3
Correct prediction
Energy consumption = 138.692786 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 531 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 531 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 531 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.032757, 0.028408, 0.70952, 0.018787, 0.0043712, 0.0012379, 0.0055476, 0.79878, 0.54879, 0.023812]
Predicted label: 7
Correct prediction
Energy consumption = 152.540531 pJ
sum error= 263
Actual label: 9
Output voltages: [0.36569, 0.0017188, 0.018901, 0.047856, 0.037276, 0.02619, 0.0011408, 0.3699, 0.55317, 0.77746]
Predicted label: 9
Correct prediction
Energy consumption = 151.340562 pJ
sum error= 263
Actual label: 4
Output voltages: [0.0076026, 0.0032767, 0.055927, 0.027478, 0.79873, 0.0014184, 0.074596, 0.020753, 0.030757, 0.016948]
Predicted label: 4
Correct prediction
Energy consumption = 145.071425 pJ
sum error= 263
Actual label: 7
Output voltages: [0.064813, 0.031951, 0.058951, 0.094271, 0.0076887, 0.008677, 0.0010678, 0.79849, 0.19255, 0.20758]
Predicted label: 7
Correct prediction
Energy consumption = 146.326884 pJ
sum error= 263
Actual label: 1
Output voltages: [0.042953, 0.79879, 0.35564, 0.038018, 0.24798, 0.0026973, 0.79087, 0.0011241, 0.016402, 0.0088803]
Predicted label: 1
Correct prediction
Energy consumption = 157.742018 pJ
sum error= 263
Actual label: 9
Output voltages: [0.62577, 0.0015258, 0.01471, 0.031535, 0.24468, 0.014682, 0.0010662, 0.274, 0.3942, 0.79483]
Predicted label: 9
Correct prediction
Energy consumption = 158.359112 pJ
sum error= 263
Actual label: 1
Output voltages: [0.038856, 0.79868, 0.41009, 0.01063, 0.21623, 0.0011575, 0.31968, 0.008943, 0.021173, 0.031436]
Predicted label: 1
Correct prediction
Energy consumption = 161.417944 pJ
sum error= 263
Actual label: 7
Output voltages: [0.084599, 0.027261, 0.29168, 0.091051, 0.023808, 0.002392, 0.0010829, 0.79849, 0.1787, 0.17166]
Predicted label: 7
Correct prediction
Energy consumption = 147.933273 pJ
sum error= 263
Actual label: 1
Output voltages: [0.0047368, 0.7986, 0.035041, 0.064117, 0.025455, 0.0010929, 0.66878, 0.016841, 0.069836, 0.03515]
Predicted label: 1
Correct prediction
Energy consumption = 154.074801 pJ
sum error= 263
Actual label: 4
Output voltages: [0.016113, 0.011031, 0.1227, 0.027733, 0.79871, 0.0010951, 0.58698, 0.063198, 0.0027203, 0.0071676]
Predicted label: 4
Correct prediction
Energy consumption = 150.419501 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 532 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 532 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 532 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.024137, 0.011366, 0.20369, 0.0021721, 0.18244, 0.1652, 0.011845, 0.46559, 0.12239]
Predicted label: 0
Correct prediction
Energy consumption = 161.512730 pJ
sum error= 263
Actual label: 0
Output voltages: [0.79878, 0.11713, 0.030904, 0.021301, 0.029746, 0.0056508, 0.57411, 0.015064, 0.064291, 0.12837]
Predicted label: 0
Correct prediction
Energy consumption = 146.417286 pJ
sum error= 263
Actual label: 4
Output voltages: [0.025393, 0.017546, 0.038793, 0.030045, 0.79874, 0.0010723, 0.0049869, 0.020686, 0.019296, 0.30269]
Predicted label: 4
Correct prediction
Energy consumption = 155.265872 pJ
sum error= 263
Actual label: 1
Output voltages: [0.0053859, 0.79879, 0.013189, 0.0044424, 0.68292, 0.0048984, 0.39685, 0.017818, 0.22102, 0.048708]
Predicted label: 1
Correct prediction
Energy consumption = 158.939031 pJ
sum error= 263
Actual label: 7
Output voltages: [0.50337, 0.028851, 0.24386, 0.26778, 0.0036324, 0.0010659, 0.0011038, 0.79877, 0.14013, 0.049022]
Predicted label: 7
Correct prediction
Energy consumption = 157.529207 pJ
sum error= 263
Actual label: 5
Output voltages: [0.019637, 0.0035672, 0.003001, 0.45912, 0.03131, 0.79879, 0.10236, 0.21429, 0.74595, 0.35599]
Predicted label: 5
Correct prediction
Energy consumption = 144.576789 pJ
sum error= 263
Actual label: 7
Output voltages: [0.034067, 0.10807, 0.05365, 0.044495, 0.0075289, 0.001233, 0.001338, 0.79862, 0.17757, 0.17929]
Predicted label: 7
Correct prediction
Energy consumption = 153.022448 pJ
sum error= 263
Actual label: 1
Output voltages: [0.051851, 0.79876, 0.11062, 0.0026647, 0.50635, 0.0011202, 0.30332, 0.0040465, 0.20026, 0.078479]
Predicted label: 1
Correct prediction
Energy consumption = 155.045235 pJ
sum error= 263
Actual label: 3
Output voltages: [0.1523, 0.0084531, 0.19777, 0.79873, 0.042217, 0.012225, 0.0054379, 0.042638, 0.65325, 0.21665]
Predicted label: 3
Correct prediction
Energy consumption = 153.386303 pJ
sum error= 263
Actual label: 3
Output voltages: [0.54438, 0.019104, 0.043112, 0.79867, 0.023739, 0.14306, 0.037457, 0.011722, 0.61934, 0.21422]
Predicted label: 3
Correct prediction
Energy consumption = 134.173898 pJ
sum error= 263
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 533 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 533 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 533 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.48466, 0.013321, 0.032227, 0.79867, 0.014656, 0.029187, 0.023705, 0.015631, 0.67127, 0.046929]
Predicted label: 3
Correct prediction
Energy consumption = 150.322295 pJ
sum error= 263
Actual label: 1
Output voltages: [0.56416, 0.79832, 0.043124, 0.13299, 0.05632, 0.18219, 0.79841, 0.0030337, 0.1255, 0.0026937]
Predicted label: 6
Wrong prediction!
Energy consumption = 161.284100 pJ
sum error= 264
Actual label: 6
Output voltages: [0.081267, 0.01243, 0.36572, 0.0047262, 0.23154, 0.23714, 0.79878, 0.0010663, 0.64165, 0.087808]
Predicted label: 6
Correct prediction
Energy consumption = 145.262234 pJ
sum error= 264
Actual label: 9
Output voltages: [0.42937, 0.001335, 0.0078914, 0.028082, 0.32314, 0.018333, 0.0011444, 0.040556, 0.62318, 0.7974]
Predicted label: 9
Correct prediction
Energy consumption = 150.816038 pJ
sum error= 264
Actual label: 7
Output voltages: [0.45821, 0.005657, 0.5436, 0.21341, 0.0026099, 0.0012045, 0.0010708, 0.79878, 0.30737, 0.017592]
Predicted label: 7
Correct prediction
Energy consumption = 147.452106 pJ
sum error= 264
Actual label: 4
Output voltages: [0.01031, 0.0044939, 0.052894, 0.043588, 0.79868, 0.0010799, 0.052011, 0.028558, 0.015821, 0.032354]
Predicted label: 4
Correct prediction
Energy consumption = 143.336633 pJ
sum error= 264
Actual label: 3
Output voltages: [0.18005, 0.0041959, 0.33822, 0.7987, 0.03382, 0.018475, 0.023223, 0.0061108, 0.48752, 0.23133]
Predicted label: 3
Correct prediction
Energy consumption = 147.204428 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79871, 0.0872, 0.040573, 0.0035628, 0.008685, 0.0044923, 0.67799, 0.012677, 0.042628, 0.11827]
Predicted label: 0
Correct prediction
Energy consumption = 157.817405 pJ
sum error= 264
Actual label: 2
Output voltages: [0.45824, 0.0086058, 0.79871, 0.2621, 0.015989, 0.0010715, 0.022893, 0.016269, 0.51047, 0.0061101]
Predicted label: 2
Correct prediction
Energy consumption = 145.569034 pJ
sum error= 264
Actual label: 5
Output voltages: [0.30986, 0.0010704, 0.0060302, 0.64972, 0.016388, 0.79837, 0.0032604, 0.04285, 0.72515, 0.055059]
Predicted label: 5
Correct prediction
Energy consumption = 146.411612 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 534 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 534 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 534 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.45836, 0.0099423, 0.79868, 0.027999, 0.027487, 0.0010719, 0.049872, 0.041893, 0.57021, 0.0046501]
Predicted label: 2
Correct prediction
Energy consumption = 145.111255 pJ
sum error= 264
Actual label: 6
Output voltages: [0.072802, 0.17188, 0.037516, 0.010556, 0.049034, 0.74425, 0.79874, 0.021986, 0.56643, 0.0025836]
Predicted label: 6
Correct prediction
Energy consumption = 154.177327 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79846, 0.027756, 0.031294, 0.0090039, 0.036091, 0.0019316, 0.70705, 0.017349, 0.33648, 0.032575]
Predicted label: 0
Correct prediction
Energy consumption = 147.710113 pJ
sum error= 264
Actual label: 8
Output voltages: [0.026484, 0.27861, 0.048462, 0.15748, 0.0095326, 0.0070858, 0.038402, 0.0024777, 0.79734, 0.57853]
Predicted label: 8
Correct prediction
Energy consumption = 157.457870 pJ
sum error= 264
Actual label: 9
Output voltages: [0.73264, 0.019228, 0.01477, 0.038013, 0.21487, 0.022269, 0.0050089, 0.0078889, 0.1949, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.582639 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0077464, 0.01132, 0.41621, 0.030101, 0.79862, 0.005889, 0.32527, 0.076367, 0.023688, 0.076183]
Predicted label: 4
Correct prediction
Energy consumption = 154.306111 pJ
sum error= 264
Actual label: 3
Output voltages: [0.43393, 0.009573, 0.4274, 0.79879, 0.029167, 0.0073608, 0.0050859, 0.012692, 0.33799, 0.20145]
Predicted label: 3
Correct prediction
Energy consumption = 147.317317 pJ
sum error= 264
Actual label: 5
Output voltages: [0.029829, 0.0049025, 0.005843, 0.59485, 0.022424, 0.79856, 0.11232, 0.064056, 0.7636, 0.11644]
Predicted label: 5
Correct prediction
Energy consumption = 141.358691 pJ
sum error= 264
Actual label: 4
Output voltages: [0.02048, 0.039504, 0.053596, 0.025028, 0.79878, 0.0071102, 0.12875, 0.099954, 0.028481, 0.019151]
Predicted label: 4
Correct prediction
Energy consumption = 152.630301 pJ
sum error= 264
Actual label: 8
Output voltages: [0.025454, 0.26227, 0.35847, 0.035861, 0.026972, 0.0072487, 0.025509, 0.0036304, 0.79878, 0.25628]
Predicted label: 8
Correct prediction
Energy consumption = 150.945593 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 535 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 535 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 535 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.012818, 0.79869, 0.53415, 0.028638, 0.07335, 0.0010936, 0.099598, 0.015602, 0.067971, 0.048554]
Predicted label: 1
Correct prediction
Energy consumption = 159.989925 pJ
sum error= 264
Actual label: 5
Output voltages: [0.03617, 0.0038838, 0.001066, 0.59263, 0.023942, 0.79879, 0.017485, 0.03736, 0.76472, 0.018464]
Predicted label: 5
Correct prediction
Energy consumption = 147.524182 pJ
sum error= 264
Actual label: 9
Output voltages: [0.19668, 0.0017288, 0.026848, 0.022825, 0.28611, 0.0016844, 0.0025048, 0.069302, 0.32334, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 151.715603 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79861, 0.016681, 0.0038566, 0.019665, 0.041134, 0.013911, 0.72802, 0.0086695, 0.24859, 0.025741]
Predicted label: 0
Correct prediction
Energy consumption = 151.404109 pJ
sum error= 264
Actual label: 6
Output voltages: [0.21254, 0.032979, 0.20315, 0.0023799, 0.29415, 0.27374, 0.79873, 0.0015498, 0.446, 0.0091059]
Predicted label: 6
Correct prediction
Energy consumption = 143.187109 pJ
sum error= 264
Actual label: 4
Output voltages: [0.056577, 0.017403, 0.25014, 0.010685, 0.79867, 0.0026754, 0.21243, 0.027168, 0.043934, 0.0096686]
Predicted label: 4
Correct prediction
Energy consumption = 146.529980 pJ
sum error= 264
Actual label: 3
Output voltages: [0.1854, 0.022826, 0.056775, 0.79868, 0.029125, 0.0087757, 0.0075005, 0.014074, 0.5983, 0.1678]
Predicted label: 3
Correct prediction
Energy consumption = 145.035727 pJ
sum error= 264
Actual label: 6
Output voltages: [0.12987, 0.050122, 0.10662, 0.0039672, 0.346, 0.058924, 0.79878, 0.0049434, 0.69852, 0.0037731]
Predicted label: 6
Correct prediction
Energy consumption = 146.253072 pJ
sum error= 264
Actual label: 3
Output voltages: [0.25279, 0.014073, 0.16409, 0.79876, 0.016399, 0.030157, 0.0034733, 0.0032689, 0.75789, 0.036465]
Predicted label: 3
Correct prediction
Energy consumption = 146.751619 pJ
sum error= 264
Actual label: 3
Output voltages: [0.07469, 0.020828, 0.049221, 0.79871, 0.030952, 0.020557, 0.011581, 0.0022972, 0.5364, 0.22812]
Predicted label: 3
Correct prediction
Energy consumption = 138.299342 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 536 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 536 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 536 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.017455, 0.26359, 0.28788, 0.029891, 0.0044157, 0.0035819, 0.014893, 0.016389, 0.79879, 0.46429]
Predicted label: 8
Correct prediction
Energy consumption = 151.262876 pJ
sum error= 264
Actual label: 1
Output voltages: [0.027696, 0.79864, 0.17692, 0.036005, 0.40995, 0.0010692, 0.26683, 0.0038551, 0.023741, 0.058357]
Predicted label: 1
Correct prediction
Energy consumption = 157.106034 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0098832, 0.004147, 0.075083, 0.026931, 0.79869, 0.0014189, 0.057276, 0.034236, 0.026626, 0.035451]
Predicted label: 4
Correct prediction
Energy consumption = 149.217089 pJ
sum error= 264
Actual label: 7
Output voltages: [0.2207, 0.030702, 0.028324, 0.256, 0.0046756, 0.013017, 0.0011763, 0.79873, 0.22414, 0.44703]
Predicted label: 7
Correct prediction
Energy consumption = 148.088812 pJ
sum error= 264
Actual label: 5
Output voltages: [0.035154, 0.0010676, 0.018845, 0.44419, 0.068289, 0.79875, 0.057229, 0.19413, 0.78285, 0.03976]
Predicted label: 5
Correct prediction
Energy consumption = 140.736276 pJ
sum error= 264
Actual label: 7
Output voltages: [0.28065, 0.011766, 0.051184, 0.056572, 0.01527, 0.029424, 0.0010718, 0.7985, 0.11685, 0.35765]
Predicted label: 7
Correct prediction
Energy consumption = 152.142876 pJ
sum error= 264
Actual label: 2
Output voltages: [0.46506, 0.024842, 0.79862, 0.028457, 0.011269, 0.0010839, 0.036511, 0.037156, 0.46133, 0.0041286]
Predicted label: 2
Correct prediction
Energy consumption = 138.006034 pJ
sum error= 264
Actual label: 2
Output voltages: [0.5507, 0.0016131, 0.79877, 0.052517, 0.010633, 0.0010661, 0.030078, 0.13669, 0.58345, 0.0018256]
Predicted label: 2
Correct prediction
Energy consumption = 131.587427 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79877, 0.075346, 0.040019, 0.017761, 0.027467, 0.0018741, 0.74788, 0.014932, 0.18694, 0.26132]
Predicted label: 0
Correct prediction
Energy consumption = 153.924449 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79879, 0.042906, 0.023623, 0.028441, 0.01227, 0.0061716, 0.63789, 0.023626, 0.25214, 0.10589]
Predicted label: 0
Correct prediction
Energy consumption = 142.067015 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 537 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 537 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 537 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.014384, 0.79847, 0.20949, 0.0311, 0.023641, 0.0028687, 0.52826, 0.0049053, 0.45392, 0.037218]
Predicted label: 1
Correct prediction
Energy consumption = 168.440025 pJ
sum error= 264
Actual label: 7
Output voltages: [0.30174, 0.17329, 0.015602, 0.047477, 0.0043804, 0.071103, 0.001253, 0.79876, 0.19927, 0.49884]
Predicted label: 7
Correct prediction
Energy consumption = 154.646229 pJ
sum error= 264
Actual label: 7
Output voltages: [0.064786, 0.43361, 0.33574, 0.014942, 0.0023945, 0.0010702, 0.0011733, 0.79859, 0.099575, 0.041061]
Predicted label: 7
Correct prediction
Energy consumption = 140.106972 pJ
sum error= 264
Actual label: 9
Output voltages: [0.34723, 0.0090524, 0.02412, 0.11566, 0.13276, 0.0091643, 0.0021839, 0.026369, 0.31285, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 146.674532 pJ
sum error= 264
Actual label: 5
Output voltages: [0.031226, 0.0020123, 0.0010831, 0.74458, 0.013839, 0.79873, 0.014959, 0.033018, 0.75227, 0.013652]
Predicted label: 5
Correct prediction
Energy consumption = 141.535293 pJ
sum error= 264
Actual label: 9
Output voltages: [0.16687, 0.024542, 0.012676, 0.02468, 0.026931, 0.0028752, 0.0011809, 0.027715, 0.57979, 0.79819]
Predicted label: 9
Correct prediction
Energy consumption = 150.979262 pJ
sum error= 264
Actual label: 8
Output voltages: [0.026074, 0.1347, 0.40347, 0.014812, 0.13617, 0.0083063, 0.063587, 0.0032917, 0.79878, 0.069294]
Predicted label: 8
Correct prediction
Energy consumption = 144.893872 pJ
sum error= 264
Actual label: 9
Output voltages: [0.53744, 0.0017274, 0.05201, 0.0053285, 0.4499, 0.013657, 0.0021902, 0.031571, 0.48248, 0.79463]
Predicted label: 9
Correct prediction
Energy consumption = 150.247151 pJ
sum error= 264
Actual label: 6
Output voltages: [0.033363, 0.033874, 0.12093, 0.0028318, 0.14692, 0.20566, 0.79879, 0.0062141, 0.69624, 0.0013431]
Predicted label: 6
Correct prediction
Energy consumption = 145.622658 pJ
sum error= 264
Actual label: 8
Output voltages: [0.043314, 0.038101, 0.051202, 0.030879, 0.029633, 0.0030238, 0.013567, 0.031072, 0.79878, 0.082364]
Predicted label: 8
Correct prediction
Energy consumption = 151.043770 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 538 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 538 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 538 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.053463, 0.00811, 0.13564, 0.0363, 0.0071865, 0.042533, 0.0086379, 0.021214, 0.79873, 0.14992]
Predicted label: 8
Correct prediction
Energy consumption = 154.973627 pJ
sum error= 264
Actual label: 2
Output voltages: [0.74566, 0.0020315, 0.79875, 0.10016, 0.01901, 0.0011328, 0.018358, 0.098487, 0.59665, 0.014826]
Predicted label: 2
Correct prediction
Energy consumption = 143.198818 pJ
sum error= 264
Actual label: 3
Output voltages: [0.55332, 0.010208, 0.20653, 0.79873, 0.017796, 0.025288, 0.022767, 0.027978, 0.25947, 0.061125]
Predicted label: 3
Correct prediction
Energy consumption = 142.199841 pJ
sum error= 264
Actual label: 6
Output voltages: [0.09926, 0.15253, 0.14727, 0.0075611, 0.054007, 0.58994, 0.7987, 0.006946, 0.36472, 0.0036875]
Predicted label: 6
Correct prediction
Energy consumption = 149.824324 pJ
sum error= 264
Actual label: 1
Output voltages: [0.012716, 0.79847, 0.19115, 0.078042, 0.055023, 0.0010892, 0.14574, 0.019657, 0.050657, 0.023421]
Predicted label: 1
Correct prediction
Energy consumption = 162.434652 pJ
sum error= 264
Actual label: 2
Output voltages: [0.44043, 0.018526, 0.79877, 0.17434, 0.043171, 0.0011859, 0.22863, 0.035885, 0.42885, 0.017531]
Predicted label: 2
Correct prediction
Energy consumption = 150.653086 pJ
sum error= 264
Actual label: 9
Output voltages: [0.49598, 0.02, 0.018928, 0.065138, 0.22411, 0.03616, 0.0030281, 0.024346, 0.37051, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 153.396020 pJ
sum error= 264
Actual label: 8
Output voltages: [0.081316, 0.1898, 0.20978, 0.28549, 0.0074727, 0.022039, 0.02622, 0.0063637, 0.79879, 0.30997]
Predicted label: 8
Correct prediction
Energy consumption = 149.362768 pJ
sum error= 264
Actual label: 9
Output voltages: [0.43363, 0.025426, 0.0099574, 0.049583, 0.1734, 0.024725, 0.01611, 0.011093, 0.35081, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 149.857914 pJ
sum error= 264
Actual label: 5
Output voltages: [0.15378, 0.0019843, 0.013383, 0.51561, 0.0093973, 0.79867, 0.022637, 0.15514, 0.7698, 0.036778]
Predicted label: 5
Correct prediction
Energy consumption = 140.408974 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 539 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 539 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 539 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33323, 0.011163, 0.79873, 0.11192, 0.037182, 0.0010714, 0.014118, 0.0089919, 0.66149, 0.0091607]
Predicted label: 2
Correct prediction
Energy consumption = 141.698329 pJ
sum error= 264
Actual label: 6
Output voltages: [0.095373, 0.052733, 0.07461, 0.009951, 0.24441, 0.1079, 0.79878, 0.0011351, 0.60977, 0.004628]
Predicted label: 6
Correct prediction
Energy consumption = 146.220615 pJ
sum error= 264
Actual label: 2
Output voltages: [0.71155, 0.063302, 0.79876, 0.050391, 0.0034208, 0.0011111, 0.039254, 0.040508, 0.36261, 0.019151]
Predicted label: 2
Correct prediction
Energy consumption = 150.674274 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0047936, 0.0023908, 0.2876, 0.0067478, 0.79861, 0.0018973, 0.31532, 0.047781, 0.036101, 0.011914]
Predicted label: 4
Correct prediction
Energy consumption = 150.069761 pJ
sum error= 264
Actual label: 8
Output voltages: [0.20126, 0.070104, 0.04367, 0.0030751, 0.064314, 0.0013224, 0.030012, 0.0030175, 0.79827, 0.53007]
Predicted label: 8
Correct prediction
Energy consumption = 151.864563 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0051887, 0.017235, 0.048042, 0.0036233, 0.79879, 0.0022193, 0.26528, 0.051297, 0.037233, 0.0094638]
Predicted label: 4
Correct prediction
Energy consumption = 150.118669 pJ
sum error= 264
Actual label: 6
Output voltages: [0.02646, 0.0070862, 0.045266, 0.0021217, 0.37146, 0.087995, 0.79879, 0.014892, 0.59898, 0.014772]
Predicted label: 6
Correct prediction
Energy consumption = 151.321965 pJ
sum error= 264
Actual label: 5
Output voltages: [0.14262, 0.001101, 0.01903, 0.34285, 0.0080121, 0.79879, 0.018396, 0.21617, 0.79665, 0.04065]
Predicted label: 5
Correct prediction
Energy consumption = 141.935271 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79869, 0.086145, 0.12184, 0.0062787, 0.026244, 0.013602, 0.11479, 0.049099, 0.038801, 0.29181]
Predicted label: 0
Correct prediction
Energy consumption = 160.977685 pJ
sum error= 264
Actual label: 1
Output voltages: [0.041394, 0.79864, 0.46831, 0.0197, 0.043776, 0.0010665, 0.64318, 0.0089203, 0.046681, 0.023501]
Predicted label: 1
Correct prediction
Energy consumption = 157.270405 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 540 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 540 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 540 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.047951, 0.0010667, 0.001079, 0.38591, 0.11104, 0.79879, 0.41591, 0.0076105, 0.7017, 0.048515]
Predicted label: 5
Correct prediction
Energy consumption = 144.909770 pJ
sum error= 264
Actual label: 6
Output voltages: [0.25941, 0.017563, 0.166, 0.0021713, 0.54654, 0.30978, 0.79879, 0.0020811, 0.53544, 0.005977]
Predicted label: 6
Correct prediction
Energy consumption = 149.122494 pJ
sum error= 264
Actual label: 7
Output voltages: [0.13963, 0.038822, 0.033336, 0.065872, 0.010127, 0.0053014, 0.0010729, 0.79874, 0.34671, 0.55843]
Predicted label: 7
Correct prediction
Energy consumption = 158.266650 pJ
sum error= 264
Actual label: 8
Output voltages: [0.20641, 0.017608, 0.11307, 0.13764, 0.20803, 0.0010712, 0.026577, 0.0034036, 0.79707, 0.13016]
Predicted label: 8
Correct prediction
Energy consumption = 151.917352 pJ
sum error= 264
Actual label: 9
Output voltages: [0.24777, 0.010245, 0.012208, 0.14574, 0.1272, 0.0076516, 0.0029463, 0.017924, 0.63038, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 144.694934 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79776, 0.1863, 0.023461, 0.0051073, 0.017087, 0.0038224, 0.52345, 0.16974, 0.17765, 0.061244]
Predicted label: 0
Correct prediction
Energy consumption = 144.785453 pJ
sum error= 264
Actual label: 1
Output voltages: [0.0087079, 0.79879, 0.2605, 0.0061983, 0.45483, 0.0013089, 0.3689, 0.012918, 0.30655, 0.025408]
Predicted label: 1
Correct prediction
Energy consumption = 157.321980 pJ
sum error= 264
Actual label: 2
Output voltages: [0.15822, 0.040334, 0.79877, 0.041791, 0.0088706, 0.0013256, 0.054928, 0.40934, 0.39061, 0.14923]
Predicted label: 2
Correct prediction
Energy consumption = 144.259460 pJ
sum error= 264
Actual label: 3
Output voltages: [0.4227, 0.010793, 0.04777, 0.79873, 0.0049311, 0.031295, 0.0072513, 0.014558, 0.74976, 0.014823]
Predicted label: 3
Correct prediction
Energy consumption = 142.853943 pJ
sum error= 264
Actual label: 4
Output voltages: [0.18591, 0.0037621, 0.17393, 0.001862, 0.79879, 0.016539, 0.69913, 0.013036, 0.10295, 0.0095871]
Predicted label: 4
Correct prediction
Energy consumption = 154.250296 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 541 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 541 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 541 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.042776, 0.0011199, 0.0017665, 0.036843, 0.053564, 0.79863, 0.19012, 0.0049621, 0.79646, 0.011359]
Predicted label: 5
Correct prediction
Energy consumption = 147.788236 pJ
sum error= 264
Actual label: 6
Output voltages: [0.26107, 0.086206, 0.27241, 0.0032722, 0.21643, 0.30363, 0.79876, 0.001487, 0.35007, 0.012704]
Predicted label: 6
Correct prediction
Energy consumption = 141.145568 pJ
sum error= 264
Actual label: 7
Output voltages: [0.47658, 0.026926, 0.035729, 0.033792, 0.0050723, 0.0014841, 0.0010873, 0.79872, 0.63476, 0.31535]
Predicted label: 7
Correct prediction
Energy consumption = 156.980874 pJ
sum error= 264
Actual label: 8
Output voltages: [0.0048439, 0.022641, 0.031985, 0.44265, 0.03552, 0.010308, 0.013449, 0.018298, 0.79879, 0.043413]
Predicted label: 8
Correct prediction
Energy consumption = 143.736373 pJ
sum error= 264
Actual label: 9
Output voltages: [0.2032, 0.0069127, 0.022611, 0.023611, 0.05467, 0.021385, 0.0026962, 0.26306, 0.67174, 0.79377]
Predicted label: 9
Correct prediction
Energy consumption = 141.173628 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79873, 0.12713, 0.022848, 0.019095, 0.0051663, 0.022012, 0.2855, 0.015005, 0.017387, 0.031066]
Predicted label: 0
Correct prediction
Energy consumption = 145.967966 pJ
sum error= 264
Actual label: 1
Output voltages: [0.001917, 0.79854, 0.031495, 0.04197, 0.08017, 0.0033839, 0.38075, 0.0023679, 0.20844, 0.12795]
Predicted label: 1
Correct prediction
Energy consumption = 159.427955 pJ
sum error= 264
Actual label: 2
Output voltages: [0.051468, 0.35176, 0.79879, 0.32676, 0.022259, 0.0012784, 0.021818, 0.3566, 0.068932, 0.034426]
Predicted label: 2
Correct prediction
Energy consumption = 150.355689 pJ
sum error= 264
Actual label: 3
Output voltages: [0.14953, 0.0029832, 0.6834, 0.79819, 0.0029828, 0.0011091, 0.011823, 0.0075217, 0.76258, 0.0091071]
Predicted label: 3
Correct prediction
Energy consumption = 133.563024 pJ
sum error= 264
Actual label: 4
Output voltages: [0.02513, 0.023627, 0.024811, 0.016724, 0.7987, 0.020276, 0.34191, 0.084885, 0.021723, 0.0014683]
Predicted label: 4
Correct prediction
Energy consumption = 151.806752 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 542 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 542 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 542 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.034046, 0.001209, 0.0011209, 0.16307, 0.027576, 0.7987, 0.16434, 0.019759, 0.78206, 0.0031733]
Predicted label: 5
Correct prediction
Energy consumption = 143.741830 pJ
sum error= 264
Actual label: 6
Output voltages: [0.039363, 0.1365, 0.41782, 0.00107, 0.32954, 0.047586, 0.7987, 0.0012903, 0.27525, 0.0053052]
Predicted label: 6
Correct prediction
Energy consumption = 144.366421 pJ
sum error= 264
Actual label: 7
Output voltages: [0.52165, 0.0037121, 0.0087412, 0.35775, 0.017286, 0.028856, 0.001231, 0.79875, 0.46999, 0.3883]
Predicted label: 7
Correct prediction
Energy consumption = 157.128723 pJ
sum error= 264
Actual label: 8
Output voltages: [0.017649, 0.049061, 0.28318, 0.19674, 0.0042447, 0.016952, 0.03157, 0.011581, 0.79876, 0.41886]
Predicted label: 8
Correct prediction
Energy consumption = 149.966152 pJ
sum error= 264
Actual label: 9
Output voltages: [0.38483, 0.0095927, 0.011213, 0.18347, 0.24373, 0.013553, 0.0010756, 0.2403, 0.47281, 0.78781]
Predicted label: 9
Correct prediction
Energy consumption = 146.699927 pJ
sum error= 264
Actual label: 7
Output voltages: [0.3042, 0.01376, 0.035304, 0.0024033, 0.037644, 0.0016477, 0.0010683, 0.79862, 0.17218, 0.043218]
Predicted label: 7
Correct prediction
Energy consumption = 149.428378 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0012097, 0.030882, 0.067746, 0.018656, 0.79866, 0.0038156, 0.32759, 0.36814, 0.007988, 0.080109]
Predicted label: 4
Correct prediction
Energy consumption = 151.233445 pJ
sum error= 264
Actual label: 2
Output voltages: [0.10806, 0.058069, 0.79866, 0.014306, 0.0094585, 0.0011373, 0.046619, 0.012772, 0.41131, 0.027608]
Predicted label: 2
Correct prediction
Energy consumption = 150.232139 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79871, 0.027518, 0.32349, 0.020079, 0.0064641, 0.019716, 0.34984, 0.0141, 0.13414, 0.0083109]
Predicted label: 0
Correct prediction
Energy consumption = 141.945034 pJ
sum error= 264
Actual label: 9
Output voltages: [0.13278, 0.014083, 0.013374, 0.12306, 0.08029, 0.0053461, 0.0071556, 0.11409, 0.61673, 0.79811]
Predicted label: 9
Correct prediction
Energy consumption = 146.885666 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 543 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 543 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 543 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79871, 0.031197, 0.11937, 0.026034, 0.0031489, 0.013038, 0.28053, 0.025196, 0.048452, 0.042752]
Predicted label: 0
Correct prediction
Energy consumption = 148.877852 pJ
sum error= 264
Actual label: 1
Output voltages: [0.0097109, 0.79858, 0.21285, 0.022978, 0.093279, 0.0016294, 0.74627, 0.0077895, 0.28173, 0.047555]
Predicted label: 1
Correct prediction
Energy consumption = 156.716629 pJ
sum error= 264
Actual label: 5
Output voltages: [0.10874, 0.0011017, 0.00109, 0.10706, 0.16215, 0.79879, 0.36773, 0.017, 0.77368, 0.026714]
Predicted label: 5
Correct prediction
Energy consumption = 145.207971 pJ
sum error= 264
Actual label: 8
Output voltages: [0.014286, 0.2229, 0.23029, 0.061072, 0.012224, 0.010028, 0.044593, 0.13183, 0.79868, 0.092311]
Predicted label: 8
Correct prediction
Energy consumption = 150.072247 pJ
sum error= 264
Actual label: 8
Output voltages: [0.024896, 0.04971, 0.034796, 0.023377, 0.011198, 0.016163, 0.14179, 0.028953, 0.79872, 0.4599]
Predicted label: 8
Correct prediction
Energy consumption = 143.981465 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79877, 0.032676, 0.13319, 0.02813, 0.034947, 0.010586, 0.34193, 0.23406, 0.39089, 0.13223]
Predicted label: 0
Correct prediction
Energy consumption = 156.695041 pJ
sum error= 264
Actual label: 2
Output voltages: [0.56663, 0.012293, 0.79876, 0.25262, 0.030801, 0.0010676, 0.034037, 0.12676, 0.47624, 0.013855]
Predicted label: 2
Correct prediction
Energy consumption = 142.766255 pJ
sum error= 264
Actual label: 7
Output voltages: [0.046562, 0.016683, 0.035677, 0.03774, 0.0043274, 0.014692, 0.0010872, 0.79866, 0.37352, 0.46868]
Predicted label: 7
Correct prediction
Energy consumption = 147.989181 pJ
sum error= 264
Actual label: 8
Output voltages: [0.031517, 0.011485, 0.027906, 0.39878, 0.0026886, 0.02905, 0.0091459, 0.0057462, 0.79858, 0.38505]
Predicted label: 8
Correct prediction
Energy consumption = 146.408819 pJ
sum error= 264
Actual label: 4
Output voltages: [0.2373, 0.0049146, 0.11371, 0.0058625, 0.79879, 0.0024794, 0.73544, 0.022885, 0.021318, 0.0049574]
Predicted label: 4
Correct prediction
Energy consumption = 149.241019 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 544 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 544 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 544 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0094748, 0.0015256, 0.32929, 0.014682, 0.79864, 0.0010722, 0.054048, 0.067287, 0.0058398, 0.027968]
Predicted label: 4
Correct prediction
Energy consumption = 155.500115 pJ
sum error= 264
Actual label: 6
Output voltages: [0.087168, 0.38173, 0.46693, 0.016304, 0.055449, 0.030294, 0.79866, 0.0055478, 0.045863, 0.11751]
Predicted label: 6
Correct prediction
Energy consumption = 147.754940 pJ
sum error= 264
Actual label: 1
Output voltages: [0.0017575, 0.79856, 0.044281, 0.03102, 0.040038, 0.0024184, 0.70979, 0.019197, 0.085218, 0.021805]
Predicted label: 1
Correct prediction
Energy consumption = 152.522902 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79879, 0.22071, 0.010352, 0.014196, 0.0024253, 0.011345, 0.59423, 0.027466, 0.36187, 0.053637]
Predicted label: 0
Correct prediction
Energy consumption = 149.596355 pJ
sum error= 264
Actual label: 4
Output voltages: [0.034137, 0.0014329, 0.025664, 0.0023389, 0.79879, 0.0056621, 0.62983, 0.04177, 0.26334, 0.0012864]
Predicted label: 4
Correct prediction
Energy consumption = 150.677435 pJ
sum error= 264
Actual label: 5
Output voltages: [0.10178, 0.0010738, 0.0011724, 0.14532, 0.056189, 0.79866, 0.39619, 0.054407, 0.74136, 0.01229]
Predicted label: 5
Correct prediction
Energy consumption = 141.924349 pJ
sum error= 264
Actual label: 3
Output voltages: [0.13474, 0.0072613, 0.13555, 0.79873, 0.010275, 0.03692, 0.0072557, 0.019884, 0.50947, 0.036191]
Predicted label: 3
Correct prediction
Energy consumption = 141.553672 pJ
sum error= 264
Actual label: 9
Output voltages: [0.34398, 0.0023594, 0.016263, 0.014562, 0.40163, 0.0047528, 0.0023481, 0.028996, 0.50928, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 146.257813 pJ
sum error= 264
Actual label: 4
Output voltages: [0.013243, 0.022657, 0.20299, 0.050959, 0.79874, 0.0010764, 0.008457, 0.11027, 0.0050984, 0.3191]
Predicted label: 4
Correct prediction
Energy consumption = 146.217801 pJ
sum error= 264
Actual label: 2
Output voltages: [0.39641, 0.0029618, 0.79686, 0.45087, 0.023801, 0.0010723, 0.0061744, 0.069523, 0.78063, 0.055647]
Predicted label: 2
Correct prediction
Energy consumption = 146.312043 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 545 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 545 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 545 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.78714, 0.014369, 0.0017546, 0.059623, 0.00357, 0.23962, 0.27148, 0.47363, 0.49867, 0.19353]
Predicted label: 0
Correct prediction
Energy consumption = 146.873060 pJ
sum error= 264
Actual label: 5
Output voltages: [0.030507, 0.0010841, 0.0032694, 0.17662, 0.014782, 0.79877, 0.54639, 0.027946, 0.7462, 0.0044199]
Predicted label: 5
Correct prediction
Energy consumption = 140.076808 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79875, 0.090155, 0.016058, 0.010895, 0.0085248, 0.009579, 0.41986, 0.033861, 0.1101, 0.046943]
Predicted label: 0
Correct prediction
Energy consumption = 141.513138 pJ
sum error= 264
Actual label: 1
Output voltages: [0.028495, 0.7985, 0.022803, 0.058199, 0.066899, 0.0019299, 0.53125, 0.0099035, 0.07776, 0.066407]
Predicted label: 1
Correct prediction
Energy consumption = 164.022062 pJ
sum error= 264
Actual label: 3
Output voltages: [0.06125, 0.0029108, 0.013465, 0.79879, 0.14143, 0.30759, 0.026283, 0.0024894, 0.63545, 0.049974]
Predicted label: 3
Correct prediction
Energy consumption = 149.092574 pJ
sum error= 264
Actual label: 2
Output voltages: [0.43148, 0.015115, 0.79879, 0.19396, 0.024887, 0.0012454, 0.23563, 0.069876, 0.63025, 0.039085]
Predicted label: 2
Correct prediction
Energy consumption = 146.660335 pJ
sum error= 264
Actual label: 9
Output voltages: [0.15498, 0.031872, 0.04495, 0.051632, 0.04343, 0.027441, 0.01311, 0.11154, 0.44859, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 150.510507 pJ
sum error= 264
Actual label: 1
Output voltages: [0.57773, 0.79857, 0.02964, 0.10497, 0.29947, 0.002298, 0.33551, 0.0013635, 0.7154, 0.14695]
Predicted label: 1
Correct prediction
Energy consumption = 160.742288 pJ
sum error= 264
Actual label: 6
Output voltages: [0.074291, 0.11105, 0.42542, 0.0010664, 0.2069, 0.038648, 0.79876, 0.0010697, 0.34138, 0.0029649]
Predicted label: 6
Correct prediction
Energy consumption = 149.558700 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79879, 0.030254, 0.034437, 0.024975, 0.0022879, 0.012305, 0.34797, 0.070696, 0.27946, 0.027796]
Predicted label: 0
Correct prediction
Energy consumption = 141.313423 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 546 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 546 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 546 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.03367, 0.79864, 0.021995, 0.011038, 0.33327, 0.016278, 0.66025, 0.0040758, 0.20769, 0.13958]
Predicted label: 1
Correct prediction
Energy consumption = 161.163306 pJ
sum error= 264
Actual label: 1
Output voltages: [0.018138, 0.79872, 0.45039, 0.0068536, 0.094632, 0.0010672, 0.35073, 0.0081517, 0.15223, 0.016222]
Predicted label: 1
Correct prediction
Energy consumption = 144.221819 pJ
sum error= 264
Actual label: 8
Output voltages: [0.0095368, 0.011474, 0.039535, 0.28801, 0.0079225, 0.024544, 0.0061012, 0.0029797, 0.79878, 0.039305]
Predicted label: 8
Correct prediction
Energy consumption = 147.281896 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79876, 0.0057501, 0.019941, 0.0078874, 0.030811, 0.023611, 0.4866, 0.01509, 0.089972, 0.029436]
Predicted label: 0
Correct prediction
Energy consumption = 148.594839 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0054548, 0.0033813, 0.022417, 0.011709, 0.79814, 0.079259, 0.090525, 0.028014, 0.22007, 0.16904]
Predicted label: 4
Correct prediction
Energy consumption = 159.448484 pJ
sum error= 264
Actual label: 7
Output voltages: [0.20853, 0.034175, 0.015343, 0.045112, 0.0064741, 0.0063107, 0.0010775, 0.79868, 0.45856, 0.35437]
Predicted label: 7
Correct prediction
Energy consumption = 155.914466 pJ
sum error= 264
Actual label: 7
Output voltages: [0.3288, 0.047119, 0.03757, 0.014512, 0.0060294, 0.0010718, 0.0011064, 0.79875, 0.50421, 0.15617]
Predicted label: 7
Correct prediction
Energy consumption = 134.261297 pJ
sum error= 264
Actual label: 6
Output voltages: [0.062435, 0.036815, 0.27346, 0.0017547, 0.36595, 0.16885, 0.79873, 0.0022438, 0.41794, 0.0054824]
Predicted label: 6
Correct prediction
Energy consumption = 149.287826 pJ
sum error= 264
Actual label: 3
Output voltages: [0.31526, 0.0011409, 0.50725, 0.79725, 0.0037408, 0.021675, 0.002915, 0.0015686, 0.71807, 0.011141]
Predicted label: 3
Correct prediction
Energy consumption = 146.692962 pJ
sum error= 264
Actual label: 6
Output voltages: [0.20573, 0.064077, 0.24138, 0.0014483, 0.57857, 0.11582, 0.79875, 0.0010811, 0.42742, 0.003629]
Predicted label: 6
Correct prediction
Energy consumption = 147.498862 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 547 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 547 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 547 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.014612, 0.019597, 0.055821, 0.0026685, 0.063919, 0.60896, 0.20337, 0.23683, 0.019315]
Predicted label: 0
Correct prediction
Energy consumption = 150.028408 pJ
sum error= 264
Actual label: 7
Output voltages: [0.29839, 0.01734, 0.065882, 0.55491, 0.011163, 0.0053278, 0.0012729, 0.79878, 0.19272, 0.50181]
Predicted label: 7
Correct prediction
Energy consumption = 153.720054 pJ
sum error= 264
Actual label: 3
Output voltages: [0.48581, 0.0042117, 0.088647, 0.79872, 0.010835, 0.0071608, 0.0023957, 0.028853, 0.75678, 0.0023901]
Predicted label: 3
Correct prediction
Energy consumption = 141.374236 pJ
sum error= 264
Actual label: 5
Output voltages: [0.03476, 0.0013473, 0.0031097, 0.4609, 0.025491, 0.79861, 0.39202, 0.016693, 0.78153, 0.033687]
Predicted label: 5
Correct prediction
Energy consumption = 141.135480 pJ
sum error= 264
Actual label: 4
Output voltages: [0.048503, 0.0044103, 0.16127, 0.0037629, 0.79869, 0.026144, 0.60319, 0.09367, 0.028763, 0.0028871]
Predicted label: 4
Correct prediction
Energy consumption = 151.759045 pJ
sum error= 264
Actual label: 2
Output voltages: [0.47129, 0.049875, 0.79872, 0.048818, 0.023677, 0.0012289, 0.42264, 0.046651, 0.62329, 0.035783]
Predicted label: 2
Correct prediction
Energy consumption = 148.074521 pJ
sum error= 264
Actual label: 4
Output voltages: [0.034304, 0.0031063, 0.37045, 0.0012823, 0.79862, 0.0051907, 0.64903, 0.11161, 0.049107, 0.0079121]
Predicted label: 4
Correct prediction
Energy consumption = 148.756186 pJ
sum error= 264
Actual label: 1
Output voltages: [0.020462, 0.7986, 0.03963, 0.023431, 0.17892, 0.0012116, 0.63951, 0.018205, 0.028558, 0.10597]
Predicted label: 1
Correct prediction
Energy consumption = 154.880317 pJ
sum error= 264
Actual label: 8
Output voltages: [0.011999, 0.14759, 0.1216, 0.04912, 0.010345, 0.0032127, 0.024526, 0.026694, 0.79871, 0.34171]
Predicted label: 8
Correct prediction
Energy consumption = 148.958529 pJ
sum error= 264
Actual label: 3
Output voltages: [0.24847, 0.01953, 0.028912, 0.79866, 0.019489, 0.4337, 0.0050551, 0.0059718, 0.60962, 0.025027]
Predicted label: 3
Correct prediction
Energy consumption = 142.343288 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 548 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 548 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 548 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.032058, 0.0010671, 0.0021013, 0.29777, 0.032148, 0.79873, 0.53007, 0.0075341, 0.77175, 0.0049749]
Predicted label: 5
Correct prediction
Energy consumption = 143.087670 pJ
sum error= 264
Actual label: 6
Output voltages: [0.10381, 0.25736, 0.15113, 0.0030228, 0.37007, 0.72931, 0.79869, 0.0021471, 0.28926, 0.008035]
Predicted label: 6
Correct prediction
Energy consumption = 137.748224 pJ
sum error= 264
Actual label: 7
Output voltages: [0.050962, 0.062713, 0.11737, 0.14788, 0.0040224, 0.0010661, 0.0010831, 0.79866, 0.43773, 0.13237]
Predicted label: 7
Correct prediction
Energy consumption = 155.038063 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79732, 0.054939, 0.024698, 0.011579, 0.049637, 0.01306, 0.70439, 0.046272, 0.11244, 0.041139]
Predicted label: 0
Correct prediction
Energy consumption = 151.299814 pJ
sum error= 264
Actual label: 6
Output voltages: [0.13176, 0.095948, 0.25138, 0.0021469, 0.31409, 0.15952, 0.79873, 0.001356, 0.33394, 0.011195]
Predicted label: 6
Correct prediction
Energy consumption = 143.402695 pJ
sum error= 264
Actual label: 7
Output voltages: [0.25246, 0.013495, 0.049566, 0.048219, 0.0034423, 0.0031788, 0.0011947, 0.79863, 0.61553, 0.21325]
Predicted label: 7
Correct prediction
Energy consumption = 157.443578 pJ
sum error= 264
Actual label: 1
Output voltages: [0.14475, 0.79877, 0.10483, 0.0026631, 0.53434, 0.0021937, 0.34919, 0.0010737, 0.026238, 0.13471]
Predicted label: 1
Correct prediction
Energy consumption = 155.280514 pJ
sum error= 264
Actual label: 2
Output voltages: [0.4343, 0.046867, 0.7987, 0.062836, 0.017861, 0.0012721, 0.14651, 0.052343, 0.35291, 0.025236]
Predicted label: 2
Correct prediction
Energy consumption = 143.690884 pJ
sum error= 264
Actual label: 5
Output voltages: [0.027329, 0.00109, 0.021251, 0.43886, 0.018658, 0.79874, 0.027926, 0.24416, 0.77925, 0.14267]
Predicted label: 5
Correct prediction
Energy consumption = 144.455459 pJ
sum error= 264
Actual label: 8
Output voltages: [0.0052567, 0.081304, 0.23169, 0.028543, 0.014693, 0.0039748, 0.025408, 0.052558, 0.79872, 0.20578]
Predicted label: 8
Correct prediction
Energy consumption = 142.821321 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 549 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 549 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 549 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.037908, 0.79877, 0.071482, 0.012008, 0.063931, 0.0010909, 0.11454, 0.053898, 0.12585, 0.12751]
Predicted label: 1
Correct prediction
Energy consumption = 161.229091 pJ
sum error= 264
Actual label: 9
Output voltages: [0.29033, 0.011581, 0.032264, 0.025345, 0.46967, 0.0063747, 0.0071422, 0.0023942, 0.36958, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 152.514978 pJ
sum error= 264
Actual label: 3
Output voltages: [0.35333, 0.0016678, 0.68743, 0.7987, 0.0054318, 0.012851, 0.024592, 0.0058011, 0.79416, 0.01659]
Predicted label: 3
Correct prediction
Energy consumption = 142.475419 pJ
sum error= 264
Actual label: 8
Output voltages: [0.020152, 0.0055901, 0.21911, 0.14761, 0.0011228, 0.23912, 0.0055518, 0.096308, 0.79872, 0.016794]
Predicted label: 8
Correct prediction
Energy consumption = 143.704025 pJ
sum error= 264
Actual label: 2
Output voltages: [0.19503, 0.037968, 0.79877, 0.11486, 0.01777, 0.0012441, 0.22517, 0.0087692, 0.58592, 0.026067]
Predicted label: 2
Correct prediction
Energy consumption = 145.198024 pJ
sum error= 264
Actual label: 8
Output voltages: [0.014219, 0.032247, 0.043898, 0.22429, 0.0043635, 0.023449, 0.0082308, 0.029666, 0.79876, 0.24062]
Predicted label: 8
Correct prediction
Energy consumption = 144.767847 pJ
sum error= 264
Actual label: 7
Output voltages: [0.067288, 0.15472, 0.52669, 0.14375, 0.0014569, 0.0010674, 0.0010659, 0.79878, 0.65607, 0.17497]
Predicted label: 7
Correct prediction
Energy consumption = 146.683034 pJ
sum error= 264
Actual label: 6
Output voltages: [0.096624, 0.032143, 0.3751, 0.0010943, 0.21866, 0.037417, 0.79878, 0.0013431, 0.31021, 0.0012056]
Predicted label: 6
Correct prediction
Energy consumption = 145.563667 pJ
sum error= 264
Actual label: 7
Output voltages: [0.17978, 0.029089, 0.23198, 0.52217, 0.0050612, 0.0040013, 0.0012126, 0.79862, 0.57441, 0.11788]
Predicted label: 7
Correct prediction
Energy consumption = 158.245424 pJ
sum error= 264
Actual label: 1
Output voltages: [0.030325, 0.79879, 0.069031, 0.0092069, 0.30541, 0.0010659, 0.0052607, 0.28049, 0.033789, 0.12008]
Predicted label: 1
Correct prediction
Energy consumption = 152.158991 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 550 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 550 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 550 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.018892, 0.0065877, 0.059885, 0.0065947, 0.79868, 0.0030519, 0.16099, 0.40934, 0.03183, 0.0043243]
Predicted label: 4
Correct prediction
Energy consumption = 147.976121 pJ
sum error= 264
Actual label: 6
Output voltages: [0.056519, 0.05048, 0.36448, 0.0013996, 0.56139, 0.12916, 0.79868, 0.0022036, 0.36407, 0.0054691]
Predicted label: 6
Correct prediction
Energy consumption = 145.017678 pJ
sum error= 264
Actual label: 2
Output voltages: [0.57516, 0.017066, 0.79879, 0.34132, 0.02051, 0.0011224, 0.28099, 0.022121, 0.57947, 0.016348]
Predicted label: 2
Correct prediction
Energy consumption = 146.948671 pJ
sum error= 264
Actual label: 9
Output voltages: [0.39576, 0.0097906, 0.022915, 0.31283, 0.31288, 0.043727, 0.0070586, 0.10602, 0.5882, 0.79805]
Predicted label: 9
Correct prediction
Energy consumption = 148.641425 pJ
sum error= 264
Actual label: 3
Output voltages: [0.42255, 0.0034863, 0.11654, 0.79875, 0.0071741, 0.10055, 0.0023067, 0.016954, 0.76167, 0.027145]
Predicted label: 3
Correct prediction
Energy consumption = 144.697209 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79878, 0.069259, 0.017316, 0.031441, 0.011516, 0.2287, 0.57459, 0.025815, 0.46627, 0.047476]
Predicted label: 0
Correct prediction
Energy consumption = 157.720170 pJ
sum error= 264
Actual label: 1
Output voltages: [0.01192, 0.79859, 0.083374, 0.25995, 0.011684, 0.0012399, 0.14194, 0.011916, 0.36731, 0.028902]
Predicted label: 1
Correct prediction
Energy consumption = 159.308650 pJ
sum error= 264
Actual label: 2
Output voltages: [0.28749, 0.36706, 0.7985, 0.098647, 0.026187, 0.0013072, 0.58431, 0.015659, 0.38549, 0.016585]
Predicted label: 2
Correct prediction
Energy consumption = 142.261646 pJ
sum error= 264
Actual label: 3
Output voltages: [0.053799, 0.019303, 0.088117, 0.79868, 0.030574, 0.037519, 0.032745, 0.024646, 0.37442, 0.12915]
Predicted label: 3
Correct prediction
Energy consumption = 145.548957 pJ
sum error= 264
Actual label: 4
Output voltages: [0.019297, 0.011806, 0.18714, 0.022602, 0.79877, 0.0013286, 0.30522, 0.12925, 0.0088757, 0.73373]
Predicted label: 4
Correct prediction
Energy consumption = 154.483756 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 551 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 551 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 551 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.016186, 0.0010771, 0.0034747, 0.75282, 0.01151, 0.78269, 0.064344, 0.05716, 0.58755, 0.018838]
Predicted label: 5
Correct prediction
Energy consumption = 146.325620 pJ
sum error= 264
Actual label: 6
Output voltages: [0.17218, 0.063335, 0.30029, 0.0044332, 0.41126, 0.39913, 0.79866, 0.0025529, 0.3418, 0.0078551]
Predicted label: 6
Correct prediction
Energy consumption = 150.054695 pJ
sum error= 264
Actual label: 7
Output voltages: [0.081553, 0.063985, 0.012838, 0.0087683, 0.022076, 0.015823, 0.0011474, 0.79868, 0.1445, 0.43703]
Predicted label: 7
Correct prediction
Energy consumption = 160.303875 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79871, 0.1519, 0.042273, 0.015025, 0.0059617, 0.029804, 0.62622, 0.0036577, 0.036718, 0.01825]
Predicted label: 0
Correct prediction
Energy consumption = 157.086848 pJ
sum error= 264
Actual label: 1
Output voltages: [0.018687, 0.7986, 0.1082, 0.074477, 0.017467, 0.0013197, 0.17105, 0.0034989, 0.18557, 0.12204]
Predicted label: 1
Correct prediction
Energy consumption = 166.017227 pJ
sum error= 264
Actual label: 2
Output voltages: [0.34635, 0.72146, 0.7849, 0.56201, 0.025482, 0.0012815, 0.33358, 0.0011119, 0.20063, 0.01207]
Predicted label: 2
Correct prediction
Energy consumption = 148.563251 pJ
sum error= 264
Actual label: 3
Output voltages: [0.5411, 0.029282, 0.045674, 0.79869, 0.0047284, 0.030183, 0.021064, 0.034479, 0.44347, 0.019896]
Predicted label: 3
Correct prediction
Energy consumption = 139.353858 pJ
sum error= 264
Actual label: 4
Output voltages: [0.018378, 0.012609, 0.059757, 0.011041, 0.79863, 0.0018419, 0.10117, 0.052861, 0.12833, 0.05561]
Predicted label: 4
Correct prediction
Energy consumption = 163.489669 pJ
sum error= 264
Actual label: 5
Output voltages: [0.24569, 0.001206, 0.024388, 0.35473, 0.016754, 0.79873, 0.13834, 0.017982, 0.78616, 0.037022]
Predicted label: 5
Correct prediction
Energy consumption = 145.579062 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79303, 0.047781, 0.013127, 0.011814, 0.036044, 0.2168, 0.78616, 0.016394, 0.24086, 0.045527]
Predicted label: 0
Correct prediction
Energy consumption = 153.403299 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 552 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 552 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 552 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.021998, 0.79847, 0.063595, 0.27987, 0.1925, 0.033834, 0.30315, 0.019304, 0.011691, 0.19467]
Predicted label: 1
Correct prediction
Energy consumption = 165.860355 pJ
sum error= 264
Actual label: 2
Output voltages: [0.38725, 0.44513, 0.79852, 0.040149, 0.0086972, 0.0013914, 0.5239, 0.0037332, 0.43334, 0.047247]
Predicted label: 2
Correct prediction
Energy consumption = 148.004258 pJ
sum error= 264
Actual label: 8
Output voltages: [0.39237, 0.0065953, 0.30075, 0.035499, 0.010495, 0.037319, 0.0013211, 0.0020711, 0.79878, 0.33556]
Predicted label: 8
Correct prediction
Energy consumption = 148.041606 pJ
sum error= 264
Actual label: 9
Output voltages: [0.30218, 0.0011463, 0.020273, 0.037859, 0.11875, 0.0070803, 0.0017672, 0.23452, 0.30141, 0.79757]
Predicted label: 9
Correct prediction
Energy consumption = 154.216061 pJ
sum error= 264
Actual label: 1
Output voltages: [0.037249, 0.7984, 0.12757, 0.22917, 0.066563, 0.0081637, 0.17924, 0.010206, 0.071382, 0.16175]
Predicted label: 1
Correct prediction
Energy consumption = 170.181409 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0097374, 0.037983, 0.093109, 0.0013949, 0.79874, 0.0010867, 0.17841, 0.014434, 0.017898, 0.29649]
Predicted label: 4
Correct prediction
Energy consumption = 149.141562 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79868, 0.062483, 0.061529, 0.01067, 0.029342, 0.0054206, 0.23153, 0.070223, 0.56908, 0.1582]
Predicted label: 0
Correct prediction
Energy consumption = 160.313584 pJ
sum error= 264
Actual label: 9
Output voltages: [0.42081, 0.010683, 0.064335, 0.050996, 0.39342, 0.030014, 0.031303, 0.0040936, 0.067372, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 153.268301 pJ
sum error= 264
Actual label: 5
Output voltages: [0.034061, 0.0031046, 0.0055546, 0.39955, 0.011848, 0.79851, 0.045675, 0.066188, 0.78386, 0.13714]
Predicted label: 5
Correct prediction
Energy consumption = 147.520278 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79876, 0.098899, 0.054279, 0.024986, 0.025346, 0.024533, 0.54043, 0.033704, 0.11433, 0.059935]
Predicted label: 0
Correct prediction
Energy consumption = 156.121271 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 553 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 553 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 553 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.41921, 0.010727, 0.20774, 0.61733, 0.0035973, 0.25371, 0.029026, 0.0013237, 0.79878, 0.31394]
Predicted label: 8
Correct prediction
Energy consumption = 155.033167 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79873, 0.015973, 0.025373, 0.0087431, 0.018311, 0.0050059, 0.5985, 0.0024763, 0.045349, 0.034856]
Predicted label: 0
Correct prediction
Energy consumption = 151.147426 pJ
sum error= 264
Actual label: 7
Output voltages: [0.20748, 0.040903, 0.0012068, 0.068511, 0.035827, 0.0057809, 0.0010724, 0.79857, 0.41769, 0.41725]
Predicted label: 7
Correct prediction
Energy consumption = 159.500131 pJ
sum error= 264
Actual label: 7
Output voltages: [0.078028, 0.020826, 0.019537, 0.067532, 0.036558, 0.0029278, 0.0010659, 0.79864, 0.27103, 0.35095]
Predicted label: 7
Correct prediction
Energy consumption = 146.043096 pJ
sum error= 264
Actual label: 1
Output voltages: [0.0063784, 0.79851, 0.1364, 0.22357, 0.042775, 0.0011251, 0.48174, 0.0077846, 0.20724, 0.044126]
Predicted label: 1
Correct prediction
Energy consumption = 163.814992 pJ
sum error= 264
Actual label: 1
Output voltages: [0.065609, 0.79854, 0.066945, 0.27085, 0.038563, 0.0011142, 0.27716, 0.0081216, 0.018985, 0.51929]
Predicted label: 1
Correct prediction
Energy consumption = 153.878975 pJ
sum error= 264
Actual label: 2
Output voltages: [0.32911, 0.10591, 0.79872, 0.053725, 0.0079544, 0.0012784, 0.24788, 0.044938, 0.48415, 0.025336]
Predicted label: 2
Correct prediction
Energy consumption = 149.912461 pJ
sum error= 264
Actual label: 9
Output voltages: [0.39137, 0.024804, 0.024182, 0.20451, 0.052545, 0.036814, 0.021192, 0.01963, 0.089898, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 158.693091 pJ
sum error= 264
Actual label: 3
Output voltages: [0.025806, 0.0092893, 0.046655, 0.79879, 0.010483, 0.010026, 0.0077053, 0.012959, 0.7695, 0.02477]
Predicted label: 3
Correct prediction
Energy consumption = 138.367444 pJ
sum error= 264
Actual label: 6
Output voltages: [0.71624, 0.28957, 0.057767, 0.017394, 0.23403, 0.019836, 0.79792, 0.0010918, 0.49445, 0.0036045]
Predicted label: 6
Correct prediction
Energy consumption = 155.787045 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 554 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 554 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 554 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.075444, 0.030715, 0.36139, 0.040884, 0.0011172, 0.0011119, 0.0010684, 0.7987, 0.33359, 0.049811]
Predicted label: 7
Correct prediction
Energy consumption = 157.763056 pJ
sum error= 264
Actual label: 2
Output voltages: [0.42152, 0.13675, 0.79874, 0.22525, 0.031346, 0.0012435, 0.27945, 0.018406, 0.43027, 0.046288]
Predicted label: 2
Correct prediction
Energy consumption = 146.763320 pJ
sum error= 264
Actual label: 3
Output voltages: [0.22725, 0.0060672, 0.36643, 0.7987, 0.039422, 0.015437, 0.0088432, 0.043657, 0.31552, 0.080081]
Predicted label: 3
Correct prediction
Energy consumption = 140.133357 pJ
sum error= 264
Actual label: 8
Output voltages: [0.26229, 0.016087, 0.38784, 0.40789, 0.022645, 0.018693, 0.025197, 0.002076, 0.79877, 0.25033]
Predicted label: 8
Correct prediction
Energy consumption = 150.161091 pJ
sum error= 264
Actual label: 1
Output voltages: [0.01691, 0.79862, 0.36468, 0.073379, 0.18725, 0.0011026, 0.3689, 0.0020837, 0.070149, 0.03446]
Predicted label: 1
Correct prediction
Energy consumption = 166.293583 pJ
sum error= 264
Actual label: 2
Output voltages: [0.47171, 0.0066657, 0.7986, 0.26329, 0.027904, 0.0011715, 0.23279, 0.054441, 0.7602, 0.014071]
Predicted label: 2
Correct prediction
Energy consumption = 144.470546 pJ
sum error= 264
Actual label: 9
Output voltages: [0.26071, 0.023667, 0.038299, 0.04876, 0.52544, 0.0024721, 0.024166, 0.0021072, 0.30634, 0.78952]
Predicted label: 9
Correct prediction
Energy consumption = 147.689044 pJ
sum error= 264
Actual label: 8
Output voltages: [0.38095, 0.018677, 0.10826, 0.66353, 0.0060259, 0.040592, 0.10374, 0.0010659, 0.79847, 0.35134]
Predicted label: 8
Correct prediction
Energy consumption = 154.292096 pJ
sum error= 264
Actual label: 8
Output voltages: [0.45469, 0.0061851, 0.51709, 0.10284, 0.018196, 0.0026368, 0.021913, 0.004341, 0.79874, 0.2259]
Predicted label: 8
Correct prediction
Energy consumption = 141.860919 pJ
sum error= 264
Actual label: 7
Output voltages: [0.036481, 0.048135, 0.068372, 0.025409, 0.001634, 0.0012191, 0.0020997, 0.79874, 0.34707, 0.062963]
Predicted label: 7
Correct prediction
Energy consumption = 159.433860 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 555 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 555 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 555 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.035409, 0.79835, 0.036639, 0.33922, 0.019589, 0.0081508, 0.74502, 0.0012211, 0.035693, 0.20064]
Predicted label: 1
Correct prediction
Energy consumption = 161.789290 pJ
sum error= 264
Actual label: 7
Output voltages: [0.33002, 0.12149, 0.0085346, 0.0091603, 0.0024814, 0.013438, 0.001661, 0.79878, 0.25514, 0.41012]
Predicted label: 7
Correct prediction
Energy consumption = 162.998716 pJ
sum error= 264
Actual label: 1
Output voltages: [0.46316, 0.79877, 0.48816, 0.38277, 0.20201, 0.0011909, 0.04509, 0.0015628, 0.01759, 0.090727]
Predicted label: 1
Correct prediction
Energy consumption = 161.167925 pJ
sum error= 264
Actual label: 1
Output voltages: [0.034537, 0.79837, 0.13072, 0.12402, 0.011614, 0.0027952, 0.71713, 0.0043523, 0.028013, 0.081836]
Predicted label: 1
Correct prediction
Energy consumption = 150.236075 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79879, 0.067448, 0.0056433, 0.031778, 0.0089033, 0.18324, 0.71199, 0.017083, 0.28009, 0.019349]
Predicted label: 0
Correct prediction
Energy consumption = 156.141036 pJ
sum error= 264
Actual label: 3
Output voltages: [0.25199, 0.0067654, 0.1257, 0.79866, 0.026549, 0.065663, 0.029369, 0.040605, 0.74334, 0.11233]
Predicted label: 3
Correct prediction
Energy consumption = 148.215382 pJ
sum error= 264
Actual label: 4
Output voltages: [0.23268, 0.0027485, 0.21152, 0.0011859, 0.79878, 0.0011377, 0.039623, 0.01762, 0.048894, 0.13774]
Predicted label: 4
Correct prediction
Energy consumption = 146.339671 pJ
sum error= 264
Actual label: 2
Output voltages: [0.37344, 0.038509, 0.79871, 0.14186, 0.0020801, 0.0011891, 0.15479, 0.15049, 0.71099, 0.01203]
Predicted label: 2
Correct prediction
Energy consumption = 148.803600 pJ
sum error= 264
Actual label: 6
Output voltages: [0.094347, 0.030806, 0.18127, 0.0010737, 0.38124, 0.065724, 0.79878, 0.0018902, 0.49081, 0.003532]
Predicted label: 6
Correct prediction
Energy consumption = 142.729093 pJ
sum error= 264
Actual label: 4
Output voltages: [0.043377, 0.0066074, 0.3371, 0.0024296, 0.79872, 0.0010703, 0.3498, 0.0050189, 0.02109, 0.085511]
Predicted label: 4
Correct prediction
Energy consumption = 145.829462 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 556 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 556 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 556 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28284, 0.015691, 0.012768, 0.049822, 0.011564, 0.012862, 0.001134, 0.79875, 0.54283, 0.5646]
Predicted label: 7
Correct prediction
Energy consumption = 158.619431 pJ
sum error= 264
Actual label: 4
Output voltages: [0.17658, 0.018803, 0.23192, 0.0010714, 0.79877, 0.0010795, 0.30296, 0.0012156, 0.1315, 0.19165]
Predicted label: 4
Correct prediction
Energy consumption = 146.408719 pJ
sum error= 264
Actual label: 2
Output voltages: [0.034266, 0.36302, 0.79856, 0.30304, 0.0047563, 0.0012646, 0.19957, 0.025506, 0.49579, 0.063465]
Predicted label: 2
Correct prediction
Energy consumption = 150.858206 pJ
sum error= 264
Actual label: 7
Output voltages: [0.05799, 0.11562, 0.3148, 0.14192, 0.0038816, 0.0010675, 0.0011021, 0.79866, 0.58345, 0.24832]
Predicted label: 7
Correct prediction
Energy consumption = 159.543736 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0099108, 0.02782, 0.36895, 0.0011405, 0.79741, 0.0010765, 0.68196, 0.098567, 0.33962, 0.035381]
Predicted label: 4
Correct prediction
Energy consumption = 142.404865 pJ
sum error= 264
Actual label: 9
Output voltages: [0.48608, 0.014115, 0.018283, 0.021521, 0.40398, 0.011882, 0.0063215, 0.016895, 0.086111, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 155.210763 pJ
sum error= 264
Actual label: 1
Output voltages: [0.12697, 0.79855, 0.039226, 0.1991, 0.0093287, 0.0073134, 0.75565, 0.0047281, 0.027471, 0.052298]
Predicted label: 1
Correct prediction
Energy consumption = 162.858552 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79846, 0.03395, 0.033515, 0.022234, 0.021401, 0.015949, 0.75607, 0.021984, 0.0541, 0.097086]
Predicted label: 0
Correct prediction
Energy consumption = 159.041009 pJ
sum error= 264
Actual label: 6
Output voltages: [0.2252, 0.27819, 0.37617, 0.0069672, 0.23348, 0.12591, 0.79868, 0.0014118, 0.24213, 0.034578]
Predicted label: 6
Correct prediction
Energy consumption = 140.002278 pJ
sum error= 264
Actual label: 8
Output voltages: [0.27153, 0.013392, 0.59945, 0.024374, 0.0089479, 0.014732, 0.0033575, 0.0039178, 0.79879, 0.36539]
Predicted label: 8
Correct prediction
Energy consumption = 147.645603 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 557 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 557 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 557 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.018494, 0.001066, 0.0023893, 0.15482, 0.018188, 0.79879, 0.24378, 0.079844, 0.72756, 0.051357]
Predicted label: 5
Correct prediction
Energy consumption = 147.043076 pJ
sum error= 264
Actual label: 5
Output voltages: [0.0047861, 0.0011831, 0.0034125, 0.59897, 0.043258, 0.79817, 0.0356, 0.135, 0.76581, 0.10432]
Predicted label: 5
Correct prediction
Energy consumption = 130.837861 pJ
sum error= 264
Actual label: 5
Output voltages: [0.23192, 0.0011145, 0.0014704, 0.33674, 0.046173, 0.79879, 0.11934, 0.043115, 0.76475, 0.032886]
Predicted label: 5
Correct prediction
Energy consumption = 131.200097 pJ
sum error= 264
Actual label: 3
Output voltages: [0.20432, 0.0017676, 0.066593, 0.79875, 0.030255, 0.31225, 0.010546, 0.022609, 0.7345, 0.026634]
Predicted label: 3
Correct prediction
Energy consumption = 140.287739 pJ
sum error= 264
Actual label: 5
Output voltages: [0.035279, 0.0010809, 0.002046, 0.31719, 0.066269, 0.79875, 0.022859, 0.17871, 0.77592, 0.03481]
Predicted label: 5
Correct prediction
Energy consumption = 140.481010 pJ
sum error= 264
Actual label: 9
Output voltages: [0.23654, 0.023682, 0.025388, 0.031153, 0.25579, 0.0052813, 0.019607, 0.026969, 0.13562, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 155.041633 pJ
sum error= 264
Actual label: 7
Output voltages: [0.03516, 0.10055, 0.40233, 0.030438, 0.017752, 0.0011153, 0.0018557, 0.79868, 0.090552, 0.094238]
Predicted label: 7
Correct prediction
Energy consumption = 147.625659 pJ
sum error= 264
Actual label: 4
Output voltages: [0.0096179, 0.021172, 0.015215, 0.063556, 0.79879, 0.001099, 0.11794, 0.030023, 0.013554, 0.017823]
Predicted label: 4
Correct prediction
Energy consumption = 149.989308 pJ
sum error= 264
Actual label: 8
Output voltages: [0.20175, 0.047548, 0.1481, 0.23695, 0.042487, 0.0041067, 0.2066, 0.0010729, 0.79763, 0.63159]
Predicted label: 8
Correct prediction
Energy consumption = 161.821642 pJ
sum error= 264
Actual label: 5
Output voltages: [0.041149, 0.0011436, 0.0030263, 0.15735, 0.057341, 0.79854, 0.18198, 0.027301, 0.7908, 0.020821]
Predicted label: 5
Correct prediction
Energy consumption = 139.349971 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 558 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 558 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 558 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.34923, 0.020997, 0.11294, 0.14083, 0.24405, 0.039024, 0.023812, 0.01762, 0.073791, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 158.571271 pJ
sum error= 264
Actual label: 6
Output voltages: [0.024047, 0.18068, 0.3412, 0.0034145, 0.17425, 0.19863, 0.79866, 0.0025673, 0.54453, 0.015625]
Predicted label: 6
Correct prediction
Energy consumption = 149.229784 pJ
sum error= 264
Actual label: 9
Output voltages: [0.53173, 0.015682, 0.022127, 0.025621, 0.23324, 0.043751, 0.0025685, 0.023874, 0.36208, 0.79841]
Predicted label: 9
Correct prediction
Energy consumption = 155.017177 pJ
sum error= 264
Actual label: 3
Output voltages: [0.0559, 0.0082381, 0.030316, 0.79879, 0.012525, 0.046983, 0.003289, 0.023641, 0.72096, 0.045776]
Predicted label: 3
Correct prediction
Energy consumption = 142.432551 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79877, 0.39676, 0.024803, 0.012344, 0.027255, 0.021229, 0.68989, 0.01826, 0.050087, 0.074504]
Predicted label: 0
Correct prediction
Energy consumption = 155.802283 pJ
sum error= 264
Actual label: 3
Output voltages: [0.15063, 0.026857, 0.039592, 0.7986, 0.027042, 0.0069726, 0.023847, 0.033695, 0.59988, 0.045752]
Predicted label: 3
Correct prediction
Energy consumption = 146.246989 pJ
sum error= 264
Actual label: 8
Output voltages: [0.44632, 0.0090802, 0.38474, 0.44022, 0.0092466, 0.0023232, 0.013394, 0.0013743, 0.7961, 0.52077]
Predicted label: 8
Correct prediction
Energy consumption = 150.562955 pJ
sum error= 264
Actual label: 9
Output voltages: [0.23357, 0.017846, 0.046346, 0.027047, 0.068724, 0.023158, 0.0060367, 0.11962, 0.55287, 0.79616]
Predicted label: 9
Correct prediction
Energy consumption = 151.436918 pJ
sum error= 264
Actual label: 1
Output voltages: [0.015574, 0.79854, 0.011944, 0.010613, 0.01894, 0.0047827, 0.47264, 0.002257, 0.71889, 0.025758]
Predicted label: 1
Correct prediction
Energy consumption = 167.197866 pJ
sum error= 264
Actual label: 8
Output voltages: [0.025715, 0.095733, 0.45592, 0.017938, 0.029384, 0.0051078, 0.023663, 0.0041485, 0.79872, 0.12741]
Predicted label: 8
Correct prediction
Energy consumption = 151.577904 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 559 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 559 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 559 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0026068, 0.79862, 0.041929, 0.031602, 0.013827, 0.0010667, 0.59403, 0.0011716, 0.26625, 0.048521]
Predicted label: 1
Correct prediction
Energy consumption = 159.701555 pJ
sum error= 264
Actual label: 6
Output voltages: [0.16846, 0.16396, 0.047926, 0.03741, 0.36881, 0.16038, 0.79878, 0.0013484, 0.53571, 0.021117]
Predicted label: 6
Correct prediction
Energy consumption = 149.268694 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79879, 0.096092, 0.29842, 0.033329, 0.033763, 0.014451, 0.38214, 0.038254, 0.49928, 0.038054]
Predicted label: 0
Correct prediction
Energy consumption = 156.862502 pJ
sum error= 264
Actual label: 0
Output voltages: [0.79694, 0.050524, 0.52335, 0.020352, 0.0069902, 0.001072, 0.49827, 0.0072548, 0.31951, 0.069621]
Predicted label: 0
Correct prediction
Energy consumption = 140.566860 pJ
sum error= 264
Actual label: 1
Output voltages: [0.0084822, 0.79871, 0.053426, 0.1261, 0.036606, 0.0012791, 0.52329, 0.0065301, 0.39005, 0.020437]
Predicted label: 1
Correct prediction
Energy consumption = 158.270927 pJ
sum error= 264
Actual label: 2
Output voltages: [0.3388, 0.14281, 0.79865, 0.68618, 0.034359, 0.0012005, 0.15417, 0.010035, 0.22887, 0.02803]
Predicted label: 2
Correct prediction
Energy consumption = 146.283169 pJ
sum error= 264
Actual label: 3
Output voltages: [0.044511, 0.0032841, 0.13506, 0.79877, 0.19436, 0.16629, 0.018438, 0.018968, 0.42309, 0.18109]
Predicted label: 3
Correct prediction
Energy consumption = 144.386858 pJ
sum error= 264
Actual label: 4
Output voltages: [0.001096, 0.063794, 0.1756, 0.010918, 0.79878, 0.0011011, 0.063682, 0.076391, 0.021593, 0.18414]
Predicted label: 4
Correct prediction
Energy consumption = 153.871712 pJ
sum error= 264
Actual label: 5
Output voltages: [0.039119, 0.0014535, 0.0011514, 0.39934, 0.016938, 0.79868, 0.23312, 0.019476, 0.77443, 0.0017925]
Predicted label: 5
Correct prediction
Energy consumption = 151.546205 pJ
sum error= 264
Actual label: 6
Output voltages: [0.075944, 0.0033534, 0.018548, 0.027747, 0.51903, 0.29784, 0.79877, 0.0011006, 0.72524, 0.10316]
Predicted label: 6
Correct prediction
Energy consumption = 144.629530 pJ
sum error= 264
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 560 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 560 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 560 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.68957, 0.11265, 0.001303, 0.001463, 0.037067, 0.0010696, 0.006209, 0.41587, 0.2492, 0.76051]
Predicted label: 9
Wrong prediction!
Energy consumption = 170.035689 pJ
sum error= 265
Actual label: 8
Output voltages: [0.13654, 0.025314, 0.24507, 0.037758, 0.35512, 0.0010661, 0.06681, 0.0011675, 0.79321, 0.04547]
Predicted label: 8
Correct prediction
Energy consumption = 150.102121 pJ
sum error= 265
Actual label: 9
Output voltages: [0.21628, 0.017031, 0.12675, 0.010102, 0.034571, 0.031426, 0.0035572, 0.14537, 0.73262, 0.79136]
Predicted label: 9
Correct prediction
Energy consumption = 147.524005 pJ
sum error= 265
Actual label: 0
Output voltages: [0.79815, 0.016602, 0.15954, 0.036369, 0.0057069, 0.061876, 0.42594, 0.0010659, 0.45388, 0.24833]
Predicted label: 0
Correct prediction
Energy consumption = 146.817097 pJ
sum error= 265
Actual label: 1
Output voltages: [0.0056585, 0.79862, 0.039108, 0.57404, 0.069125, 0.0010693, 0.037532, 0.046477, 0.066189, 0.15409]
Predicted label: 1
Correct prediction
Energy consumption = 165.871661 pJ
sum error= 265
Actual label: 2
Output voltages: [0.61819, 0.0092646, 0.79754, 0.47127, 0.0068803, 0.001127, 0.024538, 0.0076096, 0.29126, 0.0031052]
Predicted label: 2
Correct prediction
Energy consumption = 144.245075 pJ
sum error= 265
Actual label: 3
Output voltages: [0.22659, 0.033449, 0.035587, 0.79865, 0.013439, 0.0098906, 0.016191, 0.009841, 0.5171, 0.078291]
Predicted label: 3
Correct prediction
Energy consumption = 141.071297 pJ
sum error= 265
Actual label: 4
Output voltages: [0.031811, 0.037381, 0.050808, 0.0029718, 0.79872, 0.0061389, 0.025762, 0.042312, 0.032295, 0.48558]
Predicted label: 4
Correct prediction
Energy consumption = 150.849309 pJ
sum error= 265
Actual label: 5
Output voltages: [0.079069, 0.0010915, 0.0011068, 0.64781, 0.097378, 0.79876, 0.45458, 0.018182, 0.76634, 0.025142]
Predicted label: 5
Correct prediction
Energy consumption = 145.036884 pJ
sum error= 265
Actual label: 6
Output voltages: [0.058093, 0.19667, 0.2993, 0.0011174, 0.37741, 0.13569, 0.79869, 0.0011581, 0.3919, 0.011762]
Predicted label: 6
Correct prediction
Energy consumption = 137.504141 pJ
sum error= 265
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 561 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 561 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 561 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.48081, 0.026028, 0.045152, 0.0068711, 0.069667, 0.0032615, 0.0073312, 0.79879, 0.027929, 0.62659]
Predicted label: 7
Correct prediction
Energy consumption = 159.501274 pJ
sum error= 265
Actual label: 8
Output voltages: [0.043075, 0.018934, 0.09546, 0.26443, 0.0096918, 0.035105, 0.16229, 0.0030846, 0.79867, 0.079964]
Predicted label: 8
Correct prediction
Energy consumption = 155.680908 pJ
sum error= 265
Actual label: 9
Output voltages: [0.19375, 0.03908, 0.03546, 0.062911, 0.036965, 0.03052, 0.011818, 0.046155, 0.46917, 0.7985]
Predicted label: 9
Correct prediction
Energy consumption = 151.135477 pJ
sum error= 265
Actual label: 0
Output voltages: [0.79364, 0.013724, 0.035001, 0.0056818, 0.036825, 0.07821, 0.78315, 0.0020873, 0.20015, 0.21867]
Predicted label: 0
Correct prediction
Energy consumption = 142.417657 pJ
sum error= 265
Actual label: 1
Output voltages: [0.0074393, 0.7984, 0.055348, 0.074051, 0.028149, 0.0095315, 0.14036, 0.002902, 0.066248, 0.18377]
Predicted label: 1
Correct prediction
Energy consumption = 161.303930 pJ
sum error= 265
Actual label: 2
Output voltages: [0.18993, 0.11984, 0.79878, 0.38332, 0.024764, 0.0013033, 0.42698, 0.0079278, 0.56679, 0.054479]
Predicted label: 2
Correct prediction
Energy consumption = 142.668778 pJ
sum error= 265
Actual label: 3
Output voltages: [0.27118, 0.015256, 0.36277, 0.79879, 0.033098, 0.0024703, 0.012658, 0.0031579, 0.7302, 0.1422]
Predicted label: 3
Correct prediction
Energy consumption = 143.238941 pJ
sum error= 265
Actual label: 4
Output voltages: [0.0011293, 0.042699, 0.0011184, 0.001274, 0.79873, 0.0010676, 0.043436, 0.21243, 0.3738, 0.021412]
Predicted label: 4
Correct prediction
Energy consumption = 154.337262 pJ
sum error= 265
Actual label: 5
Output voltages: [0.063939, 0.0034504, 0.021874, 0.48581, 0.010793, 0.79817, 0.029742, 0.0085696, 0.79867, 0.054577]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.669780 pJ
sum error= 266
Actual label: 6
Output voltages: [0.039681, 0.053161, 0.63101, 0.0010709, 0.51911, 0.21086, 0.79871, 0.0011479, 0.044558, 0.0034742]
Predicted label: 6
Correct prediction
Energy consumption = 146.356030 pJ
sum error= 266
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 562 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 562 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 562 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.10179, 0.037518, 0.046878, 0.0027484, 0.035537, 0.0020313, 0.0096081, 0.7987, 0.19806, 0.55702]
Predicted label: 7
Correct prediction
Energy consumption = 157.202185 pJ
sum error= 266
Actual label: 8
Output voltages: [0.01445, 0.0071798, 0.018313, 0.031338, 0.049911, 0.056924, 0.28627, 0.020995, 0.79875, 0.054912]
Predicted label: 8
Correct prediction
Energy consumption = 151.128221 pJ
sum error= 266
Actual label: 9
Output voltages: [0.38415, 0.015979, 0.01823, 0.042549, 0.42753, 0.020153, 0.011579, 0.034052, 0.072731, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 154.704402 pJ
sum error= 266
Actual label: 3
Output voltages: [0.67451, 0.010771, 0.021168, 0.79879, 0.0021342, 0.26433, 0.0041739, 0.1051, 0.30926, 0.016121]
Predicted label: 3
Correct prediction
Energy consumption = 147.784970 pJ
sum error= 266
Actual label: 5
Output voltages: [0.017758, 0.0015533, 0.0048976, 0.59577, 0.010332, 0.79266, 0.083066, 0.0047927, 0.75514, 0.039638]
Predicted label: 5
Correct prediction
Energy consumption = 137.968063 pJ
sum error= 266
Actual label: 3
Output voltages: [0.29719, 0.0092073, 0.035331, 0.79873, 0.025436, 0.01895, 0.031433, 0.0052596, 0.41162, 0.036867]
Predicted label: 3
Correct prediction
Energy consumption = 141.141978 pJ
sum error= 266
Actual label: 2
Output voltages: [0.2318, 0.037712, 0.79877, 0.089866, 0.015759, 0.0013038, 0.45383, 0.067685, 0.50969, 0.012572]
Predicted label: 2
Correct prediction
Energy consumption = 139.154190 pJ
sum error= 266
Actual label: 9
Output voltages: [0.22323, 0.03761, 0.032284, 0.13952, 0.099221, 0.014301, 0.012293, 0.013462, 0.087169, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 158.655170 pJ
sum error= 266
Actual label: 3
Output voltages: [0.44667, 0.001742, 0.28003, 0.79878, 0.0037579, 0.080872, 0.0044247, 0.0092633, 0.52935, 0.0086493]
Predicted label: 3
Correct prediction
Energy consumption = 148.892002 pJ
sum error= 266
Actual label: 2
Output voltages: [0.35182, 0.020817, 0.79879, 0.10276, 0.028098, 0.001229, 0.13454, 0.015557, 0.65643, 0.032358]
Predicted label: 2
Correct prediction
Energy consumption = 142.366573 pJ
sum error= 266
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 563 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 563 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 563 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0033107, 0.79879, 0.061884, 0.56225, 0.065381, 0.001066, 0.021526, 0.28159, 0.11895, 0.040445]
Predicted label: 1
Correct prediction
Energy consumption = 170.468933 pJ
sum error= 266
Actual label: 4
Output voltages: [0.0038253, 0.017579, 0.14499, 0.024351, 0.79868, 0.001105, 0.035478, 0.24815, 0.021717, 0.064115]
Predicted label: 4
Correct prediction
Energy consumption = 151.923060 pJ
sum error= 266
Actual label: 5
Output voltages: [0.033615, 0.0010733, 0.0013738, 0.41618, 0.077638, 0.79879, 0.14908, 0.015356, 0.7327, 0.095085]
Predicted label: 5
Correct prediction
Energy consumption = 151.399307 pJ
sum error= 266
Actual label: 5
Output voltages: [0.21491, 0.0010715, 0.0012409, 0.12145, 0.021702, 0.79873, 0.29147, 0.013896, 0.71907, 0.0027265]
Predicted label: 5
Correct prediction
Energy consumption = 142.221525 pJ
sum error= 266
Actual label: 2
Output voltages: [0.43371, 0.036233, 0.79351, 0.74637, 0.0032828, 0.0012127, 0.014457, 0.010761, 0.74699, 0.015934]
Predicted label: 2
Correct prediction
Energy consumption = 148.707764 pJ
sum error= 266
Actual label: 3
Output voltages: [0.12393, 0.014809, 0.14059, 0.79875, 0.033474, 0.031725, 0.0059909, 0.036147, 0.72353, 0.19048]
Predicted label: 3
Correct prediction
Energy consumption = 137.869111 pJ
sum error= 266
Actual label: 2
Output voltages: [0.31973, 0.041029, 0.79859, 0.53454, 0.036454, 0.0012874, 0.13796, 0.012731, 0.48733, 0.01876]
Predicted label: 2
Correct prediction
Energy consumption = 140.512117 pJ
sum error= 266
Actual label: 1
Output voltages: [0.022025, 0.79844, 0.022236, 0.39113, 0.029097, 0.016264, 0.32802, 0.010962, 0.25728, 0.44399]
Predicted label: 1
Correct prediction
Energy consumption = 163.080243 pJ
sum error= 266
Actual label: 3
Output voltages: [0.2552, 0.016653, 0.019247, 0.79874, 0.0021497, 0.020748, 0.12852, 0.12093, 0.3197, 0.0019566]
Predicted label: 3
Correct prediction
Energy consumption = 147.458477 pJ
sum error= 266
Actual label: 9
Output voltages: [0.3009, 0.0096444, 0.017302, 0.10398, 0.0061205, 0.019512, 0.0020817, 0.32973, 0.61034, 0.79787]
Predicted label: 9
Correct prediction
Energy consumption = 151.410599 pJ
sum error= 266
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 564 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 564 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 564 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.077641, 0.027828, 0.023021, 0.029943, 0.014494, 0.0038052, 0.0010676, 0.79867, 0.11023, 0.52878]
Predicted label: 7
Correct prediction
Energy consumption = 156.502585 pJ
sum error= 266
Actual label: 2
Output voltages: [0.14691, 0.0048973, 0.79878, 0.27854, 0.025073, 0.001096, 0.085443, 0.013603, 0.69189, 0.0081238]
Predicted label: 2
Correct prediction
Energy consumption = 146.624079 pJ
sum error= 266
Actual label: 1
Output voltages: [0.26418, 0.78378, 0.0013735, 0.0053434, 0.065311, 0.62618, 0.29067, 0.0047699, 0.76801, 0.0021007]
Predicted label: 1
Correct prediction
Energy consumption = 164.874643 pJ
sum error= 266
Actual label: 2
Output voltages: [0.056407, 0.0026031, 0.78253, 0.73407, 0.024516, 0.0014423, 0.018267, 0.0084256, 0.78958, 0.0060318]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.005767 pJ
sum error= 267
Actual label: 8
Output voltages: [0.0034092, 0.019056, 0.0043224, 0.049989, 0.016225, 0.072831, 0.52935, 0.011444, 0.79849, 0.018295]
Predicted label: 8
Correct prediction
Energy consumption = 148.437345 pJ
sum error= 267
Actual label: 9
Output voltages: [0.28896, 0.0083727, 0.013498, 0.017747, 0.15657, 0.006698, 0.002602, 0.029237, 0.45739, 0.79824]
Predicted label: 9
Correct prediction
Energy consumption = 151.041136 pJ
sum error= 267
Actual label: 1
Output voltages: [0.010019, 0.79848, 0.018054, 0.040936, 0.012226, 0.0015848, 0.75397, 0.0062909, 0.41769, 0.039883]
Predicted label: 1
Correct prediction
Energy consumption = 165.594100 pJ
sum error= 267
Actual label: 8
Output voltages: [0.006617, 0.08454, 0.036412, 0.02805, 0.10955, 0.267, 0.61289, 0.012275, 0.79871, 0.0049028]
Predicted label: 8
Correct prediction
Energy consumption = 152.493697 pJ
sum error= 267
Actual label: 8
Output voltages: [0.0060523, 0.037648, 0.050271, 0.036743, 0.05681, 0.048858, 0.056013, 0.025326, 0.79871, 0.040837]
Predicted label: 8
Correct prediction
Energy consumption = 149.623890 pJ
sum error= 267
Actual label: 7
Output voltages: [0.35008, 0.098902, 0.0017473, 0.0010751, 0.037261, 0.0053999, 0.0023863, 0.76217, 0.53443, 0.59746]
Predicted label: 7
Correct prediction
Energy consumption = 159.377239 pJ
sum error= 267
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 565 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 565 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 565 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0058655, 0.0068307, 0.010472, 0.013039, 0.1199, 0.0423, 0.22751, 0.048059, 0.79869, 0.023353]
Predicted label: 8
Correct prediction
Energy consumption = 149.416367 pJ
sum error= 267
Actual label: 1
Output voltages: [0.27922, 0.79864, 0.024732, 0.027599, 0.048534, 0.0011976, 0.18366, 0.002969, 0.29882, 0.2128]
Predicted label: 1
Correct prediction
Energy consumption = 162.709878 pJ
sum error= 267
Actual label: 0
Output voltages: [0.79845, 0.069204, 0.014725, 0.021493, 0.096203, 0.0099231, 0.76607, 0.0099814, 0.16822, 0.022034]
Predicted label: 0
Correct prediction
Energy consumption = 155.834778 pJ
sum error= 267
Actual label: 0
Output voltages: [0.79853, 0.030335, 0.10068, 0.020092, 0.051942, 0.010371, 0.7652, 0.018812, 0.39098, 0.04768]
Predicted label: 0
Correct prediction
Energy consumption = 143.256501 pJ
sum error= 267
Actual label: 7
Output voltages: [0.53643, 0.24895, 0.4176, 0.023583, 0.26506, 0.0012898, 0.025644, 0.03233, 0.084116, 0.71049]
Predicted label: 9
Wrong prediction!
Energy consumption = 159.891609 pJ
sum error= 268
Actual label: 7
Output voltages: [0.27592, 0.35624, 0.64121, 0.0015573, 0.0049384, 0.0011109, 0.0014501, 0.79678, 0.39815, 0.19272]
Predicted label: 7
Correct prediction
Energy consumption = 147.196093 pJ
sum error= 268
Actual label: 8
Output voltages: [0.0087787, 0.019417, 0.047874, 0.34496, 0.009862, 0.016565, 0.048997, 0.0029448, 0.79876, 0.051541]
Predicted label: 8
Correct prediction
Energy consumption = 153.494751 pJ
sum error= 268
Actual label: 7
Output voltages: [0.16122, 0.050042, 0.023917, 0.077606, 0.010928, 0.0068903, 0.0010829, 0.79869, 0.047801, 0.46967]
Predicted label: 7
Correct prediction
Energy consumption = 154.337617 pJ
sum error= 268
Actual label: 5
Output voltages: [0.040215, 0.0011633, 0.0010728, 0.51985, 0.048115, 0.79879, 0.15438, 0.075181, 0.75957, 0.026046]
Predicted label: 5
Correct prediction
Energy consumption = 141.013686 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79873, 0.041703, 0.084326, 0.0051927, 0.0085675, 0.00173, 0.70299, 0.0096228, 0.048083, 0.18621]
Predicted label: 0
Correct prediction
Energy consumption = 152.446535 pJ
sum error= 268
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 566 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 566 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 566 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.089791, 0.054515, 0.18296, 0.017097, 0.12588, 0.53112, 0.79867, 0.0071053, 0.37183, 0.01951]
Predicted label: 6
Correct prediction
Energy consumption = 148.753562 pJ
sum error= 268
Actual label: 1
Output voltages: [0.0018616, 0.79877, 0.021246, 0.047895, 0.011642, 0.022055, 0.64792, 0.020167, 0.60069, 0.0013981]
Predicted label: 1
Correct prediction
Energy consumption = 156.296855 pJ
sum error= 268
Actual label: 5
Output voltages: [0.087198, 0.001427, 0.0070369, 0.53392, 0.018012, 0.79859, 0.053503, 0.037862, 0.76339, 0.082807]
Predicted label: 5
Correct prediction
Energy consumption = 148.239653 pJ
sum error= 268
Actual label: 7
Output voltages: [0.073338, 0.094448, 0.026491, 0.055414, 0.025754, 0.0081018, 0.0017768, 0.7987, 0.045759, 0.67334]
Predicted label: 7
Correct prediction
Energy consumption = 157.208707 pJ
sum error= 268
Actual label: 4
Output voltages: [0.0081324, 0.016527, 0.016743, 0.0054079, 0.79875, 0.0010865, 0.02148, 0.026427, 0.20955, 0.019698]
Predicted label: 4
Correct prediction
Energy consumption = 142.752028 pJ
sum error= 268
Actual label: 6
Output voltages: [0.40203, 0.01947, 0.039051, 0.020469, 0.39759, 0.27944, 0.79878, 0.0012164, 0.5081, 0.022552]
Predicted label: 6
Correct prediction
Energy consumption = 153.481873 pJ
sum error= 268
Actual label: 1
Output voltages: [0.011151, 0.79865, 0.023835, 0.082867, 0.040275, 0.0032662, 0.68831, 0.010242, 0.39297, 0.016611]
Predicted label: 1
Correct prediction
Energy consumption = 163.162175 pJ
sum error= 268
Actual label: 2
Output voltages: [0.19848, 0.0043571, 0.79879, 0.18314, 0.0059138, 0.0011778, 0.072505, 0.052604, 0.65046, 0.0094021]
Predicted label: 2
Correct prediction
Energy consumption = 146.518094 pJ
sum error= 268
Actual label: 5
Output voltages: [0.025145, 0.0017217, 0.010386, 0.027847, 0.046886, 0.79682, 0.16172, 0.0026927, 0.78393, 0.025245]
Predicted label: 5
Correct prediction
Energy consumption = 147.506387 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79872, 0.042774, 0.044872, 0.021755, 0.0084642, 0.034251, 0.57307, 0.0071438, 0.34057, 0.36968]
Predicted label: 0
Correct prediction
Energy consumption = 153.440460 pJ
sum error= 268
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 567 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 567 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 567 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.063206, 0.11468, 0.050828, 0.018032, 0.017976, 0.049155, 0.0010663, 0.79859, 0.28792, 0.25715]
Predicted label: 7
Correct prediction
Energy consumption = 155.703241 pJ
sum error= 268
Actual label: 9
Output voltages: [0.27678, 0.024771, 0.016837, 0.052812, 0.38588, 0.0098713, 0.00115, 0.0070208, 0.26655, 0.7979]
Predicted label: 9
Correct prediction
Energy consumption = 145.174861 pJ
sum error= 268
Actual label: 9
Output voltages: [0.23614, 0.0081136, 0.033174, 0.017094, 0.39658, 0.007859, 0.010284, 0.0040126, 0.46487, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 142.113253 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79874, 0.21938, 0.040573, 0.03208, 0.0020978, 0.018695, 0.17865, 0.0041566, 0.21621, 0.5249]
Predicted label: 0
Correct prediction
Energy consumption = 147.654016 pJ
sum error= 268
Actual label: 3
Output voltages: [0.75497, 0.016255, 0.034282, 0.79865, 0.012286, 0.041758, 0.0049334, 0.018559, 0.34702, 0.026049]
Predicted label: 3
Correct prediction
Energy consumption = 148.250292 pJ
sum error= 268
Actual label: 8
Output voltages: [0.024156, 0.0012129, 0.19437, 0.046475, 0.046613, 0.0052182, 0.63077, 0.0038063, 0.79869, 0.018176]
Predicted label: 8
Correct prediction
Energy consumption = 152.740167 pJ
sum error= 268
Actual label: 4
Output voltages: [0.033184, 0.13684, 0.29606, 0.010872, 0.79067, 0.0012452, 0.34829, 0.25356, 0.10104, 0.1393]
Predicted label: 4
Correct prediction
Energy consumption = 141.499641 pJ
sum error= 268
Actual label: 4
Output voltages: [0.0017075, 0.44235, 0.29514, 0.0011338, 0.79874, 0.0084836, 0.095805, 0.025946, 0.020911, 0.037044]
Predicted label: 4
Correct prediction
Energy consumption = 146.029494 pJ
sum error= 268
Actual label: 8
Output voltages: [0.0061871, 0.025007, 0.0050586, 0.22976, 0.02647, 0.028794, 0.70523, 0.0049758, 0.79823, 0.007719]
Predicted label: 8
Correct prediction
Energy consumption = 152.074216 pJ
sum error= 268
Actual label: 1
Output voltages: [0.0045461, 0.79869, 0.13967, 0.18401, 0.032584, 0.0010661, 0.028434, 0.012827, 0.22668, 0.097057]
Predicted label: 1
Correct prediction
Energy consumption = 163.139213 pJ
sum error= 268
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 568 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 568 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 568 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.013239, 0.003833, 0.01434, 0.11112, 0.0070702, 0.066009, 0.53343, 0.005715, 0.79879, 0.022722]
Predicted label: 8
Correct prediction
Energy consumption = 158.494610 pJ
sum error= 268
Actual label: 6
Output voltages: [0.29613, 0.022739, 0.2037, 0.013328, 0.43477, 0.359, 0.79876, 0.0018684, 0.57628, 0.0063395]
Predicted label: 6
Correct prediction
Energy consumption = 147.339333 pJ
sum error= 268
Actual label: 5
Output voltages: [0.27187, 0.0011812, 0.010986, 0.46469, 0.010726, 0.79879, 0.20762, 0.038332, 0.73352, 0.064194]
Predicted label: 5
Correct prediction
Energy consumption = 150.082625 pJ
sum error= 268
Actual label: 9
Output voltages: [0.42817, 0.011372, 0.006507, 0.039712, 0.11993, 0.021806, 0.0031095, 0.0302, 0.41764, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 149.057680 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79879, 0.17599, 0.015765, 0.013719, 0.0065718, 0.0096367, 0.54961, 0.030221, 0.19793, 0.04085]
Predicted label: 0
Correct prediction
Energy consumption = 149.720133 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79877, 0.028308, 0.012043, 0.0083804, 0.013135, 0.26306, 0.36258, 0.0063426, 0.35443, 0.017024]
Predicted label: 0
Correct prediction
Energy consumption = 147.685408 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79852, 0.051868, 0.023899, 0.0027505, 0.0088245, 0.012347, 0.58306, 0.012151, 0.037018, 0.32019]
Predicted label: 0
Correct prediction
Energy consumption = 144.576966 pJ
sum error= 268
Actual label: 3
Output voltages: [0.18667, 0.0073527, 0.03397, 0.7987, 0.034609, 0.022321, 0.036278, 0.015215, 0.69897, 0.26276]
Predicted label: 3
Correct prediction
Energy consumption = 150.896523 pJ
sum error= 268
Actual label: 7
Output voltages: [0.38054, 0.041133, 0.013508, 0.085973, 0.0051496, 0.085424, 0.001092, 0.78997, 0.72365, 0.77328]
Predicted label: 7
Correct prediction
Energy consumption = 158.837372 pJ
sum error= 268
Actual label: 1
Output voltages: [0.40928, 0.7985, 0.0041127, 0.41012, 0.0019475, 0.0086291, 0.58593, 0.012135, 0.088374, 0.05806]
Predicted label: 1
Correct prediction
Energy consumption = 166.026517 pJ
sum error= 268
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 569 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 569 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 569 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.15695, 0.02254, 0.12465, 0.012489, 0.40805, 0.26369, 0.79877, 0.0016127, 0.41513, 0.016981]
Predicted label: 6
Correct prediction
Energy consumption = 149.670471 pJ
sum error= 268
Actual label: 4
Output voltages: [0.013996, 0.53457, 0.051933, 0.082508, 0.79453, 0.0011183, 0.10099, 0.30379, 0.045624, 0.033407]
Predicted label: 4
Correct prediction
Energy consumption = 154.496845 pJ
sum error= 268
Actual label: 2
Output voltages: [0.40231, 0.11115, 0.79872, 0.077045, 0.036527, 0.0012218, 0.55502, 0.025798, 0.50287, 0.075802]
Predicted label: 2
Correct prediction
Energy consumption = 142.342790 pJ
sum error= 268
Actual label: 6
Output voltages: [0.13745, 0.045295, 0.087693, 0.0088077, 0.35879, 0.55108, 0.79872, 0.0026345, 0.5106, 0.0032752]
Predicted label: 6
Correct prediction
Energy consumption = 145.645255 pJ
sum error= 268
Actual label: 6
Output voltages: [0.055679, 0.11867, 0.26747, 0.0040832, 0.28558, 0.38345, 0.79869, 0.0016492, 0.44692, 0.02215]
Predicted label: 6
Correct prediction
Energy consumption = 132.181031 pJ
sum error= 268
Actual label: 0
Output voltages: [0.79271, 0.036013, 0.046652, 0.0074026, 0.0047936, 0.0088513, 0.1008, 0.0060427, 0.77538, 0.037512]
Predicted label: 0
Correct prediction
Energy consumption = 150.787763 pJ
sum error= 268
Actual label: 4
Output voltages: [0.0037342, 0.0071416, 0.067288, 0.0087258, 0.79868, 0.0015998, 0.55913, 0.021851, 0.027636, 0.027863]
Predicted label: 4
Correct prediction
Energy consumption = 149.532374 pJ
sum error= 268
Actual label: 5
Output voltages: [0.047298, 0.0011234, 0.0020094, 0.53507, 0.015366, 0.79844, 0.067133, 0.037415, 0.72712, 0.21561]
Predicted label: 5
Correct prediction
Energy consumption = 150.371515 pJ
sum error= 268
Actual label: 4
Output voltages: [0.0016863, 0.22228, 0.021861, 0.0010716, 0.79879, 0.041643, 0.13395, 0.073363, 0.25766, 0.064418]
Predicted label: 4
Correct prediction
Energy consumption = 157.616930 pJ
sum error= 268
Actual label: 1
Output voltages: [0.018724, 0.79844, 0.043475, 0.15153, 0.2274, 0.010779, 0.16998, 0.015187, 0.035839, 0.29274]
Predicted label: 1
Correct prediction
Energy consumption = 158.758438 pJ
sum error= 268
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 570 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 570 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 570 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.2768, 0.039264, 0.025774, 0.79866, 0.0083342, 0.0066071, 0.023118, 0.0048976, 0.44118, 0.13595]
Predicted label: 3
Correct prediction
Energy consumption = 151.911934 pJ
sum error= 268
Actual label: 8
Output voltages: [0.0097197, 0.043347, 0.30136, 0.0040642, 0.25804, 0.0060096, 0.040881, 0.0025281, 0.79874, 0.15663]
Predicted label: 8
Correct prediction
Energy consumption = 151.844848 pJ
sum error= 268
Actual label: 6
Output voltages: [0.059471, 0.039002, 0.3619, 0.0015843, 0.48363, 0.47943, 0.79868, 0.0020624, 0.13932, 0.0049214]
Predicted label: 6
Correct prediction
Energy consumption = 143.628247 pJ
sum error= 268
Actual label: 3
Output voltages: [0.069613, 0.0061657, 0.15426, 0.79879, 0.037774, 0.022674, 0.016015, 0.034408, 0.76122, 0.10694]
Predicted label: 3
Correct prediction
Energy consumption = 148.961988 pJ
sum error= 268
Actual label: 9
Output voltages: [0.041827, 0.0078079, 0.022648, 0.12455, 0.41674, 0.22303, 0.23359, 0.01933, 0.18704, 0.79865]
Predicted label: 9
Correct prediction
Energy consumption = 154.126301 pJ
sum error= 268
Actual label: 9
Output voltages: [0.34986, 0.012645, 0.026153, 0.21366, 0.55657, 0.01009, 0.0028712, 0.036353, 0.053536, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 141.786656 pJ
sum error= 268
Actual label: 5
Output voltages: [0.10591, 0.0011004, 0.044064, 0.13625, 0.0062258, 0.79651, 0.083505, 0.0017928, 0.7984, 0.045463]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.884931 pJ
sum error= 269
Actual label: 9
Output voltages: [0.12284, 0.038987, 0.033727, 0.14008, 0.022207, 0.044318, 0.034541, 0.21952, 0.39134, 0.79716]
Predicted label: 9
Correct prediction
Energy consumption = 147.899055 pJ
sum error= 269
Actual label: 3
Output voltages: [0.2312, 0.029459, 0.036593, 0.79859, 0.016117, 0.019351, 0.010881, 0.024546, 0.51753, 0.06331]
Predicted label: 3
Correct prediction
Energy consumption = 149.149237 pJ
sum error= 269
Actual label: 7
Output voltages: [0.24707, 0.29117, 0.008312, 0.0066734, 0.0014506, 0.01654, 0.0036134, 0.79872, 0.1162, 0.6933]
Predicted label: 7
Correct prediction
Energy consumption = 161.505855 pJ
sum error= 269
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 571 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 571 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 571 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.018778, 0.022419, 0.014776, 0.63221, 0.005866, 0.018575, 0.18559, 0.0015442, 0.79846, 0.44959]
Predicted label: 8
Correct prediction
Energy consumption = 155.871069 pJ
sum error= 269
Actual label: 5
Output voltages: [0.053021, 0.0012091, 0.0015569, 0.39238, 0.02255, 0.79836, 0.15218, 0.0065117, 0.75301, 0.13391]
Predicted label: 5
Correct prediction
Energy consumption = 146.687719 pJ
sum error= 269
Actual label: 6
Output voltages: [0.23405, 0.064675, 0.30853, 0.0051059, 0.44352, 0.49325, 0.79861, 0.0040432, 0.45471, 0.0062072]
Predicted label: 6
Correct prediction
Energy consumption = 142.675509 pJ
sum error= 269
Actual label: 4
Output voltages: [0.0050738, 0.039655, 0.26872, 0.0015903, 0.7987, 0.0027074, 0.051177, 0.61895, 0.072317, 0.29269]
Predicted label: 4
Correct prediction
Energy consumption = 151.189535 pJ
sum error= 269
Actual label: 7
Output voltages: [0.19394, 0.057605, 0.093353, 0.040193, 0.0078696, 0.021463, 0.0013199, 0.79854, 0.2164, 0.25232]
Predicted label: 7
Correct prediction
Energy consumption = 159.234365 pJ
sum error= 269
Actual label: 6
Output voltages: [0.045193, 0.044146, 0.1751, 0.0023159, 0.4178, 0.23235, 0.79871, 0.0022576, 0.53064, 0.0097314]
Predicted label: 6
Correct prediction
Energy consumption = 149.845455 pJ
sum error= 269
Actual label: 2
Output voltages: [0.41876, 0.04393, 0.79876, 0.17371, 0.048061, 0.0011834, 0.43371, 0.032994, 0.66395, 0.050405]
Predicted label: 2
Correct prediction
Energy consumption = 145.405098 pJ
sum error= 269
Actual label: 2
Output voltages: [0.14305, 0.022587, 0.79879, 0.022473, 0.0025947, 0.0011112, 0.036639, 0.022397, 0.73151, 0.024283]
Predicted label: 2
Correct prediction
Energy consumption = 140.599888 pJ
sum error= 269
Actual label: 0
Output voltages: [0.79756, 0.19142, 0.020703, 0.0040595, 0.0070503, 0.011586, 0.63392, 0.0020852, 0.32153, 0.091516]
Predicted label: 0
Correct prediction
Energy consumption = 157.577870 pJ
sum error= 269
Actual label: 9
Output voltages: [0.2336, 0.018803, 0.016829, 0.088501, 0.32495, 0.19385, 0.019351, 0.027697, 0.086392, 0.79862]
Predicted label: 9
Correct prediction
Energy consumption = 152.522372 pJ
sum error= 269
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 572 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 572 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 572 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0010859, 0.28762, 0.015756, 0.035361, 0.79474, 0.0012001, 0.14292, 0.0090057, 0.40166, 0.008934]
Predicted label: 4
Correct prediction
Energy consumption = 150.440814 pJ
sum error= 269
Actual label: 0
Output voltages: [0.79879, 0.030885, 0.042375, 0.0080525, 0.039383, 0.0058306, 0.5459, 0.024125, 0.057105, 0.20755]
Predicted label: 0
Correct prediction
Energy consumption = 159.976808 pJ
sum error= 269
Actual label: 1
Output voltages: [0.0074006, 0.79865, 0.017233, 0.024098, 0.014405, 0.0010691, 0.64108, 0.0023197, 0.47713, 0.018581]
Predicted label: 1
Correct prediction
Energy consumption = 155.923877 pJ
sum error= 269
Actual label: 2
Output voltages: [0.51335, 0.015917, 0.79877, 0.023791, 0.0085488, 0.0011936, 0.061602, 0.041425, 0.54373, 0.013592]
Predicted label: 2
Correct prediction
Energy consumption = 146.217173 pJ
sum error= 269
Actual label: 3
Output voltages: [0.055448, 0.027203, 0.049569, 0.79874, 0.012248, 0.0025733, 0.011117, 0.013395, 0.73812, 0.033001]
Predicted label: 3
Correct prediction
Energy consumption = 145.476694 pJ
sum error= 269
Actual label: 4
Output voltages: [0.035227, 0.0048249, 0.27512, 0.0022224, 0.79861, 0.0015606, 0.23791, 0.04804, 0.050206, 0.031074]
Predicted label: 4
Correct prediction
Energy consumption = 156.869394 pJ
sum error= 269
Actual label: 5
Output voltages: [0.026158, 0.0011678, 0.0063871, 0.1072, 0.038629, 0.79726, 0.038499, 0.010387, 0.78794, 0.16236]
Predicted label: 5
Correct prediction
Energy consumption = 144.679312 pJ
sum error= 269
Actual label: 6
Output voltages: [0.082194, 0.04752, 0.40654, 0.001528, 0.45877, 0.2925, 0.79875, 0.0034937, 0.18124, 0.0022431]
Predicted label: 6
Correct prediction
Energy consumption = 147.158728 pJ
sum error= 269
Actual label: 7
Output voltages: [0.049124, 0.0011083, 0.016358, 0.038264, 0.20341, 0.026748, 0.0011158, 0.79871, 0.59142, 0.32711]
Predicted label: 7
Correct prediction
Energy consumption = 154.566694 pJ
sum error= 269
Actual label: 8
Output voltages: [0.0054711, 0.061689, 0.24301, 0.049545, 0.0044813, 0.019164, 0.021987, 0.032025, 0.79872, 0.18824]
Predicted label: 8
Correct prediction
Energy consumption = 139.760039 pJ
sum error= 269
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 573 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 573 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 573 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.48129, 0.014061, 0.027126, 0.0217, 0.19663, 0.021719, 0.0028321, 0.031915, 0.50768, 0.79784]
Predicted label: 9
Correct prediction
Energy consumption = 149.225408 pJ
sum error= 269
Actual label: 0
Output voltages: [0.79809, 0.062823, 0.052322, 0.27305, 0.0025027, 0.0013783, 0.47139, 0.0012429, 0.10071, 0.56844]
Predicted label: 0
Correct prediction
Energy consumption = 153.253709 pJ
sum error= 269
Actual label: 1
Output voltages: [0.0046508, 0.79857, 0.24635, 0.18784, 0.0024897, 0.0010935, 0.31652, 0.0056735, 0.26884, 0.011053]
Predicted label: 1
Correct prediction
Energy consumption = 162.640696 pJ
sum error= 269
Actual label: 2
Output voltages: [0.4671, 0.11428, 0.7987, 0.15482, 0.090073, 0.0010748, 0.37044, 0.032738, 0.37221, 0.034599]
Predicted label: 2
Correct prediction
Energy consumption = 144.740077 pJ
sum error= 269
Actual label: 3
Output voltages: [0.02402, 0.027323, 0.51663, 0.79815, 0.0011466, 0.011192, 0.0069475, 0.4705, 0.044737, 0.33214]
Predicted label: 3
Correct prediction
Energy consumption = 137.268191 pJ
sum error= 269
Actual label: 5
Output voltages: [0.0071201, 0.0014007, 0.11588, 0.19416, 0.024438, 0.7746, 0.49269, 0.0068143, 0.78172, 0.029964]
Predicted label: 8
Wrong prediction!
Energy consumption = 155.296342 pJ
sum error= 270
Actual label: 6
Output voltages: [0.037176, 0.0013882, 0.23066, 0.052129, 0.69675, 0.038177, 0.7945, 0.0046111, 0.45479, 0.032363]
Predicted label: 6
Correct prediction
Energy consumption = 135.740157 pJ
sum error= 270
Actual label: 0
Output voltages: [0.79864, 0.32494, 0.033013, 0.29802, 0.0043481, 0.1173, 0.30151, 0.0038424, 0.13003, 0.17105]
Predicted label: 0
Correct prediction
Energy consumption = 153.421861 pJ
sum error= 270
Actual label: 1
Output voltages: [0.0054862, 0.79846, 0.034928, 0.081143, 0.0056994, 0.001408, 0.74459, 0.016101, 0.1398, 0.022872]
Predicted label: 1
Correct prediction
Energy consumption = 158.171589 pJ
sum error= 270
Actual label: 2
Output voltages: [0.12802, 0.24006, 0.79879, 0.29846, 0.030814, 0.0013132, 0.044029, 0.044085, 0.23714, 0.041265]
Predicted label: 2
Correct prediction
Energy consumption = 142.822776 pJ
sum error= 270
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 574 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 574 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 574 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.029464, 0.003993, 0.028217, 0.79878, 0.19696, 0.054844, 0.044153, 0.038035, 0.36322, 0.053228]
Predicted label: 3
Correct prediction
Energy consumption = 151.891355 pJ
sum error= 270
Actual label: 4
Output voltages: [0.0060352, 0.01295, 0.030006, 0.0023109, 0.79867, 0.0030337, 0.25575, 0.54842, 0.082273, 0.0075405]
Predicted label: 4
Correct prediction
Energy consumption = 149.962087 pJ
sum error= 270
Actual label: 5
Output voltages: [0.051399, 0.0010661, 0.0040166, 0.61236, 0.0099229, 0.79613, 0.0042583, 0.020329, 0.76091, 0.16035]
Predicted label: 5
Correct prediction
Energy consumption = 149.436490 pJ
sum error= 270
Actual label: 6
Output voltages: [0.023294, 0.011004, 0.31705, 0.0078169, 0.27019, 0.28973, 0.79875, 0.003537, 0.73095, 0.0013843]
Predicted label: 6
Correct prediction
Energy consumption = 148.650876 pJ
sum error= 270
Actual label: 8
Output voltages: [0.0065804, 0.039003, 0.12151, 0.099297, 0.0053466, 0.036923, 0.021815, 0.030797, 0.79874, 0.23035]
Predicted label: 8
Correct prediction
Energy consumption = 142.298597 pJ
sum error= 270
Actual label: 7
Output voltages: [0.081269, 0.68506, 0.21737, 0.20036, 0.014208, 0.0012782, 0.0014703, 0.77713, 0.28804, 0.090757]
Predicted label: 7
Correct prediction
Energy consumption = 152.466477 pJ
sum error= 270
Actual label: 1
Output voltages: [0.034499, 0.79879, 0.042302, 0.0023044, 0.040611, 0.0022018, 0.35102, 0.0064894, 0.50522, 0.074141]
Predicted label: 1
Correct prediction
Energy consumption = 155.430170 pJ
sum error= 270
Actual label: 3
Output voltages: [0.29326, 0.0081711, 0.60137, 0.79878, 0.015465, 0.0030536, 0.003246, 0.040811, 0.41247, 0.097065]
Predicted label: 3
Correct prediction
Energy consumption = 153.312391 pJ
sum error= 270
Actual label: 2
Output voltages: [0.2012, 0.019002, 0.79879, 0.082321, 0.024387, 0.0010717, 0.098622, 0.043771, 0.75201, 0.0080936]
Predicted label: 2
Correct prediction
Energy consumption = 135.323930 pJ
sum error= 270
Actual label: 8
Output voltages: [0.0054988, 0.0026551, 0.036282, 0.0010759, 0.059393, 0.69241, 0.61419, 0.027103, 0.795, 0.001643]
Predicted label: 8
Correct prediction
Energy consumption = 142.028888 pJ
sum error= 270
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 575 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 575 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 575 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79822, 0.31655, 0.2202, 0.021346, 0.0018561, 0.001066, 0.50083, 0.012313, 0.17777, 0.21191]
Predicted label: 0
Correct prediction
Energy consumption = 151.409046 pJ
sum error= 270
Actual label: 7
Output voltages: [0.27504, 0.023382, 0.096478, 0.44282, 0.002412, 0.0015635, 0.0012132, 0.79859, 0.54264, 0.15639]
Predicted label: 7
Correct prediction
Energy consumption = 153.142218 pJ
sum error= 270
Actual label: 5
Output voltages: [0.51952, 0.0010788, 0.0095777, 0.78601, 0.0010662, 0.77155, 0.01796, 0.010638, 0.51791, 0.07683]
Predicted label: 3
Wrong prediction!
Energy consumption = 142.218523 pJ
sum error= 271
Actual label: 9
Output voltages: [0.30223, 0.0065042, 0.048845, 0.36278, 0.69689, 0.0062116, 0.0054671, 0.053966, 0.028805, 0.79788]
Predicted label: 9
Correct prediction
Energy consumption = 144.992059 pJ
sum error= 271
Actual label: 9
Output voltages: [0.19842, 0.0014185, 0.085663, 0.014317, 0.61746, 0.0073116, 0.034615, 0.30513, 0.011396, 0.78904]
Predicted label: 9
Correct prediction
Energy consumption = 145.503441 pJ
sum error= 271
Actual label: 6
Output voltages: [0.041469, 0.036327, 0.48294, 0.0011521, 0.32054, 0.20463, 0.79875, 0.0025331, 0.62702, 0.0024947]
Predicted label: 6
Correct prediction
Energy consumption = 137.516070 pJ
sum error= 271
Actual label: 0
Output voltages: [0.79573, 0.015756, 0.22454, 0.049869, 0.21429, 0.0010904, 0.61056, 0.011529, 0.21823, 0.26057]
Predicted label: 0
Correct prediction
Energy consumption = 140.881400 pJ
sum error= 271
Actual label: 9
Output voltages: [0.73588, 0.0077401, 0.0036448, 0.13833, 0.37775, 0.03656, 0.0039351, 0.0048072, 0.33805, 0.79459]
Predicted label: 9
Correct prediction
Energy consumption = 149.190384 pJ
sum error= 271
Actual label: 4
Output voltages: [0.0014418, 0.018142, 0.063976, 0.0052575, 0.79862, 0.0046986, 0.14501, 0.35352, 0.14339, 0.0035501]
Predicted label: 4
Correct prediction
Energy consumption = 148.690206 pJ
sum error= 271
Actual label: 1
Output voltages: [0.41153, 0.79579, 0.06345, 0.0017177, 0.56889, 0.0042668, 0.60816, 0.0013979, 0.048481, 0.021609]
Predicted label: 1
Correct prediction
Energy consumption = 152.079106 pJ
sum error= 271
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 576 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 576 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 576 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.55923, 0.0080157, 0.47085, 0.79875, 0.016636, 0.0017462, 0.011991, 0.026486, 0.34196, 0.012063]
Predicted label: 3
Correct prediction
Energy consumption = 146.577277 pJ
sum error= 271
Actual label: 2
Output voltages: [0.46718, 0.0018936, 0.79874, 0.034668, 0.014485, 0.0011295, 0.01425, 0.091464, 0.63891, 0.0017093]
Predicted label: 2
Correct prediction
Energy consumption = 130.921410 pJ
sum error= 271
Actual label: 1
Output voltages: [0.03083, 0.79877, 0.538, 0.14239, 0.28688, 0.0011564, 0.22473, 0.0016506, 0.025339, 0.28525]
Predicted label: 1
Correct prediction
Energy consumption = 162.931599 pJ
sum error= 271
Actual label: 2
Output voltages: [0.44167, 0.018127, 0.79878, 0.046301, 0.0054366, 0.0012178, 0.069078, 0.13606, 0.75064, 0.012075]
Predicted label: 2
Correct prediction
Energy consumption = 138.505530 pJ
sum error= 271
Actual label: 3
Output voltages: [0.24016, 0.02419, 0.071633, 0.79862, 0.042372, 0.017572, 0.0093004, 0.013233, 0.72603, 0.030749]
Predicted label: 3
Correct prediction
Energy consumption = 146.704683 pJ
sum error= 271
Actual label: 8
Output voltages: [0.023281, 0.0077478, 0.32776, 0.064786, 0.029594, 0.0052385, 0.014912, 0.034793, 0.79874, 0.023999]
Predicted label: 8
Correct prediction
Energy consumption = 136.861235 pJ
sum error= 271
Actual label: 3
Output voltages: [0.10019, 0.14604, 0.26513, 0.79869, 0.0095577, 0.010019, 0.0017846, 0.011827, 0.7417, 0.060161]
Predicted label: 3
Correct prediction
Energy consumption = 140.593346 pJ
sum error= 271
Actual label: 2
Output voltages: [0.65275, 0.10741, 0.7987, 0.05242, 0.03057, 0.0011914, 0.3836, 0.047926, 0.22514, 0.095471]
Predicted label: 2
Correct prediction
Energy consumption = 140.376254 pJ
sum error= 271
Actual label: 6
Output voltages: [0.049506, 0.034985, 0.41121, 0.0012401, 0.30629, 0.17901, 0.79874, 0.0038878, 0.40872, 0.0043553]
Predicted label: 6
Correct prediction
Energy consumption = 141.175509 pJ
sum error= 271
Actual label: 5
Output voltages: [0.29275, 0.0037662, 0.022972, 0.16862, 0.031975, 0.75493, 0.77721, 0.0011452, 0.76266, 0.016279]
Predicted label: 6
Wrong prediction!
Energy consumption = 138.548424 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 577 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 577 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 577 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.06185, 0.045327, 0.41763, 0.0015468, 0.29662, 0.1213, 0.79879, 0.0012459, 0.55047, 0.0027671]
Predicted label: 6
Correct prediction
Energy consumption = 148.896967 pJ
sum error= 272
Actual label: 8
Output voltages: [0.049967, 0.0043227, 0.11043, 0.25597, 0.0050701, 0.037557, 0.016087, 0.0018693, 0.79879, 0.38577]
Predicted label: 8
Correct prediction
Energy consumption = 142.964063 pJ
sum error= 272
Actual label: 2
Output voltages: [0.56949, 0.04266, 0.79875, 0.065458, 0.015629, 0.0011983, 0.049629, 0.2471, 0.42697, 0.034149]
Predicted label: 2
Correct prediction
Energy consumption = 144.222227 pJ
sum error= 272
Actual label: 7
Output voltages: [0.26957, 0.033152, 0.0021404, 0.24445, 0.0034202, 0.0029536, 0.0012573, 0.78996, 0.44754, 0.75503]
Predicted label: 7
Correct prediction
Energy consumption = 151.383923 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0033975, 0.017794, 0.029048, 0.025726, 0.79869, 0.001074, 0.15672, 0.048244, 0.074709, 0.016486]
Predicted label: 4
Correct prediction
Energy consumption = 155.408820 pJ
sum error= 272
Actual label: 8
Output voltages: [0.0065104, 0.063743, 0.20387, 0.022979, 0.025932, 0.0053289, 0.056683, 0.0058615, 0.79873, 0.44396]
Predicted label: 8
Correct prediction
Energy consumption = 137.592334 pJ
sum error= 272
Actual label: 1
Output voltages: [0.03167, 0.7985, 0.10545, 0.011342, 0.10356, 0.0041475, 0.63871, 0.0084649, 0.18148, 0.056856]
Predicted label: 1
Correct prediction
Energy consumption = 162.193836 pJ
sum error= 272
Actual label: 8
Output voltages: [0.0064642, 0.032698, 0.10676, 0.040225, 0.024091, 0.010137, 0.18201, 0.010398, 0.79873, 0.32015]
Predicted label: 8
Correct prediction
Energy consumption = 142.939343 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79843, 0.080759, 0.33802, 0.020077, 0.1575, 0.0010731, 0.23078, 0.039789, 0.22869, 0.008008]
Predicted label: 0
Correct prediction
Energy consumption = 155.431153 pJ
sum error= 272
Actual label: 5
Output voltages: [0.035162, 0.0017218, 0.001092, 0.6663, 0.0081752, 0.79875, 0.12788, 0.034344, 0.68754, 0.035866]
Predicted label: 5
Correct prediction
Energy consumption = 155.767664 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 578 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 578 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 578 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.52846, 0.018853, 0.44084, 0.79875, 0.018037, 0.002387, 0.0020706, 0.036366, 0.57659, 0.022007]
Predicted label: 3
Correct prediction
Energy consumption = 150.023920 pJ
sum error= 272
Actual label: 9
Output voltages: [0.17995, 0.012311, 0.013919, 0.058987, 0.046929, 0.0090307, 0.0015289, 0.024279, 0.71116, 0.79843]
Predicted label: 9
Correct prediction
Energy consumption = 147.889204 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0012469, 0.01599, 0.44577, 0.0073928, 0.7986, 0.0044833, 0.13714, 0.043562, 0.032467, 0.15263]
Predicted label: 4
Correct prediction
Energy consumption = 149.066245 pJ
sum error= 272
Actual label: 1
Output voltages: [0.047326, 0.79865, 0.21222, 0.045029, 0.05684, 0.0010659, 0.61136, 0.0010721, 0.12408, 0.026184]
Predicted label: 1
Correct prediction
Energy consumption = 164.733154 pJ
sum error= 272
Actual label: 9
Output voltages: [0.25568, 0.0070434, 0.0058398, 0.053294, 0.66555, 0.020748, 0.03104, 0.094338, 0.013877, 0.79408]
Predicted label: 9
Correct prediction
Energy consumption = 154.038149 pJ
sum error= 272
Actual label: 2
Output voltages: [0.39547, 0.032289, 0.79864, 0.03273, 0.0084577, 0.0011326, 0.20906, 0.024159, 0.43387, 0.023465]
Predicted label: 2
Correct prediction
Energy consumption = 135.154667 pJ
sum error= 272
Actual label: 1
Output voltages: [0.0092006, 0.79852, 0.16368, 0.10577, 0.017557, 0.0014294, 0.74854, 0.0046063, 0.11212, 0.047537]
Predicted label: 1
Correct prediction
Energy consumption = 155.767071 pJ
sum error= 272
Actual label: 9
Output voltages: [0.46309, 0.0070932, 0.024462, 0.017529, 0.12409, 0.021212, 0.0032431, 0.020336, 0.45184, 0.79866]
Predicted label: 9
Correct prediction
Energy consumption = 150.830395 pJ
sum error= 272
Actual label: 6
Output voltages: [0.042192, 0.047168, 0.18583, 0.0077328, 0.37234, 0.30018, 0.79872, 0.0029648, 0.60164, 0.005088]
Predicted label: 6
Correct prediction
Energy consumption = 147.375591 pJ
sum error= 272
Actual label: 7
Output voltages: [0.11858, 0.01699, 0.033924, 0.10732, 0.0042718, 0.0041877, 0.001153, 0.79872, 0.59522, 0.40168]
Predicted label: 7
Correct prediction
Energy consumption = 160.949311 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 579 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 579 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 579 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.67, 0.0027843, 0.02378, 0.0078456, 0.058612, 0.059143, 0.004012, 0.047626, 0.75526, 0.79798]
Predicted label: 9
Correct prediction
Energy consumption = 150.630774 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79791, 0.034195, 0.17307, 0.03657, 0.022816, 0.0042802, 0.76965, 0.016968, 0.16872, 0.016996]
Predicted label: 0
Correct prediction
Energy consumption = 149.104294 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0074342, 0.0056083, 0.052553, 0.0070114, 0.79871, 0.019947, 0.20591, 0.38229, 0.14375, 0.0015905]
Predicted label: 4
Correct prediction
Energy consumption = 155.211722 pJ
sum error= 272
Actual label: 6
Output voltages: [0.21653, 0.1266, 0.35244, 0.0044401, 0.26538, 0.22606, 0.79873, 0.0016595, 0.17884, 0.0063422]
Predicted label: 6
Correct prediction
Energy consumption = 147.360822 pJ
sum error= 272
Actual label: 1
Output voltages: [0.0069935, 0.79875, 0.032805, 0.0031831, 0.24435, 0.016149, 0.76149, 0.0018417, 0.46513, 0.016185]
Predicted label: 1
Correct prediction
Energy consumption = 156.840806 pJ
sum error= 272
Actual label: 7
Output voltages: [0.016565, 0.02278, 0.055933, 0.038045, 0.0098233, 0.0012618, 0.0011924, 0.79879, 0.76153, 0.15054]
Predicted label: 7
Correct prediction
Energy consumption = 154.023483 pJ
sum error= 272
Actual label: 3
Output voltages: [0.53212, 0.047531, 0.031699, 0.7986, 0.022653, 0.020354, 0.040834, 0.003004, 0.56842, 0.22724]
Predicted label: 3
Correct prediction
Energy consumption = 146.407452 pJ
sum error= 272
Actual label: 8
Output voltages: [0.015171, 0.03722, 0.065582, 0.62758, 0.0012696, 0.026376, 0.036534, 0.032808, 0.79877, 0.013358]
Predicted label: 8
Correct prediction
Energy consumption = 146.471255 pJ
sum error= 272
Actual label: 7
Output voltages: [0.24306, 0.022926, 0.019369, 0.20516, 0.00316, 0.0083591, 0.0011397, 0.79879, 0.42948, 0.71076]
Predicted label: 7
Correct prediction
Energy consumption = 150.939314 pJ
sum error= 272
Actual label: 2
Output voltages: [0.31834, 0.055776, 0.79876, 0.11632, 0.016724, 0.0012928, 0.3668, 0.052866, 0.64236, 0.048108]
Predicted label: 2
Correct prediction
Energy consumption = 145.034364 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 580 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 580 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 580 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.21265, 0.0073831, 0.042467, 0.375, 0.096006, 0.061238, 0.049366, 0.072821, 0.17897, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 156.232655 pJ
sum error= 272
Actual label: 6
Output voltages: [0.52087, 0.23423, 0.13447, 0.019882, 0.20942, 0.042799, 0.79562, 0.0010935, 0.53683, 0.0047282]
Predicted label: 6
Correct prediction
Energy consumption = 147.215119 pJ
sum error= 272
Actual label: 5
Output voltages: [0.045064, 0.0054692, 0.0089492, 0.48081, 0.010197, 0.79855, 0.026725, 0.012788, 0.78142, 0.068799]
Predicted label: 5
Correct prediction
Energy consumption = 146.740806 pJ
sum error= 272
Actual label: 8
Output voltages: [0.016218, 0.0030071, 0.034138, 0.24935, 0.0042239, 0.18787, 0.029712, 0.0011171, 0.7987, 0.040522]
Predicted label: 8
Correct prediction
Energy consumption = 138.990458 pJ
sum error= 272
Actual label: 3
Output voltages: [0.39577, 0.036604, 0.040851, 0.79858, 0.013694, 0.027826, 0.007993, 0.029547, 0.70263, 0.038015]
Predicted label: 3
Correct prediction
Energy consumption = 145.299088 pJ
sum error= 272
Actual label: 9
Output voltages: [0.45302, 0.01466, 0.0068726, 0.18689, 0.17293, 0.014691, 0.002364, 0.019716, 0.4747, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 142.452827 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79879, 0.049224, 0.074929, 0.049933, 0.14855, 0.0011194, 0.57621, 0.0058843, 0.14826, 0.065849]
Predicted label: 0
Correct prediction
Energy consumption = 152.388736 pJ
sum error= 272
Actual label: 5
Output voltages: [0.16792, 0.0011028, 0.026067, 0.35363, 0.0026812, 0.79811, 0.016689, 0.10933, 0.76053, 0.0569]
Predicted label: 5
Correct prediction
Energy consumption = 152.978058 pJ
sum error= 272
Actual label: 7
Output voltages: [0.26009, 0.11593, 0.31078, 0.35129, 0.0044121, 0.0021168, 0.0012024, 0.79871, 0.25642, 0.16454]
Predicted label: 7
Correct prediction
Energy consumption = 153.130601 pJ
sum error= 272
Actual label: 1
Output voltages: [0.006402, 0.79866, 0.031633, 0.015793, 0.16859, 0.0081739, 0.47625, 0.016265, 0.20122, 0.030082]
Predicted label: 1
Correct prediction
Energy consumption = 152.376426 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 581 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 581 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 581 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.072792, 0.025187, 0.1151, 0.0016555, 0.32686, 0.35333, 0.79866, 0.0057439, 0.53066, 0.011248]
Predicted label: 6
Correct prediction
Energy consumption = 149.498947 pJ
sum error= 272
Actual label: 1
Output voltages: [0.012993, 0.79864, 0.40837, 0.014512, 0.50682, 0.0011113, 0.28249, 0.014128, 0.074066, 0.014235]
Predicted label: 1
Correct prediction
Energy consumption = 153.742463 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79879, 0.035143, 0.23647, 0.047375, 0.041566, 0.0011464, 0.15238, 0.011821, 0.12572, 0.12173]
Predicted label: 0
Correct prediction
Energy consumption = 153.796978 pJ
sum error= 272
Actual label: 9
Output voltages: [0.54575, 0.0040087, 0.017345, 0.028346, 0.20488, 0.0057463, 0.0012267, 0.05277, 0.44966, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 152.668871 pJ
sum error= 272
Actual label: 3
Output voltages: [0.75349, 0.065451, 0.034557, 0.79879, 0.0046629, 0.42218, 0.13179, 0.037936, 0.19064, 0.0024341]
Predicted label: 3
Correct prediction
Energy consumption = 151.654207 pJ
sum error= 272
Actual label: 3
Output voltages: [0.73913, 0.012041, 0.064731, 0.79862, 0.024948, 0.09316, 0.013459, 0.023103, 0.62341, 0.039259]
Predicted label: 3
Correct prediction
Energy consumption = 133.372950 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0077874, 0.0048643, 0.46124, 0.0096444, 0.7987, 0.0014132, 0.50306, 0.48438, 0.013076, 0.0068027]
Predicted label: 4
Correct prediction
Energy consumption = 144.799474 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0021381, 0.0041495, 0.30792, 0.0073563, 0.79862, 0.001208, 0.42758, 0.093948, 0.017563, 0.022927]
Predicted label: 4
Correct prediction
Energy consumption = 145.844003 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79855, 0.036087, 0.043787, 0.02065, 0.024992, 0.0026599, 0.62975, 0.0056136, 0.080154, 0.065058]
Predicted label: 0
Correct prediction
Energy consumption = 157.797847 pJ
sum error= 272
Actual label: 6
Output voltages: [0.30165, 0.1103, 0.19077, 0.0039453, 0.30656, 0.13606, 0.79876, 0.0012368, 0.48206, 0.0045348]
Predicted label: 6
Correct prediction
Energy consumption = 145.298245 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 582 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 582 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 582 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.24872, 0.019329, 0.79879, 0.15427, 0.013756, 0.0011233, 0.15933, 0.24065, 0.4798, 0.0043061]
Predicted label: 2
Correct prediction
Energy consumption = 142.315149 pJ
sum error= 272
Actual label: 5
Output voltages: [0.050617, 0.0052558, 0.0025969, 0.45586, 0.018968, 0.79879, 0.17001, 0.039556, 0.7283, 0.04582]
Predicted label: 5
Correct prediction
Energy consumption = 149.112090 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0081147, 0.012146, 0.053514, 0.0072532, 0.79874, 0.0011145, 0.40859, 0.22253, 0.044323, 0.018797]
Predicted label: 4
Correct prediction
Energy consumption = 156.966380 pJ
sum error= 272
Actual label: 2
Output voltages: [0.23231, 0.065823, 0.79876, 0.024794, 0.0042236, 0.0012155, 0.034826, 0.04379, 0.28354, 0.037576]
Predicted label: 2
Correct prediction
Energy consumption = 151.310161 pJ
sum error= 272
Actual label: 3
Output voltages: [0.042823, 0.025319, 0.031188, 0.79874, 0.027591, 0.011257, 0.0041327, 0.024621, 0.70221, 0.069498]
Predicted label: 3
Correct prediction
Energy consumption = 134.896923 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0029254, 0.0049055, 0.36736, 0.0014971, 0.79851, 0.0076778, 0.20391, 0.14257, 0.073111, 0.087611]
Predicted label: 4
Correct prediction
Energy consumption = 150.023806 pJ
sum error= 272
Actual label: 6
Output voltages: [0.12378, 0.044761, 0.30778, 0.0017005, 0.12593, 0.091971, 0.79878, 0.0017757, 0.44284, 0.01504]
Predicted label: 6
Correct prediction
Energy consumption = 138.994402 pJ
sum error= 272
Actual label: 0
Output voltages: [0.7986, 0.036083, 0.21074, 0.035419, 0.022703, 0.001194, 0.58012, 0.015618, 0.29551, 0.1909]
Predicted label: 0
Correct prediction
Energy consumption = 157.024334 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79878, 0.01575, 0.039516, 0.062371, 0.0071831, 0.03781, 0.66309, 0.0020232, 0.03167, 0.31168]
Predicted label: 0
Correct prediction
Energy consumption = 138.097128 pJ
sum error= 272
Actual label: 2
Output voltages: [0.3382, 0.16055, 0.79482, 0.74535, 0.20969, 0.0011023, 0.016973, 0.08423, 0.043993, 0.029503]
Predicted label: 2
Correct prediction
Energy consumption = 146.398280 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 583 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 583 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 583 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7987, 0.029089, 0.016485, 0.035032, 0.037497, 0.01788, 0.31082, 0.034475, 0.24302, 0.33662]
Predicted label: 0
Correct prediction
Energy consumption = 149.527005 pJ
sum error= 272
Actual label: 1
Output voltages: [0.022928, 0.79856, 0.018401, 0.043635, 0.017199, 0.038704, 0.76954, 0.033756, 0.19257, 0.0064173]
Predicted label: 1
Correct prediction
Energy consumption = 162.727638 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0074558, 0.0013393, 0.38761, 0.0011834, 0.79857, 0.0012437, 0.073041, 0.021009, 0.069175, 0.049699]
Predicted label: 4
Correct prediction
Energy consumption = 141.496674 pJ
sum error= 272
Actual label: 5
Output voltages: [0.02757, 0.0013655, 0.0050515, 0.55504, 0.0082301, 0.79877, 0.017853, 0.048971, 0.75925, 0.071198]
Predicted label: 5
Correct prediction
Energy consumption = 143.645527 pJ
sum error= 272
Actual label: 6
Output voltages: [0.10476, 0.045112, 0.14804, 0.0032754, 0.17277, 0.14234, 0.79878, 0.0016786, 0.65836, 0.0085193]
Predicted label: 6
Correct prediction
Energy consumption = 146.159595 pJ
sum error= 272
Actual label: 7
Output voltages: [0.45544, 0.0015271, 0.62137, 0.058611, 0.040632, 0.0010842, 0.081631, 0.77714, 0.032705, 0.66448]
Predicted label: 7
Correct prediction
Energy consumption = 157.283456 pJ
sum error= 272
Actual label: 8
Output voltages: [0.0041327, 0.035171, 0.21179, 0.074871, 0.0031395, 0.03133, 0.055605, 0.0089601, 0.79875, 0.0475]
Predicted label: 8
Correct prediction
Energy consumption = 150.237515 pJ
sum error= 272
Actual label: 9
Output voltages: [0.39167, 0.0091569, 0.040524, 0.021332, 0.26374, 0.029886, 0.013415, 0.020399, 0.19502, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 154.227864 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79863, 0.03418, 0.038281, 0.013468, 0.036442, 0.14608, 0.4675, 0.041355, 0.031833, 0.020601]
Predicted label: 0
Correct prediction
Energy consumption = 142.214566 pJ
sum error= 272
Actual label: 1
Output voltages: [0.014365, 0.79866, 0.061371, 0.020141, 0.069259, 0.001707, 0.28343, 0.0010798, 0.31756, 0.038624]
Predicted label: 1
Correct prediction
Energy consumption = 157.263193 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 584 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 584 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 584 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.03237, 0.0036273, 0.79879, 0.12932, 0.0040378, 0.001067, 0.30915, 0.064026, 0.71925, 0.0026313]
Predicted label: 2
Correct prediction
Energy consumption = 148.913173 pJ
sum error= 272
Actual label: 3
Output voltages: [0.59013, 0.010542, 0.0086586, 0.79877, 0.0011095, 0.65438, 0.041135, 0.1399, 0.17029, 0.0011607]
Predicted label: 3
Correct prediction
Energy consumption = 136.344761 pJ
sum error= 272
Actual label: 4
Output voltages: [0.0011569, 0.009573, 0.047117, 0.01156, 0.79879, 0.0010885, 0.038518, 0.66878, 0.020537, 0.045608]
Predicted label: 4
Correct prediction
Energy consumption = 144.352095 pJ
sum error= 272
Actual label: 5
Output voltages: [0.030048, 0.001149, 0.0074652, 0.14531, 0.015352, 0.79845, 0.21168, 0.0088248, 0.76798, 0.056665]
Predicted label: 5
Correct prediction
Energy consumption = 145.552934 pJ
sum error= 272
Actual label: 6
Output voltages: [0.072048, 0.047956, 0.43526, 0.0021353, 0.36255, 0.2345, 0.7987, 0.0034198, 0.66232, 0.026283]
Predicted label: 6
Correct prediction
Energy consumption = 137.641290 pJ
sum error= 272
Actual label: 7
Output voltages: [0.54635, 0.0010799, 0.14701, 0.020107, 0.40589, 0.00108, 0.0012025, 0.79879, 0.24565, 0.11699]
Predicted label: 7
Correct prediction
Energy consumption = 150.089365 pJ
sum error= 272
Actual label: 8
Output voltages: [0.0056583, 0.011657, 0.048326, 0.039206, 0.0045675, 0.12727, 0.027856, 0.028202, 0.79869, 0.039571]
Predicted label: 8
Correct prediction
Energy consumption = 146.715280 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79878, 0.015186, 0.047958, 0.047226, 0.061632, 0.011678, 0.016761, 0.31141, 0.38691, 0.02906]
Predicted label: 0
Correct prediction
Energy consumption = 151.500619 pJ
sum error= 272
Actual label: 1
Output voltages: [0.010244, 0.79858, 0.13429, 0.052066, 0.0019512, 0.0012062, 0.38906, 0.008225, 0.38893, 0.017132]
Predicted label: 1
Correct prediction
Energy consumption = 165.839429 pJ
sum error= 272
Actual label: 2
Output voltages: [0.50252, 0.029981, 0.79649, 0.48708, 0.017899, 0.0011323, 0.21256, 0.015639, 0.68832, 0.016103]
Predicted label: 2
Correct prediction
Energy consumption = 143.698393 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 585 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 585 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 585 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.74054, 0.0086618, 0.12719, 0.79878, 0.0061477, 0.25711, 0.0013424, 0.061407, 0.29025, 0.0058513]
Predicted label: 3
Correct prediction
Energy consumption = 146.003732 pJ
sum error= 272
Actual label: 4
Output voltages: [0.052591, 0.040519, 0.19974, 0.04311, 0.79871, 0.0012736, 0.34224, 0.039188, 0.0075441, 0.03702]
Predicted label: 4
Correct prediction
Energy consumption = 148.323916 pJ
sum error= 272
Actual label: 5
Output voltages: [0.048707, 0.0016826, 0.0011296, 0.46313, 0.049778, 0.79878, 0.22273, 0.038903, 0.64409, 0.1742]
Predicted label: 5
Correct prediction
Energy consumption = 149.625083 pJ
sum error= 272
Actual label: 6
Output voltages: [0.032628, 0.010924, 0.075183, 0.0082625, 0.32662, 0.28458, 0.79877, 0.0045518, 0.62952, 0.017176]
Predicted label: 6
Correct prediction
Energy consumption = 147.487526 pJ
sum error= 272
Actual label: 7
Output voltages: [0.24443, 0.0037189, 0.022138, 0.024525, 0.073757, 0.0012912, 0.0010722, 0.79877, 0.40185, 0.27178]
Predicted label: 7
Correct prediction
Energy consumption = 150.074826 pJ
sum error= 272
Actual label: 8
Output voltages: [0.16739, 0.060945, 0.19676, 0.48282, 0.0064783, 0.014653, 0.19746, 0.0079144, 0.79879, 0.033885]
Predicted label: 8
Correct prediction
Energy consumption = 150.721089 pJ
sum error= 272
Actual label: 9
Output voltages: [0.63178, 0.012698, 0.0045569, 0.12038, 0.6004, 0.16548, 0.020358, 0.027678, 0.13106, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 155.518402 pJ
sum error= 272
Actual label: 8
Output voltages: [0.16481, 0.034198, 0.42567, 0.17903, 0.02387, 0.0025308, 0.039913, 0.0012287, 0.79873, 0.091325]
Predicted label: 8
Correct prediction
Energy consumption = 152.185818 pJ
sum error= 272
Actual label: 7
Output voltages: [0.24408, 0.0011593, 0.0066754, 0.67087, 0.31027, 0.0011074, 0.0011458, 0.70198, 0.62029, 0.32317]
Predicted label: 7
Correct prediction
Energy consumption = 143.516032 pJ
sum error= 272
Actual label: 1
Output voltages: [0.01475, 0.7984, 0.37485, 0.14891, 0.026965, 0.0026051, 0.5877, 0.0042123, 0.030668, 0.070273]
Predicted label: 1
Correct prediction
Energy consumption = 156.746404 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 586 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 586 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 586 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.47567, 0.001069, 0.023718, 0.79876, 0.089361, 0.48687, 0.0057806, 0.0087072, 0.3933, 0.014714]
Predicted label: 3
Correct prediction
Energy consumption = 142.906631 pJ
sum error= 272
Actual label: 7
Output voltages: [0.027956, 0.020617, 0.14556, 0.042867, 0.031929, 0.0011027, 0.0012409, 0.79862, 0.12478, 0.017425]
Predicted label: 7
Correct prediction
Energy consumption = 149.954433 pJ
sum error= 272
Actual label: 5
Output voltages: [0.18066, 0.0018784, 0.0025789, 0.74369, 0.026781, 0.79872, 0.04292, 0.14888, 0.54378, 0.21727]
Predicted label: 5
Correct prediction
Energy consumption = 145.590626 pJ
sum error= 272
Actual label: 2
Output voltages: [0.30023, 0.030871, 0.79879, 0.031744, 0.013821, 0.0012927, 0.38767, 0.021586, 0.65359, 0.021064]
Predicted label: 2
Correct prediction
Energy consumption = 153.033824 pJ
sum error= 272
Actual label: 8
Output voltages: [0.010883, 0.02097, 0.055015, 0.018388, 0.013274, 0.013372, 0.056418, 0.010796, 0.79873, 0.25521]
Predicted label: 8
Correct prediction
Energy consumption = 148.800429 pJ
sum error= 272
Actual label: 0
Output voltages: [0.79873, 0.046691, 0.044884, 0.018547, 0.024146, 0.018872, 0.19068, 0.012687, 0.24469, 0.033517]
Predicted label: 0
Correct prediction
Energy consumption = 154.730376 pJ
sum error= 272
Actual label: 7
Output voltages: [0.13573, 0.0091483, 0.074008, 0.0050952, 0.36138, 0.0010919, 0.0011717, 0.79866, 0.036467, 0.027371]
Predicted label: 7
Correct prediction
Energy consumption = 152.028487 pJ
sum error= 272
Actual label: 5
Output voltages: [0.20931, 0.0015252, 0.0021012, 0.70682, 0.030909, 0.79852, 0.059582, 0.028126, 0.61539, 0.1702]
Predicted label: 5
Correct prediction
Energy consumption = 148.590741 pJ
sum error= 272
Actual label: 9
Output voltages: [0.23673, 0.042668, 0.038006, 0.2666, 0.27609, 0.027218, 0.021938, 0.027884, 0.16885, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 147.985855 pJ
sum error= 272
Actual label: 9
Output voltages: [0.2516, 0.020561, 0.027838, 0.19699, 0.4028, 0.065399, 0.022079, 0.014707, 0.056604, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 140.036146 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 587 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 587 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 587 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79873, 0.050013, 0.236, 0.011776, 0.03994, 0.0016081, 0.10944, 0.027393, 0.25928, 0.042616]
Predicted label: 0
Correct prediction
Energy consumption = 161.405030 pJ
sum error= 272
Actual label: 9
Output voltages: [0.17226, 0.014772, 0.0037573, 0.26187, 0.62292, 0.3118, 0.10475, 0.019199, 0.02768, 0.79837]
Predicted label: 9
Correct prediction
Energy consumption = 146.108261 pJ
sum error= 272
Actual label: 1
Output voltages: [0.048252, 0.79866, 0.34388, 0.31954, 0.024062, 0.0011143, 0.28861, 0.0013549, 0.11079, 0.1402]
Predicted label: 1
Correct prediction
Energy consumption = 168.495262 pJ
sum error= 272
Actual label: 1
Output voltages: [0.072438, 0.7985, 0.024963, 0.14203, 0.006541, 0.0037043, 0.7564, 0.0020656, 0.24655, 0.037255]
Predicted label: 1
Correct prediction
Energy consumption = 154.830381 pJ
sum error= 272
Actual label: 5
Output voltages: [0.029814, 0.0011353, 0.0041712, 0.75855, 0.012208, 0.79494, 0.082579, 0.033759, 0.59859, 0.046147]
Predicted label: 5
Correct prediction
Energy consumption = 148.313094 pJ
sum error= 272
Actual label: 8
Output voltages: [0.028243, 0.15308, 0.09009, 0.12789, 0.025217, 0.0077401, 0.041092, 0.0093079, 0.79874, 0.47934]
Predicted label: 8
Correct prediction
Energy consumption = 148.954673 pJ
sum error= 272
Actual label: 8
Output voltages: [0.02041, 0.016257, 0.33302, 0.084488, 0.0059278, 0.011968, 0.029465, 0.022619, 0.79875, 0.19034]
Predicted label: 8
Correct prediction
Energy consumption = 143.735842 pJ
sum error= 272
Actual label: 6
Output voltages: [0.62809, 0.1065, 0.025229, 0.0089871, 0.03883, 0.77494, 0.7976, 0.017275, 0.2661, 0.001066]
Predicted label: 6
Correct prediction
Energy consumption = 153.259325 pJ
sum error= 272
Actual label: 3
Output voltages: [0.33255, 0.0010663, 0.27139, 0.79764, 0.016372, 0.48675, 0.003678, 0.0052069, 0.62524, 0.0076402]
Predicted label: 3
Correct prediction
Energy consumption = 140.966111 pJ
sum error= 272
Actual label: 2
Output voltages: [0.58369, 0.084429, 0.79879, 0.20044, 0.031143, 0.0011857, 0.46501, 0.027785, 0.41136, 0.048837]
Predicted label: 2
Correct prediction
Energy consumption = 140.985831 pJ
sum error= 272
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 588 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 588 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 588 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.038037, 0.79836, 0.019906, 0.079223, 0.034952, 0.022386, 0.49699, 0.010329, 0.041934, 0.10309]
Predicted label: 1
Correct prediction
Energy consumption = 163.866608 pJ
sum error= 272
Actual label: 8
Output voltages: [0.015212, 0.046811, 0.22199, 0.035579, 0.0041037, 0.033357, 0.020266, 0.02302, 0.79866, 0.047102]
Predicted label: 8
Correct prediction
Energy consumption = 156.412981 pJ
sum error= 272
Actual label: 3
Output voltages: [0.17981, 0.026956, 0.20824, 0.79879, 0.0082198, 0.02791, 0.0026781, 0.0010825, 0.75163, 0.019869]
Predicted label: 3
Correct prediction
Energy consumption = 141.966826 pJ
sum error= 272
Actual label: 2
Output voltages: [0.4194, 0.036363, 0.79878, 0.053227, 0.01504, 0.0011983, 0.38079, 0.023757, 0.68497, 0.013274]
Predicted label: 2
Correct prediction
Energy consumption = 142.411447 pJ
sum error= 272
Actual label: 6
Output voltages: [0.048269, 0.29491, 0.20598, 0.0067281, 0.25367, 0.32342, 0.79859, 0.0036516, 0.30567, 0.022098]
Predicted label: 6
Correct prediction
Energy consumption = 146.694128 pJ
sum error= 272
Actual label: 5
Output voltages: [0.032179, 0.0019828, 0.0083879, 0.4421, 0.015057, 0.79864, 0.059544, 0.066368, 0.75516, 0.30402]
Predicted label: 5
Correct prediction
Energy consumption = 148.231770 pJ
sum error= 272
Actual label: 6
Output voltages: [0.097068, 0.05072, 0.06568, 0.0095004, 0.049911, 0.24225, 0.79869, 0.0018523, 0.59025, 0.0042968]
Predicted label: 6
Correct prediction
Energy consumption = 152.169619 pJ
sum error= 272
Actual label: 7
Output voltages: [0.79153, 0.36169, 0.64583, 0.0031522, 0.087408, 0.0011024, 0.044635, 0.041764, 0.23065, 0.67717]
Predicted label: 0
Wrong prediction!
Energy consumption = 155.092238 pJ
sum error= 273
Actual label: 4
Output voltages: [0.66196, 0.020968, 0.44578, 0.049098, 0.61555, 0.0010838, 0.69039, 0.00193, 0.20009, 0.12013]
Predicted label: 6
Wrong prediction!
Energy consumption = 148.594805 pJ
sum error= 274
Actual label: 1
Output voltages: [0.0029258, 0.79875, 0.62034, 0.50916, 0.43305, 0.0027158, 0.32356, 0.028132, 0.032348, 0.095061]
Predicted label: 1
Correct prediction
Energy consumption = 166.730010 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 589 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 589 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 589 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79866, 0.056763, 0.014031, 0.0027823, 0.018327, 0.050524, 0.73926, 0.17729, 0.49124, 0.02745]
Predicted label: 0
Correct prediction
Energy consumption = 167.618259 pJ
sum error= 274
Actual label: 5
Output voltages: [0.5948, 0.0010659, 0.024702, 0.59858, 0.0046281, 0.77928, 0.42728, 0.020647, 0.72924, 0.016473]
Predicted label: 5
Correct prediction
Energy consumption = 140.828262 pJ
sum error= 274
Actual label: 3
Output voltages: [0.70312, 0.0223, 0.060121, 0.79865, 0.017629, 0.011561, 0.020003, 0.023607, 0.5514, 0.027473]
Predicted label: 3
Correct prediction
Energy consumption = 140.435311 pJ
sum error= 274
Actual label: 1
Output voltages: [0.0060355, 0.79844, 0.015643, 0.23952, 0.053972, 0.014923, 0.33048, 0.0099654, 0.12229, 0.18694]
Predicted label: 1
Correct prediction
Energy consumption = 166.071821 pJ
sum error= 274
Actual label: 9
Output voltages: [0.43077, 0.010577, 0.0056297, 0.043725, 0.050197, 0.21999, 0.029954, 0.21321, 0.59025, 0.79847]
Predicted label: 9
Correct prediction
Energy consumption = 155.470364 pJ
sum error= 274
Actual label: 2
Output voltages: [0.20475, 0.11738, 0.79835, 0.061467, 0.019235, 0.0011781, 0.30942, 0.027169, 0.44955, 0.0073915]
Predicted label: 2
Correct prediction
Energy consumption = 149.563193 pJ
sum error= 274
Actual label: 1
Output voltages: [0.031049, 0.79836, 0.016039, 0.080938, 0.024227, 0.014417, 0.55253, 0.025107, 0.13606, 0.096798]
Predicted label: 1
Correct prediction
Energy consumption = 158.788366 pJ
sum error= 274
Actual label: 9
Output voltages: [0.45709, 0.0016021, 0.022955, 0.0059041, 0.44583, 0.012604, 0.013676, 0.016749, 0.26253, 0.79854]
Predicted label: 9
Correct prediction
Energy consumption = 152.984477 pJ
sum error= 274
Actual label: 6
Output voltages: [0.042916, 0.10287, 0.13364, 0.010301, 0.32891, 0.32283, 0.79867, 0.0029263, 0.52688, 0.011379]
Predicted label: 6
Correct prediction
Energy consumption = 146.237023 pJ
sum error= 274
Actual label: 0
Output voltages: [0.79599, 0.055472, 0.060658, 0.024093, 0.011588, 0.0025339, 0.78246, 0.0082774, 0.15923, 0.077888]
Predicted label: 0
Correct prediction
Energy consumption = 156.305268 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 590 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 590 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 590 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0012991, 0.014534, 0.2927, 0.013927, 0.79867, 0.0096558, 0.23254, 0.065881, 0.031604, 0.21046]
Predicted label: 4
Correct prediction
Energy consumption = 146.850776 pJ
sum error= 274
Actual label: 6
Output voltages: [0.073115, 0.044731, 0.19155, 0.0039521, 0.43998, 0.10638, 0.79871, 0.0018538, 0.54303, 0.0034616]
Predicted label: 6
Correct prediction
Energy consumption = 149.655377 pJ
sum error= 274
Actual label: 1
Output voltages: [0.023199, 0.79838, 0.042276, 0.042215, 0.0058535, 0.0016539, 0.5098, 0.0046246, 0.32225, 0.024182]
Predicted label: 1
Correct prediction
Energy consumption = 163.963633 pJ
sum error= 274
Actual label: 7
Output voltages: [0.030588, 0.23781, 0.025757, 0.042991, 0.019462, 0.0024675, 0.0045989, 0.7987, 0.038406, 0.48586]
Predicted label: 7
Correct prediction
Energy consumption = 159.426611 pJ
sum error= 274
Actual label: 3
Output voltages: [0.046956, 0.043277, 0.18377, 0.79875, 0.020004, 0.044596, 0.0022895, 0.0070602, 0.6844, 0.12619]
Predicted label: 3
Correct prediction
Energy consumption = 145.524273 pJ
sum error= 274
Actual label: 8
Output voltages: [0.020986, 0.12953, 0.10181, 0.49623, 0.0023788, 0.026365, 0.016785, 0.0068614, 0.79875, 0.10312]
Predicted label: 8
Correct prediction
Energy consumption = 146.108518 pJ
sum error= 274
Actual label: 7
Output voltages: [0.3095, 0.011838, 0.0044917, 0.48079, 0.64362, 0.0010662, 0.0022197, 0.79876, 0.023068, 0.46624]
Predicted label: 7
Correct prediction
Energy consumption = 155.490139 pJ
sum error= 274
Actual label: 2
Output voltages: [0.096095, 0.40761, 0.79772, 0.34011, 0.0013626, 0.0012926, 0.21551, 0.0014008, 0.42157, 0.017558]
Predicted label: 2
Correct prediction
Energy consumption = 146.532391 pJ
sum error= 274
Actual label: 9
Output voltages: [0.25042, 0.029307, 0.027125, 0.71501, 0.16347, 0.0049609, 0.0055262, 0.038689, 0.03775, 0.7984]
Predicted label: 9
Correct prediction
Energy consumption = 149.382452 pJ
sum error= 274
Actual label: 6
Output voltages: [0.17992, 0.039877, 0.080348, 0.0017427, 0.49976, 0.071307, 0.79879, 0.0017126, 0.62987, 0.0024157]
Predicted label: 6
Correct prediction
Energy consumption = 148.409632 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 591 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 591 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 591 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.032324, 0.0013944, 0.001557, 0.65286, 0.017061, 0.79872, 0.12979, 0.40275, 0.73981, 0.049608]
Predicted label: 5
Correct prediction
Energy consumption = 147.778718 pJ
sum error= 274
Actual label: 8
Output voltages: [0.027411, 0.0053545, 0.02787, 0.052214, 0.026138, 0.033933, 0.016261, 0.0099904, 0.79872, 0.12263]
Predicted label: 8
Correct prediction
Energy consumption = 149.525489 pJ
sum error= 274
Actual label: 3
Output voltages: [0.69257, 0.0034804, 0.0092518, 0.79677, 0.011688, 0.36505, 0.053415, 0.052679, 0.45226, 0.0020287]
Predicted label: 3
Correct prediction
Energy consumption = 140.702419 pJ
sum error= 274
Actual label: 5
Output voltages: [0.715, 0.025206, 0.016285, 0.69797, 0.0022611, 0.79772, 0.39232, 0.0028199, 0.58676, 0.0080278]
Predicted label: 5
Correct prediction
Energy consumption = 137.443660 pJ
sum error= 274
Actual label: 7
Output voltages: [0.12508, 0.020013, 0.010462, 0.019961, 0.44679, 0.0011239, 0.001121, 0.79874, 0.44783, 0.027346]
Predicted label: 7
Correct prediction
Energy consumption = 156.038069 pJ
sum error= 274
Actual label: 1
Output voltages: [0.0023406, 0.79849, 0.037304, 0.14908, 0.0065509, 0.014654, 0.77661, 0.065413, 0.098292, 0.017652]
Predicted label: 1
Correct prediction
Energy consumption = 165.887341 pJ
sum error= 274
Actual label: 6
Output voltages: [0.21936, 0.084026, 0.21612, 0.0011222, 0.31178, 0.13803, 0.79877, 0.0011582, 0.39647, 0.0044133]
Predicted label: 6
Correct prediction
Energy consumption = 148.879914 pJ
sum error= 274
Actual label: 1
Output voltages: [0.0072645, 0.79857, 0.10837, 0.12836, 0.055716, 0.0014238, 0.37983, 0.0015353, 0.18827, 0.33875]
Predicted label: 1
Correct prediction
Energy consumption = 165.058184 pJ
sum error= 274
Actual label: 0
Output voltages: [0.79536, 0.051257, 0.15654, 0.019933, 0.022844, 0.0041382, 0.62252, 0.0080664, 0.52095, 0.016074]
Predicted label: 0
Correct prediction
Energy consumption = 164.323572 pJ
sum error= 274
Actual label: 9
Output voltages: [0.14144, 0.0067844, 0.043672, 0.03681, 0.28581, 0.010524, 0.16339, 0.014035, 0.099528, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 154.524047 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 592 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 592 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 592 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.1274, 0.032111, 0.22933, 0.0028653, 0.40063, 0.22712, 0.79874, 0.0015337, 0.60905, 0.0061975]
Predicted label: 6
Correct prediction
Energy consumption = 154.198003 pJ
sum error= 274
Actual label: 2
Output voltages: [0.19509, 0.42659, 0.7975, 0.10795, 0.0016338, 0.0012115, 0.077794, 0.1218, 0.43668, 0.042659]
Predicted label: 2
Correct prediction
Energy consumption = 155.687124 pJ
sum error= 274
Actual label: 5
Output voltages: [0.75504, 0.0010664, 0.01995, 0.36689, 0.0020323, 0.79821, 0.03148, 0.031912, 0.65868, 0.048951]
Predicted label: 5
Correct prediction
Energy consumption = 151.303502 pJ
sum error= 274
Actual label: 4
Output voltages: [0.0021684, 0.14832, 0.20292, 0.001674, 0.79867, 0.001256, 0.35148, 0.32239, 0.0048132, 0.13045]
Predicted label: 4
Correct prediction
Energy consumption = 152.193491 pJ
sum error= 274
Actual label: 2
Output voltages: [0.31538, 0.22831, 0.79875, 0.09452, 0.0048572, 0.0012956, 0.3335, 0.11045, 0.30392, 0.010005]
Predicted label: 2
Correct prediction
Energy consumption = 156.315351 pJ
sum error= 274
Actual label: 3
Output voltages: [0.38778, 0.0028725, 0.14527, 0.79877, 0.039321, 0.41237, 0.0096732, 0.025321, 0.6358, 0.021317]
Predicted label: 3
Correct prediction
Energy consumption = 145.731538 pJ
sum error= 274
Actual label: 4
Output voltages: [0.0024894, 0.011969, 0.06342, 0.060451, 0.79877, 0.0057632, 0.011617, 0.12511, 0.041599, 0.28822]
Predicted label: 4
Correct prediction
Energy consumption = 156.741026 pJ
sum error= 274
Actual label: 4
Output voltages: [0.011501, 0.0033382, 0.36782, 0.013881, 0.79857, 0.0055464, 0.069384, 0.032833, 0.027983, 0.21287]
Predicted label: 4
Correct prediction
Energy consumption = 147.509660 pJ
sum error= 274
Actual label: 6
Output voltages: [0.070653, 0.048355, 0.26491, 0.0021052, 0.22705, 0.046854, 0.79874, 0.001135, 0.35554, 0.0081498]
Predicted label: 6
Correct prediction
Energy consumption = 143.800240 pJ
sum error= 274
Actual label: 0
Output voltages: [0.79847, 0.20116, 0.29876, 0.014717, 0.020987, 0.0020283, 0.41839, 0.0021677, 0.48551, 0.052443]
Predicted label: 0
Correct prediction
Energy consumption = 152.646793 pJ
sum error= 274
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 593 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 593 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 593 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79823, 0.061105, 0.05408, 0.012438, 0.0068358, 0.0037939, 0.74854, 0.0055631, 0.24226, 0.023443]
Predicted label: 0
Correct prediction
Energy consumption = 158.358945 pJ
sum error= 274
Actual label: 2
Output voltages: [0.47161, 0.11098, 0.79873, 0.050647, 0.038645, 0.0012015, 0.57971, 0.021755, 0.46538, 0.048195]
Predicted label: 2
Correct prediction
Energy consumption = 141.581096 pJ
sum error= 274
Actual label: 0
Output voltages: [0.79877, 0.048898, 0.0070599, 0.017019, 0.01043, 0.019111, 0.5539, 0.021563, 0.12062, 0.073314]
Predicted label: 0
Correct prediction
Energy consumption = 150.638376 pJ
sum error= 274
Actual label: 1
Output voltages: [0.015997, 0.79852, 0.26674, 0.10102, 0.021319, 0.010604, 0.40298, 0.0016877, 0.01705, 0.052262]
Predicted label: 1
Correct prediction
Energy consumption = 166.495255 pJ
sum error= 274
Actual label: 2
Output voltages: [0.28484, 0.33894, 0.79875, 0.28335, 0.031002, 0.0012167, 0.42528, 0.051572, 0.07163, 0.027507]
Predicted label: 2
Correct prediction
Energy consumption = 151.539449 pJ
sum error= 274
Actual label: 3
Output voltages: [0.71894, 0.01368, 0.069383, 0.79834, 0.0076804, 0.022293, 0.0059515, 0.012912, 0.34319, 0.19648]
Predicted label: 3
Correct prediction
Energy consumption = 150.310530 pJ
sum error= 274
Actual label: 4
Output voltages: [0.049406, 0.024171, 0.036006, 0.019085, 0.75182, 0.049379, 0.0099999, 0.46374, 0.035029, 0.78739]
Predicted label: 9
Wrong prediction!
Energy consumption = 150.264827 pJ
sum error= 275
Actual label: 5
Output voltages: [0.022754, 0.001085, 0.016157, 0.76517, 0.11132, 0.58074, 0.0083516, 0.0247, 0.30353, 0.52442]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.233582 pJ
sum error= 276
Actual label: 6
Output voltages: [0.049281, 0.04604, 0.26506, 0.0019427, 0.35754, 0.22863, 0.79869, 0.0025584, 0.53358, 0.0090077]
Predicted label: 6
Correct prediction
Energy consumption = 148.315165 pJ
sum error= 276
Actual label: 7
Output voltages: [0.12646, 0.025926, 0.016401, 0.03567, 0.016883, 0.0012342, 0.0011173, 0.79832, 0.14005, 0.57447]
Predicted label: 7
Correct prediction
Energy consumption = 156.195747 pJ
sum error= 276
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 594 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 594 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 594 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.12704, 0.0047732, 0.64723, 0.048009, 0.019243, 0.0088976, 0.021786, 0.0039577, 0.79878, 0.27786]
Predicted label: 8
Correct prediction
Energy consumption = 154.185041 pJ
sum error= 276
Actual label: 9
Output voltages: [0.60052, 0.0046458, 0.016728, 0.03072, 0.13917, 0.016987, 0.0011228, 0.00967, 0.55056, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.345692 pJ
sum error= 276
Actual label: 0
Output voltages: [0.79863, 0.031725, 0.034032, 0.0097807, 0.0041643, 0.016624, 0.71478, 0.012277, 0.24722, 0.031556]
Predicted label: 0
Correct prediction
Energy consumption = 143.206309 pJ
sum error= 276
Actual label: 1
Output voltages: [0.0247, 0.7986, 0.079998, 0.25679, 0.0082347, 0.0019719, 0.65512, 0.0013002, 0.061419, 0.018603]
Predicted label: 1
Correct prediction
Energy consumption = 156.078355 pJ
sum error= 276
Actual label: 2
Output voltages: [0.21429, 0.18795, 0.79867, 0.012504, 0.0094145, 0.0012626, 0.073231, 0.035474, 0.29319, 0.046121]
Predicted label: 2
Correct prediction
Energy consumption = 150.941584 pJ
sum error= 276
Actual label: 3
Output voltages: [0.32622, 0.059838, 0.025506, 0.79876, 0.015771, 0.11331, 0.012202, 0.001376, 0.72101, 0.1283]
Predicted label: 3
Correct prediction
Energy consumption = 145.751338 pJ
sum error= 276
Actual label: 4
Output voltages: [0.0063516, 0.0037636, 0.2731, 0.053613, 0.79862, 0.033317, 0.014913, 0.048954, 0.090752, 0.50428]
Predicted label: 4
Correct prediction
Energy consumption = 154.383587 pJ
sum error= 276
Actual label: 5
Output voltages: [0.19373, 0.001108, 0.0037332, 0.44268, 0.015728, 0.79828, 0.031666, 0.19238, 0.77693, 0.028871]
Predicted label: 5
Correct prediction
Energy consumption = 146.458250 pJ
sum error= 276
Actual label: 6
Output voltages: [0.034023, 0.032615, 0.39706, 0.0013164, 0.55344, 0.18684, 0.79868, 0.0043654, 0.42995, 0.013754]
Predicted label: 6
Correct prediction
Energy consumption = 146.714690 pJ
sum error= 276
Actual label: 7
Output voltages: [0.46657, 0.25346, 0.0056646, 0.56997, 0.0010741, 0.047109, 0.0012412, 0.7973, 0.041555, 0.61568]
Predicted label: 7
Correct prediction
Energy consumption = 158.320802 pJ
sum error= 276
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 595 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 595 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 595 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.47791, 0.0020494, 0.73046, 0.36569, 0.0035102, 0.0011638, 0.048785, 0.0021176, 0.78802, 0.57443]
Predicted label: 8
Correct prediction
Energy consumption = 154.740553 pJ
sum error= 276
Actual label: 9
Output voltages: [0.44195, 0.011287, 0.029396, 0.019204, 0.038259, 0.0011458, 0.0012671, 0.03355, 0.60405, 0.7981]
Predicted label: 9
Correct prediction
Energy consumption = 146.360445 pJ
sum error= 276
Actual label: 0
Output voltages: [0.7987, 0.071781, 0.011015, 0.0095237, 0.0043931, 0.017287, 0.57991, 0.0080857, 0.05751, 0.33784]
Predicted label: 0
Correct prediction
Energy consumption = 153.477919 pJ
sum error= 276
Actual label: 1
Output voltages: [0.0072135, 0.79863, 0.57155, 0.4822, 0.41484, 0.0017816, 0.0287, 0.032357, 0.0065934, 0.04101]
Predicted label: 1
Correct prediction
Energy consumption = 161.516482 pJ
sum error= 276
Actual label: 2
Output voltages: [0.10376, 0.022178, 0.79879, 0.23245, 0.035934, 0.0011156, 0.045668, 0.1158, 0.058435, 0.010735]
Predicted label: 2
Correct prediction
Energy consumption = 141.377864 pJ
sum error= 276
Actual label: 3
Output voltages: [0.44713, 0.029283, 0.29599, 0.099213, 0.0041432, 0.0035137, 0.01019, 0.0013441, 0.79837, 0.73422]
Predicted label: 8
Wrong prediction!
Energy consumption = 151.347906 pJ
sum error= 277
Actual label: 4
Output voltages: [0.018146, 0.003221, 0.19889, 0.014624, 0.79861, 0.0035728, 0.064726, 0.010925, 0.051167, 0.19921]
Predicted label: 4
Correct prediction
Energy consumption = 151.975138 pJ
sum error= 277
Actual label: 5
Output voltages: [0.16824, 0.0011446, 0.013899, 0.070109, 0.021291, 0.7942, 0.048413, 0.024698, 0.7954, 0.2819]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.548709 pJ
sum error= 278
Actual label: 6
Output voltages: [0.085475, 0.044808, 0.47029, 0.0010691, 0.7283, 0.12515, 0.79868, 0.0013218, 0.066632, 0.020063]
Predicted label: 6
Correct prediction
Energy consumption = 145.383390 pJ
sum error= 278
Actual label: 7
Output voltages: [0.097222, 0.021093, 0.026874, 0.026443, 0.021274, 0.0072972, 0.0010966, 0.79819, 0.078968, 0.77035]
Predicted label: 7
Correct prediction
Energy consumption = 158.848009 pJ
sum error= 278
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 596 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 596 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 596 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.036322, 0.0025405, 0.7501, 0.10622, 0.0041642, 0.002131, 0.037207, 0.0053013, 0.79857, 0.19697]
Predicted label: 8
Correct prediction
Energy consumption = 158.388145 pJ
sum error= 278
Actual label: 9
Output voltages: [0.084541, 0.036787, 0.10438, 0.25934, 0.049002, 0.0014179, 0.0011072, 0.41722, 0.022866, 0.79354]
Predicted label: 9
Correct prediction
Energy consumption = 155.921453 pJ
sum error= 278
Actual label: 8
Output voltages: [0.15475, 0.0136, 0.64931, 0.031742, 0.03068, 0.01354, 0.32042, 0.0022205, 0.79816, 0.28302]
Predicted label: 8
Correct prediction
Energy consumption = 150.739143 pJ
sum error= 278
Actual label: 6
Output voltages: [0.077538, 0.023633, 0.055819, 0.0053154, 0.52137, 0.28252, 0.79874, 0.0093731, 0.69917, 0.0048803]
Predicted label: 6
Correct prediction
Energy consumption = 148.448000 pJ
sum error= 278
Actual label: 5
Output voltages: [0.040554, 0.0014607, 0.0038542, 0.50888, 0.019525, 0.79797, 0.062566, 0.024545, 0.73666, 0.088425]
Predicted label: 5
Correct prediction
Energy consumption = 142.852282 pJ
sum error= 278
Actual label: 0
Output voltages: [0.79873, 0.0083623, 0.038922, 0.0077406, 0.0072284, 0.0033467, 0.52259, 0.045055, 0.26672, 0.042278]
Predicted label: 0
Correct prediction
Energy consumption = 153.189162 pJ
sum error= 278
Actual label: 6
Output voltages: [0.53376, 0.033455, 0.098763, 0.012649, 0.081521, 0.10278, 0.79876, 0.001209, 0.61037, 0.020988]
Predicted label: 6
Correct prediction
Energy consumption = 142.696435 pJ
sum error= 278
Actual label: 8
Output voltages: [0.16012, 0.014889, 0.6655, 0.02697, 0.01533, 0.0017298, 0.013942, 0.0078745, 0.79879, 0.22128]
Predicted label: 8
Correct prediction
Energy consumption = 151.342450 pJ
sum error= 278
Actual label: 9
Output voltages: [0.40811, 0.014701, 0.041202, 0.034273, 0.061256, 0.0092037, 0.013764, 0.13195, 0.43916, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.548926 pJ
sum error= 278
Actual label: 4
Output voltages: [0.0032002, 0.0094069, 0.057669, 0.026029, 0.79879, 0.13316, 0.012161, 0.0047167, 0.19303, 0.74116]
Predicted label: 4
Correct prediction
Energy consumption = 156.174711 pJ
sum error= 278
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 597 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 597 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 597 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.013147, 0.79879, 0.26097, 0.045311, 0.031274, 0.0012657, 0.67013, 0.0010712, 0.10859, 0.048377]
Predicted label: 1
Correct prediction
Energy consumption = 163.899355 pJ
sum error= 278
Actual label: 9
Output voltages: [0.19414, 0.010317, 0.018457, 0.091753, 0.12128, 0.0056989, 0.01825, 0.054059, 0.39497, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 152.992918 pJ
sum error= 278
Actual label: 5
Output voltages: [0.040622, 0.0010929, 0.018051, 0.74885, 0.025402, 0.74057, 0.0039224, 0.042032, 0.77314, 0.076136]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.311148 pJ
sum error= 279
Actual label: 3
Output voltages: [0.052789, 0.045545, 0.038173, 0.79844, 0.0020738, 0.0020169, 0.035882, 0.0040813, 0.79352, 0.068829]
Predicted label: 3
Correct prediction
Energy consumption = 149.358706 pJ
sum error= 279
Actual label: 0
Output voltages: [0.79879, 0.038558, 0.036737, 0.020243, 0.021582, 0.004621, 0.70599, 0.034164, 0.24209, 0.19634]
Predicted label: 0
Correct prediction
Energy consumption = 159.214605 pJ
sum error= 279
Actual label: 4
Output voltages: [0.011303, 0.0013671, 0.052861, 0.019619, 0.77365, 0.022758, 0.28361, 0.017958, 0.24187, 0.74526]
Predicted label: 4
Correct prediction
Energy consumption = 158.215170 pJ
sum error= 279
Actual label: 8
Output voltages: [0.029612, 0.025241, 0.099785, 0.017742, 0.017102, 0.044626, 0.024812, 0.0039328, 0.79873, 0.36987]
Predicted label: 8
Correct prediction
Energy consumption = 150.618748 pJ
sum error= 279
Actual label: 9
Output voltages: [0.67683, 0.0064435, 0.026471, 0.023218, 0.12111, 0.012175, 0.0010684, 0.0050243, 0.40638, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 148.191442 pJ
sum error= 279
Actual label: 1
Output voltages: [0.0016831, 0.79879, 0.44974, 0.34566, 0.11313, 0.001248, 0.032968, 0.15324, 0.03142, 0.032148]
Predicted label: 1
Correct prediction
Energy consumption = 164.505293 pJ
sum error= 279
Actual label: 4
Output voltages: [0.065598, 0.02234, 0.15985, 0.036789, 0.79878, 0.011896, 0.0043712, 0.0082099, 0.019048, 0.75911]
Predicted label: 4
Correct prediction
Energy consumption = 152.761035 pJ
sum error= 279
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 598 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 598 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 598 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.016791, 0.033277, 0.0018839, 0.19686, 0.0061252, 0.72411, 0.041642, 0.025701, 0.019252]
Predicted label: 0
Correct prediction
Energy consumption = 155.757909 pJ
sum error= 279
Actual label: 5
Output voltages: [0.11237, 0.0011124, 0.010725, 0.15201, 0.039116, 0.068136, 0.0066907, 0.018999, 0.72077, 0.77829]
Predicted label: 9
Wrong prediction!
Energy consumption = 152.046349 pJ
sum error= 280
Actual label: 5
Output voltages: [0.048722, 0.0010667, 0.031442, 0.73211, 0.0032569, 0.76788, 0.0041137, 0.020126, 0.76499, 0.042154]
Predicted label: 5
Correct prediction
Energy consumption = 145.724037 pJ
sum error= 280
Actual label: 2
Output voltages: [0.55764, 0.056727, 0.79875, 0.20108, 0.024648, 0.0011724, 0.15871, 0.32472, 0.41642, 0.0097601]
Predicted label: 2
Correct prediction
Energy consumption = 147.489317 pJ
sum error= 280
Actual label: 1
Output voltages: [0.0087608, 0.7987, 0.50788, 0.43018, 0.41393, 0.0015246, 0.034829, 0.098631, 0.0019932, 0.033288]
Predicted label: 1
Correct prediction
Energy consumption = 157.063328 pJ
sum error= 280
Actual label: 5
Output voltages: [0.0013448, 0.0016388, 0.016658, 0.64266, 0.050368, 0.59314, 0.12934, 0.0086042, 0.77861, 0.30596]
Predicted label: 8
Wrong prediction!
Energy consumption = 154.100577 pJ
sum error= 281
Actual label: 4
Output voltages: [0.043871, 0.034279, 0.39388, 0.03224, 0.7966, 0.034345, 0.0068952, 0.0044709, 0.19108, 0.74728]
Predicted label: 4
Correct prediction
Energy consumption = 156.687700 pJ
sum error= 281
Actual label: 0
Output voltages: [0.79872, 0.040064, 0.19265, 0.0083436, 0.013628, 0.0010788, 0.56848, 0.026976, 0.049328, 0.26442]
Predicted label: 0
Correct prediction
Energy consumption = 158.706809 pJ
sum error= 281
Actual label: 7
Output voltages: [0.20884, 0.33502, 0.29813, 0.74654, 0.012132, 0.0017308, 0.001066, 0.79829, 0.011452, 0.65934]
Predicted label: 7
Correct prediction
Energy consumption = 153.213813 pJ
sum error= 281
Actual label: 6
Output voltages: [0.23714, 0.040217, 0.023302, 0.075257, 0.42701, 0.54119, 0.79879, 0.0053956, 0.36981, 0.0014132]
Predicted label: 6
Correct prediction
Energy consumption = 156.547052 pJ
sum error= 281
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 599 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 599 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 599 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79866, 0.067596, 0.0233, 0.0097327, 0.05288, 0.014363, 0.7407, 0.022375, 0.036913, 0.034809]
Predicted label: 0
Correct prediction
Energy consumption = 156.855697 pJ
sum error= 281
Actual label: 1
Output voltages: [0.025866, 0.79841, 0.13984, 0.22523, 0.043103, 0.0067916, 0.43568, 0.0046395, 0.0094378, 0.26769]
Predicted label: 1
Correct prediction
Energy consumption = 163.264500 pJ
sum error= 281
Actual label: 7
Output voltages: [0.24769, 0.091005, 0.014288, 0.32264, 0.0012215, 0.007438, 0.0012038, 0.79876, 0.043231, 0.62312]
Predicted label: 7
Correct prediction
Energy consumption = 150.950949 pJ
sum error= 281
Actual label: 0
Output voltages: [0.79875, 0.034242, 0.017165, 0.0046927, 0.036371, 0.022012, 0.58744, 0.011539, 0.018569, 0.069696]
Predicted label: 0
Correct prediction
Energy consumption = 153.895621 pJ
sum error= 281
Actual label: 6
Output voltages: [0.082835, 0.043312, 0.1397, 0.005085, 0.32877, 0.52483, 0.79872, 0.0024552, 0.52463, 0.005534]
Predicted label: 6
Correct prediction
Energy consumption = 148.756700 pJ
sum error= 281
Actual label: 8
Output voltages: [0.047308, 0.04267, 0.55887, 0.041085, 0.020048, 0.008573, 0.023191, 0.0034487, 0.79878, 0.29029]
Predicted label: 8
Correct prediction
Energy consumption = 153.297169 pJ
sum error= 281
Actual label: 9
Output voltages: [0.57403, 0.0015836, 0.32672, 0.0039775, 0.25902, 0.0020753, 0.021435, 0.0015682, 0.12725, 0.79859]
Predicted label: 9
Correct prediction
Energy consumption = 141.581741 pJ
sum error= 281
Actual label: 5
Output voltages: [0.088293, 0.0044961, 0.025433, 0.31294, 0.0035408, 0.78155, 0.0059926, 0.014699, 0.78519, 0.45167]
Predicted label: 8
Wrong prediction!
Energy consumption = 151.845059 pJ
sum error= 282
Actual label: 1
Output voltages: [0.015105, 0.79839, 0.11866, 0.22432, 0.0038602, 0.010517, 0.15035, 0.0021857, 0.096406, 0.077958]
Predicted label: 1
Correct prediction
Energy consumption = 160.177838 pJ
sum error= 282
Actual label: 7
Output voltages: [0.10811, 0.023952, 0.01423, 0.16352, 0.0062349, 0.0031961, 0.0012124, 0.79879, 0.28291, 0.41053]
Predicted label: 7
Correct prediction
Energy consumption = 156.125750 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 600 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 600 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 600 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.56267, 0.0011394, 0.019559, 0.11731, 0.038346, 0.022927, 0.0011685, 0.77719, 0.40724, 0.7855]
Predicted label: 9
Correct prediction
Energy consumption = 156.273288 pJ
sum error= 282
Actual label: 8
Output voltages: [0.26416, 0.013582, 0.1306, 0.74419, 0.011109, 0.012097, 0.036229, 0.0013719, 0.79827, 0.073456]
Predicted label: 8
Correct prediction
Energy consumption = 154.936985 pJ
sum error= 282
Actual label: 6
Output voltages: [0.12617, 0.30484, 0.20242, 0.015719, 0.24806, 0.24425, 0.79867, 0.0044692, 0.2659, 0.014701]
Predicted label: 6
Correct prediction
Energy consumption = 146.836879 pJ
sum error= 282
Actual label: 0
Output voltages: [0.79864, 0.035085, 0.014733, 0.01076, 0.040413, 0.0087555, 0.75043, 0.025667, 0.25376, 0.034551]
Predicted label: 0
Correct prediction
Energy consumption = 151.419650 pJ
sum error= 282
Actual label: 8
Output voltages: [0.33568, 0.0053251, 0.13158, 0.0032938, 0.02856, 0.0078475, 0.0027215, 0.028838, 0.7808, 0.77683]
Predicted label: 8
Correct prediction
Energy consumption = 152.674649 pJ
sum error= 282
Actual label: 1
Output voltages: [0.004604, 0.79855, 0.71358, 0.16018, 0.54689, 0.0010973, 0.0082131, 0.011958, 0.011683, 0.067407]
Predicted label: 1
Correct prediction
Energy consumption = 162.138141 pJ
sum error= 282
Actual label: 7
Output voltages: [0.043041, 0.24975, 0.0092244, 0.035637, 0.0012152, 0.033595, 0.0010662, 0.79286, 0.046592, 0.77452]
Predicted label: 7
Correct prediction
Energy consumption = 158.330346 pJ
sum error= 282
Actual label: 7
Output voltages: [0.1587, 0.066241, 0.0021346, 0.028926, 0.0031269, 0.0072088, 0.0010672, 0.79879, 0.25068, 0.72725]
Predicted label: 7
Correct prediction
Energy consumption = 143.846829 pJ
sum error= 282
Actual label: 1
Output voltages: [0.0010736, 0.79873, 0.10038, 0.37562, 0.48845, 0.0028203, 0.10306, 0.036409, 0.13154, 0.035555]
Predicted label: 1
Correct prediction
Energy consumption = 162.241344 pJ
sum error= 282
Actual label: 3
Output voltages: [0.49948, 0.030924, 0.21612, 0.79871, 0.12081, 0.0036504, 0.049516, 0.012464, 0.55572, 0.10705]
Predicted label: 3
Correct prediction
Energy consumption = 151.826837 pJ
sum error= 282
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 601 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 601 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 601 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.24339, 0.019115, 0.79879, 0.30306, 0.012734, 0.0011672, 0.25625, 0.29373, 0.65861, 0.046117]
Predicted label: 2
Correct prediction
Energy consumption = 153.934537 pJ
sum error= 282
Actual label: 3
Output voltages: [0.7968, 0.013304, 0.16639, 0.44094, 0.0010679, 0.36565, 0.30816, 0.0020784, 0.094757, 0.28072]
Predicted label: 0
Wrong prediction!
Energy consumption = 155.728140 pJ
sum error= 283
Actual label: 1
Output voltages: [0.015734, 0.79836, 0.16888, 0.15743, 0.0039729, 0.0040304, 0.70504, 0.0082319, 0.037669, 0.052555]
Predicted label: 1
Correct prediction
Energy consumption = 158.824875 pJ
sum error= 283
Actual label: 4
Output voltages: [0.035268, 0.0017438, 0.45452, 0.041261, 0.79874, 0.0075849, 0.051866, 0.038538, 0.011955, 0.51248]
Predicted label: 4
Correct prediction
Energy consumption = 156.825009 pJ
sum error= 283
Actual label: 2
Output voltages: [0.49091, 0.48232, 0.79376, 0.42209, 0.011675, 0.0011518, 0.045486, 0.041133, 0.011927, 0.017979]
Predicted label: 2
Correct prediction
Energy consumption = 153.292396 pJ
sum error= 283
Actual label: 0
Output voltages: [0.79871, 0.03822, 0.0084387, 0.013609, 0.008986, 0.036282, 0.72045, 0.0053167, 0.067067, 0.039317]
Predicted label: 0
Correct prediction
Energy consumption = 151.733058 pJ
sum error= 283
Actual label: 0
Output voltages: [0.79874, 0.039292, 0.032906, 0.0094661, 0.053677, 0.0095043, 0.5871, 0.031048, 0.042801, 0.035768]
Predicted label: 0
Correct prediction
Energy consumption = 142.789131 pJ
sum error= 283
Actual label: 7
Output voltages: [0.41747, 0.033079, 0.72118, 0.068634, 0.0023746, 0.0011525, 0.0022339, 0.79879, 0.23737, 0.10334]
Predicted label: 7
Correct prediction
Energy consumption = 161.062160 pJ
sum error= 283
Actual label: 8
Output voltages: [0.10032, 0.010873, 0.46589, 0.03104, 0.0085204, 0.021217, 0.0086966, 0.0014944, 0.79879, 0.32824]
Predicted label: 8
Correct prediction
Energy consumption = 146.936241 pJ
sum error= 283
Actual label: 4
Output voltages: [0.01221, 0.0039647, 0.011267, 0.013657, 0.79874, 0.023336, 0.029874, 0.03275, 0.47804, 0.20069]
Predicted label: 4
Correct prediction
Energy consumption = 154.596639 pJ
sum error= 283
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 602 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 602 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 602 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.22644, 0.010788, 0.07455, 0.0065521, 0.42899, 0.21466, 0.79877, 0.0064205, 0.65972, 0.0016143]
Predicted label: 6
Correct prediction
Energy consumption = 149.941434 pJ
sum error= 283
Actual label: 4
Output voltages: [0.023139, 0.019201, 0.031837, 0.11108, 0.79869, 0.039463, 0.034974, 0.029272, 0.068411, 0.44651]
Predicted label: 4
Correct prediction
Energy consumption = 154.567828 pJ
sum error= 283
Actual label: 9
Output voltages: [0.1876, 0.014804, 0.035298, 0.38861, 0.021453, 0.016983, 0.0065918, 0.071163, 0.14386, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.936337 pJ
sum error= 283
Actual label: 3
Output voltages: [0.082421, 0.04267, 0.019211, 0.79876, 0.093794, 0.25783, 0.045315, 0.0010833, 0.4725, 0.23884]
Predicted label: 3
Correct prediction
Energy consumption = 145.899183 pJ
sum error= 283
Actual label: 8
Output voltages: [0.033719, 0.014367, 0.050446, 0.46873, 0.0011546, 0.042444, 0.0062223, 0.0083379, 0.79879, 0.38647]
Predicted label: 8
Correct prediction
Energy consumption = 145.806386 pJ
sum error= 283
Actual label: 4
Output voltages: [0.036386, 0.0087611, 0.40942, 0.055013, 0.79877, 0.0077544, 0.011424, 0.002607, 0.0092078, 0.56738]
Predicted label: 4
Correct prediction
Energy consumption = 154.172857 pJ
sum error= 283
Actual label: 7
Output voltages: [0.24782, 0.70732, 0.040816, 0.46413, 0.0017639, 0.010719, 0.001082, 0.79637, 0.012453, 0.75327]
Predicted label: 7
Correct prediction
Energy consumption = 155.787107 pJ
sum error= 283
Actual label: 2
Output voltages: [0.12835, 0.13523, 0.79879, 0.013484, 0.0026603, 0.0012633, 0.56068, 0.044955, 0.44234, 0.020624]
Predicted label: 2
Correct prediction
Energy consumption = 152.926068 pJ
sum error= 283
Actual label: 5
Output voltages: [0.043162, 0.0010891, 0.0030927, 0.35928, 0.014841, 0.79487, 0.052608, 0.044285, 0.75813, 0.064616]
Predicted label: 5
Correct prediction
Energy consumption = 149.072058 pJ
sum error= 283
Actual label: 6
Output voltages: [0.19431, 0.016154, 0.010165, 0.13364, 0.082378, 0.77972, 0.79877, 0.0010837, 0.39511, 0.0018119]
Predicted label: 6
Correct prediction
Energy consumption = 148.218894 pJ
sum error= 283
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 603 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 603 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 603 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.19407, 0.10046, 0.016888, 0.79878, 0.0028295, 0.029394, 0.12981, 0.0049223, 0.57557, 0.026341]
Predicted label: 3
Correct prediction
Energy consumption = 147.765634 pJ
sum error= 283
Actual label: 6
Output voltages: [0.018833, 0.058712, 0.13851, 0.016036, 0.22515, 0.26657, 0.79876, 0.030877, 0.65198, 0.001601]
Predicted label: 6
Correct prediction
Energy consumption = 149.202151 pJ
sum error= 283
Actual label: 9
Output voltages: [0.39628, 0.0021867, 0.017958, 0.019394, 0.041214, 0.0011718, 0.001352, 0.044734, 0.508, 0.79662]
Predicted label: 9
Correct prediction
Energy consumption = 152.427767 pJ
sum error= 283
Actual label: 6
Output voltages: [0.10984, 0.040945, 0.022455, 0.034569, 0.23783, 0.61136, 0.79879, 0.0023256, 0.62641, 0.0018278]
Predicted label: 6
Correct prediction
Energy consumption = 157.523750 pJ
sum error= 283
Actual label: 3
Output voltages: [0.030656, 0.0047038, 0.021014, 0.79879, 0.065601, 0.029631, 0.054727, 0.0047856, 0.66352, 0.076273]
Predicted label: 3
Correct prediction
Energy consumption = 155.438280 pJ
sum error= 283
Actual label: 2
Output voltages: [0.79808, 0.018602, 0.14834, 0.054109, 0.013594, 0.003202, 0.19154, 0.032424, 0.0029193, 0.57439]
Predicted label: 0
Wrong prediction!
Energy consumption = 154.521527 pJ
sum error= 284
Actual label: 2
Output voltages: [0.39234, 0.020531, 0.79649, 0.46844, 0.011839, 0.0013007, 0.048189, 0.047748, 0.45652, 0.014742]
Predicted label: 2
Correct prediction
Energy consumption = 147.541384 pJ
sum error= 284
Actual label: 4
Output voltages: [0.011354, 0.023286, 0.11237, 0.11464, 0.79789, 0.062828, 0.014435, 0.018869, 0.17068, 0.72448]
Predicted label: 4
Correct prediction
Energy consumption = 157.207230 pJ
sum error= 284
Actual label: 6
Output voltages: [0.13662, 0.022462, 0.17642, 0.0048516, 0.2665, 0.26264, 0.79867, 0.0016585, 0.67676, 0.02984]
Predicted label: 6
Correct prediction
Energy consumption = 145.403260 pJ
sum error= 284
Actual label: 9
Output voltages: [0.2954, 0.024602, 0.048743, 0.39384, 0.046945, 0.025275, 0.0080732, 0.23024, 0.19407, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 154.083288 pJ
sum error= 284
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 604 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 604 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 604 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.0095434, 0.0041567, 0.0097518, 0.046127, 0.024748, 0.66961, 0.015924, 0.041779, 0.16496]
Predicted label: 0
Correct prediction
Energy consumption = 160.233344 pJ
sum error= 284
Actual label: 2
Output voltages: [0.5043, 0.48327, 0.79832, 0.10405, 0.0040364, 0.0013186, 0.21253, 0.0054466, 0.15802, 0.00688]
Predicted label: 2
Correct prediction
Energy consumption = 159.492355 pJ
sum error= 284
Actual label: 5
Output voltages: [0.060103, 0.0010721, 0.036553, 0.039539, 0.0092115, 0.75421, 0.0013897, 0.019468, 0.79648, 0.59806]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.385744 pJ
sum error= 285
Actual label: 5
Output voltages: [0.054647, 0.0011898, 0.0011772, 0.19452, 0.030147, 0.79463, 0.10913, 0.079708, 0.77788, 0.041789]
Predicted label: 5
Correct prediction
Energy consumption = 137.149454 pJ
sum error= 285
Actual label: 1
Output voltages: [0.023635, 0.79879, 0.18194, 0.015404, 0.42684, 0.012641, 0.71786, 0.0013651, 0.038511, 0.025936]
Predicted label: 1
Correct prediction
Energy consumption = 170.229211 pJ
sum error= 285
Actual label: 3
Output voltages: [0.037182, 0.023823, 0.049022, 0.79879, 0.0061739, 0.0064639, 0.045231, 0.0053426, 0.75721, 0.074588]
Predicted label: 3
Correct prediction
Energy consumption = 147.260793 pJ
sum error= 285
Actual label: 3
Output voltages: [0.041725, 0.043815, 0.32453, 0.79875, 0.021866, 0.0011401, 0.20022, 0.0077438, 0.75184, 0.12921]
Predicted label: 3
Correct prediction
Energy consumption = 139.947527 pJ
sum error= 285
Actual label: 9
Output voltages: [0.3949, 0.0014159, 0.026918, 0.025977, 0.031107, 0.0010661, 0.0013119, 0.05822, 0.6057, 0.79723]
Predicted label: 9
Correct prediction
Energy consumption = 147.128044 pJ
sum error= 285
Actual label: 7
Output voltages: [0.18583, 0.48257, 0.7219, 0.026387, 0.044202, 0.0013271, 0.0013827, 0.79603, 0.005807, 0.68208]
Predicted label: 7
Correct prediction
Energy consumption = 158.886845 pJ
sum error= 285
Actual label: 8
Output voltages: [0.39888, 0.0013379, 0.43833, 0.47437, 0.0099126, 0.0067863, 0.048322, 0.0016364, 0.79765, 0.31748]
Predicted label: 8
Correct prediction
Energy consumption = 152.346491 pJ
sum error= 285
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 605 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 605 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 605 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.053373, 0.062289, 0.081086, 0.025685, 0.020209, 0.027562, 0.0011002, 0.79864, 0.052883, 0.50835]
Predicted label: 7
Correct prediction
Energy consumption = 161.361303 pJ
sum error= 285
Actual label: 2
Output voltages: [0.18476, 0.04204, 0.79877, 0.044128, 0.038045, 0.0012499, 0.27087, 0.30316, 0.39417, 0.029143]
Predicted label: 2
Correct prediction
Energy consumption = 156.555209 pJ
sum error= 285
Actual label: 2
Output voltages: [0.37737, 0.44573, 0.79879, 0.031469, 0.013271, 0.0011939, 0.31203, 0.0074169, 0.13793, 0.031711]
Predicted label: 2
Correct prediction
Energy consumption = 144.098174 pJ
sum error= 285
Actual label: 5
Output voltages: [0.0039134, 0.0016682, 0.050366, 0.42075, 0.04831, 0.36642, 0.003789, 0.014612, 0.79005, 0.40266]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.255404 pJ
sum error= 286
Actual label: 7
Output voltages: [0.058541, 0.29147, 0.3799, 0.21956, 0.0015574, 0.0011087, 0.0014988, 0.79879, 0.019672, 0.71488]
Predicted label: 7
Correct prediction
Energy consumption = 157.857599 pJ
sum error= 286
Actual label: 9
Output voltages: [0.48259, 0.011053, 0.037713, 0.034336, 0.023325, 0.010737, 0.0016407, 0.13499, 0.52878, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 150.409575 pJ
sum error= 286
Actual label: 8
Output voltages: [0.18806, 0.011111, 0.041488, 0.51077, 0.0013389, 0.12455, 0.0071701, 0.0018641, 0.79878, 0.35086]
Predicted label: 8
Correct prediction
Energy consumption = 144.054777 pJ
sum error= 286
Actual label: 2
Output voltages: [0.19287, 0.22196, 0.79875, 0.026733, 0.023142, 0.0014166, 0.3067, 0.027252, 0.20567, 0.025337]
Predicted label: 2
Correct prediction
Energy consumption = 153.971302 pJ
sum error= 286
Actual label: 1
Output voltages: [0.041729, 0.79853, 0.056687, 0.11765, 0.074704, 0.0011635, 0.41881, 0.0010696, 0.051185, 0.25692]
Predicted label: 1
Correct prediction
Energy consumption = 156.199384 pJ
sum error= 286
Actual label: 3
Output voltages: [0.038985, 0.029129, 0.078884, 0.79875, 0.0041136, 0.047094, 0.03753, 0.0093225, 0.52464, 0.044914]
Predicted label: 3
Correct prediction
Energy consumption = 155.628893 pJ
sum error= 286
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 606 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 606 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 606 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.015188, 0.79872, 0.0069315, 0.091864, 0.013431, 0.034052, 0.13931, 0.003461, 0.40891, 0.015354]
Predicted label: 1
Correct prediction
Energy consumption = 168.130944 pJ
sum error= 286
Actual label: 3
Output voltages: [0.39718, 0.016194, 0.079129, 0.79869, 0.018332, 0.036811, 0.037318, 0.029603, 0.39715, 0.05221]
Predicted label: 3
Correct prediction
Energy consumption = 148.888307 pJ
sum error= 286
Actual label: 0
Output voltages: [0.79877, 0.11308, 0.018815, 0.0113, 0.01697, 0.0085845, 0.39771, 0.036417, 0.26304, 0.039199]
Predicted label: 0
Correct prediction
Energy consumption = 144.965348 pJ
sum error= 286
Actual label: 1
Output voltages: [0.018493, 0.79849, 0.13066, 0.3192, 0.0021664, 0.0010927, 0.76303, 0.0056131, 0.038715, 0.020224]
Predicted label: 1
Correct prediction
Energy consumption = 163.184221 pJ
sum error= 286
Actual label: 2
Output voltages: [0.58879, 0.031999, 0.79848, 0.32539, 0.016756, 0.0012005, 0.15039, 0.0082504, 0.55987, 0.021279]
Predicted label: 2
Correct prediction
Energy consumption = 148.969594 pJ
sum error= 286
Actual label: 3
Output voltages: [0.090627, 0.0082412, 0.38005, 0.7959, 0.0012637, 0.0012868, 0.0015667, 0.19742, 0.79504, 0.0022856]
Predicted label: 3
Correct prediction
Energy consumption = 143.006433 pJ
sum error= 286
Actual label: 4
Output voltages: [0.0039387, 0.011611, 0.055726, 0.015296, 0.79861, 0.0028438, 0.3081, 0.32942, 0.035117, 0.036227]
Predicted label: 4
Correct prediction
Energy consumption = 144.190118 pJ
sum error= 286
Actual label: 5
Output voltages: [0.027075, 0.0010963, 0.0019088, 0.073152, 0.1213, 0.79843, 0.15989, 0.039106, 0.77967, 0.052832]
Predicted label: 5
Correct prediction
Energy consumption = 144.340513 pJ
sum error= 286
Actual label: 6
Output voltages: [0.23912, 0.030872, 0.29066, 0.0018433, 0.30582, 0.3063, 0.79877, 0.0023032, 0.59467, 0.013736]
Predicted label: 6
Correct prediction
Energy consumption = 137.992958 pJ
sum error= 286
Actual label: 7
Output voltages: [0.04434, 0.0080142, 0.013567, 0.041488, 0.03686, 0.014633, 0.0010663, 0.7987, 0.57584, 0.34661]
Predicted label: 7
Correct prediction
Energy consumption = 154.473565 pJ
sum error= 286
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 607 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 607 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 607 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.61831, 0.014308, 0.50672, 0.42558, 0.0084378, 0.0013156, 0.07126, 0.001127, 0.79566, 0.35206]
Predicted label: 8
Correct prediction
Energy consumption = 154.687846 pJ
sum error= 286
Actual label: 9
Output voltages: [0.080953, 0.0010662, 0.039654, 0.28279, 0.035563, 0.049122, 0.0041611, 0.002708, 0.78, 0.44613]
Predicted label: 8
Wrong prediction!
Energy consumption = 142.838623 pJ
sum error= 287
Actual label: 0
Output voltages: [0.79876, 0.02009, 0.029655, 0.0065991, 0.027241, 0.0041349, 0.69208, 0.018242, 0.097634, 0.064617]
Predicted label: 0
Correct prediction
Energy consumption = 139.471065 pJ
sum error= 287
Actual label: 1
Output voltages: [0.013754, 0.79853, 0.044625, 0.23447, 0.0010664, 0.0011399, 0.76713, 0.013749, 0.065222, 0.030604]
Predicted label: 1
Correct prediction
Energy consumption = 159.422802 pJ
sum error= 287
Actual label: 2
Output voltages: [0.44956, 0.056373, 0.79879, 0.35435, 0.023275, 0.0012142, 0.38883, 0.028416, 0.5018, 0.054097]
Predicted label: 2
Correct prediction
Energy consumption = 146.953640 pJ
sum error= 287
Actual label: 3
Output voltages: [0.16098, 0.0010704, 0.056685, 0.79875, 0.067249, 0.31847, 0.0049834, 0.040627, 0.77259, 0.024271]
Predicted label: 3
Correct prediction
Energy consumption = 143.460332 pJ
sum error= 287
Actual label: 4
Output voltages: [0.032777, 0.02386, 0.23708, 0.0084007, 0.79873, 0.0028017, 0.22454, 0.032924, 0.021806, 0.55488]
Predicted label: 4
Correct prediction
Energy consumption = 149.862048 pJ
sum error= 287
Actual label: 5
Output voltages: [0.03362, 0.0013545, 0.011444, 0.099761, 0.015535, 0.79879, 0.56053, 0.02654, 0.78937, 0.0028014]
Predicted label: 5
Correct prediction
Energy consumption = 147.239600 pJ
sum error= 287
Actual label: 6
Output voltages: [0.14318, 0.013135, 0.34334, 0.0010718, 0.51862, 0.16273, 0.79878, 0.0012638, 0.37425, 0.0030344]
Predicted label: 6
Correct prediction
Energy consumption = 142.831043 pJ
sum error= 287
Actual label: 7
Output voltages: [0.15277, 0.13613, 0.050562, 0.084519, 0.0078235, 0.005419, 0.0011276, 0.79855, 0.14429, 0.35415]
Predicted label: 7
Correct prediction
Energy consumption = 161.044463 pJ
sum error= 287
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 608 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 608 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 608 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.044845, 0.0098136, 0.75278, 0.018251, 0.025429, 0.0013203, 0.6915, 0.001885, 0.79743, 0.088425]
Predicted label: 8
Correct prediction
Energy consumption = 152.260126 pJ
sum error= 287
Actual label: 9
Output voltages: [0.75457, 0.0046495, 0.15837, 0.19223, 0.014471, 0.021788, 0.0080987, 0.001089, 0.78325, 0.6487]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.639929 pJ
sum error= 288
Actual label: 0
Output voltages: [0.79879, 0.10087, 0.025692, 0.026327, 0.015176, 0.014511, 0.62079, 0.033834, 0.29618, 0.049188]
Predicted label: 0
Correct prediction
Energy consumption = 137.224167 pJ
sum error= 288
Actual label: 1
Output voltages: [0.030599, 0.79878, 0.019356, 0.1102, 0.34219, 0.0030437, 0.4511, 0.0010663, 0.63683, 0.04468]
Predicted label: 1
Correct prediction
Energy consumption = 163.086394 pJ
sum error= 288
Actual label: 2
Output voltages: [0.38875, 0.050484, 0.79879, 0.25569, 0.01132, 0.0012707, 0.045855, 0.032702, 0.38263, 0.020583]
Predicted label: 2
Correct prediction
Energy consumption = 144.160057 pJ
sum error= 288
Actual label: 3
Output voltages: [0.10771, 0.0016631, 0.25832, 0.7971, 0.0013671, 0.031539, 0.0011863, 0.031338, 0.7982, 0.0046293]
Predicted label: 8
Wrong prediction!
Energy consumption = 138.506127 pJ
sum error= 289
Actual label: 4
Output voltages: [0.0083158, 0.01999, 0.032025, 0.0073186, 0.79867, 0.0034095, 0.33298, 0.099732, 0.03979, 0.037551]
Predicted label: 4
Correct prediction
Energy consumption = 144.100548 pJ
sum error= 289
Actual label: 5
Output voltages: [0.28679, 0.0012529, 0.0055198, 0.14607, 0.016701, 0.79727, 0.097149, 0.014579, 0.78204, 0.0030017]
Predicted label: 5
Correct prediction
Energy consumption = 144.575819 pJ
sum error= 289
Actual label: 6
Output voltages: [0.042646, 0.036969, 0.14677, 0.014593, 0.31107, 0.5145, 0.79877, 0.0029004, 0.74597, 0.011065]
Predicted label: 6
Correct prediction
Energy consumption = 139.360192 pJ
sum error= 289
Actual label: 7
Output voltages: [0.15124, 0.089324, 0.049533, 0.03623, 0.0012699, 0.0014823, 0.0011242, 0.7987, 0.23682, 0.23734]
Predicted label: 7
Correct prediction
Energy consumption = 157.380011 pJ
sum error= 289
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 609 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 609 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 609 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.28919, 0.0013698, 0.23907, 0.12292, 0.010168, 0.034317, 0.033744, 0.0016513, 0.79876, 0.14668]
Predicted label: 8
Correct prediction
Energy consumption = 157.227613 pJ
sum error= 289
Actual label: 9
Output voltages: [0.68235, 0.0011094, 0.01594, 0.06316, 0.0019684, 0.33082, 0.0056469, 0.0014777, 0.79132, 0.25726]
Predicted label: 8
Wrong prediction!
Energy consumption = 140.510617 pJ
sum error= 290
Actual label: 1
Output voltages: [0.032503, 0.7987, 0.26633, 0.12301, 0.35552, 0.0013406, 0.30252, 0.0083419, 0.13088, 0.019532]
Predicted label: 1
Correct prediction
Energy consumption = 162.290295 pJ
sum error= 290
Actual label: 2
Output voltages: [0.062549, 0.016386, 0.79878, 0.049296, 0.0076001, 0.0012458, 0.14155, 0.028938, 0.74331, 0.028993]
Predicted label: 2
Correct prediction
Energy consumption = 143.429935 pJ
sum error= 290
Actual label: 6
Output voltages: [0.1542, 0.048521, 0.053672, 0.0017298, 0.31543, 0.35115, 0.79878, 0.0053105, 0.45197, 0.0013626]
Predicted label: 6
Correct prediction
Energy consumption = 152.017085 pJ
sum error= 290
Actual label: 5
Output voltages: [0.069381, 0.001145, 0.0018116, 0.059837, 0.052142, 0.79874, 0.27561, 0.017985, 0.77239, 0.0085625]
Predicted label: 5
Correct prediction
Energy consumption = 141.605643 pJ
sum error= 290
Actual label: 3
Output voltages: [0.15492, 0.015798, 0.03743, 0.79863, 0.034414, 0.019795, 0.0098728, 0.039774, 0.61064, 0.14746]
Predicted label: 3
Correct prediction
Energy consumption = 145.331397 pJ
sum error= 290
Actual label: 0
Output voltages: [0.79874, 0.15414, 0.019082, 0.014707, 0.0073036, 0.013803, 0.56282, 0.041361, 0.24508, 0.026943]
Predicted label: 0
Correct prediction
Energy consumption = 147.406545 pJ
sum error= 290
Actual label: 7
Output voltages: [0.042931, 0.032384, 0.14693, 0.096567, 0.0013092, 0.0015653, 0.0011776, 0.79872, 0.54275, 0.32287]
Predicted label: 7
Correct prediction
Energy consumption = 160.444312 pJ
sum error= 290
Actual label: 0
Output voltages: [0.7987, 0.10854, 0.023863, 0.013384, 0.010274, 0.0061362, 0.63226, 0.03047, 0.24741, 0.025295]
Predicted label: 0
Correct prediction
Energy consumption = 143.887209 pJ
sum error= 290
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 610 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 610 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 610 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.014023, 0.023184, 0.31432, 0.0015046, 0.79872, 0.02936, 0.21767, 0.083883, 0.051273, 0.021382]
Predicted label: 4
Correct prediction
Energy consumption = 150.026661 pJ
sum error= 290
Actual label: 1
Output voltages: [0.059599, 0.78711, 0.013698, 0.69405, 0.0010686, 0.038505, 0.43455, 0.0016834, 0.77144, 0.0081471]
Predicted label: 1
Correct prediction
Energy consumption = 165.393782 pJ
sum error= 290
Actual label: 4
Output voltages: [0.012382, 0.0070117, 0.058034, 0.0028842, 0.79877, 0.0010681, 0.52639, 0.14972, 0.01086, 0.011158]
Predicted label: 4
Correct prediction
Energy consumption = 154.462642 pJ
sum error= 290
Actual label: 3
Output voltages: [0.099542, 0.0095455, 0.058748, 0.79872, 0.032456, 0.2166, 0.047886, 0.041555, 0.68423, 0.045424]
Predicted label: 3
Correct prediction
Energy consumption = 143.678978 pJ
sum error= 290
Actual label: 6
Output voltages: [0.12107, 0.047723, 0.33925, 0.001627, 0.28038, 0.23436, 0.79874, 0.002513, 0.6782, 0.013859]
Predicted label: 6
Correct prediction
Energy consumption = 144.471341 pJ
sum error= 290
Actual label: 7
Output voltages: [0.05152, 0.029386, 0.19391, 0.02753, 0.0013923, 0.0015566, 0.00121, 0.79876, 0.78173, 0.14948]
Predicted label: 7
Correct prediction
Energy consumption = 152.629410 pJ
sum error= 290
Actual label: 2
Output voltages: [0.4449, 0.022664, 0.79874, 0.13346, 0.026644, 0.0012398, 0.38016, 0.042644, 0.72581, 0.062915]
Predicted label: 2
Correct prediction
Energy consumption = 139.600649 pJ
sum error= 290
Actual label: 3
Output voltages: [0.031282, 0.0049706, 0.035638, 0.79878, 0.014128, 0.0088248, 0.00913, 0.021723, 0.78146, 0.026968]
Predicted label: 3
Correct prediction
Energy consumption = 137.292082 pJ
sum error= 290
Actual label: 1
Output voltages: [0.0033981, 0.7985, 0.059715, 0.021211, 0.014238, 0.0013851, 0.76429, 0.025219, 0.21435, 0.020039]
Predicted label: 1
Correct prediction
Energy consumption = 152.184732 pJ
sum error= 290
Actual label: 2
Output voltages: [0.2459, 0.037656, 0.79875, 0.03418, 0.0059843, 0.0011763, 0.024567, 0.74306, 0.68496, 0.0017916]
Predicted label: 2
Correct prediction
Energy consumption = 136.364925 pJ
sum error= 290
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 611 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 611 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 611 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.022658, 0.79816, 0.0068679, 0.69899, 0.017254, 0.001068, 0.69551, 0.0010772, 0.67675, 0.34579]
Predicted label: 1
Correct prediction
Energy consumption = 165.991006 pJ
sum error= 290
Actual label: 2
Output voltages: [0.28858, 0.030519, 0.79879, 0.046357, 0.011549, 0.0012277, 0.058029, 0.29571, 0.73508, 0.019102]
Predicted label: 2
Correct prediction
Energy consumption = 142.884220 pJ
sum error= 290
Actual label: 9
Output voltages: [0.74133, 0.0014263, 0.033158, 0.018777, 0.02838, 0.01754, 0.016892, 0.0058778, 0.64487, 0.78228]
Predicted label: 9
Correct prediction
Energy consumption = 142.264431 pJ
sum error= 290
Actual label: 6
Output voltages: [0.12192, 0.040715, 0.26226, 0.0014404, 0.33625, 0.037322, 0.79875, 0.0027921, 0.42065, 0.0075754]
Predicted label: 6
Correct prediction
Energy consumption = 143.258941 pJ
sum error= 290
Actual label: 0
Output voltages: [0.79879, 0.050194, 0.0057225, 0.018698, 0.019315, 0.013889, 0.66953, 0.018151, 0.13715, 0.049268]
Predicted label: 0
Correct prediction
Energy consumption = 143.619585 pJ
sum error= 290
Actual label: 1
Output voltages: [0.050031, 0.79878, 0.01177, 0.12151, 0.33243, 0.001093, 0.11561, 0.0010845, 0.61929, 0.13768]
Predicted label: 1
Correct prediction
Energy consumption = 160.926776 pJ
sum error= 290
Actual label: 3
Output voltages: [0.19102, 0.026559, 0.039399, 0.7987, 0.018551, 0.0050697, 0.009012, 0.022127, 0.74062, 0.031834]
Predicted label: 3
Correct prediction
Energy consumption = 138.780053 pJ
sum error= 290
Actual label: 0
Output voltages: [0.79389, 0.027476, 0.022474, 0.012761, 0.029588, 0.0016719, 0.66144, 0.024702, 0.45638, 0.032128]
Predicted label: 0
Correct prediction
Energy consumption = 151.404428 pJ
sum error= 290
Actual label: 2
Output voltages: [0.54654, 0.061637, 0.7987, 0.051564, 0.0089349, 0.0012252, 0.09302, 0.050652, 0.41328, 0.018216]
Predicted label: 2
Correct prediction
Energy consumption = 147.435274 pJ
sum error= 290
Actual label: 7
Output voltages: [0.046777, 0.052399, 0.057448, 0.015712, 0.011495, 0.0010706, 0.0011099, 0.79876, 0.74026, 0.10628]
Predicted label: 7
Correct prediction
Energy consumption = 149.452413 pJ
sum error= 290
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 612 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 612 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 612 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.04737, 0.0010661, 0.0034721, 0.038962, 0.030105, 0.79875, 0.64302, 0.020541, 0.7805, 0.0012044]
Predicted label: 5
Correct prediction
Energy consumption = 138.642281 pJ
sum error= 290
Actual label: 7
Output voltages: [0.51852, 0.22005, 0.069401, 0.021229, 0.019534, 0.0015535, 0.0010666, 0.79878, 0.18366, 0.010373]
Predicted label: 7
Correct prediction
Energy consumption = 152.448400 pJ
sum error= 290
Actual label: 6
Output voltages: [0.32884, 0.032438, 0.030439, 0.017317, 0.21644, 0.46062, 0.7987, 0.0014285, 0.56589, 0.01632]
Predicted label: 6
Correct prediction
Energy consumption = 147.413471 pJ
sum error= 290
Actual label: 2
Output voltages: [0.37012, 0.039619, 0.79878, 0.082775, 0.015784, 0.0012637, 0.32518, 0.02795, 0.68134, 0.026271]
Predicted label: 2
Correct prediction
Energy consumption = 144.689374 pJ
sum error= 290
Actual label: 9
Output voltages: [0.18728, 0.0011249, 0.032084, 0.012008, 0.018307, 0.38795, 0.0029465, 0.0085206, 0.78838, 0.44846]
Predicted label: 8
Wrong prediction!
Energy consumption = 149.805902 pJ
sum error= 291
Actual label: 1
Output voltages: [0.016262, 0.79836, 0.071517, 0.15703, 0.0070355, 0.015443, 0.76449, 0.013549, 0.069146, 0.062022]
Predicted label: 1
Correct prediction
Energy consumption = 166.753284 pJ
sum error= 291
Actual label: 9
Output voltages: [0.30311, 0.001977, 0.033861, 0.027245, 0.011672, 0.038417, 0.013074, 0.0035402, 0.75871, 0.77021]
Predicted label: 9
Correct prediction
Energy consumption = 147.215826 pJ
sum error= 291
Actual label: 0
Output voltages: [0.79867, 0.080914, 0.043457, 0.016864, 0.0040441, 0.043987, 0.21099, 0.036202, 0.080992, 0.0088397]
Predicted label: 0
Correct prediction
Energy consumption = 144.170286 pJ
sum error= 291
Actual label: 6
Output voltages: [0.072704, 0.058002, 0.23302, 0.001604, 0.32126, 0.33817, 0.79867, 0.0023098, 0.301, 0.023644]
Predicted label: 6
Correct prediction
Energy consumption = 140.595933 pJ
sum error= 291
Actual label: 0
Output voltages: [0.79868, 0.1305, 0.03866, 0.022909, 0.0063814, 0.037884, 0.26403, 0.0056244, 0.060366, 0.066111]
Predicted label: 0
Correct prediction
Energy consumption = 146.422226 pJ
sum error= 291
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 613 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 613 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 613 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.048486, 0.043368, 0.30338, 0.001151, 0.28, 0.067152, 0.79874, 0.0036738, 0.35467, 0.0074161]
Predicted label: 6
Correct prediction
Energy consumption = 147.138102 pJ
sum error= 291
Actual label: 0
Output voltages: [0.79869, 0.03947, 0.036408, 0.013416, 0.0093859, 0.012369, 0.41998, 0.010265, 0.065196, 0.050033]
Predicted label: 0
Correct prediction
Energy consumption = 145.904080 pJ
sum error= 291
Actual label: 2
Output voltages: [0.29135, 0.049845, 0.79878, 0.037885, 0.017711, 0.0012982, 0.39724, 0.026408, 0.67859, 0.035738]
Predicted label: 2
Correct prediction
Energy consumption = 145.988056 pJ
sum error= 291
Actual label: 0
Output voltages: [0.79875, 0.10134, 0.016422, 0.10678, 0.0093739, 0.14562, 0.42498, 0.01697, 0.032588, 0.039522]
Predicted label: 0
Correct prediction
Energy consumption = 151.713624 pJ
sum error= 291
Actual label: 6
Output voltages: [0.054286, 0.032237, 0.10138, 0.0051192, 0.12559, 0.3186, 0.79879, 0.0012166, 0.63363, 0.01113]
Predicted label: 6
Correct prediction
Energy consumption = 147.645361 pJ
sum error= 291
Actual label: 1
Output voltages: [0.026123, 0.79863, 0.048038, 0.19785, 0.077134, 0.0010664, 0.744, 0.0015943, 0.28636, 0.041308]
Predicted label: 1
Correct prediction
Energy consumption = 163.343287 pJ
sum error= 291
Actual label: 5
Output voltages: [0.048802, 0.0011093, 0.0011276, 0.40295, 0.0078722, 0.79873, 0.3125, 0.019749, 0.75402, 0.010627]
Predicted label: 5
Correct prediction
Energy consumption = 140.486321 pJ
sum error= 291
Actual label: 8
Output voltages: [0.18256, 0.018465, 0.32429, 0.065103, 0.059739, 0.0073585, 0.092429, 0.0015992, 0.79879, 0.1834]
Predicted label: 8
Correct prediction
Energy consumption = 140.983568 pJ
sum error= 291
Actual label: 4
Output voltages: [0.0053719, 0.0039564, 0.071247, 0.015299, 0.79855, 0.0035814, 0.26206, 0.15113, 0.032901, 0.01632]
Predicted label: 4
Correct prediction
Energy consumption = 152.892432 pJ
sum error= 291
Actual label: 3
Output voltages: [0.28157, 0.0039481, 0.53794, 0.79866, 0.013479, 0.0011348, 0.011976, 0.0011351, 0.74461, 0.020883]
Predicted label: 3
Correct prediction
Energy consumption = 141.615587 pJ
sum error= 291
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 614 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 614 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 614 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.068713, 0.014087, 0.028555, 0.005168, 0.025261, 0.61114, 0.031179, 0.26661, 0.028261]
Predicted label: 0
Correct prediction
Energy consumption = 146.511967 pJ
sum error= 291
Actual label: 1
Output voltages: [0.29595, 0.79867, 0.13041, 0.1438, 0.013104, 0.0011159, 0.55706, 0.0012375, 0.022499, 0.12438]
Predicted label: 1
Correct prediction
Energy consumption = 156.833465 pJ
sum error= 291
Actual label: 5
Output voltages: [0.12234, 0.0012131, 0.0015152, 0.069397, 0.042168, 0.79835, 0.16765, 0.0084136, 0.78229, 0.0015364]
Predicted label: 5
Correct prediction
Energy consumption = 144.890864 pJ
sum error= 291
Actual label: 4
Output voltages: [0.026392, 0.0083124, 0.020162, 0.0011281, 0.79879, 0.0040452, 0.29439, 0.16384, 0.2635, 0.002804]
Predicted label: 4
Correct prediction
Energy consumption = 150.002541 pJ
sum error= 291
Actual label: 4
Output voltages: [0.051813, 0.0035696, 0.37583, 0.003789, 0.79875, 0.0020039, 0.406, 0.035749, 0.020782, 0.01158]
Predicted label: 4
Correct prediction
Energy consumption = 137.060398 pJ
sum error= 291
Actual label: 8
Output voltages: [0.022314, 0.10246, 0.1481, 0.15591, 0.016324, 0.018882, 0.035755, 0.0071039, 0.79871, 0.367]
Predicted label: 8
Correct prediction
Energy consumption = 151.244230 pJ
sum error= 291
Actual label: 5
Output voltages: [0.015048, 0.0012031, 0.011141, 0.054969, 0.010051, 0.78576, 0.30241, 0.0039719, 0.77242, 0.025217]
Predicted label: 5
Correct prediction
Energy consumption = 141.276338 pJ
sum error= 291
Actual label: 7
Output voltages: [0.23591, 0.034811, 0.001465, 0.12759, 0.0097236, 0.0043779, 0.0011123, 0.79796, 0.22867, 0.72333]
Predicted label: 7
Correct prediction
Energy consumption = 152.394910 pJ
sum error= 291
Actual label: 5
Output voltages: [0.028945, 0.0022457, 0.0027025, 0.26519, 0.011245, 0.79875, 0.28861, 0.049963, 0.75799, 0.010879]
Predicted label: 5
Correct prediction
Energy consumption = 143.565251 pJ
sum error= 291
Actual label: 7
Output voltages: [0.053271, 0.066236, 0.13674, 0.12729, 0.0053749, 0.0011264, 0.0011163, 0.79868, 0.65912, 0.039169]
Predicted label: 7
Correct prediction
Energy consumption = 151.930546 pJ
sum error= 291
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 615 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 615 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 615 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.17803, 0.022852, 0.52466, 0.031243, 0.022368, 0.011452, 0.01528, 0.0014768, 0.79876, 0.058565]
Predicted label: 8
Correct prediction
Energy consumption = 153.495206 pJ
sum error= 291
Actual label: 3
Output voltages: [0.39675, 0.0058937, 0.051441, 0.7986, 0.050681, 0.025327, 0.01882, 0.03968, 0.63167, 0.10164]
Predicted label: 3
Correct prediction
Energy consumption = 144.960689 pJ
sum error= 291
Actual label: 4
Output voltages: [0.0088859, 0.030303, 0.028704, 0.001201, 0.79871, 0.0020298, 0.09135, 0.032249, 0.10288, 0.057184]
Predicted label: 4
Correct prediction
Energy consumption = 151.785907 pJ
sum error= 291
Actual label: 8
Output voltages: [0.050962, 0.013445, 0.11814, 0.27477, 0.014924, 0.12553, 0.011049, 0.0012583, 0.79879, 0.50788]
Predicted label: 8
Correct prediction
Energy consumption = 151.693854 pJ
sum error= 291
Actual label: 8
Output voltages: [0.046749, 0.008453, 0.10798, 0.15942, 0.002984, 0.3995, 0.022012, 0.0010757, 0.79879, 0.060109]
Predicted label: 8
Correct prediction
Energy consumption = 145.231927 pJ
sum error= 291
Actual label: 5
Output voltages: [0.049833, 0.00117, 0.0016073, 0.17198, 0.15249, 0.79876, 0.51839, 0.019854, 0.73965, 0.023257]
Predicted label: 5
Correct prediction
Energy consumption = 146.530684 pJ
sum error= 291
Actual label: 2
Output voltages: [0.35578, 0.056105, 0.79873, 0.032757, 0.047401, 0.0012413, 0.37957, 0.017096, 0.55043, 0.039205]
Predicted label: 2
Correct prediction
Energy consumption = 151.741220 pJ
sum error= 291
Actual label: 9
Output voltages: [0.77831, 0.0071403, 0.049738, 0.084183, 0.11371, 0.0022786, 0.088253, 0.001068, 0.73879, 0.74612]
Predicted label: 0
Wrong prediction!
Energy consumption = 150.948007 pJ
sum error= 292
Actual label: 7
Output voltages: [0.05744, 0.020508, 0.025729, 0.15783, 0.0076567, 0.010608, 0.0011064, 0.79874, 0.66505, 0.38497]
Predicted label: 7
Correct prediction
Energy consumption = 151.531916 pJ
sum error= 292
Actual label: 1
Output voltages: [0.13956, 0.79852, 0.28697, 0.10847, 0.015957, 0.0010664, 0.37591, 0.0023561, 0.32116, 0.12437]
Predicted label: 1
Correct prediction
Energy consumption = 159.136962 pJ
sum error= 292
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 616 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 616 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 616 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.083368, 0.02457, 0.38781, 0.79875, 0.019052, 0.0017077, 0.023857, 0.013005, 0.75079, 0.039606]
Predicted label: 3
Correct prediction
Energy consumption = 139.731124 pJ
sum error= 292
Actual label: 8
Output voltages: [0.11322, 0.0085165, 0.31974, 0.019413, 0.05019, 0.0081728, 0.047681, 0.0026444, 0.79878, 0.021228]
Predicted label: 8
Correct prediction
Energy consumption = 144.411240 pJ
sum error= 292
Actual label: 1
Output voltages: [0.086608, 0.79867, 0.031042, 0.058001, 0.16018, 0.010719, 0.3893, 0.004011, 0.10949, 0.087625]
Predicted label: 1
Correct prediction
Energy consumption = 165.000286 pJ
sum error= 292
Actual label: 0
Output voltages: [0.79876, 0.056669, 0.037672, 0.014372, 0.007759, 0.0043291, 0.5674, 0.022052, 0.16168, 0.022511]
Predicted label: 0
Correct prediction
Energy consumption = 152.537792 pJ
sum error= 292
Actual label: 7
Output voltages: [0.062258, 0.027426, 0.012869, 0.10243, 0.049112, 0.0059717, 0.0010667, 0.79878, 0.48129, 0.39041]
Predicted label: 7
Correct prediction
Energy consumption = 156.617650 pJ
sum error= 292
Actual label: 5
Output voltages: [0.046718, 0.0010857, 0.010071, 0.2987, 0.025245, 0.78795, 0.044435, 0.023021, 0.79349, 0.073061]
Predicted label: 8
Wrong prediction!
Energy consumption = 143.243685 pJ
sum error= 293
Actual label: 9
Output voltages: [0.55558, 0.0027646, 0.014122, 0.22283, 0.0038931, 0.045947, 0.011688, 0.0010847, 0.79757, 0.37037]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.387878 pJ
sum error= 294
Actual label: 6
Output voltages: [0.085327, 0.026839, 0.2008, 0.0086179, 0.36367, 0.28805, 0.79875, 0.0011372, 0.60774, 0.0084699]
Predicted label: 6
Correct prediction
Energy consumption = 144.216474 pJ
sum error= 294
Actual label: 9
Output voltages: [0.28786, 0.0038771, 0.02761, 0.02771, 0.095069, 0.0037068, 0.011398, 0.0055505, 0.76753, 0.76234]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.160559 pJ
sum error= 295
Actual label: 4
Output voltages: [0.0047999, 0.022469, 0.11026, 0.0030456, 0.79878, 0.0015265, 0.44088, 0.20706, 0.031748, 0.02705]
Predicted label: 4
Correct prediction
Energy consumption = 146.164707 pJ
sum error= 295
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 617 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 617 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 617 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.4966, 0.14835, 0.20955, 0.2203, 0.0060134, 0.0012793, 0.0011516, 0.79859, 0.42996, 0.15173]
Predicted label: 7
Correct prediction
Energy consumption = 155.470267 pJ
sum error= 295
Actual label: 7
Output voltages: [0.17596, 0.10381, 0.33225, 0.093441, 0.012164, 0.0022034, 0.0010827, 0.79856, 0.18631, 0.1756]
Predicted label: 7
Correct prediction
Energy consumption = 141.032228 pJ
sum error= 295
Actual label: 9
Output voltages: [0.76429, 0.0023258, 0.029765, 0.21585, 0.017869, 0.046778, 0.11345, 0.0010675, 0.75109, 0.58406]
Predicted label: 0
Wrong prediction!
Energy consumption = 149.216328 pJ
sum error= 296
Actual label: 9
Output voltages: [0.79492, 0.0011653, 0.1486, 0.078634, 0.15283, 0.0010662, 0.0089935, 0.032561, 0.64762, 0.33883]
Predicted label: 0
Wrong prediction!
Energy consumption = 137.242425 pJ
sum error= 297
Actual label: 3
Output voltages: [0.1974, 0.0211, 0.33293, 0.79863, 0.042128, 0.030064, 0.047852, 0.042848, 0.76829, 0.080097]
Predicted label: 3
Correct prediction
Energy consumption = 135.358433 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0073449, 0.0016387, 0.02272, 0.0020415, 0.79868, 0.001071, 0.077034, 0.041782, 0.31122, 0.013101]
Predicted label: 4
Correct prediction
Energy consumption = 152.322120 pJ
sum error= 297
Actual label: 4
Output voltages: [0.062818, 0.0094654, 0.045451, 0.0011016, 0.79877, 0.0023797, 0.090925, 0.017829, 0.15723, 0.024629]
Predicted label: 4
Correct prediction
Energy consumption = 138.264846 pJ
sum error= 297
Actual label: 3
Output voltages: [0.13011, 0.0043709, 0.084101, 0.79872, 0.0086517, 0.041114, 0.0048803, 0.020444, 0.4433, 0.040039]
Predicted label: 3
Correct prediction
Energy consumption = 143.561405 pJ
sum error= 297
Actual label: 8
Output voltages: [0.27787, 0.019174, 0.30701, 0.038852, 0.010341, 0.019654, 0.0017063, 0.0010718, 0.79867, 0.45674]
Predicted label: 8
Correct prediction
Energy consumption = 144.526767 pJ
sum error= 297
Actual label: 6
Output voltages: [0.083095, 0.0088578, 0.21085, 0.0012789, 0.25976, 0.45396, 0.79866, 0.00115, 0.73443, 0.061352]
Predicted label: 6
Correct prediction
Energy consumption = 149.270499 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 618 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 618 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 618 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36583, 0.006248, 0.79879, 0.24824, 0.0064376, 0.0012066, 0.3832, 0.080781, 0.50931, 0.026679]
Predicted label: 2
Correct prediction
Energy consumption = 146.534310 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79596, 0.084914, 0.019485, 0.0055226, 0.01878, 0.0011922, 0.39891, 0.043152, 0.48473, 0.27919]
Predicted label: 0
Correct prediction
Energy consumption = 146.218882 pJ
sum error= 297
Actual label: 1
Output voltages: [0.002997, 0.79851, 0.24034, 0.24057, 0.041201, 0.0022159, 0.50104, 0.012918, 0.40199, 0.055678]
Predicted label: 1
Correct prediction
Energy consumption = 158.858799 pJ
sum error= 297
Actual label: 2
Output voltages: [0.45007, 0.020011, 0.79823, 0.51164, 0.0028776, 0.0011022, 0.11836, 0.017321, 0.37632, 0.021225]
Predicted label: 2
Correct prediction
Energy consumption = 151.948718 pJ
sum error= 297
Actual label: 3
Output voltages: [0.1103, 0.02134, 0.094859, 0.79878, 0.0036797, 0.0082176, 0.0022628, 0.030774, 0.77029, 0.0095759]
Predicted label: 3
Correct prediction
Energy consumption = 138.209618 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0057529, 0.022258, 0.16974, 0.0083775, 0.79877, 0.0080184, 0.035599, 0.069996, 0.077383, 0.013399]
Predicted label: 4
Correct prediction
Energy consumption = 149.442238 pJ
sum error= 297
Actual label: 5
Output voltages: [0.037401, 0.0010678, 0.0011523, 0.76204, 0.03434, 0.79696, 0.065703, 0.027063, 0.74989, 0.039149]
Predicted label: 5
Correct prediction
Energy consumption = 149.795589 pJ
sum error= 297
Actual label: 6
Output voltages: [0.090529, 0.043002, 0.44441, 0.0011192, 0.218, 0.17257, 0.79875, 0.0031512, 0.40667, 0.0022338]
Predicted label: 6
Correct prediction
Energy consumption = 147.581356 pJ
sum error= 297
Actual label: 7
Output voltages: [0.16135, 0.34571, 0.065314, 0.11171, 0.0035889, 0.002663, 0.0010663, 0.79879, 0.23907, 0.34244]
Predicted label: 7
Correct prediction
Energy consumption = 159.285353 pJ
sum error= 297
Actual label: 8
Output voltages: [0.025256, 0.18112, 0.039131, 0.69205, 0.0016107, 0.029308, 0.022635, 0.0022419, 0.79874, 0.072174]
Predicted label: 8
Correct prediction
Energy consumption = 149.056742 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 619 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 619 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 619 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.10959, 0.010092, 0.015185, 0.057328, 0.044364, 0.015986, 0.0021699, 0.047079, 0.72442, 0.79704]
Predicted label: 9
Correct prediction
Energy consumption = 152.144748 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79878, 0.063521, 0.1833, 0.023763, 0.0024957, 0.003611, 0.38134, 0.01745, 0.048371, 0.054631]
Predicted label: 0
Correct prediction
Energy consumption = 143.394119 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0055663, 0.79876, 0.2006, 0.041189, 0.36908, 0.0010678, 0.75737, 0.003417, 0.18259, 0.013453]
Predicted label: 1
Correct prediction
Energy consumption = 160.032121 pJ
sum error= 297
Actual label: 2
Output voltages: [0.67173, 0.053117, 0.79879, 0.16631, 0.01878, 0.0010857, 0.03795, 0.069663, 0.53343, 0.0045922]
Predicted label: 2
Correct prediction
Energy consumption = 147.676421 pJ
sum error= 297
Actual label: 3
Output voltages: [0.66323, 0.015181, 0.22564, 0.79873, 0.015276, 0.0095236, 0.0047456, 0.022482, 0.54412, 0.031138]
Predicted label: 3
Correct prediction
Energy consumption = 141.219702 pJ
sum error= 297
Actual label: 4
Output voltages: [0.015508, 0.0051772, 0.42352, 0.0025803, 0.79869, 0.0035291, 0.072033, 0.03911, 0.024451, 0.035085]
Predicted label: 4
Correct prediction
Energy consumption = 152.368576 pJ
sum error= 297
Actual label: 5
Output voltages: [0.029687, 0.0010704, 0.0024191, 0.16084, 0.034693, 0.79879, 0.089951, 0.02324, 0.77741, 0.043828]
Predicted label: 5
Correct prediction
Energy consumption = 152.490195 pJ
sum error= 297
Actual label: 6
Output voltages: [0.094605, 0.018095, 0.19836, 0.0060483, 0.35892, 0.23813, 0.79877, 0.0010834, 0.60963, 0.0090226]
Predicted label: 6
Correct prediction
Energy consumption = 141.350338 pJ
sum error= 297
Actual label: 7
Output voltages: [0.23767, 0.021348, 0.024765, 0.20148, 0.012428, 0.026113, 0.0010924, 0.79867, 0.18114, 0.39346]
Predicted label: 7
Correct prediction
Energy consumption = 157.028293 pJ
sum error= 297
Actual label: 8
Output voltages: [0.017049, 0.019507, 0.12175, 0.058229, 0.006087, 0.13866, 0.029909, 0.0058295, 0.79868, 0.11509]
Predicted label: 8
Correct prediction
Energy consumption = 145.010356 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 620 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 620 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 620 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.13557, 0.011445, 0.037625, 0.020574, 0.045928, 0.049498, 0.017134, 0.11118, 0.69915, 0.79841]
Predicted label: 9
Correct prediction
Energy consumption = 156.208594 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.057645, 0.059591, 0.0217, 0.0057207, 0.0039664, 0.43359, 0.015565, 0.041442, 0.10813]
Predicted label: 0
Correct prediction
Energy consumption = 150.153674 pJ
sum error= 297
Actual label: 1
Output voltages: [0.033724, 0.79858, 0.21877, 0.015651, 0.020044, 0.0051091, 0.7372, 0.001291, 0.32826, 0.019867]
Predicted label: 1
Correct prediction
Energy consumption = 161.144114 pJ
sum error= 297
Actual label: 2
Output voltages: [0.52758, 0.017111, 0.79876, 0.031512, 0.02154, 0.0011668, 0.057233, 0.036604, 0.40066, 0.015715]
Predicted label: 2
Correct prediction
Energy consumption = 150.695849 pJ
sum error= 297
Actual label: 3
Output voltages: [0.55365, 0.027139, 0.048042, 0.79864, 0.015665, 0.05439, 0.010113, 0.085119, 0.69679, 0.024314]
Predicted label: 3
Correct prediction
Energy consumption = 146.955672 pJ
sum error= 297
Actual label: 4
Output voltages: [0.010435, 0.0070748, 0.036999, 0.0085589, 0.79872, 0.019768, 0.18931, 0.12312, 0.1258, 0.0015896]
Predicted label: 4
Correct prediction
Energy consumption = 149.972485 pJ
sum error= 297
Actual label: 5
Output voltages: [0.04359, 0.0012909, 0.0013168, 0.48986, 0.034128, 0.79722, 0.2004, 0.011659, 0.68146, 0.18782]
Predicted label: 5
Correct prediction
Energy consumption = 147.406826 pJ
sum error= 297
Actual label: 6
Output voltages: [0.09115, 0.023126, 0.2648, 0.0010829, 0.43024, 0.046989, 0.79875, 0.0012397, 0.48869, 0.0036084]
Predicted label: 6
Correct prediction
Energy consumption = 145.443217 pJ
sum error= 297
Actual label: 7
Output voltages: [0.2888, 0.078062, 0.016095, 0.051027, 0.0034979, 0.0017864, 0.0011643, 0.79877, 0.44698, 0.48602]
Predicted label: 7
Correct prediction
Energy consumption = 153.910469 pJ
sum error= 297
Actual label: 8
Output voltages: [0.02688, 0.053023, 0.17793, 0.12281, 0.0046162, 0.029862, 0.023519, 0.0079784, 0.79863, 0.18712]
Predicted label: 8
Correct prediction
Energy consumption = 148.699112 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 621 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 621 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 621 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.70897, 0.0015971, 0.039124, 0.008124, 0.30583, 0.025073, 0.0013711, 0.040371, 0.57445, 0.79623]
Predicted label: 9
Correct prediction
Energy consumption = 148.786125 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.092974, 0.020319, 0.019861, 0.036659, 0.016275, 0.68598, 0.0033021, 0.069848, 0.018669]
Predicted label: 0
Correct prediction
Energy consumption = 150.762050 pJ
sum error= 297
Actual label: 8
Output voltages: [0.043152, 0.025036, 0.033066, 0.26798, 0.0056301, 0.029909, 0.015411, 0.0015964, 0.7987, 0.40579]
Predicted label: 8
Correct prediction
Energy consumption = 152.623730 pJ
sum error= 297
Actual label: 3
Output voltages: [0.12413, 0.015643, 0.044626, 0.79878, 0.02384, 0.30044, 0.067403, 0.056315, 0.64039, 0.043345]
Predicted label: 3
Correct prediction
Energy consumption = 145.074764 pJ
sum error= 297
Actual label: 9
Output voltages: [0.21746, 0.020174, 0.022205, 0.027187, 0.16471, 0.018697, 0.0012572, 0.013425, 0.38824, 0.7978]
Predicted label: 9
Correct prediction
Energy consumption = 150.194368 pJ
sum error= 297
Actual label: 5
Output voltages: [0.1409, 0.0011503, 0.0039384, 0.39771, 0.021804, 0.79767, 0.72167, 0.0062619, 0.76191, 0.0089075]
Predicted label: 5
Correct prediction
Energy consumption = 148.004694 pJ
sum error= 297
Actual label: 5
Output voltages: [0.056072, 0.0014732, 0.0063492, 0.4636, 0.0080678, 0.79879, 0.21318, 0.045865, 0.75933, 0.067448]
Predicted label: 5
Correct prediction
Energy consumption = 134.123693 pJ
sum error= 297
Actual label: 2
Output voltages: [0.5107, 0.0098821, 0.79877, 0.19166, 0.01507, 0.0010736, 0.043517, 0.24842, 0.6256, 0.006493]
Predicted label: 2
Correct prediction
Energy consumption = 144.497679 pJ
sum error= 297
Actual label: 6
Output voltages: [0.18593, 0.066486, 0.43772, 0.0010662, 0.38145, 0.020829, 0.79879, 0.0010698, 0.10416, 0.0040603]
Predicted label: 6
Correct prediction
Energy consumption = 143.211403 pJ
sum error= 297
Actual label: 8
Output voltages: [0.021851, 0.15779, 0.037146, 0.73954, 0.0034039, 0.028025, 0.088461, 0.011295, 0.79878, 0.10868]
Predicted label: 8
Correct prediction
Energy consumption = 152.862618 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 622 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 622 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 622 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.013669, 0.0030537, 0.13089, 0.0012803, 0.79872, 0.0011363, 0.4293, 0.074328, 0.033357, 0.0082976]
Predicted label: 4
Correct prediction
Energy consumption = 158.572564 pJ
sum error= 297
Actual label: 9
Output voltages: [0.1996, 0.028033, 0.01249, 0.051947, 0.30606, 0.017307, 0.0033507, 0.011538, 0.25265, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 145.101110 pJ
sum error= 297
Actual label: 1
Output voltages: [0.024265, 0.79861, 0.31309, 0.057393, 0.40324, 0.0010914, 0.43089, 0.0015837, 0.044747, 0.038558]
Predicted label: 1
Correct prediction
Energy consumption = 168.535419 pJ
sum error= 297
Actual label: 7
Output voltages: [0.051486, 0.059327, 0.046318, 0.19552, 0.0055399, 0.034694, 0.0010893, 0.79855, 0.05725, 0.37]
Predicted label: 7
Correct prediction
Energy consumption = 149.991082 pJ
sum error= 297
Actual label: 1
Output voltages: [0.017259, 0.79863, 0.024134, 0.16514, 0.44855, 0.001152, 0.43379, 0.035494, 0.036969, 0.055412]
Predicted label: 1
Correct prediction
Energy consumption = 162.516278 pJ
sum error= 297
Actual label: 2
Output voltages: [0.45295, 0.010904, 0.79879, 0.33403, 0.0070351, 0.0010663, 0.020436, 0.038017, 0.69634, 0.001793]
Predicted label: 2
Correct prediction
Energy consumption = 146.271037 pJ
sum error= 297
Actual label: 3
Output voltages: [0.48291, 0.0015659, 0.076285, 0.79878, 0.082636, 0.03169, 0.0051939, 0.0027993, 0.53686, 0.010205]
Predicted label: 3
Correct prediction
Energy consumption = 144.275749 pJ
sum error= 297
Actual label: 5
Output voltages: [0.017793, 0.0010671, 0.0012502, 0.73677, 0.049031, 0.79872, 0.0039815, 0.049572, 0.76832, 0.0055459]
Predicted label: 5
Correct prediction
Energy consumption = 137.261849 pJ
sum error= 297
Actual label: 9
Output voltages: [0.27661, 0.0020418, 0.021763, 0.018352, 0.036932, 0.027276, 0.0021507, 0.034768, 0.78056, 0.79039]
Predicted label: 9
Correct prediction
Energy consumption = 144.298947 pJ
sum error= 297
Actual label: 6
Output voltages: [0.035644, 0.026118, 0.34101, 0.0012586, 0.34571, 0.028657, 0.79878, 0.0011857, 0.45311, 0.0031598]
Predicted label: 6
Correct prediction
Energy consumption = 146.719535 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 623 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 623 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 623 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.24999, 0.017664, 0.024449, 0.056318, 0.044831, 0.061199, 0.006402, 0.11593, 0.53741, 0.79759]
Predicted label: 9
Correct prediction
Energy consumption = 153.587513 pJ
sum error= 297
Actual label: 1
Output voltages: [0.050785, 0.7987, 0.055772, 0.020037, 0.054638, 0.0011022, 0.56243, 0.001083, 0.13869, 0.020487]
Predicted label: 1
Correct prediction
Energy consumption = 166.091398 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0077395, 0.79876, 0.022543, 0.27309, 0.043535, 0.0020118, 0.22926, 0.0027116, 0.55295, 0.41985]
Predicted label: 1
Correct prediction
Energy consumption = 154.523126 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0055188, 0.79852, 0.13917, 0.041195, 0.008835, 0.0020628, 0.747, 0.025092, 0.19422, 0.0145]
Predicted label: 1
Correct prediction
Energy consumption = 150.691405 pJ
sum error= 297
Actual label: 2
Output voltages: [0.15591, 0.041637, 0.79869, 0.62755, 0.018073, 0.0010905, 0.02337, 0.042265, 0.41008, 0.0047964]
Predicted label: 2
Correct prediction
Energy consumption = 150.838612 pJ
sum error= 297
Actual label: 9
Output voltages: [0.22026, 0.014851, 0.015647, 0.043385, 0.026807, 0.021447, 0.015209, 0.21541, 0.61442, 0.79544]
Predicted label: 9
Correct prediction
Energy consumption = 150.698095 pJ
sum error= 297
Actual label: 5
Output voltages: [0.01317, 0.001129, 0.0099158, 0.099265, 0.015676, 0.79843, 0.051107, 0.027128, 0.791, 0.017796]
Predicted label: 5
Correct prediction
Energy consumption = 143.902651 pJ
sum error= 297
Actual label: 6
Output voltages: [0.082136, 0.048906, 0.48417, 0.0017415, 0.25394, 0.05798, 0.79877, 0.0027554, 0.081307, 0.011606]
Predicted label: 6
Correct prediction
Energy consumption = 146.775377 pJ
sum error= 297
Actual label: 8
Output voltages: [0.53615, 0.056084, 0.44088, 0.021742, 0.0064521, 0.30283, 0.021715, 0.010047, 0.79877, 0.005531]
Predicted label: 8
Correct prediction
Energy consumption = 151.041841 pJ
sum error= 297
Actual label: 1
Output voltages: [0.003419, 0.79874, 0.025768, 0.0084037, 0.013465, 0.0030163, 0.27333, 0.029098, 0.32703, 0.044009]
Predicted label: 1
Correct prediction
Energy consumption = 151.045031 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 624 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 624 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 624 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.63747, 0.038764, 0.79874, 0.058267, 0.014106, 0.0010885, 0.054114, 0.18555, 0.47148, 0.014211]
Predicted label: 2
Correct prediction
Energy consumption = 146.754235 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79877, 0.033997, 0.027279, 0.025557, 0.25611, 0.009924, 0.6615, 0.016534, 0.04693, 0.036042]
Predicted label: 0
Correct prediction
Energy consumption = 151.852341 pJ
sum error= 297
Actual label: 7
Output voltages: [0.1391, 0.084926, 0.011681, 0.024087, 0.0052578, 0.018284, 0.0010833, 0.79869, 0.060466, 0.40423]
Predicted label: 7
Correct prediction
Energy consumption = 153.903207 pJ
sum error= 297
Actual label: 7
Output voltages: [0.11746, 0.0062471, 0.0016401, 0.001444, 0.37126, 0.25357, 0.0031085, 0.79855, 0.13604, 0.0468]
Predicted label: 7
Correct prediction
Energy consumption = 143.802572 pJ
sum error= 297
Actual label: 5
Output voltages: [0.031803, 0.0013592, 0.0011233, 0.4233, 0.080088, 0.79875, 0.15586, 0.020486, 0.72656, 0.0061741]
Predicted label: 5
Correct prediction
Energy consumption = 144.224897 pJ
sum error= 297
Actual label: 8
Output voltages: [0.014949, 0.021534, 0.33011, 0.25454, 0.0085949, 0.29806, 0.024313, 0.14295, 0.79861, 0.014911]
Predicted label: 8
Correct prediction
Energy consumption = 150.130485 pJ
sum error= 297
Actual label: 2
Output voltages: [0.29076, 0.035894, 0.79866, 0.034824, 0.013832, 0.0010917, 0.10492, 0.03674, 0.55019, 0.016104]
Predicted label: 2
Correct prediction
Energy consumption = 141.854087 pJ
sum error= 297
Actual label: 9
Output voltages: [0.50237, 0.015039, 0.02891, 0.028684, 0.22609, 0.031152, 0.0016636, 0.040713, 0.39917, 0.79802]
Predicted label: 9
Correct prediction
Energy consumption = 150.153006 pJ
sum error= 297
Actual label: 8
Output voltages: [0.019189, 0.15039, 0.27452, 0.096075, 0.011354, 0.015789, 0.016595, 0.031031, 0.79862, 0.12567]
Predicted label: 8
Correct prediction
Energy consumption = 148.124640 pJ
sum error= 297
Actual label: 9
Output voltages: [0.18921, 0.033757, 0.025229, 0.049347, 0.088535, 0.038809, 0.018612, 0.020991, 0.33836, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 148.531819 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 625 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 625 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 625 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.039507, 0.021276, 0.015161, 0.030039, 0.010084, 0.75509, 0.02211, 0.21706, 0.11019]
Predicted label: 0
Correct prediction
Energy consumption = 152.607879 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0024972, 0.025662, 0.28243, 0.018907, 0.79865, 0.0015546, 0.18307, 0.051866, 0.02344, 0.20554]
Predicted label: 4
Correct prediction
Energy consumption = 156.294415 pJ
sum error= 297
Actual label: 6
Output voltages: [0.039006, 0.0050114, 0.095146, 0.0017688, 0.42082, 0.018404, 0.79879, 0.001483, 0.4861, 0.0092462]
Predicted label: 6
Correct prediction
Energy consumption = 142.306040 pJ
sum error= 297
Actual label: 7
Output voltages: [0.044443, 0.060538, 0.016296, 0.030081, 0.0097051, 0.0032333, 0.0010665, 0.79872, 0.04164, 0.55109]
Predicted label: 7
Correct prediction
Energy consumption = 155.924328 pJ
sum error= 297
Actual label: 1
Output voltages: [0.022721, 0.79848, 0.017978, 0.034131, 0.032092, 0.0016609, 0.49728, 0.011352, 0.057663, 0.040357]
Predicted label: 1
Correct prediction
Energy consumption = 157.688893 pJ
sum error= 297
Actual label: 3
Output voltages: [0.4173, 0.038321, 0.022602, 0.79858, 0.0083837, 0.027392, 0.0088952, 0.0077785, 0.65973, 0.14027]
Predicted label: 3
Correct prediction
Energy consumption = 152.808442 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0050662, 0.007449, 0.17693, 0.0068279, 0.79868, 0.0034862, 0.11235, 0.034709, 0.17573, 0.021727]
Predicted label: 4
Correct prediction
Energy consumption = 155.760769 pJ
sum error= 297
Actual label: 5
Output voltages: [0.068763, 0.0011122, 0.0019632, 0.097663, 0.060412, 0.79879, 0.23474, 0.039426, 0.78766, 0.022888]
Predicted label: 5
Correct prediction
Energy consumption = 146.095896 pJ
sum error= 297
Actual label: 6
Output voltages: [0.12604, 0.0062873, 0.0089787, 0.15668, 0.4779, 0.55827, 0.79868, 0.0011036, 0.70943, 0.085598]
Predicted label: 6
Correct prediction
Energy consumption = 142.229564 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79878, 0.08359, 0.033109, 0.010699, 0.05533, 0.029519, 0.50687, 0.009917, 0.033716, 0.24121]
Predicted label: 0
Correct prediction
Energy consumption = 152.204775 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 626 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 626 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 626 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.56231, 0.047268, 0.15601, 0.79862, 0.0099945, 0.0085041, 0.0023474, 0.0038273, 0.63957, 0.049973]
Predicted label: 3
Correct prediction
Energy consumption = 150.436202 pJ
sum error= 297
Actual label: 6
Output voltages: [0.043874, 0.0396, 0.41497, 0.0011248, 0.13575, 0.045731, 0.79879, 0.0017814, 0.53001, 0.0017618]
Predicted label: 6
Correct prediction
Energy consumption = 153.740135 pJ
sum error= 297
Actual label: 8
Output voltages: [0.03549, 0.014362, 0.22018, 0.66663, 0.0056639, 0.0066755, 0.0024633, 0.0030399, 0.79811, 0.12249]
Predicted label: 8
Correct prediction
Energy consumption = 148.621367 pJ
sum error= 297
Actual label: 7
Output voltages: [0.2118, 0.0095595, 0.021471, 0.063715, 0.012644, 0.0086312, 0.001105, 0.79861, 0.04843, 0.19262]
Predicted label: 7
Correct prediction
Energy consumption = 146.975936 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79834, 0.031132, 0.042336, 0.015105, 0.019565, 0.0029245, 0.6895, 0.010799, 0.062036, 0.039814]
Predicted label: 0
Correct prediction
Energy consumption = 150.482040 pJ
sum error= 297
Actual label: 4
Output voltages: [0.039592, 0.0055446, 0.16351, 0.0042383, 0.7987, 0.0039075, 0.029081, 0.023167, 0.22576, 0.012749]
Predicted label: 4
Correct prediction
Energy consumption = 149.635185 pJ
sum error= 297
Actual label: 2
Output voltages: [0.019691, 0.032571, 0.79854, 0.19151, 0.016366, 0.001068, 0.10593, 0.036241, 0.56269, 0.011201]
Predicted label: 2
Correct prediction
Energy consumption = 157.051843 pJ
sum error= 297
Actual label: 7
Output voltages: [0.087144, 0.030209, 0.04954, 0.059895, 0.0068284, 0.0069257, 0.0011653, 0.79877, 0.05054, 0.73539]
Predicted label: 7
Correct prediction
Energy consumption = 153.053624 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0040744, 0.01101, 0.04014, 0.0076137, 0.79871, 0.0011997, 0.25498, 0.14156, 0.0412, 0.023984]
Predicted label: 4
Correct prediction
Energy consumption = 152.402147 pJ
sum error= 297
Actual label: 7
Output voltages: [0.35596, 0.028836, 0.013001, 0.017715, 0.022154, 0.027887, 0.0010711, 0.79861, 0.41426, 0.17342]
Predicted label: 7
Correct prediction
Energy consumption = 151.343520 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 627 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 627 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 627 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.03683, 0.0010763, 0.0024692, 0.060881, 0.018671, 0.79878, 0.22608, 0.10311, 0.76902, 0.028053]
Predicted label: 5
Correct prediction
Energy consumption = 146.600481 pJ
sum error= 297
Actual label: 4
Output voltages: [0.001448, 0.014007, 0.11852, 0.010374, 0.79876, 0.0010854, 0.1068, 0.014071, 0.046306, 0.036508]
Predicted label: 4
Correct prediction
Energy consumption = 153.908438 pJ
sum error= 297
Actual label: 3
Output voltages: [0.1308, 0.01036, 0.25186, 0.79879, 0.012591, 0.0024004, 0.023017, 0.011436, 0.71956, 0.11792]
Predicted label: 3
Correct prediction
Energy consumption = 143.739315 pJ
sum error= 297
Actual label: 4
Output voltages: [0.22675, 0.017797, 0.064125, 0.0025421, 0.79877, 0.001666, 0.017795, 0.016005, 0.016746, 0.50713]
Predicted label: 4
Correct prediction
Energy consumption = 152.959032 pJ
sum error= 297
Actual label: 2
Output voltages: [0.64815, 0.016364, 0.79879, 0.083979, 0.016791, 0.0011377, 0.028647, 0.049464, 0.34381, 0.010761]
Predicted label: 2
Correct prediction
Energy consumption = 150.238058 pJ
sum error= 297
Actual label: 8
Output voltages: [0.024149, 0.15284, 0.26717, 0.18595, 0.010626, 0.0098527, 0.022057, 0.0045357, 0.79874, 0.30138]
Predicted label: 8
Correct prediction
Energy consumption = 149.257393 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0047847, 0.79857, 0.02107, 0.02686, 0.036226, 0.0031806, 0.71908, 0.018033, 0.37604, 0.016273]
Predicted label: 1
Correct prediction
Energy consumption = 152.943531 pJ
sum error= 297
Actual label: 5
Output voltages: [0.026589, 0.0011427, 0.0010662, 0.36788, 0.15824, 0.79878, 0.62874, 0.025434, 0.56683, 0.041304]
Predicted label: 5
Correct prediction
Energy consumption = 150.365500 pJ
sum error= 297
Actual label: 1
Output voltages: [0.022723, 0.79865, 0.33277, 0.021735, 0.36123, 0.0012066, 0.52555, 0.028656, 0.081302, 0.030846]
Predicted label: 1
Correct prediction
Energy consumption = 162.377908 pJ
sum error= 297
Actual label: 2
Output voltages: [0.047975, 0.019079, 0.79863, 0.037215, 0.034613, 0.0011114, 0.030645, 0.075792, 0.48273, 0.04214]
Predicted label: 2
Correct prediction
Energy consumption = 133.563759 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 628 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 628 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 628 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.073319, 0.017364, 0.021242, 0.026029, 0.01854, 0.72245, 0.017815, 0.15926, 0.033311]
Predicted label: 0
Correct prediction
Energy consumption = 156.092567 pJ
sum error= 297
Actual label: 2
Output voltages: [0.2115, 0.021749, 0.79874, 0.35011, 0.12869, 0.0011122, 0.031667, 0.03636, 0.36939, 0.055761]
Predicted label: 2
Correct prediction
Energy consumption = 142.901778 pJ
sum error= 297
Actual label: 5
Output voltages: [0.026522, 0.0010885, 0.0019899, 0.27331, 0.018966, 0.79591, 0.038589, 0.0090734, 0.76316, 0.12952]
Predicted label: 5
Correct prediction
Energy consumption = 147.600346 pJ
sum error= 297
Actual label: 6
Output voltages: [0.049862, 0.013427, 0.20318, 0.0041108, 0.33363, 0.23756, 0.79879, 0.0017883, 0.61399, 0.0017329]
Predicted label: 6
Correct prediction
Energy consumption = 146.971822 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0096657, 0.0083722, 0.04806, 0.0043931, 0.79868, 0.0049635, 0.13093, 0.10666, 0.058209, 0.020283]
Predicted label: 4
Correct prediction
Energy consumption = 148.600448 pJ
sum error= 297
Actual label: 3
Output voltages: [0.56981, 0.0016504, 0.25722, 0.79878, 0.030538, 0.13108, 0.0173, 0.016068, 0.78489, 0.0067822]
Predicted label: 3
Correct prediction
Energy consumption = 144.179481 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.15474, 0.031056, 0.016749, 0.005062, 0.0036031, 0.46179, 0.014438, 0.051356, 0.32925]
Predicted label: 0
Correct prediction
Energy consumption = 142.849799 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.08995, 0.10292, 0.0092675, 0.0077315, 0.003584, 0.21529, 0.027758, 0.24499, 0.21466]
Predicted label: 0
Correct prediction
Energy consumption = 135.769075 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.25115, 0.045608, 0.021891, 0.0079022, 0.0079877, 0.51396, 0.0035474, 0.077471, 0.066892]
Predicted label: 0
Correct prediction
Energy consumption = 143.887117 pJ
sum error= 297
Actual label: 3
Output voltages: [0.050166, 0.002889, 0.19049, 0.79879, 0.03981, 0.084547, 0.0044731, 0.14484, 0.73535, 0.10072]
Predicted label: 3
Correct prediction
Energy consumption = 147.743942 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 629 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 629 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 629 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.76234, 0.0079632, 0.38775, 0.79868, 0.040767, 0.017754, 0.019198, 0.02508, 0.7669, 0.0082942]
Predicted label: 3
Correct prediction
Energy consumption = 149.705582 pJ
sum error= 297
Actual label: 5
Output voltages: [0.036511, 0.0013198, 0.0010802, 0.28822, 0.11655, 0.79878, 0.47213, 0.019695, 0.48162, 0.053382]
Predicted label: 5
Correct prediction
Energy consumption = 144.785868 pJ
sum error= 297
Actual label: 7
Output voltages: [0.050283, 0.061203, 0.041064, 0.034211, 0.0062499, 0.0047971, 0.0010725, 0.79857, 0.046098, 0.1917]
Predicted label: 7
Correct prediction
Energy consumption = 151.394125 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79875, 0.054303, 0.025796, 0.03727, 0.01631, 0.011115, 0.51612, 0.041076, 0.26186, 0.057715]
Predicted label: 0
Correct prediction
Energy consumption = 149.286606 pJ
sum error= 297
Actual label: 6
Output voltages: [0.04414, 0.051934, 0.28288, 0.0010787, 0.42663, 0.05629, 0.79878, 0.0020486, 0.48797, 0.0056807]
Predicted label: 6
Correct prediction
Energy consumption = 142.353676 pJ
sum error= 297
Actual label: 4
Output voltages: [0.001782, 0.0050974, 0.08693, 0.010931, 0.7987, 0.0012733, 0.24132, 0.045861, 0.068457, 0.022581]
Predicted label: 4
Correct prediction
Energy consumption = 148.415965 pJ
sum error= 297
Actual label: 8
Output voltages: [0.022109, 0.040735, 0.42908, 0.26212, 0.0022472, 0.11778, 0.029735, 0.03525, 0.79861, 0.042221]
Predicted label: 8
Correct prediction
Energy consumption = 151.719074 pJ
sum error= 297
Actual label: 8
Output voltages: [0.022056, 0.0025222, 0.0028467, 0.22042, 0.020027, 0.14039, 0.019115, 0.0056432, 0.79879, 0.14101]
Predicted label: 8
Correct prediction
Energy consumption = 141.250878 pJ
sum error= 297
Actual label: 6
Output voltages: [0.33503, 0.3653, 0.007695, 0.068559, 0.048384, 0.52144, 0.79875, 0.0013282, 0.3265, 0.0013886]
Predicted label: 6
Correct prediction
Energy consumption = 149.144858 pJ
sum error= 297
Actual label: 3
Output voltages: [0.49769, 0.014978, 0.08266, 0.79877, 0.0067132, 0.00589, 0.0085629, 0.014008, 0.26469, 0.018442]
Predicted label: 3
Correct prediction
Energy consumption = 150.229430 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 630 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 630 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 630 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0048059, 0.003111, 0.23437, 0.0020292, 0.79873, 0.0034739, 0.19733, 0.067408, 0.13084, 0.0079172]
Predicted label: 4
Correct prediction
Energy consumption = 150.069319 pJ
sum error= 297
Actual label: 6
Output voltages: [0.092767, 0.23689, 0.26422, 0.008174, 0.32283, 0.043668, 0.7987, 0.0011205, 0.31041, 0.024534]
Predicted label: 6
Correct prediction
Energy consumption = 144.889818 pJ
sum error= 297
Actual label: 9
Output voltages: [0.1925, 0.020578, 0.039522, 0.018929, 0.039609, 0.011389, 0.0066406, 0.022033, 0.75432, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 146.334716 pJ
sum error= 297
Actual label: 9
Output voltages: [0.19841, 0.0010692, 0.019638, 0.025502, 0.022188, 0.05983, 0.0012223, 0.41133, 0.70664, 0.77122]
Predicted label: 9
Correct prediction
Energy consumption = 138.674857 pJ
sum error= 297
Actual label: 8
Output voltages: [0.018672, 0.16593, 0.054802, 0.19202, 0.0014329, 0.035771, 0.03346, 0.081733, 0.79865, 0.016364]
Predicted label: 8
Correct prediction
Energy consumption = 153.337328 pJ
sum error= 297
Actual label: 2
Output voltages: [0.36484, 0.0014051, 0.79753, 0.56498, 0.011178, 0.0016972, 0.019287, 0.0093924, 0.74548, 0.026351]
Predicted label: 2
Correct prediction
Energy consumption = 140.234331 pJ
sum error= 297
Actual label: 7
Output voltages: [0.039625, 0.019561, 0.50973, 0.027142, 0.002339, 0.001124, 0.0011324, 0.79878, 0.7495, 0.045243]
Predicted label: 7
Correct prediction
Energy consumption = 139.362630 pJ
sum error= 297
Actual label: 7
Output voltages: [0.093248, 0.11604, 0.26338, 0.10421, 0.0020038, 0.0015115, 0.0010765, 0.79865, 0.47425, 0.26287]
Predicted label: 7
Correct prediction
Energy consumption = 137.366888 pJ
sum error= 297
Actual label: 1
Output voltages: [0.019734, 0.79843, 0.0094388, 0.047177, 0.036773, 0.0064759, 0.67133, 0.023879, 0.048872, 0.12092]
Predicted label: 1
Correct prediction
Energy consumption = 157.897339 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79878, 0.021511, 0.038511, 0.011742, 0.022817, 0.007451, 0.73133, 0.012134, 0.2203, 0.045644]
Predicted label: 0
Correct prediction
Energy consumption = 158.103068 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 631 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 631 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 631 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.03747, 0.79873, 0.63542, 0.055764, 0.052142, 0.0011073, 0.47624, 0.0032783, 0.070193, 0.031693]
Predicted label: 1
Correct prediction
Energy consumption = 165.281292 pJ
sum error= 297
Actual label: 2
Output voltages: [0.38514, 0.016906, 0.7987, 0.049163, 0.022645, 0.0011618, 0.25415, 0.03255, 0.29219, 0.014425]
Predicted label: 2
Correct prediction
Energy consumption = 140.221448 pJ
sum error= 297
Actual label: 3
Output voltages: [0.0092802, 0.013727, 0.02721, 0.79879, 0.028789, 0.0085926, 0.0010952, 0.05098, 0.71211, 0.18013]
Predicted label: 3
Correct prediction
Energy consumption = 137.494061 pJ
sum error= 297
Actual label: 4
Output voltages: [0.03204, 0.018182, 0.038759, 0.0021953, 0.79868, 0.0038877, 0.12563, 0.050871, 0.050928, 0.0098288]
Predicted label: 4
Correct prediction
Energy consumption = 152.269644 pJ
sum error= 297
Actual label: 5
Output voltages: [0.2219, 0.0039564, 0.0093384, 0.47434, 0.011545, 0.79862, 0.47556, 0.026183, 0.67451, 0.14944]
Predicted label: 5
Correct prediction
Energy consumption = 152.483967 pJ
sum error= 297
Actual label: 6
Output voltages: [0.073076, 0.18634, 0.17044, 0.021579, 0.16244, 0.31346, 0.79867, 0.0046995, 0.39113, 0.023661]
Predicted label: 6
Correct prediction
Energy consumption = 149.868189 pJ
sum error= 297
Actual label: 7
Output voltages: [0.16521, 0.029461, 0.10433, 0.35417, 0.0013718, 0.0010969, 0.0010659, 0.7987, 0.11744, 0.11005]
Predicted label: 7
Correct prediction
Energy consumption = 160.288531 pJ
sum error= 297
Actual label: 8
Output voltages: [0.037368, 0.016734, 0.72938, 0.16055, 0.0025682, 0.016674, 0.021916, 0.012157, 0.79874, 0.049026]
Predicted label: 8
Correct prediction
Energy consumption = 142.343644 pJ
sum error= 297
Actual label: 9
Output voltages: [0.29148, 0.029399, 0.022667, 0.15133, 0.19537, 0.015524, 0.014107, 0.018134, 0.249, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 148.480580 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79878, 0.019565, 0.021291, 0.010565, 0.026085, 0.017677, 0.55663, 0.004313, 0.10674, 0.034724]
Predicted label: 0
Correct prediction
Energy consumption = 151.497210 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 632 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 632 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 632 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.041498, 0.79858, 0.32556, 0.013266, 0.33196, 0.0012488, 0.4793, 0.0023603, 0.064504, 0.10274]
Predicted label: 1
Correct prediction
Energy consumption = 164.976905 pJ
sum error= 297
Actual label: 2
Output voltages: [0.7054, 0.004306, 0.7987, 0.19347, 0.021614, 0.0010739, 0.049605, 0.035159, 0.4364, 0.010924]
Predicted label: 2
Correct prediction
Energy consumption = 146.813969 pJ
sum error= 297
Actual label: 3
Output voltages: [0.54379, 0.032213, 0.056108, 0.79872, 0.0039123, 0.007246, 0.013509, 0.018845, 0.54461, 0.01204]
Predicted label: 3
Correct prediction
Energy consumption = 141.129318 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0058783, 0.0040383, 0.24901, 0.0089171, 0.79874, 0.0023745, 0.15454, 0.041813, 0.12583, 0.020021]
Predicted label: 4
Correct prediction
Energy consumption = 153.817840 pJ
sum error= 297
Actual label: 5
Output voltages: [0.025399, 0.0071456, 0.0018421, 0.10851, 0.035493, 0.79866, 0.29526, 0.040799, 0.66073, 0.033785]
Predicted label: 5
Correct prediction
Energy consumption = 151.281036 pJ
sum error= 297
Actual label: 6
Output voltages: [0.13119, 0.10953, 0.35834, 0.001203, 0.24332, 0.1534, 0.79871, 0.0018432, 0.46069, 0.0049854]
Predicted label: 6
Correct prediction
Energy consumption = 147.808464 pJ
sum error= 297
Actual label: 7
Output voltages: [0.45621, 0.018753, 0.013876, 0.01763, 0.011114, 0.030314, 0.0016998, 0.79847, 0.35478, 0.046439]
Predicted label: 7
Correct prediction
Energy consumption = 158.115898 pJ
sum error= 297
Actual label: 8
Output voltages: [0.12059, 0.024821, 0.44829, 0.080992, 0.022117, 0.004168, 0.14985, 0.0032298, 0.79878, 0.10372]
Predicted label: 8
Correct prediction
Energy consumption = 151.194995 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79853, 0.028391, 0.022586, 0.0059095, 0.11132, 0.011729, 0.7621, 0.011526, 0.03529, 0.019469]
Predicted label: 0
Correct prediction
Energy consumption = 154.433004 pJ
sum error= 297
Actual label: 1
Output voltages: [0.0080428, 0.79858, 0.22587, 0.037905, 0.21421, 0.0010944, 0.38736, 0.015918, 0.16693, 0.063088]
Predicted label: 1
Correct prediction
Energy consumption = 162.498228 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 633 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 633 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 633 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.63225, 0.020731, 0.79874, 0.21607, 0.025018, 0.0011497, 0.074078, 0.071387, 0.38795, 0.026187]
Predicted label: 2
Correct prediction
Energy consumption = 144.576884 pJ
sum error= 297
Actual label: 3
Output voltages: [0.75556, 0.0037909, 0.16097, 0.79876, 0.010556, 0.021178, 0.0041075, 0.032542, 0.21134, 0.0028687]
Predicted label: 3
Correct prediction
Energy consumption = 142.879310 pJ
sum error= 297
Actual label: 4
Output voltages: [0.0091344, 0.0029964, 0.16799, 0.002146, 0.79867, 0.0011708, 0.086433, 0.019678, 0.066119, 0.036523]
Predicted label: 4
Correct prediction
Energy consumption = 151.128999 pJ
sum error= 297
Actual label: 5
Output voltages: [0.10612, 0.0014536, 0.0013913, 0.26015, 0.047303, 0.79867, 0.034563, 0.027233, 0.66865, 0.10417]
Predicted label: 5
Correct prediction
Energy consumption = 149.936793 pJ
sum error= 297
Actual label: 6
Output voltages: [0.17374, 0.025577, 0.28101, 0.001118, 0.32826, 0.090779, 0.79879, 0.001512, 0.55271, 0.0052369]
Predicted label: 6
Correct prediction
Energy consumption = 144.219248 pJ
sum error= 297
Actual label: 7
Output voltages: [0.20545, 0.047345, 0.038067, 0.15398, 0.03196, 0.0027194, 0.0010946, 0.79858, 0.19356, 0.28526]
Predicted label: 7
Correct prediction
Energy consumption = 157.085204 pJ
sum error= 297
Actual label: 8
Output voltages: [0.038842, 0.041544, 0.55095, 0.030453, 0.031142, 0.0042894, 0.02342, 0.012653, 0.79879, 0.17961]
Predicted label: 8
Correct prediction
Energy consumption = 148.510909 pJ
sum error= 297
Actual label: 2
Output voltages: [0.51747, 0.017867, 0.79877, 0.078099, 0.021522, 0.0013712, 0.035583, 0.049256, 0.50777, 0.0063273]
Predicted label: 2
Correct prediction
Energy consumption = 141.249649 pJ
sum error= 297
Actual label: 1
Output voltages: [0.046057, 0.79879, 0.0046073, 0.27387, 0.23919, 0.0074615, 0.01029, 0.0016294, 0.77999, 0.21032]
Predicted label: 1
Correct prediction
Energy consumption = 168.552236 pJ
sum error= 297
Actual label: 7
Output voltages: [0.060715, 0.017598, 0.0096491, 0.18979, 0.03286, 0.014879, 0.001066, 0.79877, 0.1626, 0.56811]
Predicted label: 7
Correct prediction
Energy consumption = 155.973103 pJ
sum error= 297
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 634 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 634 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 634 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.49857, 0.0061275, 0.79879, 0.07008, 0.061381, 0.0020734, 0.095159, 0.063389, 0.29038, 0.0045391]
Predicted label: 2
Correct prediction
Energy consumption = 151.591665 pJ
sum error= 297
Actual label: 5
Output voltages: [0.036764, 0.0010959, 0.0074974, 0.30012, 0.055667, 0.79873, 0.12421, 0.24408, 0.7702, 0.043693]
Predicted label: 5
Correct prediction
Energy consumption = 142.586574 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79879, 0.18501, 0.047004, 0.032629, 0.018283, 0.0028601, 0.58365, 0.003507, 0.19703, 0.029776]
Predicted label: 0
Correct prediction
Energy consumption = 154.001553 pJ
sum error= 297
Actual label: 8
Output voltages: [0.051402, 0.039507, 0.39354, 0.036006, 0.047315, 0.0085054, 0.039635, 0.0052083, 0.79874, 0.20805]
Predicted label: 8
Correct prediction
Energy consumption = 150.897016 pJ
sum error= 297
Actual label: 0
Output voltages: [0.79833, 0.034793, 0.029559, 0.013737, 0.0094691, 0.0033996, 0.74938, 0.042327, 0.2061, 0.15627]
Predicted label: 0
Correct prediction
Energy consumption = 147.518484 pJ
sum error= 297
Actual label: 2
Output voltages: [0.42265, 0.030856, 0.79866, 0.021086, 0.017251, 0.0011612, 0.16375, 0.011485, 0.29084, 0.017088]
Predicted label: 2
Correct prediction
Energy consumption = 137.954957 pJ
sum error= 297
Actual label: 7
Output voltages: [0.12964, 0.011305, 0.019007, 0.33783, 0.012605, 0.007989, 0.0010814, 0.79869, 0.25973, 0.56768]
Predicted label: 7
Correct prediction
Energy consumption = 154.299695 pJ
sum error= 297
Actual label: 8
Output voltages: [0.36893, 0.01548, 0.048425, 0.73424, 0.0011047, 0.0013015, 0.49695, 0.0010749, 0.72958, 0.047234]
Predicted label: 3
Wrong prediction!
Energy consumption = 160.211455 pJ
sum error= 298
Actual label: 8
Output voltages: [0.054751, 0.015002, 0.60191, 0.016056, 0.020995, 0.011323, 0.035809, 0.0077971, 0.79877, 0.13434]
Predicted label: 8
Correct prediction
Energy consumption = 149.174891 pJ
sum error= 298
Actual label: 3
Output voltages: [0.41606, 0.014242, 0.16034, 0.79872, 0.023138, 0.0018333, 0.021316, 0.0035952, 0.46787, 0.041455]
Predicted label: 3
Correct prediction
Energy consumption = 143.689190 pJ
sum error= 298
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 635 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 635 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 635 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.046966, 0.085234, 0.28595, 0.0042841, 0.21778, 0.19159, 0.79871, 0.0021646, 0.62189, 0.0045108]
Predicted label: 6
Correct prediction
Energy consumption = 148.136611 pJ
sum error= 298
Actual label: 0
Output voltages: [0.79879, 0.068536, 0.090869, 0.016971, 0.014648, 0.0023216, 0.63693, 0.015531, 0.19116, 0.17264]
Predicted label: 0
Correct prediction
Energy consumption = 145.870425 pJ
sum error= 298
Actual label: 2
Output voltages: [0.71577, 0.019289, 0.79879, 0.33258, 0.013303, 0.0025633, 0.093054, 0.019227, 0.33517, 0.041067]
Predicted label: 2
Correct prediction
Energy consumption = 140.715253 pJ
sum error= 298
Actual label: 7
Output voltages: [0.31328, 0.014121, 0.0045445, 0.031919, 0.17869, 0.060673, 0.0011075, 0.7987, 0.018191, 0.3952]
Predicted label: 7
Correct prediction
Energy consumption = 160.745794 pJ
sum error= 298
Actual label: 6
Output voltages: [0.1352, 0.068951, 0.13342, 0.0066899, 0.34937, 0.19772, 0.79871, 0.0040876, 0.4842, 0.010456]
Predicted label: 6
Correct prediction
Energy consumption = 151.979318 pJ
sum error= 298
Actual label: 6
Output voltages: [0.062726, 0.050202, 0.24502, 0.0028713, 0.2731, 0.26991, 0.79872, 0.0015369, 0.62092, 0.0048984]
Predicted label: 6
Correct prediction
Energy consumption = 132.152345 pJ
sum error= 298
Actual label: 1
Output voltages: [0.061653, 0.79879, 0.10769, 0.047217, 0.042314, 0.0010845, 0.15584, 0.005999, 0.54615, 0.09905]
Predicted label: 1
Correct prediction
Energy consumption = 162.138433 pJ
sum error= 298
Actual label: 2
Output voltages: [0.54422, 0.0055699, 0.79875, 0.14541, 0.02495, 0.0012073, 0.051123, 0.053757, 0.53703, 0.0080871]
Predicted label: 2
Correct prediction
Energy consumption = 146.261293 pJ
sum error= 298
Actual label: 8
Output voltages: [0.027995, 0.057121, 0.036976, 0.51348, 0.0010821, 0.13575, 0.0151, 0.0052126, 0.79879, 0.23045]
Predicted label: 8
Correct prediction
Energy consumption = 150.379388 pJ
sum error= 298
Actual label: 8
Output voltages: [0.055199, 0.0097444, 0.66488, 0.10389, 0.0067303, 0.001066, 0.031142, 0.0014095, 0.79803, 0.35216]
Predicted label: 8
Correct prediction
Energy consumption = 144.995989 pJ
sum error= 298
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 636 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 636 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 636 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.28423, 0.043647, 0.0074472, 0.57585, 0.0066813, 0.017289, 0.0011323, 0.79869, 0.025996, 0.43003]
Predicted label: 7
Correct prediction
Energy consumption = 153.213089 pJ
sum error= 298
Actual label: 7
Output voltages: [0.03056, 0.19627, 0.087417, 0.12963, 0.0040434, 0.0013673, 0.0010661, 0.79851, 0.20633, 0.037847]
Predicted label: 7
Correct prediction
Energy consumption = 146.744150 pJ
sum error= 298
Actual label: 4
Output voltages: [0.015378, 0.016178, 0.034482, 0.0071414, 0.79864, 0.0010715, 0.18635, 0.05115, 0.023509, 0.010142]
Predicted label: 4
Correct prediction
Energy consumption = 154.265621 pJ
sum error= 298
Actual label: 7
Output voltages: [0.37446, 0.0058429, 0.016333, 0.036134, 0.11964, 0.038518, 0.0012685, 0.79852, 0.089216, 0.29331]
Predicted label: 7
Correct prediction
Energy consumption = 153.093003 pJ
sum error= 298
Actual label: 7
Output voltages: [0.22975, 0.043598, 0.01231, 0.43914, 0.0047086, 0.0017249, 0.0010708, 0.79872, 0.064688, 0.58319]
Predicted label: 7
Correct prediction
Energy consumption = 138.132487 pJ
sum error= 298
Actual label: 3
Output voltages: [0.50069, 0.0071705, 0.22458, 0.79872, 0.033071, 0.01625, 0.020894, 0.013392, 0.56977, 0.042077]
Predicted label: 3
Correct prediction
Energy consumption = 135.857436 pJ
sum error= 298
Actual label: 7
Output voltages: [0.21445, 0.0065819, 0.007619, 0.03029, 0.0239, 0.017585, 0.0010714, 0.79858, 0.52246, 0.19704]
Predicted label: 7
Correct prediction
Energy consumption = 147.377918 pJ
sum error= 298
Actual label: 4
Output voltages: [0.0026916, 0.0028536, 0.081239, 0.02081, 0.79869, 0.0011017, 0.21164, 0.1018, 0.033001, 0.021942]
Predicted label: 4
Correct prediction
Energy consumption = 151.920641 pJ
sum error= 298
Actual label: 5
Output voltages: [0.11714, 0.0014587, 0.0011967, 0.38938, 0.013463, 0.79875, 0.23716, 0.014357, 0.66167, 0.038579]
Predicted label: 5
Correct prediction
Energy consumption = 150.893501 pJ
sum error= 298
Actual label: 4
Output voltages: [0.0018545, 0.019562, 0.048719, 0.021004, 0.79879, 0.0010778, 0.05714, 0.10985, 0.022337, 0.021301]
Predicted label: 4
Correct prediction
Energy consumption = 157.060628 pJ
sum error= 298
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 637 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 637 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 637 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.4381, 0.022394, 0.28171, 0.79879, 0.0053562, 0.001187, 0.01967, 0.0012674, 0.30498, 0.024495]
Predicted label: 3
Correct prediction
Energy consumption = 148.649514 pJ
sum error= 298
Actual label: 3
Output voltages: [0.1354, 0.013511, 0.03662, 0.79873, 0.014278, 0.0047783, 0.0040944, 0.016552, 0.73056, 0.054546]
Predicted label: 3
Correct prediction
Energy consumption = 130.658887 pJ
sum error= 298
Actual label: 8
Output voltages: [0.056662, 0.043453, 0.22478, 0.4045, 0.010547, 0.0039108, 0.19893, 0.0047966, 0.79873, 0.23773]
Predicted label: 8
Correct prediction
Energy consumption = 147.152973 pJ
sum error= 298
Actual label: 4
Output voltages: [0.0015426, 0.031346, 0.08188, 0.014281, 0.79852, 0.014071, 0.3779, 0.33374, 0.022885, 0.035273]
Predicted label: 4
Correct prediction
Energy consumption = 152.739669 pJ
sum error= 298
Actual label: 1
Output voltages: [0.027999, 0.79854, 0.060309, 0.50903, 0.23735, 0.0042278, 0.5042, 0.0018986, 0.22559, 0.16162]
Predicted label: 1
Correct prediction
Energy consumption = 162.568983 pJ
sum error= 298
Actual label: 1
Output voltages: [0.037808, 0.79835, 0.068986, 0.15981, 0.013513, 0.0081774, 0.74385, 0.0048319, 0.058855, 0.059931]
Predicted label: 1
Correct prediction
Energy consumption = 149.553158 pJ
sum error= 298
Actual label: 9
Output voltages: [0.39521, 0.02349, 0.0059053, 0.029634, 0.048306, 0.01061, 0.0012617, 0.0077219, 0.38472, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 155.563332 pJ
sum error= 298
Actual label: 7
Output voltages: [0.092457, 0.028156, 0.031339, 0.032596, 0.034699, 0.0041096, 0.0010681, 0.79857, 0.043036, 0.28861]
Predicted label: 7
Correct prediction
Energy consumption = 152.548701 pJ
sum error= 298
Actual label: 4
Output voltages: [0.0021714, 0.020044, 0.04097, 0.0018327, 0.79846, 0.008686, 0.046267, 0.31243, 0.21202, 0.053301]
Predicted label: 4
Correct prediction
Energy consumption = 154.040059 pJ
sum error= 298
Actual label: 3
Output voltages: [0.098595, 0.027349, 0.16632, 0.79879, 0.0037055, 0.0011094, 0.0081924, 0.0035482, 0.51068, 0.21679]
Predicted label: 3
Correct prediction
Energy consumption = 149.975941 pJ
sum error= 298
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 638 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 638 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 638 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.35763, 0.034048, 0.022943, 0.22375, 0.020743, 0.030164, 0.0010723, 0.79859, 0.20388, 0.47626]
Predicted label: 7
Correct prediction
Energy consumption = 155.898232 pJ
sum error= 298
Actual label: 3
Output voltages: [0.18869, 0.034178, 0.29025, 0.79878, 0.019266, 0.0015946, 0.020965, 0.0021196, 0.63255, 0.10112]
Predicted label: 3
Correct prediction
Energy consumption = 146.617215 pJ
sum error= 298
Actual label: 3
Output voltages: [0.3004, 0.028295, 0.023048, 0.79863, 0.012261, 0.0026014, 0.014962, 0.013516, 0.48993, 0.031959]
Predicted label: 3
Correct prediction
Energy consumption = 130.247098 pJ
sum error= 298
Actual label: 0
Output voltages: [0.79878, 0.0085661, 0.022706, 0.11735, 0.39096, 0.0035655, 0.50429, 0.028398, 0.42576, 0.027201]
Predicted label: 0
Correct prediction
Energy consumption = 157.139986 pJ
sum error= 298
Actual label: 2
Output voltages: [0.53079, 0.16229, 0.79869, 0.047028, 0.010463, 0.001135, 0.12413, 0.022399, 0.3047, 0.023632]
Predicted label: 2
Correct prediction
Energy consumption = 143.002623 pJ
sum error= 298
Actual label: 5
Output voltages: [0.26327, 0.0010674, 0.002958, 0.39547, 0.009586, 0.79878, 0.59775, 0.063005, 0.65304, 0.0093761]
Predicted label: 5
Correct prediction
Energy consumption = 144.495057 pJ
sum error= 298
Actual label: 5
Output voltages: [0.017574, 0.0011429, 0.0010741, 0.095581, 0.038974, 0.77791, 0.18769, 0.019948, 0.78522, 0.027442]
Predicted label: 8
Wrong prediction!
Energy consumption = 128.349650 pJ
sum error= 299
Actual label: 6
Output voltages: [0.0798, 0.086954, 0.3466, 0.0047741, 0.38545, 0.29071, 0.79872, 0.0019317, 0.516, 0.016054]
Predicted label: 6
Correct prediction
Energy consumption = 142.763434 pJ
sum error= 299
Actual label: 6
Output voltages: [0.22922, 0.037831, 0.13656, 0.0010673, 0.32827, 0.23519, 0.79874, 0.0046038, 0.45031, 0.0072917]
Predicted label: 6
Correct prediction
Energy consumption = 132.075029 pJ
sum error= 299
Actual label: 3
Output voltages: [0.20326, 0.0020026, 0.14091, 0.79879, 0.034244, 0.037811, 0.012134, 0.015328, 0.53056, 0.11843]
Predicted label: 3
Correct prediction
Energy consumption = 144.879788 pJ
sum error= 299
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 639 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 639 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 639 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.24074, 0.0011426, 0.0054446, 0.081673, 0.0074333, 0.79864, 0.24126, 0.021888, 0.77847, 0.015622]
Predicted label: 5
Correct prediction
Energy consumption = 143.221769 pJ
sum error= 299
Actual label: 2
Output voltages: [0.75186, 0.031295, 0.79865, 0.47164, 0.0066317, 0.0010851, 0.036048, 0.04812, 0.55401, 0.0081222]
Predicted label: 2
Correct prediction
Energy consumption = 144.252265 pJ
sum error= 299
Actual label: 5
Output voltages: [0.28372, 0.0010715, 0.013376, 0.19109, 0.092448, 0.7902, 0.50623, 0.0023331, 0.78917, 0.0045447]
Predicted label: 5
Correct prediction
Energy consumption = 141.335260 pJ
sum error= 299
Actual label: 9
Output voltages: [0.52064, 0.017209, 0.0079186, 0.025293, 0.76777, 0.037171, 0.035626, 0.01498, 0.19107, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 152.482730 pJ
sum error= 299
Actual label: 9
Output voltages: [0.42816, 0.012546, 0.022543, 0.025528, 0.08323, 0.015527, 0.011707, 0.028221, 0.38991, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 146.150043 pJ
sum error= 299
Actual label: 8
Output voltages: [0.023371, 0.029718, 0.24274, 0.036027, 0.022915, 0.027696, 0.034719, 0.0085307, 0.79867, 0.061411]
Predicted label: 8
Correct prediction
Energy consumption = 149.033157 pJ
sum error= 299
Actual label: 4
Output voltages: [0.0025098, 0.011614, 0.049528, 0.022166, 0.79871, 0.0015465, 0.033955, 0.101, 0.086256, 0.013275]
Predicted label: 4
Correct prediction
Energy consumption = 145.017795 pJ
sum error= 299
Actual label: 1
Output voltages: [0.026484, 0.79879, 0.10307, 0.67919, 0.32805, 0.0010689, 0.020006, 0.029704, 0.092798, 0.19605]
Predicted label: 1
Correct prediction
Energy consumption = 166.460358 pJ
sum error= 299
Actual label: 0
Output voltages: [0.79869, 0.10262, 0.034473, 0.025802, 0.022654, 0.024885, 0.069238, 0.01421, 0.34487, 0.045128]
Predicted label: 0
Correct prediction
Energy consumption = 159.335845 pJ
sum error= 299
Actual label: 6
Output voltages: [0.19915, 0.1011, 0.27244, 0.0070753, 0.37812, 0.22123, 0.79872, 0.0022227, 0.31691, 0.023822]
Predicted label: 6
Correct prediction
Energy consumption = 145.981384 pJ
sum error= 299
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 640 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 640 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 640 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7832, 0.085232, 0.078582, 0.0078715, 0.036021, 0.0022171, 0.7547, 0.019173, 0.27542, 0.010762]
Predicted label: 0
Correct prediction
Energy consumption = 157.226500 pJ
sum error= 299
Actual label: 9
Output voltages: [0.2323, 0.024735, 0.012613, 0.090853, 0.13636, 0.0069761, 0.010687, 0.012022, 0.13882, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 156.803538 pJ
sum error= 299
Actual label: 6
Output voltages: [0.052889, 0.14815, 0.13484, 0.0017541, 0.61818, 0.060776, 0.79875, 0.0020825, 0.042131, 0.0028914]
Predicted label: 6
Correct prediction
Energy consumption = 155.954563 pJ
sum error= 299
Actual label: 8
Output voltages: [0.10157, 0.052354, 0.76203, 0.12144, 0.0095987, 0.014398, 0.1395, 0.0082187, 0.79879, 0.10474]
Predicted label: 8
Correct prediction
Energy consumption = 149.859033 pJ
sum error= 299
Actual label: 8
Output voltages: [0.057804, 0.01723, 0.54719, 0.20499, 0.044771, 0.002198, 0.084267, 0.0054272, 0.79875, 0.054378]
Predicted label: 8
Correct prediction
Energy consumption = 138.007789 pJ
sum error= 299
Actual label: 5
Output voltages: [0.014122, 0.0010967, 0.0019618, 0.37251, 0.039304, 0.79833, 0.40585, 0.014528, 0.76647, 0.027737]
Predicted label: 5
Correct prediction
Energy consumption = 142.253081 pJ
sum error= 299
Actual label: 6
Output voltages: [0.075703, 0.22982, 0.41158, 0.0012228, 0.22376, 0.027329, 0.7987, 0.0011256, 0.42109, 0.011409]
Predicted label: 6
Correct prediction
Energy consumption = 138.621127 pJ
sum error= 299
Actual label: 1
Output voltages: [0.01178, 0.79854, 0.35605, 0.34036, 0.019476, 0.001096, 0.73075, 0.0099305, 0.087615, 0.018649]
Predicted label: 1
Correct prediction
Energy consumption = 162.299335 pJ
sum error= 299
Actual label: 1
Output voltages: [0.010238, 0.7986, 0.012102, 0.28145, 0.30762, 0.0027626, 0.023831, 0.0024177, 0.17979, 0.16923]
Predicted label: 1
Correct prediction
Energy consumption = 156.218605 pJ
sum error= 299
Actual label: 9
Output voltages: [0.48272, 0.0023624, 0.060099, 0.0479, 0.57635, 0.032603, 0.12923, 0.01399, 0.022495, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 159.944561 pJ
sum error= 299
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 641 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 641 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 641 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18831, 0.017966, 0.20516, 0.27114, 0.0022894, 0.017557, 0.51471, 0.0013199, 0.79552, 0.052705]
Predicted label: 8
Correct prediction
Energy consumption = 154.155443 pJ
sum error= 299
Actual label: 9
Output voltages: [0.012975, 0.0060624, 0.053308, 0.15493, 0.2173, 0.0015652, 0.010147, 0.019322, 0.61571, 0.79539]
Predicted label: 9
Correct prediction
Energy consumption = 157.629355 pJ
sum error= 299
Actual label: 2
Output voltages: [0.78088, 0.048959, 0.79878, 0.20302, 0.0016612, 0.0010716, 0.070271, 0.027637, 0.30346, 0.016718]
Predicted label: 2
Correct prediction
Energy consumption = 147.633201 pJ
sum error= 299
Actual label: 3
Output voltages: [0.51319, 0.01923, 0.037031, 0.79869, 0.0092325, 0.0095982, 0.020845, 0.005553, 0.3616, 0.03858]
Predicted label: 3
Correct prediction
Energy consumption = 145.615466 pJ
sum error= 299
Actual label: 5
Output voltages: [0.021428, 0.0010825, 0.0019767, 0.42018, 0.028968, 0.79613, 0.091864, 0.018848, 0.78086, 0.026776]
Predicted label: 5
Correct prediction
Energy consumption = 138.792910 pJ
sum error= 299
Actual label: 5
Output voltages: [0.0056016, 0.0010801, 0.011385, 0.1741, 0.011444, 0.79662, 0.052343, 0.0046282, 0.78273, 0.021735]
Predicted label: 5
Correct prediction
Energy consumption = 131.258564 pJ
sum error= 299
Actual label: 9
Output voltages: [0.74844, 0.0011129, 0.040742, 0.041892, 0.07596, 0.0084445, 0.011741, 0.086195, 0.099713, 0.79506]
Predicted label: 9
Correct prediction
Energy consumption = 149.329287 pJ
sum error= 299
Actual label: 4
Output voltages: [0.0012371, 0.025863, 0.0049471, 0.011789, 0.79841, 0.0038449, 0.43539, 0.028451, 0.25735, 0.0098302]
Predicted label: 4
Correct prediction
Energy consumption = 154.938345 pJ
sum error= 299
Actual label: 2
Output voltages: [0.2051, 0.035058, 0.79831, 0.75409, 0.029871, 0.001066, 0.012811, 0.027897, 0.22112, 0.0081837]
Predicted label: 2
Correct prediction
Energy consumption = 132.298710 pJ
sum error= 299
Actual label: 1
Output voltages: [0.0036297, 0.79859, 0.45528, 0.28354, 0.09299, 0.0010765, 0.27945, 0.002792, 0.027518, 0.30132]
Predicted label: 1
Correct prediction
Energy consumption = 161.874389 pJ
sum error= 299
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 642 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 642 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 642 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.046461, 0.023086, 0.0099811, 0.20668, 0.78055, 0.044148, 0.016104, 0.0025317, 0.18373, 0.76829]
Predicted label: 4
Wrong prediction!
Energy consumption = 156.882014 pJ
sum error= 300
Actual label: 3
Output voltages: [0.25344, 0.015195, 0.50486, 0.79849, 0.015896, 0.0010956, 0.083751, 0.0012197, 0.68426, 0.070176]
Predicted label: 3
Correct prediction
Energy consumption = 155.580385 pJ
sum error= 300
Actual label: 9
Output voltages: [0.45197, 0.0012007, 0.027344, 0.010721, 0.068089, 0.031833, 0.015511, 0.53881, 0.42259, 0.77897]
Predicted label: 9
Correct prediction
Energy consumption = 156.866203 pJ
sum error= 300
Actual label: 2
Output voltages: [0.50591, 0.049775, 0.79875, 0.12413, 0.021842, 0.0010681, 0.3506, 0.032928, 0.22419, 0.015239]
Predicted label: 2
Correct prediction
Energy consumption = 144.647297 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79833, 0.047624, 0.052913, 0.012039, 0.010553, 0.0012524, 0.75031, 0.021037, 0.31213, 0.072509]
Predicted label: 0
Correct prediction
Energy consumption = 145.867432 pJ
sum error= 300
Actual label: 6
Output voltages: [0.34156, 0.35588, 0.27259, 0.0015941, 0.079071, 0.019463, 0.79858, 0.0010767, 0.54881, 0.03392]
Predicted label: 6
Correct prediction
Energy consumption = 144.371946 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.026065, 0.03185, 0.0048723, 0.029259, 0.012386, 0.77389, 0.02102, 0.10416, 0.26992]
Predicted label: 0
Correct prediction
Energy consumption = 150.652785 pJ
sum error= 300
Actual label: 4
Output voltages: [0.0092545, 0.0080641, 0.029145, 0.010474, 0.79871, 0.0029676, 0.048096, 0.26056, 0.07433, 0.0056979]
Predicted label: 4
Correct prediction
Energy consumption = 151.445953 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.046964, 0.16511, 0.010374, 0.010085, 0.0014333, 0.63646, 0.011936, 0.18969, 0.05691]
Predicted label: 0
Correct prediction
Energy consumption = 154.411142 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79878, 0.066533, 0.64962, 0.063377, 0.014572, 0.010974, 0.33119, 0.021922, 0.14017, 0.0082012]
Predicted label: 0
Correct prediction
Energy consumption = 142.944791 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 643 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 643 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 643 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.041264, 0.79874, 0.070793, 0.15246, 0.068322, 0.0010661, 0.71163, 0.0039485, 0.079838, 0.04551]
Predicted label: 1
Correct prediction
Energy consumption = 159.285208 pJ
sum error= 300
Actual label: 2
Output voltages: [0.21736, 0.023065, 0.7987, 0.034183, 0.019245, 0.0011114, 0.20602, 0.036227, 0.5536, 0.009012]
Predicted label: 2
Correct prediction
Energy consumption = 146.225862 pJ
sum error= 300
Actual label: 3
Output voltages: [0.052656, 0.02347, 0.21324, 0.79879, 0.0094837, 0.0012728, 0.0068212, 0.0037413, 0.65919, 0.041797]
Predicted label: 3
Correct prediction
Energy consumption = 138.740416 pJ
sum error= 300
Actual label: 4
Output voltages: [0.0059751, 0.012183, 0.040032, 0.1176, 0.79879, 0.0010683, 0.047236, 0.052256, 0.030857, 0.0099942]
Predicted label: 4
Correct prediction
Energy consumption = 149.682353 pJ
sum error= 300
Actual label: 7
Output voltages: [0.028516, 0.031214, 0.018167, 0.0093321, 0.50052, 0.0010925, 0.0011466, 0.79814, 0.25899, 0.13287]
Predicted label: 7
Correct prediction
Energy consumption = 149.194060 pJ
sum error= 300
Actual label: 8
Output voltages: [0.041932, 0.043429, 0.49404, 0.014183, 0.036874, 0.0076266, 0.013806, 0.014486, 0.79875, 0.16452]
Predicted label: 8
Correct prediction
Energy consumption = 142.104222 pJ
sum error= 300
Actual label: 9
Output voltages: [0.42713, 0.039763, 0.0079969, 0.25822, 0.48629, 0.0040961, 0.0033452, 0.0037049, 0.070129, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.559143 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79874, 0.22864, 0.086585, 0.028287, 0.026404, 0.02224, 0.20428, 0.027786, 0.10993, 0.060168]
Predicted label: 0
Correct prediction
Energy consumption = 148.399630 pJ
sum error= 300
Actual label: 1
Output voltages: [0.081658, 0.79864, 0.047541, 0.020762, 0.14847, 0.0082689, 0.39618, 0.0040761, 0.029787, 0.008448]
Predicted label: 1
Correct prediction
Energy consumption = 152.095559 pJ
sum error= 300
Actual label: 2
Output voltages: [0.19316, 0.11774, 0.79878, 0.020439, 0.04423, 0.0010988, 0.13382, 0.019642, 0.61433, 0.051933]
Predicted label: 2
Correct prediction
Energy consumption = 143.365024 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 644 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 644 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 644 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.17612, 0.022737, 0.033833, 0.7987, 0.010197, 0.0063232, 0.0094331, 0.0038927, 0.52924, 0.042612]
Predicted label: 3
Correct prediction
Energy consumption = 145.109505 pJ
sum error= 300
Actual label: 7
Output voltages: [0.20655, 0.0095969, 0.0059335, 0.010328, 0.5358, 0.0015972, 0.0011342, 0.79867, 0.37301, 0.10163]
Predicted label: 7
Correct prediction
Energy consumption = 149.397474 pJ
sum error= 300
Actual label: 8
Output voltages: [0.019254, 0.11146, 0.39342, 0.045067, 0.0024709, 0.03039, 0.014511, 0.083482, 0.79869, 0.048599]
Predicted label: 8
Correct prediction
Energy consumption = 141.260640 pJ
sum error= 300
Actual label: 9
Output voltages: [0.3722, 0.03664, 0.025748, 0.13319, 0.39108, 0.011815, 0.023369, 0.007265, 0.073655, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 154.273465 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79878, 0.019901, 0.038889, 0.012761, 0.012508, 0.0028093, 0.41647, 0.035467, 0.32632, 0.044001]
Predicted label: 0
Correct prediction
Energy consumption = 150.973654 pJ
sum error= 300
Actual label: 1
Output voltages: [0.044685, 0.79751, 0.1908, 0.001066, 0.70525, 0.0039379, 0.34351, 0.0010779, 0.32182, 0.35992]
Predicted label: 1
Correct prediction
Energy consumption = 156.804274 pJ
sum error= 300
Actual label: 2
Output voltages: [0.03149, 0.039483, 0.79878, 0.1409, 0.015782, 0.0011611, 0.26744, 0.020306, 0.67397, 0.030768]
Predicted label: 2
Correct prediction
Energy consumption = 142.033070 pJ
sum error= 300
Actual label: 3
Output voltages: [0.096012, 0.0015366, 0.050418, 0.79875, 0.067662, 0.082031, 0.011519, 0.0023534, 0.41983, 0.048225]
Predicted label: 3
Correct prediction
Energy consumption = 145.229476 pJ
sum error= 300
Actual label: 4
Output voltages: [0.016445, 0.0034772, 0.14376, 0.01913, 0.79867, 0.0011707, 0.015034, 0.055436, 0.046137, 0.024203]
Predicted label: 4
Correct prediction
Energy consumption = 151.882790 pJ
sum error= 300
Actual label: 7
Output voltages: [0.054331, 0.054366, 0.025874, 0.098264, 0.029288, 0.0083059, 0.0011155, 0.79864, 0.086021, 0.33305]
Predicted label: 7
Correct prediction
Energy consumption = 145.875314 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 645 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 645 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 645 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.096753, 0.0067169, 0.1545, 0.05037, 0.033793, 0.081406, 0.0072885, 0.012797, 0.79867, 0.0090577]
Predicted label: 8
Correct prediction
Energy consumption = 149.532217 pJ
sum error= 300
Actual label: 9
Output voltages: [0.14445, 0.023371, 0.042529, 0.033733, 0.065638, 0.030056, 0.0098306, 0.042848, 0.3538, 0.79717]
Predicted label: 9
Correct prediction
Energy consumption = 149.068445 pJ
sum error= 300
Actual label: 7
Output voltages: [0.1667, 0.0021482, 0.016514, 0.26008, 0.029228, 0.020358, 0.0011596, 0.7987, 0.58076, 0.029757]
Predicted label: 7
Correct prediction
Energy consumption = 148.119451 pJ
sum error= 300
Actual label: 3
Output voltages: [0.20507, 0.01462, 0.14243, 0.79872, 0.070163, 0.10381, 0.02515, 0.022722, 0.73746, 0.27783]
Predicted label: 3
Correct prediction
Energy consumption = 144.693906 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.037254, 0.18133, 0.0091935, 0.0224, 0.0035549, 0.32717, 0.0052481, 0.31226, 0.079513]
Predicted label: 0
Correct prediction
Energy consumption = 148.727294 pJ
sum error= 300
Actual label: 3
Output voltages: [0.56175, 0.0023277, 0.21065, 0.79872, 0.10734, 0.044471, 0.0036158, 0.0022708, 0.62529, 0.022447]
Predicted label: 3
Correct prediction
Energy consumption = 146.782304 pJ
sum error= 300
Actual label: 1
Output voltages: [0.061209, 0.7987, 0.033849, 0.025526, 0.070059, 0.0011521, 0.48874, 0.005609, 0.089969, 0.030238]
Predicted label: 1
Correct prediction
Energy consumption = 159.168427 pJ
sum error= 300
Actual label: 8
Output voltages: [0.043684, 0.036848, 0.55045, 0.027798, 0.0062192, 0.0096565, 0.032077, 0.032947, 0.7987, 0.031664]
Predicted label: 8
Correct prediction
Energy consumption = 146.420935 pJ
sum error= 300
Actual label: 7
Output voltages: [0.20601, 0.29305, 0.028808, 0.28861, 0.17828, 0.0012057, 0.0012092, 0.79821, 0.20338, 0.25602]
Predicted label: 7
Correct prediction
Energy consumption = 150.620310 pJ
sum error= 300
Actual label: 6
Output voltages: [0.21588, 0.0060039, 0.23062, 0.0052422, 0.34768, 0.23464, 0.79879, 0.0017052, 0.555, 0.043872]
Predicted label: 6
Correct prediction
Energy consumption = 146.700600 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 646 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 646 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 646 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0082894, 0.095593, 0.38219, 0.0075313, 0.7986, 0.03101, 0.071244, 0.20922, 0.1309, 0.017621]
Predicted label: 4
Correct prediction
Energy consumption = 148.881699 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.030498, 0.022888, 0.019344, 0.060245, 0.0054145, 0.68689, 0.017201, 0.071763, 0.03399]
Predicted label: 0
Correct prediction
Energy consumption = 151.845803 pJ
sum error= 300
Actual label: 2
Output voltages: [0.38252, 0.023646, 0.79872, 0.019186, 0.012517, 0.0010811, 0.073275, 0.031276, 0.54119, 0.020032]
Predicted label: 2
Correct prediction
Energy consumption = 141.000433 pJ
sum error= 300
Actual label: 6
Output voltages: [0.060914, 0.013584, 0.069327, 0.0011865, 0.28818, 0.050587, 0.79879, 0.0010986, 0.61827, 0.0020819]
Predicted label: 6
Correct prediction
Energy consumption = 141.625335 pJ
sum error= 300
Actual label: 8
Output voltages: [0.024814, 0.084613, 0.33241, 0.01222, 0.030891, 0.0088445, 0.011218, 0.0085069, 0.79875, 0.12983]
Predicted label: 8
Correct prediction
Energy consumption = 144.291526 pJ
sum error= 300
Actual label: 3
Output voltages: [0.70433, 0.010585, 0.055335, 0.79868, 0.009599, 0.030817, 0.0066511, 0.021523, 0.32449, 0.024807]
Predicted label: 3
Correct prediction
Energy consumption = 139.541618 pJ
sum error= 300
Actual label: 2
Output voltages: [0.29692, 0.043621, 0.79867, 0.020745, 0.0048765, 0.0011645, 0.19183, 0.3719, 0.63431, 0.0014871]
Predicted label: 2
Correct prediction
Energy consumption = 141.772770 pJ
sum error= 300
Actual label: 8
Output voltages: [0.013292, 0.052134, 0.2911, 0.14818, 0.0087104, 0.049886, 0.030876, 0.025788, 0.79861, 0.041856]
Predicted label: 8
Correct prediction
Energy consumption = 142.065558 pJ
sum error= 300
Actual label: 1
Output voltages: [0.021109, 0.79879, 0.072851, 0.012131, 0.28863, 0.0010675, 0.30244, 0.0026002, 0.41011, 0.20672]
Predicted label: 1
Correct prediction
Energy consumption = 152.774875 pJ
sum error= 300
Actual label: 2
Output voltages: [0.12246, 0.29221, 0.79872, 0.027483, 0.0074156, 0.001098, 0.039426, 0.045953, 0.35221, 0.031774]
Predicted label: 2
Correct prediction
Energy consumption = 141.550638 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 647 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 647 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 647 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79848, 0.02834, 0.10213, 0.022228, 0.0094281, 0.0021632, 0.50265, 0.022753, 0.12167, 0.031118]
Predicted label: 0
Correct prediction
Energy consumption = 151.992042 pJ
sum error= 300
Actual label: 7
Output voltages: [0.071414, 0.04545, 0.030919, 0.021477, 0.53888, 0.0010686, 0.0012375, 0.79863, 0.31206, 0.018364]
Predicted label: 7
Correct prediction
Energy consumption = 150.745955 pJ
sum error= 300
Actual label: 1
Output voltages: [0.010758, 0.79879, 0.19651, 0.0050647, 0.43465, 0.0016333, 0.54299, 0.0010674, 0.0375, 0.081768]
Predicted label: 1
Correct prediction
Energy consumption = 153.035697 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.020933, 0.34764, 0.0096947, 0.041505, 0.0011359, 0.13738, 0.011336, 0.22739, 0.032098]
Predicted label: 0
Correct prediction
Energy consumption = 151.601311 pJ
sum error= 300
Actual label: 4
Output voltages: [0.0091203, 0.028239, 0.17105, 0.055981, 0.79873, 0.0013145, 0.1663, 0.15747, 0.020653, 0.010182]
Predicted label: 4
Correct prediction
Energy consumption = 143.274036 pJ
sum error= 300
Actual label: 4
Output voltages: [0.0081241, 0.0032536, 0.47785, 0.025763, 0.79864, 0.0012545, 0.14194, 0.16633, 0.008142, 0.03652]
Predicted label: 4
Correct prediction
Energy consumption = 135.902128 pJ
sum error= 300
Actual label: 5
Output voltages: [0.011114, 0.0010664, 0.0012298, 0.29412, 0.025189, 0.79848, 0.35101, 0.0035157, 0.77337, 0.010547]
Predicted label: 5
Correct prediction
Energy consumption = 142.029673 pJ
sum error= 300
Actual label: 8
Output voltages: [0.0079079, 0.043894, 0.19208, 0.022968, 0.028197, 0.016288, 0.027802, 0.0053548, 0.79878, 0.28959]
Predicted label: 8
Correct prediction
Energy consumption = 141.105678 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79879, 0.065181, 0.033279, 0.047856, 0.017122, 0.032075, 0.67446, 0.019012, 0.2548, 0.029392]
Predicted label: 0
Correct prediction
Energy consumption = 151.316438 pJ
sum error= 300
Actual label: 6
Output voltages: [0.023577, 0.056624, 0.031963, 0.020224, 0.17103, 0.18097, 0.79879, 0.0074129, 0.75537, 0.0057195]
Predicted label: 6
Correct prediction
Energy consumption = 138.836813 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 648 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 648 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 648 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.045254, 0.0058601, 0.79879, 0.11486, 0.020084, 0.0012897, 0.34277, 0.076592, 0.36482, 0.014881]
Predicted label: 2
Correct prediction
Energy consumption = 147.469337 pJ
sum error= 300
Actual label: 3
Output voltages: [0.42842, 0.017714, 0.066428, 0.79867, 0.076022, 0.03642, 0.018188, 0.031189, 0.76766, 0.041276]
Predicted label: 3
Correct prediction
Energy consumption = 142.852797 pJ
sum error= 300
Actual label: 1
Output voltages: [0.01473, 0.79857, 0.31285, 0.16365, 0.0325, 0.0010733, 0.54226, 0.0095134, 0.026634, 0.013022]
Predicted label: 1
Correct prediction
Energy consumption = 153.240296 pJ
sum error= 300
Actual label: 5
Output voltages: [0.079859, 0.0011573, 0.0011136, 0.5062, 0.106, 0.79866, 0.5406, 0.040907, 0.7366, 0.024544]
Predicted label: 5
Correct prediction
Energy consumption = 150.587231 pJ
sum error= 300
Actual label: 1
Output voltages: [0.037541, 0.79879, 0.54498, 0.041117, 0.39396, 0.0011182, 0.14259, 0.0096578, 0.2035, 0.061179]
Predicted label: 1
Correct prediction
Energy consumption = 160.812451 pJ
sum error= 300
Actual label: 8
Output voltages: [0.027541, 0.12248, 0.5523, 0.022535, 0.04775, 0.029092, 0.018235, 0.0048701, 0.79876, 0.030305]
Predicted label: 8
Correct prediction
Energy consumption = 151.723018 pJ
sum error= 300
Actual label: 5
Output voltages: [0.37674, 0.0014497, 0.0011206, 0.67486, 0.35714, 0.79861, 0.43383, 0.011794, 0.54172, 0.013103]
Predicted label: 5
Correct prediction
Energy consumption = 143.980005 pJ
sum error= 300
Actual label: 9
Output voltages: [0.383, 0.042535, 0.015841, 0.1822, 0.25747, 0.017024, 0.022304, 0.014459, 0.1008, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 150.080464 pJ
sum error= 300
Actual label: 4
Output voltages: [0.041036, 0.0051794, 0.18727, 0.029063, 0.79877, 0.0010904, 0.018683, 0.045279, 0.016981, 0.0070545]
Predicted label: 4
Correct prediction
Energy consumption = 148.268174 pJ
sum error= 300
Actual label: 0
Output voltages: [0.79875, 0.028495, 0.12852, 0.027476, 0.023676, 0.0030906, 0.19982, 0.020633, 0.10313, 0.046873]
Predicted label: 0
Correct prediction
Energy consumption = 151.574393 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 649 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 649 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 649 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.40459, 0.066035, 0.020346, 0.03226, 0.37418, 0.0011028, 0.0011883, 0.79867, 0.1576, 0.010317]
Predicted label: 7
Correct prediction
Energy consumption = 148.733340 pJ
sum error= 300
Actual label: 5
Output voltages: [0.2994, 0.00107, 0.0010987, 0.30014, 0.25801, 0.79854, 0.06593, 0.026453, 0.60822, 0.041756]
Predicted label: 5
Correct prediction
Energy consumption = 144.314025 pJ
sum error= 300
Actual label: 8
Output voltages: [0.020382, 0.13429, 0.28005, 0.012582, 0.017187, 0.0024618, 0.015688, 0.0091344, 0.79879, 0.41343]
Predicted label: 8
Correct prediction
Energy consumption = 147.618777 pJ
sum error= 300
Actual label: 8
Output voltages: [0.0096212, 0.14162, 0.21434, 0.028122, 0.019167, 0.011741, 0.090921, 0.0027178, 0.79878, 0.3593]
Predicted label: 8
Correct prediction
Energy consumption = 142.188498 pJ
sum error= 300
Actual label: 3
Output voltages: [0.2718, 0.0018625, 0.034828, 0.79871, 0.016898, 0.1195, 0.13113, 0.023437, 0.63867, 0.049416]
Predicted label: 3
Correct prediction
Energy consumption = 147.529530 pJ
sum error= 300
Actual label: 8
Output voltages: [0.042778, 0.0058655, 0.13102, 0.0083275, 0.025605, 0.0057292, 0.02595, 0.0024559, 0.79878, 0.13419]
Predicted label: 8
Correct prediction
Energy consumption = 146.568173 pJ
sum error= 300
Actual label: 9
Output voltages: [0.073366, 0.060459, 0.026372, 0.10335, 0.051292, 0.0092062, 0.0080005, 0.013263, 0.39393, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 144.169541 pJ
sum error= 300
Actual label: 2
Output voltages: [0.42216, 0.032956, 0.79873, 0.020532, 0.0053373, 0.0011147, 0.033616, 0.30978, 0.72535, 0.0016207]
Predicted label: 2
Correct prediction
Energy consumption = 148.131436 pJ
sum error= 300
Actual label: 6
Output voltages: [0.18925, 0.0094755, 0.031831, 0.0089091, 0.40883, 0.16769, 0.79878, 0.0010791, 0.63184, 0.012012]
Predicted label: 6
Correct prediction
Energy consumption = 139.970257 pJ
sum error= 300
Actual label: 2
Output voltages: [0.25529, 0.034311, 0.79877, 0.037578, 0.045952, 0.0010943, 0.13818, 0.038778, 0.61034, 0.037875]
Predicted label: 2
Correct prediction
Energy consumption = 139.901443 pJ
sum error= 300
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 650 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 650 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 650 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.018047, 0.0011576, 0.00457, 0.058566, 0.070243, 0.79875, 0.27745, 0.0068879, 0.7911, 0.0042763]
Predicted label: 5
Correct prediction
Energy consumption = 143.909972 pJ
sum error= 300
Actual label: 3
Output voltages: [0.22917, 0.0027635, 0.058403, 0.79879, 0.02594, 0.2089, 0.020026, 0.0023313, 0.64264, 0.038824]
Predicted label: 3
Correct prediction
Energy consumption = 143.933611 pJ
sum error= 300
Actual label: 1
Output voltages: [0.026134, 0.7987, 0.053497, 0.0025504, 0.65067, 0.0010718, 0.29683, 0.0010826, 0.01382, 0.44537]
Predicted label: 1
Correct prediction
Energy consumption = 157.545661 pJ
sum error= 300
Actual label: 7
Output voltages: [0.031625, 0.059907, 0.02568, 0.045108, 0.036549, 0.0067922, 0.001121, 0.79867, 0.063623, 0.1097]
Predicted label: 7
Correct prediction
Energy consumption = 150.659850 pJ
sum error= 300
Actual label: 3
Output voltages: [0.09841, 0.016839, 0.11068, 0.79871, 0.048879, 0.0029457, 0.0087151, 0.0062135, 0.46768, 0.040289]
Predicted label: 3
Correct prediction
Energy consumption = 143.004771 pJ
sum error= 300
Actual label: 9
Output voltages: [0.76357, 0.040832, 0.37477, 0.033515, 0.065028, 0.0010659, 0.52394, 0.0080087, 0.056203, 0.73409]
Predicted label: 0
Wrong prediction!
Energy consumption = 147.510607 pJ
sum error= 301
Actual label: 1
Output voltages: [0.055672, 0.79871, 0.32201, 0.031759, 0.53139, 0.0010753, 0.43079, 0.0021402, 0.014524, 0.028199]
Predicted label: 1
Correct prediction
Energy consumption = 147.290141 pJ
sum error= 301
Actual label: 9
Output voltages: [0.47579, 0.019624, 0.018221, 0.17323, 0.26948, 0.0093608, 0.04347, 0.0030576, 0.23487, 0.7941]
Predicted label: 9
Correct prediction
Energy consumption = 148.793351 pJ
sum error= 301
Actual label: 9
Output voltages: [0.23866, 0.014142, 0.012453, 0.034038, 0.045935, 0.044009, 0.0045456, 0.089296, 0.6255, 0.79748]
Predicted label: 9
Correct prediction
Energy consumption = 138.065980 pJ
sum error= 301
Actual label: 6
Output voltages: [0.17512, 0.039564, 0.30166, 0.0011307, 0.38743, 0.08366, 0.79877, 0.001169, 0.52828, 0.0042249]
Predicted label: 6
Correct prediction
Energy consumption = 145.378369 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 651 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 651 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 651 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79861, 0.0323, 0.042938, 0.010878, 0.011584, 0.013967, 0.32965, 0.025959, 0.065994, 0.048907]
Predicted label: 0
Correct prediction
Energy consumption = 147.978231 pJ
sum error= 301
Actual label: 3
Output voltages: [0.3081, 0.0011121, 0.01164, 0.79607, 0.015369, 0.73461, 0.0096776, 0.018979, 0.67813, 0.080057]
Predicted label: 3
Correct prediction
Energy consumption = 147.555542 pJ
sum error= 301
Actual label: 9
Output voltages: [0.58989, 0.0097064, 0.03169, 0.029717, 0.22994, 0.017491, 0.016045, 0.0083466, 0.34118, 0.79693]
Predicted label: 9
Correct prediction
Energy consumption = 146.246466 pJ
sum error= 301
Actual label: 2
Output voltages: [0.41811, 0.11609, 0.7987, 0.054759, 0.025166, 0.001215, 0.086396, 0.06068, 0.3865, 0.040102]
Predicted label: 2
Correct prediction
Energy consumption = 149.185304 pJ
sum error= 301
Actual label: 8
Output voltages: [0.024606, 0.10563, 0.58787, 0.0091439, 0.0096006, 0.022703, 0.041275, 0.0016933, 0.79875, 0.12977]
Predicted label: 8
Correct prediction
Energy consumption = 141.573560 pJ
sum error= 301
Actual label: 1
Output voltages: [0.083661, 0.79879, 0.58216, 0.0014281, 0.47556, 0.021478, 0.37273, 0.0010678, 0.23916, 0.039337]
Predicted label: 1
Correct prediction
Energy consumption = 153.978643 pJ
sum error= 301
Actual label: 4
Output voltages: [0.0059056, 0.0070624, 0.020297, 0.01521, 0.79862, 0.012855, 0.12248, 0.062277, 0.084123, 0.01538]
Predicted label: 4
Correct prediction
Energy consumption = 141.386084 pJ
sum error= 301
Actual label: 3
Output voltages: [0.76809, 0.0012533, 0.46327, 0.78562, 0.001088, 0.027349, 0.00699, 0.016539, 0.07998, 0.0010985]
Predicted label: 3
Correct prediction
Energy consumption = 148.321281 pJ
sum error= 301
Actual label: 5
Output voltages: [0.028565, 0.0012849, 0.0015373, 0.44784, 0.024842, 0.79879, 0.34752, 0.0065627, 0.71879, 0.0014283]
Predicted label: 5
Correct prediction
Energy consumption = 139.208004 pJ
sum error= 301
Actual label: 2
Output voltages: [0.40681, 0.026773, 0.79873, 0.02509, 0.012753, 0.0010851, 0.055968, 0.017333, 0.42962, 0.019136]
Predicted label: 2
Correct prediction
Energy consumption = 147.425684 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 652 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 652 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 652 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.26895, 0.028022, 0.019667, 0.064998, 0.34466, 0.0096218, 0.0020336, 0.0031108, 0.28021, 0.79859]
Predicted label: 9
Correct prediction
Energy consumption = 150.385430 pJ
sum error= 301
Actual label: 2
Output voltages: [0.25294, 0.011897, 0.79874, 0.018112, 0.012213, 0.0011123, 0.035263, 0.044192, 0.4743, 0.0086077]
Predicted label: 2
Correct prediction
Energy consumption = 148.390537 pJ
sum error= 301
Actual label: 5
Output voltages: [0.038854, 0.0011083, 0.0011031, 0.48876, 0.25592, 0.79878, 0.28017, 0.023547, 0.77829, 0.0075305]
Predicted label: 5
Correct prediction
Energy consumption = 143.455314 pJ
sum error= 301
Actual label: 8
Output voltages: [0.025788, 0.53448, 0.21952, 0.031415, 0.027813, 0.0015431, 0.0051435, 0.02491, 0.79816, 0.29743]
Predicted label: 8
Correct prediction
Energy consumption = 154.347446 pJ
sum error= 301
Actual label: 9
Output voltages: [0.40591, 0.023899, 0.026288, 0.18118, 0.16538, 0.014384, 0.0023929, 0.019674, 0.33642, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 151.152241 pJ
sum error= 301
Actual label: 5
Output voltages: [0.026826, 0.0010892, 0.0023546, 0.21949, 0.047521, 0.79876, 0.27193, 0.02863, 0.77063, 0.0046076]
Predicted label: 5
Correct prediction
Energy consumption = 144.320723 pJ
sum error= 301
Actual label: 0
Output voltages: [0.79877, 0.044515, 0.036052, 0.022676, 0.0018967, 0.020418, 0.43822, 0.13844, 0.15345, 0.011013]
Predicted label: 0
Correct prediction
Energy consumption = 142.296901 pJ
sum error= 301
Actual label: 1
Output voltages: [0.16694, 0.79879, 0.24219, 0.030398, 0.34072, 0.0010695, 0.048778, 0.0076951, 0.029634, 0.043003]
Predicted label: 1
Correct prediction
Energy consumption = 160.204919 pJ
sum error= 301
Actual label: 2
Output voltages: [0.011012, 0.035916, 0.79873, 0.183, 0.074795, 0.0014592, 0.031783, 0.11898, 0.44862, 0.011607]
Predicted label: 2
Correct prediction
Energy consumption = 140.018739 pJ
sum error= 301
Actual label: 4
Output voltages: [0.042265, 0.016749, 0.16163, 0.022552, 0.79859, 0.0010699, 0.039538, 0.02033, 0.1739, 0.02557]
Predicted label: 4
Correct prediction
Energy consumption = 141.364572 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 653 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 653 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 653 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.047862, 0.001093, 0.0018158, 0.24162, 0.03739, 0.79879, 0.19649, 0.0022707, 0.6475, 0.020733]
Predicted label: 5
Correct prediction
Energy consumption = 139.543953 pJ
sum error= 301
Actual label: 6
Output voltages: [0.19533, 0.044635, 0.26299, 0.0064513, 0.36591, 0.15636, 0.7987, 0.0032338, 0.26964, 0.032]
Predicted label: 6
Correct prediction
Energy consumption = 137.760393 pJ
sum error= 301
Actual label: 0
Output voltages: [0.79878, 0.010104, 0.0010699, 0.11276, 0.0019928, 0.75414, 0.005893, 0.016787, 0.13577, 0.003379]
Predicted label: 0
Correct prediction
Energy consumption = 143.349429 pJ
sum error= 301
Actual label: 1
Output voltages: [0.0074907, 0.79856, 0.036043, 0.02765, 0.011047, 0.0013248, 0.46384, 0.013085, 0.5765, 0.0075502]
Predicted label: 1
Correct prediction
Energy consumption = 163.213791 pJ
sum error= 301
Actual label: 2
Output voltages: [0.30048, 0.018494, 0.79878, 0.18958, 0.010829, 0.0011988, 0.038118, 0.46464, 0.56938, 0.019989]
Predicted label: 2
Correct prediction
Energy consumption = 140.309690 pJ
sum error= 301
Actual label: 3
Output voltages: [0.18031, 0.1977, 0.12084, 0.79866, 0.012912, 0.017024, 0.0098882, 0.027096, 0.47483, 0.32124]
Predicted label: 3
Correct prediction
Energy consumption = 142.199942 pJ
sum error= 301
Actual label: 4
Output voltages: [0.026505, 0.0076216, 0.1026, 0.018182, 0.79872, 0.0011652, 0.065509, 0.12729, 0.21284, 0.0085276]
Predicted label: 4
Correct prediction
Energy consumption = 151.378188 pJ
sum error= 301
Actual label: 5
Output voltages: [0.15914, 0.0010695, 0.004964, 0.23051, 0.111, 0.79867, 0.32181, 0.013506, 0.41018, 0.035405]
Predicted label: 5
Correct prediction
Energy consumption = 146.872103 pJ
sum error= 301
Actual label: 6
Output voltages: [0.02569, 0.34033, 0.14706, 0.023859, 0.22181, 0.0081421, 0.79869, 0.0023181, 0.18837, 0.24503]
Predicted label: 6
Correct prediction
Energy consumption = 138.355924 pJ
sum error= 301
Actual label: 7
Output voltages: [0.27631, 0.014357, 0.025877, 0.20809, 0.031421, 0.018503, 0.0010844, 0.7987, 0.19743, 0.65949]
Predicted label: 7
Correct prediction
Energy consumption = 150.844510 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 654 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 654 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 654 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.018811, 0.79835, 0.0099625, 0.030662, 0.020449, 0.0049172, 0.51258, 0.019017, 0.047549, 0.31263]
Predicted label: 1
Correct prediction
Energy consumption = 162.557123 pJ
sum error= 301
Actual label: 2
Output voltages: [0.25207, 0.34424, 0.79879, 0.3659, 0.01841, 0.0013333, 0.1823, 0.033867, 0.23248, 0.024001]
Predicted label: 2
Correct prediction
Energy consumption = 148.090997 pJ
sum error= 301
Actual label: 3
Output voltages: [0.26851, 0.11138, 0.24386, 0.79847, 0.029886, 0.0010667, 0.001289, 0.63427, 0.065915, 0.016184]
Predicted label: 3
Correct prediction
Energy consumption = 139.055626 pJ
sum error= 301
Actual label: 4
Output voltages: [0.0010661, 0.0084517, 0.30971, 0.060393, 0.79873, 0.0010893, 0.064614, 0.30701, 0.0090517, 0.05099]
Predicted label: 4
Correct prediction
Energy consumption = 141.530719 pJ
sum error= 301
Actual label: 5
Output voltages: [0.05233, 0.0010765, 0.0010751, 0.31438, 0.048294, 0.79797, 0.33724, 0.0021973, 0.65495, 0.21848]
Predicted label: 5
Correct prediction
Energy consumption = 153.035712 pJ
sum error= 301
Actual label: 1
Output voltages: [0.032385, 0.79872, 0.43722, 0.07649, 0.19556, 0.0011139, 0.57181, 0.0061874, 0.038374, 0.026382]
Predicted label: 1
Correct prediction
Energy consumption = 168.844025 pJ
sum error= 301
Actual label: 0
Output voltages: [0.79837, 0.029615, 0.026033, 0.038325, 0.0010803, 0.011465, 0.59334, 0.0078233, 0.40461, 0.35148]
Predicted label: 0
Correct prediction
Energy consumption = 141.610586 pJ
sum error= 301
Actual label: 4
Output voltages: [0.0038092, 0.014845, 0.045333, 0.0013596, 0.79852, 0.0012191, 0.59876, 0.061742, 0.02847, 0.026471]
Predicted label: 4
Correct prediction
Energy consumption = 145.928376 pJ
sum error= 301
Actual label: 5
Output voltages: [0.0091774, 0.0013132, 0.001094, 0.24293, 0.22507, 0.79878, 0.28357, 0.020605, 0.54767, 0.13086]
Predicted label: 5
Correct prediction
Energy consumption = 143.694074 pJ
sum error= 301
Actual label: 6
Output voltages: [0.17148, 0.032969, 0.19964, 0.0018731, 0.25456, 0.047451, 0.79878, 0.001088, 0.20512, 0.015169]
Predicted label: 6
Correct prediction
Energy consumption = 137.375642 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 655 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 655 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 655 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.062424, 0.12969, 0.26405, 0.01764, 0.26839, 0.18829, 0.79867, 0.0028544, 0.28382, 0.016404]
Predicted label: 6
Correct prediction
Energy consumption = 145.205279 pJ
sum error= 301
Actual label: 3
Output voltages: [0.58548, 0.059295, 0.23145, 0.79855, 0.053873, 0.022385, 0.026763, 0.11234, 0.46539, 0.10502]
Predicted label: 3
Correct prediction
Energy consumption = 149.958860 pJ
sum error= 301
Actual label: 4
Output voltages: [0.025969, 0.0077875, 0.5015, 0.015456, 0.79875, 0.0036035, 0.40239, 0.04314, 0.03211, 0.019765]
Predicted label: 4
Correct prediction
Energy consumption = 148.404989 pJ
sum error= 301
Actual label: 4
Output voltages: [0.010549, 0.0036273, 0.033163, 0.60592, 0.78807, 0.0014795, 0.050428, 0.012003, 0.24166, 0.038367]
Predicted label: 4
Correct prediction
Energy consumption = 140.556756 pJ
sum error= 301
Actual label: 2
Output voltages: [0.039038, 0.0061829, 0.79548, 0.23456, 0.016283, 0.0012641, 0.02457, 0.24642, 0.71616, 0.12711]
Predicted label: 2
Correct prediction
Energy consumption = 132.356465 pJ
sum error= 301
Actual label: 8
Output voltages: [0.018374, 0.016741, 0.025535, 0.22515, 0.005286, 0.0097131, 0.0010705, 0.32359, 0.79561, 0.78131]
Predicted label: 8
Correct prediction
Energy consumption = 142.443960 pJ
sum error= 301
Actual label: 1
Output voltages: [0.012267, 0.79853, 0.016926, 0.16432, 0.05009, 0.0032156, 0.57706, 0.034362, 0.055831, 0.23945]
Predicted label: 1
Correct prediction
Energy consumption = 155.548361 pJ
sum error= 301
Actual label: 0
Output voltages: [0.78056, 0.024126, 0.76582, 0.045079, 0.0010668, 0.0011381, 0.41077, 0.26644, 0.48323, 0.0076975]
Predicted label: 0
Correct prediction
Energy consumption = 152.729823 pJ
sum error= 301
Actual label: 6
Output voltages: [0.043537, 0.1324, 0.7752, 0.0033169, 0.012357, 0.014934, 0.795, 0.016458, 0.72598, 0.0017528]
Predicted label: 6
Correct prediction
Energy consumption = 136.525914 pJ
sum error= 301
Actual label: 4
Output voltages: [0.0015721, 0.010007, 0.45755, 0.18588, 0.79846, 0.0019663, 0.0080179, 0.37247, 0.038105, 0.081766]
Predicted label: 4
Correct prediction
Energy consumption = 150.857659 pJ
sum error= 301
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 656 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 656 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 656 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.077507, 0.027817, 0.0014619, 0.77017, 0.61147, 0.55061, 0.2531, 0.0017382, 0.019014, 0.74925]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.555212 pJ
sum error= 302
Actual label: 7
Output voltages: [0.11328, 0.73255, 0.16954, 0.4488, 0.0015654, 0.0011605, 0.0011149, 0.79875, 0.28004, 0.491]
Predicted label: 7
Correct prediction
Energy consumption = 156.873249 pJ
sum error= 302
Actual label: 2
Output voltages: [0.44053, 0.11734, 0.79878, 0.045922, 0.0041833, 0.0010778, 0.0042387, 0.74838, 0.46512, 0.011269]
Predicted label: 2
Correct prediction
Energy consumption = 135.162896 pJ
sum error= 302
Actual label: 3
Output voltages: [0.16729, 0.025085, 0.17391, 0.79863, 0.002259, 0.12616, 0.0064551, 0.12067, 0.29084, 0.026532]
Predicted label: 3
Correct prediction
Energy consumption = 146.719673 pJ
sum error= 302
Actual label: 3
Output voltages: [0.072941, 0.0041491, 0.083698, 0.79879, 0.23701, 0.096639, 0.020216, 0.074248, 0.31492, 0.20898]
Predicted label: 3
Correct prediction
Energy consumption = 141.268735 pJ
sum error= 302
Actual label: 9
Output voltages: [0.26351, 0.018824, 0.026458, 0.04056, 0.025293, 0.015333, 0.0032391, 0.036815, 0.736, 0.79847]
Predicted label: 9
Correct prediction
Energy consumption = 146.514866 pJ
sum error= 302
Actual label: 2
Output voltages: [0.34219, 0.0043771, 0.79796, 0.12084, 0.42101, 0.0010664, 0.02251, 0.010377, 0.62275, 0.01441]
Predicted label: 2
Correct prediction
Energy consumption = 148.784821 pJ
sum error= 302
Actual label: 0
Output voltages: [0.79878, 0.079476, 0.032724, 0.0082399, 0.0047173, 0.0097659, 0.64134, 0.030733, 0.2455, 0.038655]
Predicted label: 0
Correct prediction
Energy consumption = 141.850197 pJ
sum error= 302
Actual label: 9
Output voltages: [0.019671, 0.018887, 0.058294, 0.13844, 0.014383, 0.004313, 0.0085894, 0.0055062, 0.76337, 0.79831]
Predicted label: 9
Correct prediction
Energy consumption = 141.591674 pJ
sum error= 302
Actual label: 3
Output voltages: [0.4112, 0.047903, 0.29885, 0.79839, 0.0063347, 0.0036281, 0.0011416, 0.012383, 0.14449, 0.45731]
Predicted label: 3
Correct prediction
Energy consumption = 148.375537 pJ
sum error= 302
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 657 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 657 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 657 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.27559, 0.018234, 0.056603, 0.79868, 0.0077456, 0.0084587, 0.0052107, 0.054623, 0.49094, 0.017633]
Predicted label: 3
Correct prediction
Energy consumption = 149.241218 pJ
sum error= 302
Actual label: 9
Output voltages: [0.23982, 0.028914, 0.059124, 0.39648, 0.053466, 0.058973, 0.0044241, 0.75658, 0.19951, 0.7982]
Predicted label: 9
Correct prediction
Energy consumption = 139.054891 pJ
sum error= 302
Actual label: 1
Output voltages: [0.032789, 0.79879, 0.56386, 0.31732, 0.0010661, 0.02048, 0.083998, 0.015424, 0.30557, 0.083685]
Predicted label: 1
Correct prediction
Energy consumption = 154.572725 pJ
sum error= 302
Actual label: 5
Output voltages: [0.1104, 0.0030594, 0.012164, 0.79696, 0.026979, 0.76878, 0.051631, 0.003827, 0.38035, 0.011249]
Predicted label: 3
Wrong prediction!
Energy consumption = 145.147591 pJ
sum error= 303
Actual label: 2
Output voltages: [0.65896, 0.0010908, 0.78822, 0.038453, 0.025411, 0.0012539, 0.074019, 0.49251, 0.40249, 0.017034]
Predicted label: 2
Correct prediction
Energy consumption = 132.298243 pJ
sum error= 303
Actual label: 3
Output voltages: [0.29715, 0.0080656, 0.053907, 0.79872, 0.03606, 0.033736, 0.015664, 0.028305, 0.6147, 0.1376]
Predicted label: 3
Correct prediction
Energy consumption = 145.151132 pJ
sum error= 303
Actual label: 7
Output voltages: [0.18987, 0.78886, 0.31762, 0.084332, 0.0032743, 0.0012462, 0.0053085, 0.74066, 0.52989, 0.0073528]
Predicted label: 1
Wrong prediction!
Energy consumption = 150.856048 pJ
sum error= 304
Actual label: 7
Output voltages: [0.039398, 0.49168, 0.7552, 0.22371, 0.0015922, 0.0010748, 0.001077, 0.79878, 0.33588, 0.39844]
Predicted label: 7
Correct prediction
Energy consumption = 139.077806 pJ
sum error= 304
Actual label: 8
Output voltages: [0.026009, 0.0069268, 0.046856, 0.054172, 0.0010919, 0.62601, 0.097069, 0.005658, 0.79848, 0.015639]
Predicted label: 8
Correct prediction
Energy consumption = 147.586598 pJ
sum error= 304
Actual label: 4
Output voltages: [0.011336, 0.002266, 0.075039, 0.014921, 0.79868, 0.0010786, 0.044449, 0.022267, 0.10084, 0.0053402]
Predicted label: 4
Correct prediction
Energy consumption = 149.709810 pJ
sum error= 304
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 658 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 658 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 658 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79876, 0.081331, 0.136, 0.025245, 0.0031204, 0.0093641, 0.061138, 0.032156, 0.14187, 0.13628]
Predicted label: 0
Correct prediction
Energy consumption = 152.548035 pJ
sum error= 304
Actual label: 2
Output voltages: [0.53943, 0.15785, 0.79879, 0.22997, 0.2183, 0.0011656, 0.10115, 0.73103, 0.11278, 0.25274]
Predicted label: 2
Correct prediction
Energy consumption = 146.490561 pJ
sum error= 304
Actual label: 4
Output voltages: [0.0012578, 0.11418, 0.14263, 0.0062053, 0.79869, 0.0019853, 0.68718, 0.42108, 0.0013449, 0.02103]
Predicted label: 4
Correct prediction
Energy consumption = 149.196404 pJ
sum error= 304
Actual label: 0
Output voltages: [0.79877, 0.077819, 0.012254, 0.071449, 0.0019878, 0.16623, 0.26716, 0.018033, 0.028414, 0.03237]
Predicted label: 0
Correct prediction
Energy consumption = 158.491657 pJ
sum error= 304
Actual label: 2
Output voltages: [0.71204, 0.056507, 0.79875, 0.034505, 0.0011449, 0.0012422, 0.027379, 0.18497, 0.27479, 0.040619]
Predicted label: 2
Correct prediction
Energy consumption = 148.170427 pJ
sum error= 304
Actual label: 4
Output voltages: [0.0025513, 0.0037889, 0.17506, 0.01581, 0.79872, 0.0014508, 0.30012, 0.12468, 0.040183, 0.016243]
Predicted label: 4
Correct prediction
Energy consumption = 153.888543 pJ
sum error= 304
Actual label: 7
Output voltages: [0.050497, 0.022985, 0.10194, 0.23348, 0.015353, 0.0010699, 0.0010885, 0.79869, 0.13508, 0.18028]
Predicted label: 7
Correct prediction
Energy consumption = 153.349171 pJ
sum error= 304
Actual label: 8
Output voltages: [0.0082668, 0.25768, 0.20354, 0.02887, 0.019195, 0.038975, 0.014106, 0.28435, 0.79872, 0.02593]
Predicted label: 8
Correct prediction
Energy consumption = 148.991355 pJ
sum error= 304
Actual label: 0
Output voltages: [0.79879, 0.026912, 0.24338, 0.014134, 0.040365, 0.0022363, 0.045485, 0.010136, 0.078305, 0.13683]
Predicted label: 0
Correct prediction
Energy consumption = 151.699287 pJ
sum error= 304
Actual label: 7
Output voltages: [0.20539, 0.021475, 0.4962, 0.059118, 0.0026407, 0.0010661, 0.0011122, 0.79866, 0.059679, 0.22486]
Predicted label: 7
Correct prediction
Energy consumption = 149.624825 pJ
sum error= 304
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 659 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 659 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 659 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79875, 0.026886, 0.013596, 0.16967, 0.0011294, 0.39306, 0.25956, 0.0023169, 0.051537, 0.023371]
Predicted label: 0
Correct prediction
Energy consumption = 150.321827 pJ
sum error= 304
Actual label: 6
Output voltages: [0.12847, 0.041659, 0.17839, 0.0098207, 0.21796, 0.19466, 0.79868, 0.0021574, 0.31376, 0.034552]
Predicted label: 6
Correct prediction
Energy consumption = 138.033665 pJ
sum error= 304
Actual label: 9
Output voltages: [0.053485, 0.0052024, 0.0014254, 0.14103, 0.55017, 0.64302, 0.54642, 0.023049, 0.047488, 0.78785]
Predicted label: 9
Correct prediction
Energy consumption = 148.615144 pJ
sum error= 304
Actual label: 3
Output voltages: [0.092273, 0.011891, 0.14369, 0.79869, 0.016091, 0.0093585, 0.0036117, 0.16198, 0.26914, 0.15092]
Predicted label: 3
Correct prediction
Energy consumption = 144.352501 pJ
sum error= 304
Actual label: 2
Output voltages: [0.16307, 0.0031321, 0.79879, 0.3449, 0.14733, 0.0011384, 0.17461, 0.095682, 0.46982, 0.027883]
Predicted label: 2
Correct prediction
Energy consumption = 135.289007 pJ
sum error= 304
Actual label: 8
Output voltages: [0.0079522, 0.041401, 0.062285, 0.039721, 0.015239, 0.05556, 0.0021551, 0.065171, 0.79867, 0.02708]
Predicted label: 8
Correct prediction
Energy consumption = 149.560885 pJ
sum error= 304
Actual label: 6
Output voltages: [0.24086, 0.0098144, 0.19303, 0.0028091, 0.61426, 0.081218, 0.79877, 0.0012752, 0.67645, 0.0074229]
Predicted label: 6
Correct prediction
Energy consumption = 140.205425 pJ
sum error= 304
Actual label: 0
Output voltages: [0.63044, 0.19487, 0.072328, 0.48825, 0.011662, 0.0055672, 0.0021067, 0.79872, 0.010139, 0.070091]
Predicted label: 7
Wrong prediction!
Energy consumption = 149.685554 pJ
sum error= 305
Actual label: 5
Output voltages: [0.21112, 0.0058734, 0.049128, 0.1189, 0.001717, 0.7929, 0.76787, 0.0052321, 0.27683, 0.0016907]
Predicted label: 5
Correct prediction
Energy consumption = 139.454495 pJ
sum error= 305
Actual label: 7
Output voltages: [0.034397, 0.31868, 0.38321, 0.0026672, 0.008087, 0.0010875, 0.001129, 0.79842, 0.32321, 0.38003]
Predicted label: 7
Correct prediction
Energy consumption = 144.882318 pJ
sum error= 305
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 660 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 660 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 660 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.031217, 0.0011599, 0.0010877, 0.040416, 0.35538, 0.79876, 0.33497, 0.0063309, 0.75417, 0.019109]
Predicted label: 5
Correct prediction
Energy consumption = 141.809504 pJ
sum error= 305
Actual label: 1
Output voltages: [0.13953, 0.79861, 0.51282, 0.065034, 0.060151, 0.0010699, 0.33517, 0.0205, 0.036919, 0.060901]
Predicted label: 1
Correct prediction
Energy consumption = 166.550100 pJ
sum error= 305
Actual label: 0
Output voltages: [0.79878, 0.035056, 0.058185, 0.016997, 0.010232, 0.057987, 0.33813, 0.048338, 0.57078, 0.34344]
Predicted label: 0
Correct prediction
Energy consumption = 157.097335 pJ
sum error= 305
Actual label: 8
Output voltages: [0.59461, 0.0029732, 0.082699, 0.0084955, 0.012836, 0.017603, 0.0013961, 0.056222, 0.79446, 0.56957]
Predicted label: 8
Correct prediction
Energy consumption = 147.700267 pJ
sum error= 305
Actual label: 1
Output voltages: [0.029669, 0.79849, 0.18444, 0.0294, 0.0069643, 0.0030624, 0.71347, 0.0020143, 0.40125, 0.041505]
Predicted label: 1
Correct prediction
Energy consumption = 162.257832 pJ
sum error= 305
Actual label: 6
Output voltages: [0.19607, 0.02775, 0.16614, 0.0018253, 0.37306, 0.50165, 0.79877, 0.0013726, 0.27981, 0.0034604]
Predicted label: 6
Correct prediction
Energy consumption = 145.936953 pJ
sum error= 305
Actual label: 7
Output voltages: [0.028935, 0.02331, 0.23656, 0.02114, 0.02845, 0.0013061, 0.0011747, 0.79858, 0.47331, 0.083719]
Predicted label: 7
Correct prediction
Energy consumption = 148.632531 pJ
sum error= 305
Actual label: 2
Output voltages: [0.61104, 0.0056538, 0.79802, 0.19397, 0.10715, 0.0010885, 0.012705, 0.018816, 0.51039, 0.0057415]
Predicted label: 2
Correct prediction
Energy consumption = 144.646583 pJ
sum error= 305
Actual label: 9
Output voltages: [0.45946, 0.0028739, 0.0010949, 0.18499, 0.28161, 0.57501, 0.044143, 0.0047009, 0.052223, 0.7961]
Predicted label: 9
Correct prediction
Energy consumption = 156.027551 pJ
sum error= 305
Actual label: 7
Output voltages: [0.045253, 0.20159, 0.72578, 0.031916, 0.011835, 0.0011755, 0.0022702, 0.79879, 0.11575, 0.14056]
Predicted label: 7
Correct prediction
Energy consumption = 151.519870 pJ
sum error= 305
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 661 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 661 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 661 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.015483, 0.015811, 0.0024552, 0.50984, 0.20406, 0.64893, 0.15356, 0.0066293, 0.364, 0.71383]
Predicted label: 9
Correct prediction
Energy consumption = 152.129108 pJ
sum error= 305
Actual label: 5
Output voltages: [0.31278, 0.0013284, 0.0010678, 0.39604, 0.16992, 0.79869, 0.33457, 0.024407, 0.65368, 0.0035004]
Predicted label: 5
Correct prediction
Energy consumption = 131.553456 pJ
sum error= 305
Actual label: 8
Output voltages: [0.017304, 0.028362, 0.35389, 0.077975, 0.0042303, 0.035019, 0.025379, 0.032916, 0.79871, 0.036088]
Predicted label: 8
Correct prediction
Energy consumption = 148.991760 pJ
sum error= 305
Actual label: 6
Output voltages: [0.4276, 0.0025259, 0.035585, 0.01608, 0.0064322, 0.21656, 0.77514, 0.78563, 0.020317, 0.059695]
Predicted label: 7
Wrong prediction!
Energy consumption = 138.466103 pJ
sum error= 306
Actual label: 2
Output voltages: [0.7219, 0.031887, 0.79873, 0.040955, 0.0018805, 0.0011473, 0.053681, 0.58636, 0.23058, 0.03627]
Predicted label: 2
Correct prediction
Energy consumption = 146.275629 pJ
sum error= 306
Actual label: 6
Output voltages: [0.036319, 0.012015, 0.32485, 0.0012653, 0.16072, 0.083059, 0.79879, 0.0024906, 0.44812, 0.0014806]
Predicted label: 6
Correct prediction
Energy consumption = 146.971271 pJ
sum error= 306
Actual label: 2
Output voltages: [0.65396, 0.0024125, 0.79877, 0.074084, 0.0019935, 0.0010662, 0.029338, 0.21566, 0.68108, 0.0094817]
Predicted label: 2
Correct prediction
Energy consumption = 143.759492 pJ
sum error= 306
Actual label: 8
Output voltages: [0.044724, 0.017063, 0.55856, 0.0069177, 0.02296, 0.0046693, 0.017873, 0.0037088, 0.79878, 0.1071]
Predicted label: 8
Correct prediction
Energy consumption = 142.383970 pJ
sum error= 306
Actual label: 1
Output voltages: [0.01555, 0.79848, 0.21934, 0.031062, 0.03626, 0.0011564, 0.38123, 0.0045368, 0.41292, 0.044176]
Predicted label: 1
Correct prediction
Energy consumption = 154.693690 pJ
sum error= 306
Actual label: 7
Output voltages: [0.49919, 0.035086, 0.0055865, 0.021347, 0.19427, 0.066727, 0.0015887, 0.79877, 0.45083, 0.39944]
Predicted label: 7
Correct prediction
Energy consumption = 149.335002 pJ
sum error= 306
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 662 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 662 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 662 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.043142, 0.0010824, 0.0010979, 0.046666, 0.037973, 0.79879, 0.26732, 0.038904, 0.76733, 0.0085243]
Predicted label: 5
Correct prediction
Energy consumption = 148.730165 pJ
sum error= 306
Actual label: 0
Output voltages: [0.79868, 0.020443, 0.054991, 0.065476, 0.0091956, 0.023919, 0.038574, 0.025344, 0.29169, 0.083703]
Predicted label: 0
Correct prediction
Energy consumption = 154.430313 pJ
sum error= 306
Actual label: 1
Output voltages: [0.014446, 0.79864, 0.0058953, 0.023416, 0.15212, 0.0019643, 0.35164, 0.0081746, 0.35776, 0.10255]
Predicted label: 1
Correct prediction
Energy consumption = 162.837076 pJ
sum error= 306
Actual label: 1
Output voltages: [0.024774, 0.79836, 0.050298, 0.062586, 0.0083986, 0.029489, 0.53581, 0.017076, 0.1407, 0.022833]
Predicted label: 1
Correct prediction
Energy consumption = 150.380561 pJ
sum error= 306
Actual label: 3
Output voltages: [0.20599, 0.0078411, 0.11273, 0.79868, 0.075763, 0.046344, 0.026882, 0.019607, 0.40633, 0.2036]
Predicted label: 3
Correct prediction
Energy consumption = 149.551671 pJ
sum error= 306
Actual label: 8
Output voltages: [0.014356, 0.053378, 0.52603, 0.018382, 0.0093828, 0.0011426, 0.24676, 0.15516, 0.7924, 0.038332]
Predicted label: 8
Correct prediction
Energy consumption = 145.424075 pJ
sum error= 306
Actual label: 4
Output voltages: [0.0087525, 0.016359, 0.09889, 0.046304, 0.7987, 0.0029966, 0.036656, 0.043472, 0.03395, 0.0095717]
Predicted label: 4
Correct prediction
Energy consumption = 150.717395 pJ
sum error= 306
Actual label: 9
Output voltages: [0.31753, 0.0063291, 0.0098034, 0.030169, 0.532, 0.005031, 0.0017895, 0.0037094, 0.30975, 0.79628]
Predicted label: 9
Correct prediction
Energy consumption = 139.552274 pJ
sum error= 306
Actual label: 1
Output voltages: [0.0050371, 0.79872, 0.29825, 0.33805, 0.58012, 0.0011039, 0.016662, 0.013259, 0.014945, 0.29414]
Predicted label: 1
Correct prediction
Energy consumption = 162.443200 pJ
sum error= 306
Actual label: 8
Output voltages: [0.12335, 0.010253, 0.063866, 0.11667, 0.0054159, 0.50017, 0.013905, 0.01966, 0.79865, 0.035882]
Predicted label: 8
Correct prediction
Energy consumption = 149.488189 pJ
sum error= 306
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 663 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 663 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 663 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.063733, 0.033958, 0.32384, 0.0012238, 0.28213, 0.10685, 0.79876, 0.001605, 0.5227, 0.0019897]
Predicted label: 6
Correct prediction
Energy consumption = 145.785282 pJ
sum error= 306
Actual label: 8
Output voltages: [0.22583, 0.035667, 0.50757, 0.0064948, 0.029015, 0.0012937, 0.016305, 0.0024712, 0.79848, 0.43232]
Predicted label: 8
Correct prediction
Energy consumption = 146.966546 pJ
sum error= 306
Actual label: 9
Output voltages: [0.15376, 0.0092771, 0.0020053, 0.014781, 0.054141, 0.35291, 0.0016081, 0.034784, 0.3058, 0.77742]
Predicted label: 9
Correct prediction
Energy consumption = 151.022116 pJ
sum error= 306
Actual label: 0
Output voltages: [0.79879, 0.039626, 0.11633, 0.016317, 0.01069, 0.0072769, 0.26562, 0.016276, 0.30605, 0.019821]
Predicted label: 0
Correct prediction
Energy consumption = 152.874392 pJ
sum error= 306
Actual label: 1
Output voltages: [0.018809, 0.79857, 0.13701, 0.034608, 0.21659, 0.0011816, 0.47323, 0.021776, 0.25821, 0.030566]
Predicted label: 1
Correct prediction
Energy consumption = 160.179038 pJ
sum error= 306
Actual label: 2
Output voltages: [0.061158, 0.044824, 0.79878, 0.086097, 0.011216, 0.0011699, 0.32375, 0.31114, 0.51984, 0.011715]
Predicted label: 2
Correct prediction
Energy consumption = 141.830129 pJ
sum error= 306
Actual label: 3
Output voltages: [0.51613, 0.012785, 0.037315, 0.79876, 0.0030365, 0.017285, 0.0086211, 0.010717, 0.7658, 0.0080956]
Predicted label: 3
Correct prediction
Energy consumption = 142.884265 pJ
sum error= 306
Actual label: 4
Output voltages: [0.04603, 0.043785, 0.047967, 0.026886, 0.79874, 0.0010663, 0.043597, 0.17028, 0.14014, 0.03909]
Predicted label: 4
Correct prediction
Energy consumption = 151.066441 pJ
sum error= 306
Actual label: 5
Output voltages: [0.022167, 0.0010996, 0.003088, 0.4646, 0.057939, 0.79868, 0.54025, 0.29001, 0.71986, 0.028506]
Predicted label: 5
Correct prediction
Energy consumption = 148.231035 pJ
sum error= 306
Actual label: 6
Output voltages: [0.035669, 0.043449, 0.42386, 0.0037393, 0.17021, 0.14752, 0.79879, 0.0020679, 0.74727, 0.01617]
Predicted label: 6
Correct prediction
Energy consumption = 145.955372 pJ
sum error= 306
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 664 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 664 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 664 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.15745, 0.18145, 0.22084, 0.037907, 0.026892, 0.0011339, 0.0010669, 0.79857, 0.08596, 0.034317]
Predicted label: 7
Correct prediction
Energy consumption = 149.938879 pJ
sum error= 306
Actual label: 8
Output voltages: [0.028658, 0.013917, 0.10273, 0.29722, 0.0010983, 0.21168, 0.011932, 0.0016339, 0.79878, 0.035621]
Predicted label: 8
Correct prediction
Energy consumption = 147.701158 pJ
sum error= 306
Actual label: 9
Output voltages: [0.015553, 0.015894, 0.001085, 0.086394, 0.59009, 0.46685, 0.0014128, 0.01394, 0.32326, 0.74207]
Predicted label: 9
Correct prediction
Energy consumption = 143.948283 pJ
sum error= 306
Actual label: 0
Output voltages: [0.79872, 0.048671, 0.049347, 0.018778, 0.0019659, 0.0058181, 0.16201, 0.24845, 0.25726, 0.022743]
Predicted label: 0
Correct prediction
Energy consumption = 150.137668 pJ
sum error= 306
Actual label: 1
Output voltages: [0.044166, 0.79876, 0.14901, 0.012669, 0.29665, 0.001066, 0.26099, 0.0015085, 0.035657, 0.016113]
Predicted label: 1
Correct prediction
Energy consumption = 154.058657 pJ
sum error= 306
Actual label: 2
Output voltages: [0.14019, 0.065105, 0.79876, 0.030768, 0.025716, 0.0011296, 0.034742, 0.031111, 0.5103, 0.028148]
Predicted label: 2
Correct prediction
Energy consumption = 142.993376 pJ
sum error= 306
Actual label: 3
Output voltages: [0.069249, 0.0058635, 0.0488, 0.79871, 0.01849, 0.04031, 0.026078, 0.033744, 0.75428, 0.029665]
Predicted label: 3
Correct prediction
Energy consumption = 140.935823 pJ
sum error= 306
Actual label: 4
Output voltages: [0.0053914, 0.0059871, 0.038469, 0.0082539, 0.79864, 0.001205, 0.068144, 0.1091, 0.035634, 0.0042407]
Predicted label: 4
Correct prediction
Energy consumption = 149.274725 pJ
sum error= 306
Actual label: 7
Output voltages: [0.18713, 0.05091, 0.7593, 0.034599, 0.011659, 0.0010668, 0.0010666, 0.79872, 0.17574, 0.24108]
Predicted label: 7
Correct prediction
Energy consumption = 147.394840 pJ
sum error= 306
Actual label: 8
Output voltages: [0.021258, 0.020847, 0.054573, 0.15689, 0.0022193, 0.06147, 0.026251, 0.0032856, 0.79874, 0.064425]
Predicted label: 8
Correct prediction
Energy consumption = 148.641589 pJ
sum error= 306
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 665 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 665 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 665 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.12468, 0.0039464, 0.0047087, 0.026927, 0.2003, 0.0082867, 0.003717, 0.01507, 0.70696, 0.79847]
Predicted label: 9
Correct prediction
Energy consumption = 141.870635 pJ
sum error= 306
Actual label: 0
Output voltages: [0.67769, 0.77652, 0.39841, 0.011427, 0.35992, 0.0096002, 0.078119, 0.0041854, 0.20353, 0.01001]
Predicted label: 1
Wrong prediction!
Energy consumption = 149.088637 pJ
sum error= 307
Actual label: 1
Output voltages: [0.021863, 0.79847, 0.20282, 0.004838, 0.38291, 0.0010782, 0.31449, 0.0018376, 0.17863, 0.017084]
Predicted label: 1
Correct prediction
Energy consumption = 139.516939 pJ
sum error= 307
Actual label: 7
Output voltages: [0.19798, 0.062772, 0.57214, 0.0076873, 0.01938, 0.0010674, 0.0015835, 0.79861, 0.085262, 0.047078]
Predicted label: 7
Correct prediction
Energy consumption = 141.957173 pJ
sum error= 307
Actual label: 8
Output voltages: [0.021407, 0.016144, 0.050357, 0.57106, 0.0013999, 0.37474, 0.029895, 0.0026548, 0.79879, 0.053107]
Predicted label: 8
Correct prediction
Energy consumption = 147.374372 pJ
sum error= 307
Actual label: 9
Output voltages: [0.049537, 0.0040589, 0.017468, 0.018808, 0.031088, 0.016469, 0.0011927, 0.050568, 0.78301, 0.79105]
Predicted label: 9
Correct prediction
Energy consumption = 135.800581 pJ
sum error= 307
Actual label: 9
Output voltages: [0.049914, 0.0039929, 0.020799, 0.023451, 0.0572, 0.0086879, 0.0014899, 0.038688, 0.7733, 0.79243]
Predicted label: 9
Correct prediction
Energy consumption = 130.137010 pJ
sum error= 307
Actual label: 8
Output voltages: [0.029397, 0.014753, 0.029176, 0.58249, 0.0012341, 0.66578, 0.019626, 0.0072673, 0.79879, 0.07703]
Predicted label: 8
Correct prediction
Energy consumption = 143.335205 pJ
sum error= 307
Actual label: 9
Output voltages: [0.055022, 0.010608, 0.019053, 0.01956, 0.047647, 0.0056549, 0.001592, 0.024127, 0.77808, 0.79747]
Predicted label: 9
Correct prediction
Energy consumption = 138.299033 pJ
sum error= 307
Actual label: 8
Output voltages: [0.29263, 0.021659, 0.13457, 0.034513, 0.057393, 0.10479, 0.020056, 0.0044014, 0.79879, 0.034171]
Predicted label: 8
Correct prediction
Energy consumption = 140.743536 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 666 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 666 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 666 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0078658, 0.024994, 0.080348, 0.03032, 0.79875, 0.015612, 0.052475, 0.13454, 0.039294, 0.0087967]
Predicted label: 4
Correct prediction
Energy consumption = 147.294016 pJ
sum error= 307
Actual label: 1
Output voltages: [0.0080658, 0.79867, 0.040809, 0.027788, 0.028441, 0.0024344, 0.42731, 0.0014037, 0.39884, 0.026687]
Predicted label: 1
Correct prediction
Energy consumption = 144.852301 pJ
sum error= 307
Actual label: 7
Output voltages: [0.40557, 0.04791, 0.74391, 0.069981, 0.0010804, 0.0010713, 0.0012466, 0.79877, 0.45209, 0.025308]
Predicted label: 7
Correct prediction
Energy consumption = 147.774893 pJ
sum error= 307
Actual label: 7
Output voltages: [0.056763, 0.044283, 0.69916, 0.0092269, 0.0099713, 0.0010706, 0.0023834, 0.7986, 0.26522, 0.059985]
Predicted label: 7
Correct prediction
Energy consumption = 133.221172 pJ
sum error= 307
Actual label: 3
Output voltages: [0.47971, 0.0010664, 0.46565, 0.79819, 0.025244, 0.0094292, 0.0041483, 0.0054341, 0.51331, 0.0027068]
Predicted label: 3
Correct prediction
Energy consumption = 138.956942 pJ
sum error= 307
Actual label: 3
Output voltages: [0.18066, 0.021226, 0.03057, 0.79871, 0.0021843, 0.012543, 0.0046529, 0.19491, 0.6903, 0.024848]
Predicted label: 3
Correct prediction
Energy consumption = 130.919226 pJ
sum error= 307
Actual label: 7
Output voltages: [0.34227, 0.010441, 0.036352, 0.041927, 0.024815, 0.0063473, 0.0020214, 0.79871, 0.045268, 0.54043]
Predicted label: 7
Correct prediction
Energy consumption = 138.077392 pJ
sum error= 307
Actual label: 6
Output voltages: [0.51207, 0.0028679, 0.0031318, 0.11658, 0.026156, 0.77207, 0.79253, 0.0011638, 0.64424, 0.14179]
Predicted label: 6
Correct prediction
Energy consumption = 142.294829 pJ
sum error= 307
Actual label: 6
Output voltages: [0.19654, 0.0012241, 0.032499, 0.0088502, 0.41487, 0.63779, 0.79604, 0.0010659, 0.7538, 0.010286]
Predicted label: 6
Correct prediction
Energy consumption = 133.900582 pJ
sum error= 307
Actual label: 6
Output voltages: [0.12317, 0.0025682, 0.015031, 0.02135, 0.16971, 0.66776, 0.79731, 0.0011937, 0.60243, 0.087676]
Predicted label: 6
Correct prediction
Energy consumption = 133.985130 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 667 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 667 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 667 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0024453, 0.79879, 0.025142, 0.21374, 0.25066, 0.0010686, 0.061109, 0.0097153, 0.087695, 0.058597]
Predicted label: 1
Correct prediction
Energy consumption = 152.549897 pJ
sum error= 307
Actual label: 9
Output voltages: [0.26721, 0.028369, 0.019344, 0.064923, 0.25182, 0.036096, 0.0047511, 0.013205, 0.58574, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 147.687407 pJ
sum error= 307
Actual label: 0
Output voltages: [0.79764, 0.029086, 0.026691, 0.0052422, 0.024466, 0.0066964, 0.74101, 0.17953, 0.041182, 0.20188]
Predicted label: 0
Correct prediction
Energy consumption = 142.629837 pJ
sum error= 307
Actual label: 1
Output voltages: [0.019799, 0.79708, 0.0061765, 0.0016987, 0.33606, 0.0011018, 0.01868, 0.0039279, 0.72793, 0.054061]
Predicted label: 1
Correct prediction
Energy consumption = 147.511725 pJ
sum error= 307
Actual label: 7
Output voltages: [0.23666, 0.013541, 0.017938, 0.093502, 0.020523, 0.018385, 0.0010781, 0.79857, 0.072569, 0.3433]
Predicted label: 7
Correct prediction
Energy consumption = 145.766408 pJ
sum error= 307
Actual label: 6
Output voltages: [0.27706, 0.028151, 0.15787, 0.0026322, 0.29334, 0.037173, 0.79755, 0.001095, 0.75792, 0.0048599]
Predicted label: 6
Correct prediction
Energy consumption = 146.277611 pJ
sum error= 307
Actual label: 3
Output voltages: [0.39757, 0.0034912, 0.33586, 0.79878, 0.02798, 0.018082, 0.0017667, 0.0068439, 0.65735, 0.00873]
Predicted label: 3
Correct prediction
Energy consumption = 143.459963 pJ
sum error= 307
Actual label: 2
Output voltages: [0.061888, 0.035221, 0.79879, 0.11093, 0.0060916, 0.001156, 0.00635, 0.76013, 0.59375, 0.011383]
Predicted label: 2
Correct prediction
Energy consumption = 131.711884 pJ
sum error= 307
Actual label: 1
Output voltages: [0.03322, 0.79872, 0.012238, 0.0083033, 0.3704, 0.011633, 0.21126, 0.011693, 0.34, 0.070621]
Predicted label: 1
Correct prediction
Energy consumption = 160.526516 pJ
sum error= 307
Actual label: 7
Output voltages: [0.042029, 0.062317, 0.27611, 0.046325, 0.0021966, 0.0020073, 0.0012552, 0.79879, 0.38057, 0.31531]
Predicted label: 7
Correct prediction
Energy consumption = 142.989377 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 668 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 668 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 668 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.026203, 0.7987, 0.0020357, 0.025264, 0.24956, 0.010743, 0.25669, 0.010244, 0.052121, 0.042118]
Predicted label: 1
Correct prediction
Energy consumption = 155.840639 pJ
sum error= 307
Actual label: 3
Output voltages: [0.69479, 0.012199, 0.19302, 0.79868, 0.0051035, 0.027465, 0.019883, 0.015542, 0.54208, 0.011933]
Predicted label: 3
Correct prediction
Energy consumption = 145.371383 pJ
sum error= 307
Actual label: 9
Output voltages: [0.38032, 0.035411, 0.013798, 0.063377, 0.21383, 0.019668, 0.0029741, 0.0051919, 0.26951, 0.79806]
Predicted label: 9
Correct prediction
Energy consumption = 144.775558 pJ
sum error= 307
Actual label: 1
Output voltages: [0.018745, 0.79874, 0.03668, 0.0072376, 0.25854, 0.0012325, 0.26164, 0.020645, 0.11908, 0.02283]
Predicted label: 1
Correct prediction
Energy consumption = 158.296844 pJ
sum error= 307
Actual label: 7
Output voltages: [0.16292, 0.40344, 0.70698, 0.019592, 0.03243, 0.0011541, 0.0013123, 0.79877, 0.02514, 0.046649]
Predicted label: 7
Correct prediction
Energy consumption = 142.663985 pJ
sum error= 307
Actual label: 6
Output voltages: [0.099979, 0.01363, 0.31757, 0.0010696, 0.32497, 0.30982, 0.79877, 0.0017914, 0.63534, 0.003354]
Predicted label: 6
Correct prediction
Energy consumption = 147.277675 pJ
sum error= 307
Actual label: 8
Output voltages: [0.13819, 0.071617, 0.02791, 0.46098, 0.0044421, 0.19099, 0.051896, 0.0032741, 0.79876, 0.018565]
Predicted label: 8
Correct prediction
Energy consumption = 144.284818 pJ
sum error= 307
Actual label: 4
Output voltages: [0.0082447, 0.034404, 0.044842, 0.02617, 0.79873, 0.0020816, 0.04837, 0.16936, 0.010208, 0.026622]
Predicted label: 4
Correct prediction
Energy consumption = 149.126409 pJ
sum error= 307
Actual label: 1
Output voltages: [0.030678, 0.79667, 0.048725, 0.0046835, 0.50561, 0.0011737, 0.01306, 0.013515, 0.051441, 0.019114]
Predicted label: 1
Correct prediction
Energy consumption = 141.224141 pJ
sum error= 307
Actual label: 4
Output voltages: [0.030586, 0.0048318, 0.11569, 0.029512, 0.79873, 0.031077, 0.43978, 0.027328, 0.053417, 0.0027623]
Predicted label: 4
Correct prediction
Energy consumption = 136.891511 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 669 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 669 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 669 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.021864, 0.029198, 0.065684, 0.79879, 0.025088, 0.03313, 0.0023756, 0.039672, 0.79314, 0.021352]
Predicted label: 3
Correct prediction
Energy consumption = 139.328807 pJ
sum error= 307
Actual label: 6
Output voltages: [0.11197, 0.022985, 0.054096, 0.012154, 0.19887, 0.4215, 0.7941, 0.00107, 0.78673, 0.010093]
Predicted label: 6
Correct prediction
Energy consumption = 144.934879 pJ
sum error= 307
Actual label: 9
Output voltages: [0.30693, 0.0024043, 0.0028696, 0.024565, 0.14001, 0.041445, 0.0012524, 0.062132, 0.45471, 0.79781]
Predicted label: 9
Correct prediction
Energy consumption = 139.929560 pJ
sum error= 307
Actual label: 6
Output voltages: [0.27229, 0.013136, 0.049612, 0.0052629, 0.43772, 0.048426, 0.79859, 0.0012392, 0.70042, 0.0085746]
Predicted label: 6
Correct prediction
Energy consumption = 141.229562 pJ
sum error= 307
Actual label: 1
Output voltages: [0.049419, 0.79788, 0.37644, 0.030117, 0.4663, 0.0010663, 0.091262, 0.017412, 0.21377, 0.0022882]
Predicted label: 1
Correct prediction
Energy consumption = 148.344680 pJ
sum error= 307
Actual label: 4
Output voltages: [0.015659, 0.0012508, 0.48233, 0.034294, 0.79877, 0.0011319, 0.001603, 0.013274, 0.23222, 0.041785]
Predicted label: 4
Correct prediction
Energy consumption = 141.289246 pJ
sum error= 307
Actual label: 4
Output voltages: [0.015272, 0.0076563, 0.2452, 0.06114, 0.79878, 0.001079, 0.014629, 0.046729, 0.022188, 0.024044]
Predicted label: 4
Correct prediction
Energy consumption = 140.343417 pJ
sum error= 307
Actual label: 7
Output voltages: [0.21914, 0.034678, 0.13236, 0.26415, 0.0016523, 0.0017343, 0.0011572, 0.79873, 0.30022, 0.25605]
Predicted label: 7
Correct prediction
Energy consumption = 148.613636 pJ
sum error= 307
Actual label: 2
Output voltages: [0.54265, 0.0094369, 0.79874, 0.032541, 0.021961, 0.0010879, 0.029793, 0.029557, 0.47016, 0.0036053]
Predicted label: 2
Correct prediction
Energy consumption = 142.995784 pJ
sum error= 307
Actual label: 4
Output voltages: [0.0062486, 0.1246, 0.23327, 0.040207, 0.79877, 0.0010707, 0.034519, 0.078411, 0.0020203, 0.47947]
Predicted label: 4
Correct prediction
Energy consumption = 151.702149 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 670 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 670 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 670 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.25996, 0.10873, 0.069121, 0.0050509, 0.79878, 0.0040684, 0.56707, 0.0026219, 0.037394, 0.044501]
Predicted label: 4
Correct prediction
Energy consumption = 149.173608 pJ
sum error= 307
Actual label: 0
Output voltages: [0.79843, 0.033942, 0.040834, 0.010776, 0.016493, 0.0013571, 0.66547, 0.030687, 0.30285, 0.043773]
Predicted label: 0
Correct prediction
Energy consumption = 151.637894 pJ
sum error= 307
Actual label: 1
Output voltages: [0.0026165, 0.79851, 0.034821, 0.018179, 0.0061584, 0.0022074, 0.70232, 0.014315, 0.42282, 0.018814]
Predicted label: 1
Correct prediction
Energy consumption = 157.032347 pJ
sum error= 307
Actual label: 2
Output voltages: [0.59832, 0.010667, 0.79877, 0.19501, 0.013592, 0.0011278, 0.01379, 0.044764, 0.45203, 0.0047068]
Predicted label: 2
Correct prediction
Energy consumption = 146.867698 pJ
sum error= 307
Actual label: 3
Output voltages: [0.57051, 0.0074349, 0.48774, 0.79879, 0.0039882, 0.0013043, 0.0016353, 0.0056487, 0.5684, 0.0068505]
Predicted label: 3
Correct prediction
Energy consumption = 131.552178 pJ
sum error= 307
Actual label: 4
Output voltages: [0.035686, 0.0090691, 0.169, 0.0018591, 0.79867, 0.026341, 0.15425, 0.049835, 0.17185, 0.0052135]
Predicted label: 4
Correct prediction
Energy consumption = 153.547583 pJ
sum error= 307
Actual label: 5
Output voltages: [0.029895, 0.0018837, 0.0095689, 0.55151, 0.020484, 0.79013, 0.036764, 0.23527, 0.44296, 0.66051]
Predicted label: 5
Correct prediction
Energy consumption = 137.110721 pJ
sum error= 307
Actual label: 6
Output voltages: [0.14594, 0.035187, 0.29626, 0.0017249, 0.34905, 0.049259, 0.79879, 0.0012587, 0.29553, 0.0054061]
Predicted label: 6
Correct prediction
Energy consumption = 143.918737 pJ
sum error= 307
Actual label: 7
Output voltages: [0.42396, 0.012546, 0.25874, 0.025834, 0.016736, 0.001128, 0.0012162, 0.79798, 0.62319, 0.35883]
Predicted label: 7
Correct prediction
Energy consumption = 143.497551 pJ
sum error= 307
Actual label: 8
Output voltages: [0.01162, 0.025247, 0.019116, 0.027205, 0.011015, 0.093736, 0.3893, 0.0097611, 0.79866, 0.0087553]
Predicted label: 8
Correct prediction
Energy consumption = 141.464868 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 671 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 671 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 671 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.74939, 0.0082348, 0.0061753, 0.030094, 0.039043, 0.018451, 0.048861, 0.010954, 0.33192, 0.79693]
Predicted label: 9
Correct prediction
Energy consumption = 150.645508 pJ
sum error= 307
Actual label: 0
Output voltages: [0.79875, 0.074706, 0.13561, 0.033677, 0.0077338, 0.0017766, 0.18677, 0.012933, 0.33219, 0.063868]
Predicted label: 0
Correct prediction
Energy consumption = 144.076803 pJ
sum error= 307
Actual label: 1
Output voltages: [0.028947, 0.79863, 0.28103, 0.0050546, 0.15039, 0.0038474, 0.45711, 0.0016243, 0.10718, 0.014166]
Predicted label: 1
Correct prediction
Energy consumption = 153.046533 pJ
sum error= 307
Actual label: 2
Output voltages: [0.606, 0.0027996, 0.79875, 0.14645, 0.010264, 0.0010905, 0.025896, 0.087897, 0.70325, 0.0050026]
Predicted label: 2
Correct prediction
Energy consumption = 144.656479 pJ
sum error= 307
Actual label: 3
Output voltages: [0.21432, 0.027442, 0.036173, 0.79859, 0.015349, 0.017237, 0.010594, 0.02152, 0.54741, 0.047374]
Predicted label: 3
Correct prediction
Energy consumption = 135.622824 pJ
sum error= 307
Actual label: 4
Output voltages: [0.034026, 0.010249, 0.045035, 0.0065102, 0.79875, 0.0045536, 0.3614, 0.030503, 0.11764, 0.0028728]
Predicted label: 4
Correct prediction
Energy consumption = 143.575552 pJ
sum error= 307
Actual label: 5
Output voltages: [0.053636, 0.0017328, 0.0010888, 0.25752, 0.34922, 0.79878, 0.58375, 0.0026383, 0.40296, 0.033824]
Predicted label: 5
Correct prediction
Energy consumption = 134.558273 pJ
sum error= 307
Actual label: 6
Output voltages: [0.038521, 0.028569, 0.38816, 0.0011822, 0.39376, 0.037168, 0.79876, 0.001076, 0.27148, 0.0045317]
Predicted label: 6
Correct prediction
Energy consumption = 139.057553 pJ
sum error= 307
Actual label: 9
Output voltages: [0.25438, 0.0020927, 0.014965, 0.0093336, 0.10027, 0.017568, 0.030084, 0.0066407, 0.68277, 0.77882]
Predicted label: 9
Correct prediction
Energy consumption = 138.964481 pJ
sum error= 307
Actual label: 0
Output voltages: [0.79877, 0.037317, 0.074367, 0.029697, 0.021478, 0.0030839, 0.49795, 0.026565, 0.05971, 0.33399]
Predicted label: 0
Correct prediction
Energy consumption = 139.373907 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 672 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 672 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 672 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0084643, 0.79878, 0.014392, 0.060309, 0.75634, 0.0011094, 0.075117, 0.0011777, 0.042661, 0.33932]
Predicted label: 1
Correct prediction
Energy consumption = 159.176976 pJ
sum error= 307
Actual label: 2
Output voltages: [0.021561, 0.023849, 0.79878, 0.069558, 0.048089, 0.0012016, 0.028491, 0.62165, 0.40315, 0.046328]
Predicted label: 2
Correct prediction
Energy consumption = 131.334801 pJ
sum error= 307
Actual label: 3
Output voltages: [0.63473, 0.0032299, 0.44574, 0.79879, 0.0066173, 0.006489, 0.0014255, 0.0012994, 0.60274, 0.0069683]
Predicted label: 3
Correct prediction
Energy consumption = 134.907219 pJ
sum error= 307
Actual label: 4
Output voltages: [0.017889, 0.018167, 0.21493, 0.0030131, 0.79865, 0.00113, 0.27106, 0.046458, 0.030188, 0.01454]
Predicted label: 4
Correct prediction
Energy consumption = 142.660086 pJ
sum error= 307
Actual label: 7
Output voltages: [0.042468, 0.05376, 0.041503, 0.13445, 0.0084084, 0.0011103, 0.0011275, 0.79878, 0.42561, 0.50205]
Predicted label: 7
Correct prediction
Energy consumption = 144.790619 pJ
sum error= 307
Actual label: 8
Output voltages: [0.017019, 0.010141, 0.22666, 0.016692, 0.19597, 0.0056305, 0.32426, 0.0010666, 0.79863, 0.11372]
Predicted label: 8
Correct prediction
Energy consumption = 133.109091 pJ
sum error= 307
Actual label: 1
Output voltages: [0.030058, 0.79872, 0.27206, 0.020781, 0.43963, 0.0024223, 0.11641, 0.012882, 0.05276, 0.012649]
Predicted label: 1
Correct prediction
Energy consumption = 158.365911 pJ
sum error= 307
Actual label: 3
Output voltages: [0.039372, 0.0095089, 0.037949, 0.79871, 0.050238, 0.0022312, 0.013283, 0.1887, 0.73881, 0.041447]
Predicted label: 3
Correct prediction
Energy consumption = 145.705052 pJ
sum error= 307
Actual label: 5
Output voltages: [0.25508, 0.0012464, 0.001432, 0.46761, 0.0094014, 0.79869, 0.2605, 0.060644, 0.74945, 0.0060993]
Predicted label: 5
Correct prediction
Energy consumption = 144.192924 pJ
sum error= 307
Actual label: 1
Output voltages: [0.008478, 0.79849, 0.04384, 0.016699, 0.051626, 0.0016288, 0.66152, 0.021357, 0.23519, 0.022657]
Predicted label: 1
Correct prediction
Energy consumption = 153.426426 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 673 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 673 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 673 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.03934, 0.026418, 0.18299, 0.13079, 0.033998, 0.001117, 0.0012129, 0.79871, 0.54271, 0.15117]
Predicted label: 7
Correct prediction
Energy consumption = 138.462225 pJ
sum error= 307
Actual label: 7
Output voltages: [0.056311, 0.47209, 0.14516, 0.161, 0.022115, 0.0012982, 0.0011171, 0.79879, 0.051744, 0.42493]
Predicted label: 7
Correct prediction
Energy consumption = 130.481116 pJ
sum error= 307
Actual label: 2
Output voltages: [0.23711, 0.025914, 0.79874, 0.33108, 0.035642, 0.0012102, 0.02094, 0.1429, 0.15896, 0.029357]
Predicted label: 2
Correct prediction
Energy consumption = 130.874063 pJ
sum error= 307
Actual label: 1
Output voltages: [0.016315, 0.79874, 0.10511, 0.0098977, 0.056011, 0.018439, 0.51639, 0.0018181, 0.46057, 0.014965]
Predicted label: 1
Correct prediction
Energy consumption = 148.421727 pJ
sum error= 307
Actual label: 4
Output voltages: [0.024401, 0.030389, 0.093982, 0.0075059, 0.79872, 0.0078276, 0.35894, 0.059154, 0.10008, 0.0084071]
Predicted label: 4
Correct prediction
Energy consumption = 141.857871 pJ
sum error= 307
Actual label: 8
Output voltages: [0.3077, 0.096405, 0.024936, 0.028086, 0.015061, 0.048552, 0.1264, 0.0018475, 0.79879, 0.02928]
Predicted label: 8
Correct prediction
Energy consumption = 146.381481 pJ
sum error= 307
Actual label: 3
Output voltages: [0.36849, 0.005291, 0.1203, 0.79875, 0.044845, 0.030078, 0.0068286, 0.0031263, 0.57061, 0.032235]
Predicted label: 3
Correct prediction
Energy consumption = 147.294343 pJ
sum error= 307
Actual label: 4
Output voltages: [0.055526, 0.0021743, 0.14725, 0.0013439, 0.79873, 0.0035766, 0.23521, 0.020054, 0.37226, 0.0011749]
Predicted label: 4
Correct prediction
Energy consumption = 144.442433 pJ
sum error= 307
Actual label: 4
Output voltages: [0.004532, 0.03879, 0.045421, 0.0099813, 0.79865, 0.027283, 0.37513, 0.38715, 0.019625, 0.010363]
Predicted label: 4
Correct prediction
Energy consumption = 138.990312 pJ
sum error= 307
Actual label: 3
Output voltages: [0.29202, 0.0012482, 0.42467, 0.79869, 0.0010959, 0.036496, 0.0011448, 0.02822, 0.78773, 0.0066344]
Predicted label: 3
Correct prediction
Energy consumption = 140.680201 pJ
sum error= 307
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 674 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 674 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 674 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.77276, 0.0012193, 0.029945, 0.042169, 0.0073214, 0.016534, 0.039319, 0.024402, 0.19702, 0.7581]
Predicted label: 0
Wrong prediction!
Energy consumption = 146.807555 pJ
sum error= 308
Actual label: 7
Output voltages: [0.32312, 0.007772, 0.029917, 0.079679, 0.024166, 0.0068671, 0.0013319, 0.79879, 0.52154, 0.54914]
Predicted label: 7
Correct prediction
Energy consumption = 135.784223 pJ
sum error= 308
Actual label: 4
Output voltages: [0.023095, 0.0073998, 0.2324, 0.019031, 0.79861, 0.0011579, 0.038893, 0.015936, 0.031892, 0.027531]
Predicted label: 4
Correct prediction
Energy consumption = 142.657336 pJ
sum error= 308
Actual label: 1
Output voltages: [0.052342, 0.79838, 0.30244, 0.0355, 0.4101, 0.0011118, 0.085812, 0.0041993, 0.030429, 0.014838]
Predicted label: 1
Correct prediction
Energy consumption = 148.897796 pJ
sum error= 308
Actual label: 2
Output voltages: [0.016401, 0.0029704, 0.79658, 0.12821, 0.0048506, 0.0010901, 0.050197, 0.78795, 0.76868, 0.0023093]
Predicted label: 2
Correct prediction
Energy consumption = 134.157610 pJ
sum error= 308
Actual label: 3
Output voltages: [0.26298, 0.0041713, 0.05374, 0.79876, 0.038451, 0.097443, 0.027238, 0.0060725, 0.37188, 0.023585]
Predicted label: 3
Correct prediction
Energy consumption = 144.218856 pJ
sum error= 308
Actual label: 5
Output voltages: [0.026283, 0.001074, 0.0040571, 0.030936, 0.22044, 0.78208, 0.55278, 0.0016516, 0.73902, 0.0017101]
Predicted label: 5
Correct prediction
Energy consumption = 125.244692 pJ
sum error= 308
Actual label: 9
Output voltages: [0.44894, 0.0018554, 0.013339, 0.055799, 0.49354, 0.0027648, 0.00281, 0.0012067, 0.57203, 0.78143]
Predicted label: 9
Correct prediction
Energy consumption = 143.297606 pJ
sum error= 308
Actual label: 1
Output voltages: [0.0065914, 0.79853, 0.054925, 0.0032109, 0.12595, 0.0013778, 0.4351, 0.00137, 0.54607, 0.12059]
Predicted label: 1
Correct prediction
Energy consumption = 150.618267 pJ
sum error= 308
Actual label: 6
Output voltages: [0.28701, 0.025772, 0.034271, 0.052053, 0.27559, 0.4669, 0.79868, 0.0053846, 0.63133, 0.019024]
Predicted label: 6
Correct prediction
Energy consumption = 143.212801 pJ
sum error= 308
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 675 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 675 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 675 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.02919, 0.12792, 0.0038478, 0.0037423, 0.0023953, 0.55954, 0.030824, 0.11266, 0.30305]
Predicted label: 0
Correct prediction
Energy consumption = 145.614671 pJ
sum error= 308
Actual label: 1
Output voltages: [0.16993, 0.79681, 0.15124, 0.0083429, 0.63071, 0.0013423, 0.042273, 0.0015665, 0.089375, 0.1949]
Predicted label: 1
Correct prediction
Energy consumption = 156.345874 pJ
sum error= 308
Actual label: 0
Output voltages: [0.79879, 0.17148, 0.094312, 0.022331, 0.0080831, 0.0021839, 0.40754, 0.014762, 0.10179, 0.14798]
Predicted label: 0
Correct prediction
Energy consumption = 141.863748 pJ
sum error= 308
Actual label: 0
Output voltages: [0.79873, 0.11478, 0.047488, 0.010639, 0.01342, 0.0085941, 0.49411, 0.017463, 0.069386, 0.052019]
Predicted label: 0
Correct prediction
Energy consumption = 132.488196 pJ
sum error= 308
Actual label: 2
Output voltages: [0.03451, 0.014398, 0.7966, 0.5138, 0.090272, 0.0013647, 0.010198, 0.53598, 0.13752, 0.035521]
Predicted label: 2
Correct prediction
Energy consumption = 140.353917 pJ
sum error= 308
Actual label: 8
Output voltages: [0.15157, 0.02759, 0.1649, 0.036864, 0.016151, 0.0045289, 0.0045894, 0.008166, 0.79877, 0.57756]
Predicted label: 8
Correct prediction
Energy consumption = 147.904307 pJ
sum error= 308
Actual label: 7
Output voltages: [0.29323, 0.0043973, 0.73575, 0.057125, 0.0085312, 0.001081, 0.0010666, 0.76379, 0.78125, 0.24816]
Predicted label: 8
Wrong prediction!
Energy consumption = 130.736504 pJ
sum error= 309
Actual label: 1
Output voltages: [0.15751, 0.7986, 0.29069, 0.041067, 0.12245, 0.001379, 0.42134, 0.0013626, 0.097602, 0.042117]
Predicted label: 1
Correct prediction
Energy consumption = 150.927115 pJ
sum error= 309
Actual label: 1
Output voltages: [0.018215, 0.79803, 0.19774, 0.038755, 0.19483, 0.001228, 0.41973, 0.0060189, 0.033109, 0.23936]
Predicted label: 1
Correct prediction
Energy consumption = 134.144328 pJ
sum error= 309
Actual label: 4
Output voltages: [0.027691, 0.0015631, 0.27853, 0.0010673, 0.79877, 0.0017741, 0.20359, 0.032884, 0.36944, 0.003974]
Predicted label: 4
Correct prediction
Energy consumption = 137.216745 pJ
sum error= 309
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 676 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 676 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 676 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79773, 0.044017, 0.018323, 0.01268, 0.0079333, 0.0079772, 0.77916, 0.0079193, 0.30983, 0.12407]
Predicted label: 0
Correct prediction
Energy consumption = 144.854049 pJ
sum error= 309
Actual label: 4
Output voltages: [0.022118, 0.0049128, 0.027916, 0.0279, 0.79876, 0.0017461, 0.20119, 0.018003, 0.048238, 0.0020178]
Predicted label: 4
Correct prediction
Energy consumption = 140.364053 pJ
sum error= 309
Actual label: 7
Output voltages: [0.2278, 0.018164, 0.75304, 0.070538, 0.0025621, 0.0011199, 0.0011002, 0.79868, 0.61399, 0.17579]
Predicted label: 7
Correct prediction
Energy consumption = 144.832476 pJ
sum error= 309
Actual label: 3
Output voltages: [0.66459, 0.0020384, 0.32141, 0.79874, 0.048267, 0.024754, 0.0012728, 0.0014783, 0.57019, 0.013052]
Predicted label: 3
Correct prediction
Energy consumption = 143.807145 pJ
sum error= 309
Actual label: 6
Output voltages: [0.044905, 0.0020096, 0.069563, 0.0056526, 0.29901, 0.40652, 0.79879, 0.0012542, 0.47403, 0.015578]
Predicted label: 6
Correct prediction
Energy consumption = 145.283740 pJ
sum error= 309
Actual label: 8
Output voltages: [0.27193, 0.002228, 0.0026674, 0.058149, 0.30166, 0.33367, 0.63599, 0.0011115, 0.79564, 0.0050617]
Predicted label: 8
Correct prediction
Energy consumption = 129.610863 pJ
sum error= 309
Actual label: 0
Output voltages: [0.79876, 0.040927, 0.044785, 0.024379, 0.020127, 0.0076564, 0.29877, 0.015264, 0.13364, 0.26703]
Predicted label: 0
Correct prediction
Energy consumption = 146.354127 pJ
sum error= 309
Actual label: 3
Output voltages: [0.67766, 0.0029739, 0.25231, 0.79877, 0.0068283, 0.023274, 0.011668, 0.045746, 0.75656, 0.0029455]
Predicted label: 3
Correct prediction
Energy consumption = 143.805674 pJ
sum error= 309
Actual label: 7
Output voltages: [0.010926, 0.02917, 0.78244, 0.19516, 0.0026497, 0.0011827, 0.0011118, 0.7969, 0.64447, 0.014491]
Predicted label: 7
Correct prediction
Energy consumption = 137.789300 pJ
sum error= 309
Actual label: 4
Output voltages: [0.046731, 0.0075764, 0.3903, 0.0015075, 0.79737, 0.0058937, 0.054084, 0.0058141, 0.68269, 0.0030159]
Predicted label: 4
Correct prediction
Energy consumption = 141.947638 pJ
sum error= 309
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 677 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 677 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 677 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79869, 0.028454, 0.13544, 0.014108, 0.0056412, 0.010388, 0.2926, 0.038204, 0.03847, 0.040391]
Predicted label: 0
Correct prediction
Energy consumption = 148.431027 pJ
sum error= 309
Actual label: 6
Output voltages: [0.064877, 0.040544, 0.35507, 0.0038882, 0.41976, 0.14059, 0.79874, 0.0024397, 0.40637, 0.0064264]
Predicted label: 6
Correct prediction
Energy consumption = 139.088403 pJ
sum error= 309
Actual label: 9
Output voltages: [0.36178, 0.0068701, 0.020745, 0.0321, 0.73151, 0.0033414, 0.0024138, 0.0010664, 0.23769, 0.78955]
Predicted label: 9
Correct prediction
Energy consumption = 150.082909 pJ
sum error= 309
Actual label: 2
Output voltages: [0.54583, 0.0016442, 0.79863, 0.19942, 0.010446, 0.0010928, 0.03445, 0.060502, 0.71733, 0.005785]
Predicted label: 2
Correct prediction
Energy consumption = 148.368704 pJ
sum error= 309
Actual label: 6
Output voltages: [0.032961, 0.026068, 0.43424, 0.0012391, 0.15088, 0.052865, 0.79879, 0.0016024, 0.60088, 0.0015148]
Predicted label: 6
Correct prediction
Energy consumption = 141.331127 pJ
sum error= 309
Actual label: 5
Output voltages: [0.022591, 0.0011981, 0.0013495, 0.25411, 0.0098821, 0.79683, 0.087613, 0.016888, 0.75386, 0.054383]
Predicted label: 5
Correct prediction
Energy consumption = 135.514220 pJ
sum error= 309
Actual label: 8
Output voltages: [0.0095938, 0.020018, 0.2361, 0.043099, 0.0074699, 0.031638, 0.1093, 0.02114, 0.79866, 0.009714]
Predicted label: 8
Correct prediction
Energy consumption = 142.259723 pJ
sum error= 309
Actual label: 6
Output voltages: [0.13932, 0.12987, 0.32752, 0.0030113, 0.24662, 0.032785, 0.79879, 0.0010725, 0.6842, 0.026995]
Predicted label: 6
Correct prediction
Energy consumption = 146.527747 pJ
sum error= 309
Actual label: 9
Output voltages: [0.12371, 0.012829, 0.027346, 0.016295, 0.07096, 0.01437, 0.003572, 0.015413, 0.59757, 0.79785]
Predicted label: 9
Correct prediction
Energy consumption = 149.050661 pJ
sum error= 309
Actual label: 0
Output voltages: [0.7986, 0.065153, 0.012236, 0.015681, 0.026795, 0.052849, 0.18413, 0.0084417, 0.16997, 0.047294]
Predicted label: 0
Correct prediction
Energy consumption = 147.414444 pJ
sum error= 309
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 678 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 678 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 678 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.06208, 0.0011757, 0.50225, 0.004038, 0.76596, 0.0028132, 0.026219, 0.0010721, 0.75422, 0.20125]
Predicted label: 4
Correct prediction
Energy consumption = 144.919109 pJ
sum error= 309
Actual label: 0
Output voltages: [0.79612, 0.052339, 0.051868, 0.016893, 0.051874, 0.001171, 0.7723, 0.0060882, 0.44553, 0.053495]
Predicted label: 0
Correct prediction
Energy consumption = 140.759208 pJ
sum error= 309
Actual label: 6
Output voltages: [0.059255, 0.0019401, 0.027491, 0.017468, 0.36347, 0.096776, 0.79802, 0.001081, 0.76308, 0.044165]
Predicted label: 6
Correct prediction
Energy consumption = 138.438779 pJ
sum error= 309
Actual label: 1
Output voltages: [0.050437, 0.46104, 0.12043, 0.053925, 0.5169, 0.024357, 0.79383, 0.003613, 0.63933, 0.002473]
Predicted label: 6
Wrong prediction!
Energy consumption = 153.195746 pJ
sum error= 310
Actual label: 9
Output voltages: [0.54169, 0.0015915, 0.022301, 0.041892, 0.67115, 0.0011181, 0.0021039, 0.0058359, 0.30062, 0.77941]
Predicted label: 9
Correct prediction
Energy consumption = 142.908083 pJ
sum error= 310
Actual label: 2
Output voltages: [0.023981, 0.0014826, 0.7867, 0.76907, 0.038805, 0.0010661, 0.023092, 0.023059, 0.61674, 0.0037016]
Predicted label: 2
Correct prediction
Energy consumption = 128.415944 pJ
sum error= 310
Actual label: 0
Output voltages: [0.79879, 0.037581, 0.1739, 0.011501, 0.026117, 0.0015811, 0.38435, 0.024341, 0.22045, 0.030269]
Predicted label: 0
Correct prediction
Energy consumption = 149.559416 pJ
sum error= 310
Actual label: 9
Output voltages: [0.29933, 0.0050127, 0.0050997, 0.03446, 0.31078, 0.0012801, 0.0013856, 0.010821, 0.68183, 0.79765]
Predicted label: 9
Correct prediction
Energy consumption = 151.082738 pJ
sum error= 310
Actual label: 5
Output voltages: [0.033371, 0.0073652, 0.013317, 0.7969, 0.039654, 0.75308, 0.025401, 0.0046179, 0.59897, 0.0055972]
Predicted label: 3
Wrong prediction!
Energy consumption = 133.846339 pJ
sum error= 311
Actual label: 1
Output voltages: [0.020481, 0.79874, 0.40037, 0.033965, 0.52796, 0.0010904, 0.39726, 0.010651, 0.010071, 0.021322]
Predicted label: 1
Correct prediction
Energy consumption = 152.814769 pJ
sum error= 311
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 679 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 679 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 679 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.19022, 0.0013881, 0.60194, 0.79791, 0.036513, 0.025098, 0.0012952, 0.0010913, 0.56472, 0.067113]
Predicted label: 3
Correct prediction
Energy consumption = 145.236244 pJ
sum error= 311
Actual label: 7
Output voltages: [0.023412, 0.2323, 0.66433, 0.022035, 0.015214, 0.0010882, 0.0011505, 0.79876, 0.40855, 0.061911]
Predicted label: 7
Correct prediction
Energy consumption = 139.228621 pJ
sum error= 311
Actual label: 6
Output voltages: [0.24562, 0.030023, 0.057409, 0.0093968, 0.28313, 0.074207, 0.79878, 0.0011282, 0.52002, 0.026693]
Predicted label: 6
Correct prediction
Energy consumption = 149.322064 pJ
sum error= 311
Actual label: 9
Output voltages: [0.31975, 0.0053901, 0.041937, 0.024542, 0.2267, 0.0082188, 0.0091106, 0.018007, 0.67717, 0.79136]
Predicted label: 9
Correct prediction
Energy consumption = 144.781269 pJ
sum error= 311
Actual label: 3
Output voltages: [0.24838, 0.0017268, 0.033915, 0.79879, 0.022965, 0.012357, 0.0022469, 0.34719, 0.76425, 0.031515]
Predicted label: 3
Correct prediction
Energy consumption = 139.574206 pJ
sum error= 311
Actual label: 0
Output voltages: [0.79878, 0.027439, 0.0085214, 0.013583, 0.037636, 0.012009, 0.5488, 0.0064663, 0.089508, 0.02723]
Predicted label: 0
Correct prediction
Energy consumption = 145.536753 pJ
sum error= 311
Actual label: 2
Output voltages: [0.49116, 0.0026261, 0.7923, 0.027662, 0.032278, 0.0010759, 0.0016676, 0.79773, 0.081087, 0.010507]
Predicted label: 7
Wrong prediction!
Energy consumption = 131.909828 pJ
sum error= 312
Actual label: 2
Output voltages: [0.4683, 0.10282, 0.79871, 0.047883, 0.0040411, 0.0011851, 0.037293, 0.29372, 0.40974, 0.018599]
Predicted label: 2
Correct prediction
Energy consumption = 141.028740 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79878, 0.24343, 0.012788, 0.015886, 0.030996, 0.015689, 0.4341, 0.026247, 0.035045, 0.16116]
Predicted label: 0
Correct prediction
Energy consumption = 149.366279 pJ
sum error= 312
Actual label: 1
Output voltages: [0.008344, 0.7985, 0.044388, 0.13757, 0.031316, 0.0013131, 0.68607, 0.0098224, 0.144, 0.020012]
Predicted label: 1
Correct prediction
Energy consumption = 161.031925 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 680 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 680 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 680 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.20234, 0.15699, 0.78007, 0.6628, 0.0064675, 0.0012024, 0.41708, 0.0028982, 0.51214, 0.012648]
Predicted label: 2
Correct prediction
Energy consumption = 150.780129 pJ
sum error= 312
Actual label: 3
Output voltages: [0.51946, 0.0049992, 0.41179, 0.79877, 0.0031388, 0.016864, 0.023602, 0.034696, 0.34108, 0.0035409]
Predicted label: 3
Correct prediction
Energy consumption = 139.612083 pJ
sum error= 312
Actual label: 4
Output voltages: [0.0020955, 0.0077331, 0.041869, 0.0011464, 0.79865, 0.010625, 0.29107, 0.14712, 0.32922, 0.029261]
Predicted label: 4
Correct prediction
Energy consumption = 158.332476 pJ
sum error= 312
Actual label: 5
Output voltages: [0.02267, 0.0010692, 0.0018899, 0.067373, 0.17481, 0.79873, 0.46353, 0.026101, 0.60589, 0.033699]
Predicted label: 5
Correct prediction
Energy consumption = 141.075422 pJ
sum error= 312
Actual label: 6
Output voltages: [0.15086, 0.035752, 0.1268, 0.0063367, 0.46886, 0.41055, 0.79872, 0.0058789, 0.50438, 0.0067746]
Predicted label: 6
Correct prediction
Energy consumption = 140.996197 pJ
sum error= 312
Actual label: 7
Output voltages: [0.063248, 0.25348, 0.21699, 0.26861, 0.0019808, 0.0011554, 0.0040265, 0.79879, 0.021587, 0.54916]
Predicted label: 7
Correct prediction
Energy consumption = 164.447896 pJ
sum error= 312
Actual label: 8
Output voltages: [0.048277, 0.056183, 0.035125, 0.57763, 0.0012133, 0.013292, 0.0041969, 0.0017741, 0.79831, 0.25188]
Predicted label: 8
Correct prediction
Energy consumption = 146.617068 pJ
sum error= 312
Actual label: 9
Output voltages: [0.16016, 0.010152, 0.026172, 0.030455, 0.074643, 0.032835, 0.0050195, 0.072403, 0.71832, 0.7934]
Predicted label: 9
Correct prediction
Energy consumption = 150.931884 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79879, 0.041302, 0.045083, 0.027649, 0.022352, 0.020855, 0.58991, 0.027906, 0.046351, 0.046813]
Predicted label: 0
Correct prediction
Energy consumption = 155.072444 pJ
sum error= 312
Actual label: 1
Output voltages: [0.066541, 0.7984, 0.0040643, 0.041957, 0.030535, 0.0029457, 0.209, 0.0084357, 0.26802, 0.18895]
Predicted label: 1
Correct prediction
Energy consumption = 163.946287 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 681 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 681 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 681 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.40812, 0.59133, 0.79831, 0.027607, 0.021212, 0.0013974, 0.43929, 0.036642, 0.2974, 0.080996]
Predicted label: 2
Correct prediction
Energy consumption = 156.310353 pJ
sum error= 312
Actual label: 3
Output voltages: [0.31613, 0.0078696, 0.035968, 0.79865, 0.23309, 0.041346, 0.047692, 0.014241, 0.42784, 0.033983]
Predicted label: 3
Correct prediction
Energy consumption = 146.733789 pJ
sum error= 312
Actual label: 4
Output voltages: [0.017474, 0.02837, 0.091426, 0.0016915, 0.79866, 0.0016076, 0.33122, 0.03204, 0.031482, 0.035691]
Predicted label: 4
Correct prediction
Energy consumption = 155.898488 pJ
sum error= 312
Actual label: 5
Output voltages: [0.010234, 0.001103, 0.0015225, 0.032314, 0.047544, 0.79721, 0.1498, 0.015219, 0.78704, 0.028348]
Predicted label: 5
Correct prediction
Energy consumption = 140.042310 pJ
sum error= 312
Actual label: 6
Output voltages: [0.051289, 0.0053282, 0.037328, 0.0073011, 0.57538, 0.19762, 0.79876, 0.0017665, 0.76439, 0.0085608]
Predicted label: 6
Correct prediction
Energy consumption = 137.673290 pJ
sum error= 312
Actual label: 7
Output voltages: [0.069625, 0.015989, 0.043779, 0.044803, 0.016307, 0.010904, 0.0010739, 0.79853, 0.075975, 0.39488]
Predicted label: 7
Correct prediction
Energy consumption = 155.035218 pJ
sum error= 312
Actual label: 8
Output voltages: [0.025335, 0.018048, 0.3095, 0.44671, 0.0090769, 0.0030175, 0.052288, 0.02789, 0.79868, 0.19198]
Predicted label: 8
Correct prediction
Energy consumption = 152.168336 pJ
sum error= 312
Actual label: 9
Output voltages: [0.30091, 0.0039315, 0.0034187, 0.035595, 0.10487, 0.0038839, 0.0010664, 0.2687, 0.48018, 0.79458]
Predicted label: 9
Correct prediction
Energy consumption = 156.613777 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79877, 0.018404, 0.011418, 0.11295, 0.04436, 0.015662, 0.49764, 0.0097402, 0.23539, 0.052537]
Predicted label: 0
Correct prediction
Energy consumption = 151.949134 pJ
sum error= 312
Actual label: 1
Output voltages: [0.0024854, 0.79853, 0.064653, 0.050242, 0.03871, 0.0050185, 0.75184, 0.0018637, 0.16344, 0.18211]
Predicted label: 1
Correct prediction
Energy consumption = 164.629085 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 682 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 682 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 682 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.18693, 0.43452, 0.79874, 0.092618, 0.029924, 0.0013417, 0.17727, 0.027131, 0.036415, 0.018313]
Predicted label: 2
Correct prediction
Energy consumption = 153.639654 pJ
sum error= 312
Actual label: 3
Output voltages: [0.6745, 0.039988, 0.18742, 0.79874, 0.0019667, 0.034172, 0.018307, 0.080706, 0.20854, 0.0013272]
Predicted label: 3
Correct prediction
Energy consumption = 143.645042 pJ
sum error= 312
Actual label: 4
Output voltages: [0.013847, 0.001823, 0.27003, 0.007353, 0.79866, 0.0017886, 0.057072, 0.019728, 0.03735, 0.034497]
Predicted label: 4
Correct prediction
Energy consumption = 156.715003 pJ
sum error= 312
Actual label: 5
Output voltages: [0.0092201, 0.0010693, 0.0018775, 0.27184, 0.028914, 0.79864, 0.28113, 0.024139, 0.73876, 0.11548]
Predicted label: 5
Correct prediction
Energy consumption = 145.951368 pJ
sum error= 312
Actual label: 6
Output voltages: [0.21799, 0.15784, 0.26051, 0.0051078, 0.34274, 0.1853, 0.79872, 0.0011046, 0.29836, 0.009632]
Predicted label: 6
Correct prediction
Energy consumption = 144.429030 pJ
sum error= 312
Actual label: 7
Output voltages: [0.21845, 0.058782, 0.033985, 0.59329, 0.0024628, 0.0010779, 0.0010701, 0.79879, 0.28779, 0.57487]
Predicted label: 7
Correct prediction
Energy consumption = 163.148462 pJ
sum error= 312
Actual label: 8
Output voltages: [0.034433, 0.010857, 0.11872, 0.041918, 0.0081823, 0.024985, 0.033747, 0.0024332, 0.79877, 0.35717]
Predicted label: 8
Correct prediction
Energy consumption = 147.017559 pJ
sum error= 312
Actual label: 9
Output voltages: [0.16764, 0.015407, 0.0059109, 0.014802, 0.028668, 0.0012902, 0.0010697, 0.011825, 0.68104, 0.79733]
Predicted label: 9
Correct prediction
Energy consumption = 146.660634 pJ
sum error= 312
Actual label: 2
Output voltages: [0.30123, 0.23381, 0.79868, 0.061411, 0.037403, 0.0012695, 0.30438, 0.048863, 0.17304, 0.080366]
Predicted label: 2
Correct prediction
Energy consumption = 153.469829 pJ
sum error= 312
Actual label: 1
Output voltages: [0.039166, 0.79857, 0.01917, 0.038789, 0.0020129, 0.0024818, 0.25135, 0.0032345, 0.6676, 0.038934]
Predicted label: 1
Correct prediction
Energy consumption = 158.469939 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 683 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 683 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 683 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.24201, 0.02186, 0.045013, 0.079195, 0.016491, 0.01919, 0.001067, 0.79874, 0.12241, 0.68141]
Predicted label: 7
Correct prediction
Energy consumption = 154.581047 pJ
sum error= 312
Actual label: 2
Output voltages: [0.2668, 0.23634, 0.79879, 0.081183, 0.012472, 0.0013541, 0.30125, 0.0094076, 0.40943, 0.12759]
Predicted label: 2
Correct prediction
Energy consumption = 148.739946 pJ
sum error= 312
Actual label: 5
Output voltages: [0.1508, 0.001066, 0.0022432, 0.423, 0.011673, 0.79877, 0.13497, 0.036172, 0.74188, 0.040974]
Predicted label: 5
Correct prediction
Energy consumption = 146.043271 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79879, 0.081517, 0.025742, 0.032553, 0.0087177, 0.0069655, 0.47414, 0.003854, 0.037012, 0.70238]
Predicted label: 0
Correct prediction
Energy consumption = 156.269161 pJ
sum error= 312
Actual label: 8
Output voltages: [0.093938, 0.0056841, 0.05626, 0.065762, 0.0099086, 0.034234, 0.0084261, 0.0091831, 0.79874, 0.21363]
Predicted label: 8
Correct prediction
Energy consumption = 151.182940 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79851, 0.039629, 0.14216, 0.0098069, 0.013428, 0.038726, 0.66925, 0.0028533, 0.026546, 0.041289]
Predicted label: 0
Correct prediction
Energy consumption = 152.529962 pJ
sum error= 312
Actual label: 2
Output voltages: [0.30387, 0.18629, 0.76774, 0.17011, 0.0019104, 0.001203, 0.42674, 0.030013, 0.49095, 0.0034335]
Predicted label: 2
Correct prediction
Energy consumption = 152.548620 pJ
sum error= 312
Actual label: 7
Output voltages: [0.061072, 0.016597, 0.40988, 0.035735, 0.002928, 0.0010807, 0.0010766, 0.79866, 0.4726, 0.13185]
Predicted label: 7
Correct prediction
Energy consumption = 148.555193 pJ
sum error= 312
Actual label: 8
Output voltages: [0.012608, 0.068627, 0.072489, 0.049058, 0.017501, 0.006753, 0.016838, 0.029215, 0.79877, 0.2802]
Predicted label: 8
Correct prediction
Energy consumption = 147.724531 pJ
sum error= 312
Actual label: 8
Output voltages: [0.23436, 0.0079987, 0.054695, 0.24797, 0.0058585, 0.33436, 0.0046006, 0.018722, 0.79874, 0.37219]
Predicted label: 8
Correct prediction
Energy consumption = 150.357237 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 684 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 684 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 684 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.76006, 0.026565, 0.1497, 0.79873, 0.0025768, 0.018509, 0.016638, 0.027617, 0.55113, 0.0031357]
Predicted label: 3
Correct prediction
Energy consumption = 148.606763 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79876, 0.0079387, 0.31825, 0.22617, 0.0092967, 0.0051754, 0.051858, 0.0037269, 0.23688, 0.084282]
Predicted label: 0
Correct prediction
Energy consumption = 154.526426 pJ
sum error= 312
Actual label: 6
Output voltages: [0.26782, 0.26064, 0.34999, 0.030813, 0.22775, 0.081377, 0.79873, 0.0011046, 0.31256, 0.047407]
Predicted label: 6
Correct prediction
Energy consumption = 144.821053 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79879, 0.0082129, 0.034793, 0.0056933, 0.046642, 0.0061789, 0.7472, 0.02868, 0.10001, 0.27244]
Predicted label: 0
Correct prediction
Energy consumption = 151.533464 pJ
sum error= 312
Actual label: 2
Output voltages: [0.46555, 0.53641, 0.79872, 0.51237, 0.011869, 0.0011689, 0.37594, 0.0037678, 0.22992, 0.035328]
Predicted label: 2
Correct prediction
Energy consumption = 149.273183 pJ
sum error= 312
Actual label: 7
Output voltages: [0.35102, 0.042388, 0.080779, 0.47819, 0.0016639, 0.0010987, 0.0010864, 0.79865, 0.039542, 0.39333]
Predicted label: 7
Correct prediction
Energy consumption = 156.183671 pJ
sum error= 312
Actual label: 6
Output voltages: [0.077799, 0.063242, 0.26738, 0.0098174, 0.46936, 0.54465, 0.79863, 0.0073972, 0.12173, 0.027906]
Predicted label: 6
Correct prediction
Energy consumption = 147.059661 pJ
sum error= 312
Actual label: 6
Output voltages: [0.032517, 0.0098098, 0.021849, 0.0054526, 0.457, 0.19854, 0.79877, 0.013298, 0.17505, 0.030661]
Predicted label: 6
Correct prediction
Energy consumption = 137.167596 pJ
sum error= 312
Actual label: 1
Output voltages: [0.022587, 0.79834, 0.31971, 0.2816, 0.0026411, 0.0036969, 0.41144, 0.02945, 0.024652, 0.078604]
Predicted label: 1
Correct prediction
Energy consumption = 169.198487 pJ
sum error= 312
Actual label: 2
Output voltages: [0.2837, 0.49886, 0.7963, 0.32128, 0.018782, 0.0012901, 0.25707, 0.0070156, 0.22815, 0.035974]
Predicted label: 2
Correct prediction
Energy consumption = 150.309963 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 685 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 685 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 685 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.037789, 0.028198, 0.2583, 0.033091, 0.023542, 0.0060767, 0.013563, 0.002952, 0.79871, 0.11288]
Predicted label: 8
Correct prediction
Energy consumption = 155.780307 pJ
sum error= 312
Actual label: 8
Output voltages: [0.043665, 0.019969, 0.75832, 0.030403, 0.030147, 0.0012224, 0.062498, 0.002391, 0.79878, 0.17289]
Predicted label: 8
Correct prediction
Energy consumption = 139.226618 pJ
sum error= 312
Actual label: 7
Output voltages: [0.19476, 0.17108, 0.0093549, 0.29597, 0.024711, 0.0010663, 0.0014587, 0.79879, 0.0068077, 0.37218]
Predicted label: 7
Correct prediction
Energy consumption = 159.475587 pJ
sum error= 312
Actual label: 7
Output voltages: [0.062304, 0.048523, 0.050575, 0.157, 0.010752, 0.0010868, 0.0010662, 0.79865, 0.22676, 0.21881]
Predicted label: 7
Correct prediction
Energy consumption = 147.856969 pJ
sum error= 312
Actual label: 4
Output voltages: [0.0011189, 0.10172, 0.0010878, 0.0010902, 0.79863, 0.011939, 0.37924, 0.041289, 0.3307, 0.31059]
Predicted label: 4
Correct prediction
Energy consumption = 153.291753 pJ
sum error= 312
Actual label: 7
Output voltages: [0.2326, 0.0073168, 0.019632, 0.037736, 0.041437, 0.017512, 0.0010748, 0.79852, 0.13516, 0.41157]
Predicted label: 7
Correct prediction
Energy consumption = 150.697730 pJ
sum error= 312
Actual label: 7
Output voltages: [0.21216, 0.28386, 0.019695, 0.068135, 0.0055739, 0.0027135, 0.001094, 0.79874, 0.012599, 0.54682]
Predicted label: 7
Correct prediction
Energy consumption = 141.802062 pJ
sum error= 312
Actual label: 3
Output voltages: [0.53056, 0.031596, 0.10696, 0.7986, 0.032253, 0.022066, 0.016486, 0.0051535, 0.54289, 0.043983]
Predicted label: 3
Correct prediction
Energy consumption = 146.363132 pJ
sum error= 312
Actual label: 7
Output voltages: [0.21383, 0.0067534, 0.0021711, 0.1589, 0.023962, 0.016077, 0.001224, 0.79879, 0.10705, 0.21044]
Predicted label: 7
Correct prediction
Energy consumption = 155.469679 pJ
sum error= 312
Actual label: 4
Output voltages: [0.004192, 0.019452, 0.042689, 0.0070861, 0.79876, 0.0025049, 0.069722, 0.58261, 0.19262, 0.0045634]
Predicted label: 4
Correct prediction
Energy consumption = 147.164535 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 686 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 686 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 686 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.15778, 0.0016284, 0.0040685, 0.40735, 0.015881, 0.79879, 0.34117, 0.050076, 0.70964, 0.078791]
Predicted label: 5
Correct prediction
Energy consumption = 144.685141 pJ
sum error= 312
Actual label: 4
Output voltages: [0.01688, 0.0047255, 0.050565, 0.0092364, 0.7986, 0.0013355, 0.046371, 0.20894, 0.039267, 0.03376]
Predicted label: 4
Correct prediction
Energy consumption = 158.030070 pJ
sum error= 312
Actual label: 3
Output voltages: [0.32143, 0.043722, 0.025823, 0.7987, 0.010994, 0.0061398, 0.016706, 0.0028599, 0.47733, 0.09249]
Predicted label: 3
Correct prediction
Energy consumption = 148.685963 pJ
sum error= 312
Actual label: 3
Output voltages: [0.39469, 0.028543, 0.15468, 0.7987, 0.037208, 0.0080158, 0.016636, 0.012379, 0.56518, 0.075115]
Predicted label: 3
Correct prediction
Energy consumption = 133.895120 pJ
sum error= 312
Actual label: 8
Output voltages: [0.044462, 0.012179, 0.31636, 0.36611, 0.0011257, 0.013422, 0.0077242, 0.0081294, 0.79879, 0.093038]
Predicted label: 8
Correct prediction
Energy consumption = 152.235912 pJ
sum error= 312
Actual label: 4
Output voltages: [0.0055213, 0.011776, 0.080768, 0.015458, 0.79867, 0.0017978, 0.24794, 0.12628, 0.099518, 0.021796]
Predicted label: 4
Correct prediction
Energy consumption = 157.712275 pJ
sum error= 312
Actual label: 5
Output voltages: [0.037083, 0.0012375, 0.0019774, 0.17748, 0.049756, 0.79871, 0.40989, 0.062955, 0.74, 0.20661]
Predicted label: 5
Correct prediction
Energy consumption = 153.271962 pJ
sum error= 312
Actual label: 4
Output voltages: [0.0061283, 0.034461, 0.013013, 0.033281, 0.79875, 0.0010676, 0.044841, 0.051326, 0.048976, 0.019299]
Predicted label: 4
Correct prediction
Energy consumption = 157.337040 pJ
sum error= 312
Actual label: 1
Output voltages: [0.02523, 0.79864, 0.40995, 0.016229, 0.04421, 0.0010738, 0.56765, 0.0099453, 0.04635, 0.024488]
Predicted label: 1
Correct prediction
Energy consumption = 162.983931 pJ
sum error= 312
Actual label: 1
Output voltages: [0.0085903, 0.79873, 0.21201, 0.45288, 0.045211, 0.0010725, 0.026274, 0.0015512, 0.43303, 0.33805]
Predicted label: 1
Correct prediction
Energy consumption = 159.604003 pJ
sum error= 312
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 687 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 687 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 687 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.48259, 0.002982, 0.04153, 0.0047023, 0.095732, 0.033008, 0.0038177, 0.2209, 0.67479, 0.79636]
Predicted label: 9
Correct prediction
Energy consumption = 153.504526 pJ
sum error= 312
Actual label: 7
Output voltages: [0.15065, 0.013557, 0.14908, 0.59313, 0.0026138, 0.0017069, 0.0022948, 0.79879, 0.41929, 0.50074]
Predicted label: 7
Correct prediction
Energy consumption = 153.452076 pJ
sum error= 312
Actual label: 4
Output voltages: [0.058344, 0.0072337, 0.35977, 0.0035599, 0.79878, 0.0011014, 0.44452, 0.033439, 0.026331, 0.027663]
Predicted label: 4
Correct prediction
Energy consumption = 152.609894 pJ
sum error= 312
Actual label: 3
Output voltages: [0.40298, 0.021629, 0.22849, 0.79865, 0.18054, 0.0061107, 0.025983, 0.0084496, 0.69996, 0.12266]
Predicted label: 3
Correct prediction
Energy consumption = 144.969031 pJ
sum error= 312
Actual label: 7
Output voltages: [0.097655, 0.11222, 0.37587, 0.42595, 0.0057818, 0.001073, 0.0023833, 0.79865, 0.2161, 0.34567]
Predicted label: 7
Correct prediction
Energy consumption = 153.855988 pJ
sum error= 312
Actual label: 3
Output voltages: [0.56101, 0.010399, 0.048053, 0.79861, 0.067103, 0.0094989, 0.027137, 0.0071415, 0.69057, 0.040064]
Predicted label: 3
Correct prediction
Energy consumption = 144.419244 pJ
sum error= 312
Actual label: 3
Output voltages: [0.61559, 0.043006, 0.11202, 0.79873, 0.0015021, 0.0082661, 0.024926, 0.027736, 0.2856, 0.0059136]
Predicted label: 3
Correct prediction
Energy consumption = 135.896023 pJ
sum error= 312
Actual label: 0
Output voltages: [0.79879, 0.023889, 0.22046, 0.029818, 0.034473, 0.015287, 0.70023, 0.020567, 0.028109, 0.36776]
Predicted label: 0
Correct prediction
Energy consumption = 159.128416 pJ
sum error= 312
Actual label: 2
Output voltages: [0.26024, 0.69569, 0.76372, 0.39153, 0.23332, 0.012215, 0.77142, 0.0043208, 0.033982, 0.0012613]
Predicted label: 6
Wrong prediction!
Energy consumption = 151.192097 pJ
sum error= 313
Actual label: 5
Output voltages: [0.041919, 0.0011354, 0.0039448, 0.36711, 0.03151, 0.79717, 0.036959, 0.039053, 0.7804, 0.041115]
Predicted label: 5
Correct prediction
Energy consumption = 142.331939 pJ
sum error= 313
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 688 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 688 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 688 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.14449, 0.0010984, 0.018737, 0.40671, 0.033844, 0.79879, 0.012283, 0.043446, 0.7875, 0.17516]
Predicted label: 5
Correct prediction
Energy consumption = 143.323181 pJ
sum error= 313
Actual label: 6
Output voltages: [0.11139, 0.10813, 0.33436, 0.0030711, 0.32642, 0.29399, 0.79862, 0.0029239, 0.26963, 0.024634]
Predicted label: 6
Correct prediction
Energy consumption = 146.608305 pJ
sum error= 313
Actual label: 3
Output voltages: [0.41977, 0.037595, 0.030118, 0.79859, 0.015595, 0.019941, 0.029807, 0.010364, 0.56713, 0.16129]
Predicted label: 3
Correct prediction
Energy consumption = 149.350622 pJ
sum error= 313
Actual label: 1
Output voltages: [0.0046979, 0.79871, 0.44678, 0.041565, 0.032923, 0.0010861, 0.76149, 0.014002, 0.033145, 0.035057]
Predicted label: 1
Correct prediction
Energy consumption = 149.130982 pJ
sum error= 313
Actual label: 5
Output voltages: [0.022514, 0.0010681, 0.010136, 0.29883, 0.010557, 0.79809, 0.20453, 0.0059759, 0.77381, 0.018498]
Predicted label: 5
Correct prediction
Energy consumption = 150.102545 pJ
sum error= 313
Actual label: 2
Output voltages: [0.050208, 0.5107, 0.78599, 0.077528, 0.068638, 0.0011946, 0.45236, 0.022875, 0.41472, 0.015149]
Predicted label: 2
Correct prediction
Energy consumption = 155.917968 pJ
sum error= 313
Actual label: 5
Output voltages: [0.15224, 0.0010669, 0.0011566, 0.49089, 0.044823, 0.78736, 0.51628, 0.018096, 0.38317, 0.03586]
Predicted label: 5
Correct prediction
Energy consumption = 142.743179 pJ
sum error= 313
Actual label: 9
Output voltages: [0.26857, 0.0083972, 0.065162, 0.020812, 0.048922, 0.0083214, 0.0016702, 0.10466, 0.58714, 0.79236]
Predicted label: 9
Correct prediction
Energy consumption = 152.956517 pJ
sum error= 313
Actual label: 9
Output voltages: [0.48505, 0.020799, 0.012509, 0.040195, 0.11439, 0.01854, 0.005666, 0.019485, 0.43229, 0.79848]
Predicted label: 9
Correct prediction
Energy consumption = 137.426202 pJ
sum error= 313
Actual label: 8
Output voltages: [0.029867, 0.016372, 0.27606, 0.016175, 0.017927, 0.02367, 0.0092645, 0.0023165, 0.79879, 0.40469]
Predicted label: 8
Correct prediction
Energy consumption = 143.380617 pJ
sum error= 313
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 689 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 689 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 689 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.004197, 0.0094096, 0.04012, 0.0068469, 0.79859, 0.0014934, 0.051723, 0.082499, 0.041934, 0.044156]
Predicted label: 4
Correct prediction
Energy consumption = 152.333740 pJ
sum error= 313
Actual label: 1
Output voltages: [0.031156, 0.79837, 0.044059, 0.32515, 0.017137, 0.0054704, 0.48516, 0.016825, 0.16908, 0.31035]
Predicted label: 1
Correct prediction
Energy consumption = 164.315015 pJ
sum error= 313
Actual label: 0
Output voltages: [0.79875, 0.02581, 0.015301, 0.0042135, 0.024913, 0.013214, 0.51836, 0.0051258, 0.030149, 0.045862]
Predicted label: 0
Correct prediction
Energy consumption = 161.198926 pJ
sum error= 313
Actual label: 6
Output voltages: [0.25789, 0.13544, 0.19175, 0.010015, 0.2875, 0.18903, 0.79868, 0.0013815, 0.3203, 0.039659]
Predicted label: 6
Correct prediction
Energy consumption = 142.386324 pJ
sum error= 313
Actual label: 0
Output voltages: [0.79871, 0.022966, 0.36372, 0.031214, 0.010481, 0.0050524, 0.34842, 0.11752, 0.39498, 0.17904]
Predicted label: 0
Correct prediction
Energy consumption = 154.679134 pJ
sum error= 313
Actual label: 9
Output voltages: [0.11217, 0.056362, 0.0021332, 0.25079, 0.028421, 0.0024198, 0.0032606, 0.020166, 0.21918, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 155.604430 pJ
sum error= 313
Actual label: 6
Output voltages: [0.20185, 0.12043, 0.23066, 0.05002, 0.075708, 0.28629, 0.79865, 0.0028709, 0.069869, 0.093421]
Predicted label: 6
Correct prediction
Energy consumption = 151.563266 pJ
sum error= 313
Actual label: 8
Output voltages: [0.073152, 0.0065249, 0.65819, 0.01503, 0.014992, 0.0078503, 0.076718, 0.0042702, 0.79878, 0.046957]
Predicted label: 8
Correct prediction
Energy consumption = 152.053270 pJ
sum error= 313
Actual label: 8
Output voltages: [0.021141, 0.051641, 0.134, 0.043115, 0.0065402, 0.011067, 0.02441, 0.0027836, 0.79879, 0.53508]
Predicted label: 8
Correct prediction
Energy consumption = 144.673664 pJ
sum error= 313
Actual label: 5
Output voltages: [0.015372, 0.0013744, 0.0063743, 0.12285, 0.021508, 0.79199, 0.067712, 0.0033283, 0.76143, 0.1514]
Predicted label: 5
Correct prediction
Energy consumption = 139.996165 pJ
sum error= 313
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 690 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 690 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 690 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.098492, 0.21813, 0.10341, 0.036634, 0.15065, 0.43857, 0.7987, 0.0091595, 0.36407, 0.010296]
Predicted label: 6
Correct prediction
Energy consumption = 150.304714 pJ
sum error= 313
Actual label: 1
Output voltages: [0.020342, 0.79849, 0.0063765, 0.095202, 0.04994, 0.010165, 0.26159, 0.014493, 0.24628, 0.1007]
Predicted label: 1
Correct prediction
Energy consumption = 165.627692 pJ
sum error= 313
Actual label: 1
Output voltages: [0.059588, 0.79847, 0.0022773, 0.021288, 0.02006, 0.0012057, 0.062175, 0.025947, 0.25162, 0.41054]
Predicted label: 1
Correct prediction
Energy consumption = 156.950756 pJ
sum error= 313
Actual label: 9
Output voltages: [0.12913, 0.0074436, 0.018634, 0.025772, 0.1019, 0.0068629, 0.0015127, 0.050157, 0.5232, 0.79223]
Predicted label: 9
Correct prediction
Energy consumption = 146.397403 pJ
sum error= 313
Actual label: 8
Output voltages: [0.0086264, 0.061938, 0.53538, 0.21707, 0.0065828, 0.0092025, 0.02405, 0.018723, 0.79875, 0.1934]
Predicted label: 8
Correct prediction
Energy consumption = 144.264917 pJ
sum error= 313
Actual label: 9
Output voltages: [0.079165, 0.010409, 0.014694, 0.021844, 0.12288, 0.0020894, 0.0028772, 0.020904, 0.52505, 0.79862]
Predicted label: 9
Correct prediction
Energy consumption = 153.583338 pJ
sum error= 313
Actual label: 2
Output voltages: [0.46074, 0.3094, 0.60267, 0.47494, 0.46527, 0.013697, 0.78855, 0.1458, 0.001633, 0.0016375]
Predicted label: 6
Wrong prediction!
Energy consumption = 154.553490 pJ
sum error= 314
Actual label: 3
Output voltages: [0.72581, 0.016017, 0.026459, 0.79864, 0.014395, 0.028961, 0.014615, 0.0093986, 0.46459, 0.23143]
Predicted label: 3
Correct prediction
Energy consumption = 145.496310 pJ
sum error= 314
Actual label: 5
Output voltages: [0.047483, 0.0011314, 0.0033119, 0.40451, 0.0061454, 0.7985, 0.16956, 0.02666, 0.70851, 0.041555]
Predicted label: 5
Correct prediction
Energy consumption = 140.359143 pJ
sum error= 314
Actual label: 5
Output voltages: [0.0012974, 0.0071075, 0.011828, 0.1969, 0.022242, 0.78317, 0.01627, 0.082392, 0.76055, 0.28516]
Predicted label: 5
Correct prediction
Energy consumption = 133.335743 pJ
sum error= 314
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 691 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 691 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 691 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.29022, 0.0013962, 0.035165, 0.054243, 0.66672, 0.0010873, 0.0010981, 0.19141, 0.4756, 0.78822]
Predicted label: 9
Correct prediction
Energy consumption = 151.792910 pJ
sum error= 314
Actual label: 4
Output voltages: [0.0072936, 0.0047663, 0.024436, 0.0035758, 0.79862, 0.0010825, 0.099691, 0.065566, 0.081044, 0.024346]
Predicted label: 4
Correct prediction
Energy consumption = 147.289170 pJ
sum error= 314
Actual label: 2
Output voltages: [0.32346, 0.023436, 0.79823, 0.19391, 0.01135, 0.0012264, 0.14531, 0.58508, 0.14909, 0.030357]
Predicted label: 2
Correct prediction
Energy consumption = 143.603827 pJ
sum error= 314
Actual label: 1
Output voltages: [0.027862, 0.79842, 0.21537, 0.10029, 0.019286, 0.0029977, 0.42818, 0.0044568, 0.36757, 0.044094]
Predicted label: 1
Correct prediction
Energy consumption = 162.413875 pJ
sum error= 314
Actual label: 9
Output voltages: [0.071215, 0.092182, 0.15617, 0.0016696, 0.33015, 0.0053705, 0.0011225, 0.059917, 0.33193, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 153.676281 pJ
sum error= 314
Actual label: 4
Output voltages: [0.0080419, 0.043321, 0.022086, 0.038933, 0.79879, 0.001067, 0.028056, 0.25956, 0.020919, 0.042379]
Predicted label: 4
Correct prediction
Energy consumption = 150.843328 pJ
sum error= 314
Actual label: 9
Output voltages: [0.24278, 0.0031085, 0.028022, 0.014441, 0.32397, 0.017386, 0.010992, 0.16008, 0.42317, 0.79757]
Predicted label: 9
Correct prediction
Energy consumption = 149.414410 pJ
sum error= 314
Actual label: 1
Output voltages: [0.020985, 0.7984, 0.20071, 0.20914, 0.059671, 0.0051225, 0.56321, 0.015424, 0.05252, 0.1275]
Predicted label: 1
Correct prediction
Energy consumption = 166.578181 pJ
sum error= 314
Actual label: 3
Output voltages: [0.40833, 0.024921, 0.049368, 0.79869, 0.0078609, 0.005636, 0.0090408, 0.0066116, 0.33035, 0.034059]
Predicted label: 3
Correct prediction
Energy consumption = 143.520097 pJ
sum error= 314
Actual label: 9
Output voltages: [0.21233, 0.0060278, 0.012997, 0.001529, 0.077818, 0.0011729, 0.0010662, 0.031803, 0.50395, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 154.015715 pJ
sum error= 314
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 692 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 692 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 692 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.48087, 0.46158, 0.79879, 0.020328, 0.007042, 0.0013613, 0.22855, 0.035066, 0.18176, 0.017758]
Predicted label: 2
Correct prediction
Energy consumption = 155.136925 pJ
sum error= 314
Actual label: 0
Output voltages: [0.79878, 0.086005, 0.03404, 0.0045041, 0.0084304, 0.001693, 0.40939, 0.0076441, 0.07182, 0.075635]
Predicted label: 0
Correct prediction
Energy consumption = 151.272996 pJ
sum error= 314
Actual label: 6
Output voltages: [0.034892, 0.013624, 0.031394, 0.01829, 0.40495, 0.23098, 0.79875, 0.004865, 0.76063, 0.0081744]
Predicted label: 6
Correct prediction
Energy consumption = 140.557530 pJ
sum error= 314
Actual label: 0
Output voltages: [0.79867, 0.065949, 0.11246, 0.010535, 0.05698, 0.010804, 0.21662, 0.04206, 0.15807, 0.25124]
Predicted label: 0
Correct prediction
Energy consumption = 154.005125 pJ
sum error= 314
Actual label: 4
Output voltages: [0.0094286, 0.0065882, 0.012604, 0.0057078, 0.79879, 0.0012057, 0.029231, 0.050142, 0.45724, 0.064825]
Predicted label: 4
Correct prediction
Energy consumption = 149.621955 pJ
sum error= 314
Actual label: 0
Output voltages: [0.7987, 0.025418, 0.47795, 0.014333, 0.014389, 0.004474, 0.36474, 0.050454, 0.41445, 0.24112]
Predicted label: 0
Correct prediction
Energy consumption = 159.822035 pJ
sum error= 314
Actual label: 6
Output voltages: [0.013664, 0.0030123, 0.02955, 0.00978, 0.79226, 0.096065, 0.77295, 0.029899, 0.20618, 0.020079]
Predicted label: 4
Wrong prediction!
Energy consumption = 146.020768 pJ
sum error= 315
Actual label: 0
Output voltages: [0.79877, 0.13541, 0.085278, 0.01213, 0.013083, 0.0017983, 0.5944, 0.019943, 0.077645, 0.27603]
Predicted label: 0
Correct prediction
Energy consumption = 158.658576 pJ
sum error= 315
Actual label: 1
Output voltages: [0.0091712, 0.79859, 0.1843, 0.092375, 0.077749, 0.0014962, 0.57043, 0.0037709, 0.38503, 0.12523]
Predicted label: 1
Correct prediction
Energy consumption = 161.907135 pJ
sum error= 315
Actual label: 2
Output voltages: [0.37616, 0.21173, 0.79872, 0.18478, 0.0053176, 0.0011318, 0.16846, 0.020111, 0.16708, 0.037748]
Predicted label: 2
Correct prediction
Energy consumption = 143.667053 pJ
sum error= 315
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 693 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 693 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 693 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.59623, 0.0084041, 0.26681, 0.79877, 0.027205, 0.0025772, 0.0031531, 0.006749, 0.45491, 0.031945]
Predicted label: 3
Correct prediction
Energy consumption = 151.017956 pJ
sum error= 315
Actual label: 4
Output voltages: [0.0022146, 0.01112, 0.088951, 0.14495, 0.7987, 0.0010664, 0.023346, 0.044448, 0.019032, 0.027697]
Predicted label: 4
Correct prediction
Energy consumption = 154.324490 pJ
sum error= 315
Actual label: 5
Output voltages: [0.026425, 0.0010903, 0.0010828, 0.31756, 0.19101, 0.79876, 0.41985, 0.017097, 0.66188, 0.046466]
Predicted label: 5
Correct prediction
Energy consumption = 146.120386 pJ
sum error= 315
Actual label: 6
Output voltages: [0.054956, 0.049605, 0.4371, 0.0012442, 0.15617, 0.16269, 0.79877, 0.0022198, 0.42529, 0.0016331]
Predicted label: 6
Correct prediction
Energy consumption = 142.521446 pJ
sum error= 315
Actual label: 7
Output voltages: [0.30357, 0.022158, 0.029162, 0.035029, 0.0066846, 0.023343, 0.0010998, 0.79858, 0.11245, 0.25291]
Predicted label: 7
Correct prediction
Energy consumption = 159.748630 pJ
sum error= 315
Actual label: 8
Output voltages: [0.014919, 0.11415, 0.32791, 0.045214, 0.021671, 0.0031219, 0.016995, 0.017738, 0.79875, 0.19938]
Predicted label: 8
Correct prediction
Energy consumption = 148.939684 pJ
sum error= 315
Actual label: 9
Output voltages: [0.49617, 0.0024634, 0.019506, 0.0042252, 0.156, 0.061598, 0.006305, 0.25233, 0.34793, 0.78901]
Predicted label: 9
Correct prediction
Energy consumption = 148.075181 pJ
sum error= 315
Actual label: 0
Output voltages: [0.7987, 0.0389, 0.20358, 0.038089, 0.012165, 0.0019631, 0.51845, 0.023362, 0.042782, 0.068052]
Predicted label: 0
Correct prediction
Energy consumption = 151.024007 pJ
sum error= 315
Actual label: 1
Output voltages: [0.0034137, 0.7985, 0.13573, 0.044684, 0.51461, 0.022577, 0.41246, 0.019376, 0.051746, 0.071203]
Predicted label: 1
Correct prediction
Energy consumption = 171.933703 pJ
sum error= 315
Actual label: 2
Output voltages: [0.50859, 0.026857, 0.79878, 0.056233, 0.023534, 0.0010858, 0.043068, 0.090854, 0.40337, 0.013774]
Predicted label: 2
Correct prediction
Energy consumption = 151.930315 pJ
sum error= 315
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 694 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 694 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 694 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.10139, 0.0047755, 0.052923, 0.79873, 0.24719, 0.63848, 0.014965, 0.0090864, 0.53802, 0.0045729]
Predicted label: 3
Correct prediction
Energy consumption = 148.824907 pJ
sum error= 315
Actual label: 4
Output voltages: [0.0023401, 0.0044094, 0.040704, 0.017725, 0.79864, 0.0033657, 0.14119, 0.22054, 0.1135, 0.013253]
Predicted label: 4
Correct prediction
Energy consumption = 145.874427 pJ
sum error= 315
Actual label: 5
Output voltages: [0.030621, 0.0011187, 0.0010805, 0.68357, 0.033405, 0.79869, 0.37641, 0.0044056, 0.65711, 0.034594]
Predicted label: 5
Correct prediction
Energy consumption = 141.811420 pJ
sum error= 315
Actual label: 6
Output voltages: [0.11899, 0.020056, 0.12726, 0.004672, 0.33951, 0.063466, 0.79879, 0.0065516, 0.59795, 0.0021785]
Predicted label: 6
Correct prediction
Energy consumption = 145.576989 pJ
sum error= 315
Actual label: 7
Output voltages: [0.41955, 0.013214, 0.047551, 0.22528, 0.010223, 0.041469, 0.0011329, 0.79856, 0.29046, 0.35799]
Predicted label: 7
Correct prediction
Energy consumption = 154.681201 pJ
sum error= 315
Actual label: 8
Output voltages: [0.22621, 0.059864, 0.024401, 0.025683, 0.0043516, 0.0016478, 0.0010831, 0.40778, 0.79837, 0.69156]
Predicted label: 8
Correct prediction
Energy consumption = 142.848941 pJ
sum error= 315
Actual label: 9
Output voltages: [0.32815, 0.016691, 0.023065, 0.031556, 0.29091, 0.010261, 0.0047113, 0.0066478, 0.47791, 0.79867]
Predicted label: 9
Correct prediction
Energy consumption = 142.503404 pJ
sum error= 315
Actual label: 0
Output voltages: [0.79875, 0.087785, 0.030345, 0.014288, 0.032884, 0.017936, 0.57957, 0.014643, 0.032906, 0.062753]
Predicted label: 0
Correct prediction
Energy consumption = 148.533630 pJ
sum error= 315
Actual label: 1
Output voltages: [0.012571, 0.79867, 0.37026, 0.023471, 0.024469, 0.001257, 0.76382, 0.005857, 0.1165, 0.010828]
Predicted label: 1
Correct prediction
Energy consumption = 159.944178 pJ
sum error= 315
Actual label: 2
Output voltages: [0.4329, 0.047352, 0.79864, 0.015388, 0.016128, 0.0011349, 0.058645, 0.14783, 0.51039, 0.0080867]
Predicted label: 2
Correct prediction
Energy consumption = 146.232149 pJ
sum error= 315
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 695 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 695 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 695 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.32112, 0.0080795, 0.039807, 0.79879, 0.015611, 0.07505, 0.0010712, 0.035481, 0.76332, 0.06297]
Predicted label: 3
Correct prediction
Energy consumption = 147.916288 pJ
sum error= 315
Actual label: 4
Output voltages: [0.0060748, 0.01187, 0.049975, 0.024726, 0.79862, 0.0016392, 0.094958, 0.058759, 0.025857, 0.015046]
Predicted label: 4
Correct prediction
Energy consumption = 152.679141 pJ
sum error= 315
Actual label: 5
Output voltages: [0.32866, 0.0010896, 0.0013385, 0.18627, 0.092948, 0.79865, 0.039049, 0.032537, 0.6989, 0.011721]
Predicted label: 5
Correct prediction
Energy consumption = 142.284688 pJ
sum error= 315
Actual label: 6
Output voltages: [0.32714, 0.12504, 0.038062, 0.011179, 0.17125, 0.72751, 0.79878, 0.0029117, 0.51133, 0.01432]
Predicted label: 6
Correct prediction
Energy consumption = 146.021671 pJ
sum error= 315
Actual label: 7
Output voltages: [0.42007, 0.31314, 0.79658, 0.037038, 0.0012526, 0.0010778, 0.0058673, 0.79398, 0.36593, 0.08486]
Predicted label: 2
Wrong prediction!
Energy consumption = 154.517995 pJ
sum error= 316
Actual label: 8
Output voltages: [0.04694, 0.056277, 0.16947, 0.050552, 0.025779, 0.043087, 0.033354, 0.0032336, 0.79873, 0.065701]
Predicted label: 8
Correct prediction
Energy consumption = 149.962932 pJ
sum error= 316
Actual label: 9
Output voltages: [0.23048, 0.016504, 0.023285, 0.024542, 0.04282, 0.021945, 0.0055965, 0.040723, 0.64751, 0.79806]
Predicted label: 9
Correct prediction
Energy consumption = 140.023809 pJ
sum error= 316
Actual label: 3
Output voltages: [0.34783, 0.012557, 0.036806, 0.79873, 0.015227, 0.0044503, 0.0079857, 0.0017279, 0.48003, 0.03532]
Predicted label: 3
Correct prediction
Energy consumption = 151.023166 pJ
sum error= 316
Actual label: 8
Output voltages: [0.029278, 0.19048, 0.032691, 0.31558, 0.0079293, 0.019331, 0.012147, 0.010119, 0.79868, 0.37809]
Predicted label: 8
Correct prediction
Energy consumption = 138.415899 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79875, 0.049752, 0.10559, 0.029626, 0.025843, 0.0048182, 0.56363, 0.033276, 0.057792, 0.05396]
Predicted label: 0
Correct prediction
Energy consumption = 159.663666 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 696 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 696 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 696 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.19941, 0.023784, 0.057713, 0.12159, 0.0015951, 0.011626, 0.0011492, 0.79859, 0.23983, 0.26619]
Predicted label: 7
Correct prediction
Energy consumption = 157.913853 pJ
sum error= 316
Actual label: 1
Output voltages: [0.0074401, 0.79859, 0.24056, 0.19856, 0.032302, 0.0011295, 0.63267, 0.0074682, 0.24276, 0.038416]
Predicted label: 1
Correct prediction
Energy consumption = 163.802066 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79841, 0.048489, 0.32538, 0.021561, 0.031189, 0.0010661, 0.76232, 0.013061, 0.41859, 0.19015]
Predicted label: 0
Correct prediction
Energy consumption = 157.030676 pJ
sum error= 316
Actual label: 7
Output voltages: [0.16688, 0.045072, 0.18176, 0.038489, 0.0043765, 0.0010681, 0.0010823, 0.79862, 0.41921, 0.11168]
Predicted label: 7
Correct prediction
Energy consumption = 155.113613 pJ
sum error= 316
Actual label: 5
Output voltages: [0.51025, 0.0049497, 0.0037742, 0.56912, 0.0062672, 0.7987, 0.13188, 0.020956, 0.73398, 0.020149]
Predicted label: 5
Correct prediction
Energy consumption = 148.324522 pJ
sum error= 316
Actual label: 5
Output voltages: [0.055288, 0.0023458, 0.0010685, 0.5066, 0.0328, 0.79877, 0.29106, 0.003738, 0.65194, 0.026594]
Predicted label: 5
Correct prediction
Energy consumption = 141.743625 pJ
sum error= 316
Actual label: 6
Output voltages: [0.050798, 0.036336, 0.11119, 0.0026003, 0.21125, 0.15073, 0.79876, 0.0017623, 0.4352, 0.0026258]
Predicted label: 6
Correct prediction
Energy consumption = 148.381007 pJ
sum error= 316
Actual label: 9
Output voltages: [0.46282, 0.0094711, 0.0073628, 0.029952, 0.20373, 0.0055129, 0.0019702, 0.0025659, 0.33623, 0.7974]
Predicted label: 9
Correct prediction
Energy consumption = 157.096182 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79875, 0.17293, 0.21184, 0.03831, 0.010657, 0.0065836, 0.76267, 0.044127, 0.35143, 0.040536]
Predicted label: 0
Correct prediction
Energy consumption = 149.959527 pJ
sum error= 316
Actual label: 1
Output voltages: [0.026846, 0.79857, 0.29479, 0.028371, 0.045081, 0.0012663, 0.49348, 0.0011903, 0.057544, 0.019829]
Predicted label: 1
Correct prediction
Energy consumption = 153.732321 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 697 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 697 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 697 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79773, 0.032583, 0.48318, 0.025969, 0.011388, 0.0011419, 0.16893, 0.0024586, 0.48002, 0.048361]
Predicted label: 0
Correct prediction
Energy consumption = 154.443325 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79879, 0.036512, 0.50087, 0.018848, 0.028056, 0.0013143, 0.13438, 0.014927, 0.25351, 0.091487]
Predicted label: 0
Correct prediction
Energy consumption = 147.167723 pJ
sum error= 316
Actual label: 8
Output voltages: [0.20559, 0.0061638, 0.45642, 0.011099, 0.024608, 0.016084, 0.0063713, 0.047775, 0.79872, 0.028177]
Predicted label: 8
Correct prediction
Energy consumption = 144.893077 pJ
sum error= 316
Actual label: 3
Output voltages: [0.76419, 0.009693, 0.22398, 0.79875, 0.024, 0.015608, 0.0084879, 0.020974, 0.3221, 0.0077597]
Predicted label: 3
Correct prediction
Energy consumption = 146.120505 pJ
sum error= 316
Actual label: 4
Output voltages: [0.011616, 0.0049308, 0.0299, 0.012374, 0.79859, 0.0012811, 0.18819, 0.03099, 0.18517, 0.0062172]
Predicted label: 4
Correct prediction
Energy consumption = 152.163834 pJ
sum error= 316
Actual label: 3
Output voltages: [0.70204, 0.0013408, 0.70157, 0.79831, 0.020297, 0.0014888, 0.0011931, 0.020822, 0.42519, 0.0045014]
Predicted label: 3
Correct prediction
Energy consumption = 139.941017 pJ
sum error= 316
Actual label: 1
Output voltages: [0.016202, 0.7986, 0.022316, 0.037786, 0.031613, 0.0011558, 0.65446, 0.019351, 0.031626, 0.039232]
Predicted label: 1
Correct prediction
Energy consumption = 152.759338 pJ
sum error= 316
Actual label: 5
Output voltages: [0.13036, 0.0085626, 0.0011102, 0.5785, 0.030422, 0.79873, 0.039402, 0.011821, 0.72616, 0.057252]
Predicted label: 5
Correct prediction
Energy consumption = 155.841161 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79879, 0.14697, 0.067439, 0.018353, 0.06591, 0.0027998, 0.72868, 0.009719, 0.13393, 0.072253]
Predicted label: 0
Correct prediction
Energy consumption = 159.709574 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79876, 0.038976, 0.01545, 0.031446, 0.091453, 0.023482, 0.6331, 0.022487, 0.074497, 0.052209]
Predicted label: 0
Correct prediction
Energy consumption = 146.404892 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 698 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 698 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 698 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.2218, 0.0021941, 0.0093441, 0.032295, 0.17716, 0.005707, 0.0013215, 0.018201, 0.59136, 0.79798]
Predicted label: 9
Correct prediction
Energy consumption = 153.144238 pJ
sum error= 316
Actual label: 5
Output voltages: [0.071827, 0.0011838, 0.0010662, 0.15076, 0.20404, 0.79863, 0.46144, 0.0029073, 0.76864, 0.033307]
Predicted label: 5
Correct prediction
Energy consumption = 148.012892 pJ
sum error= 316
Actual label: 3
Output voltages: [0.35803, 0.010777, 0.03342, 0.79874, 0.031519, 0.03037, 0.01109, 0.025645, 0.60441, 0.018442]
Predicted label: 3
Correct prediction
Energy consumption = 146.457762 pJ
sum error= 316
Actual label: 4
Output voltages: [0.041001, 0.0069779, 0.19298, 0.010587, 0.79859, 0.0010793, 0.0011025, 0.01565, 0.13997, 0.30906]
Predicted label: 4
Correct prediction
Energy consumption = 151.354900 pJ
sum error= 316
Actual label: 9
Output voltages: [0.2422, 0.014501, 0.0078272, 0.050913, 0.36144, 0.0058142, 0.0016976, 0.0033596, 0.1778, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 147.186397 pJ
sum error= 316
Actual label: 3
Output voltages: [0.52227, 0.02659, 0.036731, 0.79863, 0.034802, 0.051457, 0.0031686, 0.0034671, 0.72913, 0.022791]
Predicted label: 3
Correct prediction
Energy consumption = 143.460725 pJ
sum error= 316
Actual label: 7
Output voltages: [0.3016, 0.22412, 0.43286, 0.0013693, 0.023232, 0.0012409, 0.0025252, 0.79879, 0.21837, 0.065659]
Predicted label: 7
Correct prediction
Energy consumption = 155.893908 pJ
sum error= 316
Actual label: 6
Output voltages: [0.016478, 0.082578, 0.59062, 0.0017147, 0.24276, 0.056468, 0.79872, 0.0079556, 0.40078, 0.0044806]
Predicted label: 6
Correct prediction
Energy consumption = 153.433764 pJ
sum error= 316
Actual label: 9
Output voltages: [0.037134, 0.015561, 0.018556, 0.030943, 0.034999, 0.0074081, 0.0027157, 0.032424, 0.71392, 0.79694]
Predicted label: 9
Correct prediction
Energy consumption = 156.813914 pJ
sum error= 316
Actual label: 2
Output voltages: [0.36722, 0.022089, 0.79844, 0.12099, 0.049646, 0.0013987, 0.010285, 0.013272, 0.62225, 0.0046224]
Predicted label: 2
Correct prediction
Energy consumption = 151.346678 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 699 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 699 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 699 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0030664, 0.0015817, 0.064401, 0.21473, 0.79872, 0.014663, 0.0098457, 0.0095484, 0.31623, 0.052228]
Predicted label: 4
Correct prediction
Energy consumption = 150.261743 pJ
sum error= 316
Actual label: 5
Output voltages: [0.057616, 0.0011598, 0.0015516, 0.39629, 0.074739, 0.79873, 0.62184, 0.021335, 0.7731, 0.0070865]
Predicted label: 5
Correct prediction
Energy consumption = 138.083406 pJ
sum error= 316
Actual label: 7
Output voltages: [0.37146, 0.0088124, 0.019482, 0.063915, 0.02192, 0.020244, 0.0010787, 0.79859, 0.22838, 0.27247]
Predicted label: 7
Correct prediction
Energy consumption = 148.718722 pJ
sum error= 316
Actual label: 2
Output voltages: [0.44145, 0.040039, 0.79868, 0.038699, 0.013901, 0.0010769, 0.031973, 0.016826, 0.47618, 0.018974]
Predicted label: 2
Correct prediction
Energy consumption = 141.935657 pJ
sum error= 316
Actual label: 6
Output voltages: [0.11204, 0.02461, 0.38094, 0.0026002, 0.31884, 0.055782, 0.79879, 0.002081, 0.45006, 0.0064435]
Predicted label: 6
Correct prediction
Energy consumption = 145.867156 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0018974, 0.021714, 0.018478, 0.033074, 0.79863, 0.0048338, 0.063723, 0.056949, 0.024238, 0.029113]
Predicted label: 4
Correct prediction
Energy consumption = 145.187904 pJ
sum error= 316
Actual label: 9
Output voltages: [0.549, 0.023456, 0.0084874, 0.062876, 0.40033, 0.0090533, 0.012725, 0.0014368, 0.19622, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 147.147366 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0021925, 0.020562, 0.031542, 0.026885, 0.79875, 0.074918, 0.025192, 0.0029565, 0.37158, 0.12263]
Predicted label: 4
Correct prediction
Energy consumption = 152.668636 pJ
sum error= 316
Actual label: 9
Output voltages: [0.27867, 0.0062939, 0.011744, 0.025691, 0.30312, 0.0024365, 0.0071807, 0.0026003, 0.43398, 0.79828]
Predicted label: 9
Correct prediction
Energy consumption = 143.414516 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0095612, 0.023833, 0.04393, 0.033557, 0.79869, 0.0010723, 0.031508, 0.028212, 0.048772, 0.019275]
Predicted label: 4
Correct prediction
Energy consumption = 147.159179 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 700 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 700 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 700 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0047371, 0.79859, 0.011454, 0.039676, 0.01321, 0.0029437, 0.70579, 0.0093672, 0.41444, 0.018704]
Predicted label: 1
Correct prediction
Energy consumption = 157.597193 pJ
sum error= 316
Actual label: 2
Output voltages: [0.24966, 0.025329, 0.79878, 0.19421, 0.23551, 0.0010706, 0.18736, 0.019422, 0.54832, 0.096645]
Predicted label: 2
Correct prediction
Energy consumption = 150.245430 pJ
sum error= 316
Actual label: 2
Output voltages: [0.12119, 0.019061, 0.79879, 0.037098, 0.0054799, 0.00109, 0.040292, 0.036077, 0.73908, 0.0091745]
Predicted label: 2
Correct prediction
Energy consumption = 144.931170 pJ
sum error= 316
Actual label: 5
Output voltages: [0.051366, 0.0010738, 0.0011805, 0.74929, 0.029918, 0.79877, 0.15526, 0.025616, 0.34823, 0.19388]
Predicted label: 5
Correct prediction
Energy consumption = 152.055839 pJ
sum error= 316
Actual label: 8
Output voltages: [0.01397, 0.071509, 0.10824, 0.042705, 0.0060363, 0.0036623, 0.025588, 0.0058922, 0.79869, 0.20609]
Predicted label: 8
Correct prediction
Energy consumption = 154.161127 pJ
sum error= 316
Actual label: 1
Output voltages: [0.0062029, 0.79867, 0.58033, 0.028884, 0.048323, 0.0010822, 0.38596, 0.022866, 0.077607, 0.013666]
Predicted label: 1
Correct prediction
Energy consumption = 157.288376 pJ
sum error= 316
Actual label: 3
Output voltages: [0.30114, 0.014422, 0.20322, 0.79869, 0.018699, 0.015052, 0.0070126, 0.016532, 0.42047, 0.033691]
Predicted label: 3
Correct prediction
Energy consumption = 144.674499 pJ
sum error= 316
Actual label: 2
Output voltages: [0.30492, 0.042481, 0.79873, 0.079089, 0.019215, 0.0010905, 0.21967, 0.060709, 0.44783, 0.017082]
Predicted label: 2
Correct prediction
Energy consumption = 148.123145 pJ
sum error= 316
Actual label: 9
Output voltages: [0.11712, 0.034802, 0.059824, 0.15915, 0.041497, 0.016135, 0.01418, 0.03584, 0.46209, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 158.467256 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0081763, 0.024964, 0.1766, 0.098941, 0.79876, 0.0016874, 0.013982, 0.02079, 0.034947, 0.014126]
Predicted label: 4
Correct prediction
Energy consumption = 151.928412 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 701 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 701 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 701 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.1155, 0.032447, 0.093909, 0.79879, 0.0038917, 0.003503, 0.0027473, 0.012309, 0.71968, 0.032577]
Predicted label: 3
Correct prediction
Energy consumption = 143.291129 pJ
sum error= 316
Actual label: 8
Output voltages: [0.056398, 0.014956, 0.12082, 0.024023, 0.047589, 0.034197, 0.013644, 0.019254, 0.79858, 0.021801]
Predicted label: 8
Correct prediction
Energy consumption = 141.965636 pJ
sum error= 316
Actual label: 2
Output voltages: [0.28065, 0.022306, 0.79872, 0.029764, 0.013992, 0.0010811, 0.040824, 0.03449, 0.49498, 0.013108]
Predicted label: 2
Correct prediction
Energy consumption = 148.680008 pJ
sum error= 316
Actual label: 2
Output voltages: [0.4328, 0.026756, 0.79869, 0.034919, 0.019972, 0.0010759, 0.067517, 0.065641, 0.51769, 0.020704]
Predicted label: 2
Correct prediction
Energy consumption = 133.634984 pJ
sum error= 316
Actual label: 1
Output voltages: [0.042071, 0.79872, 0.69079, 0.24313, 0.023948, 0.0011442, 0.11754, 0.0011844, 0.084518, 0.068842]
Predicted label: 1
Correct prediction
Energy consumption = 158.196189 pJ
sum error= 316
Actual label: 2
Output voltages: [0.32898, 0.014203, 0.79877, 0.15014, 0.045457, 0.0010762, 0.051062, 0.063231, 0.37172, 0.0080359]
Predicted label: 2
Correct prediction
Energy consumption = 143.564021 pJ
sum error= 316
Actual label: 8
Output voltages: [0.18486, 0.017901, 0.19313, 0.67036, 0.010821, 0.0052497, 0.034273, 0.0018417, 0.79879, 0.22224]
Predicted label: 8
Correct prediction
Energy consumption = 151.928337 pJ
sum error= 316
Actual label: 6
Output voltages: [0.055686, 0.044673, 0.1364, 0.012379, 0.44457, 0.37578, 0.79867, 0.011104, 0.52073, 0.016057]
Predicted label: 6
Correct prediction
Energy consumption = 148.253185 pJ
sum error= 316
Actual label: 5
Output voltages: [0.06212, 0.0010677, 0.0015395, 0.32751, 0.018612, 0.79804, 0.056536, 0.023015, 0.64729, 0.18347]
Predicted label: 5
Correct prediction
Energy consumption = 145.120503 pJ
sum error= 316
Actual label: 1
Output voltages: [0.056876, 0.79878, 0.30424, 0.09159, 0.45877, 0.0010977, 0.51178, 0.0031761, 0.037375, 0.03278]
Predicted label: 1
Correct prediction
Energy consumption = 168.828363 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 702 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 702 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 702 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.15564, 0.22742, 0.026451, 0.020058, 0.22011, 0.69427, 0.79871, 0.0059625, 0.42832, 0.0043769]
Predicted label: 6
Correct prediction
Energy consumption = 151.459477 pJ
sum error= 316
Actual label: 7
Output voltages: [0.29642, 0.098785, 0.37901, 0.41731, 0.0010723, 0.001173, 0.0013135, 0.79474, 0.53914, 0.083295]
Predicted label: 7
Correct prediction
Energy consumption = 159.481605 pJ
sum error= 316
Actual label: 2
Output voltages: [0.43029, 0.01733, 0.79877, 0.20045, 0.036794, 0.0010773, 0.046951, 0.010621, 0.41699, 0.019969]
Predicted label: 2
Correct prediction
Energy consumption = 144.168253 pJ
sum error= 316
Actual label: 1
Output voltages: [0.18581, 0.79871, 0.22739, 0.021084, 0.65244, 0.0017551, 0.34814, 0.001272, 0.024212, 0.12217]
Predicted label: 1
Correct prediction
Energy consumption = 165.597034 pJ
sum error= 316
Actual label: 3
Output voltages: [0.74998, 0.013066, 0.14795, 0.79875, 0.023905, 0.064816, 0.0036829, 0.01903, 0.67446, 0.0093163]
Predicted label: 3
Correct prediction
Energy consumption = 151.513212 pJ
sum error= 316
Actual label: 9
Output voltages: [0.045319, 0.0056057, 0.022594, 0.36766, 0.056581, 0.0020768, 0.0017081, 0.043233, 0.26361, 0.79491]
Predicted label: 9
Correct prediction
Energy consumption = 146.767742 pJ
sum error= 316
Actual label: 3
Output voltages: [0.76469, 0.016687, 0.030245, 0.79867, 0.023462, 0.051429, 0.0045482, 0.015906, 0.48526, 0.029373]
Predicted label: 3
Correct prediction
Energy consumption = 141.731753 pJ
sum error= 316
Actual label: 8
Output voltages: [0.026182, 0.033529, 0.057804, 0.015898, 0.0034754, 0.038482, 0.006018, 0.019936, 0.79862, 0.032752]
Predicted label: 8
Correct prediction
Energy consumption = 144.644806 pJ
sum error= 316
Actual label: 7
Output voltages: [0.054179, 0.017407, 0.018457, 0.20231, 0.01476, 0.005644, 0.0010687, 0.79865, 0.068314, 0.33482]
Predicted label: 7
Correct prediction
Energy consumption = 151.352147 pJ
sum error= 316
Actual label: 5
Output voltages: [0.43509, 0.024895, 0.0011274, 0.73762, 0.24706, 0.79873, 0.43927, 0.0015571, 0.50737, 0.061516]
Predicted label: 5
Correct prediction
Energy consumption = 147.990641 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 703 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 703 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 703 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.13835, 0.048098, 0.68036, 0.01661, 0.038892, 0.0011171, 0.0011216, 0.79873, 0.28335, 0.32765]
Predicted label: 7
Correct prediction
Energy consumption = 152.854907 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79742, 0.065942, 0.69021, 0.032312, 0.0094193, 0.0010659, 0.091951, 0.0020191, 0.69209, 0.66118]
Predicted label: 0
Correct prediction
Energy consumption = 153.216625 pJ
sum error= 316
Actual label: 7
Output voltages: [0.029615, 0.027289, 0.031441, 0.057682, 0.038161, 0.0015551, 0.0010722, 0.7987, 0.54673, 0.52735]
Predicted label: 7
Correct prediction
Energy consumption = 156.579139 pJ
sum error= 316
Actual label: 4
Output voltages: [0.041097, 0.0028565, 0.021509, 0.035779, 0.79879, 0.0010741, 0.013303, 0.013825, 0.14522, 0.044723]
Predicted label: 4
Correct prediction
Energy consumption = 148.489194 pJ
sum error= 316
Actual label: 8
Output voltages: [0.011684, 0.03808, 0.32421, 0.028505, 0.019266, 0.0028518, 0.023842, 0.0067925, 0.79869, 0.070816]
Predicted label: 8
Correct prediction
Energy consumption = 144.441709 pJ
sum error= 316
Actual label: 8
Output voltages: [0.66519, 0.0066555, 0.03972, 0.78099, 0.0010661, 0.020566, 0.014627, 0.0012844, 0.79655, 0.053116]
Predicted label: 8
Correct prediction
Energy consumption = 153.455490 pJ
sum error= 316
Actual label: 5
Output voltages: [0.023183, 0.0011201, 0.0019619, 0.25468, 0.092316, 0.79879, 0.31768, 0.017236, 0.78552, 0.0014042]
Predicted label: 5
Correct prediction
Energy consumption = 137.428065 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79823, 0.0378, 0.019676, 0.016922, 0.045636, 0.016993, 0.76905, 0.027534, 0.052419, 0.031103]
Predicted label: 0
Correct prediction
Energy consumption = 154.455825 pJ
sum error= 316
Actual label: 6
Output voltages: [0.066395, 0.10828, 0.31037, 0.0043773, 0.27994, 0.071065, 0.79873, 0.0020142, 0.46807, 0.01866]
Predicted label: 6
Correct prediction
Energy consumption = 139.907440 pJ
sum error= 316
Actual label: 6
Output voltages: [0.15176, 0.018274, 0.081696, 0.0045474, 0.5057, 0.27081, 0.79879, 0.0023837, 0.74944, 0.0019189]
Predicted label: 6
Correct prediction
Energy consumption = 131.704280 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 704 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 704 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 704 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.41442, 0.0017879, 0.13759, 0.79879, 0.0081293, 0.047163, 0.0014206, 0.022762, 0.7713, 0.010117]
Predicted label: 3
Correct prediction
Energy consumption = 148.720874 pJ
sum error= 316
Actual label: 7
Output voltages: [0.34473, 0.019415, 0.19402, 0.28028, 0.009014, 0.009001, 0.0012331, 0.79873, 0.2811, 0.37012]
Predicted label: 7
Correct prediction
Energy consumption = 147.158546 pJ
sum error= 316
Actual label: 6
Output voltages: [0.14019, 0.027652, 0.038612, 0.0029461, 0.26668, 0.55617, 0.79877, 0.0084649, 0.47714, 0.0088784]
Predicted label: 6
Correct prediction
Energy consumption = 152.929919 pJ
sum error= 316
Actual label: 9
Output voltages: [0.42499, 0.0087497, 0.022021, 0.033802, 0.54467, 0.0075762, 0.021808, 0.0016118, 0.69013, 0.79829]
Predicted label: 9
Correct prediction
Energy consumption = 150.087086 pJ
sum error= 316
Actual label: 9
Output voltages: [0.49341, 0.0091864, 0.0033373, 0.062315, 0.56599, 0.0018114, 0.0020338, 0.0019023, 0.27148, 0.79863]
Predicted label: 9
Correct prediction
Energy consumption = 138.562521 pJ
sum error= 316
Actual label: 4
Output voltages: [0.026806, 0.029768, 0.17407, 0.020292, 0.7986, 0.0012073, 0.05679, 0.024186, 0.012924, 0.035533]
Predicted label: 4
Correct prediction
Energy consumption = 147.873652 pJ
sum error= 316
Actual label: 8
Output voltages: [0.041766, 0.036873, 0.073873, 0.079322, 0.0094738, 0.045697, 0.032207, 0.011321, 0.79873, 0.04214]
Predicted label: 8
Correct prediction
Energy consumption = 153.229342 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0041448, 0.0094149, 0.047651, 0.072413, 0.79874, 0.0065524, 0.0068931, 0.0080052, 0.12371, 0.027764]
Predicted label: 4
Correct prediction
Energy consumption = 146.100284 pJ
sum error= 316
Actual label: 1
Output voltages: [0.021174, 0.79865, 0.058643, 0.15002, 0.37912, 0.0010673, 0.60165, 0.0075308, 0.014696, 0.23823]
Predicted label: 1
Correct prediction
Energy consumption = 156.993876 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79801, 0.0085964, 0.1146, 0.035452, 0.0066731, 0.0046794, 0.36248, 0.042811, 0.39182, 0.021156]
Predicted label: 0
Correct prediction
Energy consumption = 151.981868 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 705 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 705 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 705 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.30403, 0.019403, 0.050259, 0.0054441, 0.53939, 0.053835, 0.79871, 0.0027662, 0.64766, 0.0029398]
Predicted label: 6
Correct prediction
Energy consumption = 150.885156 pJ
sum error= 316
Actual label: 6
Output voltages: [0.19699, 0.055352, 0.023383, 0.014046, 0.24886, 0.14105, 0.79761, 0.0049315, 0.74834, 0.016855]
Predicted label: 6
Correct prediction
Energy consumption = 131.983756 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79833, 0.064972, 0.23744, 0.010841, 0.027473, 0.0013755, 0.69501, 0.013252, 0.19566, 0.13099]
Predicted label: 0
Correct prediction
Energy consumption = 147.557161 pJ
sum error= 316
Actual label: 1
Output voltages: [0.020573, 0.79848, 0.031996, 0.016789, 0.032989, 0.0031059, 0.64002, 0.0092449, 0.16504, 0.034724]
Predicted label: 1
Correct prediction
Energy consumption = 160.068560 pJ
sum error= 316
Actual label: 2
Output voltages: [0.52892, 0.17468, 0.79879, 0.010619, 0.031245, 0.0012712, 0.018164, 0.76898, 0.11866, 0.02357]
Predicted label: 2
Correct prediction
Energy consumption = 145.569361 pJ
sum error= 316
Actual label: 3
Output voltages: [0.051337, 0.017083, 0.031071, 0.79872, 0.020839, 0.0055005, 0.0039433, 0.0145, 0.58377, 0.031678]
Predicted label: 3
Correct prediction
Energy consumption = 141.979476 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0028987, 0.005898, 0.024439, 0.0069447, 0.79864, 0.0040837, 0.24077, 0.57404, 0.25227, 0.0041203]
Predicted label: 4
Correct prediction
Energy consumption = 143.199050 pJ
sum error= 316
Actual label: 5
Output voltages: [0.036407, 0.0010709, 0.0017772, 0.13814, 0.010982, 0.79856, 0.41218, 0.0065625, 0.74035, 0.0063861]
Predicted label: 5
Correct prediction
Energy consumption = 141.142744 pJ
sum error= 316
Actual label: 6
Output voltages: [0.14173, 0.041215, 0.12745, 0.0012693, 0.29469, 0.28875, 0.79877, 0.006539, 0.28226, 0.0015929]
Predicted label: 6
Correct prediction
Energy consumption = 140.392998 pJ
sum error= 316
Actual label: 7
Output voltages: [0.24616, 0.21362, 0.77837, 0.02812, 0.0058954, 0.0010805, 0.0011241, 0.79879, 0.3599, 0.07721]
Predicted label: 7
Correct prediction
Energy consumption = 153.373808 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 706 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 706 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 706 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.036759, 0.029042, 0.033345, 0.56414, 0.0016418, 0.65562, 0.020268, 0.0027987, 0.79874, 0.043779]
Predicted label: 8
Correct prediction
Energy consumption = 150.909559 pJ
sum error= 316
Actual label: 9
Output voltages: [0.46562, 0.0063264, 0.029763, 0.014632, 0.58918, 0.0020228, 0.0010905, 0.028815, 0.35929, 0.79555]
Predicted label: 9
Correct prediction
Energy consumption = 152.413682 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79849, 0.041823, 0.064718, 0.015837, 0.013013, 0.0053828, 0.51974, 0.012961, 0.11595, 0.009944]
Predicted label: 0
Correct prediction
Energy consumption = 149.325878 pJ
sum error= 316
Actual label: 1
Output voltages: [0.033422, 0.79864, 0.18591, 0.11718, 0.066233, 0.0016174, 0.50057, 0.0047986, 0.15659, 0.043589]
Predicted label: 1
Correct prediction
Energy consumption = 165.732499 pJ
sum error= 316
Actual label: 2
Output voltages: [0.024253, 0.25825, 0.79876, 0.10863, 0.015133, 0.0012781, 0.022911, 0.51902, 0.25523, 0.0098494]
Predicted label: 2
Correct prediction
Energy consumption = 140.774477 pJ
sum error= 316
Actual label: 3
Output voltages: [0.46973, 0.046233, 0.038253, 0.79856, 0.064372, 0.016634, 0.023971, 0.014051, 0.42942, 0.41192]
Predicted label: 3
Correct prediction
Energy consumption = 144.433903 pJ
sum error= 316
Actual label: 4
Output voltages: [0.011792, 0.016107, 0.019049, 0.0018286, 0.79873, 0.024031, 0.085615, 0.43976, 0.22736, 0.0041504]
Predicted label: 4
Correct prediction
Energy consumption = 151.677754 pJ
sum error= 316
Actual label: 5
Output voltages: [0.011164, 0.001104, 0.0014366, 0.058918, 0.10743, 0.79737, 0.33845, 0.0020214, 0.77773, 0.016526]
Predicted label: 5
Correct prediction
Energy consumption = 145.297171 pJ
sum error= 316
Actual label: 6
Output voltages: [0.03151, 0.050202, 0.21938, 0.0015642, 0.17701, 0.10559, 0.79876, 0.0017228, 0.75852, 0.0062382]
Predicted label: 6
Correct prediction
Energy consumption = 144.100178 pJ
sum error= 316
Actual label: 7
Output voltages: [0.43145, 0.010361, 0.044118, 0.10104, 0.0026377, 0.0011156, 0.001161, 0.79865, 0.49328, 0.14093]
Predicted label: 7
Correct prediction
Energy consumption = 151.010597 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 707 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 707 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 707 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.019395, 0.21767, 0.21522, 0.16595, 0.020987, 0.0012643, 0.0060071, 0.036677, 0.79872, 0.043047]
Predicted label: 8
Correct prediction
Energy consumption = 151.724822 pJ
sum error= 316
Actual label: 9
Output voltages: [0.28273, 0.0029793, 0.0065754, 0.055766, 0.55248, 0.0046884, 0.0040816, 0.0044348, 0.34912, 0.7961]
Predicted label: 9
Correct prediction
Energy consumption = 144.166625 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79864, 0.21087, 0.035407, 0.058527, 0.0013438, 0.025049, 0.51481, 0.021121, 0.044306, 0.022183]
Predicted label: 0
Correct prediction
Energy consumption = 152.747147 pJ
sum error= 316
Actual label: 1
Output voltages: [0.010283, 0.79852, 0.042697, 0.05131, 0.0096907, 0.0018138, 0.61877, 0.015692, 0.40191, 0.014532]
Predicted label: 1
Correct prediction
Energy consumption = 157.256385 pJ
sum error= 316
Actual label: 2
Output voltages: [0.54368, 0.051846, 0.79877, 0.059632, 0.003689, 0.0012293, 0.159, 0.30602, 0.32572, 0.010605]
Predicted label: 2
Correct prediction
Energy consumption = 149.991701 pJ
sum error= 316
Actual label: 3
Output voltages: [0.5047, 0.0016686, 0.36401, 0.79877, 0.033565, 0.023974, 0.0034843, 0.0068659, 0.53535, 0.029145]
Predicted label: 3
Correct prediction
Energy consumption = 140.542808 pJ
sum error= 316
Actual label: 4
Output voltages: [0.002893, 0.0083327, 0.013675, 0.015777, 0.7987, 0.0013811, 0.045325, 0.04062, 0.1534, 0.0042588]
Predicted label: 4
Correct prediction
Energy consumption = 150.586192 pJ
sum error= 316
Actual label: 5
Output voltages: [0.034354, 0.0010965, 0.0010942, 0.25854, 0.046824, 0.79878, 0.39449, 0.013828, 0.53372, 0.032941]
Predicted label: 5
Correct prediction
Energy consumption = 145.316904 pJ
sum error= 316
Actual label: 6
Output voltages: [0.3631, 0.032858, 0.24477, 0.0010663, 0.33905, 0.033578, 0.79877, 0.001066, 0.12573, 0.0078974]
Predicted label: 6
Correct prediction
Energy consumption = 145.141917 pJ
sum error= 316
Actual label: 7
Output voltages: [0.072771, 0.06352, 0.037618, 0.2823, 0.0024178, 0.0010675, 0.0011407, 0.7987, 0.34199, 0.068341]
Predicted label: 7
Correct prediction
Energy consumption = 154.586774 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 708 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 708 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 708 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.30539, 0.13884, 0.4968, 0.039706, 0.022699, 0.0027504, 0.047171, 0.0015691, 0.79877, 0.15095]
Predicted label: 8
Correct prediction
Energy consumption = 155.619235 pJ
sum error= 316
Actual label: 9
Output voltages: [0.23201, 0.0015745, 0.015872, 0.0082146, 0.78047, 0.019062, 0.016788, 0.016531, 0.348, 0.79623]
Predicted label: 9
Correct prediction
Energy consumption = 145.389807 pJ
sum error= 316
Actual label: 7
Output voltages: [0.17657, 0.024582, 0.031424, 0.046969, 0.0019096, 0.0025691, 0.0011752, 0.79879, 0.76759, 0.44214]
Predicted label: 7
Correct prediction
Energy consumption = 149.035303 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0011336, 0.0022211, 0.014091, 0.023635, 0.79872, 0.0041422, 0.0051372, 0.11067, 0.33348, 0.021154]
Predicted label: 4
Correct prediction
Energy consumption = 152.735192 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79878, 0.13571, 0.25429, 0.025255, 0.014084, 0.0063998, 0.085073, 0.0068182, 0.1745, 0.2817]
Predicted label: 0
Correct prediction
Energy consumption = 162.786551 pJ
sum error= 316
Actual label: 4
Output voltages: [0.002331, 0.0013011, 0.0082536, 0.0040666, 0.79864, 0.0014466, 0.23617, 0.36714, 0.43043, 0.0014131]
Predicted label: 4
Correct prediction
Energy consumption = 147.542223 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79878, 0.026853, 0.094377, 0.0078032, 0.027003, 0.0043837, 0.18605, 0.027549, 0.17778, 0.01445]
Predicted label: 0
Correct prediction
Energy consumption = 154.935288 pJ
sum error= 316
Actual label: 1
Output voltages: [0.18809, 0.79857, 0.5036, 0.032578, 0.19683, 0.0010881, 0.26931, 0.0014743, 0.030081, 0.048002]
Predicted label: 1
Correct prediction
Energy consumption = 162.368636 pJ
sum error= 316
Actual label: 7
Output voltages: [0.33003, 0.0321, 0.16558, 0.12928, 0.014779, 0.0014548, 0.0011053, 0.79854, 0.306, 0.21955]
Predicted label: 7
Correct prediction
Energy consumption = 153.018658 pJ
sum error= 316
Actual label: 9
Output voltages: [0.14154, 0.014029, 0.047396, 0.027736, 0.73605, 0.0063501, 0.018711, 0.027235, 0.19511, 0.79623]
Predicted label: 9
Correct prediction
Energy consumption = 147.803760 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 709 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 709 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 709 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.028093, 0.005355, 0.001859, 0.44911, 0.028498, 0.79879, 0.25108, 0.032951, 0.36149, 0.055542]
Predicted label: 5
Correct prediction
Energy consumption = 153.432639 pJ
sum error= 316
Actual label: 1
Output voltages: [0.053838, 0.79876, 0.43678, 0.024788, 0.32249, 0.0012565, 0.54589, 0.0013873, 0.043493, 0.0063622]
Predicted label: 1
Correct prediction
Energy consumption = 160.481500 pJ
sum error= 316
Actual label: 4
Output voltages: [0.014447, 0.0065069, 0.02475, 0.0020357, 0.79873, 0.0040214, 0.27397, 0.4547, 0.16871, 0.0019364]
Predicted label: 4
Correct prediction
Energy consumption = 142.149151 pJ
sum error= 316
Actual label: 2
Output voltages: [0.28384, 0.097335, 0.7987, 0.081602, 0.0079047, 0.0012121, 0.024477, 0.40973, 0.59819, 0.014379]
Predicted label: 2
Correct prediction
Energy consumption = 152.368415 pJ
sum error= 316
Actual label: 8
Output voltages: [0.10877, 0.028485, 0.082743, 0.046002, 0.004279, 0.020832, 0.0044648, 0.017092, 0.79842, 0.7554]
Predicted label: 8
Correct prediction
Energy consumption = 148.739467 pJ
sum error= 316
Actual label: 9
Output voltages: [0.20939, 0.0054073, 0.018463, 0.028617, 0.40033, 0.0032469, 0.0041258, 0.015766, 0.39969, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 137.443576 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0029937, 0.0091949, 0.013732, 0.0022132, 0.79875, 0.0054939, 0.23317, 0.46672, 0.27235, 0.0044713]
Predicted label: 4
Correct prediction
Energy consumption = 140.235316 pJ
sum error= 316
Actual label: 3
Output voltages: [0.33588, 0.056919, 0.018777, 0.79862, 0.0062283, 0.026684, 0.0020364, 0.41593, 0.72134, 0.019168]
Predicted label: 3
Correct prediction
Energy consumption = 149.889573 pJ
sum error= 316
Actual label: 7
Output voltages: [0.26904, 0.012167, 0.022271, 0.66018, 0.0044108, 0.011933, 0.0012497, 0.79877, 0.54908, 0.47469]
Predicted label: 7
Correct prediction
Energy consumption = 141.216903 pJ
sum error= 316
Actual label: 8
Output voltages: [0.010708, 0.26574, 0.02365, 0.2136, 0.0020012, 0.065081, 0.0045331, 0.015427, 0.79872, 0.18455]
Predicted label: 8
Correct prediction
Energy consumption = 145.342072 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 710 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 710 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 710 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.16323, 0.019987, 0.79876, 0.26358, 0.011246, 0.0012095, 0.030254, 0.30167, 0.33018, 0.026874]
Predicted label: 2
Correct prediction
Energy consumption = 145.807374 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0020414, 0.002452, 0.017798, 0.0096975, 0.79868, 0.0025969, 0.054887, 0.059829, 0.3216, 0.0042955]
Predicted label: 4
Correct prediction
Energy consumption = 148.993935 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0020088, 0.0041206, 0.042875, 0.026566, 0.79876, 0.038882, 0.053653, 0.12053, 0.43677, 0.010221]
Predicted label: 4
Correct prediction
Energy consumption = 139.778046 pJ
sum error= 316
Actual label: 3
Output voltages: [0.24532, 0.023608, 0.13225, 0.79859, 0.030609, 0.025264, 0.018229, 0.041228, 0.46608, 0.13093]
Predicted label: 3
Correct prediction
Energy consumption = 147.772728 pJ
sum error= 316
Actual label: 3
Output voltages: [0.043597, 0.018171, 0.10469, 0.79874, 0.016217, 0.010487, 0.0031551, 0.061337, 0.59416, 0.039096]
Predicted label: 3
Correct prediction
Energy consumption = 128.636170 pJ
sum error= 316
Actual label: 6
Output voltages: [0.078447, 0.049022, 0.22761, 0.0012352, 0.19558, 0.20555, 0.79877, 0.0019122, 0.32709, 0.0017391]
Predicted label: 6
Correct prediction
Energy consumption = 144.707884 pJ
sum error= 316
Actual label: 9
Output voltages: [0.41538, 0.023321, 0.0018479, 0.22445, 0.47417, 0.004092, 0.0025326, 0.002675, 0.17875, 0.7983]
Predicted label: 9
Correct prediction
Energy consumption = 145.448148 pJ
sum error= 316
Actual label: 9
Output voltages: [0.34531, 0.0090856, 0.01814, 0.18007, 0.61657, 0.001971, 0.0035507, 0.024002, 0.084612, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 133.077196 pJ
sum error= 316
Actual label: 5
Output voltages: [0.50191, 0.0135, 0.0011144, 0.49212, 0.058454, 0.79878, 0.29142, 0.017213, 0.26097, 0.067958]
Predicted label: 5
Correct prediction
Energy consumption = 144.615696 pJ
sum error= 316
Actual label: 8
Output voltages: [0.028776, 0.070869, 0.21875, 0.21306, 0.017079, 0.0070065, 0.037629, 0.0030415, 0.79866, 0.31974]
Predicted label: 8
Correct prediction
Energy consumption = 145.325605 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 711 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 711 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 711 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.13944, 0.023359, 0.13333, 0.0088625, 0.40946, 0.43122, 0.79876, 0.001861, 0.66949, 0.0045177]
Predicted label: 6
Correct prediction
Energy consumption = 153.347419 pJ
sum error= 316
Actual label: 7
Output voltages: [0.0448, 0.015578, 0.089144, 0.48013, 0.0019999, 0.013751, 0.0011627, 0.79854, 0.20528, 0.39988]
Predicted label: 7
Correct prediction
Energy consumption = 155.138103 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79662, 0.07306, 0.052972, 0.015764, 0.0023773, 0.00122, 0.6962, 0.021583, 0.23171, 0.16811]
Predicted label: 0
Correct prediction
Energy consumption = 154.443391 pJ
sum error= 316
Actual label: 6
Output voltages: [0.23397, 0.021732, 0.35824, 0.001076, 0.35654, 0.049462, 0.79873, 0.0011525, 0.059878, 0.0034002]
Predicted label: 6
Correct prediction
Energy consumption = 139.126484 pJ
sum error= 316
Actual label: 8
Output voltages: [0.025605, 0.061012, 0.28112, 0.10088, 0.021527, 0.025156, 0.026368, 0.028968, 0.79868, 0.14457]
Predicted label: 8
Correct prediction
Energy consumption = 151.476134 pJ
sum error= 316
Actual label: 2
Output voltages: [0.055299, 0.014406, 0.79879, 0.34281, 0.02968, 0.0012011, 0.0092059, 0.49269, 0.3329, 0.02664]
Predicted label: 2
Correct prediction
Energy consumption = 140.326900 pJ
sum error= 316
Actual label: 6
Output voltages: [0.045132, 0.10671, 0.43247, 0.0011591, 0.28416, 0.044593, 0.79878, 0.0012259, 0.30753, 0.0019397]
Predicted label: 6
Correct prediction
Energy consumption = 141.631097 pJ
sum error= 316
Actual label: 3
Output voltages: [0.019011, 0.01754, 0.27952, 0.79875, 0.0011422, 0.0041926, 0.0038739, 0.027365, 0.78514, 0.016904]
Predicted label: 3
Correct prediction
Energy consumption = 142.166599 pJ
sum error= 316
Actual label: 9
Output voltages: [0.052393, 0.01973, 0.021989, 0.063657, 0.036737, 0.01462, 0.0013005, 0.023706, 0.49372, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.457620 pJ
sum error= 316
Actual label: 3
Output voltages: [0.26216, 0.052389, 0.042768, 0.79869, 0.012326, 0.017276, 0.015978, 0.016893, 0.70668, 0.033829]
Predicted label: 3
Correct prediction
Energy consumption = 139.875873 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 712 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 712 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 712 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.13615, 0.12151, 0.79815, 0.40514, 0.04686, 0.0010953, 0.030145, 0.52491, 0.73067, 0.0098071]
Predicted label: 2
Correct prediction
Energy consumption = 151.068629 pJ
sum error= 316
Actual label: 8
Output voltages: [0.033434, 0.029422, 0.030218, 0.032059, 0.0059371, 0.0024251, 0.0023439, 0.003516, 0.79738, 0.74177]
Predicted label: 8
Correct prediction
Energy consumption = 153.906085 pJ
sum error= 316
Actual label: 6
Output voltages: [0.18999, 0.13907, 0.069428, 0.0058671, 0.37142, 0.23003, 0.79871, 0.0033221, 0.19716, 0.0035988]
Predicted label: 6
Correct prediction
Energy consumption = 154.424739 pJ
sum error= 316
Actual label: 1
Output voltages: [0.022551, 0.79864, 0.29279, 0.039442, 0.11934, 0.0010681, 0.55165, 0.0069605, 0.059336, 0.024331]
Predicted label: 1
Correct prediction
Energy consumption = 159.688570 pJ
sum error= 316
Actual label: 7
Output voltages: [0.10696, 0.047065, 0.75591, 0.039678, 0.0014493, 0.0011575, 0.0010696, 0.79879, 0.58903, 0.049985]
Predicted label: 7
Correct prediction
Energy consumption = 148.293072 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0032913, 0.0073091, 0.036893, 0.0082481, 0.79871, 0.0094366, 0.11697, 0.36944, 0.26204, 0.0016126]
Predicted label: 4
Correct prediction
Energy consumption = 147.893855 pJ
sum error= 316
Actual label: 8
Output voltages: [0.0060969, 0.021996, 0.061395, 0.037334, 0.018391, 0.027235, 0.014882, 0.016186, 0.79872, 0.058875]
Predicted label: 8
Correct prediction
Energy consumption = 143.085009 pJ
sum error= 316
Actual label: 8
Output voltages: [0.0057084, 0.24228, 0.03068, 0.37797, 0.0025929, 0.0059396, 0.0036734, 0.027276, 0.79879, 0.23623]
Predicted label: 8
Correct prediction
Energy consumption = 136.182052 pJ
sum error= 316
Actual label: 9
Output voltages: [0.24882, 0.0072184, 0.026606, 0.021406, 0.43687, 0.0029924, 0.0013377, 0.02199, 0.42171, 0.79858]
Predicted label: 9
Correct prediction
Energy consumption = 142.898343 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79819, 0.18452, 0.14616, 0.023756, 0.01511, 0.0031291, 0.139, 0.0099203, 0.087981, 0.018354]
Predicted label: 0
Correct prediction
Energy consumption = 152.274983 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 713 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 713 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 713 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.065244, 0.13145, 0.037635, 0.79866, 0.0052797, 0.0019632, 0.0041262, 0.035397, 0.4505, 0.16283]
Predicted label: 3
Correct prediction
Energy consumption = 148.871527 pJ
sum error= 316
Actual label: 3
Output voltages: [0.13342, 0.048786, 0.06049, 0.79852, 0.013267, 0.021199, 0.0060736, 0.055254, 0.53053, 0.040052]
Predicted label: 3
Correct prediction
Energy consumption = 134.617902 pJ
sum error= 316
Actual label: 9
Output voltages: [0.15566, 0.0057732, 0.017313, 0.016436, 0.32307, 0.023275, 0.023843, 0.012787, 0.43412, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 144.468500 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79853, 0.050685, 0.12382, 0.047694, 0.019016, 0.0016028, 0.59232, 0.019301, 0.35217, 0.058681]
Predicted label: 0
Correct prediction
Energy consumption = 157.234906 pJ
sum error= 316
Actual label: 5
Output voltages: [0.036751, 0.0010858, 0.0010673, 0.18496, 0.20502, 0.79876, 0.46107, 0.011925, 0.73764, 0.026841]
Predicted label: 5
Correct prediction
Energy consumption = 142.465981 pJ
sum error= 316
Actual label: 2
Output voltages: [0.11416, 0.033801, 0.79879, 0.34749, 0.010761, 0.0011935, 0.017354, 0.38742, 0.22519, 0.012802]
Predicted label: 2
Correct prediction
Energy consumption = 143.167458 pJ
sum error= 316
Actual label: 9
Output voltages: [0.047943, 0.015059, 0.035809, 0.025056, 0.058789, 0.0051516, 0.0049713, 0.0041909, 0.7474, 0.79356]
Predicted label: 9
Correct prediction
Energy consumption = 146.301081 pJ
sum error= 316
Actual label: 4
Output voltages: [0.03982, 0.0059229, 0.30798, 0.0096452, 0.79879, 0.0088821, 0.065778, 0.022335, 0.31678, 0.0014564]
Predicted label: 4
Correct prediction
Energy consumption = 139.357373 pJ
sum error= 316
Actual label: 1
Output voltages: [0.019068, 0.79879, 0.38121, 0.049182, 0.20081, 0.0010781, 0.547, 0.014684, 0.029367, 0.0027927]
Predicted label: 1
Correct prediction
Energy consumption = 148.336939 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79874, 0.026468, 0.083765, 0.018262, 0.01784, 0.0019883, 0.3503, 0.0063591, 0.33248, 0.048928]
Predicted label: 0
Correct prediction
Energy consumption = 147.137869 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 714 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 714 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 714 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.4734, 0.022421, 0.040325, 0.79862, 0.020197, 0.015876, 0.022357, 0.018536, 0.39988, 0.034244]
Predicted label: 3
Correct prediction
Energy consumption = 149.563322 pJ
sum error= 316
Actual label: 7
Output voltages: [0.045298, 0.039898, 0.18447, 0.40152, 0.0028035, 0.0010822, 0.0010998, 0.79865, 0.42991, 0.20079]
Predicted label: 7
Correct prediction
Energy consumption = 151.647861 pJ
sum error= 316
Actual label: 5
Output voltages: [0.034881, 0.0011077, 0.0010708, 0.062311, 0.17791, 0.79869, 0.18165, 0.0214, 0.72182, 0.043619]
Predicted label: 5
Correct prediction
Energy consumption = 146.837925 pJ
sum error= 316
Actual label: 8
Output voltages: [0.025289, 0.089504, 0.33934, 0.068681, 0.0085628, 0.010048, 0.038615, 0.027096, 0.79876, 0.14346]
Predicted label: 8
Correct prediction
Energy consumption = 142.603229 pJ
sum error= 316
Actual label: 7
Output voltages: [0.36035, 0.048783, 0.029985, 0.22052, 0.013708, 0.0012455, 0.0010864, 0.79868, 0.63731, 0.21674]
Predicted label: 7
Correct prediction
Energy consumption = 150.334879 pJ
sum error= 316
Actual label: 7
Output voltages: [0.4367, 0.11799, 0.38962, 0.0032264, 0.022406, 0.0010825, 0.0021992, 0.79877, 0.40102, 0.14146]
Predicted label: 7
Correct prediction
Energy consumption = 137.684658 pJ
sum error= 316
Actual label: 8
Output voltages: [0.035981, 0.03053, 0.28718, 0.065984, 0.024864, 0.01912, 0.017076, 0.013164, 0.79871, 0.055473]
Predicted label: 8
Correct prediction
Energy consumption = 148.073556 pJ
sum error= 316
Actual label: 2
Output voltages: [0.44531, 0.011235, 0.79877, 0.047027, 0.013625, 0.0010682, 0.1088, 0.246, 0.68096, 0.0088144]
Predicted label: 2
Correct prediction
Energy consumption = 143.203292 pJ
sum error= 316
Actual label: 9
Output voltages: [0.090959, 0.023227, 0.031189, 0.18755, 0.08147, 0.0097267, 0.0053295, 0.033805, 0.56717, 0.79843]
Predicted label: 9
Correct prediction
Energy consumption = 151.409876 pJ
sum error= 316
Actual label: 7
Output voltages: [0.099261, 0.041338, 0.30155, 0.04937, 0.01712, 0.0018072, 0.0012834, 0.79879, 0.37043, 0.24034]
Predicted label: 7
Correct prediction
Energy consumption = 139.147648 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 715 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 715 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 715 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.04635, 0.79878, 0.15288, 0.053421, 0.42831, 0.0010926, 0.20854, 0.0026813, 0.028209, 0.067177]
Predicted label: 1
Correct prediction
Energy consumption = 155.123328 pJ
sum error= 316
Actual label: 2
Output voltages: [0.29782, 0.010962, 0.79879, 0.28214, 0.03541, 0.0011796, 0.020864, 0.19674, 0.55786, 0.036309]
Predicted label: 2
Correct prediction
Energy consumption = 141.029219 pJ
sum error= 316
Actual label: 6
Output voltages: [0.087121, 0.046343, 0.16251, 0.0011905, 0.35114, 0.054534, 0.79873, 0.001066, 0.4365, 0.0025262]
Predicted label: 6
Correct prediction
Energy consumption = 146.540885 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0011818, 0.015574, 0.066284, 0.0010873, 0.79876, 0.023763, 0.029067, 0.043233, 0.66637, 0.02065]
Predicted label: 4
Correct prediction
Energy consumption = 146.705731 pJ
sum error= 316
Actual label: 2
Output voltages: [0.19177, 0.044185, 0.79878, 0.12232, 0.015276, 0.0013113, 0.050102, 0.40305, 0.48434, 0.024206]
Predicted label: 2
Correct prediction
Energy consumption = 149.739401 pJ
sum error= 316
Actual label: 5
Output voltages: [0.11853, 0.0010826, 0.0034233, 0.43139, 0.063871, 0.79879, 0.27288, 0.014563, 0.69371, 0.0083593]
Predicted label: 5
Correct prediction
Energy consumption = 143.142431 pJ
sum error= 316
Actual label: 2
Output voltages: [0.041197, 0.15627, 0.7987, 0.026058, 0.017068, 0.0011691, 0.017638, 0.62047, 0.13312, 0.039137]
Predicted label: 2
Correct prediction
Energy consumption = 148.706222 pJ
sum error= 316
Actual label: 3
Output voltages: [0.17698, 0.051566, 0.092303, 0.79861, 0.018058, 0.0091222, 0.0082642, 0.026128, 0.67806, 0.028053]
Predicted label: 3
Correct prediction
Energy consumption = 147.306159 pJ
sum error= 316
Actual label: 6
Output voltages: [0.22744, 0.078222, 0.06934, 0.0064556, 0.37382, 0.54812, 0.79875, 0.0093913, 0.41254, 0.0025006]
Predicted label: 6
Correct prediction
Energy consumption = 156.397019 pJ
sum error= 316
Actual label: 6
Output voltages: [0.18539, 0.12205, 0.22599, 0.0029249, 0.10759, 0.32084, 0.79873, 0.0060195, 0.28354, 0.011678]
Predicted label: 6
Correct prediction
Energy consumption = 136.842646 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 716 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 716 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 716 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.047541, 0.0010791, 0.0011122, 0.68454, 0.16378, 0.79879, 0.62247, 0.01131, 0.68793, 0.025206]
Predicted label: 5
Correct prediction
Energy consumption = 148.793940 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79856, 0.04689, 0.14376, 0.012709, 0.037064, 0.0050881, 0.30079, 0.016625, 0.14558, 0.01186]
Predicted label: 0
Correct prediction
Energy consumption = 156.377279 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79548, 0.0064501, 0.21644, 0.033085, 0.028619, 0.0020653, 0.5259, 0.0061436, 0.63633, 0.29595]
Predicted label: 0
Correct prediction
Energy consumption = 149.798094 pJ
sum error= 316
Actual label: 2
Output voltages: [0.11911, 0.06924, 0.79879, 0.20171, 0.027543, 0.0011415, 0.0436, 0.72305, 0.52088, 0.092714]
Predicted label: 2
Correct prediction
Energy consumption = 147.913258 pJ
sum error= 316
Actual label: 8
Output voltages: [0.006496, 0.11905, 0.22429, 0.061074, 0.024228, 0.016345, 0.011012, 0.036488, 0.79867, 0.076883]
Predicted label: 8
Correct prediction
Energy consumption = 149.341946 pJ
sum error= 316
Actual label: 1
Output voltages: [0.051173, 0.79879, 0.062478, 0.0045583, 0.56762, 0.00218, 0.17306, 0.0010742, 0.17062, 0.054424]
Predicted label: 1
Correct prediction
Energy consumption = 153.263018 pJ
sum error= 316
Actual label: 6
Output voltages: [0.02164, 0.019703, 0.42558, 0.0010679, 0.29621, 0.042889, 0.79878, 0.0016496, 0.52858, 0.0014545]
Predicted label: 6
Correct prediction
Energy consumption = 141.217879 pJ
sum error= 316
Actual label: 1
Output voltages: [0.018156, 0.79858, 0.037705, 0.012311, 0.038323, 0.0015194, 0.59631, 0.010468, 0.25631, 0.020965]
Predicted label: 1
Correct prediction
Energy consumption = 155.697954 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79877, 0.069011, 0.44024, 0.011386, 0.03181, 0.0014964, 0.28577, 0.011493, 0.34967, 0.048976]
Predicted label: 0
Correct prediction
Energy consumption = 152.142078 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0030874, 0.021123, 0.037718, 0.0043305, 0.79875, 0.014774, 0.033728, 0.38843, 0.41672, 0.0035873]
Predicted label: 4
Correct prediction
Energy consumption = 150.755873 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 717 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 717 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 717 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.048834, 0.31835, 0.10118, 0.79876, 0.0011357, 0.0051391, 0.0019644, 0.34903, 0.78241, 0.011643]
Predicted label: 3
Correct prediction
Energy consumption = 147.487199 pJ
sum error= 316
Actual label: 1
Output voltages: [0.039598, 0.79857, 0.12269, 0.048168, 0.31744, 0.0010666, 0.3698, 0.0054465, 0.037429, 0.15336]
Predicted label: 1
Correct prediction
Energy consumption = 154.924529 pJ
sum error= 316
Actual label: 6
Output voltages: [0.021384, 0.027426, 0.32532, 0.0015135, 0.52571, 0.069299, 0.79869, 0.0020021, 0.40395, 0.0054533]
Predicted label: 6
Correct prediction
Energy consumption = 143.361511 pJ
sum error= 316
Actual label: 1
Output voltages: [0.028035, 0.79871, 0.17344, 0.030411, 0.081172, 0.0013965, 0.73131, 0.0010801, 0.15768, 0.02217]
Predicted label: 1
Correct prediction
Energy consumption = 145.872024 pJ
sum error= 316
Actual label: 9
Output voltages: [0.19619, 0.0032883, 0.024796, 0.016614, 0.28209, 0.0023069, 0.0034441, 0.013605, 0.55351, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 149.800055 pJ
sum error= 316
Actual label: 0
Output voltages: [0.7987, 0.26935, 0.027136, 0.023339, 0.024511, 0.015097, 0.27193, 0.011162, 0.041843, 0.16502]
Predicted label: 0
Correct prediction
Energy consumption = 144.071070 pJ
sum error= 316
Actual label: 1
Output voltages: [0.041704, 0.79848, 0.048611, 0.14864, 0.021144, 0.0013909, 0.65964, 0.049273, 0.035366, 0.03268]
Predicted label: 1
Correct prediction
Energy consumption = 163.665526 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0022397, 0.024828, 0.048305, 0.028054, 0.79862, 0.0010769, 0.022106, 0.056494, 0.023121, 0.044913]
Predicted label: 4
Correct prediction
Energy consumption = 155.920183 pJ
sum error= 316
Actual label: 5
Output voltages: [0.015337, 0.0010757, 0.0014493, 0.51303, 0.057672, 0.7985, 0.039231, 0.032812, 0.66365, 0.1663]
Predicted label: 5
Correct prediction
Energy consumption = 142.894446 pJ
sum error= 316
Actual label: 6
Output voltages: [0.031886, 0.0027385, 0.034605, 0.012686, 0.1279, 0.22263, 0.7987, 0.0010722, 0.76684, 0.053986]
Predicted label: 6
Correct prediction
Energy consumption = 135.161960 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 718 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 718 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 718 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.038257, 0.038282, 0.16473, 0.056848, 0.01028, 0.0010671, 0.0020739, 0.79857, 0.022798, 0.13981]
Predicted label: 7
Correct prediction
Energy consumption = 157.059132 pJ
sum error= 316
Actual label: 8
Output voltages: [0.036157, 0.024946, 0.47435, 0.51612, 0.0027859, 0.0058413, 0.019032, 0.0012277, 0.79879, 0.045604]
Predicted label: 8
Correct prediction
Energy consumption = 149.194193 pJ
sum error= 316
Actual label: 9
Output voltages: [0.039539, 0.0012617, 0.044493, 0.040438, 0.0082591, 0.071124, 0.014761, 0.30062, 0.5082, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 150.702706 pJ
sum error= 316
Actual label: 1
Output voltages: [0.015159, 0.79846, 0.24148, 0.044139, 0.028941, 0.0044579, 0.56379, 0.012018, 0.29057, 0.023404]
Predicted label: 1
Correct prediction
Energy consumption = 168.477300 pJ
sum error= 316
Actual label: 2
Output voltages: [0.67426, 0.0014528, 0.79877, 0.12722, 0.0066977, 0.0010741, 0.020312, 0.060232, 0.60224, 0.0040946]
Predicted label: 2
Correct prediction
Energy consumption = 140.869697 pJ
sum error= 316
Actual label: 3
Output voltages: [0.41823, 0.003208, 0.030603, 0.79869, 0.011464, 0.047957, 0.0095846, 0.012511, 0.46462, 0.020721]
Predicted label: 3
Correct prediction
Energy consumption = 143.031024 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0014129, 0.0032755, 0.042824, 0.035381, 0.79867, 0.0016444, 0.014955, 0.011479, 0.1168, 0.03943]
Predicted label: 4
Correct prediction
Energy consumption = 141.166575 pJ
sum error= 316
Actual label: 5
Output voltages: [0.26434, 0.0011819, 0.0010858, 0.74052, 0.029019, 0.79874, 0.31965, 0.044119, 0.57551, 0.055338]
Predicted label: 5
Correct prediction
Energy consumption = 139.558223 pJ
sum error= 316
Actual label: 6
Output voltages: [0.023119, 0.0083702, 0.17371, 0.0032674, 0.1947, 0.32856, 0.79879, 0.0034463, 0.65932, 0.0018527]
Predicted label: 6
Correct prediction
Energy consumption = 141.242212 pJ
sum error= 316
Actual label: 7
Output voltages: [0.095703, 0.24618, 0.37594, 0.24101, 0.0036162, 0.0011393, 0.0012301, 0.79879, 0.03949, 0.23936]
Predicted label: 7
Correct prediction
Energy consumption = 149.462339 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 719 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 719 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 719 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.035847, 0.039017, 0.014759, 0.0020614, 0.010455, 0.58552, 0.031685, 0.084719, 0.02976]
Predicted label: 0
Correct prediction
Energy consumption = 142.151293 pJ
sum error= 316
Actual label: 1
Output voltages: [0.0452, 0.79879, 0.1436, 0.0094926, 0.15774, 0.0010931, 0.67289, 0.0014945, 0.19414, 0.0069753]
Predicted label: 1
Correct prediction
Energy consumption = 155.629664 pJ
sum error= 316
Actual label: 2
Output voltages: [0.45375, 0.0068768, 0.79876, 0.023508, 0.0071485, 0.0011113, 0.038242, 0.042133, 0.58992, 0.0016754]
Predicted label: 2
Correct prediction
Energy consumption = 139.021058 pJ
sum error= 316
Actual label: 3
Output voltages: [0.74791, 0.023061, 0.1169, 0.79878, 0.0045184, 0.028078, 0.0082362, 0.0064171, 0.3112, 0.012265]
Predicted label: 3
Correct prediction
Energy consumption = 137.650558 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0029703, 0.026001, 0.12156, 0.078494, 0.79869, 0.0015504, 0.052306, 0.066472, 0.0053583, 0.041266]
Predicted label: 4
Correct prediction
Energy consumption = 144.343426 pJ
sum error= 316
Actual label: 5
Output voltages: [0.27754, 0.0010908, 0.0012069, 0.41652, 0.024403, 0.79875, 0.42428, 0.043771, 0.5071, 0.010955]
Predicted label: 5
Correct prediction
Energy consumption = 131.922697 pJ
sum error= 316
Actual label: 6
Output voltages: [0.19262, 0.0056696, 0.10512, 0.0032329, 0.15743, 0.1252, 0.79874, 0.0010665, 0.7175, 0.022999]
Predicted label: 6
Correct prediction
Energy consumption = 139.050526 pJ
sum error= 316
Actual label: 7
Output voltages: [0.71528, 0.016206, 0.011214, 0.05695, 0.14029, 0.023584, 0.0064555, 0.79869, 0.17777, 0.28765]
Predicted label: 7
Correct prediction
Energy consumption = 150.233666 pJ
sum error= 316
Actual label: 8
Output voltages: [0.36557, 0.013947, 0.58169, 0.26785, 0.012623, 0.001066, 0.024852, 0.0028947, 0.78989, 0.29977]
Predicted label: 8
Correct prediction
Energy consumption = 143.647941 pJ
sum error= 316
Actual label: 9
Output voltages: [0.23331, 0.013592, 0.013563, 0.042273, 0.05306, 0.022211, 0.0012728, 0.038168, 0.48674, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 142.782387 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 720 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 720 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 720 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.025238, 0.28254, 0.053118, 0.36106, 0.02186, 0.0043163, 0.049185, 0.0037525, 0.79877, 0.3744]
Predicted label: 8
Correct prediction
Energy consumption = 157.058065 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0089339, 0.033234, 0.093532, 0.020442, 0.79867, 0.0012903, 0.020876, 0.036069, 0.036495, 0.013193]
Predicted label: 4
Correct prediction
Energy consumption = 151.063166 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79877, 0.31547, 0.031807, 0.027681, 0.0059465, 0.023001, 0.35902, 0.076107, 0.04972, 0.038019]
Predicted label: 0
Correct prediction
Energy consumption = 147.258707 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79879, 0.043471, 0.037191, 0.022584, 0.016652, 0.0035771, 0.40357, 0.014198, 0.10657, 0.033831]
Predicted label: 0
Correct prediction
Energy consumption = 140.751800 pJ
sum error= 316
Actual label: 7
Output voltages: [0.22322, 0.060293, 0.7557, 0.033951, 0.0034941, 0.0011579, 0.0010669, 0.79868, 0.27914, 0.062794]
Predicted label: 7
Correct prediction
Energy consumption = 151.633212 pJ
sum error= 316
Actual label: 2
Output voltages: [0.13751, 0.03414, 0.79868, 0.026607, 0.0027565, 0.0011547, 0.012187, 0.36963, 0.38596, 0.032545]
Predicted label: 2
Correct prediction
Energy consumption = 127.923445 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0017709, 0.042654, 0.086584, 0.028508, 0.79867, 0.0026805, 0.10743, 0.24825, 0.019738, 0.030075]
Predicted label: 4
Correct prediction
Energy consumption = 144.713758 pJ
sum error= 316
Actual label: 3
Output voltages: [0.34861, 0.015367, 0.031127, 0.79868, 0.013671, 0.02966, 0.0035297, 0.012548, 0.63115, 0.02006]
Predicted label: 3
Correct prediction
Energy consumption = 143.085793 pJ
sum error= 316
Actual label: 8
Output voltages: [0.014849, 0.11994, 0.73835, 0.45783, 0.0010669, 0.0015022, 0.022851, 0.37387, 0.7984, 0.19581]
Predicted label: 8
Correct prediction
Energy consumption = 136.279099 pJ
sum error= 316
Actual label: 6
Output voltages: [0.091437, 0.0013466, 0.016102, 0.014198, 0.064792, 0.76417, 0.79708, 0.0011992, 0.77447, 0.027946]
Predicted label: 6
Correct prediction
Energy consumption = 143.554350 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 721 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 721 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 721 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.29104, 0.037216, 0.014583, 0.023013, 0.40348, 0.17242, 0.79876, 0.0028215, 0.70934, 0.019435]
Predicted label: 6
Correct prediction
Energy consumption = 155.191061 pJ
sum error= 316
Actual label: 3
Output voltages: [0.23783, 0.0011669, 0.048759, 0.79879, 0.035198, 0.52685, 0.013948, 0.030741, 0.70995, 0.014221]
Predicted label: 3
Correct prediction
Energy consumption = 144.489971 pJ
sum error= 316
Actual label: 2
Output voltages: [0.030178, 0.0035207, 0.79879, 0.22326, 0.046312, 0.0011518, 0.013772, 0.1984, 0.18013, 0.037514]
Predicted label: 2
Correct prediction
Energy consumption = 129.658503 pJ
sum error= 316
Actual label: 6
Output voltages: [0.1214, 0.019862, 0.29324, 0.0017052, 0.36899, 0.34579, 0.79879, 0.0010735, 0.51311, 0.015908]
Predicted label: 6
Correct prediction
Energy consumption = 137.127355 pJ
sum error= 316
Actual label: 3
Output voltages: [0.40016, 0.0091201, 0.036219, 0.79868, 0.0072331, 0.016306, 0.010583, 0.018967, 0.51133, 0.026625]
Predicted label: 3
Correct prediction
Energy consumption = 147.073040 pJ
sum error= 316
Actual label: 3
Output voltages: [0.19734, 0.034625, 0.035977, 0.79862, 0.0073078, 0.043759, 0.0046976, 0.070343, 0.72579, 0.020535]
Predicted label: 3
Correct prediction
Energy consumption = 129.622607 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79854, 0.095135, 0.04291, 0.15456, 0.0012514, 0.0048056, 0.72693, 0.046375, 0.45147, 0.035918]
Predicted label: 0
Correct prediction
Energy consumption = 143.845033 pJ
sum error= 316
Actual label: 1
Output voltages: [0.1037, 0.79873, 0.45677, 0.0035873, 0.45891, 0.0025582, 0.05635, 0.0045262, 0.019333, 0.23358]
Predicted label: 1
Correct prediction
Energy consumption = 157.573856 pJ
sum error= 316
Actual label: 4
Output voltages: [0.0014969, 0.089458, 0.019827, 0.01852, 0.79857, 0.020856, 0.11888, 0.33141, 0.0058176, 0.062309]
Predicted label: 4
Correct prediction
Energy consumption = 143.754510 pJ
sum error= 316
Actual label: 7
Output voltages: [0.32571, 0.06584, 0.02589, 0.014094, 0.022667, 0.01172, 0.0019153, 0.79855, 0.064494, 0.1546]
Predicted label: 7
Correct prediction
Energy consumption = 153.466412 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 722 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 722 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 722 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.038018, 0.042907, 0.04775, 0.48667, 0.0054111, 0.0095193, 0.037117, 0.0088473, 0.79733, 0.52014]
Predicted label: 8
Correct prediction
Energy consumption = 149.764645 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79875, 0.14131, 0.020083, 0.02829, 0.032311, 0.011607, 0.28268, 0.021679, 0.083266, 0.41654]
Predicted label: 0
Correct prediction
Energy consumption = 146.469997 pJ
sum error= 316
Actual label: 3
Output voltages: [0.19506, 0.016425, 0.017361, 0.79868, 0.0097232, 0.0075449, 0.0084666, 0.011374, 0.54939, 0.04529]
Predicted label: 3
Correct prediction
Energy consumption = 140.834589 pJ
sum error= 316
Actual label: 1
Output voltages: [0.32809, 0.79865, 0.0078838, 0.038605, 0.63832, 0.0081732, 0.20832, 0.0011406, 0.33939, 0.051458]
Predicted label: 1
Correct prediction
Energy consumption = 152.836276 pJ
sum error= 316
Actual label: 9
Output voltages: [0.2989, 0.081308, 0.032583, 0.22611, 0.060023, 0.036483, 0.016383, 0.033455, 0.44657, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 149.593104 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79878, 0.089653, 0.023354, 0.027574, 0.019099, 0.012033, 0.46775, 0.0087656, 0.041509, 0.11998]
Predicted label: 0
Correct prediction
Energy consumption = 153.635905 pJ
sum error= 316
Actual label: 1
Output voltages: [0.029678, 0.79879, 0.019335, 0.063217, 0.14675, 0.0013541, 0.59298, 0.0042673, 0.077897, 0.052885]
Predicted label: 1
Correct prediction
Energy consumption = 154.724474 pJ
sum error= 316
Actual label: 9
Output voltages: [0.58273, 0.042925, 0.015, 0.1614, 0.38224, 0.018741, 0.0074972, 0.0031665, 0.24097, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 149.655200 pJ
sum error= 316
Actual label: 1
Output voltages: [0.068548, 0.79558, 0.04535, 0.0017154, 0.41483, 0.0010848, 0.44207, 0.0010676, 0.55072, 0.032481]
Predicted label: 1
Correct prediction
Energy consumption = 159.410125 pJ
sum error= 316
Actual label: 2
Output voltages: [0.077795, 0.0019849, 0.79875, 0.03491, 0.01428, 0.001066, 0.036054, 0.29604, 0.75201, 0.014211]
Predicted label: 2
Correct prediction
Energy consumption = 139.879195 pJ
sum error= 316
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 723 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 723 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 723 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25224, 0.15827, 0.31903, 0.036701, 0.019884, 0.0026055, 0.0010671, 0.79865, 0.035945, 0.30059]
Predicted label: 7
Correct prediction
Energy consumption = 155.803252 pJ
sum error= 316
Actual label: 0
Output voltages: [0.79878, 0.043277, 0.0062973, 0.030076, 0.032391, 0.0097037, 0.53633, 0.029598, 0.26378, 0.12635]
Predicted label: 0
Correct prediction
Energy consumption = 144.558090 pJ
sum error= 316
Actual label: 1
Output voltages: [0.021277, 0.79878, 0.02506, 0.0022458, 0.36901, 0.0029129, 0.32495, 0.0046784, 0.25226, 0.033233]
Predicted label: 1
Correct prediction
Energy consumption = 157.989940 pJ
sum error= 316
Actual label: 3
Output voltages: [0.79814, 0.0010749, 0.0084157, 0.79602, 0.0011275, 0.53966, 0.0038995, 0.077557, 0.38816, 0.014932]
Predicted label: 0
Wrong prediction!
Energy consumption = 149.984265 pJ
sum error= 317
Actual label: 8
Output voltages: [0.11112, 0.027988, 0.56115, 0.038485, 0.0021081, 0.0019405, 0.0086995, 0.02396, 0.79879, 0.311]
Predicted label: 8
Correct prediction
Energy consumption = 140.570173 pJ
sum error= 317
Actual label: 2
Output voltages: [0.059476, 0.001066, 0.79879, 0.041118, 0.025941, 0.0040534, 0.018026, 0.46703, 0.78023, 0.0037722]
Predicted label: 2
Correct prediction
Energy consumption = 131.963850 pJ
sum error= 317
Actual label: 9
Output voltages: [0.47072, 0.0083509, 0.042634, 0.046827, 0.255, 0.024395, 0.016299, 0.016986, 0.44495, 0.79353]
Predicted label: 9
Correct prediction
Energy consumption = 147.804596 pJ
sum error= 317
Actual label: 2
Output voltages: [0.59358, 0.0012955, 0.79837, 0.40848, 0.0075416, 0.010723, 0.011153, 0.030829, 0.73087, 0.0018373]
Predicted label: 2
Correct prediction
Energy consumption = 140.886820 pJ
sum error= 317
Actual label: 7
Output voltages: [0.226, 0.21737, 0.6662, 0.026587, 0.024375, 0.0010895, 0.020788, 0.79875, 0.0051444, 0.13504]
Predicted label: 7
Correct prediction
Energy consumption = 149.010775 pJ
sum error= 317
Actual label: 6
Output voltages: [0.20145, 0.047626, 0.1811, 0.003958, 0.24406, 0.18128, 0.79876, 0.0022582, 0.68123, 0.0033961]
Predicted label: 6
Correct prediction
Energy consumption = 141.366590 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 724 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 724 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 724 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.025005, 0.0011013, 0.010117, 0.7649, 0.23268, 0.79769, 0.026447, 0.023606, 0.57997, 0.0010987]
Predicted label: 5
Correct prediction
Energy consumption = 135.963452 pJ
sum error= 317
Actual label: 5
Output voltages: [0.031615, 0.0014286, 0.0010779, 0.21322, 0.52483, 0.79848, 0.34603, 0.0049286, 0.51743, 0.055047]
Predicted label: 5
Correct prediction
Energy consumption = 119.349437 pJ
sum error= 317
Actual label: 9
Output voltages: [0.53441, 0.0092677, 0.019188, 0.047896, 0.28755, 0.042781, 0.017084, 0.0058209, 0.49246, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 144.532071 pJ
sum error= 317
Actual label: 9
Output voltages: [0.20394, 0.030909, 0.015844, 0.18014, 0.13747, 0.020933, 0.028106, 0.030393, 0.64202, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 129.863395 pJ
sum error= 317
Actual label: 8
Output voltages: [0.050806, 0.019321, 0.05153, 0.05358, 0.0094182, 0.047474, 0.0075882, 0.003334, 0.79873, 0.40005]
Predicted label: 8
Correct prediction
Energy consumption = 136.184180 pJ
sum error= 317
Actual label: 2
Output voltages: [0.32111, 0.0045598, 0.79874, 0.091056, 0.0049526, 0.0010968, 0.041012, 0.10539, 0.73207, 0.0062403]
Predicted label: 2
Correct prediction
Energy consumption = 137.064048 pJ
sum error= 317
Actual label: 9
Output voltages: [0.25563, 0.0074215, 0.016068, 0.025855, 0.046025, 0.015121, 0.0034773, 0.050328, 0.60988, 0.79563]
Predicted label: 9
Correct prediction
Energy consumption = 148.241008 pJ
sum error= 317
Actual label: 1
Output voltages: [0.024427, 0.79833, 0.31516, 0.0069184, 0.2744, 0.0011252, 0.47808, 0.001905, 0.08124, 0.0081307]
Predicted label: 1
Correct prediction
Energy consumption = 152.439005 pJ
sum error= 317
Actual label: 3
Output voltages: [0.049809, 0.001188, 0.05378, 0.79879, 0.0056991, 0.16422, 0.018826, 0.022971, 0.35254, 0.0036889]
Predicted label: 3
Correct prediction
Energy consumption = 138.927416 pJ
sum error= 317
Actual label: 2
Output voltages: [0.52001, 0.0010671, 0.79842, 0.21206, 0.012891, 0.0068893, 0.041988, 0.27859, 0.75831, 0.0035169]
Predicted label: 2
Correct prediction
Energy consumption = 129.643045 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 725 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 725 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 725 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.49295, 0.0042908, 0.1336, 0.79879, 0.012375, 0.38349, 0.0016864, 0.0061162, 0.75635, 0.0035828]
Predicted label: 3
Correct prediction
Energy consumption = 141.733514 pJ
sum error= 317
Actual label: 4
Output voltages: [0.027398, 0.024315, 0.078038, 0.0016944, 0.79867, 0.00296, 0.27565, 0.31387, 0.037447, 0.0053658]
Predicted label: 4
Correct prediction
Energy consumption = 145.698647 pJ
sum error= 317
Actual label: 3
Output voltages: [0.66923, 0.0073441, 0.022648, 0.79873, 0.024235, 0.062265, 0.0067686, 0.0072593, 0.56704, 0.016819]
Predicted label: 3
Correct prediction
Energy consumption = 143.601482 pJ
sum error= 317
Actual label: 1
Output voltages: [0.17965, 0.79819, 0.51688, 0.0030245, 0.66383, 0.001069, 0.30096, 0.0014643, 0.037979, 0.0085776]
Predicted label: 1
Correct prediction
Energy consumption = 153.308792 pJ
sum error= 317
Actual label: 9
Output voltages: [0.33526, 0.023373, 0.022374, 0.057829, 0.17689, 0.021926, 0.010494, 0.012175, 0.44421, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 145.541089 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79873, 0.038437, 0.088128, 0.010254, 0.019642, 0.013288, 0.19851, 0.033241, 0.12769, 0.12228]
Predicted label: 0
Correct prediction
Energy consumption = 143.751690 pJ
sum error= 317
Actual label: 9
Output voltages: [0.047665, 0.0091395, 0.013087, 0.4018, 0.034318, 0.0026812, 0.0015111, 0.055433, 0.61913, 0.798]
Predicted label: 9
Correct prediction
Energy consumption = 149.913345 pJ
sum error= 317
Actual label: 3
Output voltages: [0.75923, 0.0017064, 0.096736, 0.79875, 0.040895, 0.1898, 0.0070793, 0.0083857, 0.25585, 0.02072]
Predicted label: 3
Correct prediction
Energy consumption = 143.221312 pJ
sum error= 317
Actual label: 6
Output voltages: [0.26568, 0.0031, 0.035421, 0.003483, 0.24118, 0.34808, 0.79809, 0.0011088, 0.74436, 0.036779]
Predicted label: 6
Correct prediction
Energy consumption = 143.770982 pJ
sum error= 317
Actual label: 8
Output voltages: [0.019511, 0.10933, 0.28931, 0.41825, 0.0011468, 0.001096, 0.028521, 0.042871, 0.79779, 0.52463]
Predicted label: 8
Correct prediction
Energy consumption = 139.129391 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 726 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 726 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 726 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.26656, 0.12619, 0.14733, 0.0039295, 0.037673, 0.0028203, 0.0014635, 0.79878, 0.053046, 0.22964]
Predicted label: 7
Correct prediction
Energy consumption = 151.582051 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79732, 0.054976, 0.21463, 0.018346, 0.0015766, 0.0015686, 0.60168, 0.016195, 0.1885, 0.077079]
Predicted label: 0
Correct prediction
Energy consumption = 141.438352 pJ
sum error= 317
Actual label: 1
Output voltages: [0.0098702, 0.7987, 0.02705, 0.0093774, 0.4734, 0.0018203, 0.14435, 0.0012944, 0.58599, 0.42409]
Predicted label: 1
Correct prediction
Energy consumption = 146.110985 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79879, 0.026629, 0.16714, 0.031294, 0.026721, 0.0014367, 0.32385, 0.010027, 0.20129, 0.043679]
Predicted label: 0
Correct prediction
Energy consumption = 143.183522 pJ
sum error= 317
Actual label: 5
Output voltages: [0.30578, 0.0010933, 0.0020826, 0.52327, 0.046128, 0.79862, 0.32319, 0.025874, 0.78033, 0.031806]
Predicted label: 5
Correct prediction
Energy consumption = 140.830928 pJ
sum error= 317
Actual label: 8
Output voltages: [0.028866, 0.014781, 0.050925, 0.72579, 0.0047995, 0.024474, 0.0069511, 0.0014367, 0.79869, 0.3012]
Predicted label: 8
Correct prediction
Energy consumption = 143.809004 pJ
sum error= 317
Actual label: 2
Output voltages: [0.29157, 0.0065235, 0.79868, 0.02299, 0.0027629, 0.0022965, 0.037171, 0.23399, 0.56779, 0.021582]
Predicted label: 2
Correct prediction
Energy consumption = 140.740321 pJ
sum error= 317
Actual label: 7
Output voltages: [0.46023, 0.040994, 0.17218, 0.03698, 0.0015679, 0.012117, 0.17667, 0.79807, 0.017179, 0.055499]
Predicted label: 7
Correct prediction
Energy consumption = 146.498456 pJ
sum error= 317
Actual label: 7
Output voltages: [0.31944, 0.026228, 0.02898, 0.0015021, 0.15904, 0.0011809, 0.0011726, 0.78448, 0.18952, 0.55044]
Predicted label: 7
Correct prediction
Energy consumption = 148.369196 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79877, 0.046552, 0.063221, 0.01372, 0.26194, 0.0062438, 0.32053, 0.0043871, 0.26759, 0.10129]
Predicted label: 0
Correct prediction
Energy consumption = 154.778335 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 727 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 727 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 727 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.024171, 0.79838, 0.030083, 0.13782, 0.016624, 0.0033721, 0.67218, 0.0055807, 0.04664, 0.041712]
Predicted label: 1
Correct prediction
Energy consumption = 164.800643 pJ
sum error= 317
Actual label: 2
Output voltages: [0.1271, 0.069121, 0.79691, 0.57267, 0.013847, 0.0011009, 0.0064588, 0.43464, 0.74446, 0.003613]
Predicted label: 2
Correct prediction
Energy consumption = 150.513825 pJ
sum error= 317
Actual label: 3
Output voltages: [0.057789, 0.034441, 0.17303, 0.79872, 0.02693, 0.0074797, 0.012992, 0.0075254, 0.46296, 0.2405]
Predicted label: 3
Correct prediction
Energy consumption = 149.379331 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0022853, 0.015264, 0.03324, 0.033036, 0.79867, 0.0011226, 0.02614, 0.050886, 0.025837, 0.027311]
Predicted label: 4
Correct prediction
Energy consumption = 152.117657 pJ
sum error= 317
Actual label: 5
Output voltages: [0.037828, 0.001066, 0.0063382, 0.4167, 0.026735, 0.79878, 0.17058, 0.19221, 0.73819, 0.064246]
Predicted label: 5
Correct prediction
Energy consumption = 148.837528 pJ
sum error= 317
Actual label: 6
Output voltages: [0.30625, 0.085259, 0.033061, 0.018111, 0.34274, 0.5257, 0.79874, 0.0011898, 0.58271, 0.0011391]
Predicted label: 6
Correct prediction
Energy consumption = 145.404438 pJ
sum error= 317
Actual label: 7
Output voltages: [0.58338, 0.03334, 0.044931, 0.03257, 0.030992, 0.0010775, 0.0010837, 0.79879, 0.12239, 0.22942]
Predicted label: 7
Correct prediction
Energy consumption = 162.901102 pJ
sum error= 317
Actual label: 8
Output voltages: [0.15083, 0.010197, 0.28282, 0.017199, 0.11198, 0.0063253, 0.020954, 0.0051202, 0.79878, 0.30524]
Predicted label: 8
Correct prediction
Energy consumption = 144.140939 pJ
sum error= 317
Actual label: 9
Output voltages: [0.3909, 0.0091717, 0.023799, 0.010982, 0.053399, 0.0082732, 0.0016132, 0.028019, 0.64164, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 150.089578 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79862, 0.039305, 0.38364, 0.029755, 0.0012126, 0.0041445, 0.26787, 0.0017383, 0.0666, 0.019205]
Predicted label: 0
Correct prediction
Energy consumption = 151.621902 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 728 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 728 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 728 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.033194, 0.79843, 0.14614, 0.17673, 0.3939, 0.0033946, 0.45892, 0.025479, 0.028464, 0.096382]
Predicted label: 1
Correct prediction
Energy consumption = 169.233985 pJ
sum error= 317
Actual label: 2
Output voltages: [0.63628, 0.13378, 0.79859, 0.054388, 0.013278, 0.001069, 0.1957, 0.055511, 0.28029, 0.042664]
Predicted label: 2
Correct prediction
Energy consumption = 143.508833 pJ
sum error= 317
Actual label: 3
Output voltages: [0.28669, 0.042344, 0.46119, 0.79879, 0.030057, 0.001081, 0.010205, 0.0011503, 0.69252, 0.063163]
Predicted label: 3
Correct prediction
Energy consumption = 144.586183 pJ
sum error= 317
Actual label: 4
Output voltages: [0.024148, 0.044132, 0.025207, 0.022343, 0.79875, 0.0011111, 0.17556, 0.02734, 0.01652, 0.040503]
Predicted label: 4
Correct prediction
Energy consumption = 155.577898 pJ
sum error= 317
Actual label: 5
Output voltages: [0.025599, 0.001574, 0.01052, 0.4427, 0.016783, 0.79803, 0.19301, 0.006103, 0.77053, 0.02063]
Predicted label: 5
Correct prediction
Energy consumption = 152.686427 pJ
sum error= 317
Actual label: 6
Output voltages: [0.029566, 0.038979, 0.090496, 0.012647, 0.45477, 0.11863, 0.79872, 0.0022444, 0.63535, 0.012845]
Predicted label: 6
Correct prediction
Energy consumption = 146.072211 pJ
sum error= 317
Actual label: 7
Output voltages: [0.33737, 0.06169, 0.014884, 0.029766, 0.0048374, 0.020703, 0.0010917, 0.79864, 0.11763, 0.2921]
Predicted label: 7
Correct prediction
Energy consumption = 157.953047 pJ
sum error= 317
Actual label: 8
Output voltages: [0.42735, 0.022525, 0.3406, 0.18327, 0.03477, 0.031524, 0.13098, 0.0032992, 0.79877, 0.040643]
Predicted label: 8
Correct prediction
Energy consumption = 156.987854 pJ
sum error= 317
Actual label: 9
Output voltages: [0.10591, 0.020488, 0.0096357, 0.34308, 0.15676, 0.015436, 0.0011205, 0.024971, 0.1178, 0.79818]
Predicted label: 9
Correct prediction
Energy consumption = 154.563698 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79874, 0.083972, 0.015973, 0.016757, 0.016864, 0.0073629, 0.73922, 0.01651, 0.22816, 0.046313]
Predicted label: 0
Correct prediction
Energy consumption = 150.768358 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 729 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 729 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 729 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0080273, 0.79854, 0.49042, 0.067851, 0.029214, 0.0010782, 0.40996, 0.0029719, 0.16907, 0.05119]
Predicted label: 1
Correct prediction
Energy consumption = 168.091315 pJ
sum error= 317
Actual label: 2
Output voltages: [0.47392, 0.24044, 0.79876, 0.29171, 0.001408, 0.001126, 0.050035, 0.033073, 0.33673, 0.05739]
Predicted label: 2
Correct prediction
Energy consumption = 151.511526 pJ
sum error= 317
Actual label: 3
Output voltages: [0.43955, 0.010229, 0.033364, 0.7987, 0.023616, 0.0043812, 0.031615, 0.0029923, 0.41236, 0.2516]
Predicted label: 3
Correct prediction
Energy consumption = 142.645667 pJ
sum error= 317
Actual label: 4
Output voltages: [0.095628, 0.014634, 0.0068789, 0.036531, 0.79878, 0.02898, 0.018507, 0.29767, 0.0039181, 0.68313]
Predicted label: 4
Correct prediction
Energy consumption = 165.330812 pJ
sum error= 317
Actual label: 5
Output voltages: [0.041878, 0.0010929, 0.0013452, 0.58805, 0.022972, 0.79878, 0.29218, 0.023004, 0.75268, 0.18797]
Predicted label: 5
Correct prediction
Energy consumption = 152.634636 pJ
sum error= 317
Actual label: 6
Output voltages: [0.077691, 0.037858, 0.35635, 0.0019684, 0.28435, 0.33564, 0.79869, 0.0051311, 0.41502, 0.0048772]
Predicted label: 6
Correct prediction
Energy consumption = 145.981703 pJ
sum error= 317
Actual label: 7
Output voltages: [0.048231, 0.066236, 0.011066, 0.049428, 0.015029, 0.015089, 0.0012709, 0.79879, 0.13862, 0.6427]
Predicted label: 7
Correct prediction
Energy consumption = 160.348565 pJ
sum error= 317
Actual label: 8
Output voltages: [0.021162, 0.058899, 0.60823, 0.098168, 0.024703, 0.027337, 0.059869, 0.020828, 0.79876, 0.20848]
Predicted label: 8
Correct prediction
Energy consumption = 151.632629 pJ
sum error= 317
Actual label: 9
Output voltages: [0.36758, 0.0066617, 0.019546, 0.024382, 0.27233, 0.0052462, 0.0011707, 0.032703, 0.44847, 0.79673]
Predicted label: 9
Correct prediction
Energy consumption = 155.950986 pJ
sum error= 317
Actual label: 1
Output voltages: [0.0086718, 0.79844, 0.050786, 0.12971, 0.039633, 0.0029826, 0.6333, 0.044199, 0.091292, 0.053354]
Predicted label: 1
Correct prediction
Energy consumption = 163.857034 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 730 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 730 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 730 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.15989, 0.024536, 0.010913, 0.14909, 0.015383, 0.021327, 0.0010666, 0.79877, 0.20959, 0.61923]
Predicted label: 7
Correct prediction
Energy consumption = 157.067245 pJ
sum error= 317
Actual label: 4
Output voltages: [0.015992, 0.41705, 0.12816, 0.633, 0.79879, 0.0010686, 0.19942, 0.21541, 0.001452, 0.045824]
Predicted label: 4
Correct prediction
Energy consumption = 154.508952 pJ
sum error= 317
Actual label: 8
Output voltages: [0.13126, 0.040331, 0.55379, 0.36045, 0.026034, 0.0017756, 0.046179, 0.0022057, 0.79865, 0.40824]
Predicted label: 8
Correct prediction
Energy consumption = 152.611951 pJ
sum error= 317
Actual label: 1
Output voltages: [0.0020357, 0.79861, 0.088701, 0.045952, 0.072255, 0.0011888, 0.24758, 0.0054017, 0.29051, 0.093495]
Predicted label: 1
Correct prediction
Energy consumption = 163.407219 pJ
sum error= 317
Actual label: 5
Output voltages: [0.031288, 0.0010827, 0.001094, 0.46906, 0.0167, 0.79851, 0.11094, 0.022316, 0.67959, 0.081393]
Predicted label: 5
Correct prediction
Energy consumption = 153.222058 pJ
sum error= 317
Actual label: 6
Output voltages: [0.06695, 0.036085, 0.38926, 0.0010755, 0.28761, 0.030056, 0.79879, 0.0011855, 0.41474, 0.0028277]
Predicted label: 6
Correct prediction
Energy consumption = 143.985249 pJ
sum error= 317
Actual label: 5
Output voltages: [0.04799, 0.0010864, 0.0010746, 0.31265, 0.19841, 0.79873, 0.28632, 0.020821, 0.66895, 0.0050472]
Predicted label: 5
Correct prediction
Energy consumption = 148.496833 pJ
sum error= 317
Actual label: 7
Output voltages: [0.42165, 0.04267, 0.016724, 0.18344, 0.015952, 0.0017587, 0.0012078, 0.79879, 0.040796, 0.272]
Predicted label: 7
Correct prediction
Energy consumption = 157.130594 pJ
sum error= 317
Actual label: 2
Output voltages: [0.55828, 0.0097784, 0.79877, 0.077451, 0.038402, 0.0011144, 0.05435, 0.045678, 0.47351, 0.03964]
Predicted label: 2
Correct prediction
Energy consumption = 138.124221 pJ
sum error= 317
Actual label: 8
Output voltages: [0.4859, 0.0089944, 0.2414, 0.14059, 0.0028656, 0.018229, 0.035151, 0.017789, 0.79874, 0.015819]
Predicted label: 8
Correct prediction
Energy consumption = 151.838099 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 731 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 731 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 731 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.040801, 0.020389, 0.36404, 0.0019767, 0.33934, 0.070554, 0.79877, 0.0032752, 0.46023, 0.0017642]
Predicted label: 6
Correct prediction
Energy consumption = 149.767009 pJ
sum error= 317
Actual label: 3
Output voltages: [0.42893, 0.030646, 0.4987, 0.79872, 0.041874, 0.0079381, 0.0071254, 0.014732, 0.52354, 0.053897]
Predicted label: 3
Correct prediction
Energy consumption = 148.771887 pJ
sum error= 317
Actual label: 3
Output voltages: [0.11148, 0.020499, 0.062164, 0.79866, 0.035109, 0.0043768, 0.010644, 0.025078, 0.65111, 0.05239]
Predicted label: 3
Correct prediction
Energy consumption = 126.198244 pJ
sum error= 317
Actual label: 8
Output voltages: [0.027129, 0.033475, 0.18384, 0.09684, 0.020833, 0.024878, 0.023365, 0.0055929, 0.79867, 0.33023]
Predicted label: 8
Correct prediction
Energy consumption = 142.859414 pJ
sum error= 317
Actual label: 6
Output voltages: [0.028651, 0.020039, 0.29626, 0.0016234, 0.23787, 0.17521, 0.79876, 0.0033164, 0.60935, 0.0017417]
Predicted label: 6
Correct prediction
Energy consumption = 149.222731 pJ
sum error= 317
Actual label: 5
Output voltages: [0.0065628, 0.0058675, 0.017167, 0.7773, 0.1493, 0.79781, 0.039942, 0.12498, 0.52326, 0.071912]
Predicted label: 5
Correct prediction
Energy consumption = 152.573041 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0076038, 0.0044314, 0.023412, 0.0040668, 0.79856, 0.0059692, 0.20974, 0.23247, 0.097863, 0.010118]
Predicted label: 4
Correct prediction
Energy consumption = 155.097043 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79864, 0.026635, 0.022802, 0.010019, 0.023335, 0.013945, 0.14934, 0.030365, 0.1466, 0.024879]
Predicted label: 0
Correct prediction
Energy consumption = 149.646394 pJ
sum error= 317
Actual label: 9
Output voltages: [0.47323, 0.01832, 0.030295, 0.33692, 0.15497, 0.029232, 0.0061752, 0.18564, 0.078498, 0.79797]
Predicted label: 9
Correct prediction
Energy consumption = 158.830482 pJ
sum error= 317
Actual label: 1
Output voltages: [0.017612, 0.79862, 0.061276, 0.013934, 0.019037, 0.0010687, 0.44718, 0.0011087, 0.29639, 0.027427]
Predicted label: 1
Correct prediction
Energy consumption = 164.381502 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 732 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 732 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 732 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.32663, 0.016373, 0.023054, 0.023426, 0.013619, 0.016846, 0.0010764, 0.79869, 0.51338, 0.31736]
Predicted label: 7
Correct prediction
Energy consumption = 162.818845 pJ
sum error= 317
Actual label: 2
Output voltages: [0.31331, 0.050301, 0.79871, 0.0093562, 0.020168, 0.0011517, 0.11718, 0.13354, 0.61672, 0.020353]
Predicted label: 2
Correct prediction
Energy consumption = 149.364709 pJ
sum error= 317
Actual label: 9
Output voltages: [0.23467, 0.012838, 0.079493, 0.37823, 0.27531, 0.015027, 0.025057, 0.26518, 0.46987, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 162.697172 pJ
sum error= 317
Actual label: 1
Output voltages: [0.024154, 0.79843, 0.044644, 0.097257, 0.034299, 0.0078932, 0.63544, 0.0042524, 0.077151, 0.071313]
Predicted label: 1
Correct prediction
Energy consumption = 171.005188 pJ
sum error= 317
Actual label: 5
Output voltages: [0.035601, 0.0071689, 0.0018531, 0.74037, 0.037689, 0.79854, 0.028578, 0.016244, 0.75583, 0.15135]
Predicted label: 5
Correct prediction
Energy consumption = 148.264714 pJ
sum error= 317
Actual label: 1
Output voltages: [0.055036, 0.79875, 0.28957, 0.070088, 0.44202, 0.0011074, 0.49634, 0.0074559, 0.024929, 0.020393]
Predicted label: 1
Correct prediction
Energy consumption = 166.552994 pJ
sum error= 317
Actual label: 3
Output voltages: [0.39683, 0.019528, 0.20632, 0.79864, 0.029031, 0.022059, 0.0039075, 0.013667, 0.74499, 0.038844]
Predicted label: 3
Correct prediction
Energy consumption = 146.138281 pJ
sum error= 317
Actual label: 2
Output voltages: [0.4066, 0.045086, 0.79875, 0.28812, 0.020884, 0.0010669, 0.036247, 0.097813, 0.15581, 0.030589]
Predicted label: 2
Correct prediction
Energy consumption = 143.095544 pJ
sum error= 317
Actual label: 2
Output voltages: [0.35474, 0.34894, 0.79878, 0.13117, 0.015132, 0.0012457, 0.054606, 0.054095, 0.048355, 0.01365]
Predicted label: 2
Correct prediction
Energy consumption = 138.160620 pJ
sum error= 317
Actual label: 3
Output voltages: [0.44505, 0.001945, 0.020105, 0.79873, 0.0071138, 0.023551, 0.0033728, 0.031382, 0.75966, 0.018881]
Predicted label: 3
Correct prediction
Energy consumption = 138.925882 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 733 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 733 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 733 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79868, 0.025756, 0.047923, 0.0086323, 0.019342, 0.0090481, 0.26788, 0.037784, 0.02531, 0.036477]
Predicted label: 0
Correct prediction
Energy consumption = 150.525409 pJ
sum error= 317
Actual label: 6
Output voltages: [0.10253, 0.0044271, 0.21163, 0.0012687, 0.65735, 0.54138, 0.79878, 0.0010739, 0.15143, 0.0042844]
Predicted label: 6
Correct prediction
Energy consumption = 140.915246 pJ
sum error= 317
Actual label: 4
Output voltages: [0.016552, 0.0039042, 0.041243, 0.035542, 0.79861, 0.0010755, 0.10811, 0.015662, 0.031439, 0.0089072]
Predicted label: 4
Correct prediction
Energy consumption = 155.691687 pJ
sum error= 317
Actual label: 3
Output voltages: [0.19366, 0.0085752, 0.24543, 0.79567, 0.01695, 0.0015997, 0.008333, 0.0054941, 0.79069, 0.025982]
Predicted label: 3
Correct prediction
Energy consumption = 148.045996 pJ
sum error= 317
Actual label: 7
Output voltages: [0.69605, 0.050167, 0.49362, 0.53296, 0.0066448, 0.0010664, 0.001069, 0.79873, 0.033133, 0.25009]
Predicted label: 7
Correct prediction
Energy consumption = 150.036967 pJ
sum error= 317
Actual label: 6
Output voltages: [0.2356, 0.02706, 0.084472, 0.0024578, 0.48332, 0.1698, 0.79875, 0.003318, 0.53049, 0.013808]
Predicted label: 6
Correct prediction
Energy consumption = 151.236565 pJ
sum error= 317
Actual label: 9
Output voltages: [0.43391, 0.014726, 0.068439, 0.039032, 0.041196, 0.005608, 0.001166, 0.10494, 0.39515, 0.79796]
Predicted label: 9
Correct prediction
Energy consumption = 157.223125 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79816, 0.056022, 0.11158, 0.059412, 0.0082028, 0.0040374, 0.41894, 0.0048403, 0.69456, 0.0068853]
Predicted label: 0
Correct prediction
Energy consumption = 154.283265 pJ
sum error= 317
Actual label: 4
Output voltages: [0.030498, 0.0047289, 0.024751, 0.039238, 0.79811, 0.0011669, 0.089904, 0.0018374, 0.18406, 0.010934]
Predicted label: 4
Correct prediction
Energy consumption = 154.757068 pJ
sum error= 317
Actual label: 8
Output voltages: [0.46617, 0.0042241, 0.14668, 0.46292, 0.011601, 0.0012316, 0.011625, 0.0014725, 0.7958, 0.20705]
Predicted label: 8
Correct prediction
Energy consumption = 152.108546 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 734 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 734 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 734 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.036856, 0.79849, 0.31312, 0.32913, 0.010237, 0.0010741, 0.24897, 0.0035005, 0.21331, 0.034293]
Predicted label: 1
Correct prediction
Energy consumption = 168.309219 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0051198, 0.024942, 0.081463, 0.019286, 0.7987, 0.0012161, 0.31419, 0.061324, 0.025942, 0.1109]
Predicted label: 4
Correct prediction
Energy consumption = 159.161056 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79867, 0.0042975, 0.030305, 0.011987, 0.016272, 0.016419, 0.29218, 0.0062399, 0.35557, 0.021372]
Predicted label: 0
Correct prediction
Energy consumption = 160.403792 pJ
sum error= 317
Actual label: 6
Output voltages: [0.06874, 0.018445, 0.13256, 0.0016176, 0.28447, 0.3036, 0.79876, 0.0047069, 0.60991, 0.0049459]
Predicted label: 6
Correct prediction
Energy consumption = 146.621513 pJ
sum error= 317
Actual label: 1
Output voltages: [0.06546, 0.79872, 0.41918, 0.10281, 0.27555, 0.0011342, 0.71951, 0.016704, 0.032026, 0.029837]
Predicted label: 1
Correct prediction
Energy consumption = 163.086825 pJ
sum error= 317
Actual label: 2
Output voltages: [0.50376, 0.64743, 0.79879, 0.026912, 0.0070483, 0.0012294, 0.022562, 0.030341, 0.21644, 0.015485]
Predicted label: 2
Correct prediction
Energy consumption = 148.865919 pJ
sum error= 317
Actual label: 6
Output voltages: [0.037951, 0.054023, 0.10162, 0.0029262, 0.24957, 0.10905, 0.79876, 0.0027567, 0.42564, 0.0039975]
Predicted label: 6
Correct prediction
Energy consumption = 148.872907 pJ
sum error= 317
Actual label: 9
Output voltages: [0.15084, 0.024089, 0.065759, 0.028592, 0.029744, 0.015383, 0.013047, 0.037532, 0.74259, 0.79722]
Predicted label: 9
Correct prediction
Energy consumption = 153.306691 pJ
sum error= 317
Actual label: 2
Output voltages: [0.044152, 0.10871, 0.79866, 0.12437, 0.002588, 0.001365, 0.054147, 0.22344, 0.54308, 0.063375]
Predicted label: 2
Correct prediction
Energy consumption = 152.615105 pJ
sum error= 317
Actual label: 2
Output voltages: [0.34633, 0.35389, 0.79879, 0.02534, 0.031926, 0.0013028, 0.035863, 0.29863, 0.34846, 0.024986]
Predicted label: 2
Correct prediction
Energy consumption = 143.157693 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 735 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 735 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 735 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.086505, 0.017012, 0.02828, 0.7986, 0.016767, 0.018261, 0.0057697, 0.028544, 0.3829, 0.071964]
Predicted label: 3
Correct prediction
Energy consumption = 148.933277 pJ
sum error= 317
Actual label: 5
Output voltages: [0.032722, 0.0011711, 0.0010679, 0.3914, 0.10137, 0.79868, 0.059688, 0.015746, 0.76115, 0.012342]
Predicted label: 5
Correct prediction
Energy consumption = 142.930386 pJ
sum error= 317
Actual label: 5
Output voltages: [0.034635, 0.0010878, 0.0015836, 0.38349, 0.17157, 0.79878, 0.15095, 0.046363, 0.7372, 0.12335]
Predicted label: 5
Correct prediction
Energy consumption = 138.683700 pJ
sum error= 317
Actual label: 1
Output voltages: [0.016321, 0.79862, 0.36513, 0.028476, 0.042998, 0.0010802, 0.32945, 0.0030899, 0.2255, 0.022331]
Predicted label: 1
Correct prediction
Energy consumption = 168.175314 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79878, 0.06284, 0.037978, 0.013649, 0.038658, 0.0040396, 0.76092, 0.032214, 0.25281, 0.043554]
Predicted label: 0
Correct prediction
Energy consumption = 150.261344 pJ
sum error= 317
Actual label: 7
Output voltages: [0.050449, 0.11439, 0.029012, 0.055607, 0.0081775, 0.01518, 0.0010693, 0.79867, 0.051263, 0.45353]
Predicted label: 7
Correct prediction
Energy consumption = 153.424387 pJ
sum error= 317
Actual label: 7
Output voltages: [0.28871, 0.12472, 0.78572, 0.014813, 0.0037339, 0.0011939, 0.0010793, 0.79878, 0.20565, 0.038628]
Predicted label: 7
Correct prediction
Energy consumption = 138.594989 pJ
sum error= 317
Actual label: 9
Output voltages: [0.044735, 0.03492, 0.014746, 0.036901, 0.015448, 0.002788, 0.0010661, 0.014788, 0.72574, 0.79708]
Predicted label: 9
Correct prediction
Energy consumption = 142.334198 pJ
sum error= 317
Actual label: 6
Output voltages: [0.10285, 0.031641, 0.11536, 0.0019444, 0.60488, 0.3425, 0.79868, 0.0020746, 0.28862, 0.0094525]
Predicted label: 6
Correct prediction
Energy consumption = 150.578982 pJ
sum error= 317
Actual label: 2
Output voltages: [0.1681, 0.19498, 0.79804, 0.41263, 0.013305, 0.0011323, 0.011256, 0.01879, 0.2602, 0.0078535]
Predicted label: 2
Correct prediction
Energy consumption = 153.963641 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 736 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 736 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 736 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.32517, 0.0074354, 0.015865, 0.015432, 0.2051, 0.014801, 0.0099133, 0.023362, 0.52826, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 151.605865 pJ
sum error= 317
Actual label: 4
Output voltages: [0.005126, 0.024146, 0.0069094, 0.024305, 0.79877, 0.0011011, 0.15404, 0.11463, 0.020927, 0.02199]
Predicted label: 4
Correct prediction
Energy consumption = 155.614272 pJ
sum error= 317
Actual label: 7
Output voltages: [0.21803, 0.0067278, 0.020387, 0.32026, 0.0028447, 0.0025726, 0.0012846, 0.79871, 0.40588, 0.33606]
Predicted label: 7
Correct prediction
Energy consumption = 148.897317 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79799, 0.043122, 0.16334, 0.0052208, 0.0086681, 0.0012104, 0.61629, 0.032351, 0.037123, 0.40802]
Predicted label: 0
Correct prediction
Energy consumption = 151.859620 pJ
sum error= 317
Actual label: 2
Output voltages: [0.42123, 0.40691, 0.7986, 0.38073, 0.0087614, 0.0011683, 0.044793, 0.060008, 0.034851, 0.028216]
Predicted label: 2
Correct prediction
Energy consumption = 150.828882 pJ
sum error= 317
Actual label: 3
Output voltages: [0.13093, 0.0091282, 0.050139, 0.79878, 0.043548, 0.012067, 0.0018636, 0.0028218, 0.74196, 0.052107]
Predicted label: 3
Correct prediction
Energy consumption = 135.251345 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0025934, 0.004225, 0.027747, 0.0057787, 0.79865, 0.0032568, 0.098781, 0.34801, 0.26205, 0.0015542]
Predicted label: 4
Correct prediction
Energy consumption = 152.187589 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79879, 0.025844, 0.042509, 0.013544, 0.022306, 0.0020047, 0.37273, 0.012326, 0.038561, 0.038923]
Predicted label: 0
Correct prediction
Energy consumption = 151.780220 pJ
sum error= 317
Actual label: 0
Output voltages: [0.7984, 0.028777, 0.18795, 0.0068708, 0.010013, 0.0016295, 0.47759, 0.022494, 0.31965, 0.027172]
Predicted label: 0
Correct prediction
Energy consumption = 143.059636 pJ
sum error= 317
Actual label: 8
Output voltages: [0.022581, 0.017085, 0.22337, 0.074975, 0.011935, 0.087419, 0.0077264, 0.018306, 0.79863, 0.03326]
Predicted label: 8
Correct prediction
Energy consumption = 143.610465 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 737 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 737 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 737 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.35418, 0.025965, 0.1351, 0.24843, 0.024901, 0.01931, 0.091403, 0.0011985, 0.79873, 0.19427]
Predicted label: 8
Correct prediction
Energy consumption = 154.140016 pJ
sum error= 317
Actual label: 8
Output voltages: [0.054172, 0.016432, 0.30017, 0.023504, 0.010942, 0.046476, 0.0052497, 0.0084521, 0.79878, 0.19321]
Predicted label: 8
Correct prediction
Energy consumption = 141.847604 pJ
sum error= 317
Actual label: 5
Output voltages: [0.010222, 0.0010799, 0.0061006, 0.11031, 0.02027, 0.79777, 0.29056, 0.027386, 0.75979, 0.23042]
Predicted label: 5
Correct prediction
Energy consumption = 142.548882 pJ
sum error= 317
Actual label: 1
Output voltages: [0.071949, 0.79868, 0.39921, 0.030233, 0.017022, 0.001091, 0.57113, 0.0021003, 0.16187, 0.040183]
Predicted label: 1
Correct prediction
Energy consumption = 164.414532 pJ
sum error= 317
Actual label: 3
Output voltages: [0.23707, 0.039294, 0.056733, 0.79875, 0.0032813, 0.0057856, 0.0079441, 0.0051285, 0.64937, 0.024706]
Predicted label: 3
Correct prediction
Energy consumption = 146.387821 pJ
sum error= 317
Actual label: 7
Output voltages: [0.18121, 0.2098, 0.65365, 0.189, 0.026434, 0.0011768, 0.001096, 0.79875, 0.15243, 0.13124]
Predicted label: 7
Correct prediction
Energy consumption = 144.676765 pJ
sum error= 317
Actual label: 4
Output voltages: [0.016157, 0.0052052, 0.1948, 0.0070785, 0.79859, 0.0078776, 0.12957, 0.043443, 0.33274, 0.0063982]
Predicted label: 4
Correct prediction
Energy consumption = 151.345583 pJ
sum error= 317
Actual label: 9
Output voltages: [0.2576, 0.028667, 0.0035052, 0.054478, 0.089689, 0.0063059, 0.0010735, 0.0028962, 0.36337, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 147.010949 pJ
sum error= 317
Actual label: 8
Output voltages: [0.17588, 0.034431, 0.097591, 0.035138, 0.0069834, 0.011449, 0.030012, 0.0011765, 0.79869, 0.029292]
Predicted label: 8
Correct prediction
Energy consumption = 144.177763 pJ
sum error= 317
Actual label: 8
Output voltages: [0.045282, 0.0026318, 0.073089, 0.24717, 0.0085475, 0.0026218, 0.061328, 0.0024652, 0.79855, 0.40238]
Predicted label: 8
Correct prediction
Energy consumption = 142.834523 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 738 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 738 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 738 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.3774, 0.0082312, 0.0060746, 0.012018, 0.18986, 0.0025274, 0.0017149, 0.0076938, 0.60468, 0.79873]
Predicted label: 9
Correct prediction
Energy consumption = 154.992688 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79879, 0.051947, 0.23015, 0.028408, 0.079077, 0.0034175, 0.16415, 0.0027916, 0.22039, 0.15783]
Predicted label: 0
Correct prediction
Energy consumption = 158.284873 pJ
sum error= 317
Actual label: 9
Output voltages: [0.2653, 0.0089388, 0.12834, 0.018991, 0.07742, 0.011912, 0.0015573, 0.13553, 0.60055, 0.79675]
Predicted label: 9
Correct prediction
Energy consumption = 159.290941 pJ
sum error= 317
Actual label: 8
Output voltages: [0.048821, 0.038309, 0.4286, 0.096548, 0.018747, 0.034681, 0.029735, 0.016578, 0.79878, 0.21147]
Predicted label: 8
Correct prediction
Energy consumption = 149.373643 pJ
sum error= 317
Actual label: 9
Output voltages: [0.032067, 0.0096104, 0.0253, 0.024616, 0.03596, 0.0098296, 0.0015434, 0.033815, 0.77243, 0.79122]
Predicted label: 9
Correct prediction
Energy consumption = 150.128247 pJ
sum error= 317
Actual label: 0
Output voltages: [0.79879, 0.049209, 0.049175, 0.021817, 0.013216, 0.0055482, 0.35091, 0.015824, 0.24872, 0.031321]
Predicted label: 0
Correct prediction
Energy consumption = 146.990418 pJ
sum error= 317
Actual label: 2
Output voltages: [0.59304, 0.096551, 0.79878, 0.47649, 0.013494, 0.0011747, 0.030257, 0.044538, 0.43004, 0.027794]
Predicted label: 2
Correct prediction
Energy consumption = 154.130161 pJ
sum error= 317
Actual label: 6
Output voltages: [0.10801, 0.019487, 0.28432, 0.0010662, 0.16719, 0.034491, 0.79877, 0.007933, 0.31832, 0.0012037]
Predicted label: 6
Correct prediction
Energy consumption = 148.928653 pJ
sum error= 317
Actual label: 5
Output voltages: [0.010456, 0.0011088, 0.0031736, 0.74071, 0.040975, 0.78384, 0.042941, 0.03099, 0.58823, 0.044789]
Predicted label: 5
Correct prediction
Energy consumption = 145.809282 pJ
sum error= 317
Actual label: 6
Output voltages: [0.047691, 0.071152, 0.34499, 0.0023109, 0.34831, 0.23981, 0.79868, 0.0071219, 0.41924, 0.0094242]
Predicted label: 6
Correct prediction
Energy consumption = 145.237184 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 739 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 739 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 739 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.31419, 0.12226, 0.75708, 0.023594, 0.0054371, 0.0012068, 0.0010837, 0.79879, 0.084894, 0.024732]
Predicted label: 7
Correct prediction
Energy consumption = 148.634920 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0039105, 0.0032112, 0.024993, 0.020179, 0.79867, 0.0014142, 0.075085, 0.053867, 0.16563, 0.0064421]
Predicted label: 4
Correct prediction
Energy consumption = 150.812057 pJ
sum error= 317
Actual label: 7
Output voltages: [0.1807, 0.041698, 0.10986, 0.24334, 0.01359, 0.0030071, 0.0011049, 0.79879, 0.66164, 0.30728]
Predicted label: 7
Correct prediction
Energy consumption = 160.192089 pJ
sum error= 317
Actual label: 5
Output voltages: [0.05921, 0.0011327, 0.0018076, 0.49007, 0.019386, 0.79871, 0.3027, 0.034374, 0.64154, 0.048236]
Predicted label: 5
Correct prediction
Energy consumption = 144.593349 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0085674, 0.021425, 0.0066143, 0.015948, 0.79872, 0.0018073, 0.13723, 0.030703, 0.19409, 0.055773]
Predicted label: 4
Correct prediction
Energy consumption = 154.450302 pJ
sum error= 317
Actual label: 1
Output voltages: [0.0099112, 0.79876, 0.21526, 0.013186, 0.044972, 0.0013024, 0.50959, 0.0012044, 0.26443, 0.0083201]
Predicted label: 1
Correct prediction
Energy consumption = 154.660296 pJ
sum error= 317
Actual label: 3
Output voltages: [0.12586, 0.055417, 0.025203, 0.79873, 0.0040075, 0.050249, 0.0089777, 0.022124, 0.74935, 0.043271]
Predicted label: 3
Correct prediction
Energy consumption = 149.767751 pJ
sum error= 317
Actual label: 5
Output voltages: [0.026813, 0.001123, 0.0011802, 0.05366, 0.24248, 0.79878, 0.36, 0.035464, 0.78454, 0.0097042]
Predicted label: 5
Correct prediction
Energy consumption = 144.481323 pJ
sum error= 317
Actual label: 3
Output voltages: [0.1067, 0.011182, 0.32017, 0.79869, 0.012191, 0.38538, 0.0025395, 0.022807, 0.74135, 0.057184]
Predicted label: 3
Correct prediction
Energy consumption = 142.480561 pJ
sum error= 317
Actual label: 1
Output voltages: [0.34771, 0.79872, 0.18759, 0.015681, 0.4041, 0.0072597, 0.35943, 0.003354, 0.021938, 0.045735]
Predicted label: 1
Correct prediction
Energy consumption = 161.454989 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 740 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 740 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 740 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.4938, 0.025261, 0.79879, 0.036825, 0.0070857, 0.0010869, 0.025688, 0.14919, 0.32887, 0.046168]
Predicted label: 2
Correct prediction
Energy consumption = 148.022605 pJ
sum error= 317
Actual label: 3
Output voltages: [0.79381, 0.029621, 0.025036, 0.7987, 0.0013879, 0.36294, 0.0012526, 0.038866, 0.28166, 0.008069]
Predicted label: 3
Correct prediction
Energy consumption = 148.049444 pJ
sum error= 317
Actual label: 4
Output voltages: [0.01369, 0.015585, 0.017747, 0.0013768, 0.79878, 0.0013051, 0.34959, 0.051716, 0.29645, 0.0098593]
Predicted label: 4
Correct prediction
Energy consumption = 157.782453 pJ
sum error= 317
Actual label: 5
Output voltages: [0.16668, 0.0019229, 0.003356, 0.6648, 0.0061986, 0.79879, 0.077241, 0.054764, 0.7605, 0.066927]
Predicted label: 5
Correct prediction
Energy consumption = 153.333018 pJ
sum error= 317
Actual label: 6
Output voltages: [0.62956, 0.035684, 0.052358, 0.0010697, 0.37055, 0.0301, 0.79878, 0.0030502, 0.098498, 0.023299]
Predicted label: 6
Correct prediction
Energy consumption = 150.955503 pJ
sum error= 317
Actual label: 1
Output voltages: [0.011424, 0.79873, 0.15409, 0.0047166, 0.13841, 0.014058, 0.45173, 0.0041426, 0.45425, 0.0066791]
Predicted label: 1
Correct prediction
Energy consumption = 145.836683 pJ
sum error= 317
Actual label: 2
Output voltages: [0.69469, 0.0023063, 0.79864, 0.20517, 0.0078389, 0.001081, 0.022973, 0.17213, 0.75842, 0.015244]
Predicted label: 2
Correct prediction
Energy consumption = 140.921566 pJ
sum error= 317
Actual label: 3
Output voltages: [0.44983, 0.013376, 0.067428, 0.79878, 0.0033858, 0.044616, 0.0011943, 0.53278, 0.22468, 0.063065]
Predicted label: 3
Correct prediction
Energy consumption = 141.433970 pJ
sum error= 317
Actual label: 4
Output voltages: [0.021765, 0.014078, 0.13679, 0.0038923, 0.79875, 0.0081673, 0.25261, 0.18573, 0.21638, 0.0020996]
Predicted label: 4
Correct prediction
Energy consumption = 146.470904 pJ
sum error= 317
Actual label: 6
Output voltages: [0.29941, 0.062227, 0.35192, 0.001106, 0.20976, 0.043256, 0.79877, 0.001086, 0.063887, 0.0068931]
Predicted label: 6
Correct prediction
Energy consumption = 138.084836 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 741 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 741 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 741 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.030312, 0.042631, 0.019881, 0.0061439, 0.0015966, 0.27945, 0.49594, 0.11403, 0.0049368]
Predicted label: 0
Correct prediction
Energy consumption = 152.370768 pJ
sum error= 317
Actual label: 1
Output voltages: [0.0014203, 0.79867, 0.017728, 0.03245, 0.27895, 0.0029982, 0.62865, 0.0033933, 0.26604, 0.075592]
Predicted label: 1
Correct prediction
Energy consumption = 153.058098 pJ
sum error= 317
Actual label: 2
Output voltages: [0.52267, 0.0035884, 0.79879, 0.17791, 0.0061316, 0.0010883, 0.014531, 0.03169, 0.52219, 0.0027648]
Predicted label: 2
Correct prediction
Energy consumption = 144.291740 pJ
sum error= 317
Actual label: 4
Output voltages: [0.74597, 0.0037419, 0.5298, 0.0013678, 0.78965, 0.0011486, 0.012134, 0.040674, 0.3091, 0.0178]
Predicted label: 4
Correct prediction
Energy consumption = 143.622805 pJ
sum error= 317
Actual label: 5
Output voltages: [0.25187, 0.0010837, 0.0011093, 0.049994, 0.0087717, 0.79854, 0.058897, 0.13004, 0.77225, 0.0010675]
Predicted label: 5
Correct prediction
Energy consumption = 147.570738 pJ
sum error= 317
Actual label: 6
Output voltages: [0.036347, 0.03935, 0.11078, 0.00238, 0.089816, 0.28123, 0.79875, 0.0089922, 0.3577, 0.0035971]
Predicted label: 6
Correct prediction
Energy consumption = 135.700546 pJ
sum error= 317
Actual label: 7
Output voltages: [0.23011, 0.04849, 0.71572, 0.035655, 0.0086086, 0.0016708, 0.0010827, 0.79872, 0.21694, 0.46165]
Predicted label: 7
Correct prediction
Energy consumption = 152.308342 pJ
sum error= 317
Actual label: 8
Output voltages: [0.043067, 0.0033409, 0.010827, 0.05275, 0.056003, 0.58166, 0.079873, 0.048454, 0.7987, 0.030224]
Predicted label: 8
Correct prediction
Energy consumption = 149.490149 pJ
sum error= 317
Actual label: 1
Output voltages: [0.014856, 0.79878, 0.21566, 0.010304, 0.076661, 0.0021687, 0.61817, 0.0027174, 0.33728, 0.0026207]
Predicted label: 1
Correct prediction
Energy consumption = 150.393375 pJ
sum error= 317
Actual label: 7
Output voltages: [0.03421, 0.19705, 0.59066, 0.15177, 0.0055262, 0.0010679, 0.0010906, 0.79877, 0.33899, 0.24317]
Predicted label: 7
Correct prediction
Energy consumption = 151.798494 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 742 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 742 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 742 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.40889, 0.0015442, 0.79622, 0.04142, 0.0028622, 0.0013712, 0.02172, 0.20713, 0.79212, 0.026865]
Predicted label: 2
Correct prediction
Energy consumption = 143.981325 pJ
sum error= 317
Actual label: 4
Output voltages: [0.05112, 0.023567, 0.38042, 0.0079282, 0.79869, 0.0016138, 0.036117, 0.03037, 0.029469, 0.035606]
Predicted label: 4
Correct prediction
Energy consumption = 151.733003 pJ
sum error= 317
Actual label: 1
Output voltages: [0.0036662, 0.79865, 0.24952, 0.030072, 0.17459, 0.0014511, 0.73137, 0.0093552, 0.31875, 0.0092643]
Predicted label: 1
Correct prediction
Energy consumption = 140.719016 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0011745, 0.005628, 0.017596, 0.010175, 0.79874, 0.011331, 0.0065753, 0.0064358, 0.3351, 0.26421]
Predicted label: 4
Correct prediction
Energy consumption = 149.453536 pJ
sum error= 317
Actual label: 1
Output voltages: [0.11005, 0.79878, 0.045439, 0.001467, 0.5314, 0.0018427, 0.39185, 0.0016195, 0.25899, 0.05427]
Predicted label: 1
Correct prediction
Energy consumption = 151.727496 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0038951, 0.013921, 0.16776, 0.016958, 0.79878, 0.0075568, 0.035799, 0.024839, 0.21481, 0.01473]
Predicted label: 4
Correct prediction
Energy consumption = 152.341931 pJ
sum error= 317
Actual label: 9
Output voltages: [0.040106, 0.0012092, 0.031009, 0.019847, 0.13914, 0.28097, 0.042271, 0.24403, 0.6399, 0.74359]
Predicted label: 9
Correct prediction
Energy consumption = 149.111464 pJ
sum error= 317
Actual label: 6
Output voltages: [0.33834, 0.028558, 0.063916, 0.00108, 0.28118, 0.042125, 0.79879, 0.010558, 0.54398, 0.0013804]
Predicted label: 6
Correct prediction
Energy consumption = 141.611096 pJ
sum error= 317
Actual label: 8
Output voltages: [0.027672, 0.022078, 0.181, 0.21407, 0.01679, 0.033718, 0.023603, 0.0031196, 0.7987, 0.31645]
Predicted label: 8
Correct prediction
Energy consumption = 146.479463 pJ
sum error= 317
Actual label: 4
Output voltages: [0.0010662, 0.024666, 0.018336, 0.044435, 0.79879, 0.015921, 0.32246, 0.052629, 0.095557, 0.030415]
Predicted label: 4
Correct prediction
Energy consumption = 147.996021 pJ
sum error= 317
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 743 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 743 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 743 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.18827, 0.0022607, 0.0010929, 0.79151, 0.56983, 0.79546, 0.10074, 0.36803, 0.11986, 0.014551]
Predicted label: 5
Correct prediction
Energy consumption = 148.080055 pJ
sum error= 317
Actual label: 3
Output voltages: [0.63207, 0.002243, 0.03843, 0.79879, 0.010928, 0.0096868, 0.0014206, 0.057802, 0.67115, 0.026026]
Predicted label: 3
Correct prediction
Energy consumption = 137.542029 pJ
sum error= 317
Actual label: 7
Output voltages: [0.032856, 0.38541, 0.76923, 0.16118, 0.0028265, 0.0011223, 0.0027026, 0.73301, 0.78202, 0.45408]
Predicted label: 8
Wrong prediction!
Energy consumption = 141.531311 pJ
sum error= 318
Actual label: 8
Output voltages: [0.055667, 0.017197, 0.0048571, 0.29419, 0.0084943, 0.17298, 0.2579, 0.015951, 0.79877, 0.0091346]
Predicted label: 8
Correct prediction
Energy consumption = 141.952155 pJ
sum error= 318
Actual label: 4
Output voltages: [0.0079006, 0.36084, 0.0089975, 0.052885, 0.78525, 0.0010661, 0.010018, 0.015013, 0.14275, 0.26002]
Predicted label: 4
Correct prediction
Energy consumption = 143.965581 pJ
sum error= 318
Actual label: 3
Output voltages: [0.097681, 0.018941, 0.029545, 0.79866, 0.014081, 0.0064058, 0.01118, 0.026874, 0.41497, 0.14319]
Predicted label: 3
Correct prediction
Energy consumption = 139.905146 pJ
sum error= 318
Actual label: 3
Output voltages: [0.037919, 0.077596, 0.28002, 0.79879, 0.0039893, 0.0013948, 0.0039035, 0.017015, 0.72605, 0.022585]
Predicted label: 3
Correct prediction
Energy consumption = 130.457864 pJ
sum error= 318
Actual label: 5
Output voltages: [0.19874, 0.0010744, 0.0010718, 0.20702, 0.03922, 0.79862, 0.25384, 0.015492, 0.79474, 0.0028131]
Predicted label: 5
Correct prediction
Energy consumption = 132.255866 pJ
sum error= 318
Actual label: 6
Output voltages: [0.034606, 0.16102, 0.16996, 0.0025313, 0.10925, 0.25608, 0.7987, 0.0031132, 0.29265, 0.0056261]
Predicted label: 6
Correct prediction
Energy consumption = 143.782024 pJ
sum error= 318
Actual label: 7
Output voltages: [0.036223, 0.02699, 0.74125, 0.063599, 0.0013462, 0.0012422, 0.0010669, 0.79575, 0.26826, 0.043544]
Predicted label: 7
Correct prediction
Energy consumption = 158.918308 pJ
sum error= 318
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 744 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 744 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 744 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79847, 0.017507, 0.11075, 0.029181, 0.21549, 0.0022908, 0.2695, 0.047087, 0.36904, 0.018837]
Predicted label: 0
Correct prediction
Energy consumption = 154.893109 pJ
sum error= 318
Actual label: 6
Output voltages: [0.30239, 0.0041737, 0.024169, 0.0013081, 0.37752, 0.25062, 0.79839, 0.0091947, 0.077804, 0.012053]
Predicted label: 6
Correct prediction
Energy consumption = 139.689757 pJ
sum error= 318
Actual label: 1
Output voltages: [0.030467, 0.79879, 0.0042648, 0.0050424, 0.24327, 0.0020404, 0.17619, 0.010232, 0.34906, 0.014289]
Predicted label: 1
Correct prediction
Energy consumption = 154.622935 pJ
sum error= 318
Actual label: 6
Output voltages: [0.21744, 0.055763, 0.45066, 0.0012222, 0.099219, 0.091167, 0.79879, 0.0011715, 0.082315, 0.0076249]
Predicted label: 6
Correct prediction
Energy consumption = 143.263603 pJ
sum error= 318
Actual label: 8
Output voltages: [0.011343, 0.0046673, 0.0026578, 0.010435, 0.20325, 0.16982, 0.13708, 0.078351, 0.79878, 0.0059831]
Predicted label: 8
Correct prediction
Energy consumption = 138.551218 pJ
sum error= 318
Actual label: 7
Output voltages: [0.034559, 0.18749, 0.75682, 0.05663, 0.0013427, 0.0013169, 0.0010781, 0.79878, 0.37869, 0.57973]
Predicted label: 7
Correct prediction
Energy consumption = 144.110177 pJ
sum error= 318
Actual label: 0
Output voltages: [0.79875, 0.018512, 0.068276, 0.014894, 0.017366, 0.0050675, 0.52422, 0.078519, 0.1785, 0.23271]
Predicted label: 0
Correct prediction
Energy consumption = 143.662793 pJ
sum error= 318
Actual label: 1
Output voltages: [0.0011964, 0.79878, 0.48826, 0.039067, 0.038852, 0.0010865, 0.24349, 0.014545, 0.32601, 0.036158]
Predicted label: 1
Correct prediction
Energy consumption = 148.828031 pJ
sum error= 318
Actual label: 5
Output voltages: [0.31635, 0.0012539, 0.001106, 0.23506, 0.034738, 0.79861, 0.122, 0.044957, 0.69635, 0.0078436]
Predicted label: 5
Correct prediction
Energy consumption = 147.658199 pJ
sum error= 318
Actual label: 0
Output voltages: [0.79876, 0.023237, 0.064439, 0.0027319, 0.025323, 0.0050832, 0.15941, 0.087008, 0.44661, 0.021421]
Predicted label: 0
Correct prediction
Energy consumption = 149.575149 pJ
sum error= 318
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 745 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 745 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 745 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.017856, 0.019328, 0.035072, 0.069241, 0.0014652, 0.2158, 0.041866, 0.029973, 0.79867, 0.02545]
Predicted label: 8
Correct prediction
Energy consumption = 148.152047 pJ
sum error= 318
Actual label: 5
Output voltages: [0.031364, 0.01632, 0.001066, 0.74629, 0.46911, 0.79002, 0.43797, 0.0011518, 0.59884, 0.036421]
Predicted label: 5
Correct prediction
Energy consumption = 133.692899 pJ
sum error= 318
Actual label: 0
Output voltages: [0.7987, 0.034529, 0.20739, 0.012995, 0.01864, 0.0092853, 0.38519, 0.053514, 0.070003, 0.11091]
Predicted label: 0
Correct prediction
Energy consumption = 146.774703 pJ
sum error= 318
Actual label: 1
Output voltages: [0.0074003, 0.79874, 0.21562, 0.0010816, 0.11914, 0.0012379, 0.32874, 0.0015228, 0.633, 0.042797]
Predicted label: 1
Correct prediction
Energy consumption = 151.081658 pJ
sum error= 318
Actual label: 5
Output voltages: [0.060581, 0.001067, 0.0011336, 0.18825, 0.20511, 0.79875, 0.2572, 0.021431, 0.28897, 0.03339]
Predicted label: 5
Correct prediction
Energy consumption = 139.463793 pJ
sum error= 318
Actual label: 8
Output voltages: [0.067029, 0.022344, 0.022304, 0.14921, 0.0031802, 0.27969, 0.0045032, 0.010087, 0.79873, 0.043583]
Predicted label: 8
Correct prediction
Energy consumption = 151.429479 pJ
sum error= 318
Actual label: 4
Output voltages: [0.039225, 0.020698, 0.38074, 0.0014485, 0.79875, 0.011645, 0.079578, 0.01648, 0.039751, 0.00485]
Predicted label: 4
Correct prediction
Energy consumption = 143.799292 pJ
sum error= 318
Actual label: 2
Output voltages: [0.16292, 0.01571, 0.79875, 0.25216, 0.0027193, 0.0011039, 0.01874, 0.6962, 0.78734, 0.015987]
Predicted label: 2
Correct prediction
Energy consumption = 147.052936 pJ
sum error= 318
Actual label: 3
Output voltages: [0.43976, 0.01943, 0.10276, 0.7986, 0.022304, 0.022852, 0.01129, 0.032256, 0.56998, 0.064457]
Predicted label: 3
Correct prediction
Energy consumption = 142.024362 pJ
sum error= 318
Actual label: 9
Output voltages: [0.024129, 0.0010667, 0.0020757, 0.031389, 0.026319, 0.55303, 0.0060366, 0.011092, 0.74683, 0.70525]
Predicted label: 8
Wrong prediction!
Energy consumption = 151.733968 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 746 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 746 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 746 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.30345, 0.071826, 0.47993, 0.041146, 0.0076789, 0.001126, 0.0038931, 0.79868, 0.031958, 0.050421]
Predicted label: 7
Correct prediction
Energy consumption = 158.207005 pJ
sum error= 319
Actual label: 6
Output voltages: [0.278, 0.016738, 0.12381, 0.0010936, 0.74034, 0.045198, 0.79877, 0.0056334, 0.040477, 0.027355]
Predicted label: 6
Correct prediction
Energy consumption = 144.460482 pJ
sum error= 319
Actual label: 9
Output voltages: [0.36284, 0.0042036, 0.0167, 0.047053, 0.019759, 0.033391, 0.0027011, 0.14448, 0.70221, 0.79783]
Predicted label: 9
Correct prediction
Energy consumption = 145.928213 pJ
sum error= 319
Actual label: 1
Output voltages: [0.01171, 0.79872, 0.39148, 0.037228, 0.12562, 0.0020659, 0.056338, 0.028987, 0.39562, 0.01702]
Predicted label: 1
Correct prediction
Energy consumption = 151.187222 pJ
sum error= 319
Actual label: 9
Output voltages: [0.19548, 0.0040194, 0.036375, 0.0066844, 0.015186, 0.017919, 0.0024914, 0.012712, 0.77337, 0.79593]
Predicted label: 9
Correct prediction
Energy consumption = 145.194782 pJ
sum error= 319
Actual label: 0
Output voltages: [0.7738, 0.052492, 0.082088, 0.013397, 0.37277, 0.0026694, 0.64143, 0.018477, 0.25364, 0.0015473]
Predicted label: 0
Correct prediction
Energy consumption = 150.720053 pJ
sum error= 319
Actual label: 6
Output voltages: [0.36382, 0.18302, 0.040241, 0.022887, 0.18287, 0.14783, 0.79872, 0.0053502, 0.66932, 0.015468]
Predicted label: 6
Correct prediction
Energy consumption = 137.481982 pJ
sum error= 319
Actual label: 7
Output voltages: [0.15907, 0.021704, 0.59823, 0.021128, 0.0033975, 0.0011884, 0.0011076, 0.79879, 0.49358, 0.014849]
Predicted label: 7
Correct prediction
Energy consumption = 155.186761 pJ
sum error= 319
Actual label: 1
Output voltages: [0.0033519, 0.79877, 0.0071757, 0.0071428, 0.02534, 0.0045763, 0.054172, 0.0045499, 0.78735, 0.034711]
Predicted label: 1
Correct prediction
Energy consumption = 136.367192 pJ
sum error= 319
Actual label: 2
Output voltages: [0.084853, 0.0088962, 0.79867, 0.036908, 0.037398, 0.0010679, 0.14177, 0.033638, 0.68024, 0.013296]
Predicted label: 2
Correct prediction
Energy consumption = 134.420566 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 747 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 747 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 747 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33241, 0.025366, 0.086986, 0.79857, 0.019875, 0.020518, 0.0096771, 0.046774, 0.63012, 0.071584]
Predicted label: 3
Correct prediction
Energy consumption = 144.415938 pJ
sum error= 319
Actual label: 9
Output voltages: [0.062085, 0.0010662, 0.0020775, 0.070156, 0.055934, 0.1355, 0.0027404, 0.060981, 0.60048, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 139.720163 pJ
sum error= 319
Actual label: 2
Output voltages: [0.3045, 0.022809, 0.79876, 0.26751, 0.018328, 0.0010861, 0.0072456, 0.28777, 0.46073, 0.20789]
Predicted label: 2
Correct prediction
Energy consumption = 137.781012 pJ
sum error= 319
Actual label: 4
Output voltages: [0.049158, 0.19552, 0.0099641, 0.010582, 0.79805, 0.0028436, 0.20926, 0.026267, 0.064374, 0.52074]
Predicted label: 4
Correct prediction
Energy consumption = 152.858556 pJ
sum error= 319
Actual label: 5
Output voltages: [0.0666, 0.0011782, 0.001074, 0.30584, 0.039131, 0.79867, 0.28968, 0.018263, 0.68092, 0.0059965]
Predicted label: 5
Correct prediction
Energy consumption = 139.345444 pJ
sum error= 319
Actual label: 5
Output voltages: [0.014206, 0.0010721, 0.0017294, 0.39643, 0.071888, 0.79879, 0.21036, 0.035037, 0.75802, 0.073265]
Predicted label: 5
Correct prediction
Energy consumption = 140.818366 pJ
sum error= 319
Actual label: 3
Output voltages: [0.79359, 0.0011238, 0.17378, 0.79593, 0.0027166, 0.0074315, 0.0010674, 0.67456, 0.40469, 0.0046796]
Predicted label: 3
Correct prediction
Energy consumption = 144.198911 pJ
sum error= 319
Actual label: 7
Output voltages: [0.50012, 0.022269, 0.56178, 0.28906, 0.011039, 0.0012992, 0.0021624, 0.79625, 0.047101, 0.034595]
Predicted label: 7
Correct prediction
Energy consumption = 145.037916 pJ
sum error= 319
Actual label: 5
Output voltages: [0.18075, 0.0013467, 0.0010977, 0.11354, 0.056243, 0.79863, 0.22013, 0.0098699, 0.71427, 0.032184]
Predicted label: 5
Correct prediction
Energy consumption = 151.881900 pJ
sum error= 319
Actual label: 3
Output voltages: [0.37703, 0.042305, 0.040001, 0.79862, 0.021908, 0.15009, 0.012988, 0.0097008, 0.57056, 0.11158]
Predicted label: 3
Correct prediction
Energy consumption = 147.259606 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 748 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 748 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 748 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0044157, 0.79861, 0.17189, 0.0091537, 0.049104, 0.0016593, 0.75951, 0.0030712, 0.13557, 0.016679]
Predicted label: 1
Correct prediction
Energy consumption = 154.679594 pJ
sum error= 319
Actual label: 8
Output voltages: [0.027912, 0.041721, 0.0078594, 0.051848, 0.012703, 0.26134, 0.040056, 0.011362, 0.79879, 0.001557]
Predicted label: 8
Correct prediction
Energy consumption = 147.716165 pJ
sum error= 319
Actual label: 2
Output voltages: [0.53337, 0.0034521, 0.79879, 0.38309, 0.002632, 0.0011116, 0.054832, 0.45599, 0.74582, 0.01231]
Predicted label: 2
Correct prediction
Energy consumption = 140.269051 pJ
sum error= 319
Actual label: 2
Output voltages: [0.1088, 0.050058, 0.79877, 0.043271, 0.0029904, 0.0010892, 0.012459, 0.40644, 0.37868, 0.040951]
Predicted label: 2
Correct prediction
Energy consumption = 134.006953 pJ
sum error= 319
Actual label: 3
Output voltages: [0.066354, 0.075186, 0.12492, 0.79873, 0.0068515, 0.015276, 0.0021485, 0.035712, 0.74887, 0.023676]
Predicted label: 3
Correct prediction
Energy consumption = 143.667428 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79876, 0.038352, 0.032798, 0.0243, 0.017823, 0.0057006, 0.42041, 0.051013, 0.19053, 0.031172]
Predicted label: 0
Correct prediction
Energy consumption = 148.120296 pJ
sum error= 319
Actual label: 2
Output voltages: [0.5826, 0.0054369, 0.79879, 0.14272, 0.0075282, 0.0011218, 0.060032, 0.23066, 0.65665, 0.017125]
Predicted label: 2
Correct prediction
Energy consumption = 141.371153 pJ
sum error= 319
Actual label: 9
Output voltages: [0.25411, 0.0046176, 0.01831, 0.025263, 0.1986, 0.027127, 0.002534, 0.0030896, 0.49983, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 141.862227 pJ
sum error= 319
Actual label: 4
Output voltages: [0.048987, 0.078097, 0.23063, 0.048388, 0.79833, 0.0040757, 0.03131, 0.054215, 0.023639, 0.010499]
Predicted label: 4
Correct prediction
Energy consumption = 146.836839 pJ
sum error= 319
Actual label: 9
Output voltages: [0.060475, 0.005332, 0.029969, 0.093381, 0.03092, 0.016448, 0.0027949, 0.19392, 0.73804, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 142.011620 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 749 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 749 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 749 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.039948, 0.017916, 0.76649, 0.027073, 0.0030482, 0.0010852, 0.0010716, 0.79876, 0.55114, 0.25269]
Predicted label: 7
Correct prediction
Energy consumption = 143.823338 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79877, 0.02046, 0.023366, 0.0074487, 0.045262, 0.0052613, 0.42035, 0.26321, 0.14498, 0.029725]
Predicted label: 0
Correct prediction
Energy consumption = 141.476242 pJ
sum error= 319
Actual label: 2
Output voltages: [0.75853, 0.03605, 0.78194, 0.26515, 0.0016688, 0.0011568, 0.015021, 0.74619, 0.58802, 0.0082295]
Predicted label: 2
Correct prediction
Energy consumption = 146.496730 pJ
sum error= 319
Actual label: 7
Output voltages: [0.055023, 0.29678, 0.75594, 0.020261, 0.012854, 0.0012136, 0.0011567, 0.79879, 0.034182, 0.1018]
Predicted label: 7
Correct prediction
Energy consumption = 149.597404 pJ
sum error= 319
Actual label: 4
Output voltages: [0.056236, 0.11058, 0.18524, 0.0094608, 0.7955, 0.0019009, 0.74526, 0.051451, 0.017527, 0.0041236]
Predicted label: 4
Correct prediction
Energy consumption = 158.268058 pJ
sum error= 319
Actual label: 9
Output voltages: [0.35429, 0.039059, 0.032291, 0.032391, 0.17829, 0.0015335, 0.0011085, 0.029382, 0.44117, 0.7978]
Predicted label: 9
Correct prediction
Energy consumption = 158.150751 pJ
sum error= 319
Actual label: 9
Output voltages: [0.40997, 0.010648, 0.014747, 0.043284, 0.30676, 0.0033497, 0.0012658, 0.042136, 0.23545, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 143.482105 pJ
sum error= 319
Actual label: 2
Output voltages: [0.20461, 0.32593, 0.7987, 0.04376, 0.024102, 0.0011488, 0.043133, 0.46603, 0.1407, 0.12409]
Predicted label: 2
Correct prediction
Energy consumption = 150.082890 pJ
sum error= 319
Actual label: 5
Output voltages: [0.44156, 0.010477, 0.0034921, 0.10501, 0.0011593, 0.79877, 0.31453, 0.032705, 0.7639, 0.0011396]
Predicted label: 5
Correct prediction
Energy consumption = 154.950769 pJ
sum error= 319
Actual label: 9
Output voltages: [0.28422, 0.01354, 0.02277, 0.017987, 0.034362, 0.0066542, 0.0010991, 0.029686, 0.66527, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 152.072902 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 750 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 750 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 750 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.011069, 0.30075, 0.17007, 0.2311, 0.0034394, 0.024353, 0.037177, 0.029138, 0.79868, 0.063849]
Predicted label: 8
Correct prediction
Energy consumption = 152.955746 pJ
sum error= 319
Actual label: 3
Output voltages: [0.42801, 0.039647, 0.23854, 0.79861, 0.0012968, 0.31548, 0.0046523, 0.10236, 0.49262, 0.0087698]
Predicted label: 3
Correct prediction
Energy consumption = 148.340559 pJ
sum error= 319
Actual label: 8
Output voltages: [0.1694, 0.009488, 0.02898, 0.49181, 0.0017173, 0.31701, 0.010332, 0.0011656, 0.79875, 0.048753]
Predicted label: 8
Correct prediction
Energy consumption = 143.867418 pJ
sum error= 319
Actual label: 6
Output voltages: [0.30278, 0.013343, 0.05168, 0.0010668, 0.23646, 0.041906, 0.79697, 0.0025766, 0.53077, 0.0010788]
Predicted label: 6
Correct prediction
Energy consumption = 141.330036 pJ
sum error= 319
Actual label: 7
Output voltages: [0.022251, 0.020022, 0.75669, 0.02215, 0.0064328, 0.0010681, 0.0010892, 0.79874, 0.48162, 0.36664]
Predicted label: 7
Correct prediction
Energy consumption = 147.758493 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79831, 0.028566, 0.22807, 0.011922, 0.16354, 0.0026713, 0.38984, 0.1728, 0.30361, 0.018675]
Predicted label: 0
Correct prediction
Energy consumption = 151.669972 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79864, 0.016636, 0.027369, 0.017111, 0.054091, 0.0051432, 0.73857, 0.008247, 0.18752, 0.068015]
Predicted label: 0
Correct prediction
Energy consumption = 147.715010 pJ
sum error= 319
Actual label: 1
Output voltages: [0.051974, 0.79879, 0.30753, 0.016775, 0.74247, 0.0053027, 0.68144, 0.001066, 0.025064, 0.032696]
Predicted label: 1
Correct prediction
Energy consumption = 152.134949 pJ
sum error= 319
Actual label: 2
Output voltages: [0.39222, 0.053379, 0.79877, 0.054502, 0.012487, 0.0011924, 0.34275, 0.0065622, 0.6778, 0.019211]
Predicted label: 2
Correct prediction
Energy consumption = 141.254433 pJ
sum error= 319
Actual label: 3
Output voltages: [0.14191, 0.011298, 0.045753, 0.79877, 0.038748, 0.004367, 0.0097889, 0.010167, 0.5829, 0.046541]
Predicted label: 3
Correct prediction
Energy consumption = 141.131065 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 751 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 751 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 751 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0054622, 0.0041975, 0.02583, 0.0055241, 0.79863, 0.0049268, 0.36168, 0.30814, 0.14197, 0.0052866]
Predicted label: 4
Correct prediction
Energy consumption = 149.256306 pJ
sum error= 319
Actual label: 5
Output voltages: [0.13612, 0.0010889, 0.0020553, 0.7505, 0.016551, 0.79681, 0.37405, 0.052915, 0.3571, 0.013222]
Predicted label: 5
Correct prediction
Energy consumption = 146.869218 pJ
sum error= 319
Actual label: 6
Output voltages: [0.01826, 0.14162, 0.47762, 0.0079853, 0.18384, 0.1408, 0.79873, 0.0015918, 0.52039, 0.010438]
Predicted label: 6
Correct prediction
Energy consumption = 141.938211 pJ
sum error= 319
Actual label: 7
Output voltages: [0.056182, 0.012115, 0.034924, 0.039865, 0.01799, 0.0062342, 0.0011255, 0.79844, 0.26181, 0.10631]
Predicted label: 7
Correct prediction
Energy consumption = 150.220164 pJ
sum error= 319
Actual label: 8
Output voltages: [0.43103, 0.0040864, 0.052602, 0.21715, 0.0064923, 0.045627, 0.30652, 0.0011472, 0.78976, 0.15265]
Predicted label: 8
Correct prediction
Energy consumption = 158.378061 pJ
sum error= 319
Actual label: 9
Output voltages: [0.27563, 0.013224, 0.035316, 0.040799, 0.30788, 0.012488, 0.0071237, 0.024436, 0.44364, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 143.712569 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79872, 0.023027, 0.029598, 0.011827, 0.033476, 0.0068761, 0.22196, 0.024477, 0.18912, 0.021977]
Predicted label: 0
Correct prediction
Energy consumption = 145.615065 pJ
sum error= 319
Actual label: 1
Output voltages: [0.25716, 0.78613, 0.21764, 0.12404, 0.021077, 0.014412, 0.76327, 0.0011466, 0.60403, 0.17092]
Predicted label: 1
Correct prediction
Energy consumption = 154.704962 pJ
sum error= 319
Actual label: 2
Output voltages: [0.2227, 0.027866, 0.79877, 0.044132, 0.0011368, 0.0011068, 0.015518, 0.055281, 0.74858, 0.0013115]
Predicted label: 2
Correct prediction
Energy consumption = 133.800528 pJ
sum error= 319
Actual label: 3
Output voltages: [0.06809, 0.017553, 0.076396, 0.79871, 0.0014214, 0.043063, 0.0026232, 0.0052445, 0.48476, 0.019359]
Predicted label: 3
Correct prediction
Energy consumption = 134.068695 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 752 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 752 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 752 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0032751, 0.021659, 0.17993, 0.033255, 0.79874, 0.0017363, 0.049995, 0.15778, 0.005788, 0.024752]
Predicted label: 4
Correct prediction
Energy consumption = 145.480731 pJ
sum error= 319
Actual label: 5
Output voltages: [0.041997, 0.014197, 0.0011438, 0.48504, 0.082545, 0.79877, 0.55438, 0.012659, 0.24116, 0.11201]
Predicted label: 5
Correct prediction
Energy consumption = 139.907648 pJ
sum error= 319
Actual label: 6
Output voltages: [0.055832, 0.2725, 0.30666, 0.1213, 0.45773, 0.0069884, 0.79879, 0.0062518, 0.034959, 0.001582]
Predicted label: 6
Correct prediction
Energy consumption = 143.137666 pJ
sum error= 319
Actual label: 7
Output voltages: [0.018057, 0.25064, 0.59833, 0.19885, 0.024356, 0.0010775, 0.0011082, 0.79872, 0.55278, 0.05336]
Predicted label: 7
Correct prediction
Energy consumption = 151.071459 pJ
sum error= 319
Actual label: 8
Output voltages: [0.32289, 0.015671, 0.13276, 0.073798, 0.0099472, 0.0054998, 0.10374, 0.0010805, 0.79863, 0.0096496]
Predicted label: 8
Correct prediction
Energy consumption = 150.121103 pJ
sum error= 319
Actual label: 9
Output voltages: [0.50902, 0.011816, 0.033533, 0.50209, 0.35272, 0.0023559, 0.0012335, 0.27236, 0.2031, 0.7915]
Predicted label: 9
Correct prediction
Energy consumption = 146.300823 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79878, 0.034268, 0.032818, 0.029974, 0.016982, 0.011463, 0.12335, 0.014998, 0.38013, 0.012041]
Predicted label: 0
Correct prediction
Energy consumption = 148.174196 pJ
sum error= 319
Actual label: 1
Output voltages: [0.0040531, 0.79873, 0.032966, 0.052328, 0.26439, 0.013821, 0.73471, 0.0012454, 0.45212, 0.030327]
Predicted label: 1
Correct prediction
Energy consumption = 160.683367 pJ
sum error= 319
Actual label: 2
Output voltages: [0.41998, 0.02719, 0.79873, 0.065224, 0.0019481, 0.0010886, 0.025103, 0.03532, 0.68038, 0.0023897]
Predicted label: 2
Correct prediction
Energy consumption = 143.755440 pJ
sum error= 319
Actual label: 3
Output voltages: [0.29838, 0.0035752, 0.26903, 0.7987, 0.068939, 0.008452, 0.0014154, 0.01435, 0.36189, 0.24583]
Predicted label: 3
Correct prediction
Energy consumption = 148.485829 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 753 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 753 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 753 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.13198, 0.05836, 0.30624, 0.0041844, 0.79868, 0.0012194, 0.0094169, 0.057181, 0.01642, 0.48563]
Predicted label: 4
Correct prediction
Energy consumption = 149.663438 pJ
sum error= 319
Actual label: 5
Output voltages: [0.043123, 0.0011244, 0.0010679, 0.33579, 0.04489, 0.79875, 0.39806, 0.011135, 0.47184, 0.027663]
Predicted label: 5
Correct prediction
Energy consumption = 140.771412 pJ
sum error= 319
Actual label: 6
Output voltages: [0.044851, 0.019377, 0.55017, 0.016413, 0.41225, 0.052899, 0.79839, 0.031938, 0.48731, 0.0011282]
Predicted label: 6
Correct prediction
Energy consumption = 144.112902 pJ
sum error= 319
Actual label: 7
Output voltages: [0.34317, 0.040532, 0.028749, 0.041573, 0.019811, 0.015948, 0.0010732, 0.79867, 0.051181, 0.056132]
Predicted label: 7
Correct prediction
Energy consumption = 156.557623 pJ
sum error= 319
Actual label: 8
Output voltages: [0.20905, 0.0051564, 0.041555, 0.44412, 0.016586, 0.24392, 0.41981, 0.0011033, 0.79743, 0.023457]
Predicted label: 8
Correct prediction
Energy consumption = 153.403650 pJ
sum error= 319
Actual label: 9
Output voltages: [0.2486, 0.0095778, 0.030802, 0.025041, 0.4002, 0.021918, 0.0023871, 0.019436, 0.37308, 0.79623]
Predicted label: 9
Correct prediction
Energy consumption = 150.558140 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79872, 0.034636, 0.041877, 0.016703, 0.044067, 0.032639, 0.17682, 0.11537, 0.26619, 0.0793]
Predicted label: 0
Correct prediction
Energy consumption = 152.045185 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79879, 0.03147, 0.048004, 0.028915, 0.021574, 0.0032171, 0.5084, 0.026233, 0.61925, 0.013144]
Predicted label: 0
Correct prediction
Energy consumption = 144.510373 pJ
sum error= 319
Actual label: 7
Output voltages: [0.037728, 0.033981, 0.21654, 0.0029726, 0.2236, 0.001451, 0.0010796, 0.79876, 0.031052, 0.39563]
Predicted label: 7
Correct prediction
Energy consumption = 151.743939 pJ
sum error= 319
Actual label: 2
Output voltages: [0.15592, 0.23308, 0.79525, 0.31191, 0.045669, 0.0012104, 0.0019857, 0.48011, 0.66925, 0.0016041]
Predicted label: 2
Correct prediction
Energy consumption = 145.397149 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 754 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 754 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 754 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.18252, 0.022316, 0.24713, 0.0010661, 0.29384, 0.11235, 0.79878, 0.0046926, 0.1442, 0.0019005]
Predicted label: 6
Correct prediction
Energy consumption = 147.669606 pJ
sum error= 319
Actual label: 5
Output voltages: [0.22127, 0.0087269, 0.0012157, 0.59841, 0.58814, 0.7987, 0.03719, 0.03875, 0.020512, 0.0065668]
Predicted label: 5
Correct prediction
Energy consumption = 136.903006 pJ
sum error= 319
Actual label: 5
Output voltages: [0.041947, 0.015917, 0.0010736, 0.25354, 0.11407, 0.79879, 0.46819, 0.011458, 0.39484, 0.0066912]
Predicted label: 5
Correct prediction
Energy consumption = 125.020351 pJ
sum error= 319
Actual label: 3
Output voltages: [0.43748, 0.014106, 0.39887, 0.79876, 0.0038675, 0.0030972, 0.0086404, 0.0031616, 0.73969, 0.0049097]
Predicted label: 3
Correct prediction
Energy consumption = 142.342019 pJ
sum error= 319
Actual label: 7
Output voltages: [0.20174, 0.065754, 0.042829, 0.15232, 0.012347, 0.0015724, 0.0012174, 0.79871, 0.056157, 0.5059]
Predicted label: 7
Correct prediction
Energy consumption = 145.045067 pJ
sum error= 319
Actual label: 8
Output voltages: [0.34264, 0.0025806, 0.24376, 0.46759, 0.019411, 0.010297, 0.021517, 0.0010693, 0.79804, 0.16516]
Predicted label: 8
Correct prediction
Energy consumption = 150.570269 pJ
sum error= 319
Actual label: 6
Output voltages: [0.060216, 0.01595, 0.2794, 0.0035467, 0.53948, 0.17132, 0.79874, 0.0020787, 0.70059, 0.0032237]
Predicted label: 6
Correct prediction
Energy consumption = 145.403760 pJ
sum error= 319
Actual label: 6
Output voltages: [0.033174, 0.079687, 0.38345, 0.0035072, 0.22424, 0.089801, 0.79874, 0.0015853, 0.60381, 0.0079648]
Predicted label: 6
Correct prediction
Energy consumption = 135.499854 pJ
sum error= 319
Actual label: 6
Output voltages: [0.085683, 0.061402, 0.35322, 0.0010748, 0.36592, 0.046653, 0.79869, 0.0013755, 0.44193, 0.0090881]
Predicted label: 6
Correct prediction
Energy consumption = 133.748815 pJ
sum error= 319
Actual label: 6
Output voltages: [0.20019, 0.26406, 0.019458, 0.010957, 0.10769, 0.68077, 0.79873, 0.022286, 0.67939, 0.0011956]
Predicted label: 6
Correct prediction
Energy consumption = 142.731275 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 755 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 755 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 755 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.025957, 0.0025624, 0.37119, 0.11645, 0.79879, 0.001113, 0.019891, 0.01834, 0.03629, 0.074651]
Predicted label: 4
Correct prediction
Energy consumption = 146.573939 pJ
sum error= 319
Actual label: 3
Output voltages: [0.49188, 0.01894, 0.027507, 0.79871, 0.026214, 0.027796, 0.026576, 0.0060562, 0.59183, 0.045934]
Predicted label: 3
Correct prediction
Energy consumption = 149.523663 pJ
sum error= 319
Actual label: 8
Output voltages: [0.11104, 0.020974, 0.051661, 0.22, 0.0068263, 0.019578, 0.024979, 0.010594, 0.79703, 0.58965]
Predicted label: 8
Correct prediction
Energy consumption = 152.391219 pJ
sum error= 319
Actual label: 8
Output voltages: [0.55458, 0.019044, 0.18951, 0.50237, 0.025136, 0.020881, 0.03958, 0.0010712, 0.7976, 0.52428]
Predicted label: 8
Correct prediction
Energy consumption = 147.771213 pJ
sum error= 319
Actual label: 3
Output voltages: [0.52781, 0.01131, 0.024977, 0.79862, 0.029227, 0.14173, 0.002821, 0.0019544, 0.46258, 0.068506]
Predicted label: 3
Correct prediction
Energy consumption = 145.169352 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79799, 0.057659, 0.19719, 0.027243, 0.010858, 0.0030442, 0.48978, 0.029071, 0.11531, 0.029213]
Predicted label: 0
Correct prediction
Energy consumption = 151.118440 pJ
sum error= 319
Actual label: 1
Output voltages: [0.024648, 0.79879, 0.46417, 0.094346, 0.27097, 0.0011049, 0.024093, 0.035642, 0.3582, 0.079283]
Predicted label: 1
Correct prediction
Energy consumption = 154.292497 pJ
sum error= 319
Actual label: 9
Output voltages: [0.40838, 0.035614, 0.0084583, 0.040401, 0.36284, 0.0024603, 0.0012158, 0.0016792, 0.08381, 0.79866]
Predicted label: 9
Correct prediction
Energy consumption = 152.153640 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79796, 0.0060158, 0.33739, 0.014935, 0.013881, 0.0013708, 0.51276, 0.072617, 0.39523, 0.042312]
Predicted label: 0
Correct prediction
Energy consumption = 154.463144 pJ
sum error= 319
Actual label: 5
Output voltages: [0.27244, 0.0030285, 0.0065009, 0.69109, 0.015305, 0.79871, 0.076133, 0.038035, 0.55461, 0.12531]
Predicted label: 5
Correct prediction
Energy consumption = 151.724317 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 756 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 756 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 756 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0016449, 0.0085966, 0.0075097, 0.013338, 0.79872, 0.030278, 0.054603, 0.6807, 0.31006, 0.0019366]
Predicted label: 4
Correct prediction
Energy consumption = 148.196900 pJ
sum error= 319
Actual label: 1
Output voltages: [0.034705, 0.79877, 0.12715, 0.018417, 0.036653, 0.0010739, 0.53049, 0.0010685, 0.22052, 0.029244]
Predicted label: 1
Correct prediction
Energy consumption = 158.116112 pJ
sum error= 319
Actual label: 9
Output voltages: [0.30606, 0.0029466, 0.017004, 0.11651, 0.33769, 0.0012669, 0.0011092, 0.0042458, 0.41949, 0.79717]
Predicted label: 9
Correct prediction
Energy consumption = 150.711234 pJ
sum error= 319
Actual label: 1
Output voltages: [0.010301, 0.79879, 0.30281, 0.0018967, 0.20836, 0.0025575, 0.6847, 0.001071, 0.59097, 0.051819]
Predicted label: 1
Correct prediction
Energy consumption = 152.097910 pJ
sum error= 319
Actual label: 2
Output voltages: [0.43475, 0.033816, 0.79876, 0.20954, 0.0041943, 0.0011256, 0.013699, 0.29351, 0.6914, 0.0018414]
Predicted label: 2
Correct prediction
Energy consumption = 144.948097 pJ
sum error= 319
Actual label: 7
Output voltages: [0.43307, 0.023056, 0.017786, 0.21794, 0.015041, 0.013355, 0.0018728, 0.79863, 0.022071, 0.0011043]
Predicted label: 7
Correct prediction
Energy consumption = 147.616536 pJ
sum error= 319
Actual label: 0
Output voltages: [0.79878, 0.023977, 0.41743, 0.018459, 0.012914, 0.0011396, 0.2866, 0.023683, 0.072213, 0.046081]
Predicted label: 0
Correct prediction
Energy consumption = 143.208903 pJ
sum error= 319
Actual label: 1
Output voltages: [0.0066928, 0.79874, 0.044948, 0.085875, 0.58941, 0.00107, 0.07097, 0.025347, 0.039254, 0.18518]
Predicted label: 1
Correct prediction
Energy consumption = 155.024507 pJ
sum error= 319
Actual label: 3
Output voltages: [0.32778, 0.0024341, 0.473, 0.79612, 0.018677, 0.0040253, 0.0028413, 0.0022834, 0.78115, 0.010438]
Predicted label: 3
Correct prediction
Energy consumption = 151.516698 pJ
sum error= 319
Actual label: 8
Output voltages: [0.043733, 0.047437, 0.19474, 0.17499, 0.0068452, 0.018128, 0.33215, 0.0014557, 0.79855, 0.031816]
Predicted label: 8
Correct prediction
Energy consumption = 151.623566 pJ
sum error= 319
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 757 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 757 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 757 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.37285, 0.065161, 0.79872, 0.059192, 0.013233, 0.0012795, 0.3476, 0.03864, 0.44555, 0.023043]
Predicted label: 2
Correct prediction
Energy consumption = 141.054553 pJ
sum error= 319
Actual label: 9
Output voltages: [0.51479, 0.010591, 0.036236, 0.020389, 0.14608, 0.0047941, 0.0013577, 0.018401, 0.51819, 0.79854]
Predicted label: 9
Correct prediction
Energy consumption = 144.977891 pJ
sum error= 319
Actual label: 2
Output voltages: [0.21981, 0.012991, 0.79869, 0.059576, 0.013541, 0.0010917, 0.040287, 0.10799, 0.55047, 0.015213]
Predicted label: 2
Correct prediction
Energy consumption = 139.066433 pJ
sum error= 319
Actual label: 7
Output voltages: [0.29762, 0.13746, 0.21809, 0.014772, 0.025446, 0.0013833, 0.0011194, 0.79874, 0.1717, 0.23374]
Predicted label: 7
Correct prediction
Energy consumption = 144.249922 pJ
sum error= 319
Actual label: 4
Output voltages: [0.0034047, 0.62084, 0.025216, 0.015225, 0.79871, 0.0015182, 0.048739, 0.059618, 0.0050831, 0.56496]
Predicted label: 4
Correct prediction
Energy consumption = 138.629229 pJ
sum error= 319
Actual label: 2
Output voltages: [0.25152, 0.029126, 0.79873, 0.042023, 0.0078777, 0.0013179, 0.24433, 0.054499, 0.51945, 0.01586]
Predicted label: 2
Correct prediction
Energy consumption = 149.624051 pJ
sum error= 319
Actual label: 6
Output voltages: [0.023429, 0.038455, 0.18224, 0.0078267, 0.029017, 0.47514, 0.79879, 0.042964, 0.75404, 0.0027856]
Predicted label: 6
Correct prediction
Energy consumption = 148.564389 pJ
sum error= 319
Actual label: 5
Output voltages: [0.18555, 0.0010874, 0.001106, 0.36176, 0.14079, 0.79871, 0.3111, 0.023766, 0.60658, 0.026031]
Predicted label: 5
Correct prediction
Energy consumption = 131.979933 pJ
sum error= 319
Actual label: 5
Output voltages: [0.25238, 0.0015466, 0.0010667, 0.60232, 0.053273, 0.79874, 0.35062, 0.006094, 0.5896, 0.047473]
Predicted label: 5
Correct prediction
Energy consumption = 124.894836 pJ
sum error= 319
Actual label: 9
Output voltages: [0.020033, 0.0015321, 0.009172, 0.68593, 0.7816, 0.010609, 0.0019261, 0.04169, 0.13589, 0.77425]
Predicted label: 4
Wrong prediction!
Energy consumption = 152.901216 pJ
sum error= 320
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 758 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 758 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 758 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.20903, 0.010621, 0.0040744, 0.41668, 0.67006, 0.0016736, 0.0011977, 0.001067, 0.15369, 0.78479]
Predicted label: 9
Correct prediction
Energy consumption = 150.863380 pJ
sum error= 320
Actual label: 1
Output voltages: [0.024854, 0.79862, 0.35252, 0.018019, 0.20623, 0.0015075, 0.70628, 0.0013423, 0.18148, 0.048908]
Predicted label: 1
Correct prediction
Energy consumption = 152.794257 pJ
sum error= 320
Actual label: 1
Output voltages: [0.0090311, 0.79877, 0.016989, 0.040918, 0.44692, 0.0014258, 0.10065, 0.041741, 0.1188, 0.053763]
Predicted label: 1
Correct prediction
Energy consumption = 137.602192 pJ
sum error= 320
Actual label: 5
Output voltages: [0.27625, 0.02357, 0.0011757, 0.5342, 0.60156, 0.79875, 0.27348, 0.0047326, 0.16851, 0.23749]
Predicted label: 5
Correct prediction
Energy consumption = 143.211651 pJ
sum error= 320
Actual label: 7
Output voltages: [0.13377, 0.051424, 0.040199, 0.29599, 0.0095946, 0.010299, 0.001306, 0.79879, 0.27424, 0.60655]
Predicted label: 7
Correct prediction
Energy consumption = 157.216558 pJ
sum error= 320
Actual label: 6
Output voltages: [0.049287, 0.015619, 0.18447, 0.0022267, 0.24825, 0.21169, 0.79879, 0.0040007, 0.57548, 0.0026959]
Predicted label: 6
Correct prediction
Energy consumption = 153.245208 pJ
sum error= 320
Actual label: 8
Output voltages: [0.20019, 0.03386, 0.39968, 0.045883, 0.014773, 0.017667, 0.047659, 0.0014848, 0.79879, 0.11349]
Predicted label: 8
Correct prediction
Energy consumption = 152.854595 pJ
sum error= 320
Actual label: 2
Output voltages: [0.054211, 0.34704, 0.79635, 0.5176, 0.0027498, 0.001331, 0.070112, 0.0047808, 0.42801, 0.058364]
Predicted label: 2
Correct prediction
Energy consumption = 148.301509 pJ
sum error= 320
Actual label: 9
Output voltages: [0.31852, 0.016591, 0.01503, 0.043961, 0.51318, 0.0024949, 0.0012551, 0.0013647, 0.21652, 0.79789]
Predicted label: 9
Correct prediction
Energy consumption = 154.974401 pJ
sum error= 320
Actual label: 4
Output voltages: [0.006595, 0.0025845, 0.61196, 0.0070971, 0.79861, 0.0015275, 0.27666, 0.056814, 0.015446, 0.035799]
Predicted label: 4
Correct prediction
Energy consumption = 141.112510 pJ
sum error= 320
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 759 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 759 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 759 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.20584, 0.017123, 0.020668, 0.7987, 0.018986, 0.01566, 0.0088696, 0.027102, 0.67829, 0.037099]
Predicted label: 3
Correct prediction
Energy consumption = 148.997842 pJ
sum error= 320
Actual label: 1
Output voltages: [0.0085708, 0.79873, 0.31961, 0.10921, 0.22706, 0.001099, 0.38735, 0.0047601, 0.23983, 0.063424]
Predicted label: 1
Correct prediction
Energy consumption = 157.593703 pJ
sum error= 320
Actual label: 9
Output voltages: [0.36422, 0.01223, 0.049326, 0.035965, 0.76978, 0.0026131, 0.0077882, 0.0033542, 0.10546, 0.79174]
Predicted label: 9
Correct prediction
Energy consumption = 155.261291 pJ
sum error= 320
Actual label: 0
Output voltages: [0.79591, 0.053139, 0.052787, 0.034969, 0.046304, 0.0018036, 0.77433, 0.0033516, 0.17361, 0.080207]
Predicted label: 0
Correct prediction
Energy consumption = 148.292241 pJ
sum error= 320
Actual label: 9
Output voltages: [0.1357, 0.027733, 0.025993, 0.045926, 0.17528, 0.008584, 0.0023954, 0.021223, 0.46678, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 145.861556 pJ
sum error= 320
Actual label: 3
Output voltages: [0.35627, 0.008606, 0.29196, 0.77802, 0.0068747, 0.0060626, 0.0042967, 0.0011981, 0.77908, 0.16373]
Predicted label: 8
Wrong prediction!
Energy consumption = 144.432027 pJ
sum error= 321
Actual label: 6
Output voltages: [0.027928, 0.033068, 0.45103, 0.0021059, 0.45132, 0.21184, 0.7987, 0.0080103, 0.34815, 0.0063206]
Predicted label: 6
Correct prediction
Energy consumption = 150.549018 pJ
sum error= 321
Actual label: 8
Output voltages: [0.04532, 0.0095422, 0.05359, 0.10382, 0.0080698, 0.044847, 0.0035408, 0.0013153, 0.79872, 0.030731]
Predicted label: 8
Correct prediction
Energy consumption = 148.774635 pJ
sum error= 321
Actual label: 7
Output voltages: [0.066579, 0.010973, 0.032407, 0.07261, 0.014598, 0.004765, 0.001074, 0.79857, 0.2876, 0.33823]
Predicted label: 7
Correct prediction
Energy consumption = 151.946642 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79744, 0.053531, 0.24819, 0.043366, 0.016376, 0.0015361, 0.31693, 0.018844, 0.5256, 0.04814]
Predicted label: 0
Correct prediction
Energy consumption = 157.022407 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 760 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 760 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 760 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.039869, 0.79865, 0.19828, 0.011698, 0.25509, 0.0022463, 0.40387, 0.0097785, 0.11993, 0.010962]
Predicted label: 1
Correct prediction
Energy consumption = 152.929565 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79877, 0.03304, 0.025416, 0.016302, 0.011978, 0.0050409, 0.40492, 0.051255, 0.17656, 0.029395]
Predicted label: 0
Correct prediction
Energy consumption = 148.491501 pJ
sum error= 321
Actual label: 5
Output voltages: [0.28149, 0.0010803, 0.0010893, 0.69854, 0.041591, 0.79814, 0.46289, 0.016646, 0.50684, 0.19903]
Predicted label: 5
Correct prediction
Energy consumption = 138.908201 pJ
sum error= 321
Actual label: 8
Output voltages: [0.51396, 0.019221, 0.32708, 0.063396, 0.038517, 0.012012, 0.030567, 0.0011153, 0.79874, 0.050722]
Predicted label: 8
Correct prediction
Energy consumption = 143.425364 pJ
sum error= 321
Actual label: 2
Output voltages: [0.55466, 0.020951, 0.79878, 0.28171, 0.0020991, 0.0011134, 0.038652, 0.027878, 0.57399, 0.0077069]
Predicted label: 2
Correct prediction
Energy consumption = 140.231773 pJ
sum error= 321
Actual label: 7
Output voltages: [0.036871, 0.059032, 0.17622, 0.0018012, 0.047011, 0.001067, 0.0010676, 0.79867, 0.21433, 0.26067]
Predicted label: 7
Correct prediction
Energy consumption = 149.633376 pJ
sum error= 321
Actual label: 7
Output voltages: [0.016567, 0.03146, 0.4992, 0.011217, 0.006365, 0.0010775, 0.0011142, 0.79832, 0.73448, 0.043248]
Predicted label: 7
Correct prediction
Energy consumption = 135.414200 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79879, 0.050111, 0.02016, 0.014121, 0.070686, 0.01024, 0.70791, 0.010261, 0.080093, 0.047138]
Predicted label: 0
Correct prediction
Energy consumption = 159.525197 pJ
sum error= 321
Actual label: 1
Output voltages: [0.056008, 0.79874, 0.031047, 0.3196, 0.13551, 0.016715, 0.68147, 0.0011709, 0.10537, 0.1083]
Predicted label: 1
Correct prediction
Energy consumption = 159.386810 pJ
sum error= 321
Actual label: 2
Output voltages: [0.54995, 0.0073876, 0.79878, 0.10195, 0.025972, 0.0011218, 0.061449, 0.030445, 0.45047, 0.027076]
Predicted label: 2
Correct prediction
Energy consumption = 146.272650 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 761 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 761 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 761 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.19923, 0.01569, 0.1487, 0.79877, 0.12051, 0.017947, 0.018441, 0.045157, 0.73195, 0.019425]
Predicted label: 3
Correct prediction
Energy consumption = 148.078864 pJ
sum error= 321
Actual label: 4
Output voltages: [0.010329, 0.015706, 0.26149, 0.027541, 0.79863, 0.03001, 0.063539, 0.047293, 0.031152, 0.040511]
Predicted label: 4
Correct prediction
Energy consumption = 159.496585 pJ
sum error= 321
Actual label: 5
Output voltages: [0.025652, 0.0012539, 0.0042624, 0.43559, 0.037588, 0.79873, 0.31659, 0.033271, 0.70441, 0.065231]
Predicted label: 5
Correct prediction
Energy consumption = 150.163452 pJ
sum error= 321
Actual label: 6
Output voltages: [0.18189, 0.063007, 0.18556, 0.001135, 0.37319, 0.33594, 0.79872, 0.0018566, 0.29406, 0.015502]
Predicted label: 6
Correct prediction
Energy consumption = 148.752071 pJ
sum error= 321
Actual label: 7
Output voltages: [0.080583, 0.042933, 0.035838, 0.13024, 0.0058845, 0.0010775, 0.0011079, 0.79873, 0.42515, 0.21415]
Predicted label: 7
Correct prediction
Energy consumption = 154.862502 pJ
sum error= 321
Actual label: 8
Output voltages: [0.015797, 0.031289, 0.23512, 0.056966, 0.0080737, 0.016326, 0.037185, 0.026734, 0.79876, 0.26844]
Predicted label: 8
Correct prediction
Energy consumption = 146.052606 pJ
sum error= 321
Actual label: 9
Output voltages: [0.3054, 0.0067876, 0.034925, 0.042334, 0.42198, 0.021819, 0.013869, 0.01417, 0.21656, 0.79866]
Predicted label: 9
Correct prediction
Energy consumption = 155.345511 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79874, 0.14694, 0.038051, 0.016741, 0.01831, 0.018985, 0.16317, 0.0099987, 0.03185, 0.22273]
Predicted label: 0
Correct prediction
Energy consumption = 154.150262 pJ
sum error= 321
Actual label: 1
Output voltages: [0.02548, 0.79846, 0.11234, 0.1798, 0.015262, 0.0029535, 0.73771, 0.0017623, 0.042101, 0.048547]
Predicted label: 1
Correct prediction
Energy consumption = 160.494369 pJ
sum error= 321
Actual label: 2
Output voltages: [0.34295, 0.0010849, 0.77598, 0.77591, 0.022934, 0.0011431, 0.0027917, 0.048483, 0.75302, 0.015374]
Predicted label: 2
Correct prediction
Energy consumption = 152.320165 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 762 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 762 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 762 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.044731, 0.019168, 0.075239, 0.79868, 0.16205, 0.010025, 0.007217, 0.030712, 0.58303, 0.11618]
Predicted label: 3
Correct prediction
Energy consumption = 142.500315 pJ
sum error= 321
Actual label: 4
Output voltages: [0.03051, 0.012877, 0.22226, 0.012401, 0.79869, 0.0016058, 0.22946, 0.030346, 0.021484, 0.053223]
Predicted label: 4
Correct prediction
Energy consumption = 152.886299 pJ
sum error= 321
Actual label: 5
Output voltages: [0.14399, 0.0046242, 0.0012683, 0.74013, 0.035018, 0.79866, 0.26999, 0.061445, 0.76992, 0.024642]
Predicted label: 5
Correct prediction
Energy consumption = 149.498313 pJ
sum error= 321
Actual label: 8
Output voltages: [0.21156, 0.15637, 0.051525, 0.16371, 0.018156, 0.040352, 0.075676, 0.010261, 0.79876, 0.3471]
Predicted label: 8
Correct prediction
Energy consumption = 150.287893 pJ
sum error= 321
Actual label: 9
Output voltages: [0.5747, 0.014965, 0.19667, 0.62746, 0.024423, 0.0099246, 0.034873, 0.042483, 0.014884, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 157.642123 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79879, 0.15139, 0.081308, 0.03356, 0.032874, 0.0082043, 0.756, 0.0096188, 0.23552, 0.021775]
Predicted label: 0
Correct prediction
Energy consumption = 155.791857 pJ
sum error= 321
Actual label: 1
Output voltages: [0.018858, 0.79844, 0.04702, 0.15208, 0.025394, 0.0066111, 0.49399, 0.017405, 0.30501, 0.029897]
Predicted label: 1
Correct prediction
Energy consumption = 163.054464 pJ
sum error= 321
Actual label: 2
Output voltages: [0.70039, 0.0019046, 0.79874, 0.35987, 0.0037015, 0.0022564, 0.063515, 0.075119, 0.5233, 0.0032155]
Predicted label: 2
Correct prediction
Energy consumption = 150.071341 pJ
sum error= 321
Actual label: 3
Output voltages: [0.069933, 0.018773, 0.32592, 0.79868, 0.045863, 0.0125, 0.0051488, 0.088141, 0.53078, 0.07083]
Predicted label: 3
Correct prediction
Energy consumption = 144.132896 pJ
sum error= 321
Actual label: 4
Output voltages: [0.011769, 0.010905, 0.033835, 0.0064387, 0.79879, 0.0025614, 0.22021, 0.60074, 0.1061, 0.037907]
Predicted label: 4
Correct prediction
Energy consumption = 160.108013 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 763 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 763 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 763 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.049259, 0.0010971, 0.0036684, 0.3824, 0.035872, 0.79875, 0.23972, 0.17988, 0.77268, 0.033643]
Predicted label: 5
Correct prediction
Energy consumption = 147.838971 pJ
sum error= 321
Actual label: 6
Output voltages: [0.20109, 0.0064718, 0.15452, 0.0026141, 0.5464, 0.24747, 0.79878, 0.0014045, 0.73674, 0.0093842]
Predicted label: 6
Correct prediction
Energy consumption = 146.910517 pJ
sum error= 321
Actual label: 7
Output voltages: [0.037314, 0.04599, 0.050303, 0.019744, 0.021541, 0.0018777, 0.0012454, 0.79854, 0.1269, 0.28594]
Predicted label: 7
Correct prediction
Energy consumption = 160.328031 pJ
sum error= 321
Actual label: 8
Output voltages: [0.036609, 0.13477, 0.09952, 0.27719, 0.014877, 0.008918, 0.046512, 0.012599, 0.79875, 0.16498]
Predicted label: 8
Correct prediction
Energy consumption = 150.519887 pJ
sum error= 321
Actual label: 9
Output voltages: [0.21866, 0.020206, 0.028022, 0.10309, 0.15298, 0.0058018, 0.0091829, 0.042983, 0.37265, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 154.098218 pJ
sum error= 321
Actual label: 2
Output voltages: [0.57182, 0.001426, 0.79876, 0.068641, 0.0055678, 0.001066, 0.009319, 0.1022, 0.59346, 0.0089734]
Predicted label: 2
Correct prediction
Energy consumption = 147.711344 pJ
sum error= 321
Actual label: 1
Output voltages: [0.0023296, 0.79857, 0.034177, 0.020486, 0.049685, 0.0019045, 0.5666, 0.0061838, 0.017821, 0.27761]
Predicted label: 1
Correct prediction
Energy consumption = 166.081937 pJ
sum error= 321
Actual label: 2
Output voltages: [0.48714, 0.0012366, 0.79875, 0.52882, 0.0024732, 0.0011448, 0.002308, 0.18102, 0.47766, 0.011839]
Predicted label: 2
Correct prediction
Energy consumption = 154.492102 pJ
sum error= 321
Actual label: 1
Output voltages: [0.0035976, 0.7987, 0.019303, 0.34299, 0.055257, 0.015067, 0.12982, 0.0024753, 0.26897, 0.1214]
Predicted label: 1
Correct prediction
Energy consumption = 164.037199 pJ
sum error= 321
Actual label: 3
Output voltages: [0.041344, 0.0016392, 0.13881, 0.79879, 0.042723, 0.029679, 0.013649, 0.01712, 0.71863, 0.036304]
Predicted label: 3
Correct prediction
Energy consumption = 143.589651 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 764 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 764 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 764 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.28227, 0.052965, 0.033504, 0.032861, 0.089351, 0.024943, 0.00735, 0.016996, 0.13774, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 159.688224 pJ
sum error= 321
Actual label: 9
Output voltages: [0.03188, 0.018545, 0.093727, 0.011776, 0.036242, 0.0073456, 0.017811, 0.012788, 0.5367, 0.79829]
Predicted label: 9
Correct prediction
Energy consumption = 147.228489 pJ
sum error= 321
Actual label: 8
Output voltages: [0.012061, 0.16287, 0.048651, 0.28256, 0.007784, 0.018055, 0.04394, 0.024926, 0.79871, 0.036491]
Predicted label: 8
Correct prediction
Energy consumption = 151.329997 pJ
sum error= 321
Actual label: 5
Output voltages: [0.14618, 0.0011067, 0.003368, 0.27218, 0.023197, 0.79868, 0.067004, 0.1943, 0.76629, 0.016724]
Predicted label: 5
Correct prediction
Energy consumption = 145.400919 pJ
sum error= 321
Actual label: 3
Output voltages: [0.44669, 0.01182, 0.06508, 0.79862, 0.02346, 0.1177, 0.013008, 0.03119, 0.57985, 0.054156]
Predicted label: 3
Correct prediction
Energy consumption = 140.283751 pJ
sum error= 321
Actual label: 7
Output voltages: [0.22672, 0.020458, 0.032593, 0.032106, 0.0052082, 0.0059439, 0.0010832, 0.79879, 0.7269, 0.50832]
Predicted label: 7
Correct prediction
Energy consumption = 140.223113 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79875, 0.10256, 0.28638, 0.0067498, 0.038028, 0.0020779, 0.073237, 0.003521, 0.27901, 0.026885]
Predicted label: 0
Correct prediction
Energy consumption = 157.723240 pJ
sum error= 321
Actual label: 7
Output voltages: [0.032742, 0.26445, 0.42427, 0.068806, 0.0016207, 0.0011283, 0.0011517, 0.79871, 0.50658, 0.29925]
Predicted label: 7
Correct prediction
Energy consumption = 150.494489 pJ
sum error= 321
Actual label: 7
Output voltages: [0.050288, 0.29076, 0.6984, 0.036763, 0.0052158, 0.0010765, 0.0010672, 0.79867, 0.23019, 0.16868]
Predicted label: 7
Correct prediction
Energy consumption = 135.007376 pJ
sum error= 321
Actual label: 5
Output voltages: [0.036218, 0.0011109, 0.0025795, 0.17524, 0.032848, 0.79876, 0.25855, 0.064425, 0.69341, 0.18948]
Predicted label: 5
Correct prediction
Energy consumption = 146.916357 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 765 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 765 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 765 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.031542, 0.16164, 0.095694, 0.18463, 0.0036636, 0.0011449, 0.0010943, 0.79872, 0.43518, 0.29509]
Predicted label: 7
Correct prediction
Energy consumption = 158.312367 pJ
sum error= 321
Actual label: 9
Output voltages: [0.022827, 0.03344, 0.039823, 0.034997, 0.28409, 0.0050531, 0.0025138, 0.0014294, 0.57504, 0.79381]
Predicted label: 9
Correct prediction
Energy consumption = 150.880609 pJ
sum error= 321
Actual label: 9
Output voltages: [0.096598, 0.0069529, 0.058746, 0.018798, 0.22996, 0.0038655, 0.074506, 0.0054815, 0.36991, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 138.577052 pJ
sum error= 321
Actual label: 4
Output voltages: [0.0075699, 0.029428, 0.20824, 0.03853, 0.79864, 0.0016184, 0.19352, 0.044658, 0.019391, 0.08564]
Predicted label: 4
Correct prediction
Energy consumption = 149.129896 pJ
sum error= 321
Actual label: 7
Output voltages: [0.046895, 0.041021, 0.10274, 0.09657, 0.0040724, 0.012113, 0.0010755, 0.79865, 0.4582, 0.43612]
Predicted label: 7
Correct prediction
Energy consumption = 152.388041 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79879, 0.20389, 0.032767, 0.025693, 0.014553, 0.0097866, 0.48597, 0.0032087, 0.16629, 0.010016]
Predicted label: 0
Correct prediction
Energy consumption = 155.850571 pJ
sum error= 321
Actual label: 3
Output voltages: [0.045522, 0.018969, 0.092047, 0.79872, 0.21732, 0.0015669, 0.027208, 0.25662, 0.64303, 0.029646]
Predicted label: 3
Correct prediction
Energy consumption = 152.503787 pJ
sum error= 321
Actual label: 4
Output voltages: [0.040032, 0.015903, 0.054703, 0.0090625, 0.79874, 0.0021641, 0.026457, 0.02611, 0.0090797, 0.49637]
Predicted label: 4
Correct prediction
Energy consumption = 158.908580 pJ
sum error= 321
Actual label: 1
Output voltages: [0.01563, 0.79846, 0.019498, 0.036426, 0.0094892, 0.0035832, 0.42276, 0.0062787, 0.6064, 0.049049]
Predicted label: 1
Correct prediction
Energy consumption = 167.194006 pJ
sum error= 321
Actual label: 5
Output voltages: [0.043666, 0.0010903, 0.0050573, 0.36935, 0.0058927, 0.79839, 0.093498, 0.028778, 0.75495, 0.075014]
Predicted label: 5
Correct prediction
Energy consumption = 148.622235 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 766 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 766 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 766 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.038257, 0.051614, 0.23728, 0.11589, 0.0075879, 0.021425, 0.02884, 0.015437, 0.79875, 0.18597]
Predicted label: 8
Correct prediction
Energy consumption = 152.589771 pJ
sum error= 321
Actual label: 1
Output voltages: [0.0078975, 0.79841, 0.029826, 0.039511, 0.023036, 0.029528, 0.75277, 0.03453, 0.043371, 0.020183]
Predicted label: 1
Correct prediction
Energy consumption = 162.285427 pJ
sum error= 321
Actual label: 4
Output voltages: [0.0010777, 0.0091154, 0.37435, 0.023239, 0.79868, 0.0014207, 0.31934, 0.051789, 0.043539, 0.039131]
Predicted label: 4
Correct prediction
Energy consumption = 154.301383 pJ
sum error= 321
Actual label: 8
Output voltages: [0.0068455, 0.17796, 0.34549, 0.033546, 0.021125, 0.0048374, 0.02282, 0.036178, 0.79874, 0.1339]
Predicted label: 8
Correct prediction
Energy consumption = 152.486931 pJ
sum error= 321
Actual label: 4
Output voltages: [0.0086872, 0.057817, 0.083785, 0.00441, 0.79867, 0.037459, 0.19463, 0.08672, 0.047573, 0.0368]
Predicted label: 4
Correct prediction
Energy consumption = 157.543422 pJ
sum error= 321
Actual label: 1
Output voltages: [0.0082296, 0.79855, 0.011128, 0.21891, 0.087477, 0.0066673, 0.54817, 0.0089415, 0.22824, 0.40044]
Predicted label: 1
Correct prediction
Energy consumption = 163.574075 pJ
sum error= 321
Actual label: 8
Output voltages: [0.019661, 0.035477, 0.36885, 0.032193, 0.021345, 0.0077555, 0.019211, 0.01366, 0.79865, 0.091051]
Predicted label: 8
Correct prediction
Energy consumption = 148.270294 pJ
sum error= 321
Actual label: 6
Output voltages: [0.098038, 0.19551, 0.40464, 0.0010876, 0.20786, 0.061483, 0.79871, 0.0018574, 0.51077, 0.011111]
Predicted label: 6
Correct prediction
Energy consumption = 147.369548 pJ
sum error= 321
Actual label: 6
Output voltages: [0.019425, 0.047492, 0.67222, 0.0010963, 0.28477, 0.19503, 0.79879, 0.0013288, 0.23767, 0.0014757]
Predicted label: 6
Correct prediction
Energy consumption = 136.468539 pJ
sum error= 321
Actual label: 4
Output voltages: [0.0017822, 0.0045166, 0.30176, 0.0049861, 0.79874, 0.002582, 0.098502, 0.063513, 0.013265, 0.16413]
Predicted label: 4
Correct prediction
Energy consumption = 157.371926 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 767 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 767 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 767 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.063024, 0.10072, 0.22461, 0.016773, 0.31924, 0.22136, 0.79864, 0.0025885, 0.5445, 0.022785]
Predicted label: 6
Correct prediction
Energy consumption = 149.440602 pJ
sum error= 321
Actual label: 0
Output voltages: [0.7914, 0.036774, 0.008922, 0.0080117, 0.018795, 0.12758, 0.76743, 0.029808, 0.15873, 0.032953]
Predicted label: 0
Correct prediction
Energy consumption = 157.109522 pJ
sum error= 321
Actual label: 5
Output voltages: [0.19149, 0.0010745, 0.00651, 0.41572, 0.0034009, 0.79879, 0.046492, 0.060449, 0.79324, 0.024266]
Predicted label: 5
Correct prediction
Energy consumption = 140.347778 pJ
sum error= 321
Actual label: 5
Output voltages: [0.051357, 0.0065496, 0.0010661, 0.78306, 0.0025856, 0.79417, 0.075014, 0.019825, 0.61871, 0.29299]
Predicted label: 5
Correct prediction
Energy consumption = 142.606127 pJ
sum error= 321
Actual label: 3
Output voltages: [0.26271, 0.034304, 0.06334, 0.79862, 0.012496, 0.015311, 0.0085395, 0.035958, 0.37614, 0.05373]
Predicted label: 3
Correct prediction
Energy consumption = 136.878790 pJ
sum error= 321
Actual label: 3
Output voltages: [0.12497, 0.022188, 0.042032, 0.79864, 0.036532, 0.021701, 0.017978, 0.016149, 0.61454, 0.16268]
Predicted label: 3
Correct prediction
Energy consumption = 133.292596 pJ
sum error= 321
Actual label: 5
Output voltages: [0.033725, 0.0010769, 0.0030485, 0.64695, 0.02359, 0.79731, 0.14796, 0.051716, 0.75552, 0.34912]
Predicted label: 5
Correct prediction
Energy consumption = 144.345966 pJ
sum error= 321
Actual label: 7
Output voltages: [0.24063, 0.13433, 0.48721, 0.26987, 0.0016637, 0.0010839, 0.0050864, 0.79879, 0.30158, 0.291]
Predicted label: 7
Correct prediction
Energy consumption = 162.311174 pJ
sum error= 321
Actual label: 2
Output voltages: [0.58362, 0.024033, 0.79878, 0.10654, 0.033576, 0.0011079, 0.06526, 0.070466, 0.54625, 0.0055463]
Predicted label: 2
Correct prediction
Energy consumption = 142.264653 pJ
sum error= 321
Actual label: 5
Output voltages: [0.32554, 0.0010684, 0.0042895, 0.27904, 0.0018234, 0.79852, 0.069847, 0.35884, 0.77016, 0.027634]
Predicted label: 5
Correct prediction
Energy consumption = 151.149264 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 768 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 768 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 768 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.27346, 0.0063061, 0.029584, 0.026249, 0.33857, 0.0014779, 0.024682, 0.0061023, 0.28033, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 158.148856 pJ
sum error= 321
Actual label: 6
Output voltages: [0.040214, 0.1485, 0.23602, 0.005569, 0.29769, 0.3354, 0.7986, 0.0050219, 0.4191, 0.017962]
Predicted label: 6
Correct prediction
Energy consumption = 147.659337 pJ
sum error= 321
Actual label: 9
Output voltages: [0.17446, 0.0088781, 0.0084996, 0.013393, 0.077112, 0.0050151, 0.0015185, 0.0073642, 0.55271, 0.79843]
Predicted label: 9
Correct prediction
Energy consumption = 156.953883 pJ
sum error= 321
Actual label: 2
Output voltages: [0.76128, 0.0015817, 0.79338, 0.53109, 0.0047388, 0.0010925, 0.0066206, 0.032309, 0.71268, 0.0077305]
Predicted label: 2
Correct prediction
Energy consumption = 148.350975 pJ
sum error= 321
Actual label: 6
Output voltages: [0.13313, 0.030003, 0.3515, 0.0017181, 0.3082, 0.22754, 0.79872, 0.0023434, 0.57054, 0.0059494]
Predicted label: 6
Correct prediction
Energy consumption = 143.126135 pJ
sum error= 321
Actual label: 2
Output voltages: [0.69699, 0.082534, 0.79872, 0.039373, 0.023968, 0.0011666, 0.047281, 0.048245, 0.28017, 0.027053]
Predicted label: 2
Correct prediction
Energy consumption = 148.842344 pJ
sum error= 321
Actual label: 1
Output voltages: [0.029489, 0.79847, 0.091684, 0.23045, 0.14411, 0.015505, 0.31465, 0.0020546, 0.36389, 0.21114]
Predicted label: 1
Correct prediction
Energy consumption = 158.320635 pJ
sum error= 321
Actual label: 2
Output voltages: [0.54767, 0.0056901, 0.79876, 0.22222, 0.0039408, 0.0010686, 0.35961, 0.22741, 0.41456, 0.0034828]
Predicted label: 2
Correct prediction
Energy consumption = 151.620509 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79877, 0.022558, 0.024796, 0.0058652, 0.011575, 0.029038, 0.56924, 0.0066142, 0.028432, 0.032639]
Predicted label: 0
Correct prediction
Energy consumption = 153.932492 pJ
sum error= 321
Actual label: 8
Output voltages: [0.34595, 0.049974, 0.03557, 0.74482, 0.0012135, 0.0031976, 0.029683, 0.040162, 0.79468, 0.052675]
Predicted label: 8
Correct prediction
Energy consumption = 160.428497 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 769 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 769 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 769 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.20093, 0.023437, 0.12637, 0.7986, 0.031656, 0.011343, 0.018174, 0.049339, 0.40883, 0.10982]
Predicted label: 3
Correct prediction
Energy consumption = 147.431822 pJ
sum error= 321
Actual label: 8
Output voltages: [0.001508, 0.52617, 0.013701, 0.090618, 0.29155, 0.01418, 0.075797, 0.006748, 0.78946, 0.14513]
Predicted label: 8
Correct prediction
Energy consumption = 156.697343 pJ
sum error= 321
Actual label: 3
Output voltages: [0.22399, 0.025885, 0.047511, 0.79866, 0.025248, 0.010337, 0.025796, 0.033819, 0.67345, 0.17335]
Predicted label: 3
Correct prediction
Energy consumption = 148.278657 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79865, 0.043432, 0.015117, 0.0074395, 0.051656, 0.017404, 0.60491, 0.0082705, 0.02882, 0.17268]
Predicted label: 0
Correct prediction
Energy consumption = 160.309126 pJ
sum error= 321
Actual label: 8
Output voltages: [0.025675, 0.0037312, 0.55426, 0.041243, 0.0014272, 0.67412, 0.1061, 0.0016503, 0.7984, 0.039928]
Predicted label: 8
Correct prediction
Energy consumption = 155.297355 pJ
sum error= 321
Actual label: 7
Output voltages: [0.19071, 0.024524, 0.23645, 0.24219, 0.0057493, 0.0013872, 0.0010734, 0.79864, 0.050934, 0.16119]
Predicted label: 7
Correct prediction
Energy consumption = 153.033840 pJ
sum error= 321
Actual label: 4
Output voltages: [0.012116, 0.0045365, 0.3889, 0.0080579, 0.79863, 0.0057355, 0.22726, 0.0492, 0.025269, 0.040534]
Predicted label: 4
Correct prediction
Energy consumption = 158.089263 pJ
sum error= 321
Actual label: 9
Output voltages: [0.43628, 0.03977, 0.0086236, 0.057804, 0.45233, 0.0012367, 0.0019966, 0.027139, 0.028047, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 156.350659 pJ
sum error= 321
Actual label: 5
Output voltages: [0.040644, 0.0014337, 0.0016628, 0.63999, 0.0049185, 0.79744, 0.057288, 0.19205, 0.57943, 0.073663]
Predicted label: 5
Correct prediction
Energy consumption = 149.436062 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79875, 0.095066, 0.029622, 0.015128, 0.012662, 0.011483, 0.40125, 0.017651, 0.054002, 0.035598]
Predicted label: 0
Correct prediction
Energy consumption = 149.780077 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 770 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 770 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 770 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.28808, 0.040632, 0.02075, 0.055848, 0.13461, 0.046019, 0.015325, 0.019566, 0.29272, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 150.840093 pJ
sum error= 321
Actual label: 7
Output voltages: [0.67388, 0.0052864, 0.47823, 0.037613, 0.011641, 0.0010673, 0.0010989, 0.79866, 0.28152, 0.022278]
Predicted label: 7
Correct prediction
Energy consumption = 148.789047 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79874, 0.063867, 0.031982, 0.011838, 0.018807, 0.0015916, 0.74842, 0.025859, 0.22713, 0.1187]
Predicted label: 0
Correct prediction
Energy consumption = 149.626429 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79879, 0.21861, 0.09785, 0.044759, 0.024149, 0.010958, 0.5162, 0.020518, 0.11456, 0.24976]
Predicted label: 0
Correct prediction
Energy consumption = 146.283817 pJ
sum error= 321
Actual label: 4
Output voltages: [0.0022688, 0.02244, 0.38354, 0.01135, 0.79876, 0.0010821, 0.037144, 0.24294, 0.021151, 0.31373]
Predicted label: 4
Correct prediction
Energy consumption = 159.351144 pJ
sum error= 321
Actual label: 6
Output voltages: [0.099802, 0.11842, 0.052802, 0.01831, 0.43022, 0.31704, 0.79875, 0.0012748, 0.2717, 0.026535]
Predicted label: 6
Correct prediction
Energy consumption = 146.130541 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79879, 0.058385, 0.050467, 0.044836, 0.0090599, 0.044991, 0.74512, 0.041572, 0.23638, 0.041065]
Predicted label: 0
Correct prediction
Energy consumption = 157.616595 pJ
sum error= 321
Actual label: 9
Output voltages: [0.18271, 0.012843, 0.02579, 0.02633, 0.093923, 0.013664, 0.0068712, 0.067823, 0.41487, 0.79773]
Predicted label: 9
Correct prediction
Energy consumption = 151.314488 pJ
sum error= 321
Actual label: 1
Output voltages: [0.032504, 0.79858, 0.030167, 0.0045582, 0.23147, 0.0083243, 0.67471, 0.0070369, 0.30661, 0.047101]
Predicted label: 1
Correct prediction
Energy consumption = 157.107246 pJ
sum error= 321
Actual label: 6
Output voltages: [0.061754, 0.13244, 0.19397, 0.0023175, 0.10586, 0.039531, 0.79879, 0.0011156, 0.48786, 0.0058352]
Predicted label: 6
Correct prediction
Energy consumption = 140.254380 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 771 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 771 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 771 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.35822, 0.0053562, 0.79878, 0.044842, 0.0090949, 0.0011141, 0.049708, 0.042268, 0.47535, 0.0062082]
Predicted label: 2
Correct prediction
Energy consumption = 149.781755 pJ
sum error= 321
Actual label: 7
Output voltages: [0.6877, 0.10811, 0.0060127, 0.082046, 0.013672, 0.09099, 0.0010759, 0.79875, 0.05007, 0.24204]
Predicted label: 7
Correct prediction
Energy consumption = 152.160135 pJ
sum error= 321
Actual label: 6
Output voltages: [0.34956, 0.04261, 0.34406, 0.0072146, 0.09102, 0.040716, 0.79869, 0.0012801, 0.68514, 0.037019]
Predicted label: 6
Correct prediction
Energy consumption = 140.914196 pJ
sum error= 321
Actual label: 8
Output voltages: [0.14636, 0.011365, 0.056666, 0.058832, 0.0013717, 0.74688, 0.1438, 0.0021538, 0.79879, 0.002011]
Predicted label: 8
Correct prediction
Energy consumption = 155.603685 pJ
sum error= 321
Actual label: 3
Output voltages: [0.010861, 0.0086682, 0.26598, 0.79879, 0.032888, 0.022081, 0.0062206, 0.0073009, 0.75383, 0.032825]
Predicted label: 3
Correct prediction
Energy consumption = 140.008690 pJ
sum error= 321
Actual label: 5
Output voltages: [0.03848, 0.0015959, 0.0068626, 0.32202, 0.0034604, 0.79866, 0.02734, 0.24281, 0.73664, 0.36997]
Predicted label: 5
Correct prediction
Energy consumption = 143.157022 pJ
sum error= 321
Actual label: 2
Output voltages: [0.50379, 0.0099507, 0.79879, 0.085795, 0.031543, 0.0011994, 0.044412, 0.027496, 0.42972, 0.023906]
Predicted label: 2
Correct prediction
Energy consumption = 152.584032 pJ
sum error= 321
Actual label: 1
Output voltages: [0.010774, 0.79848, 0.0062358, 0.15693, 0.0054385, 0.016735, 0.72653, 0.019775, 0.52774, 0.017672]
Predicted label: 1
Correct prediction
Energy consumption = 164.107420 pJ
sum error= 321
Actual label: 8
Output voltages: [0.045772, 0.014935, 0.39898, 0.0055612, 0.046939, 0.0018607, 0.024261, 0.0023517, 0.79879, 0.18853]
Predicted label: 8
Correct prediction
Energy consumption = 146.832691 pJ
sum error= 321
Actual label: 3
Output voltages: [0.18625, 0.024276, 0.053996, 0.79861, 0.038779, 0.016118, 0.026071, 0.025338, 0.5631, 0.26503]
Predicted label: 3
Correct prediction
Energy consumption = 140.505014 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 772 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 772 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 772 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.60423, 0.016468, 0.045059, 0.33271, 0.01288, 0.66478, 0.22629, 0.0019213, 0.79879, 0.044129]
Predicted label: 8
Correct prediction
Energy consumption = 156.533541 pJ
sum error= 321
Actual label: 6
Output voltages: [0.096139, 0.057531, 0.2114, 0.0015724, 0.25529, 0.42331, 0.79868, 0.008567, 0.25694, 0.025336]
Predicted label: 6
Correct prediction
Energy consumption = 141.705201 pJ
sum error= 321
Actual label: 1
Output voltages: [0.0028733, 0.7986, 0.105, 0.012224, 0.0077686, 0.0014991, 0.53141, 0.0045321, 0.4415, 0.016017]
Predicted label: 1
Correct prediction
Energy consumption = 165.084712 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79877, 0.16059, 0.060084, 0.0069939, 0.016189, 0.0055065, 0.34329, 0.0059362, 0.061136, 0.10296]
Predicted label: 0
Correct prediction
Energy consumption = 150.598517 pJ
sum error= 321
Actual label: 2
Output voltages: [0.35199, 0.024951, 0.7987, 0.28666, 0.010454, 0.0011508, 0.29042, 0.021996, 0.46704, 0.020111]
Predicted label: 2
Correct prediction
Energy consumption = 150.389821 pJ
sum error= 321
Actual label: 1
Output voltages: [0.21799, 0.79853, 0.070379, 0.062338, 0.26131, 0.0049192, 0.1591, 0.0060513, 0.090883, 0.10605]
Predicted label: 1
Correct prediction
Energy consumption = 161.370003 pJ
sum error= 321
Actual label: 4
Output voltages: [0.0021284, 0.0026232, 0.39554, 0.016675, 0.79854, 0.0015552, 0.21696, 0.02484, 0.024595, 0.039897]
Predicted label: 4
Correct prediction
Energy consumption = 152.696224 pJ
sum error= 321
Actual label: 0
Output voltages: [0.79873, 0.11765, 0.01671, 0.017494, 0.028784, 0.051419, 0.74212, 0.011525, 0.19833, 0.0018683]
Predicted label: 0
Correct prediction
Energy consumption = 157.055742 pJ
sum error= 321
Actual label: 1
Output voltages: [0.0018437, 0.79873, 0.049855, 0.18871, 0.042892, 0.0010715, 0.46078, 0.010888, 0.61448, 0.13342]
Predicted label: 1
Correct prediction
Energy consumption = 160.126136 pJ
sum error= 321
Actual label: 2
Output voltages: [0.37287, 0.018225, 0.79878, 0.03087, 0.016012, 0.0011688, 0.10574, 0.103, 0.60393, 0.026818]
Predicted label: 2
Correct prediction
Energy consumption = 144.429738 pJ
sum error= 321
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 773 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 773 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 773 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.46821, 0.0085206, 0.74085, 0.7986, 0.0020265, 0.0011624, 0.0073813, 0.0017882, 0.48828, 0.020843]
Predicted label: 3
Correct prediction
Energy consumption = 150.299684 pJ
sum error= 321
Actual label: 4
Output voltages: [0.010119, 0.021502, 0.044768, 0.0017667, 0.79873, 0.0087408, 0.11501, 0.58392, 0.10964, 0.011611]
Predicted label: 4
Correct prediction
Energy consumption = 146.051991 pJ
sum error= 321
Actual label: 5
Output voltages: [0.0076776, 0.0011299, 0.021088, 0.1173, 0.0061132, 0.76164, 0.17685, 0.001892, 0.79438, 0.013225]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.881383 pJ
sum error= 322
Actual label: 6
Output voltages: [0.35696, 0.078782, 0.084596, 0.0032572, 0.2472, 0.086643, 0.79879, 0.0010704, 0.37661, 0.0096793]
Predicted label: 6
Correct prediction
Energy consumption = 143.966537 pJ
sum error= 322
Actual label: 7
Output voltages: [0.01929, 0.14456, 0.4551, 0.052646, 0.0013241, 0.012611, 0.0011821, 0.79867, 0.41753, 0.050273]
Predicted label: 7
Correct prediction
Energy consumption = 159.603577 pJ
sum error= 322
Actual label: 8
Output voltages: [0.25875, 0.015664, 0.14118, 0.34381, 0.0021673, 0.029876, 0.006686, 0.0011333, 0.79879, 0.2587]
Predicted label: 8
Correct prediction
Energy consumption = 152.280589 pJ
sum error= 322
Actual label: 9
Output voltages: [0.61262, 0.0074827, 0.66788, 0.017631, 0.38108, 0.0010677, 0.0011072, 0.16002, 0.616, 0.70677]
Predicted label: 9
Correct prediction
Energy consumption = 149.899693 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79878, 0.065257, 0.053287, 0.012822, 0.022138, 0.0029367, 0.6011, 0.0063484, 0.073593, 0.035066]
Predicted label: 0
Correct prediction
Energy consumption = 146.651530 pJ
sum error= 322
Actual label: 1
Output voltages: [0.013221, 0.79872, 0.0069158, 0.031932, 0.52504, 0.0014041, 0.12732, 0.0010747, 0.53322, 0.055278]
Predicted label: 1
Correct prediction
Energy consumption = 156.144799 pJ
sum error= 322
Actual label: 2
Output voltages: [0.51065, 0.0015036, 0.79865, 0.6115, 0.0060171, 0.0012123, 0.0096844, 0.055609, 0.47757, 0.013276]
Predicted label: 2
Correct prediction
Energy consumption = 150.472888 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 774 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 774 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 774 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.39221, 0.010454, 0.14565, 0.79871, 0.017645, 0.0037777, 0.015494, 0.0045231, 0.59397, 0.030378]
Predicted label: 3
Correct prediction
Energy consumption = 147.467191 pJ
sum error= 322
Actual label: 4
Output voltages: [0.0060097, 0.021559, 0.19491, 0.011589, 0.79868, 0.012314, 0.047392, 0.14736, 0.057953, 0.0088251]
Predicted label: 4
Correct prediction
Energy consumption = 146.673608 pJ
sum error= 322
Actual label: 5
Output voltages: [0.043413, 0.0012792, 0.0023958, 0.12086, 0.042456, 0.79847, 0.12663, 0.01883, 0.78629, 0.013751]
Predicted label: 5
Correct prediction
Energy consumption = 148.782417 pJ
sum error= 322
Actual label: 6
Output voltages: [0.0087196, 0.017368, 0.41932, 0.0015054, 0.32349, 0.47728, 0.79878, 0.0034942, 0.25331, 0.0014479]
Predicted label: 6
Correct prediction
Energy consumption = 143.882352 pJ
sum error= 322
Actual label: 7
Output voltages: [0.41012, 0.069515, 0.70349, 0.046366, 0.026289, 0.0011581, 0.0010887, 0.79876, 0.026026, 0.032218]
Predicted label: 7
Correct prediction
Energy consumption = 155.483370 pJ
sum error= 322
Actual label: 8
Output voltages: [0.031119, 0.043903, 0.49715, 0.037785, 0.010019, 0.016656, 0.032419, 0.0026044, 0.79879, 0.2247]
Predicted label: 8
Correct prediction
Energy consumption = 149.508724 pJ
sum error= 322
Actual label: 9
Output voltages: [0.50367, 0.0012319, 0.03474, 0.1409, 0.054752, 0.0011106, 0.0010665, 0.028758, 0.74871, 0.76504]
Predicted label: 9
Correct prediction
Energy consumption = 151.154788 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79878, 0.025786, 0.044907, 0.012084, 0.024024, 0.0099612, 0.72501, 0.020964, 0.084677, 0.33174]
Predicted label: 0
Correct prediction
Energy consumption = 138.629920 pJ
sum error= 322
Actual label: 1
Output voltages: [0.040897, 0.79871, 0.035899, 0.030869, 0.27159, 0.0011631, 0.023349, 0.0011242, 0.46796, 0.24149]
Predicted label: 1
Correct prediction
Energy consumption = 155.836566 pJ
sum error= 322
Actual label: 2
Output voltages: [0.33027, 0.0020713, 0.78576, 0.63506, 0.036277, 0.0011585, 0.023185, 0.024448, 0.76937, 0.044261]
Predicted label: 2
Correct prediction
Energy consumption = 145.596988 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 775 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 775 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 775 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34816, 0.022587, 0.048382, 0.79867, 0.0064585, 0.023447, 0.0082643, 0.017726, 0.51021, 0.021627]
Predicted label: 3
Correct prediction
Energy consumption = 142.185380 pJ
sum error= 322
Actual label: 4
Output voltages: [0.012588, 0.016222, 0.11623, 0.0051995, 0.79878, 0.022064, 0.087236, 0.091536, 0.25929, 0.002764]
Predicted label: 4
Correct prediction
Energy consumption = 145.906368 pJ
sum error= 322
Actual label: 5
Output voltages: [0.052844, 0.0011446, 0.0011872, 0.29598, 0.026555, 0.79751, 0.15745, 0.043735, 0.7735, 0.045473]
Predicted label: 5
Correct prediction
Energy consumption = 145.993131 pJ
sum error= 322
Actual label: 6
Output voltages: [0.13704, 0.017747, 0.12416, 0.01799, 0.35361, 0.56361, 0.79878, 0.001083, 0.56938, 0.051996]
Predicted label: 6
Correct prediction
Energy consumption = 146.125000 pJ
sum error= 322
Actual label: 7
Output voltages: [0.1419, 0.039605, 0.066381, 0.031814, 0.010098, 0.0088422, 0.0010725, 0.79855, 0.036828, 0.365]
Predicted label: 7
Correct prediction
Energy consumption = 153.165300 pJ
sum error= 322
Actual label: 8
Output voltages: [0.046168, 0.036783, 0.59283, 0.033256, 0.025064, 0.0011721, 0.027995, 0.0019196, 0.79879, 0.051589]
Predicted label: 8
Correct prediction
Energy consumption = 150.768814 pJ
sum error= 322
Actual label: 9
Output voltages: [0.12222, 0.00326, 0.043582, 0.017339, 0.036159, 0.0018872, 0.0038736, 0.023023, 0.75767, 0.77819]
Predicted label: 9
Correct prediction
Energy consumption = 155.508901 pJ
sum error= 322
Actual label: 7
Output voltages: [0.095375, 0.25005, 0.44089, 0.068048, 0.005272, 0.0011347, 0.001076, 0.79879, 0.069309, 0.069367]
Predicted label: 7
Correct prediction
Energy consumption = 154.137736 pJ
sum error= 322
Actual label: 6
Output voltages: [0.039696, 0.29727, 0.2501, 0.0054209, 0.18992, 0.086441, 0.79869, 0.0013881, 0.31095, 0.017525]
Predicted label: 6
Correct prediction
Energy consumption = 150.026478 pJ
sum error= 322
Actual label: 4
Output voltages: [0.0013069, 0.01259, 0.020185, 0.033847, 0.79878, 0.0014203, 0.21228, 0.27255, 0.043255, 0.0023843]
Predicted label: 4
Correct prediction
Energy consumption = 148.070530 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 776 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 776 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 776 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25039, 0.012786, 0.030656, 0.16564, 0.0057686, 0.003651, 0.0012086, 0.79873, 0.39166, 0.42185]
Predicted label: 7
Correct prediction
Energy consumption = 154.721167 pJ
sum error= 322
Actual label: 6
Output voltages: [0.081562, 0.09735, 0.26147, 0.0035482, 0.22726, 0.21718, 0.79872, 0.0015475, 0.43792, 0.0046116]
Predicted label: 6
Correct prediction
Energy consumption = 149.327114 pJ
sum error= 322
Actual label: 2
Output voltages: [0.29357, 0.026066, 0.79868, 0.030686, 0.0060181, 0.0011661, 0.043285, 0.057026, 0.65571, 0.012744]
Predicted label: 2
Correct prediction
Energy consumption = 140.257856 pJ
sum error= 322
Actual label: 3
Output voltages: [0.21514, 0.043603, 0.012488, 0.79859, 0.0033695, 0.012545, 0.019013, 0.030196, 0.32316, 0.10253]
Predicted label: 3
Correct prediction
Energy consumption = 145.360406 pJ
sum error= 322
Actual label: 4
Output voltages: [0.012438, 0.011194, 0.033112, 0.0205, 0.79864, 0.0013875, 0.062783, 0.10781, 0.054224, 0.00425]
Predicted label: 4
Correct prediction
Energy consumption = 149.550953 pJ
sum error= 322
Actual label: 8
Output voltages: [0.0071495, 0.040595, 0.10511, 0.18924, 0.015503, 0.017477, 0.019203, 0.011287, 0.79876, 0.3523]
Predicted label: 8
Correct prediction
Energy consumption = 152.229332 pJ
sum error= 322
Actual label: 7
Output voltages: [0.52545, 0.027649, 0.031607, 0.059657, 0.0015091, 0.0047354, 0.0011052, 0.7987, 0.31806, 0.053869]
Predicted label: 7
Correct prediction
Energy consumption = 147.546883 pJ
sum error= 322
Actual label: 8
Output voltages: [0.034318, 0.051406, 0.28904, 0.12507, 0.01763, 0.011916, 0.03377, 0.0046275, 0.79871, 0.041174]
Predicted label: 8
Correct prediction
Energy consumption = 145.215863 pJ
sum error= 322
Actual label: 6
Output voltages: [0.023209, 0.032443, 0.249, 0.013782, 0.032901, 0.52049, 0.79871, 0.0081547, 0.29051, 0.0032275]
Predicted label: 6
Correct prediction
Energy consumption = 152.042024 pJ
sum error= 322
Actual label: 9
Output voltages: [0.044928, 0.017841, 0.034927, 0.039555, 0.015462, 0.0089007, 0.0045169, 0.042847, 0.71901, 0.79257]
Predicted label: 9
Correct prediction
Energy consumption = 152.135370 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 777 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 777 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 777 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.26614, 0.023658, 0.19801, 0.33746, 0.006454, 0.0095673, 0.01801, 0.0019183, 0.79878, 0.10256]
Predicted label: 8
Correct prediction
Energy consumption = 152.530158 pJ
sum error= 322
Actual label: 3
Output voltages: [0.62051, 0.013219, 0.0205, 0.79869, 0.0079631, 0.041555, 0.0025317, 0.013531, 0.5592, 0.020668]
Predicted label: 3
Correct prediction
Energy consumption = 145.340989 pJ
sum error= 322
Actual label: 2
Output voltages: [0.52593, 0.0059056, 0.79879, 0.10178, 0.0032884, 0.0010666, 0.01604, 0.040006, 0.7043, 0.001661]
Predicted label: 2
Correct prediction
Energy consumption = 137.447640 pJ
sum error= 322
Actual label: 2
Output voltages: [0.60726, 0.048561, 0.79874, 0.065374, 0.016135, 0.0012272, 0.082255, 0.04543, 0.45357, 0.011736]
Predicted label: 2
Correct prediction
Energy consumption = 139.647655 pJ
sum error= 322
Actual label: 8
Output voltages: [0.007636, 0.020336, 0.024549, 0.01165, 0.091465, 0.013379, 0.26387, 0.024652, 0.79876, 0.045059]
Predicted label: 8
Correct prediction
Energy consumption = 143.299196 pJ
sum error= 322
Actual label: 4
Output voltages: [0.0077858, 0.017468, 0.028289, 0.014203, 0.79869, 0.0013041, 0.13572, 0.18726, 0.034431, 0.01955]
Predicted label: 4
Correct prediction
Energy consumption = 146.310238 pJ
sum error= 322
Actual label: 8
Output voltages: [0.021986, 0.011518, 0.040026, 0.17199, 0.0067378, 0.14792, 0.041568, 0.004365, 0.79864, 0.010201]
Predicted label: 8
Correct prediction
Energy consumption = 149.720019 pJ
sum error= 322
Actual label: 5
Output voltages: [0.051315, 0.0010928, 0.0025013, 0.2011, 0.017147, 0.79879, 0.21438, 0.015601, 0.76535, 0.036553]
Predicted label: 5
Correct prediction
Energy consumption = 142.446034 pJ
sum error= 322
Actual label: 6
Output voltages: [0.14722, 0.033453, 0.24356, 0.001284, 0.43939, 0.30351, 0.79876, 0.0019952, 0.1871, 0.010929]
Predicted label: 6
Correct prediction
Energy consumption = 141.580029 pJ
sum error= 322
Actual label: 5
Output voltages: [0.13539, 0.0011205, 0.036482, 0.26916, 0.015535, 0.78991, 0.47349, 0.002254, 0.77581, 0.0019089]
Predicted label: 5
Correct prediction
Energy consumption = 137.446292 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 778 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 778 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 778 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.073188, 0.024357, 0.01377, 0.011976, 0.023914, 0.64661, 0.031311, 0.058314, 0.017211]
Predicted label: 0
Correct prediction
Energy consumption = 151.275137 pJ
sum error= 322
Actual label: 2
Output voltages: [0.46243, 0.0028237, 0.79879, 0.5044, 0.0084011, 0.0012483, 0.0083088, 0.14149, 0.34379, 0.017324]
Predicted label: 2
Correct prediction
Energy consumption = 149.835103 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79879, 0.085338, 0.026014, 0.015176, 0.0043966, 0.014028, 0.59085, 0.051188, 0.17716, 0.022903]
Predicted label: 0
Correct prediction
Energy consumption = 141.448847 pJ
sum error= 322
Actual label: 1
Output voltages: [0.087174, 0.79879, 0.37806, 0.54322, 0.0047595, 0.0012239, 0.19965, 0.001066, 0.43788, 0.41145]
Predicted label: 1
Correct prediction
Energy consumption = 157.017667 pJ
sum error= 322
Actual label: 1
Output voltages: [0.089052, 0.79869, 0.19107, 0.031623, 0.16839, 0.0013045, 0.10305, 0.0043679, 0.29818, 0.052459]
Predicted label: 1
Correct prediction
Energy consumption = 148.582126 pJ
sum error= 322
Actual label: 2
Output voltages: [0.50999, 0.0049805, 0.79876, 0.16631, 0.014931, 0.0011846, 0.015499, 0.23522, 0.64126, 0.0055162]
Predicted label: 2
Correct prediction
Energy consumption = 146.360497 pJ
sum error= 322
Actual label: 9
Output voltages: [0.15503, 0.008715, 0.017818, 0.046491, 0.014733, 0.025884, 0.0049813, 0.41492, 0.60655, 0.79108]
Predicted label: 9
Correct prediction
Energy consumption = 153.174782 pJ
sum error= 322
Actual label: 6
Output voltages: [0.24202, 0.029272, 0.095674, 0.014339, 0.31541, 0.15034, 0.79879, 0.001066, 0.61408, 0.013483]
Predicted label: 6
Correct prediction
Energy consumption = 149.874233 pJ
sum error= 322
Actual label: 8
Output voltages: [0.30017, 0.024204, 0.69354, 0.10141, 0.067304, 0.0010911, 0.14723, 0.0011336, 0.7937, 0.10534]
Predicted label: 8
Correct prediction
Energy consumption = 152.215648 pJ
sum error= 322
Actual label: 2
Output voltages: [0.4886, 0.16216, 0.79876, 0.030845, 0.0059445, 0.0012763, 0.033435, 0.040585, 0.33366, 0.014269]
Predicted label: 2
Correct prediction
Energy consumption = 143.182920 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 779 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 779 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 779 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.014995, 0.79839, 0.21568, 0.75854, 0.024798, 0.0011353, 0.32004, 0.0018718, 0.70863, 0.14916]
Predicted label: 1
Correct prediction
Energy consumption = 160.936880 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79537, 0.018624, 0.045691, 0.0045974, 0.020533, 0.0059513, 0.72063, 0.029513, 0.025013, 0.31964]
Predicted label: 0
Correct prediction
Energy consumption = 142.670462 pJ
sum error= 322
Actual label: 6
Output voltages: [0.16856, 0.041916, 0.32207, 0.0017079, 0.40372, 0.21525, 0.79869, 0.0018419, 0.40469, 0.024735]
Predicted label: 6
Correct prediction
Energy consumption = 139.087942 pJ
sum error= 322
Actual label: 5
Output voltages: [0.034547, 0.0010741, 0.0033964, 0.24997, 0.017701, 0.79865, 0.14162, 0.01115, 0.79202, 0.0088318]
Predicted label: 5
Correct prediction
Energy consumption = 143.512273 pJ
sum error= 322
Actual label: 2
Output voltages: [0.47955, 0.0059163, 0.79879, 0.043122, 0.016497, 0.001076, 0.048741, 0.029285, 0.73015, 0.03705]
Predicted label: 2
Correct prediction
Energy consumption = 144.492043 pJ
sum error= 322
Actual label: 9
Output voltages: [0.51877, 0.027831, 0.020777, 0.19145, 0.26774, 0.085081, 0.013631, 0.035872, 0.232, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 155.507413 pJ
sum error= 322
Actual label: 7
Output voltages: [0.060979, 0.14591, 0.091949, 0.036547, 0.012855, 0.0067972, 0.0010851, 0.79865, 0.11941, 0.51901]
Predicted label: 7
Correct prediction
Energy consumption = 148.075993 pJ
sum error= 322
Actual label: 5
Output voltages: [0.009505, 0.0011762, 0.0068389, 0.04256, 0.02824, 0.79818, 0.622, 0.01597, 0.75915, 0.0064023]
Predicted label: 5
Correct prediction
Energy consumption = 144.102310 pJ
sum error= 322
Actual label: 3
Output voltages: [0.48102, 0.0025654, 0.32475, 0.79879, 0.025773, 0.051342, 0.0042523, 0.0064544, 0.60018, 0.041715]
Predicted label: 3
Correct prediction
Energy consumption = 140.081429 pJ
sum error= 322
Actual label: 9
Output voltages: [0.089702, 0.020042, 0.01439, 0.044684, 0.037798, 0.0047951, 0.0016266, 0.017299, 0.71011, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 145.746051 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 780 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 780 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 780 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.78589, 0.001578, 0.4576, 0.79877, 0.024744, 0.086982, 0.017717, 0.011404, 0.45615, 0.016706]
Predicted label: 3
Correct prediction
Energy consumption = 147.666925 pJ
sum error= 322
Actual label: 7
Output voltages: [0.12824, 0.019147, 0.040764, 0.082931, 0.0083869, 0.023769, 0.0011361, 0.79849, 0.067125, 0.21445]
Predicted label: 7
Correct prediction
Energy consumption = 153.222185 pJ
sum error= 322
Actual label: 1
Output voltages: [0.026607, 0.79877, 0.037296, 0.038687, 0.32979, 0.0011269, 0.14443, 0.0010661, 0.34996, 0.3859]
Predicted label: 1
Correct prediction
Energy consumption = 159.206652 pJ
sum error= 322
Actual label: 8
Output voltages: [0.04642, 0.043102, 0.1225, 0.20106, 0.0061805, 0.03792, 0.013105, 0.0016521, 0.79865, 0.13784]
Predicted label: 8
Correct prediction
Energy consumption = 146.792782 pJ
sum error= 322
Actual label: 3
Output voltages: [0.73068, 0.0043596, 0.11533, 0.79878, 0.016957, 0.014487, 0.0069855, 0.0058608, 0.62178, 0.047459]
Predicted label: 3
Correct prediction
Energy consumption = 145.424115 pJ
sum error= 322
Actual label: 8
Output voltages: [0.0302, 0.03496, 0.22652, 0.024546, 0.023463, 0.021726, 0.1986, 0.011535, 0.79869, 0.047473]
Predicted label: 8
Correct prediction
Energy consumption = 140.986539 pJ
sum error= 322
Actual label: 1
Output voltages: [0.029972, 0.79876, 0.0079157, 0.016661, 0.049848, 0.0010668, 0.26043, 0.0017632, 0.52445, 0.28123]
Predicted label: 1
Correct prediction
Energy consumption = 153.727366 pJ
sum error= 322
Actual label: 9
Output voltages: [0.42946, 0.021493, 0.060181, 0.069778, 0.013896, 0.0029601, 0.0044721, 0.04899, 0.73592, 0.79794]
Predicted label: 9
Correct prediction
Energy consumption = 152.420953 pJ
sum error= 322
Actual label: 5
Output voltages: [0.0060116, 0.0011091, 0.0021337, 0.23209, 0.024009, 0.79751, 0.29479, 0.0049979, 0.7066, 0.037415]
Predicted label: 5
Correct prediction
Energy consumption = 137.988941 pJ
sum error= 322
Actual label: 5
Output voltages: [0.026215, 0.0011543, 0.0096547, 0.060105, 0.014445, 0.79425, 0.27531, 0.01036, 0.79163, 0.019331]
Predicted label: 5
Correct prediction
Energy consumption = 131.083802 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 781 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 781 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 781 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.0338, 0.031016, 0.014281, 0.033202, 0.0069842, 0.71172, 0.012984, 0.065437, 0.059061]
Predicted label: 0
Correct prediction
Energy consumption = 152.450433 pJ
sum error= 322
Actual label: 1
Output voltages: [0.0075485, 0.79875, 0.0050993, 0.20244, 0.15031, 0.0010729, 0.25304, 0.0011878, 0.73715, 0.25018]
Predicted label: 1
Correct prediction
Energy consumption = 158.961695 pJ
sum error= 322
Actual label: 1
Output voltages: [0.043981, 0.79775, 0.015044, 0.21254, 0.015914, 0.0029295, 0.053401, 0.0033481, 0.78473, 0.046863]
Predicted label: 1
Correct prediction
Energy consumption = 150.025437 pJ
sum error= 322
Actual label: 9
Output voltages: [0.20532, 0.0023023, 0.030396, 0.015431, 0.041798, 0.0073499, 0.002289, 0.038652, 0.75622, 0.79821]
Predicted label: 9
Correct prediction
Energy consumption = 146.374494 pJ
sum error= 322
Actual label: 8
Output voltages: [0.055439, 0.04299, 0.14572, 0.041446, 0.0077362, 0.037031, 0.0043141, 0.0011079, 0.79878, 0.32289]
Predicted label: 8
Correct prediction
Energy consumption = 142.336969 pJ
sum error= 322
Actual label: 2
Output voltages: [0.40923, 0.0028543, 0.79879, 0.061137, 0.017423, 0.0010982, 0.10887, 0.18995, 0.69112, 0.0024799]
Predicted label: 2
Correct prediction
Energy consumption = 148.650506 pJ
sum error= 322
Actual label: 6
Output voltages: [0.028145, 0.051767, 0.23175, 0.0025885, 0.14193, 0.25455, 0.79877, 0.0017478, 0.69457, 0.0019784]
Predicted label: 6
Correct prediction
Energy consumption = 145.903641 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79865, 0.027465, 0.15141, 0.016375, 0.01128, 0.032152, 0.27927, 0.046161, 0.10384, 0.018178]
Predicted label: 0
Correct prediction
Energy consumption = 140.603928 pJ
sum error= 322
Actual label: 4
Output voltages: [0.002466, 0.0081179, 0.027579, 0.0018566, 0.79869, 0.014459, 0.44947, 0.43378, 0.22465, 0.016844]
Predicted label: 4
Correct prediction
Energy consumption = 147.693249 pJ
sum error= 322
Actual label: 5
Output voltages: [0.13648, 0.0010664, 0.0037372, 0.16311, 0.0022862, 0.79869, 0.15904, 0.00237, 0.77708, 0.0011307]
Predicted label: 5
Correct prediction
Energy consumption = 143.689156 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 782 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 782 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 782 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.010026, 0.10453, 0.0080018, 0.025333, 0.0059431, 0.64634, 0.048125, 0.035337, 0.24354]
Predicted label: 0
Correct prediction
Energy consumption = 145.512345 pJ
sum error= 322
Actual label: 3
Output voltages: [0.49763, 0.0043588, 0.67421, 0.79872, 0.024805, 0.032804, 0.012811, 0.0020355, 0.77034, 0.023068]
Predicted label: 3
Correct prediction
Energy consumption = 141.157025 pJ
sum error= 322
Actual label: 1
Output voltages: [0.15391, 0.79877, 0.013976, 0.029674, 0.10253, 0.0016584, 0.42909, 0.0011692, 0.3395, 0.12056]
Predicted label: 1
Correct prediction
Energy consumption = 154.763494 pJ
sum error= 322
Actual label: 8
Output voltages: [0.049583, 0.0017656, 0.1885, 0.41436, 0.017042, 0.022962, 0.069785, 0.015542, 0.79878, 0.2741]
Predicted label: 8
Correct prediction
Energy consumption = 148.466162 pJ
sum error= 322
Actual label: 6
Output voltages: [0.095889, 0.014199, 0.24367, 0.019822, 0.30085, 0.52341, 0.79878, 0.0011279, 0.6667, 0.10577]
Predicted label: 6
Correct prediction
Energy consumption = 139.857634 pJ
sum error= 322
Actual label: 7
Output voltages: [0.58989, 0.038429, 0.42914, 0.099872, 0.01008, 0.0012459, 0.0018319, 0.79863, 0.58791, 0.022263]
Predicted label: 7
Correct prediction
Energy consumption = 155.875493 pJ
sum error= 322
Actual label: 5
Output voltages: [0.052785, 0.0011885, 0.0030214, 0.35612, 0.029338, 0.79878, 0.23689, 0.052592, 0.7771, 0.0013677]
Predicted label: 5
Correct prediction
Energy consumption = 135.241499 pJ
sum error= 322
Actual label: 9
Output voltages: [0.20905, 0.020488, 0.028539, 0.033172, 0.085057, 0.014446, 0.006282, 0.02621, 0.56717, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 149.997687 pJ
sum error= 322
Actual label: 9
Output voltages: [0.2358, 0.023547, 0.032676, 0.034959, 0.0502, 0.029931, 0.0039302, 0.010488, 0.30847, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 140.584392 pJ
sum error= 322
Actual label: 3
Output voltages: [0.38285, 0.013567, 0.10102, 0.79866, 0.036472, 0.0039972, 0.012306, 0.012791, 0.47433, 0.1012]
Predicted label: 3
Correct prediction
Energy consumption = 143.132648 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 783 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 783 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 783 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.034123, 0.014775, 0.0079893, 0.0034639, 0.002254, 0.68476, 0.024149, 0.31711, 0.0455]
Predicted label: 0
Correct prediction
Energy consumption = 146.261501 pJ
sum error= 322
Actual label: 3
Output voltages: [0.64141, 0.0015517, 0.2929, 0.79879, 0.0065234, 0.0045589, 0.0082838, 0.013278, 0.44068, 0.044]
Predicted label: 3
Correct prediction
Energy consumption = 149.090968 pJ
sum error= 322
Actual label: 1
Output voltages: [0.021721, 0.79874, 0.38764, 0.014051, 0.17647, 0.0010793, 0.24384, 0.0047239, 0.042578, 0.020891]
Predicted label: 1
Correct prediction
Energy consumption = 152.702227 pJ
sum error= 322
Actual label: 4
Output voltages: [0.010181, 0.016272, 0.0082601, 0.029362, 0.79877, 0.0010674, 0.033521, 0.16553, 0.10962, 0.0038201]
Predicted label: 4
Correct prediction
Energy consumption = 150.176978 pJ
sum error= 322
Actual label: 4
Output voltages: [0.0018121, 0.0070589, 0.032405, 0.022776, 0.79869, 0.0014253, 0.074713, 0.21721, 0.10689, 0.003325]
Predicted label: 4
Correct prediction
Energy consumption = 134.380258 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79879, 0.044702, 0.014328, 0.011225, 0.013798, 0.011243, 0.5467, 0.025017, 0.23986, 0.036756]
Predicted label: 0
Correct prediction
Energy consumption = 148.064437 pJ
sum error= 322
Actual label: 4
Output voltages: [0.012069, 0.013295, 0.025361, 0.002668, 0.79878, 0.0011833, 0.28756, 0.242, 0.037888, 0.003365]
Predicted label: 4
Correct prediction
Energy consumption = 151.749372 pJ
sum error= 322
Actual label: 9
Output voltages: [0.1935, 0.018098, 0.057338, 0.0085175, 0.043465, 0.017798, 0.0011269, 0.029036, 0.73872, 0.78259]
Predicted label: 9
Correct prediction
Energy consumption = 153.939307 pJ
sum error= 322
Actual label: 0
Output voltages: [0.79878, 0.051364, 0.023408, 0.01444, 0.015821, 0.0024357, 0.71858, 0.023393, 0.15019, 0.12526]
Predicted label: 0
Correct prediction
Energy consumption = 148.252272 pJ
sum error= 322
Actual label: 1
Output voltages: [0.29083, 0.79566, 0.02198, 0.26164, 0.18995, 0.0010748, 0.40434, 0.0011228, 0.55235, 0.0728]
Predicted label: 1
Correct prediction
Energy consumption = 155.747303 pJ
sum error= 322
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 784 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 784 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 784 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.35702, 0.020511, 0.79867, 0.026012, 0.017387, 0.0010747, 0.038884, 0.14187, 0.38214, 0.011377]
Predicted label: 2
Correct prediction
Energy consumption = 145.564033 pJ
sum error= 322
Actual label: 3
Output voltages: [0.089321, 0.017544, 0.03903, 0.79874, 0.037399, 0.045462, 0.010119, 0.01242, 0.76064, 0.1407]
Predicted label: 3
Correct prediction
Energy consumption = 151.418556 pJ
sum error= 322
Actual label: 5
Output voltages: [0.42777, 0.0014924, 0.014886, 0.41489, 0.017717, 0.35938, 0.44864, 0.0032191, 0.78735, 0.0011343]
Predicted label: 8
Wrong prediction!
Energy consumption = 141.708615 pJ
sum error= 323
Actual label: 6
Output voltages: [0.1207, 0.032763, 0.074363, 0.0021907, 0.26054, 0.1858, 0.79877, 0.0016525, 0.50911, 0.0040101]
Predicted label: 6
Correct prediction
Energy consumption = 142.978729 pJ
sum error= 323
Actual label: 7
Output voltages: [0.30596, 0.14615, 0.0059279, 0.0030483, 0.0031874, 0.0089756, 0.0033827, 0.79875, 0.52697, 0.012887]
Predicted label: 7
Correct prediction
Energy consumption = 150.896677 pJ
sum error= 323
Actual label: 8
Output voltages: [0.21664, 0.0072483, 0.26884, 0.038383, 0.010548, 0.016656, 0.10047, 0.0021478, 0.79879, 0.025865]
Predicted label: 8
Correct prediction
Energy consumption = 147.508721 pJ
sum error= 323
Actual label: 0
Output voltages: [0.79762, 0.04186, 0.4138, 0.005256, 0.0026979, 0.0014639, 0.18909, 0.0030482, 0.54097, 0.031423]
Predicted label: 0
Correct prediction
Energy consumption = 135.535418 pJ
sum error= 323
Actual label: 1
Output voltages: [0.10627, 0.64386, 0.046634, 0.24767, 0.75913, 0.0052627, 0.24022, 0.0010861, 0.31039, 0.0065612]
Predicted label: 4
Wrong prediction!
Energy consumption = 149.358487 pJ
sum error= 324
Actual label: 2
Output voltages: [0.055606, 0.0017127, 0.79872, 0.05069, 0.12798, 0.0011008, 0.029418, 0.028329, 0.60425, 0.02788]
Predicted label: 2
Correct prediction
Energy consumption = 136.339799 pJ
sum error= 324
Actual label: 3
Output voltages: [0.28316, 0.001066, 0.74206, 0.72406, 0.25506, 0.013438, 0.09209, 0.0011026, 0.35535, 0.055952]
Predicted label: 2
Wrong prediction!
Energy consumption = 137.184222 pJ
sum error= 325
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 785 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 785 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 785 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.49209, 0.0011275, 0.008843, 0.22278, 0.0049006, 0.79706, 0.43413, 0.004355, 0.76586, 0.0011535]
Predicted label: 5
Correct prediction
Energy consumption = 144.209909 pJ
sum error= 325
Actual label: 6
Output voltages: [0.065687, 0.042391, 0.57073, 0.0016716, 0.24318, 0.019737, 0.79876, 0.0011118, 0.55544, 0.025895]
Predicted label: 6
Correct prediction
Energy consumption = 142.027239 pJ
sum error= 325
Actual label: 7
Output voltages: [0.28704, 0.12653, 0.040292, 0.073663, 0.0017485, 0.0010945, 0.0010663, 0.79868, 0.22881, 0.043568]
Predicted label: 7
Correct prediction
Energy consumption = 155.266648 pJ
sum error= 325
Actual label: 8
Output voltages: [0.64892, 0.039327, 0.57599, 0.02146, 0.012512, 0.0011399, 0.53307, 0.0034831, 0.78671, 0.011963]
Predicted label: 8
Correct prediction
Energy consumption = 148.594570 pJ
sum error= 325
Actual label: 9
Output voltages: [0.71676, 0.021107, 0.014707, 0.28007, 0.071662, 0.0036555, 0.0041988, 0.01453, 0.055728, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 148.487063 pJ
sum error= 325
Actual label: 0
Output voltages: [0.79872, 0.27614, 0.039669, 0.022007, 0.0064752, 0.0067342, 0.19399, 0.011172, 0.11237, 0.14572]
Predicted label: 0
Correct prediction
Energy consumption = 142.550474 pJ
sum error= 325
Actual label: 1
Output voltages: [0.02197, 0.7844, 0.07277, 0.0017392, 0.7342, 0.0017758, 0.20641, 0.0030829, 0.29976, 0.2139]
Predicted label: 1
Correct prediction
Energy consumption = 148.947635 pJ
sum error= 325
Actual label: 2
Output voltages: [0.029015, 0.013786, 0.79879, 0.17154, 0.017703, 0.0011301, 0.061531, 0.013964, 0.77157, 0.038693]
Predicted label: 2
Correct prediction
Energy consumption = 135.068721 pJ
sum error= 325
Actual label: 3
Output voltages: [0.5456, 0.0014089, 0.61024, 0.79878, 0.024748, 0.032495, 0.013761, 0.0012868, 0.63111, 0.027275]
Predicted label: 3
Correct prediction
Energy consumption = 143.662958 pJ
sum error= 325
Actual label: 5
Output voltages: [0.1061, 0.0016156, 0.001324, 0.36702, 0.014649, 0.79879, 0.26395, 0.0044289, 0.75852, 0.0033308]
Predicted label: 5
Correct prediction
Energy consumption = 132.079350 pJ
sum error= 325
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 786 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 786 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 786 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.1334, 0.0051258, 0.058242, 0.0016784, 0.24738, 0.046778, 0.79827, 0.001066, 0.56802, 0.0023863]
Predicted label: 6
Correct prediction
Energy consumption = 146.491594 pJ
sum error= 325
Actual label: 7
Output voltages: [0.35418, 0.051569, 0.01642, 0.027193, 0.025885, 0.0016301, 0.001161, 0.79875, 0.13602, 0.036108]
Predicted label: 7
Correct prediction
Energy consumption = 152.090655 pJ
sum error= 325
Actual label: 8
Output voltages: [0.22176, 0.06631, 0.30738, 0.16921, 0.0030712, 0.011826, 0.46181, 0.0020701, 0.79875, 0.043174]
Predicted label: 8
Correct prediction
Energy consumption = 147.543363 pJ
sum error= 325
Actual label: 9
Output voltages: [0.15472, 0.012947, 0.013339, 0.012719, 0.20777, 0.0051584, 0.0012037, 0.017144, 0.49881, 0.79775]
Predicted label: 9
Correct prediction
Energy consumption = 144.189122 pJ
sum error= 325
Actual label: 9
Output voltages: [0.25763, 0.004774, 0.012206, 0.051331, 0.33956, 0.048231, 0.056297, 0.054245, 0.098201, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 150.103335 pJ
sum error= 325
Actual label: 7
Output voltages: [0.24278, 0.029695, 0.066256, 0.035246, 0.0044245, 0.0068917, 0.0012048, 0.79872, 0.66993, 0.37495]
Predicted label: 7
Correct prediction
Energy consumption = 152.529033 pJ
sum error= 325
Actual label: 0
Output voltages: [0.79876, 0.029768, 0.053278, 0.0084431, 0.025484, 0.0028348, 0.65706, 0.0428, 0.10399, 0.26657]
Predicted label: 0
Correct prediction
Energy consumption = 141.887929 pJ
sum error= 325
Actual label: 9
Output voltages: [0.28986, 0.0032327, 0.031505, 0.18271, 0.45061, 0.017792, 0.010089, 0.052004, 0.55657, 0.79714]
Predicted label: 9
Correct prediction
Energy consumption = 147.700395 pJ
sum error= 325
Actual label: 0
Output voltages: [0.79877, 0.021588, 0.028877, 0.017791, 0.032046, 0.013422, 0.19623, 0.089376, 0.45141, 0.026443]
Predicted label: 0
Correct prediction
Energy consumption = 145.218986 pJ
sum error= 325
Actual label: 1
Output voltages: [0.024251, 0.7901, 0.0022846, 0.014829, 0.5047, 0.0014647, 0.064287, 0.001088, 0.56474, 0.1705]
Predicted label: 1
Correct prediction
Energy consumption = 149.395954 pJ
sum error= 325
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 787 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 787 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 787 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.033103, 0.0011157, 0.0010811, 0.26003, 0.064912, 0.7985, 0.16097, 0.037261, 0.385, 0.018108]
Predicted label: 5
Correct prediction
Energy consumption = 138.462715 pJ
sum error= 325
Actual label: 8
Output voltages: [0.044347, 0.0069175, 0.31066, 0.071028, 0.010298, 0.038026, 0.044182, 0.014756, 0.7987, 0.042122]
Predicted label: 8
Correct prediction
Energy consumption = 144.806752 pJ
sum error= 325
Actual label: 8
Output voltages: [0.26809, 0.047385, 0.037106, 0.15589, 0.0045009, 0.043718, 0.047341, 0.0013549, 0.79879, 0.047952]
Predicted label: 8
Correct prediction
Energy consumption = 144.942552 pJ
sum error= 325
Actual label: 0
Output voltages: [0.79879, 0.20447, 0.043342, 0.018806, 0.006023, 0.010017, 0.50274, 0.03052, 0.23046, 0.043231]
Predicted label: 0
Correct prediction
Energy consumption = 140.781494 pJ
sum error= 325
Actual label: 9
Output voltages: [0.65611, 0.021833, 0.017077, 0.031139, 0.048786, 0.024845, 0.050602, 0.01142, 0.48824, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 140.529941 pJ
sum error= 325
Actual label: 3
Output voltages: [0.25597, 0.014379, 0.069943, 0.79879, 0.029803, 0.023984, 0.0042398, 0.0010894, 0.39494, 0.19107]
Predicted label: 3
Correct prediction
Energy consumption = 135.884189 pJ
sum error= 325
Actual label: 2
Output voltages: [0.19046, 0.0033561, 0.79876, 0.034771, 0.53396, 0.0010719, 0.039639, 0.0018734, 0.58473, 0.23483]
Predicted label: 2
Correct prediction
Energy consumption = 133.337650 pJ
sum error= 325
Actual label: 7
Output voltages: [0.16655, 0.03417, 0.56618, 0.0031782, 0.10707, 0.0010923, 0.0011595, 0.79879, 0.46437, 0.0537]
Predicted label: 7
Correct prediction
Energy consumption = 153.767819 pJ
sum error= 325
Actual label: 8
Output voltages: [0.15095, 0.025846, 0.64792, 0.11394, 0.010117, 0.024455, 0.030248, 0.014321, 0.79874, 0.043744]
Predicted label: 8
Correct prediction
Energy consumption = 140.084782 pJ
sum error= 325
Actual label: 4
Output voltages: [0.013404, 0.14109, 0.03326, 0.0064923, 0.79876, 0.014902, 0.054344, 0.52345, 0.036683, 0.010538]
Predicted label: 4
Correct prediction
Energy consumption = 146.352148 pJ
sum error= 325
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 788 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 788 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 788 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.020185, 0.017274, 0.49365, 0.0010679, 0.39565, 0.04178, 0.79879, 0.0013809, 0.44642, 0.0025384]
Predicted label: 6
Correct prediction
Energy consumption = 146.817468 pJ
sum error= 325
Actual label: 1
Output voltages: [0.026436, 0.79868, 0.15928, 0.0060347, 0.098375, 0.0012518, 0.17664, 0.0012779, 0.058295, 0.035533]
Predicted label: 1
Correct prediction
Energy consumption = 148.833216 pJ
sum error= 325
Actual label: 0
Output voltages: [0.79876, 0.058436, 0.045353, 0.015359, 0.017719, 0.0082447, 0.47807, 0.009053, 0.070496, 0.22552]
Predicted label: 0
Correct prediction
Energy consumption = 143.715498 pJ
sum error= 325
Actual label: 4
Output voltages: [0.0051457, 0.0051433, 0.54684, 0.029953, 0.79865, 0.0021587, 0.46833, 0.13497, 0.012273, 0.019857]
Predicted label: 4
Correct prediction
Energy consumption = 149.893630 pJ
sum error= 325
Actual label: 9
Output voltages: [0.083381, 0.0050758, 0.042217, 0.02326, 0.21823, 0.0097881, 0.0042893, 0.04544, 0.56864, 0.79842]
Predicted label: 9
Correct prediction
Energy consumption = 146.463042 pJ
sum error= 325
Actual label: 4
Output voltages: [0.039959, 0.0021471, 0.43895, 0.0032672, 0.79875, 0.0010751, 0.6997, 0.32679, 0.035791, 0.016631]
Predicted label: 4
Correct prediction
Energy consumption = 141.898776 pJ
sum error= 325
Actual label: 2
Output voltages: [0.042134, 0.0016785, 0.79879, 0.020076, 0.62422, 0.0010931, 0.049791, 0.0046077, 0.50046, 0.1861]
Predicted label: 2
Correct prediction
Energy consumption = 135.675545 pJ
sum error= 325
Actual label: 0
Output voltages: [0.79879, 0.11214, 0.049539, 0.011919, 0.020531, 0.0025553, 0.53674, 0.011223, 0.07336, 0.16921]
Predicted label: 0
Correct prediction
Energy consumption = 143.533487 pJ
sum error= 325
Actual label: 5
Output voltages: [0.0059271, 0.0011216, 0.0010664, 0.070134, 0.39323, 0.79694, 0.46923, 0.0021579, 0.42275, 0.041604]
Predicted label: 5
Correct prediction
Energy consumption = 130.502139 pJ
sum error= 325
Actual label: 0
Output voltages: [0.79878, 0.072708, 0.025473, 0.018914, 0.032105, 0.018299, 0.47213, 0.031572, 0.12045, 0.051565]
Predicted label: 0
Correct prediction
Energy consumption = 139.980840 pJ
sum error= 325
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 789 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 789 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 789 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.039489, 0.79873, 0.15462, 0.012118, 0.053571, 0.001088, 0.21578, 0.0015991, 0.23403, 0.028114]
Predicted label: 1
Correct prediction
Energy consumption = 158.494400 pJ
sum error= 325
Actual label: 6
Output voltages: [0.047158, 0.046282, 0.19179, 0.0040159, 0.14072, 0.05374, 0.79879, 0.0010817, 0.62246, 0.0031995]
Predicted label: 6
Correct prediction
Energy consumption = 143.168732 pJ
sum error= 325
Actual label: 9
Output voltages: [0.19935, 0.0045273, 0.018335, 0.0090037, 0.1057, 0.0057918, 0.0030529, 0.016282, 0.68507, 0.79753]
Predicted label: 9
Correct prediction
Energy consumption = 150.761141 pJ
sum error= 325
Actual label: 3
Output voltages: [0.71536, 0.0011101, 0.52091, 0.79504, 0.049539, 0.0043555, 0.0020732, 0.039618, 0.67014, 0.01522]
Predicted label: 3
Correct prediction
Energy consumption = 153.002782 pJ
sum error= 325
Actual label: 2
Output voltages: [0.61258, 0.0011029, 0.79703, 0.15381, 0.089531, 0.0010662, 0.018264, 0.033401, 0.77598, 0.022065]
Predicted label: 2
Correct prediction
Energy consumption = 130.276575 pJ
sum error= 325
Actual label: 9
Output voltages: [0.40864, 0.0060505, 0.032959, 0.073688, 0.34067, 0.0029473, 0.013146, 0.0028112, 0.37133, 0.79773]
Predicted label: 9
Correct prediction
Energy consumption = 154.365434 pJ
sum error= 325
Actual label: 1
Output voltages: [0.053896, 0.79858, 0.011009, 0.058595, 0.47923, 0.0010816, 0.22085, 0.0011121, 0.27016, 0.16928]
Predicted label: 1
Correct prediction
Energy consumption = 157.060083 pJ
sum error= 325
Actual label: 6
Output voltages: [0.32468, 0.048686, 0.2205, 0.0021051, 0.26718, 0.048306, 0.79877, 0.0010825, 0.44656, 0.025232]
Predicted label: 6
Correct prediction
Energy consumption = 151.856232 pJ
sum error= 325
Actual label: 0
Output voltages: [0.79635, 0.031818, 0.016819, 0.0059273, 0.0023962, 0.068622, 0.76779, 0.0029957, 0.074587, 0.099136]
Predicted label: 0
Correct prediction
Energy consumption = 139.870356 pJ
sum error= 325
Actual label: 1
Output voltages: [0.070423, 0.79615, 0.0019762, 0.27643, 0.2463, 0.0014301, 0.29103, 0.0020972, 0.74962, 0.055842]
Predicted label: 1
Correct prediction
Energy consumption = 154.220832 pJ
sum error= 325
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 790 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 790 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 790 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.030255, 0.79878, 0.19788, 0.010686, 0.13011, 0.0011194, 0.72933, 0.0015445, 0.092107, 0.027233]
Predicted label: 1
Correct prediction
Energy consumption = 152.230738 pJ
sum error= 325
Actual label: 8
Output voltages: [0.17016, 0.023832, 0.088611, 0.032287, 0.057711, 0.015906, 0.56145, 0.0011375, 0.79877, 0.047586]
Predicted label: 8
Correct prediction
Energy consumption = 144.176315 pJ
sum error= 325
Actual label: 7
Output voltages: [0.078506, 0.0060381, 0.023741, 0.05745, 0.010353, 0.0059788, 0.0011078, 0.77536, 0.78552, 0.59165]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.838315 pJ
sum error= 326
Actual label: 7
Output voltages: [0.20788, 0.1635, 0.58781, 0.047677, 0.0061026, 0.0011048, 0.0016366, 0.79874, 0.60363, 0.0054907]
Predicted label: 7
Correct prediction
Energy consumption = 136.194319 pJ
sum error= 326
Actual label: 6
Output voltages: [0.42412, 0.017903, 0.12359, 0.0014033, 0.48604, 0.022588, 0.79879, 0.0010922, 0.6432, 0.018275]
Predicted label: 6
Correct prediction
Energy consumption = 141.455991 pJ
sum error= 326
Actual label: 3
Output voltages: [0.3024, 0.0065105, 0.47181, 0.79775, 0.0062363, 0.016917, 0.018349, 0.0010661, 0.45448, 0.33936]
Predicted label: 3
Correct prediction
Energy consumption = 146.297361 pJ
sum error= 326
Actual label: 6
Output voltages: [0.11246, 0.012966, 0.19347, 0.001075, 0.57743, 0.050363, 0.79879, 0.0010866, 0.1572, 0.0027365]
Predicted label: 6
Correct prediction
Energy consumption = 143.425449 pJ
sum error= 326
Actual label: 0
Output voltages: [0.79875, 0.038026, 0.0079816, 0.023842, 0.03412, 0.006563, 0.32944, 0.026011, 0.2758, 0.043536]
Predicted label: 0
Correct prediction
Energy consumption = 140.682747 pJ
sum error= 326
Actual label: 7
Output voltages: [0.23306, 0.031907, 0.15033, 0.0023142, 0.031993, 0.0040499, 0.0010887, 0.79852, 0.5292, 0.14945]
Predicted label: 7
Correct prediction
Energy consumption = 151.018079 pJ
sum error= 326
Actual label: 2
Output voltages: [0.14357, 0.12067, 0.79879, 0.049516, 0.23738, 0.0011842, 0.060326, 0.42688, 0.11304, 0.026122]
Predicted label: 2
Correct prediction
Energy consumption = 142.571966 pJ
sum error= 326
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 791 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 791 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 791 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.087099, 0.0041124, 0.23781, 0.0030145, 0.79868, 0.0012224, 0.17413, 0.018539, 0.020519, 0.02097]
Predicted label: 4
Correct prediction
Energy consumption = 149.698404 pJ
sum error= 326
Actual label: 1
Output voltages: [0.024467, 0.79868, 0.024845, 0.013414, 0.33911, 0.0010659, 0.43858, 0.0023411, 0.059311, 0.077002]
Predicted label: 1
Correct prediction
Energy consumption = 147.814763 pJ
sum error= 326
Actual label: 7
Output voltages: [0.11663, 0.018948, 0.061974, 0.03961, 0.035591, 0.0015206, 0.0012354, 0.79877, 0.74715, 0.075374]
Predicted label: 7
Correct prediction
Energy consumption = 153.612715 pJ
sum error= 326
Actual label: 0
Output voltages: [0.79879, 0.088976, 0.059276, 0.025543, 0.032367, 0.0019379, 0.62816, 0.010555, 0.18278, 0.20688]
Predicted label: 0
Correct prediction
Energy consumption = 148.551832 pJ
sum error= 326
Actual label: 6
Output voltages: [0.11765, 0.04137, 0.52767, 0.00114, 0.19157, 0.1019, 0.79879, 0.0017334, 0.62802, 0.011411]
Predicted label: 6
Correct prediction
Energy consumption = 140.152062 pJ
sum error= 326
Actual label: 7
Output voltages: [0.035906, 0.31365, 0.006418, 0.0017513, 0.021896, 0.0023877, 0.0011692, 0.66001, 0.79805, 0.1856]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.506313 pJ
sum error= 327
Actual label: 1
Output voltages: [0.011812, 0.79875, 0.10299, 0.37259, 0.55307, 0.0015712, 0.18465, 0.0033562, 0.47328, 0.064875]
Predicted label: 1
Correct prediction
Energy consumption = 143.481010 pJ
sum error= 327
Actual label: 2
Output voltages: [0.1656, 0.0060002, 0.79879, 0.043823, 0.38601, 0.0011173, 0.039345, 0.0017108, 0.50401, 0.3175]
Predicted label: 2
Correct prediction
Energy consumption = 140.394750 pJ
sum error= 327
Actual label: 5
Output voltages: [0.35982, 0.029329, 0.0026817, 0.11883, 0.037535, 0.79239, 0.77034, 0.0010697, 0.42806, 0.0019044]
Predicted label: 5
Correct prediction
Energy consumption = 133.658921 pJ
sum error= 327
Actual label: 8
Output voltages: [0.39497, 0.0060275, 0.58698, 0.031826, 0.047881, 0.010433, 0.01184, 0.0060287, 0.79879, 0.039918]
Predicted label: 8
Correct prediction
Energy consumption = 139.868643 pJ
sum error= 327
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 792 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 792 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 792 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.033829, 0.79852, 0.17417, 0.11828, 0.28419, 0.0011099, 0.37323, 0.0010858, 0.54607, 0.39625]
Predicted label: 1
Correct prediction
Energy consumption = 153.685409 pJ
sum error= 327
Actual label: 8
Output voltages: [0.13153, 0.0012057, 0.35472, 0.53225, 0.00345, 0.23107, 0.02171, 0.0089026, 0.79877, 0.017894]
Predicted label: 8
Correct prediction
Energy consumption = 135.786886 pJ
sum error= 327
Actual label: 2
Output voltages: [0.36599, 0.013997, 0.79875, 0.077874, 0.21303, 0.00107, 0.07977, 0.089099, 0.17144, 0.012678]
Predicted label: 2
Correct prediction
Energy consumption = 135.569074 pJ
sum error= 327
Actual label: 8
Output voltages: [0.15428, 0.017712, 0.45591, 0.022315, 0.049386, 0.0079549, 0.033771, 0.0022005, 0.79872, 0.045451]
Predicted label: 8
Correct prediction
Energy consumption = 142.618281 pJ
sum error= 327
Actual label: 7
Output voltages: [0.21072, 0.051703, 0.0097099, 0.17574, 0.0051865, 0.0067612, 0.0011104, 0.79696, 0.64065, 0.10686]
Predicted label: 7
Correct prediction
Energy consumption = 147.045016 pJ
sum error= 327
Actual label: 6
Output voltages: [0.074236, 0.019249, 0.3153, 0.001093, 0.40654, 0.040943, 0.79878, 0.001272, 0.46031, 0.0014658]
Predicted label: 6
Correct prediction
Energy consumption = 141.247838 pJ
sum error= 327
Actual label: 8
Output voltages: [0.3579, 0.0094131, 0.69933, 0.032439, 0.019963, 0.0021315, 0.050935, 0.0017481, 0.79874, 0.15007]
Predicted label: 8
Correct prediction
Energy consumption = 142.353117 pJ
sum error= 327
Actual label: 7
Output voltages: [0.16697, 0.024933, 0.092938, 0.010102, 0.042693, 0.0011153, 0.0011565, 0.79861, 0.23493, 0.56667]
Predicted label: 7
Correct prediction
Energy consumption = 149.357971 pJ
sum error= 327
Actual label: 1
Output voltages: [0.12978, 0.67264, 0.0025703, 0.052131, 0.13033, 0.0013691, 0.4438, 0.0010857, 0.7204, 0.097273]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.934014 pJ
sum error= 328
Actual label: 6
Output voltages: [0.05077, 0.021522, 0.39466, 0.001066, 0.18713, 0.056569, 0.79879, 0.0015894, 0.53356, 0.0020444]
Predicted label: 6
Correct prediction
Energy consumption = 144.020088 pJ
sum error= 328
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 793 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 793 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 793 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.067762, 0.0046517, 0.7987, 0.046367, 0.20779, 0.0010669, 0.028899, 0.013172, 0.70887, 0.023354]
Predicted label: 2
Correct prediction
Energy consumption = 140.060280 pJ
sum error= 328
Actual label: 9
Output voltages: [0.18613, 0.024998, 0.046875, 0.03612, 0.02117, 0.00927, 0.0039641, 0.020923, 0.71974, 0.79721]
Predicted label: 9
Correct prediction
Energy consumption = 150.434968 pJ
sum error= 328
Actual label: 3
Output voltages: [0.51592, 0.0013897, 0.74464, 0.79857, 0.024329, 0.0046004, 0.0047837, 0.010684, 0.72643, 0.01125]
Predicted label: 3
Correct prediction
Energy consumption = 143.854731 pJ
sum error= 328
Actual label: 0
Output voltages: [0.79858, 0.06773, 0.21353, 0.011966, 0.0020673, 0.0014208, 0.34119, 0.023946, 0.17751, 0.11592]
Predicted label: 0
Correct prediction
Energy consumption = 144.571947 pJ
sum error= 328
Actual label: 1
Output voltages: [0.029317, 0.79876, 0.024281, 0.14478, 0.028162, 0.001105, 0.3259, 0.0011114, 0.53915, 0.36363]
Predicted label: 1
Correct prediction
Energy consumption = 156.594201 pJ
sum error= 328
Actual label: 2
Output voltages: [0.315, 0.017407, 0.79878, 0.40456, 0.014707, 0.0010794, 0.01359, 0.34891, 0.53533, 0.014721]
Predicted label: 2
Correct prediction
Energy consumption = 150.035211 pJ
sum error= 328
Actual label: 3
Output voltages: [0.30212, 0.039293, 0.039676, 0.79868, 0.016796, 0.0016092, 0.016936, 0.011504, 0.43563, 0.040483]
Predicted label: 3
Correct prediction
Energy consumption = 141.494025 pJ
sum error= 328
Actual label: 4
Output voltages: [0.047704, 0.0028802, 0.013956, 0.0060141, 0.79876, 0.0011521, 0.18185, 0.0087956, 0.061928, 0.0019215]
Predicted label: 4
Correct prediction
Energy consumption = 151.978936 pJ
sum error= 328
Actual label: 5
Output voltages: [0.2141, 0.0011375, 0.0067981, 0.36006, 0.10443, 0.79859, 0.38714, 0.017086, 0.786, 0.022048]
Predicted label: 5
Correct prediction
Energy consumption = 143.395342 pJ
sum error= 328
Actual label: 6
Output voltages: [0.20396, 0.023353, 0.26983, 0.0050527, 0.26913, 0.28508, 0.79875, 0.0014852, 0.32273, 0.005539]
Predicted label: 6
Correct prediction
Energy consumption = 141.916228 pJ
sum error= 328
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 794 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 794 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 794 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.34225, 0.028302, 0.1151, 0.12672, 0.0043121, 0.0011543, 0.0011248, 0.79859, 0.26112, 0.13438]
Predicted label: 7
Correct prediction
Energy consumption = 154.934273 pJ
sum error= 328
Actual label: 8
Output voltages: [0.13213, 0.035823, 0.51519, 0.032773, 0.030272, 0.0021968, 0.045014, 0.0033587, 0.79879, 0.080404]
Predicted label: 8
Correct prediction
Energy consumption = 145.235181 pJ
sum error= 328
Actual label: 9
Output voltages: [0.078328, 0.0042479, 0.0081641, 0.037645, 0.097282, 0.0028072, 0.001353, 0.022926, 0.63678, 0.79685]
Predicted label: 9
Correct prediction
Energy consumption = 142.189449 pJ
sum error= 328
Actual label: 0
Output voltages: [0.79849, 0.030072, 0.19116, 0.01327, 0.0010676, 0.026758, 0.61219, 0.021831, 0.38495, 0.0043441]
Predicted label: 0
Correct prediction
Energy consumption = 144.027649 pJ
sum error= 328
Actual label: 1
Output voltages: [0.031731, 0.79865, 0.10479, 0.02688, 0.11078, 0.0017585, 0.43662, 0.0073319, 0.28567, 0.01347]
Predicted label: 1
Correct prediction
Energy consumption = 158.462607 pJ
sum error= 328
Actual label: 2
Output voltages: [0.75772, 0.0091365, 0.78441, 0.76471, 0.023152, 0.001066, 0.020533, 0.015873, 0.037182, 0.010361]
Predicted label: 2
Correct prediction
Energy consumption = 148.264652 pJ
sum error= 328
Actual label: 3
Output voltages: [0.19725, 0.0026686, 0.3944, 0.79866, 0.03175, 0.0027259, 0.03316, 0.0010811, 0.77982, 0.051828]
Predicted label: 3
Correct prediction
Energy consumption = 142.528387 pJ
sum error= 328
Actual label: 4
Output voltages: [0.023492, 0.10544, 0.0432, 0.024537, 0.79878, 0.001347, 0.29162, 0.24709, 0.018043, 0.02786]
Predicted label: 4
Correct prediction
Energy consumption = 153.748212 pJ
sum error= 328
Actual label: 5
Output voltages: [0.023042, 0.0010785, 0.010259, 0.039536, 0.0059279, 0.7986, 0.29709, 0.010859, 0.78067, 0.003682]
Predicted label: 5
Correct prediction
Energy consumption = 151.837998 pJ
sum error= 328
Actual label: 6
Output voltages: [0.14894, 0.13881, 0.12489, 0.010246, 0.37224, 0.29684, 0.79872, 0.0012466, 0.36427, 0.019632]
Predicted label: 6
Correct prediction
Energy consumption = 146.753380 pJ
sum error= 328
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 795 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 795 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 795 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.51493, 0.030669, 0.46338, 0.11649, 0.0018523, 0.0012708, 0.0011347, 0.79835, 0.50314, 0.0052161]
Predicted label: 7
Correct prediction
Energy consumption = 154.569065 pJ
sum error= 328
Actual label: 8
Output voltages: [0.026261, 0.19645, 0.13318, 0.016392, 0.023072, 0.0017908, 0.023855, 0.004196, 0.79879, 0.66676]
Predicted label: 8
Correct prediction
Energy consumption = 143.424437 pJ
sum error= 328
Actual label: 9
Output voltages: [0.40186, 0.0026297, 0.024599, 0.01426, 0.16039, 0.0030751, 0.0010665, 0.031238, 0.50146, 0.79731]
Predicted label: 9
Correct prediction
Energy consumption = 145.919906 pJ
sum error= 328
Actual label: 0
Output voltages: [0.79879, 0.14344, 0.049824, 0.01762, 0.0051596, 0.0037129, 0.51825, 0.0088595, 0.056438, 0.12389]
Predicted label: 0
Correct prediction
Energy consumption = 148.280655 pJ
sum error= 328
Actual label: 1
Output voltages: [0.026402, 0.79878, 0.01169, 0.025142, 0.37015, 0.0010941, 0.12193, 0.0011617, 0.43145, 0.34274]
Predicted label: 1
Correct prediction
Energy consumption = 155.209600 pJ
sum error= 328
Actual label: 2
Output voltages: [0.57297, 0.0033027, 0.79869, 0.064767, 0.017517, 0.0010682, 0.0076115, 0.10462, 0.52091, 0.0090889]
Predicted label: 2
Correct prediction
Energy consumption = 143.504542 pJ
sum error= 328
Actual label: 3
Output voltages: [0.26629, 0.010096, 0.085574, 0.79872, 0.078245, 0.0032855, 0.032145, 0.0083871, 0.74078, 0.045263]
Predicted label: 3
Correct prediction
Energy consumption = 142.148753 pJ
sum error= 328
Actual label: 4
Output voltages: [0.001075, 0.012851, 0.019348, 0.019608, 0.79879, 0.0093539, 0.32659, 0.14518, 0.22745, 0.0021077]
Predicted label: 4
Correct prediction
Energy consumption = 146.969977 pJ
sum error= 328
Actual label: 5
Output voltages: [0.020066, 0.0012039, 0.004242, 0.36307, 0.041273, 0.79848, 0.17968, 0.064497, 0.76757, 0.029324]
Predicted label: 5
Correct prediction
Energy consumption = 144.271719 pJ
sum error= 328
Actual label: 6
Output voltages: [0.049729, 0.16187, 0.48483, 0.014846, 0.18772, 0.083498, 0.79873, 0.0010948, 0.56723, 0.038656]
Predicted label: 6
Correct prediction
Energy consumption = 143.083634 pJ
sum error= 328
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 796 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 796 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 796 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.02482, 0.057057, 0.76969, 0.013892, 0.0028738, 0.0010742, 0.0015768, 0.79866, 0.44691, 0.3927]
Predicted label: 7
Correct prediction
Energy consumption = 149.125893 pJ
sum error= 328
Actual label: 8
Output voltages: [0.036198, 0.076006, 0.057667, 0.037971, 0.055142, 0.0079817, 0.046569, 0.0014252, 0.79874, 0.4281]
Predicted label: 8
Correct prediction
Energy consumption = 143.905111 pJ
sum error= 328
Actual label: 9
Output voltages: [0.36452, 0.0069219, 0.030224, 0.016853, 0.053322, 0.040053, 0.0020724, 0.16114, 0.67007, 0.79057]
Predicted label: 9
Correct prediction
Energy consumption = 146.273976 pJ
sum error= 328
Actual label: 8
Output voltages: [0.0067711, 0.058063, 0.20395, 0.039629, 0.0085433, 0.004097, 0.03974, 0.029069, 0.79874, 0.15463]
Predicted label: 8
Correct prediction
Energy consumption = 144.836635 pJ
sum error= 328
Actual label: 9
Output voltages: [0.053886, 0.031765, 0.021337, 0.022639, 0.012753, 0.0020741, 0.0015009, 0.011388, 0.71744, 0.79643]
Predicted label: 9
Correct prediction
Energy consumption = 145.208217 pJ
sum error= 328
Actual label: 5
Output voltages: [0.040546, 0.0012941, 0.012156, 0.34239, 0.024525, 0.79879, 0.096916, 0.20268, 0.78814, 0.05572]
Predicted label: 5
Correct prediction
Energy consumption = 145.148277 pJ
sum error= 328
Actual label: 7
Output voltages: [0.57801, 0.003933, 0.31038, 0.54513, 0.001098, 0.001066, 0.0010692, 0.79862, 0.38425, 0.22235]
Predicted label: 7
Correct prediction
Energy consumption = 153.773160 pJ
sum error= 328
Actual label: 0
Output voltages: [0.79873, 0.046202, 0.021752, 0.020977, 0.046594, 0.01973, 0.54247, 0.016568, 0.076467, 0.042973]
Predicted label: 0
Correct prediction
Energy consumption = 146.140289 pJ
sum error= 328
Actual label: 3
Output voltages: [0.39078, 0.010404, 0.13072, 0.79868, 0.041806, 0.0067521, 0.011303, 0.0067318, 0.67519, 0.037663]
Predicted label: 3
Correct prediction
Energy consumption = 149.107912 pJ
sum error= 328
Actual label: 1
Output voltages: [0.024171, 0.79857, 0.036998, 0.020257, 0.12598, 0.0014758, 0.72167, 0.020257, 0.047499, 0.034197]
Predicted label: 1
Correct prediction
Energy consumption = 155.289513 pJ
sum error= 328
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 797 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 797 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 797 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.038777, 0.0044524, 0.1427, 0.0039923, 0.26688, 0.37318, 0.79877, 0.001116, 0.66379, 0.005818]
Predicted label: 6
Correct prediction
Energy consumption = 146.366410 pJ
sum error= 328
Actual label: 8
Output voltages: [0.43783, 0.034646, 0.20244, 0.017282, 0.04229, 0.0012019, 0.023282, 0.012087, 0.79571, 0.2152]
Predicted label: 8
Correct prediction
Energy consumption = 151.256422 pJ
sum error= 328
Actual label: 4
Output voltages: [0.003868, 0.009933, 0.03958, 0.021406, 0.79879, 0.0016066, 0.19172, 0.18582, 0.036337, 0.0028112]
Predicted label: 4
Correct prediction
Energy consumption = 145.815202 pJ
sum error= 328
Actual label: 1
Output voltages: [0.020184, 0.79876, 0.17817, 0.0042874, 0.36722, 0.0010666, 0.064905, 0.0042811, 0.073526, 0.021949]
Predicted label: 1
Correct prediction
Energy consumption = 154.882547 pJ
sum error= 328
Actual label: 5
Output voltages: [0.048291, 0.0010932, 0.0010933, 0.39018, 0.033567, 0.79873, 0.14647, 0.062742, 0.76772, 0.006819]
Predicted label: 5
Correct prediction
Energy consumption = 140.677273 pJ
sum error= 328
Actual label: 6
Output voltages: [0.064315, 0.0078245, 0.50917, 0.004084, 0.31198, 0.19059, 0.79872, 0.0011065, 0.61647, 0.040206]
Predicted label: 6
Correct prediction
Energy consumption = 148.026083 pJ
sum error= 328
Actual label: 4
Output voltages: [0.0042182, 0.0040246, 0.41721, 0.027231, 0.79866, 0.0012346, 0.51417, 0.33603, 0.0054594, 0.013019]
Predicted label: 4
Correct prediction
Energy consumption = 142.848505 pJ
sum error= 328
Actual label: 2
Output voltages: [0.57775, 0.0032531, 0.79733, 0.24076, 0.019573, 0.0012259, 0.030808, 0.11271, 0.6578, 0.012926]
Predicted label: 2
Correct prediction
Energy consumption = 146.302665 pJ
sum error= 328
Actual label: 7
Output voltages: [0.73961, 0.0089584, 0.61532, 0.33985, 0.0036448, 0.0014501, 0.0010677, 0.78669, 0.77411, 0.024219]
Predicted label: 7
Correct prediction
Energy consumption = 141.364740 pJ
sum error= 328
Actual label: 8
Output voltages: [0.037803, 0.014689, 0.48926, 0.010921, 0.020234, 0.0097109, 0.015776, 0.0049448, 0.79874, 0.22096]
Predicted label: 8
Correct prediction
Energy consumption = 137.241407 pJ
sum error= 328
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 798 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 798 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 798 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.062687, 0.79878, 0.52941, 0.045312, 0.19733, 0.0011666, 0.65454, 0.011613, 0.07098, 0.023943]
Predicted label: 1
Correct prediction
Energy consumption = 162.631352 pJ
sum error= 328
Actual label: 3
Output voltages: [0.43595, 0.024124, 0.090955, 0.79863, 0.030791, 0.011054, 0.013062, 0.011339, 0.67183, 0.043577]
Predicted label: 3
Correct prediction
Energy consumption = 144.187963 pJ
sum error= 328
Actual label: 4
Output voltages: [0.013391, 0.032006, 0.028381, 0.01988, 0.79876, 0.0010936, 0.1092, 0.011911, 0.42692, 0.013356]
Predicted label: 4
Correct prediction
Energy consumption = 149.310579 pJ
sum error= 328
Actual label: 3
Output voltages: [0.17466, 0.01467, 0.027575, 0.79867, 0.039577, 0.028726, 0.033705, 0.0040995, 0.63886, 0.14609]
Predicted label: 3
Correct prediction
Energy consumption = 149.955358 pJ
sum error= 328
Actual label: 4
Output voltages: [0.020758, 0.027289, 0.024227, 0.026298, 0.79877, 0.0010663, 0.11324, 0.072293, 0.035107, 0.0042625]
Predicted label: 4
Correct prediction
Energy consumption = 150.557648 pJ
sum error= 328
Actual label: 7
Output voltages: [0.040434, 0.060643, 0.69576, 0.033805, 0.0035369, 0.0011559, 0.0011114, 0.79875, 0.66733, 0.093825]
Predicted label: 7
Correct prediction
Energy consumption = 149.662532 pJ
sum error= 328
Actual label: 2
Output voltages: [0.47941, 0.0030747, 0.79777, 0.3438, 0.0041219, 0.0011504, 0.024096, 0.07954, 0.71108, 0.022304]
Predicted label: 2
Correct prediction
Energy consumption = 136.400994 pJ
sum error= 328
Actual label: 0
Output voltages: [0.79879, 0.034501, 0.18094, 0.017148, 0.0044829, 0.0074394, 0.38002, 0.028437, 0.45628, 0.012278]
Predicted label: 0
Correct prediction
Energy consumption = 148.338692 pJ
sum error= 328
Actual label: 5
Output voltages: [0.027172, 0.0011512, 0.001167, 0.097261, 0.038864, 0.79865, 0.43217, 0.11105, 0.74897, 0.009608]
Predicted label: 5
Correct prediction
Energy consumption = 139.164510 pJ
sum error= 328
Actual label: 0
Output voltages: [0.79844, 0.05256, 0.024649, 0.016936, 0.0029528, 0.0017865, 0.73624, 0.012354, 0.3114, 0.057337]
Predicted label: 0
Correct prediction
Energy consumption = 135.498682 pJ
sum error= 328
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 799 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 799 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 799 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.054524, 0.77574, 0.0082007, 0.029841, 0.069009, 0.0099708, 0.067123, 0.0053153, 0.78379, 0.047915]
Predicted label: 8
Wrong prediction!
Energy consumption = 154.536616 pJ
sum error= 329
Actual label: 9
Output voltages: [0.34899, 0.0016297, 0.054962, 0.0055891, 0.027024, 0.013391, 0.001142, 0.066508, 0.79152, 0.78868]
Predicted label: 8
Wrong prediction!
Energy consumption = 147.407064 pJ
sum error= 330
Actual label: 2
Output voltages: [0.23862, 0.015878, 0.79866, 0.079308, 0.021948, 0.0010683, 0.028634, 0.16735, 0.35159, 0.029858]
Predicted label: 2
Correct prediction
Energy consumption = 139.675923 pJ
sum error= 330
Actual label: 3
Output voltages: [0.60933, 0.0047352, 0.040123, 0.79869, 0.020038, 0.28631, 0.011426, 0.01217, 0.52062, 0.028743]
Predicted label: 3
Correct prediction
Energy consumption = 143.901964 pJ
sum error= 330
Actual label: 2
Output voltages: [0.54056, 0.0042321, 0.79871, 0.058764, 0.0081572, 0.0011412, 0.022047, 0.091068, 0.68755, 0.0021183]
Predicted label: 2
Correct prediction
Energy consumption = 135.696896 pJ
sum error= 330
Actual label: 3
Output voltages: [0.37841, 0.038222, 0.077604, 0.79857, 0.033288, 0.014983, 0.015879, 0.029534, 0.63476, 0.048218]
Predicted label: 3
Correct prediction
Energy consumption = 145.468528 pJ
sum error= 330
Actual label: 5
Output voltages: [0.031349, 0.0010659, 0.0011033, 0.31878, 0.33763, 0.79874, 0.44219, 0.0029435, 0.74986, 0.0019202]
Predicted label: 5
Correct prediction
Energy consumption = 132.211519 pJ
sum error= 330
Actual label: 5
Output voltages: [0.17693, 0.0012112, 0.0010739, 0.37631, 0.012662, 0.79878, 0.36533, 0.019736, 0.75456, 0.0049455]
Predicted label: 5
Correct prediction
Energy consumption = 131.558337 pJ
sum error= 330
Actual label: 7
Output voltages: [0.38902, 0.0020778, 0.032437, 0.16061, 0.0011338, 0.011337, 0.0011189, 0.79667, 0.75315, 0.5187]
Predicted label: 7
Correct prediction
Energy consumption = 148.412945 pJ
sum error= 330
Actual label: 8
Output voltages: [0.62058, 0.018444, 0.75241, 0.0070068, 0.011701, 0.001838, 0.026829, 0.013869, 0.79818, 0.20729]
Predicted label: 8
Correct prediction
Energy consumption = 141.079813 pJ
sum error= 330
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 800 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 800 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 800 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.030101, 0.0080836, 0.60992, 0.0095412, 0.79879, 0.001066, 0.6598, 0.046339, 0.034819, 0.036239]
Predicted label: 4
Correct prediction
Energy consumption = 144.688393 pJ
sum error= 330
Actual label: 9
Output voltages: [0.27917, 0.0015691, 0.012479, 0.051604, 0.37275, 0.0034408, 0.0034986, 0.032882, 0.52647, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 153.422488 pJ
sum error= 330
Actual label: 9
Output voltages: [0.052516, 0.0079387, 0.013505, 0.034041, 0.034106, 0.0062574, 0.0011534, 0.029075, 0.74633, 0.79243]
Predicted label: 9
Correct prediction
Energy consumption = 138.794052 pJ
sum error= 330
Actual label: 7
Output voltages: [0.099592, 0.050224, 0.24335, 0.38689, 0.0054368, 0.0011236, 0.0011962, 0.79879, 0.69701, 0.45388]
Predicted label: 7
Correct prediction
Energy consumption = 147.780478 pJ
sum error= 330
Actual label: 1
Output voltages: [0.532, 0.78875, 0.32741, 0.028853, 0.05242, 0.010658, 0.77096, 0.0010697, 0.035104, 0.032882]
Predicted label: 1
Correct prediction
Energy consumption = 159.453320 pJ
sum error= 330
Actual label: 1
Output voltages: [0.010276, 0.79855, 0.054061, 0.012794, 0.040963, 0.0035374, 0.7067, 0.019448, 0.33697, 0.033984]
Predicted label: 1
Correct prediction
Energy consumption = 148.989201 pJ
sum error= 330
Actual label: 9
Output voltages: [0.38675, 0.014237, 0.029578, 0.019464, 0.035907, 0.029663, 0.0083647, 0.037856, 0.74318, 0.79815]
Predicted label: 9
Correct prediction
Energy consumption = 154.719505 pJ
sum error= 330
Actual label: 0
Output voltages: [0.79879, 0.031699, 0.1094, 0.0047895, 0.0043222, 0.0024607, 0.50424, 0.080045, 0.29228, 0.023897]
Predicted label: 0
Correct prediction
Energy consumption = 143.819454 pJ
sum error= 330
Actual label: 7
Output voltages: [0.12662, 0.032266, 0.74706, 0.033176, 0.0017897, 0.0010721, 0.0010732, 0.79872, 0.61057, 0.3051]
Predicted label: 7
Correct prediction
Energy consumption = 144.484935 pJ
sum error= 330
Actual label: 8
Output voltages: [0.086594, 0.010924, 0.59508, 0.0067223, 0.036339, 0.0072364, 0.010361, 0.004247, 0.79876, 0.1902]
Predicted label: 8
Correct prediction
Energy consumption = 140.430992 pJ
sum error= 330
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 801 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 801 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 801 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.73466, 0.0010677, 0.29382, 0.79856, 0.018738, 0.010668, 0.012201, 0.0053828, 0.76515, 0.0054493]
Predicted label: 3
Correct prediction
Energy consumption = 154.380720 pJ
sum error= 330
Actual label: 4
Output voltages: [0.021674, 0.028688, 0.0088318, 0.01269, 0.79861, 0.0014487, 0.11028, 0.056244, 0.21613, 0.0089539]
Predicted label: 4
Correct prediction
Energy consumption = 150.322886 pJ
sum error= 330
Actual label: 8
Output voltages: [0.05951, 0.029989, 0.36041, 0.020066, 0.02691, 0.0054297, 0.036844, 0.01647, 0.79874, 0.13887]
Predicted label: 8
Correct prediction
Energy consumption = 142.746566 pJ
sum error= 330
Actual label: 6
Output voltages: [0.048514, 0.079629, 0.50738, 0.0021977, 0.41438, 0.10128, 0.79864, 0.0028606, 0.42237, 0.020161]
Predicted label: 6
Correct prediction
Energy consumption = 146.569863 pJ
sum error= 330
Actual label: 3
Output voltages: [0.53264, 0.0038045, 0.29935, 0.79876, 0.027602, 0.013363, 0.029236, 0.019794, 0.68535, 0.046816]
Predicted label: 3
Correct prediction
Energy consumption = 154.339273 pJ
sum error= 330
Actual label: 8
Output voltages: [0.023451, 0.052455, 0.16024, 0.018492, 0.014499, 0.038397, 0.030703, 0.0030682, 0.79874, 0.10259]
Predicted label: 8
Correct prediction
Energy consumption = 145.134773 pJ
sum error= 330
Actual label: 0
Output voltages: [0.79866, 0.038523, 0.06137, 0.023739, 0.0086768, 0.0012077, 0.66827, 0.015182, 0.27382, 0.23464]
Predicted label: 0
Correct prediction
Energy consumption = 137.578550 pJ
sum error= 330
Actual label: 9
Output voltages: [0.28758, 0.011872, 0.023467, 0.030135, 0.12111, 0.011152, 0.0021662, 0.043334, 0.61422, 0.79845]
Predicted label: 9
Correct prediction
Energy consumption = 147.327954 pJ
sum error= 330
Actual label: 6
Output voltages: [0.10448, 0.045388, 0.42947, 0.0011273, 0.29813, 0.20426, 0.79871, 0.0018748, 0.59167, 0.0050741]
Predicted label: 6
Correct prediction
Energy consumption = 152.028614 pJ
sum error= 330
Actual label: 2
Output voltages: [0.3002, 0.016866, 0.79759, 0.39767, 0.011338, 0.0011306, 0.19047, 0.016307, 0.7897, 0.1116]
Predicted label: 2
Correct prediction
Energy consumption = 151.188437 pJ
sum error= 330
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 802 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 802 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 802 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.27919, 0.7964, 0.11575, 0.023708, 0.002611, 0.0011037, 0.75487, 0.0013637, 0.65943, 0.03352]
Predicted label: 1
Correct prediction
Energy consumption = 166.343789 pJ
sum error= 330
Actual label: 0
Output voltages: [0.79879, 0.10425, 0.022215, 0.0088461, 0.049658, 0.010962, 0.61536, 0.010103, 0.056786, 0.1291]
Predicted label: 0
Correct prediction
Energy consumption = 141.967832 pJ
sum error= 330
Actual label: 1
Output voltages: [0.059981, 0.79872, 0.024666, 0.02906, 0.30084, 0.0010753, 0.17796, 0.001066, 0.52508, 0.17317]
Predicted label: 1
Correct prediction
Energy consumption = 154.740581 pJ
sum error= 330
Actual label: 0
Output voltages: [0.79681, 0.062993, 0.01261, 0.01504, 0.0090398, 0.0012076, 0.4317, 0.025808, 0.36666, 0.029948]
Predicted label: 0
Correct prediction
Energy consumption = 144.200987 pJ
sum error= 330
Actual label: 6
Output voltages: [0.079355, 0.024134, 0.35926, 0.001066, 0.36413, 0.026107, 0.79878, 0.0010838, 0.20483, 0.0061925]
Predicted label: 6
Correct prediction
Energy consumption = 144.658311 pJ
sum error= 330
Actual label: 2
Output voltages: [0.21592, 0.008687, 0.79863, 0.025893, 0.051433, 0.0011595, 0.076798, 0.07214, 0.34789, 0.0066576]
Predicted label: 2
Correct prediction
Energy consumption = 137.402850 pJ
sum error= 330
Actual label: 3
Output voltages: [0.50269, 0.01541, 0.19019, 0.79873, 0.31819, 0.0054715, 0.012625, 0.002171, 0.63205, 0.029179]
Predicted label: 3
Correct prediction
Energy consumption = 138.722012 pJ
sum error= 330
Actual label: 8
Output voltages: [0.041411, 0.024218, 0.43353, 0.01691, 0.039097, 0.0074052, 0.023992, 0.0049824, 0.79873, 0.12751]
Predicted label: 8
Correct prediction
Energy consumption = 139.386637 pJ
sum error= 330
Actual label: 9
Output voltages: [0.32015, 0.014764, 0.10068, 0.0059882, 0.042784, 0.009384, 0.0019183, 0.039667, 0.67268, 0.79792]
Predicted label: 9
Correct prediction
Energy consumption = 151.613350 pJ
sum error= 330
Actual label: 0
Output voltages: [0.79713, 0.021721, 0.26258, 0.010331, 0.018178, 0.001231, 0.67494, 0.047952, 0.28407, 0.037073]
Predicted label: 0
Correct prediction
Energy consumption = 146.786734 pJ
sum error= 330
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 803 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 803 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 803 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.6051, 0.003584, 0.74033, 0.26026, 0.0010795, 0.0018173, 0.0010726, 0.79504, 0.5892, 0.25796]
Predicted label: 7
Correct prediction
Energy consumption = 152.966085 pJ
sum error= 330
Actual label: 2
Output voltages: [0.13187, 0.055015, 0.79878, 0.50189, 0.026598, 0.0012741, 0.031565, 0.34008, 0.096733, 0.013936]
Predicted label: 2
Correct prediction
Energy consumption = 133.276254 pJ
sum error= 330
Actual label: 3
Output voltages: [0.06502, 0.0055231, 0.079164, 0.79877, 0.024598, 0.0037619, 0.0053311, 0.033021, 0.60086, 0.13178]
Predicted label: 3
Correct prediction
Energy consumption = 143.342203 pJ
sum error= 330
Actual label: 4
Output voltages: [0.0026264, 0.0093142, 0.01313, 0.0060869, 0.79869, 0.0011079, 0.041417, 0.18051, 0.24394, 0.0079681]
Predicted label: 4
Correct prediction
Energy consumption = 146.628555 pJ
sum error= 330
Actual label: 5
Output voltages: [0.0044224, 0.0011417, 0.0040135, 0.34967, 0.015212, 0.78329, 0.02552, 0.0050265, 0.77064, 0.037876]
Predicted label: 5
Correct prediction
Energy consumption = 148.202509 pJ
sum error= 330
Actual label: 5
Output voltages: [0.015596, 0.0010941, 0.0012791, 0.64118, 0.020547, 0.76771, 0.016761, 0.010511, 0.75101, 0.020648]
Predicted label: 5
Correct prediction
Energy consumption = 131.657957 pJ
sum error= 330
Actual label: 2
Output voltages: [0.57198, 0.025544, 0.79874, 0.20557, 0.052123, 0.0032523, 0.046989, 0.04236, 0.19224, 0.018069]
Predicted label: 2
Correct prediction
Energy consumption = 145.985722 pJ
sum error= 330
Actual label: 8
Output voltages: [0.020589, 0.14328, 0.15841, 0.026038, 0.027785, 0.016194, 0.034525, 0.0019119, 0.79877, 0.41513]
Predicted label: 8
Correct prediction
Energy consumption = 143.143391 pJ
sum error= 330
Actual label: 5
Output voltages: [0.029234, 0.0083943, 0.0032896, 0.28318, 0.016511, 0.79878, 0.21707, 0.031913, 0.63714, 0.022476]
Predicted label: 5
Correct prediction
Energy consumption = 145.591531 pJ
sum error= 330
Actual label: 4
Output voltages: [0.0038443, 0.027155, 0.041137, 0.023103, 0.79862, 0.0041394, 0.033336, 0.06466, 0.023632, 0.024926]
Predicted label: 4
Correct prediction
Energy consumption = 155.571728 pJ
sum error= 330
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 804 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 804 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 804 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.21006, 0.02231, 0.32089, 0.0012224, 0.50024, 0.22897, 0.79879, 0.0010689, 0.4012, 0.0052889]
Predicted label: 6
Correct prediction
Energy consumption = 151.696404 pJ
sum error= 330
Actual label: 6
Output voltages: [0.21738, 0.044967, 0.052046, 0.020242, 0.21433, 0.26166, 0.79879, 0.0011044, 0.62357, 0.0055714]
Predicted label: 6
Correct prediction
Energy consumption = 138.749116 pJ
sum error= 330
Actual label: 6
Output voltages: [0.18584, 0.071981, 0.19547, 0.011706, 0.31457, 0.26904, 0.7987, 0.0015663, 0.44204, 0.012282]
Predicted label: 6
Correct prediction
Energy consumption = 139.506833 pJ
sum error= 330
Actual label: 7
Output voltages: [0.44285, 0.21996, 0.79767, 0.019555, 0.0014673, 0.0011301, 0.021237, 0.78388, 0.61185, 0.05486]
Predicted label: 2
Wrong prediction!
Energy consumption = 154.312371 pJ
sum error= 331
Actual label: 9
Output voltages: [0.39931, 0.0024718, 0.0093912, 0.033656, 0.042173, 0.0035944, 0.0019519, 0.059915, 0.56805, 0.78897]
Predicted label: 9
Correct prediction
Energy consumption = 152.785499 pJ
sum error= 331
Actual label: 1
Output voltages: [0.041221, 0.79859, 0.020826, 0.017737, 0.50845, 0.001066, 0.13268, 0.0010837, 0.31965, 0.24918]
Predicted label: 1
Correct prediction
Energy consumption = 159.125573 pJ
sum error= 331
Actual label: 8
Output voltages: [0.024942, 0.037778, 0.19413, 0.010302, 0.01164, 0.003179, 0.027205, 0.025873, 0.79877, 0.31357]
Predicted label: 8
Correct prediction
Energy consumption = 141.756859 pJ
sum error= 331
Actual label: 2
Output voltages: [0.75269, 0.023445, 0.79879, 0.57995, 0.0085199, 0.0091765, 0.11892, 0.055622, 0.70539, 0.0095977]
Predicted label: 2
Correct prediction
Energy consumption = 143.484004 pJ
sum error= 331
Actual label: 1
Output voltages: [0.011677, 0.79861, 0.036348, 0.012555, 0.020967, 0.002392, 0.28805, 0.010684, 0.54, 0.006888]
Predicted label: 1
Correct prediction
Energy consumption = 162.353956 pJ
sum error= 331
Actual label: 5
Output voltages: [0.033268, 0.0010696, 0.0045093, 0.11559, 0.03129, 0.79858, 0.31977, 0.036824, 0.78037, 0.010237]
Predicted label: 5
Correct prediction
Energy consumption = 148.054231 pJ
sum error= 331
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 805 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 805 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 805 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.62655, 0.0078159, 0.11297, 0.79878, 0.036876, 0.006871, 0.0015883, 0.0023231, 0.49516, 0.0076356]
Predicted label: 3
Correct prediction
Energy consumption = 150.326070 pJ
sum error= 331
Actual label: 4
Output voltages: [0.023017, 0.010887, 0.038696, 0.037917, 0.79874, 0.0011758, 0.0085681, 0.011196, 0.11164, 0.013255]
Predicted label: 4
Correct prediction
Energy consumption = 146.908293 pJ
sum error= 331
Actual label: 7
Output voltages: [0.15517, 0.022555, 0.53485, 0.011295, 0.0017637, 0.0010692, 0.0010664, 0.79865, 0.34298, 0.15618]
Predicted label: 7
Correct prediction
Energy consumption = 150.097180 pJ
sum error= 331
Actual label: 9
Output voltages: [0.33115, 0.0064875, 0.014189, 0.021738, 0.10089, 0.0048713, 0.0021971, 0.032267, 0.64468, 0.79862]
Predicted label: 9
Correct prediction
Energy consumption = 144.593191 pJ
sum error= 331
Actual label: 4
Output voltages: [0.0096114, 0.011942, 0.018606, 0.0076076, 0.79869, 0.0011418, 0.12878, 0.21242, 0.035775, 0.0042152]
Predicted label: 4
Correct prediction
Energy consumption = 149.053328 pJ
sum error= 331
Actual label: 0
Output voltages: [0.79873, 0.026251, 0.042543, 0.017714, 0.078675, 0.0025681, 0.3628, 0.018236, 0.26953, 0.020802]
Predicted label: 0
Correct prediction
Energy consumption = 152.427840 pJ
sum error= 331
Actual label: 0
Output voltages: [0.79874, 0.2403, 0.028767, 0.034051, 0.0096351, 0.021098, 0.21621, 0.051585, 0.12944, 0.067385]
Predicted label: 0
Correct prediction
Energy consumption = 140.774063 pJ
sum error= 331
Actual label: 0
Output voltages: [0.79795, 0.040172, 0.032765, 0.0037561, 0.032911, 0.0014809, 0.60653, 0.017686, 0.034144, 0.13777]
Predicted label: 0
Correct prediction
Energy consumption = 140.628474 pJ
sum error= 331
Actual label: 1
Output voltages: [0.0089706, 0.79859, 0.031975, 0.10618, 0.12063, 0.0033433, 0.69835, 0.0012947, 0.34355, 0.05958]
Predicted label: 1
Correct prediction
Energy consumption = 161.756419 pJ
sum error= 331
Actual label: 2
Output voltages: [0.049679, 0.75506, 0.79563, 0.58358, 0.0018688, 0.0011107, 0.41011, 0.0025939, 0.41315, 0.068467]
Predicted label: 2
Correct prediction
Energy consumption = 152.515773 pJ
sum error= 331
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 806 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 806 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 806 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.34085, 0.065946, 0.056802, 0.79868, 0.012283, 0.0075511, 0.0017047, 0.0074067, 0.63889, 0.22363]
Predicted label: 3
Correct prediction
Energy consumption = 155.723346 pJ
sum error= 331
Actual label: 4
Output voltages: [0.22284, 0.018869, 0.099702, 0.015761, 0.79879, 0.0011996, 0.020753, 0.011133, 0.023561, 0.11552]
Predicted label: 4
Correct prediction
Energy consumption = 152.633917 pJ
sum error= 331
Actual label: 5
Output voltages: [0.07302, 0.046882, 0.0034702, 0.40589, 0.0010831, 0.77246, 0.028298, 0.0014046, 0.79784, 0.023164]
Predicted label: 8
Wrong prediction!
Energy consumption = 153.532565 pJ
sum error= 332
Actual label: 6
Output voltages: [0.27492, 0.060648, 0.09173, 0.046447, 0.1549, 0.44575, 0.79878, 0.0011688, 0.43894, 0.0049257]
Predicted label: 6
Correct prediction
Energy consumption = 150.588973 pJ
sum error= 332
Actual label: 7
Output voltages: [0.45872, 0.087716, 0.058908, 0.59238, 0.0030962, 0.0059961, 0.0011726, 0.79704, 0.72628, 0.26534]
Predicted label: 7
Correct prediction
Energy consumption = 159.903493 pJ
sum error= 332
Actual label: 8
Output voltages: [0.11663, 0.36563, 0.03912, 0.6234, 0.017273, 0.003738, 0.046387, 0.0021776, 0.79875, 0.22271]
Predicted label: 8
Correct prediction
Energy consumption = 156.697250 pJ
sum error= 332
Actual label: 9
Output voltages: [0.048353, 0.019583, 0.0097383, 0.029389, 0.027231, 0.0020345, 0.0010978, 0.011946, 0.7248, 0.7979]
Predicted label: 9
Correct prediction
Energy consumption = 145.722174 pJ
sum error= 332
Actual label: 0
Output voltages: [0.79869, 0.033805, 0.20412, 0.0042431, 0.011874, 0.014418, 0.07243, 0.020767, 0.22814, 0.039133]
Predicted label: 0
Correct prediction
Energy consumption = 152.224563 pJ
sum error= 332
Actual label: 1
Output voltages: [0.011728, 0.79853, 0.038481, 0.046775, 0.097651, 0.0033349, 0.71985, 0.0016105, 0.29019, 0.24916]
Predicted label: 1
Correct prediction
Energy consumption = 165.883489 pJ
sum error= 332
Actual label: 2
Output voltages: [0.017226, 0.79274, 0.6641, 0.15166, 0.022618, 0.0012923, 0.28714, 0.0042402, 0.23589, 0.0083672]
Predicted label: 1
Wrong prediction!
Energy consumption = 145.411090 pJ
sum error= 333
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 807 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 807 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 807 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.48236, 0.023553, 0.12357, 0.79869, 0.025174, 0.015235, 0.0057064, 0.020618, 0.62088, 0.044044]
Predicted label: 3
Correct prediction
Energy consumption = 150.114156 pJ
sum error= 333
Actual label: 4
Output voltages: [0.089629, 0.20163, 0.0012155, 0.2987, 0.79764, 0.0071247, 0.079399, 0.010007, 0.02765, 0.30431]
Predicted label: 4
Correct prediction
Energy consumption = 149.324437 pJ
sum error= 333
Actual label: 5
Output voltages: [0.023881, 0.006795, 0.0034789, 0.55973, 0.030081, 0.79872, 0.13404, 0.038655, 0.75024, 0.02885]
Predicted label: 5
Correct prediction
Energy consumption = 147.239855 pJ
sum error= 333
Actual label: 6
Output voltages: [0.032523, 0.087446, 0.21216, 0.007263, 0.035966, 0.35673, 0.79877, 0.019025, 0.53243, 0.0042111]
Predicted label: 6
Correct prediction
Energy consumption = 147.950169 pJ
sum error= 333
Actual label: 7
Output voltages: [0.038962, 0.05144, 0.05586, 0.064082, 0.0067306, 0.0010676, 0.001194, 0.79879, 0.62374, 0.2091]
Predicted label: 7
Correct prediction
Energy consumption = 158.071014 pJ
sum error= 333
Actual label: 8
Output voltages: [0.37904, 0.68859, 0.015957, 0.44481, 0.0014403, 0.0014737, 0.01954, 0.0011282, 0.79876, 0.56848]
Predicted label: 8
Correct prediction
Energy consumption = 151.551521 pJ
sum error= 333
Actual label: 9
Output voltages: [0.34441, 0.0080555, 0.027294, 0.025388, 0.13451, 0.004826, 0.0012658, 0.037663, 0.45491, 0.79757]
Predicted label: 9
Correct prediction
Energy consumption = 151.233389 pJ
sum error= 333
Actual label: 0
Output voltages: [0.79878, 0.040764, 0.18965, 0.027617, 0.10294, 0.0022785, 0.40721, 0.02202, 0.28175, 0.063435]
Predicted label: 0
Correct prediction
Energy consumption = 156.421422 pJ
sum error= 333
Actual label: 1
Output voltages: [0.041516, 0.79863, 0.046812, 0.16673, 0.036756, 0.0015037, 0.64578, 0.001068, 0.24586, 0.08198]
Predicted label: 1
Correct prediction
Energy consumption = 159.111616 pJ
sum error= 333
Actual label: 2
Output voltages: [0.16121, 0.42541, 0.79837, 0.26158, 0.0073408, 0.0011168, 0.21393, 0.0026918, 0.56157, 0.25857]
Predicted label: 2
Correct prediction
Energy consumption = 148.011204 pJ
sum error= 333
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 808 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 808 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 808 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.65051, 0.041987, 0.13616, 0.79865, 0.055668, 0.015116, 0.012917, 0.014941, 0.74555, 0.044551]
Predicted label: 3
Correct prediction
Energy consumption = 148.735446 pJ
sum error= 333
Actual label: 4
Output voltages: [0.20333, 0.1242, 0.016511, 0.031964, 0.79597, 0.00188, 0.78345, 0.0024219, 0.0052392, 0.054958]
Predicted label: 4
Correct prediction
Energy consumption = 146.671031 pJ
sum error= 333
Actual label: 5
Output voltages: [0.045065, 0.0020922, 0.0018269, 0.12726, 0.093718, 0.79875, 0.64685, 0.024541, 0.76203, 0.30428]
Predicted label: 5
Correct prediction
Energy consumption = 142.248357 pJ
sum error= 333
Actual label: 6
Output voltages: [0.13487, 0.24118, 0.16721, 0.0054082, 0.18921, 0.35573, 0.79871, 0.005307, 0.4046, 0.014689]
Predicted label: 6
Correct prediction
Energy consumption = 148.391488 pJ
sum error= 333
Actual label: 9
Output voltages: [0.31142, 0.024297, 0.037716, 0.0331, 0.24337, 0.004759, 0.0026474, 0.0070501, 0.32843, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 157.364686 pJ
sum error= 333
Actual label: 0
Output voltages: [0.79861, 0.037089, 0.15656, 0.0064725, 0.03126, 0.0024135, 0.76184, 0.0023985, 0.43676, 0.041941]
Predicted label: 0
Correct prediction
Energy consumption = 152.911396 pJ
sum error= 333
Actual label: 1
Output voltages: [0.014701, 0.79871, 0.16797, 0.11233, 0.18128, 0.0012445, 0.6584, 0.0016425, 0.04954, 0.020893]
Predicted label: 1
Correct prediction
Energy consumption = 167.088053 pJ
sum error= 333
Actual label: 3
Output voltages: [0.16673, 0.033253, 0.091404, 0.79877, 0.0041861, 0.0025939, 0.010378, 0.017571, 0.76881, 0.018707]
Predicted label: 3
Correct prediction
Energy consumption = 143.031325 pJ
sum error= 333
Actual label: 1
Output voltages: [0.24368, 0.79879, 0.061738, 0.50633, 0.0065382, 0.0016026, 0.28616, 0.0010797, 0.73717, 0.15302]
Predicted label: 1
Correct prediction
Energy consumption = 161.349468 pJ
sum error= 333
Actual label: 5
Output voltages: [0.011077, 0.001634, 0.0061533, 0.24483, 0.01594, 0.79867, 0.045776, 0.025018, 0.77775, 0.044041]
Predicted label: 5
Correct prediction
Energy consumption = 154.013457 pJ
sum error= 333
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 809 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 809 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 809 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.028088, 0.79869, 0.040352, 0.062294, 0.0058622, 0.003849, 0.73333, 0.0053132, 0.25984, 0.0095423]
Predicted label: 1
Correct prediction
Energy consumption = 162.107531 pJ
sum error= 333
Actual label: 2
Output voltages: [0.38449, 0.45741, 0.77871, 0.54577, 0.0070122, 0.0012502, 0.29268, 0.072541, 0.4151, 0.0017071]
Predicted label: 2
Correct prediction
Energy consumption = 150.866518 pJ
sum error= 333
Actual label: 4
Output voltages: [0.016252, 0.0020063, 0.051452, 0.00255, 0.79862, 0.0041535, 0.40564, 0.033134, 0.13863, 0.011331]
Predicted label: 4
Correct prediction
Energy consumption = 149.246157 pJ
sum error= 333
Actual label: 9
Output voltages: [0.1231, 0.0085562, 0.022972, 0.044096, 0.067489, 0.01035, 0.0020171, 0.044207, 0.66613, 0.79458]
Predicted label: 9
Correct prediction
Energy consumption = 147.276170 pJ
sum error= 333
Actual label: 2
Output voltages: [0.032464, 0.21016, 0.74263, 0.34406, 0.048395, 0.0010933, 0.013142, 0.019259, 0.75404, 0.019284]
Predicted label: 8
Wrong prediction!
Energy consumption = 152.347742 pJ
sum error= 334
Actual label: 4
Output voltages: [0.030007, 0.04188, 0.0030522, 0.15436, 0.79426, 0.0017521, 0.47898, 0.0055361, 0.1533, 0.0018866]
Predicted label: 4
Correct prediction
Energy consumption = 155.354886 pJ
sum error= 334
Actual label: 6
Output voltages: [0.053502, 0.054478, 0.34749, 0.0043334, 0.19915, 0.2224, 0.79875, 0.0015622, 0.51235, 0.0024549]
Predicted label: 6
Correct prediction
Energy consumption = 143.783376 pJ
sum error= 334
Actual label: 8
Output voltages: [0.67612, 0.0040546, 0.31551, 0.60275, 0.0052711, 0.014322, 0.015971, 0.0012284, 0.79808, 0.24614]
Predicted label: 8
Correct prediction
Energy consumption = 151.515674 pJ
sum error= 334
Actual label: 0
Output voltages: [0.79875, 0.044802, 0.25952, 0.012127, 0.018339, 0.0037287, 0.51007, 0.070513, 0.08668, 0.024994]
Predicted label: 0
Correct prediction
Energy consumption = 140.034064 pJ
sum error= 334
Actual label: 1
Output voltages: [0.0060683, 0.79856, 0.22983, 0.010869, 0.017907, 0.0013899, 0.36641, 0.0037934, 0.32723, 0.0066763]
Predicted label: 1
Correct prediction
Energy consumption = 155.127051 pJ
sum error= 334
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 810 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 810 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 810 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.013215, 0.7986, 0.048009, 0.026799, 0.038114, 0.0022137, 0.62229, 0.0012899, 0.26747, 0.033586]
Predicted label: 1
Correct prediction
Energy consumption = 160.913342 pJ
sum error= 334
Actual label: 9
Output voltages: [0.26475, 0.023572, 0.023562, 0.04658, 0.34576, 0.02361, 0.011938, 0.0086688, 0.26182, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 152.039029 pJ
sum error= 334
Actual label: 2
Output voltages: [0.052747, 0.39491, 0.79422, 0.491, 0.0017786, 0.0010697, 0.039021, 0.01867, 0.6269, 0.0036899]
Predicted label: 2
Correct prediction
Energy consumption = 156.188637 pJ
sum error= 334
Actual label: 6
Output voltages: [0.11498, 0.026323, 0.17912, 0.004481, 0.42796, 0.18722, 0.79876, 0.0013642, 0.7092, 0.0049393]
Predicted label: 6
Correct prediction
Energy consumption = 149.732848 pJ
sum error= 334
Actual label: 6
Output voltages: [0.059468, 0.0099261, 0.081428, 0.0014488, 0.47112, 0.027545, 0.79879, 0.001087, 0.75982, 0.004376]
Predicted label: 6
Correct prediction
Energy consumption = 139.147776 pJ
sum error= 334
Actual label: 8
Output voltages: [0.20265, 0.05854, 0.024065, 0.45745, 0.0014705, 0.081346, 0.01603, 0.0016724, 0.79878, 0.26798]
Predicted label: 8
Correct prediction
Energy consumption = 148.897255 pJ
sum error= 334
Actual label: 7
Output voltages: [0.29961, 0.21582, 0.24998, 0.023152, 0.0010661, 0.0013663, 0.0015613, 0.76453, 0.7925, 0.08542]
Predicted label: 8
Wrong prediction!
Energy consumption = 154.198775 pJ
sum error= 335
Actual label: 4
Output voltages: [0.15808, 0.0245, 0.15585, 0.0019563, 0.79873, 0.0013976, 0.14244, 0.0082969, 0.038338, 0.33785]
Predicted label: 4
Correct prediction
Energy consumption = 152.974583 pJ
sum error= 335
Actual label: 2
Output voltages: [0.55877, 0.25947, 0.79871, 0.031097, 0.0053753, 0.0012396, 0.038215, 0.1565, 0.32045, 0.0045811]
Predicted label: 2
Correct prediction
Energy consumption = 153.049736 pJ
sum error= 335
Actual label: 9
Output voltages: [0.27802, 0.0061845, 0.026279, 0.025706, 0.32555, 0.0076626, 0.0053766, 0.046047, 0.46657, 0.79786]
Predicted label: 9
Correct prediction
Energy consumption = 156.117127 pJ
sum error= 335
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 811 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 811 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 811 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.041927, 0.24878, 0.25783, 0.0044287, 0.019537, 0.0011873, 0.0010745, 0.79879, 0.41884, 0.071003]
Predicted label: 7
Correct prediction
Energy consumption = 154.816991 pJ
sum error= 335
Actual label: 0
Output voltages: [0.79879, 0.041518, 0.048738, 0.019879, 0.012883, 0.0031769, 0.46336, 0.040563, 0.088349, 0.16638]
Predicted label: 0
Correct prediction
Energy consumption = 146.394181 pJ
sum error= 335
Actual label: 2
Output voltages: [0.39049, 0.097146, 0.79877, 0.44882, 0.01184, 0.0012305, 0.24458, 0.044417, 0.46999, 0.024282]
Predicted label: 2
Correct prediction
Energy consumption = 149.456544 pJ
sum error= 335
Actual label: 1
Output voltages: [0.010714, 0.79861, 0.075299, 0.44971, 0.028122, 0.0011539, 0.77366, 0.016622, 0.063755, 0.03175]
Predicted label: 1
Correct prediction
Energy consumption = 159.732764 pJ
sum error= 335
Actual label: 0
Output voltages: [0.79877, 0.14269, 0.024009, 0.014563, 0.011663, 0.0132, 0.48273, 0.030413, 0.090507, 0.027166]
Predicted label: 0
Correct prediction
Energy consumption = 144.626124 pJ
sum error= 335
Actual label: 3
Output voltages: [0.26879, 0.012631, 0.052416, 0.79875, 0.0030114, 0.03794, 0.0056554, 0.030828, 0.76033, 0.07965]
Predicted label: 3
Correct prediction
Energy consumption = 147.294449 pJ
sum error= 335
Actual label: 6
Output voltages: [0.03585, 0.017475, 0.25114, 0.0011209, 0.2782, 0.028641, 0.79879, 0.0011633, 0.70502, 0.0028674]
Predicted label: 6
Correct prediction
Energy consumption = 144.657390 pJ
sum error= 335
Actual label: 0
Output voltages: [0.79875, 0.032815, 0.062037, 0.039201, 0.0038465, 0.0072758, 0.31585, 0.01504, 0.033779, 0.063077]
Predicted label: 0
Correct prediction
Energy consumption = 143.365401 pJ
sum error= 335
Actual label: 1
Output voltages: [0.033935, 0.79869, 0.29107, 0.0038254, 0.14248, 0.001066, 0.19324, 0.0010679, 0.060835, 0.049125]
Predicted label: 1
Correct prediction
Energy consumption = 151.436505 pJ
sum error= 335
Actual label: 2
Output voltages: [0.096053, 0.039148, 0.79865, 0.032033, 0.010131, 0.0011221, 0.049742, 0.20989, 0.46943, 0.029961]
Predicted label: 2
Correct prediction
Energy consumption = 133.463657 pJ
sum error= 335
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 812 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 812 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 812 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.22932, 0.0017058, 0.39262, 0.79856, 0.0042501, 0.016016, 0.0026678, 0.022339, 0.7692, 0.031181]
Predicted label: 3
Correct prediction
Energy consumption = 142.555942 pJ
sum error= 335
Actual label: 4
Output voltages: [0.013791, 0.006917, 0.40155, 0.028704, 0.79862, 0.0018663, 0.2986, 0.22467, 0.013055, 0.02045]
Predicted label: 4
Correct prediction
Energy consumption = 146.994382 pJ
sum error= 335
Actual label: 5
Output voltages: [0.010308, 0.0011018, 0.0015912, 0.40981, 0.021535, 0.79871, 0.38045, 0.072683, 0.7491, 0.02222]
Predicted label: 5
Correct prediction
Energy consumption = 152.555137 pJ
sum error= 335
Actual label: 6
Output voltages: [0.031963, 0.01307, 0.37636, 0.001071, 0.46285, 0.077249, 0.79878, 0.001067, 0.31517, 0.016606]
Predicted label: 6
Correct prediction
Energy consumption = 138.967295 pJ
sum error= 335
Actual label: 7
Output voltages: [0.21065, 0.034275, 0.084889, 0.19756, 0.045349, 0.0010849, 0.0011609, 0.79871, 0.041947, 0.11432]
Predicted label: 7
Correct prediction
Energy consumption = 158.527033 pJ
sum error= 335
Actual label: 8
Output voltages: [0.050882, 0.015505, 0.73111, 0.0022131, 0.092584, 0.0017575, 0.040765, 0.0025617, 0.79879, 0.28237]
Predicted label: 8
Correct prediction
Energy consumption = 142.442300 pJ
sum error= 335
Actual label: 9
Output voltages: [0.22885, 0.0055148, 0.0036427, 0.11782, 0.18623, 0.50833, 0.0059223, 0.025834, 0.28989, 0.78706]
Predicted label: 9
Correct prediction
Energy consumption = 147.007443 pJ
sum error= 335
Actual label: 0
Output voltages: [0.79879, 0.14271, 0.019566, 0.021697, 0.02275, 0.032066, 0.74018, 0.011593, 0.18067, 0.020978]
Predicted label: 0
Correct prediction
Energy consumption = 150.093693 pJ
sum error= 335
Actual label: 1
Output voltages: [0.054517, 0.79544, 0.12519, 0.15357, 0.10357, 0.0073652, 0.79286, 0.0011481, 0.56846, 0.019913]
Predicted label: 1
Correct prediction
Energy consumption = 152.470810 pJ
sum error= 335
Actual label: 2
Output voltages: [0.3613, 0.12502, 0.79877, 0.41087, 0.023212, 0.0010659, 0.02394, 0.13691, 0.25341, 0.052065]
Predicted label: 2
Correct prediction
Energy consumption = 135.698418 pJ
sum error= 335
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 813 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 813 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 813 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.26874, 0.018977, 0.060548, 0.79865, 0.016399, 0.025618, 0.007819, 0.02378, 0.71762, 0.0514]
Predicted label: 3
Correct prediction
Energy consumption = 145.428240 pJ
sum error= 335
Actual label: 4
Output voltages: [0.0032507, 0.0012114, 0.033118, 0.019895, 0.79861, 0.010863, 0.040488, 0.022004, 0.1658, 0.023289]
Predicted label: 4
Correct prediction
Energy consumption = 150.172729 pJ
sum error= 335
Actual label: 5
Output voltages: [0.16756, 0.0011373, 0.0015457, 0.45335, 0.088108, 0.79878, 0.39012, 0.034492, 0.67408, 0.0018317]
Predicted label: 5
Correct prediction
Energy consumption = 139.164657 pJ
sum error= 335
Actual label: 6
Output voltages: [0.064623, 0.18422, 0.42902, 0.001504, 0.36721, 0.0188, 0.79875, 0.001066, 0.49418, 0.017908]
Predicted label: 6
Correct prediction
Energy consumption = 140.650339 pJ
sum error= 335
Actual label: 7
Output voltages: [0.052348, 0.036912, 0.39212, 0.015867, 0.024258, 0.0010703, 0.0017948, 0.79852, 0.14983, 0.058128]
Predicted label: 7
Correct prediction
Energy consumption = 157.043783 pJ
sum error= 335
Actual label: 8
Output voltages: [0.019629, 0.01334, 0.34859, 0.02234, 0.029962, 0.015108, 0.045816, 0.0095729, 0.79879, 0.20386]
Predicted label: 8
Correct prediction
Energy consumption = 149.170728 pJ
sum error= 335
Actual label: 9
Output voltages: [0.49561, 0.0071521, 0.01635, 0.04627, 0.43908, 0.036317, 0.01063, 0.070729, 0.54668, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 145.078660 pJ
sum error= 335
Actual label: 0
Output voltages: [0.79876, 0.22309, 0.030845, 0.042488, 0.0084653, 0.022723, 0.3023, 0.00947, 0.13144, 0.23854]
Predicted label: 0
Correct prediction
Energy consumption = 144.161601 pJ
sum error= 335
Actual label: 1
Output voltages: [0.021482, 0.79863, 0.048638, 0.036473, 0.051023, 0.0014747, 0.69092, 0.0010973, 0.28707, 0.073433]
Predicted label: 1
Correct prediction
Energy consumption = 152.357420 pJ
sum error= 335
Actual label: 2
Output voltages: [0.17214, 0.009718, 0.79872, 0.20208, 0.0060643, 0.0011193, 0.019535, 0.2633, 0.60703, 0.0081078]
Predicted label: 2
Correct prediction
Energy consumption = 138.442106 pJ
sum error= 335
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 814 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 814 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 814 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.54801, 0.0010741, 0.52973, 0.79818, 0.004595, 0.079054, 0.0018266, 0.027663, 0.77168, 0.0024408]
Predicted label: 3
Correct prediction
Energy consumption = 141.716527 pJ
sum error= 335
Actual label: 4
Output voltages: [0.033537, 0.0011678, 0.31679, 0.020027, 0.7987, 0.001111, 0.0070123, 0.0057018, 0.23759, 0.042968]
Predicted label: 4
Correct prediction
Energy consumption = 141.531637 pJ
sum error= 335
Actual label: 5
Output voltages: [0.20613, 0.0010665, 0.0011435, 0.3819, 0.046399, 0.79879, 0.1735, 0.008757, 0.60371, 0.020089]
Predicted label: 5
Correct prediction
Energy consumption = 138.303774 pJ
sum error= 335
Actual label: 6
Output voltages: [0.15441, 0.0054676, 0.0022342, 0.019627, 0.068623, 0.70628, 0.79791, 0.0010678, 0.54224, 0.008421]
Predicted label: 6
Correct prediction
Energy consumption = 133.506024 pJ
sum error= 335
Actual label: 7
Output voltages: [0.021591, 0.042569, 0.76113, 0.1343, 0.0070231, 0.0010769, 0.0010807, 0.79879, 0.27944, 0.23422]
Predicted label: 7
Correct prediction
Energy consumption = 154.478230 pJ
sum error= 335
Actual label: 8
Output voltages: [0.0072354, 0.011711, 0.042155, 0.32161, 0.0015577, 0.52475, 0.048615, 0.011928, 0.79876, 0.030144]
Predicted label: 8
Correct prediction
Energy consumption = 146.211944 pJ
sum error= 335
Actual label: 9
Output voltages: [0.3341, 0.016645, 0.011402, 0.040936, 0.10594, 0.0090952, 0.0010867, 0.013456, 0.45541, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 146.496899 pJ
sum error= 335
Actual label: 8
Output voltages: [0.020987, 0.036159, 0.35826, 0.087777, 0.031584, 0.010123, 0.024917, 0.012087, 0.79873, 0.043041]
Predicted label: 8
Correct prediction
Energy consumption = 141.021092 pJ
sum error= 335
Actual label: 6
Output voltages: [0.063937, 0.049935, 0.051582, 0.021476, 0.15559, 0.39799, 0.79878, 0.0010707, 0.59107, 0.036466]
Predicted label: 6
Correct prediction
Energy consumption = 143.186107 pJ
sum error= 335
Actual label: 5
Output voltages: [0.06378, 0.0011385, 0.0088194, 0.07236, 0.12311, 0.79879, 0.030625, 0.027287, 0.77191, 0.059045]
Predicted label: 5
Correct prediction
Energy consumption = 145.404451 pJ
sum error= 335
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 815 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 815 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 815 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.061882, 0.0058088, 0.019762, 0.037836, 0.064549, 0.033746, 0.0028354, 0.2326, 0.73429, 0.78704]
Predicted label: 9
Correct prediction
Energy consumption = 152.327752 pJ
sum error= 335
Actual label: 7
Output voltages: [0.097605, 0.050351, 0.7455, 0.047937, 0.0020792, 0.0010731, 0.0010858, 0.79878, 0.43169, 0.31146]
Predicted label: 7
Correct prediction
Energy consumption = 149.280019 pJ
sum error= 335
Actual label: 0
Output voltages: [0.79879, 0.069247, 0.047079, 0.013515, 0.0066617, 0.0029031, 0.44315, 0.0075325, 0.051462, 0.031127]
Predicted label: 0
Correct prediction
Energy consumption = 146.824304 pJ
sum error= 335
Actual label: 2
Output voltages: [0.28958, 0.014141, 0.7987, 0.092096, 0.012924, 0.0011169, 0.018592, 0.031849, 0.65821, 0.010915]
Predicted label: 2
Correct prediction
Energy consumption = 140.762391 pJ
sum error= 335
Actual label: 3
Output voltages: [0.38302, 0.021905, 0.11815, 0.79862, 0.025288, 0.036748, 0.012265, 0.038187, 0.65154, 0.16396]
Predicted label: 3
Correct prediction
Energy consumption = 139.027659 pJ
sum error= 335
Actual label: 4
Output voltages: [0.0073926, 0.020157, 0.25211, 0.02926, 0.79862, 0.0026296, 0.237, 0.1479, 0.0091486, 0.024824]
Predicted label: 4
Correct prediction
Energy consumption = 152.942971 pJ
sum error= 335
Actual label: 3
Output voltages: [0.0096965, 0.16289, 0.066479, 0.79223, 0.0073737, 0.039032, 0.011568, 0.0042631, 0.73815, 0.62949]
Predicted label: 3
Correct prediction
Energy consumption = 140.128385 pJ
sum error= 335
Actual label: 8
Output voltages: [0.0042715, 0.040159, 0.038126, 0.0284, 0.018519, 0.027649, 0.035185, 0.0035982, 0.79879, 0.3094]
Predicted label: 8
Correct prediction
Energy consumption = 142.211907 pJ
sum error= 335
Actual label: 5
Output voltages: [0.32255, 0.0011111, 0.001467, 0.17978, 0.043112, 0.79877, 0.26167, 0.012949, 0.49767, 0.0043478]
Predicted label: 5
Correct prediction
Energy consumption = 137.472312 pJ
sum error= 335
Actual label: 1
Output voltages: [0.013426, 0.79879, 0.1779, 0.042927, 0.076722, 0.0011089, 0.60237, 0.065326, 0.034585, 0.041442]
Predicted label: 1
Correct prediction
Energy consumption = 159.001302 pJ
sum error= 335
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 816 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 816 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 816 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.3493, 0.0022211, 0.0011065, 0.43563, 0.044535, 0.7976, 0.036792, 0.010163, 0.49025, 0.066013]
Predicted label: 5
Correct prediction
Energy consumption = 144.711054 pJ
sum error= 335
Actual label: 2
Output voltages: [0.20113, 0.026636, 0.7987, 0.23041, 0.040062, 0.0011252, 0.02769, 0.12588, 0.48341, 0.055724]
Predicted label: 2
Correct prediction
Energy consumption = 148.026663 pJ
sum error= 335
Actual label: 3
Output voltages: [0.13276, 0.0095077, 0.20778, 0.79867, 0.010811, 0.0072094, 0.012195, 0.037324, 0.65485, 0.038262]
Predicted label: 3
Correct prediction
Energy consumption = 138.275531 pJ
sum error= 335
Actual label: 0
Output voltages: [0.79865, 0.04693, 0.030858, 0.0088656, 0.0086657, 0.003336, 0.71055, 0.014635, 0.16634, 0.037389]
Predicted label: 0
Correct prediction
Energy consumption = 140.864417 pJ
sum error= 335
Actual label: 1
Output voltages: [0.056475, 0.79747, 0.29573, 0.037366, 0.37311, 0.0010717, 0.49222, 0.0022187, 0.042083, 0.0032668]
Predicted label: 1
Correct prediction
Energy consumption = 153.065557 pJ
sum error= 335
Actual label: 2
Output voltages: [0.058666, 0.27052, 0.79866, 0.12035, 0.034152, 0.0011857, 0.053316, 0.25139, 0.027092, 0.025222]
Predicted label: 2
Correct prediction
Energy consumption = 132.687215 pJ
sum error= 335
Actual label: 1
Output voltages: [0.065473, 0.79864, 0.045496, 0.014554, 0.21997, 0.0014182, 0.3035, 0.0010791, 0.16951, 0.077723]
Predicted label: 1
Correct prediction
Energy consumption = 155.131210 pJ
sum error= 335
Actual label: 3
Output voltages: [0.11592, 0.023467, 0.14126, 0.79862, 0.050676, 0.01358, 0.017147, 0.028337, 0.66023, 0.069016]
Predicted label: 3
Correct prediction
Energy consumption = 148.944033 pJ
sum error= 335
Actual label: 2
Output voltages: [0.29755, 0.15677, 0.7987, 0.33256, 0.011945, 0.0012511, 0.16364, 0.023338, 0.20209, 0.028813]
Predicted label: 2
Correct prediction
Energy consumption = 132.083850 pJ
sum error= 335
Actual label: 6
Output voltages: [0.20195, 0.022307, 0.20944, 0.0042369, 0.31862, 0.16551, 0.79873, 0.001746, 0.71854, 0.030823]
Predicted label: 6
Correct prediction
Energy consumption = 140.980495 pJ
sum error= 335
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 817 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 817 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 817 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.046904, 0.001302, 0.0010947, 0.23247, 0.038442, 0.79871, 0.44921, 0.047787, 0.63225, 0.0025449]
Predicted label: 5
Correct prediction
Energy consumption = 132.236921 pJ
sum error= 335
Actual label: 3
Output voltages: [0.051031, 0.0023969, 0.041536, 0.79878, 0.040068, 0.01329, 0.0016314, 0.028525, 0.72503, 0.0514]
Predicted label: 3
Correct prediction
Energy consumption = 144.123123 pJ
sum error= 335
Actual label: 0
Output voltages: [0.79878, 0.080204, 0.10753, 0.0095932, 0.0072382, 0.0029434, 0.43453, 0.027753, 0.062981, 0.061842]
Predicted label: 0
Correct prediction
Energy consumption = 146.747488 pJ
sum error= 335
Actual label: 7
Output voltages: [0.22373, 0.043697, 0.72395, 0.032046, 0.0077043, 0.0010679, 0.0010852, 0.79867, 0.3554, 0.21835]
Predicted label: 7
Correct prediction
Energy consumption = 145.246769 pJ
sum error= 335
Actual label: 2
Output voltages: [0.719, 0.0010805, 0.79342, 0.52448, 0.032343, 0.0010775, 0.011579, 0.1032, 0.77911, 0.049124]
Predicted label: 2
Correct prediction
Energy consumption = 135.152893 pJ
sum error= 335
Actual label: 7
Output voltages: [0.051098, 0.2081, 0.59926, 0.12218, 0.0051027, 0.0010801, 0.0010766, 0.79875, 0.18287, 0.35743]
Predicted label: 7
Correct prediction
Energy consumption = 145.312419 pJ
sum error= 335
Actual label: 4
Output voltages: [0.017732, 0.01189, 0.058041, 0.0013276, 0.79871, 0.0027441, 0.18745, 0.35291, 0.11257, 0.009109]
Predicted label: 4
Correct prediction
Energy consumption = 145.896360 pJ
sum error= 335
Actual label: 6
Output voltages: [0.06272, 0.01338, 0.16926, 0.0027743, 0.42019, 0.11004, 0.79875, 0.0013778, 0.55331, 0.017144]
Predicted label: 6
Correct prediction
Energy consumption = 141.907696 pJ
sum error= 335
Actual label: 4
Output voltages: [0.024685, 0.0076491, 0.20524, 0.005541, 0.79859, 0.010756, 0.05533, 0.090748, 0.045771, 0.011548]
Predicted label: 4
Correct prediction
Energy consumption = 141.718570 pJ
sum error= 335
Actual label: 0
Output voltages: [0.79866, 0.034571, 0.27985, 0.020108, 0.0054244, 0.0034666, 0.29811, 0.02219, 0.033109, 0.034313]
Predicted label: 0
Correct prediction
Energy consumption = 148.270762 pJ
sum error= 335
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 818 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 818 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 818 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.026504, 0.00109, 0.0010682, 0.16017, 0.037885, 0.79875, 0.42698, 0.061538, 0.7642, 0.0064922]
Predicted label: 5
Correct prediction
Energy consumption = 142.457656 pJ
sum error= 335
Actual label: 9
Output voltages: [0.24965, 0.002106, 0.022803, 0.021388, 0.04299, 0.1802, 0.0035359, 0.0040329, 0.56608, 0.7882]
Predicted label: 9
Correct prediction
Energy consumption = 142.621703 pJ
sum error= 335
Actual label: 9
Output voltages: [0.78937, 0.0012568, 0.016448, 0.030802, 0.44238, 0.011076, 0.014321, 0.0011473, 0.3364, 0.78669]
Predicted label: 0
Wrong prediction!
Energy consumption = 133.742266 pJ
sum error= 336
Actual label: 8
Output voltages: [0.047282, 0.0012498, 0.0011421, 0.57182, 0.014419, 0.73706, 0.19533, 0.0013397, 0.78501, 0.013684]
Predicted label: 8
Correct prediction
Energy consumption = 142.535401 pJ
sum error= 336
Actual label: 9
Output voltages: [0.21026, 0.010079, 0.012042, 0.025349, 0.10993, 0.013496, 0.0017789, 0.012435, 0.61545, 0.79579]
Predicted label: 9
Correct prediction
Energy consumption = 139.052511 pJ
sum error= 336
Actual label: 5
Output voltages: [0.020337, 0.0010659, 0.012523, 0.48432, 0.010435, 0.77583, 0.049703, 0.0055247, 0.76343, 0.21039]
Predicted label: 5
Correct prediction
Energy consumption = 147.591353 pJ
sum error= 336
Actual label: 3
Output voltages: [0.14785, 0.004184, 0.013221, 0.79871, 0.040268, 0.036983, 0.001789, 0.063691, 0.7041, 0.048972]
Predicted label: 3
Correct prediction
Energy consumption = 131.599904 pJ
sum error= 336
Actual label: 1
Output voltages: [0.013277, 0.79879, 0.034798, 0.014993, 0.48594, 0.0010736, 0.064985, 0.027909, 0.041317, 0.0094846]
Predicted label: 1
Correct prediction
Energy consumption = 150.616339 pJ
sum error= 336
Actual label: 7
Output voltages: [0.045027, 0.18351, 0.27998, 0.019677, 0.0017604, 0.0016295, 0.0012788, 0.79866, 0.41528, 0.061653]
Predicted label: 7
Correct prediction
Energy consumption = 151.944967 pJ
sum error= 336
Actual label: 4
Output voltages: [0.0020546, 0.015454, 0.078555, 0.018181, 0.79866, 0.0033833, 0.25004, 0.45281, 0.013881, 0.026291]
Predicted label: 4
Correct prediction
Energy consumption = 144.786565 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 819 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 819 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 819 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.10514, 0.14394, 0.60716, 0.0553, 0.0085267, 0.0010665, 0.0018109, 0.79879, 0.2686, 0.47319]
Predicted label: 7
Correct prediction
Energy consumption = 148.300335 pJ
sum error= 336
Actual label: 6
Output voltages: [0.14819, 0.058386, 0.37676, 0.0010757, 0.41085, 0.082021, 0.79876, 0.0010704, 0.55517, 0.0053574]
Predicted label: 6
Correct prediction
Energy consumption = 148.015518 pJ
sum error= 336
Actual label: 5
Output voltages: [0.045762, 0.0011176, 0.0015053, 0.25368, 0.04893, 0.79877, 0.30327, 0.24796, 0.77165, 0.0062339]
Predicted label: 5
Correct prediction
Energy consumption = 138.782468 pJ
sum error= 336
Actual label: 4
Output voltages: [0.012407, 0.010432, 0.37775, 0.0023947, 0.7986, 0.015628, 0.15232, 0.1368, 0.040686, 0.029358]
Predicted label: 4
Correct prediction
Energy consumption = 144.003233 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79876, 0.018668, 0.46656, 0.022004, 0.037044, 0.0012094, 0.37536, 0.21774, 0.16582, 0.03242]
Predicted label: 0
Correct prediction
Energy consumption = 145.382808 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79878, 0.13905, 0.020449, 0.012726, 0.01182, 0.0035656, 0.64436, 0.017509, 0.21229, 0.05023]
Predicted label: 0
Correct prediction
Energy consumption = 131.165154 pJ
sum error= 336
Actual label: 6
Output voltages: [0.28544, 0.02369, 0.29241, 0.0011421, 0.12206, 0.059746, 0.79834, 0.0010934, 0.26518, 0.0038685]
Predicted label: 6
Correct prediction
Energy consumption = 130.309475 pJ
sum error= 336
Actual label: 6
Output voltages: [0.20413, 0.0027366, 0.047073, 0.0019044, 0.16127, 0.67661, 0.79699, 0.0010867, 0.60911, 0.013962]
Predicted label: 6
Correct prediction
Energy consumption = 130.552549 pJ
sum error= 336
Actual label: 2
Output voltages: [0.026317, 0.019409, 0.79863, 0.17476, 0.038198, 0.0010661, 0.020405, 0.26659, 0.25472, 0.028264]
Predicted label: 2
Correct prediction
Energy consumption = 132.731787 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79876, 0.12235, 0.039078, 0.014275, 0.0029399, 0.0084401, 0.63919, 0.058155, 0.14253, 0.049833]
Predicted label: 0
Correct prediction
Energy consumption = 138.847767 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 820 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 820 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 820 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.10602, 0.019562, 0.4911, 0.0010661, 0.33129, 0.17187, 0.79879, 0.0010697, 0.69284, 0.01244]
Predicted label: 6
Correct prediction
Energy consumption = 144.318318 pJ
sum error= 336
Actual label: 3
Output voltages: [0.42053, 0.0058379, 0.1709, 0.79879, 0.024999, 0.18789, 0.0027853, 0.015233, 0.73945, 0.20231]
Predicted label: 3
Correct prediction
Energy consumption = 142.425573 pJ
sum error= 336
Actual label: 7
Output voltages: [0.054918, 0.4795, 0.52192, 0.14093, 0.034452, 0.0011195, 0.001143, 0.79879, 0.032658, 0.10751]
Predicted label: 7
Correct prediction
Energy consumption = 149.934805 pJ
sum error= 336
Actual label: 7
Output voltages: [0.76443, 0.019351, 0.015651, 0.030749, 0.18373, 0.0045603, 0.0011216, 0.79876, 0.32884, 0.013724]
Predicted label: 7
Correct prediction
Energy consumption = 138.992695 pJ
sum error= 336
Actual label: 4
Output voltages: [0.072574, 0.0042297, 0.40253, 0.065452, 0.79879, 0.0011757, 0.024703, 0.027614, 0.013924, 0.038247]
Predicted label: 4
Correct prediction
Energy consumption = 146.866641 pJ
sum error= 336
Actual label: 4
Output voltages: [0.001157, 0.11543, 0.18418, 0.028731, 0.79873, 0.0015636, 0.054249, 0.58143, 0.010855, 0.034602]
Predicted label: 4
Correct prediction
Energy consumption = 138.416955 pJ
sum error= 336
Actual label: 3
Output voltages: [0.23691, 0.014006, 0.11045, 0.79866, 0.034916, 0.017051, 0.011865, 0.030958, 0.65358, 0.057215]
Predicted label: 3
Correct prediction
Energy consumption = 142.221473 pJ
sum error= 336
Actual label: 9
Output voltages: [0.32225, 0.0095225, 0.0232, 0.13201, 0.081542, 0.019105, 0.0021263, 0.039435, 0.69159, 0.79747]
Predicted label: 9
Correct prediction
Energy consumption = 143.503107 pJ
sum error= 336
Actual label: 2
Output voltages: [0.37672, 0.0085312, 0.79863, 0.032089, 0.0080231, 0.0010876, 0.035899, 0.070121, 0.64181, 0.0026956]
Predicted label: 2
Correct prediction
Energy consumption = 136.051980 pJ
sum error= 336
Actual label: 8
Output voltages: [0.096884, 0.0047947, 0.40302, 0.024903, 0.070473, 0.01586, 0.14434, 0.001973, 0.79879, 0.020772]
Predicted label: 8
Correct prediction
Energy consumption = 151.244498 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 821 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 821 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 821 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.099536, 0.024721, 0.0073692, 0.21935, 0.74542, 0.35632, 0.2798, 0.0041809, 0.070403, 0.79703]
Predicted label: 9
Correct prediction
Energy consumption = 154.600410 pJ
sum error= 336
Actual label: 6
Output voltages: [0.076214, 0.18426, 0.23843, 0.0046379, 0.25688, 0.18654, 0.79871, 0.0010867, 0.4628, 0.012408]
Predicted label: 6
Correct prediction
Energy consumption = 143.891856 pJ
sum error= 336
Actual label: 0
Output voltages: [0.7886, 0.025114, 0.11898, 0.002141, 0.0021414, 0.0014143, 0.72718, 0.44624, 0.062253, 0.22105]
Predicted label: 0
Correct prediction
Energy consumption = 134.305701 pJ
sum error= 336
Actual label: 9
Output voltages: [0.63633, 0.010546, 0.040348, 0.024991, 0.64879, 0.0091579, 0.011814, 0.0018529, 0.053614, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 140.643394 pJ
sum error= 336
Actual label: 5
Output voltages: [0.045225, 0.0012259, 0.0010678, 0.076865, 0.1529, 0.79878, 0.23488, 0.035762, 0.77156, 0.019143]
Predicted label: 5
Correct prediction
Energy consumption = 143.081486 pJ
sum error= 336
Actual label: 3
Output voltages: [0.1901, 0.0045239, 0.063719, 0.79876, 0.013613, 0.03188, 0.0037832, 0.042368, 0.74139, 0.062828]
Predicted label: 3
Correct prediction
Energy consumption = 138.206297 pJ
sum error= 336
Actual label: 8
Output voltages: [0.036429, 0.025834, 0.22028, 0.37625, 0.014251, 0.012074, 0.070258, 0.0014076, 0.79873, 0.048716]
Predicted label: 8
Correct prediction
Energy consumption = 148.237104 pJ
sum error= 336
Actual label: 8
Output voltages: [0.081485, 0.027086, 0.16645, 0.21046, 0.0043192, 0.030125, 0.021573, 0.0016046, 0.79874, 0.58065]
Predicted label: 8
Correct prediction
Energy consumption = 141.493832 pJ
sum error= 336
Actual label: 7
Output voltages: [0.104, 0.24631, 0.71635, 0.054282, 0.0071213, 0.0012801, 0.005432, 0.79871, 0.055978, 0.26263]
Predicted label: 7
Correct prediction
Energy consumption = 152.994546 pJ
sum error= 336
Actual label: 1
Output voltages: [0.028586, 0.79863, 0.46002, 0.0081587, 0.27003, 0.0010969, 0.34471, 0.0068426, 0.038984, 0.040684]
Predicted label: 1
Correct prediction
Energy consumption = 148.890869 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 822 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 822 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 822 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.017733, 0.011467, 0.11915, 0.0099409, 0.79873, 0.001597, 0.038833, 0.073813, 0.021708, 0.0053389]
Predicted label: 4
Correct prediction
Energy consumption = 149.140010 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79873, 0.13037, 0.033095, 0.014563, 0.016223, 0.0068709, 0.56752, 0.02703, 0.19394, 0.026378]
Predicted label: 0
Correct prediction
Energy consumption = 148.807898 pJ
sum error= 336
Actual label: 4
Output voltages: [0.022829, 0.015065, 0.35769, 0.10216, 0.79878, 0.0021668, 0.10578, 0.048458, 0.010216, 0.055287]
Predicted label: 4
Correct prediction
Energy consumption = 151.776096 pJ
sum error= 336
Actual label: 8
Output voltages: [0.018356, 0.0084747, 0.46717, 0.039799, 0.02956, 0.011907, 0.26214, 0.0038166, 0.79879, 0.016844]
Predicted label: 8
Correct prediction
Energy consumption = 144.882249 pJ
sum error= 336
Actual label: 5
Output voltages: [0.24728, 0.0010774, 0.0021086, 0.41277, 0.010144, 0.79871, 0.27677, 0.027517, 0.76773, 0.0041919]
Predicted label: 5
Correct prediction
Energy consumption = 140.754013 pJ
sum error= 336
Actual label: 2
Output voltages: [0.14511, 0.026612, 0.79866, 0.12178, 0.0027473, 0.0010953, 0.025775, 0.22051, 0.52278, 0.0040565]
Predicted label: 2
Correct prediction
Energy consumption = 134.615179 pJ
sum error= 336
Actual label: 3
Output voltages: [0.43139, 0.0025518, 0.36697, 0.79878, 0.010235, 0.0013156, 0.012822, 0.0037856, 0.71617, 0.0088965]
Predicted label: 3
Correct prediction
Energy consumption = 139.983452 pJ
sum error= 336
Actual label: 9
Output voltages: [0.60426, 0.0097918, 0.023244, 0.052684, 0.3059, 0.033153, 0.0034454, 0.022459, 0.29228, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 138.335436 pJ
sum error= 336
Actual label: 0
Output voltages: [0.77845, 0.014912, 0.27206, 0.036846, 0.73091, 0.001325, 0.63744, 0.014203, 0.20313, 0.04075]
Predicted label: 0
Correct prediction
Energy consumption = 150.866228 pJ
sum error= 336
Actual label: 1
Output voltages: [0.23267, 0.79604, 0.050925, 0.0048135, 0.61005, 0.0077646, 0.27903, 0.0010893, 0.53861, 0.020593]
Predicted label: 1
Correct prediction
Energy consumption = 145.511944 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 823 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 823 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 823 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.65862, 0.014922, 0.0046412, 0.040512, 0.081106, 0.030149, 0.011245, 0.022368, 0.37772, 0.79667]
Predicted label: 9
Correct prediction
Energy consumption = 145.985565 pJ
sum error= 336
Actual label: 1
Output voltages: [0.0080776, 0.79878, 0.30766, 0.012054, 0.040683, 0.0013054, 0.57358, 0.0010671, 0.23368, 0.022548]
Predicted label: 1
Correct prediction
Energy consumption = 149.776963 pJ
sum error= 336
Actual label: 5
Output voltages: [0.16649, 0.0011776, 0.0010804, 0.56286, 0.043481, 0.79877, 0.1353, 0.0066215, 0.5222, 0.041019]
Predicted label: 5
Correct prediction
Energy consumption = 145.014436 pJ
sum error= 336
Actual label: 1
Output voltages: [0.036971, 0.79879, 0.14507, 0.028432, 0.42593, 0.010352, 0.74928, 0.0013358, 0.29181, 0.013701]
Predicted label: 1
Correct prediction
Energy consumption = 156.386160 pJ
sum error= 336
Actual label: 7
Output voltages: [0.040253, 0.23493, 0.65346, 0.044377, 0.013184, 0.0010665, 0.0011237, 0.7987, 0.27282, 0.098127]
Predicted label: 7
Correct prediction
Energy consumption = 151.693087 pJ
sum error= 336
Actual label: 4
Output voltages: [0.021169, 0.0057862, 0.43359, 0.0012954, 0.79874, 0.0019341, 0.11402, 0.26381, 0.022852, 0.045557]
Predicted label: 4
Correct prediction
Energy consumption = 141.157027 pJ
sum error= 336
Actual label: 8
Output voltages: [0.0045546, 0.058845, 0.14871, 0.010145, 0.31076, 0.04592, 0.69946, 0.018917, 0.79488, 0.031967]
Predicted label: 8
Correct prediction
Energy consumption = 139.999486 pJ
sum error= 336
Actual label: 6
Output voltages: [0.14864, 0.12897, 0.30498, 0.019687, 0.22205, 0.063206, 0.79879, 0.0010992, 0.55084, 0.05033]
Predicted label: 6
Correct prediction
Energy consumption = 142.507508 pJ
sum error= 336
Actual label: 2
Output voltages: [0.27342, 0.016609, 0.79866, 0.067658, 0.012794, 0.0010977, 0.049708, 0.17346, 0.46858, 0.018701]
Predicted label: 2
Correct prediction
Energy consumption = 135.450774 pJ
sum error= 336
Actual label: 1
Output voltages: [0.073414, 0.79775, 0.01103, 0.047098, 0.74436, 0.0041645, 0.70473, 0.0011159, 0.54, 0.13718]
Predicted label: 1
Correct prediction
Energy consumption = 151.741263 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 824 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 824 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 824 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.068202, 0.0034178, 0.083103, 0.0069597, 0.45712, 0.39717, 0.79858, 0.0010723, 0.75125, 0.0091774]
Predicted label: 6
Correct prediction
Energy consumption = 143.937326 pJ
sum error= 336
Actual label: 8
Output voltages: [0.28317, 0.17471, 0.59266, 0.016487, 0.25952, 0.0024825, 0.13225, 0.0012221, 0.79852, 0.21501]
Predicted label: 8
Correct prediction
Energy consumption = 150.303491 pJ
sum error= 336
Actual label: 8
Output voltages: [0.055287, 0.014576, 0.06037, 0.026265, 0.038034, 0.18807, 0.04511, 0.017205, 0.79879, 0.023385]
Predicted label: 8
Correct prediction
Energy consumption = 143.103554 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79723, 0.0012343, 0.13351, 0.001068, 0.25112, 0.0082143, 0.72068, 0.25883, 0.042543, 0.0067879]
Predicted label: 0
Correct prediction
Energy consumption = 149.290914 pJ
sum error= 336
Actual label: 1
Output voltages: [0.0070477, 0.79808, 0.045915, 0.0097882, 0.72728, 0.0058846, 0.24878, 0.0010667, 0.19479, 0.20817]
Predicted label: 1
Correct prediction
Energy consumption = 145.580510 pJ
sum error= 336
Actual label: 2
Output voltages: [0.12607, 0.031523, 0.79863, 0.039611, 0.029227, 0.0011566, 0.035884, 0.27665, 0.21625, 0.025983]
Predicted label: 2
Correct prediction
Energy consumption = 132.573787 pJ
sum error= 336
Actual label: 3
Output voltages: [0.061454, 0.006025, 0.032705, 0.79707, 0.050131, 0.57954, 0.0042112, 0.0037351, 0.74589, 0.39644]
Predicted label: 3
Correct prediction
Energy consumption = 141.122442 pJ
sum error= 336
Actual label: 4
Output voltages: [0.010589, 0.0085149, 0.14394, 0.0014334, 0.79878, 0.005229, 0.24063, 0.28759, 0.44763, 0.001556]
Predicted label: 4
Correct prediction
Energy consumption = 140.975582 pJ
sum error= 336
Actual label: 7
Output voltages: [0.097635, 0.11976, 0.27318, 0.080407, 0.0016872, 0.0011951, 0.0010692, 0.79874, 0.62373, 0.029544]
Predicted label: 7
Correct prediction
Energy consumption = 148.279343 pJ
sum error= 336
Actual label: 8
Output voltages: [0.11875, 0.042994, 0.37757, 0.01615, 0.008915, 0.012004, 0.017366, 0.0066699, 0.79876, 0.20307]
Predicted label: 8
Correct prediction
Energy consumption = 137.294080 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 825 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 825 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 825 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.47382, 0.012048, 0.029919, 0.041678, 0.26156, 0.027312, 0.007265, 0.010153, 0.28173, 0.79867]
Predicted label: 9
Correct prediction
Energy consumption = 145.119108 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79871, 0.19008, 0.027266, 0.03001, 0.030343, 0.0070274, 0.51656, 0.0064626, 0.069379, 0.03001]
Predicted label: 0
Correct prediction
Energy consumption = 146.950045 pJ
sum error= 336
Actual label: 1
Output voltages: [0.014907, 0.79866, 0.2059, 0.014991, 0.46126, 0.0024121, 0.063523, 0.015708, 0.015524, 0.048811]
Predicted label: 1
Correct prediction
Energy consumption = 152.181735 pJ
sum error= 336
Actual label: 2
Output voltages: [0.038785, 0.034638, 0.79861, 0.065194, 0.036451, 0.0011016, 0.031042, 0.040442, 0.36056, 0.19048]
Predicted label: 2
Correct prediction
Energy consumption = 132.717908 pJ
sum error= 336
Actual label: 3
Output voltages: [0.18096, 0.022786, 0.31508, 0.79877, 0.0042162, 0.017282, 0.032418, 0.030778, 0.78228, 0.0025204]
Predicted label: 3
Correct prediction
Energy consumption = 140.738674 pJ
sum error= 336
Actual label: 4
Output voltages: [0.015914, 0.0013277, 0.41551, 0.018479, 0.79729, 0.004082, 0.25227, 0.016973, 0.59086, 0.0012046]
Predicted label: 4
Correct prediction
Energy consumption = 140.092654 pJ
sum error= 336
Actual label: 6
Output voltages: [0.041577, 0.019033, 0.2926, 0.0071696, 0.74294, 0.13134, 0.79878, 0.0016509, 0.44122, 0.0056456]
Predicted label: 6
Correct prediction
Energy consumption = 133.476207 pJ
sum error= 336
Actual label: 7
Output voltages: [0.033252, 0.021653, 0.76856, 0.022776, 0.0025401, 0.001066, 0.001073, 0.79864, 0.58841, 0.059517]
Predicted label: 7
Correct prediction
Energy consumption = 156.267679 pJ
sum error= 336
Actual label: 8
Output voltages: [0.02382, 0.0039893, 0.027559, 0.047143, 0.011387, 0.097228, 0.015048, 0.018181, 0.7987, 0.011977]
Predicted label: 8
Correct prediction
Energy consumption = 136.698526 pJ
sum error= 336
Actual label: 9
Output voltages: [0.19105, 0.0010926, 0.020924, 0.026798, 0.093421, 0.129, 0.0055927, 0.4918, 0.75261, 0.79649]
Predicted label: 9
Correct prediction
Energy consumption = 142.340498 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 826 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 826 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 826 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79845, 0.013463, 0.23235, 0.0067192, 0.058339, 0.0027211, 0.4531, 0.031199, 0.0193, 0.51462]
Predicted label: 0
Correct prediction
Energy consumption = 140.636936 pJ
sum error= 336
Actual label: 1
Output voltages: [0.062056, 0.79879, 0.31551, 0.01657, 0.038338, 0.0041246, 0.75021, 0.0010743, 0.22092, 0.0030956]
Predicted label: 1
Correct prediction
Energy consumption = 151.572351 pJ
sum error= 336
Actual label: 2
Output voltages: [0.14752, 0.1447, 0.79879, 0.43252, 0.020659, 0.0011555, 0.0087202, 0.18918, 0.047818, 0.0074357]
Predicted label: 2
Correct prediction
Energy consumption = 132.683053 pJ
sum error= 336
Actual label: 3
Output voltages: [0.19835, 0.018084, 0.11804, 0.7987, 0.027748, 0.0021953, 0.0066531, 0.026727, 0.53953, 0.072884]
Predicted label: 3
Correct prediction
Energy consumption = 141.426371 pJ
sum error= 336
Actual label: 4
Output voltages: [0.042221, 0.0087922, 0.58939, 0.048126, 0.79805, 0.0011222, 0.024719, 0.030066, 0.25555, 0.0092016]
Predicted label: 4
Correct prediction
Energy consumption = 141.056551 pJ
sum error= 336
Actual label: 7
Output voltages: [0.42406, 0.0014499, 0.12486, 0.38465, 0.0010951, 0.010278, 0.0011873, 0.79795, 0.65108, 0.2945]
Predicted label: 7
Correct prediction
Energy consumption = 144.391489 pJ
sum error= 336
Actual label: 8
Output voltages: [0.018831, 0.019049, 0.043781, 0.017378, 0.015391, 0.054919, 0.022828, 0.017671, 0.7987, 0.0508]
Predicted label: 8
Correct prediction
Energy consumption = 140.697060 pJ
sum error= 336
Actual label: 9
Output voltages: [0.39856, 0.0013255, 0.029921, 0.012094, 0.45857, 0.054828, 0.0095056, 0.14363, 0.43309, 0.78936]
Predicted label: 9
Correct prediction
Energy consumption = 144.996186 pJ
sum error= 336
Actual label: 1
Output voltages: [0.0018536, 0.79872, 0.15986, 0.022193, 0.048543, 0.0010659, 0.35094, 0.0024601, 0.058047, 0.015685]
Predicted label: 1
Correct prediction
Energy consumption = 148.879308 pJ
sum error= 336
Actual label: 4
Output voltages: [0.0019586, 0.021812, 0.075599, 0.04956, 0.79865, 0.0020013, 0.015939, 0.049896, 0.028266, 0.021318]
Predicted label: 4
Correct prediction
Energy consumption = 149.405491 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 827 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 827 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 827 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.35313, 0.0031166, 0.0011139, 0.034268, 0.10992, 0.79877, 0.5477, 0.033823, 0.52577, 0.017909]
Predicted label: 5
Correct prediction
Energy consumption = 146.478440 pJ
sum error= 336
Actual label: 3
Output voltages: [0.03399, 0.0085577, 0.05105, 0.79879, 0.011348, 0.025188, 0.0030423, 0.075814, 0.69949, 0.05225]
Predicted label: 3
Correct prediction
Energy consumption = 144.095159 pJ
sum error= 336
Actual label: 3
Output voltages: [0.035145, 0.030984, 0.15767, 0.79879, 0.0052839, 0.007919, 0.0020343, 0.0076296, 0.74959, 0.017181]
Predicted label: 3
Correct prediction
Energy consumption = 133.026357 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79854, 0.0037343, 0.2933, 0.0021511, 0.011352, 0.0010698, 0.16261, 0.43534, 0.029706, 0.22166]
Predicted label: 0
Correct prediction
Energy consumption = 143.121198 pJ
sum error= 336
Actual label: 9
Output voltages: [0.32241, 0.0054433, 0.01829, 0.029554, 0.06404, 0.013911, 0.0092143, 0.013276, 0.73546, 0.79545]
Predicted label: 9
Correct prediction
Energy consumption = 132.814938 pJ
sum error= 336
Actual label: 5
Output voltages: [0.63763, 0.0012742, 0.0011356, 0.1272, 0.0037123, 0.79841, 0.51273, 0.014543, 0.58683, 0.0019338]
Predicted label: 5
Correct prediction
Energy consumption = 144.885156 pJ
sum error= 336
Actual label: 4
Output voltages: [0.011397, 0.010754, 0.54611, 0.0024438, 0.7986, 0.0015938, 0.052795, 0.031409, 0.3156, 0.022469]
Predicted label: 4
Correct prediction
Energy consumption = 147.508330 pJ
sum error= 336
Actual label: 3
Output voltages: [0.028244, 0.0097209, 0.034711, 0.79877, 0.071354, 0.21134, 0.011712, 0.024555, 0.52842, 0.045802]
Predicted label: 3
Correct prediction
Energy consumption = 142.182792 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79871, 0.0091439, 0.50945, 0.099383, 0.011875, 0.0018658, 0.027609, 0.011357, 0.028412, 0.36657]
Predicted label: 0
Correct prediction
Energy consumption = 134.162825 pJ
sum error= 336
Actual label: 8
Output voltages: [0.021882, 0.0029967, 0.16365, 0.017997, 0.0018105, 0.0063328, 0.050469, 0.52413, 0.79789, 0.023996]
Predicted label: 8
Correct prediction
Energy consumption = 141.025727 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 828 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 828 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 828 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.012465, 0.027368, 0.22572, 0.015107, 0.79875, 0.020337, 0.036286, 0.02606, 0.1914, 0.0058248]
Predicted label: 4
Correct prediction
Energy consumption = 148.422935 pJ
sum error= 336
Actual label: 6
Output voltages: [0.093445, 0.056535, 0.16791, 0.04897, 0.094449, 0.1696, 0.79603, 0.014319, 0.68865, 0.0010661]
Predicted label: 6
Correct prediction
Energy consumption = 142.848793 pJ
sum error= 336
Actual label: 7
Output voltages: [0.11081, 0.045529, 0.67139, 0.037816, 0.0028315, 0.0010874, 0.0010728, 0.79879, 0.59232, 0.21146]
Predicted label: 7
Correct prediction
Energy consumption = 142.679118 pJ
sum error= 336
Actual label: 0
Output voltages: [0.79877, 0.019961, 0.19588, 0.016932, 0.035776, 0.0018784, 0.64705, 0.063139, 0.035208, 0.039036]
Predicted label: 0
Correct prediction
Energy consumption = 140.073698 pJ
sum error= 336
Actual label: 7
Output voltages: [0.65125, 0.0061762, 0.007146, 0.35426, 0.0010739, 0.26582, 0.0010665, 0.7986, 0.77807, 0.1955]
Predicted label: 7
Correct prediction
Energy consumption = 143.381570 pJ
sum error= 336
Actual label: 7
Output voltages: [0.026767, 0.24926, 0.66198, 0.049249, 0.0038912, 0.0010665, 0.0010685, 0.79874, 0.38135, 0.29125]
Predicted label: 7
Correct prediction
Energy consumption = 144.445387 pJ
sum error= 336
Actual label: 1
Output voltages: [0.02159, 0.79755, 0.07956, 0.02687, 0.1926, 0.0010932, 0.0061021, 0.10784, 0.4457, 0.064494]
Predicted label: 1
Correct prediction
Energy consumption = 147.555292 pJ
sum error= 336
Actual label: 6
Output voltages: [0.26856, 0.011268, 0.025519, 0.023111, 0.045441, 0.39369, 0.78615, 0.019113, 0.7519, 0.0010683]
Predicted label: 6
Correct prediction
Energy consumption = 146.793548 pJ
sum error= 336
Actual label: 9
Output voltages: [0.024321, 0.018779, 0.016622, 0.035429, 0.11572, 0.35211, 0.047264, 0.28546, 0.53357, 0.7947]
Predicted label: 9
Correct prediction
Energy consumption = 145.425167 pJ
sum error= 336
Actual label: 1
Output voltages: [0.0080808, 0.79879, 0.026297, 0.039223, 0.48511, 0.0010694, 0.056632, 0.012565, 0.062428, 0.16279]
Predicted label: 1
Correct prediction
Energy consumption = 157.002936 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 829 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 829 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 829 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.46126, 0.039174, 0.06619, 0.79869, 0.0048308, 0.058134, 0.019986, 0.0052719, 0.62155, 0.017224]
Predicted label: 3
Correct prediction
Energy consumption = 150.981133 pJ
sum error= 336
Actual label: 6
Output voltages: [0.042056, 0.019235, 0.39898, 0.0012028, 0.33091, 0.047492, 0.79878, 0.0013713, 0.73935, 0.0012868]
Predicted label: 6
Correct prediction
Energy consumption = 146.050014 pJ
sum error= 336
Actual label: 2
Output voltages: [0.4242, 0.041878, 0.79879, 0.091572, 0.011489, 0.0012682, 0.20773, 0.26531, 0.32706, 0.0018316]
Predicted label: 2
Correct prediction
Energy consumption = 143.013217 pJ
sum error= 336
Actual label: 3
Output voltages: [0.026383, 0.077289, 0.11463, 0.79879, 0.012702, 0.0049299, 0.0048525, 0.014069, 0.72382, 0.18544]
Predicted label: 3
Correct prediction
Energy consumption = 143.802826 pJ
sum error= 336
Actual label: 8
Output voltages: [0.035463, 0.0081611, 0.21623, 0.029648, 0.024554, 0.026168, 0.013511, 0.021244, 0.79874, 0.071744]
Predicted label: 8
Correct prediction
Energy consumption = 145.456909 pJ
sum error= 336
Actual label: 2
Output voltages: [0.49767, 0.0013424, 0.79861, 0.1805, 0.024818, 0.0010768, 0.05461, 0.37309, 0.77386, 0.010723]
Predicted label: 2
Correct prediction
Energy consumption = 136.342701 pJ
sum error= 336
Actual label: 3
Output voltages: [0.13081, 0.0018506, 0.40459, 0.79872, 0.035711, 0.1956, 0.0063312, 0.031177, 0.76105, 0.038396]
Predicted label: 3
Correct prediction
Energy consumption = 138.716488 pJ
sum error= 336
Actual label: 8
Output voltages: [0.010294, 0.028983, 0.2151, 0.031145, 0.028477, 0.017235, 0.046934, 0.017578, 0.79879, 0.093714]
Predicted label: 8
Correct prediction
Energy consumption = 138.367580 pJ
sum error= 336
Actual label: 9
Output voltages: [0.12704, 0.0086844, 0.010631, 0.022799, 0.33214, 0.039754, 0.019924, 0.01415, 0.46063, 0.79769]
Predicted label: 9
Correct prediction
Energy consumption = 134.710655 pJ
sum error= 336
Actual label: 5
Output voltages: [0.40761, 0.0010745, 0.001827, 0.052549, 0.019642, 0.79879, 0.63199, 0.04939, 0.77906, 0.0020115]
Predicted label: 5
Correct prediction
Energy consumption = 142.020133 pJ
sum error= 336
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 830 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 830 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 830 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.026041, 0.0017119, 0.03395, 0.27891, 0.0094793, 0.029611, 0.01621, 0.0076712, 0.79874, 0.061516]
Predicted label: 8
Correct prediction
Energy consumption = 150.154136 pJ
sum error= 336
Actual label: 8
Output voltages: [0.031113, 0.0055792, 0.035747, 0.089142, 0.015962, 0.1112, 0.013385, 0.0064917, 0.79875, 0.13232]
Predicted label: 8
Correct prediction
Energy consumption = 135.341014 pJ
sum error= 336
Actual label: 7
Output voltages: [0.73986, 0.012155, 0.093842, 0.54178, 0.014811, 0.0014915, 0.0010771, 0.79877, 0.32935, 0.37742]
Predicted label: 7
Correct prediction
Energy consumption = 146.839297 pJ
sum error= 336
Actual label: 1
Output voltages: [0.016582, 0.79875, 0.040035, 0.0062794, 0.40512, 0.0010988, 0.21805, 0.0012461, 0.03517, 0.2179]
Predicted label: 1
Correct prediction
Energy consumption = 143.803067 pJ
sum error= 336
Actual label: 7
Output voltages: [0.78738, 0.020405, 0.4194, 0.39274, 0.0012716, 0.16337, 0.0038077, 0.74282, 0.77628, 0.046209]
Predicted label: 0
Wrong prediction!
Energy consumption = 147.285780 pJ
sum error= 337
Actual label: 1
Output voltages: [0.01167, 0.7987, 0.078508, 0.0047952, 0.028885, 0.0021066, 0.30846, 0.0038434, 0.34899, 0.01025]
Predicted label: 1
Correct prediction
Energy consumption = 142.143690 pJ
sum error= 337
Actual label: 1
Output voltages: [0.35436, 0.79796, 0.19253, 0.001119, 0.51655, 0.0020966, 0.18101, 0.0010746, 0.22685, 0.022136]
Predicted label: 1
Correct prediction
Energy consumption = 135.737543 pJ
sum error= 337
Actual label: 0
Output voltages: [0.79867, 0.089786, 0.040426, 0.01466, 0.012845, 0.012542, 0.49358, 0.022479, 0.12173, 0.031968]
Predicted label: 0
Correct prediction
Energy consumption = 143.202856 pJ
sum error= 337
Actual label: 3
Output voltages: [0.2087, 0.016862, 0.091236, 0.79869, 0.029091, 0.0054389, 0.02323, 0.048984, 0.71225, 0.03896]
Predicted label: 3
Correct prediction
Energy consumption = 142.253267 pJ
sum error= 337
Actual label: 4
Output voltages: [0.0088232, 0.010182, 0.65487, 0.016155, 0.79656, 0.0012646, 0.081802, 0.0062709, 0.67531, 0.0083762]
Predicted label: 4
Correct prediction
Energy consumption = 142.874176 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 831 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 831 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 831 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.030723, 0.034287, 0.79872, 0.30612, 0.015292, 0.0012026, 0.11824, 0.037146, 0.26887, 0.014578]
Predicted label: 2
Correct prediction
Energy consumption = 134.938388 pJ
sum error= 337
Actual label: 6
Output voltages: [0.050267, 0.023062, 0.6889, 0.0010917, 0.65397, 0.045359, 0.79828, 0.0023964, 0.24178, 0.0012387]
Predicted label: 6
Correct prediction
Energy consumption = 134.126878 pJ
sum error= 337
Actual label: 4
Output voltages: [0.0075494, 0.02358, 0.043891, 0.0014688, 0.79866, 0.013167, 0.033115, 0.45746, 0.057441, 0.02185]
Predicted label: 4
Correct prediction
Energy consumption = 142.773735 pJ
sum error= 337
Actual label: 7
Output voltages: [0.048724, 0.014055, 0.13873, 0.1224, 0.0044823, 0.002001, 0.0010917, 0.7986, 0.057762, 0.29636]
Predicted label: 7
Correct prediction
Energy consumption = 149.800274 pJ
sum error= 337
Actual label: 4
Output voltages: [0.016528, 0.039286, 0.046846, 0.040047, 0.7987, 0.0014962, 0.041586, 0.028027, 0.034171, 0.023721]
Predicted label: 4
Correct prediction
Energy consumption = 148.819879 pJ
sum error= 337
Actual label: 2
Output voltages: [0.091762, 0.0034793, 0.79879, 0.032222, 0.018681, 0.0010844, 0.022007, 0.23199, 0.72715, 0.0093517]
Predicted label: 2
Correct prediction
Energy consumption = 138.389085 pJ
sum error= 337
Actual label: 7
Output voltages: [0.57528, 0.07913, 0.76332, 0.032003, 0.0011094, 0.0023803, 0.0026462, 0.77678, 0.59051, 0.025229]
Predicted label: 7
Correct prediction
Energy consumption = 142.721832 pJ
sum error= 337
Actual label: 4
Output voltages: [0.023322, 0.0042231, 0.46534, 0.043622, 0.79879, 0.0030675, 0.0047893, 0.0030299, 0.29779, 0.038031]
Predicted label: 4
Correct prediction
Energy consumption = 143.268884 pJ
sum error= 337
Actual label: 2
Output voltages: [0.44013, 0.0033991, 0.79855, 0.13958, 0.002961, 0.001179, 0.012904, 0.27036, 0.76152, 0.0054612]
Predicted label: 2
Correct prediction
Energy consumption = 140.796393 pJ
sum error= 337
Actual label: 9
Output voltages: [0.17406, 0.0035997, 0.0011855, 0.065487, 0.049414, 0.18891, 0.029094, 0.011602, 0.54468, 0.78389]
Predicted label: 9
Correct prediction
Energy consumption = 148.502780 pJ
sum error= 337
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 832 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 832 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 832 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.39364, 0.0012215, 0.7972, 0.29833, 0.0033001, 0.0011676, 0.01441, 0.53036, 0.73, 0.0088882]
Predicted label: 2
Correct prediction
Energy consumption = 141.978222 pJ
sum error= 337
Actual label: 7
Output voltages: [0.60364, 0.0091255, 0.063937, 0.74115, 0.004011, 0.024521, 0.0011504, 0.79867, 0.74887, 0.22193]
Predicted label: 7
Correct prediction
Energy consumption = 148.211177 pJ
sum error= 337
Actual label: 9
Output voltages: [0.26488, 0.00134, 0.0055524, 0.021296, 0.34221, 0.26757, 0.14242, 0.047926, 0.04936, 0.7938]
Predicted label: 9
Correct prediction
Energy consumption = 139.157103 pJ
sum error= 337
Actual label: 2
Output voltages: [0.67384, 0.059104, 0.7986, 0.4266, 0.0038826, 0.0011538, 0.093041, 0.0031055, 0.7723, 0.19192]
Predicted label: 2
Correct prediction
Energy consumption = 146.131682 pJ
sum error= 337
Actual label: 1
Output voltages: [0.0028565, 0.79877, 0.22633, 0.052362, 0.36851, 0.0010696, 0.41887, 0.01194, 0.04903, 0.032022]
Predicted label: 1
Correct prediction
Energy consumption = 148.967085 pJ
sum error= 337
Actual label: 0
Output voltages: [0.68855, 0.13951, 0.15743, 0.023834, 0.036106, 0.0044324, 0.79596, 0.010717, 0.055202, 0.0035864]
Predicted label: 6
Wrong prediction!
Energy consumption = 152.040618 pJ
sum error= 338
Actual label: 6
Output voltages: [0.1453, 0.081841, 0.66522, 0.0010866, 0.48478, 0.46541, 0.77337, 0.032463, 0.11293, 0.0011972]
Predicted label: 6
Correct prediction
Energy consumption = 136.907744 pJ
sum error= 338
Actual label: 5
Output voltages: [0.040883, 0.0013714, 0.0012751, 0.58357, 0.052292, 0.79872, 0.31339, 0.010479, 0.78315, 0.041119]
Predicted label: 5
Correct prediction
Energy consumption = 136.767730 pJ
sum error= 338
Actual label: 3
Output voltages: [0.51, 0.013065, 0.072549, 0.79868, 0.01202, 0.004641, 0.017584, 0.0076894, 0.42688, 0.037679]
Predicted label: 3
Correct prediction
Energy consumption = 140.774880 pJ
sum error= 338
Actual label: 4
Output voltages: [0.053953, 0.012554, 0.11807, 0.0025288, 0.79876, 0.0022505, 0.063026, 0.010513, 0.091684, 0.003083]
Predicted label: 4
Correct prediction
Energy consumption = 144.955211 pJ
sum error= 338
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 833 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 833 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 833 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.094306, 0.0012747, 0.23986, 0.019476, 0.0010688, 0.13218, 0.013713, 0.019461, 0.79878, 0.054927]
Predicted label: 8
Correct prediction
Energy consumption = 149.337010 pJ
sum error= 338
Actual label: 5
Output voltages: [0.025544, 0.0010672, 0.0010764, 0.37087, 0.042825, 0.79872, 0.26316, 0.031403, 0.66765, 0.0087374]
Predicted label: 5
Correct prediction
Energy consumption = 141.991999 pJ
sum error= 338
Actual label: 9
Output voltages: [0.28621, 0.0013061, 0.018803, 0.31381, 0.021287, 0.010841, 0.0010722, 0.46981, 0.7425, 0.76448]
Predicted label: 9
Correct prediction
Energy consumption = 146.934997 pJ
sum error= 338
Actual label: 6
Output voltages: [0.084375, 0.046346, 0.19251, 0.0016415, 0.22359, 0.1875, 0.79876, 0.0019197, 0.47861, 0.0047946]
Predicted label: 6
Correct prediction
Energy consumption = 144.697982 pJ
sum error= 338
Actual label: 9
Output voltages: [0.045502, 0.0026854, 0.0068116, 0.023937, 0.43647, 0.025386, 0.025695, 0.0067407, 0.43542, 0.79234]
Predicted label: 9
Correct prediction
Energy consumption = 145.695812 pJ
sum error= 338
Actual label: 0
Output voltages: [0.79485, 0.020796, 0.0096462, 0.0024028, 0.1604, 0.10213, 0.7863, 0.045489, 0.12126, 0.012725]
Predicted label: 0
Correct prediction
Energy consumption = 144.854786 pJ
sum error= 338
Actual label: 6
Output voltages: [0.20371, 0.005192, 0.2538, 0.0018003, 0.54841, 0.031782, 0.79879, 0.0010702, 0.40611, 0.022352]
Predicted label: 6
Correct prediction
Energy consumption = 131.950930 pJ
sum error= 338
Actual label: 3
Output voltages: [0.019418, 0.013765, 0.061351, 0.79879, 0.016776, 0.0045756, 0.0057285, 0.026768, 0.76217, 0.042077]
Predicted label: 3
Correct prediction
Energy consumption = 145.241560 pJ
sum error= 338
Actual label: 0
Output voltages: [0.79878, 0.12397, 0.022976, 0.012891, 0.016082, 0.0021411, 0.72792, 0.0060651, 0.17859, 0.064502]
Predicted label: 0
Correct prediction
Energy consumption = 148.953585 pJ
sum error= 338
Actual label: 8
Output voltages: [0.016425, 0.027306, 0.6397, 0.0024471, 0.40181, 0.0069682, 0.75946, 0.001927, 0.60219, 0.0041785]
Predicted label: 6
Wrong prediction!
Energy consumption = 130.204926 pJ
sum error= 339
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 834 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 834 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 834 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.015316, 0.79869, 0.43184, 0.066362, 0.022202, 0.0010737, 0.47237, 0.0037492, 0.21922, 0.053076]
Predicted label: 1
Correct prediction
Energy consumption = 156.793149 pJ
sum error= 339
Actual label: 6
Output voltages: [0.044765, 0.10364, 0.43537, 0.005497, 0.075377, 0.13437, 0.79877, 0.0014131, 0.62805, 0.013814]
Predicted label: 6
Correct prediction
Energy consumption = 140.118021 pJ
sum error= 339
Actual label: 0
Output voltages: [0.79676, 0.03097, 0.45205, 0.0047762, 0.036254, 0.0010982, 0.64022, 0.02263, 0.031135, 0.039476]
Predicted label: 0
Correct prediction
Energy consumption = 135.757391 pJ
sum error= 339
Actual label: 0
Output voltages: [0.79877, 0.043364, 0.02948, 0.019094, 0.011636, 0.0071663, 0.40076, 0.015893, 0.085371, 0.043851]
Predicted label: 0
Correct prediction
Energy consumption = 139.184360 pJ
sum error= 339
Actual label: 1
Output voltages: [0.0096694, 0.79879, 0.052167, 0.017175, 0.3513, 0.001097, 0.41051, 0.0064623, 0.21001, 0.048925]
Predicted label: 1
Correct prediction
Energy consumption = 160.310171 pJ
sum error= 339
Actual label: 2
Output voltages: [0.31246, 0.0088229, 0.79875, 0.36255, 0.065482, 0.0011512, 0.022742, 0.39411, 0.20013, 0.0095272]
Predicted label: 2
Correct prediction
Energy consumption = 141.562815 pJ
sum error= 339
Actual label: 3
Output voltages: [0.044017, 0.0024285, 0.21674, 0.79879, 0.049775, 0.044939, 0.0023138, 0.061955, 0.70336, 0.28795]
Predicted label: 3
Correct prediction
Energy consumption = 145.260263 pJ
sum error= 339
Actual label: 4
Output voltages: [0.0035255, 0.01233, 0.10912, 0.021178, 0.79863, 0.0027273, 0.052547, 0.026406, 0.036105, 0.03106]
Predicted label: 4
Correct prediction
Energy consumption = 151.155658 pJ
sum error= 339
Actual label: 5
Output voltages: [0.036388, 0.0011364, 0.016925, 0.24618, 0.019964, 0.79674, 0.42009, 0.016917, 0.78611, 0.0024087]
Predicted label: 5
Correct prediction
Energy consumption = 144.909041 pJ
sum error= 339
Actual label: 6
Output voltages: [0.046364, 0.031536, 0.48718, 0.0011193, 0.56642, 0.012211, 0.79879, 0.0010895, 0.077576, 0.0086035]
Predicted label: 6
Correct prediction
Energy consumption = 137.724189 pJ
sum error= 339
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 835 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 835 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 835 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.055045, 0.071586, 0.041329, 0.022193, 0.0057822, 0.0028614, 0.0010691, 0.79868, 0.21476, 0.33903]
Predicted label: 7
Correct prediction
Energy consumption = 152.573620 pJ
sum error= 339
Actual label: 0
Output voltages: [0.79797, 0.054605, 0.094824, 0.011334, 0.0012088, 0.0012198, 0.49609, 0.033217, 0.1492, 0.10498]
Predicted label: 0
Correct prediction
Energy consumption = 139.095073 pJ
sum error= 339
Actual label: 1
Output voltages: [0.0096305, 0.79857, 0.040837, 0.032839, 0.0073388, 0.0011385, 0.43751, 0.0051132, 0.45917, 0.030454]
Predicted label: 1
Correct prediction
Energy consumption = 156.991448 pJ
sum error= 339
Actual label: 2
Output voltages: [0.22854, 0.019655, 0.79082, 0.010882, 0.78545, 0.0013824, 0.056907, 0.036299, 0.11398, 0.13604]
Predicted label: 2
Correct prediction
Energy consumption = 134.397556 pJ
sum error= 339
Actual label: 3
Output voltages: [0.24098, 0.0041398, 0.012456, 0.79868, 0.015138, 0.5487, 0.011801, 0.058724, 0.49854, 0.001964]
Predicted label: 3
Correct prediction
Energy consumption = 148.008113 pJ
sum error= 339
Actual label: 4
Output voltages: [0.011049, 0.0066881, 0.42971, 0.0027005, 0.79869, 0.0018789, 0.04979, 0.025586, 0.019355, 0.1238]
Predicted label: 4
Correct prediction
Energy consumption = 152.855181 pJ
sum error= 339
Actual label: 7
Output voltages: [0.10278, 0.040099, 0.042984, 0.20591, 0.011241, 0.0077557, 0.0010675, 0.79852, 0.052888, 0.065761]
Predicted label: 7
Correct prediction
Energy consumption = 149.151002 pJ
sum error= 339
Actual label: 8
Output voltages: [0.039574, 0.0055608, 0.059358, 0.29227, 0.0012252, 0.090466, 0.092421, 0.00303, 0.79854, 0.026546]
Predicted label: 8
Correct prediction
Energy consumption = 141.361644 pJ
sum error= 339
Actual label: 9
Output voltages: [0.37302, 0.0086658, 0.010173, 0.055883, 0.32179, 0.015214, 0.0016749, 0.012134, 0.49749, 0.79803]
Predicted label: 9
Correct prediction
Energy consumption = 140.097940 pJ
sum error= 339
Actual label: 0
Output voltages: [0.79874, 0.013053, 0.026841, 0.0057323, 0.031533, 0.01807, 0.64096, 0.034837, 0.03752, 0.19042]
Predicted label: 0
Correct prediction
Energy consumption = 137.516809 pJ
sum error= 339
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 836 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 836 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 836 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.038813, 0.79879, 0.040553, 0.0093216, 0.24625, 0.00108, 0.54695, 0.0014386, 0.18213, 0.040498]
Predicted label: 1
Correct prediction
Energy consumption = 154.474502 pJ
sum error= 339
Actual label: 2
Output voltages: [0.22214, 0.0082478, 0.7987, 0.075963, 0.044135, 0.0010844, 0.027511, 0.067043, 0.52747, 0.020395]
Predicted label: 2
Correct prediction
Energy consumption = 134.994699 pJ
sum error= 339
Actual label: 3
Output voltages: [0.25187, 0.0025099, 0.027007, 0.79879, 0.049364, 0.064581, 0.029644, 0.012642, 0.65599, 0.0080685]
Predicted label: 3
Correct prediction
Energy consumption = 138.818941 pJ
sum error= 339
Actual label: 4
Output voltages: [0.0063031, 0.0013648, 0.37707, 0.032129, 0.79879, 0.0012206, 0.088163, 0.020892, 0.051344, 0.017939]
Predicted label: 4
Correct prediction
Energy consumption = 151.977650 pJ
sum error= 339
Actual label: 7
Output voltages: [0.085804, 0.038838, 0.76782, 0.068564, 0.0058868, 0.0010736, 0.0010914, 0.79872, 0.19878, 0.19295]
Predicted label: 7
Correct prediction
Energy consumption = 148.582246 pJ
sum error= 339
Actual label: 2
Output voltages: [0.2649, 0.026553, 0.79862, 0.044654, 0.017265, 0.0012296, 0.021173, 0.025431, 0.60811, 0.0065475]
Predicted label: 2
Correct prediction
Energy consumption = 141.089981 pJ
sum error= 339
Actual label: 5
Output voltages: [0.048439, 0.0011856, 0.0013005, 0.26172, 0.031578, 0.79878, 0.33314, 0.027174, 0.73864, 0.016621]
Predicted label: 5
Correct prediction
Energy consumption = 151.675662 pJ
sum error= 339
Actual label: 1
Output voltages: [0.0084325, 0.79863, 0.27043, 0.038018, 0.044589, 0.0011418, 0.37195, 0.017998, 0.16847, 0.0021866]
Predicted label: 1
Correct prediction
Energy consumption = 155.833504 pJ
sum error= 339
Actual label: 6
Output voltages: [0.25543, 0.012623, 0.23261, 0.0010963, 0.40839, 0.10047, 0.79879, 0.0032587, 0.24554, 0.0022996]
Predicted label: 6
Correct prediction
Energy consumption = 144.680116 pJ
sum error= 339
Actual label: 4
Output voltages: [0.013856, 0.0060396, 0.030225, 0.0010975, 0.79872, 0.0048199, 0.1903, 0.033485, 0.28361, 0.00643]
Predicted label: 4
Correct prediction
Energy consumption = 148.869770 pJ
sum error= 339
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 837 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 837 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 837 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.46125, 0.007016, 0.049197, 0.79871, 0.018591, 0.012414, 0.025252, 0.011189, 0.40238, 0.040395]
Predicted label: 3
Correct prediction
Energy consumption = 147.840511 pJ
sum error= 339
Actual label: 9
Output voltages: [0.38426, 0.0051409, 0.037978, 0.034405, 0.030104, 0.016808, 0.0040637, 0.012621, 0.75346, 0.79389]
Predicted label: 9
Correct prediction
Energy consumption = 147.972179 pJ
sum error= 339
Actual label: 9
Output voltages: [0.43009, 0.0055572, 0.12185, 0.029108, 0.049608, 0.0058271, 0.0028808, 0.036923, 0.57638, 0.79496]
Predicted label: 9
Correct prediction
Energy consumption = 129.867864 pJ
sum error= 339
Actual label: 0
Output voltages: [0.79872, 0.016256, 0.04652, 0.0097254, 0.022234, 0.0046747, 0.74906, 0.054564, 0.17775, 0.11488]
Predicted label: 0
Correct prediction
Energy consumption = 139.897203 pJ
sum error= 339
Actual label: 9
Output voltages: [0.16274, 0.016003, 0.031641, 0.025274, 0.013716, 0.033484, 0.0027109, 0.088687, 0.79342, 0.75952]
Predicted label: 8
Wrong prediction!
Energy consumption = 138.502896 pJ
sum error= 340
Actual label: 7
Output voltages: [0.11328, 0.03706, 0.029019, 0.043033, 0.031023, 0.0045651, 0.0010698, 0.7987, 0.12088, 0.028816]
Predicted label: 7
Correct prediction
Energy consumption = 146.060922 pJ
sum error= 340
Actual label: 1
Output voltages: [0.050728, 0.79879, 0.016601, 0.34497, 0.21891, 0.0041944, 0.50845, 0.056541, 0.10514, 0.037976]
Predicted label: 1
Correct prediction
Energy consumption = 162.334482 pJ
sum error= 340
Actual label: 6
Output voltages: [0.033124, 0.014957, 0.37275, 0.0010989, 0.61359, 0.11094, 0.79878, 0.0040511, 0.28746, 0.0035102]
Predicted label: 6
Correct prediction
Energy consumption = 142.824541 pJ
sum error= 340
Actual label: 4
Output voltages: [0.0030995, 0.015337, 0.1195, 0.0086958, 0.79875, 0.0016285, 0.023416, 0.047135, 0.029518, 0.017908]
Predicted label: 4
Correct prediction
Energy consumption = 152.406728 pJ
sum error= 340
Actual label: 3
Output voltages: [0.13661, 0.010127, 0.20908, 0.79879, 0.034635, 0.036224, 0.012064, 0.030046, 0.65146, 0.27179]
Predicted label: 3
Correct prediction
Energy consumption = 142.312631 pJ
sum error= 340
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 838 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 838 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 838 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.021329, 0.013178, 0.2877, 0.0013285, 0.65023, 0.16268, 0.79878, 0.0012051, 0.59996, 0.0062393]
Predicted label: 6
Correct prediction
Energy consumption = 146.566619 pJ
sum error= 340
Actual label: 2
Output voltages: [0.041945, 0.019118, 0.79861, 0.039848, 0.019258, 0.0010886, 0.038492, 0.10329, 0.44458, 0.032293]
Predicted label: 2
Correct prediction
Energy consumption = 132.929480 pJ
sum error= 340
Actual label: 0
Output voltages: [0.79713, 0.0010919, 0.75254, 0.34365, 0.0011093, 0.024431, 0.051879, 0.2028, 0.43018, 0.0071009]
Predicted label: 0
Correct prediction
Energy consumption = 135.624813 pJ
sum error= 340
Actual label: 9
Output voltages: [0.013316, 0.009761, 0.11976, 0.03325, 0.018834, 0.24049, 0.0066948, 0.0074146, 0.79432, 0.63743]
Predicted label: 8
Wrong prediction!
Energy consumption = 146.054099 pJ
sum error= 341
Actual label: 8
Output voltages: [0.070033, 0.00972, 0.22691, 0.12317, 0.025826, 0.29526, 0.016818, 0.027577, 0.79871, 0.01325]
Predicted label: 8
Correct prediction
Energy consumption = 140.389867 pJ
sum error= 341
Actual label: 6
Output voltages: [0.037017, 0.033371, 0.54207, 0.0010878, 0.35369, 0.10295, 0.79877, 0.0041392, 0.46921, 0.0040573]
Predicted label: 6
Correct prediction
Energy consumption = 143.340784 pJ
sum error= 341
Actual label: 5
Output voltages: [0.054131, 0.0011022, 0.011331, 0.056654, 0.2194, 0.79827, 0.44186, 0.001469, 0.78493, 0.028364]
Predicted label: 5
Correct prediction
Energy consumption = 139.162972 pJ
sum error= 341
Actual label: 7
Output voltages: [0.16793, 0.062359, 0.023874, 0.097743, 0.036142, 0.0011674, 0.0012046, 0.79779, 0.20066, 0.34496]
Predicted label: 7
Correct prediction
Energy consumption = 145.949004 pJ
sum error= 341
Actual label: 0
Output voltages: [0.79871, 0.0056609, 0.15709, 0.0054965, 0.012579, 0.002834, 0.55097, 0.1543, 0.048045, 0.1716]
Predicted label: 0
Correct prediction
Energy consumption = 143.598086 pJ
sum error= 341
Actual label: 0
Output voltages: [0.78936, 0.030369, 0.199, 0.019883, 0.031833, 0.0012262, 0.77438, 0.0066739, 0.44717, 0.052926]
Predicted label: 0
Correct prediction
Energy consumption = 129.506763 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 839 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 839 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 839 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.40235, 0.79875, 0.0071607, 0.038486, 0.47922, 0.017206, 0.43749, 0.0018246, 0.048384, 0.049721]
Predicted label: 1
Correct prediction
Energy consumption = 156.804002 pJ
sum error= 341
Actual label: 7
Output voltages: [0.51806, 0.039234, 0.015212, 0.044252, 0.01971, 0.023632, 0.0038108, 0.79871, 0.43843, 0.0093342]
Predicted label: 7
Correct prediction
Energy consumption = 146.038549 pJ
sum error= 341
Actual label: 4
Output voltages: [0.0072223, 0.019447, 0.27095, 0.0011092, 0.79878, 0.0060154, 0.53795, 0.036143, 0.31111, 0.0024813]
Predicted label: 4
Correct prediction
Energy consumption = 148.597737 pJ
sum error= 341
Actual label: 3
Output voltages: [0.30826, 0.007285, 0.11977, 0.79874, 0.01247, 0.0050841, 0.0048945, 0.037919, 0.65995, 0.048267]
Predicted label: 3
Correct prediction
Energy consumption = 146.317463 pJ
sum error= 341
Actual label: 2
Output voltages: [0.58735, 0.0061748, 0.7987, 0.032952, 0.0030303, 0.0010972, 0.021555, 0.12365, 0.60512, 0.0023042]
Predicted label: 2
Correct prediction
Energy consumption = 135.689244 pJ
sum error= 341
Actual label: 4
Output voltages: [0.017129, 0.010349, 0.082555, 0.098951, 0.79875, 0.0025099, 0.03756, 0.025783, 0.016365, 0.012103]
Predicted label: 4
Correct prediction
Energy consumption = 151.214432 pJ
sum error= 341
Actual label: 1
Output voltages: [0.030763, 0.79879, 0.08229, 0.025313, 0.17936, 0.0032315, 0.75743, 0.0010661, 0.418, 0.034492]
Predicted label: 1
Correct prediction
Energy consumption = 158.321757 pJ
sum error= 341
Actual label: 3
Output voltages: [0.77209, 0.037971, 0.75444, 0.79818, 0.0013705, 0.3821, 0.012547, 0.0013274, 0.62038, 0.0013704]
Predicted label: 3
Correct prediction
Energy consumption = 145.625064 pJ
sum error= 341
Actual label: 7
Output voltages: [0.025486, 0.061585, 0.16183, 0.16774, 0.007203, 0.0015486, 0.001066, 0.79865, 0.28965, 0.12359]
Predicted label: 7
Correct prediction
Energy consumption = 147.626929 pJ
sum error= 341
Actual label: 6
Output voltages: [0.026918, 0.0046176, 0.17244, 0.001286, 0.46335, 0.067391, 0.79879, 0.0033056, 0.66876, 0.0047796]
Predicted label: 6
Correct prediction
Energy consumption = 148.589244 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 840 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 840 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 840 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.010334, 0.0079115, 0.19549, 0.020687, 0.79868, 0.0024265, 0.11624, 0.030119, 0.029217, 0.03683]
Predicted label: 4
Correct prediction
Energy consumption = 153.050377 pJ
sum error= 341
Actual label: 7
Output voltages: [0.073953, 0.071168, 0.0094858, 0.010172, 0.021461, 0.0020556, 0.001879, 0.79867, 0.31187, 0.28357]
Predicted label: 7
Correct prediction
Energy consumption = 151.641125 pJ
sum error= 341
Actual label: 7
Output voltages: [0.28598, 0.032441, 0.10075, 0.0051172, 0.024084, 0.022968, 0.0010659, 0.79857, 0.27329, 0.0085182]
Predicted label: 7
Correct prediction
Energy consumption = 138.376539 pJ
sum error= 341
Actual label: 7
Output voltages: [0.19622, 0.039027, 0.04194, 0.0264, 0.02204, 0.010247, 0.0010836, 0.7986, 0.053151, 0.033265]
Predicted label: 7
Correct prediction
Energy consumption = 137.330625 pJ
sum error= 341
Actual label: 9
Output voltages: [0.52403, 0.012928, 0.022446, 0.024274, 0.21275, 0.024919, 0.0098868, 0.022816, 0.64164, 0.79846]
Predicted label: 9
Correct prediction
Energy consumption = 147.658772 pJ
sum error= 341
Actual label: 8
Output voltages: [0.023711, 0.042394, 0.055604, 0.048384, 0.016064, 0.054865, 0.025753, 0.0032595, 0.79879, 0.38447]
Predicted label: 8
Correct prediction
Energy consumption = 136.431342 pJ
sum error= 341
Actual label: 4
Output voltages: [0.004959, 0.0016981, 0.3959, 0.020887, 0.79879, 0.0010903, 0.02378, 0.0072894, 0.1498, 0.19113]
Predicted label: 4
Correct prediction
Energy consumption = 153.077674 pJ
sum error= 341
Actual label: 3
Output voltages: [0.13771, 0.0072559, 0.09519, 0.79874, 0.023189, 0.019207, 0.006868, 0.010732, 0.7368, 0.039993]
Predicted label: 3
Correct prediction
Energy consumption = 143.071811 pJ
sum error= 341
Actual label: 8
Output voltages: [0.11637, 0.0026311, 0.021587, 0.042539, 0.0095327, 0.50405, 0.765, 0.0012309, 0.78136, 0.013049]
Predicted label: 8
Correct prediction
Energy consumption = 132.362258 pJ
sum error= 341
Actual label: 2
Output voltages: [0.049064, 0.019113, 0.79859, 0.053546, 0.016987, 0.001085, 0.025035, 0.095515, 0.47679, 0.016112]
Predicted label: 2
Correct prediction
Energy consumption = 136.199453 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 841 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 841 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 841 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18926, 0.0018365, 0.030518, 0.29055, 0.0010662, 0.42468, 0.096729, 0.0010957, 0.79128, 0.11142]
Predicted label: 8
Correct prediction
Energy consumption = 152.046486 pJ
sum error= 341
Actual label: 3
Output voltages: [0.089246, 0.022176, 0.037842, 0.79868, 0.0050175, 0.0045523, 0.0066919, 0.032595, 0.60669, 0.029135]
Predicted label: 3
Correct prediction
Energy consumption = 145.800740 pJ
sum error= 341
Actual label: 5
Output voltages: [0.17277, 0.001066, 0.0010747, 0.54908, 0.035466, 0.79869, 0.0759, 0.17377, 0.54319, 0.0094247]
Predicted label: 5
Correct prediction
Energy consumption = 132.720901 pJ
sum error= 341
Actual label: 8
Output voltages: [0.25646, 0.023442, 0.025726, 0.21947, 0.024498, 0.048422, 0.49327, 0.0019519, 0.79865, 0.0019681]
Predicted label: 8
Correct prediction
Energy consumption = 144.804639 pJ
sum error= 341
Actual label: 0
Output voltages: [0.79871, 0.02264, 0.16722, 0.010827, 0.014937, 0.0024107, 0.57561, 0.04576, 0.24043, 0.021715]
Predicted label: 0
Correct prediction
Energy consumption = 144.541841 pJ
sum error= 341
Actual label: 5
Output voltages: [0.063134, 0.0011705, 0.0010699, 0.078144, 0.16865, 0.79857, 0.38691, 0.014495, 0.4519, 0.037114]
Predicted label: 5
Correct prediction
Energy consumption = 137.348499 pJ
sum error= 341
Actual label: 4
Output voltages: [0.0058017, 0.03125, 0.024752, 0.0012889, 0.79873, 0.016365, 0.037426, 0.027643, 0.53057, 0.012336]
Predicted label: 4
Correct prediction
Energy consumption = 156.313222 pJ
sum error= 341
Actual label: 7
Output voltages: [0.66334, 0.011462, 0.0053246, 0.010394, 0.023563, 0.33724, 0.0018994, 0.79861, 0.31607, 0.084558]
Predicted label: 7
Correct prediction
Energy consumption = 147.859753 pJ
sum error= 341
Actual label: 1
Output voltages: [0.019358, 0.7986, 0.015096, 0.037308, 0.044807, 0.0046495, 0.60223, 0.005061, 0.18141, 0.034536]
Predicted label: 1
Correct prediction
Energy consumption = 163.066045 pJ
sum error= 341
Actual label: 3
Output voltages: [0.049885, 0.0030376, 0.027482, 0.79874, 0.12866, 0.022068, 0.010967, 0.017416, 0.38757, 0.56385]
Predicted label: 3
Correct prediction
Energy consumption = 152.252616 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 842 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 842 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 842 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0023889, 0.79858, 0.024355, 0.027755, 0.017228, 0.001188, 0.75108, 0.0029311, 0.41517, 0.032097]
Predicted label: 1
Correct prediction
Energy consumption = 159.545279 pJ
sum error= 341
Actual label: 7
Output voltages: [0.044597, 0.48115, 0.10027, 0.025316, 0.0066467, 0.0011227, 0.0013784, 0.79874, 0.53644, 0.39808]
Predicted label: 7
Correct prediction
Energy consumption = 150.343252 pJ
sum error= 341
Actual label: 9
Output voltages: [0.072425, 0.0024139, 0.01313, 0.050891, 0.078255, 0.084401, 0.0020798, 0.23245, 0.75808, 0.79594]
Predicted label: 9
Correct prediction
Energy consumption = 135.616161 pJ
sum error= 341
Actual label: 6
Output voltages: [0.026828, 0.032737, 0.49453, 0.0010675, 0.30443, 0.044518, 0.79878, 0.0028276, 0.45063, 0.0016322]
Predicted label: 6
Correct prediction
Energy consumption = 144.491744 pJ
sum error= 341
Actual label: 2
Output voltages: [0.16328, 0.039066, 0.79858, 0.058661, 0.028808, 0.0011684, 0.055105, 0.035736, 0.22979, 0.042054]
Predicted label: 2
Correct prediction
Energy consumption = 141.372116 pJ
sum error= 341
Actual label: 0
Output voltages: [0.79876, 0.035351, 0.048342, 0.0097005, 0.028135, 0.0053009, 0.51949, 0.022758, 0.03794, 0.081882]
Predicted label: 0
Correct prediction
Energy consumption = 145.320856 pJ
sum error= 341
Actual label: 9
Output voltages: [0.76472, 0.0038388, 0.0066671, 0.086532, 0.052812, 0.3452, 0.0062241, 0.048189, 0.22649, 0.78881]
Predicted label: 9
Correct prediction
Energy consumption = 142.316958 pJ
sum error= 341
Actual label: 1
Output voltages: [0.016393, 0.79877, 0.039482, 0.11715, 0.13927, 0.0011399, 0.7476, 0.0017861, 0.23415, 0.01905]
Predicted label: 1
Correct prediction
Energy consumption = 162.748459 pJ
sum error= 341
Actual label: 7
Output voltages: [0.74705, 0.013564, 0.0087026, 0.046135, 0.14013, 0.024803, 0.0011678, 0.79869, 0.29438, 0.15974]
Predicted label: 7
Correct prediction
Energy consumption = 156.482332 pJ
sum error= 341
Actual label: 3
Output voltages: [0.030779, 0.014748, 0.035516, 0.79875, 0.036249, 0.13857, 0.0026662, 0.026453, 0.76772, 0.039402]
Predicted label: 3
Correct prediction
Energy consumption = 142.910571 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 843 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 843 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 843 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.029659, 0.0069408, 0.080371, 0.79879, 0.03199, 0.029477, 0.0044237, 0.11705, 0.74063, 0.10693]
Predicted label: 3
Correct prediction
Energy consumption = 148.916927 pJ
sum error= 341
Actual label: 9
Output voltages: [0.20279, 0.0010712, 0.0016666, 0.0088796, 0.39938, 0.23065, 0.003579, 0.067885, 0.75907, 0.77961]
Predicted label: 9
Correct prediction
Energy consumption = 143.628921 pJ
sum error= 341
Actual label: 1
Output voltages: [0.0026237, 0.79866, 0.053137, 0.01811, 0.281, 0.0013068, 0.3209, 0.013003, 0.16272, 0.042609]
Predicted label: 1
Correct prediction
Energy consumption = 158.894901 pJ
sum error= 341
Actual label: 6
Output voltages: [0.039686, 0.013579, 0.48822, 0.0010662, 0.68565, 0.046667, 0.79878, 0.0034542, 0.17285, 0.003559]
Predicted label: 6
Correct prediction
Energy consumption = 142.006975 pJ
sum error= 341
Actual label: 4
Output voltages: [0.0072308, 0.001184, 0.19436, 0.0019076, 0.79861, 0.0010666, 0.1826, 0.026351, 0.051269, 0.015141]
Predicted label: 4
Correct prediction
Energy consumption = 144.584938 pJ
sum error= 341
Actual label: 3
Output voltages: [0.42023, 0.0011219, 0.042238, 0.79879, 0.015461, 0.34897, 0.014575, 0.0056237, 0.062666, 0.0098402]
Predicted label: 3
Correct prediction
Energy consumption = 140.843269 pJ
sum error= 341
Actual label: 9
Output voltages: [0.067295, 0.026978, 0.038394, 0.045719, 0.042239, 0.014252, 0.002041, 0.087323, 0.45814, 0.7981]
Predicted label: 9
Correct prediction
Energy consumption = 149.727626 pJ
sum error= 341
Actual label: 8
Output voltages: [0.0066618, 0.0085609, 0.031932, 0.093942, 0.0089335, 0.17018, 0.074328, 0.020762, 0.7987, 0.043274]
Predicted label: 8
Correct prediction
Energy consumption = 138.451586 pJ
sum error= 341
Actual label: 2
Output voltages: [0.53284, 0.0077006, 0.79868, 0.11389, 0.0094505, 0.0015897, 0.057687, 0.04514, 0.42656, 0.004773]
Predicted label: 2
Correct prediction
Energy consumption = 139.588726 pJ
sum error= 341
Actual label: 1
Output voltages: [0.0043884, 0.79879, 0.35666, 0.034644, 0.069302, 0.001381, 0.48844, 0.019709, 0.33958, 0.0012643]
Predicted label: 1
Correct prediction
Energy consumption = 157.420420 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 844 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 844 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 844 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0035761, 0.095372, 0.089527, 0.015622, 0.021304, 0.006171, 0.023424, 0.030457, 0.79877, 0.36211]
Predicted label: 8
Correct prediction
Energy consumption = 148.175972 pJ
sum error= 341
Actual label: 6
Output voltages: [0.071223, 0.16076, 0.25672, 0.0014998, 0.34484, 0.15482, 0.7987, 0.0033339, 0.28861, 0.011457]
Predicted label: 6
Correct prediction
Energy consumption = 140.692952 pJ
sum error= 341
Actual label: 4
Output voltages: [0.038547, 0.014636, 0.081523, 0.0029259, 0.79658, 0.001783, 0.79232, 0.0031836, 0.043673, 0.027807]
Predicted label: 4
Correct prediction
Energy consumption = 140.168069 pJ
sum error= 341
Actual label: 1
Output voltages: [0.050107, 0.79869, 0.22851, 0.063765, 0.036961, 0.0011083, 0.6265, 0.0068647, 0.066424, 0.011275]
Predicted label: 1
Correct prediction
Energy consumption = 157.989283 pJ
sum error= 341
Actual label: 5
Output voltages: [0.046099, 0.0010659, 0.0011412, 0.26084, 0.20584, 0.79878, 0.13329, 0.033408, 0.55254, 0.027086]
Predicted label: 5
Correct prediction
Energy consumption = 137.171273 pJ
sum error= 341
Actual label: 5
Output voltages: [0.044027, 0.0010772, 0.0010759, 0.35231, 0.068099, 0.79865, 0.27971, 0.23049, 0.76806, 0.0032673]
Predicted label: 5
Correct prediction
Energy consumption = 131.200968 pJ
sum error= 341
Actual label: 6
Output voltages: [0.044807, 0.022568, 0.34778, 0.0039264, 0.21013, 0.083584, 0.79878, 0.0011261, 0.75423, 0.010314]
Predicted label: 6
Correct prediction
Energy consumption = 140.145580 pJ
sum error= 341
Actual label: 5
Output voltages: [0.033248, 0.002082, 0.0024876, 0.30145, 0.023642, 0.79807, 0.19634, 0.024436, 0.7519, 0.15252]
Predicted label: 5
Correct prediction
Energy consumption = 143.337641 pJ
sum error= 341
Actual label: 0
Output voltages: [0.79878, 0.12096, 0.0036806, 0.018442, 0.017043, 0.019289, 0.4268, 0.025756, 0.11344, 0.075014]
Predicted label: 0
Correct prediction
Energy consumption = 153.748893 pJ
sum error= 341
Actual label: 1
Output voltages: [0.01224, 0.79877, 0.0014772, 0.044764, 0.20256, 0.26055, 0.4804, 0.014636, 0.44354, 0.045605]
Predicted label: 1
Correct prediction
Energy consumption = 161.582365 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 845 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 845 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 845 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.3602, 0.17329, 0.79876, 0.033604, 0.043392, 0.00132, 0.28042, 0.039171, 0.21525, 0.024926]
Predicted label: 2
Correct prediction
Energy consumption = 153.547678 pJ
sum error= 341
Actual label: 3
Output voltages: [0.37747, 0.025981, 0.036487, 0.79869, 0.039367, 0.0095492, 0.017358, 0.0041018, 0.55286, 0.11361]
Predicted label: 3
Correct prediction
Energy consumption = 145.978588 pJ
sum error= 341
Actual label: 4
Output voltages: [0.027702, 0.012113, 0.17489, 0.019429, 0.79856, 0.0025004, 0.049923, 0.18822, 0.011185, 0.038305]
Predicted label: 4
Correct prediction
Energy consumption = 155.893189 pJ
sum error= 341
Actual label: 5
Output voltages: [0.022525, 0.0011898, 0.0020115, 0.46389, 0.025653, 0.79799, 0.27523, 0.0028516, 0.76619, 0.013365]
Predicted label: 5
Correct prediction
Energy consumption = 144.656090 pJ
sum error= 341
Actual label: 6
Output voltages: [0.15359, 0.046016, 0.25767, 0.0039465, 0.35962, 0.39408, 0.79866, 0.0024459, 0.45929, 0.0082575]
Predicted label: 6
Correct prediction
Energy consumption = 136.051407 pJ
sum error= 341
Actual label: 7
Output voltages: [0.1273, 0.10552, 0.50624, 0.020791, 0.0011538, 0.0011023, 0.001066, 0.7986, 0.41519, 0.055186]
Predicted label: 7
Correct prediction
Energy consumption = 159.525662 pJ
sum error= 341
Actual label: 8
Output voltages: [0.50254, 0.0037384, 0.32244, 0.20178, 0.045632, 0.017213, 0.20974, 0.0016035, 0.79879, 0.01457]
Predicted label: 8
Correct prediction
Energy consumption = 150.293919 pJ
sum error= 341
Actual label: 9
Output voltages: [0.32105, 0.0086832, 0.014517, 0.041625, 0.022035, 0.011857, 0.0015201, 0.016644, 0.75702, 0.79726]
Predicted label: 9
Correct prediction
Energy consumption = 142.146072 pJ
sum error= 341
Actual label: 0
Output voltages: [0.79869, 0.097168, 0.010266, 0.019924, 0.0043058, 0.018836, 0.61392, 0.026842, 0.10264, 0.022603]
Predicted label: 0
Correct prediction
Energy consumption = 144.043921 pJ
sum error= 341
Actual label: 1
Output voltages: [0.019578, 0.79855, 0.040819, 0.22652, 0.048989, 0.0050766, 0.39643, 0.0033446, 0.37033, 0.045835]
Predicted label: 1
Correct prediction
Energy consumption = 159.734222 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 846 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 846 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 846 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.59956, 0.0037042, 0.79824, 0.266, 0.05539, 0.0011401, 0.019608, 0.054572, 0.47711, 0.025024]
Predicted label: 2
Correct prediction
Energy consumption = 148.266627 pJ
sum error= 341
Actual label: 3
Output voltages: [0.56358, 0.014222, 0.044576, 0.79862, 0.034554, 0.024446, 0.0078572, 0.013644, 0.51539, 0.090999]
Predicted label: 3
Correct prediction
Energy consumption = 146.501339 pJ
sum error= 341
Actual label: 4
Output voltages: [0.0015674, 0.048795, 0.010893, 0.0010681, 0.79866, 0.026865, 0.044825, 0.21808, 0.452, 0.02772]
Predicted label: 4
Correct prediction
Energy consumption = 162.494755 pJ
sum error= 341
Actual label: 5
Output voltages: [0.057672, 0.0012282, 0.0010714, 0.53024, 0.025847, 0.79872, 0.30025, 0.032745, 0.73731, 0.011219]
Predicted label: 5
Correct prediction
Energy consumption = 141.889115 pJ
sum error= 341
Actual label: 6
Output voltages: [0.071481, 0.053625, 0.40879, 0.0011267, 0.40552, 0.049173, 0.79868, 0.0016352, 0.34968, 0.0063542]
Predicted label: 6
Correct prediction
Energy consumption = 144.769299 pJ
sum error= 341
Actual label: 7
Output voltages: [0.12308, 0.031076, 0.53883, 0.15824, 0.0011552, 0.002579, 0.0010907, 0.79879, 0.77766, 0.042478]
Predicted label: 7
Correct prediction
Energy consumption = 157.927463 pJ
sum error= 341
Actual label: 8
Output voltages: [0.042783, 0.042145, 0.48971, 0.033455, 0.010885, 0.0040375, 0.017422, 0.0022, 0.7987, 0.12917]
Predicted label: 8
Correct prediction
Energy consumption = 145.213255 pJ
sum error= 341
Actual label: 9
Output voltages: [0.18106, 0.0048724, 0.024312, 0.068495, 0.14581, 0.31165, 0.10743, 0.14155, 0.39698, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 151.261785 pJ
sum error= 341
Actual label: 0
Output voltages: [0.79866, 0.063761, 0.057707, 0.011645, 0.00181, 0.0054514, 0.58192, 0.023314, 0.25054, 0.042095]
Predicted label: 0
Correct prediction
Energy consumption = 144.736928 pJ
sum error= 341
Actual label: 1
Output voltages: [0.0078143, 0.79865, 0.073556, 0.1166, 0.020467, 0.0016399, 0.34119, 0.0025968, 0.38948, 0.038577]
Predicted label: 1
Correct prediction
Energy consumption = 157.061824 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 847 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 847 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 847 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36992, 0.10476, 0.79849, 0.29472, 0.079574, 0.001092, 0.031642, 0.028338, 0.29792, 0.012502]
Predicted label: 2
Correct prediction
Energy consumption = 148.270682 pJ
sum error= 341
Actual label: 3
Output voltages: [0.23848, 0.013387, 0.091534, 0.79873, 0.07217, 0.0051324, 0.012596, 0.01005, 0.64914, 0.06905]
Predicted label: 3
Correct prediction
Energy consumption = 142.191297 pJ
sum error= 341
Actual label: 4
Output voltages: [0.053585, 0.0024282, 0.39411, 0.0014316, 0.79806, 0.0010801, 0.071697, 0.0019501, 0.3419, 0.49864]
Predicted label: 4
Correct prediction
Energy consumption = 152.677874 pJ
sum error= 341
Actual label: 5
Output voltages: [0.037704, 0.0012185, 0.0032142, 0.73995, 0.038159, 0.79867, 0.072804, 0.013877, 0.74883, 0.033633]
Predicted label: 5
Correct prediction
Energy consumption = 147.188829 pJ
sum error= 341
Actual label: 6
Output voltages: [0.15917, 0.11388, 0.13166, 0.0052065, 0.10865, 0.35204, 0.79875, 0.0029934, 0.26895, 0.0037414]
Predicted label: 6
Correct prediction
Energy consumption = 141.988222 pJ
sum error= 341
Actual label: 7
Output voltages: [0.24999, 0.043024, 0.23847, 0.020264, 0.001079, 0.0014578, 0.0010926, 0.79879, 0.69468, 0.25556]
Predicted label: 7
Correct prediction
Energy consumption = 160.648326 pJ
sum error= 341
Actual label: 8
Output voltages: [0.19904, 0.0032844, 0.051764, 0.2203, 0.026244, 0.10552, 0.03897, 0.0010662, 0.79821, 0.078712]
Predicted label: 8
Correct prediction
Energy consumption = 145.419237 pJ
sum error= 341
Actual label: 9
Output voltages: [0.26389, 0.0016261, 0.0398, 0.028379, 0.032355, 0.0047297, 0.0015703, 0.16643, 0.73327, 0.77658]
Predicted label: 9
Correct prediction
Energy consumption = 146.547241 pJ
sum error= 341
Actual label: 6
Output voltages: [0.43291, 0.063417, 0.036788, 0.012453, 0.2378, 0.70484, 0.79879, 0.0022082, 0.43158, 0.0094797]
Predicted label: 6
Correct prediction
Energy consumption = 148.075279 pJ
sum error= 341
Actual label: 9
Output voltages: [0.48889, 0.0016803, 0.019429, 0.016426, 0.067766, 0.0031402, 0.0024672, 0.31705, 0.42019, 0.79393]
Predicted label: 9
Correct prediction
Energy consumption = 154.344126 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 848 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 848 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 848 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.052846, 0.059409, 0.10699, 0.0077027, 0.0052725, 0.0034723, 0.0011033, 0.79865, 0.51448, 0.091649]
Predicted label: 7
Correct prediction
Energy consumption = 157.425325 pJ
sum error= 341
Actual label: 0
Output voltages: [0.79879, 0.099353, 0.022149, 0.033155, 0.0062986, 0.022744, 0.35797, 0.013865, 0.035485, 0.055667]
Predicted label: 0
Correct prediction
Energy consumption = 157.043091 pJ
sum error= 341
Actual label: 2
Output voltages: [0.47947, 0.03966, 0.79878, 0.28186, 0.03417, 0.0011879, 0.044026, 0.022089, 0.52237, 0.022714]
Predicted label: 2
Correct prediction
Energy consumption = 145.493345 pJ
sum error= 341
Actual label: 3
Output voltages: [0.66446, 0.018319, 0.077372, 0.79866, 0.019421, 0.0056021, 0.024152, 0.0056072, 0.4477, 0.043163]
Predicted label: 3
Correct prediction
Energy consumption = 143.329634 pJ
sum error= 341
Actual label: 4
Output voltages: [0.0033955, 0.024656, 0.067165, 0.0010905, 0.79855, 0.0063526, 0.17547, 0.039093, 0.053164, 0.059533]
Predicted label: 4
Correct prediction
Energy consumption = 156.770598 pJ
sum error= 341
Actual label: 3
Output voltages: [0.18842, 0.018223, 0.12219, 0.79878, 0.033283, 0.0024596, 0.030957, 0.0054651, 0.70871, 0.1048]
Predicted label: 3
Correct prediction
Energy consumption = 153.203894 pJ
sum error= 341
Actual label: 8
Output voltages: [0.45672, 0.018095, 0.38259, 0.024979, 0.016711, 0.0033452, 0.0062242, 0.0015755, 0.79879, 0.37719]
Predicted label: 8
Correct prediction
Energy consumption = 149.439193 pJ
sum error= 341
Actual label: 5
Output voltages: [0.065331, 0.0011093, 0.0011095, 0.27039, 0.031819, 0.79801, 0.14602, 0.022215, 0.76584, 0.022153]
Predicted label: 5
Correct prediction
Energy consumption = 141.578739 pJ
sum error= 341
Actual label: 1
Output voltages: [0.015983, 0.79868, 0.0044324, 0.12014, 0.097874, 0.013818, 0.59363, 0.0034105, 0.39109, 0.047621]
Predicted label: 1
Correct prediction
Energy consumption = 161.595865 pJ
sum error= 341
Actual label: 3
Output voltages: [0.39622, 0.0091753, 0.20853, 0.79874, 0.023451, 0.032284, 0.019168, 0.0063664, 0.64577, 0.13363]
Predicted label: 3
Correct prediction
Energy consumption = 152.373198 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 849 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 849 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 849 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.026447, 0.044473, 0.014717, 0.0043219, 0.0079133, 0.53534, 0.056535, 0.14424, 0.026004]
Predicted label: 0
Correct prediction
Energy consumption = 146.855107 pJ
sum error= 341
Actual label: 1
Output voltages: [0.033397, 0.79863, 0.1601, 0.29394, 0.0012265, 0.003697, 0.5049, 0.014854, 0.31147, 0.0085778]
Predicted label: 1
Correct prediction
Energy consumption = 163.064720 pJ
sum error= 341
Actual label: 2
Output voltages: [0.13636, 0.021135, 0.79866, 0.096106, 0.029554, 0.0011349, 0.28101, 0.19658, 0.0491, 0.27747]
Predicted label: 2
Correct prediction
Energy consumption = 137.854106 pJ
sum error= 341
Actual label: 1
Output voltages: [0.0281, 0.79866, 0.028792, 0.11523, 0.030042, 0.0018, 0.12927, 0.0012076, 0.48772, 0.042999]
Predicted label: 1
Correct prediction
Energy consumption = 159.012038 pJ
sum error= 341
Actual label: 3
Output voltages: [0.4567, 0.008428, 0.039568, 0.79864, 0.02264, 0.028457, 0.023549, 0.0071209, 0.56765, 0.058716]
Predicted label: 3
Correct prediction
Energy consumption = 146.179698 pJ
sum error= 341
Actual label: 2
Output voltages: [0.352, 0.18893, 0.79701, 0.67713, 0.012099, 0.0012072, 0.37862, 0.0021067, 0.4226, 0.0057039]
Predicted label: 2
Correct prediction
Energy consumption = 138.843685 pJ
sum error= 341
Actual label: 0
Output voltages: [0.79812, 0.019119, 0.024734, 0.0014386, 0.0059388, 0.017087, 0.74957, 0.0013373, 0.050844, 0.056224]
Predicted label: 0
Correct prediction
Energy consumption = 146.007962 pJ
sum error= 341
Actual label: 7
Output voltages: [0.085777, 0.54405, 0.20559, 0.45433, 0.0022118, 0.0011419, 0.0012188, 0.79806, 0.55723, 0.081675]
Predicted label: 7
Correct prediction
Energy consumption = 160.925464 pJ
sum error= 341
Actual label: 2
Output voltages: [0.29812, 0.1711, 0.78906, 0.57679, 0.015912, 0.0012461, 0.34732, 0.018599, 0.65089, 0.053098]
Predicted label: 2
Correct prediction
Energy consumption = 143.591715 pJ
sum error= 341
Actual label: 6
Output voltages: [0.1027, 0.035503, 0.17489, 0.0028016, 0.35949, 0.35498, 0.79876, 0.0027283, 0.48377, 0.0023706]
Predicted label: 6
Correct prediction
Energy consumption = 148.082812 pJ
sum error= 341
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 850 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 850 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 850 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0077959, 0.01786, 0.088967, 0.018719, 0.79853, 0.0037918, 0.12033, 0.52785, 0.033067, 0.036214]
Predicted label: 4
Correct prediction
Energy consumption = 150.248379 pJ
sum error= 341
Actual label: 0
Output voltages: [0.79875, 0.043668, 0.015972, 0.027549, 0.03395, 0.011094, 0.55518, 0.032437, 0.19758, 0.11527]
Predicted label: 0
Correct prediction
Energy consumption = 152.590267 pJ
sum error= 341
Actual label: 5
Output voltages: [0.02229, 0.0014465, 0.0045411, 0.76107, 0.0027548, 0.72238, 0.016481, 0.0050307, 0.70038, 0.14181]
Predicted label: 3
Wrong prediction!
Energy consumption = 146.825775 pJ
sum error= 342
Actual label: 9
Output voltages: [0.3984, 0.0097706, 0.0068601, 0.024237, 0.037209, 0.22657, 0.0037754, 0.040637, 0.34559, 0.7942]
Predicted label: 9
Correct prediction
Energy consumption = 150.076819 pJ
sum error= 342
Actual label: 9
Output voltages: [0.05997, 0.0011432, 0.022281, 0.045232, 0.030207, 0.67963, 0.0061345, 0.31652, 0.74502, 0.76839]
Predicted label: 9
Correct prediction
Energy consumption = 146.341740 pJ
sum error= 342
Actual label: 8
Output voltages: [0.39572, 0.0091948, 0.20855, 0.18324, 0.0041312, 0.12709, 0.023732, 0.0037777, 0.79849, 0.086774]
Predicted label: 8
Correct prediction
Energy consumption = 147.678648 pJ
sum error= 342
Actual label: 9
Output voltages: [0.30964, 0.01083, 0.016378, 0.013354, 0.11247, 0.011029, 0.0022748, 0.026617, 0.6069, 0.79804]
Predicted label: 9
Correct prediction
Energy consumption = 151.602970 pJ
sum error= 342
Actual label: 5
Output voltages: [0.20406, 0.0011163, 0.0017516, 0.093792, 0.022189, 0.79865, 0.45994, 0.0045513, 0.78103, 0.0013643]
Predicted label: 5
Correct prediction
Energy consumption = 137.151572 pJ
sum error= 342
Actual label: 3
Output voltages: [0.54815, 0.0092714, 0.027348, 0.79865, 0.022319, 0.084672, 0.014175, 0.018688, 0.45287, 0.022591]
Predicted label: 3
Correct prediction
Energy consumption = 147.505896 pJ
sum error= 342
Actual label: 1
Output voltages: [0.040121, 0.79879, 0.038374, 0.29031, 0.050066, 0.0014496, 0.47574, 0.0010662, 0.42416, 0.0074997]
Predicted label: 1
Correct prediction
Energy consumption = 161.168737 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 851 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 851 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 851 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.041699, 0.44115, 0.30383, 0.32115, 0.0017597, 0.0011043, 0.0012012, 0.79871, 0.70558, 0.15435]
Predicted label: 7
Correct prediction
Energy consumption = 161.655700 pJ
sum error= 342
Actual label: 4
Output voltages: [0.03368, 0.0029292, 0.13399, 0.0019869, 0.79867, 0.0021194, 0.16826, 0.2187, 0.040402, 0.018052]
Predicted label: 4
Correct prediction
Energy consumption = 155.471086 pJ
sum error= 342
Actual label: 7
Output voltages: [0.051992, 0.081155, 0.23092, 0.37849, 0.0065687, 0.0010785, 0.0011388, 0.79879, 0.43498, 0.11315]
Predicted label: 7
Correct prediction
Energy consumption = 156.833588 pJ
sum error= 342
Actual label: 0
Output voltages: [0.79875, 0.010921, 0.031024, 0.08085, 0.0021629, 0.017824, 0.37357, 0.036713, 0.14553, 0.06894]
Predicted label: 0
Correct prediction
Energy consumption = 142.565811 pJ
sum error= 342
Actual label: 0
Output voltages: [0.79872, 0.071431, 0.047426, 0.018861, 0.0087348, 0.0022272, 0.75449, 0.020475, 0.29251, 0.12068]
Predicted label: 0
Correct prediction
Energy consumption = 138.919594 pJ
sum error= 342
Actual label: 6
Output voltages: [0.026738, 0.10708, 0.43301, 0.0014142, 0.16326, 0.18732, 0.79871, 0.0047267, 0.33512, 0.009992]
Predicted label: 6
Correct prediction
Energy consumption = 144.554025 pJ
sum error= 342
Actual label: 6
Output voltages: [0.2231, 0.11884, 0.20313, 0.004196, 0.32883, 0.16859, 0.79871, 0.0011057, 0.41348, 0.013941]
Predicted label: 6
Correct prediction
Energy consumption = 138.884081 pJ
sum error= 342
Actual label: 6
Output voltages: [0.055057, 0.014694, 0.27334, 0.0011489, 0.5728, 0.47746, 0.79873, 0.0013313, 0.60953, 0.0013141]
Predicted label: 6
Correct prediction
Energy consumption = 140.123830 pJ
sum error= 342
Actual label: 3
Output voltages: [0.3441, 0.022586, 0.030364, 0.79867, 0.012532, 0.0057621, 0.0086176, 0.015999, 0.481, 0.044475]
Predicted label: 3
Correct prediction
Energy consumption = 156.624367 pJ
sum error= 342
Actual label: 7
Output voltages: [0.24994, 0.61678, 0.43378, 0.23701, 0.0010812, 0.0012175, 0.0029534, 0.79871, 0.067608, 0.050879]
Predicted label: 7
Correct prediction
Energy consumption = 150.976358 pJ
sum error= 342
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 852 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 852 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 852 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0051186, 0.027245, 0.026853, 0.028075, 0.77087, 0.0010836, 0.0012923, 0.01429, 0.35811, 0.78038]
Predicted label: 9
Wrong prediction!
Energy consumption = 155.508119 pJ
sum error= 343
Actual label: 2
Output voltages: [0.41725, 0.3642, 0.79878, 0.50608, 0.0063926, 0.001321, 0.046969, 0.056711, 0.12297, 0.044082]
Predicted label: 2
Correct prediction
Energy consumption = 148.837576 pJ
sum error= 343
Actual label: 8
Output voltages: [0.027065, 0.0011744, 0.34946, 0.094241, 0.02916, 0.022809, 0.66194, 0.0032615, 0.79872, 0.01432]
Predicted label: 8
Correct prediction
Energy consumption = 146.348791 pJ
sum error= 343
Actual label: 9
Output voltages: [0.18442, 0.001094, 0.060447, 0.17331, 0.34802, 0.0081361, 0.0012315, 0.45178, 0.045244, 0.7935]
Predicted label: 9
Correct prediction
Energy consumption = 157.128112 pJ
sum error= 343
Actual label: 8
Output voltages: [0.026968, 0.026687, 0.68768, 0.062691, 0.016278, 0.0011235, 0.28973, 0.0038826, 0.79872, 0.050278]
Predicted label: 8
Correct prediction
Energy consumption = 154.018248 pJ
sum error= 343
Actual label: 7
Output voltages: [0.17218, 0.19541, 0.11397, 0.52437, 0.014405, 0.001159, 0.0011087, 0.79848, 0.44688, 0.16113]
Predicted label: 7
Correct prediction
Energy consumption = 160.481830 pJ
sum error= 343
Actual label: 1
Output voltages: [0.035186, 0.79849, 0.20605, 0.22991, 0.0023462, 0.0010666, 0.50157, 0.0039085, 0.079361, 0.035288]
Predicted label: 1
Correct prediction
Energy consumption = 159.463813 pJ
sum error= 343
Actual label: 4
Output voltages: [0.27511, 0.0027465, 0.028591, 0.014177, 0.71561, 0.033986, 0.044203, 0.23981, 0.047352, 0.79507]
Predicted label: 9
Wrong prediction!
Energy consumption = 159.976470 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79876, 0.027029, 0.03294, 0.0079341, 0.0090186, 0.23868, 0.32896, 0.0047151, 0.01401, 0.026369]
Predicted label: 0
Correct prediction
Energy consumption = 154.904543 pJ
sum error= 344
Actual label: 4
Output voltages: [0.057895, 0.015395, 0.066023, 0.0010692, 0.79866, 0.032262, 0.26843, 0.024744, 0.093717, 0.11149]
Predicted label: 4
Correct prediction
Energy consumption = 152.765323 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 853 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 853 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 853 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.42678, 0.0018397, 0.13027, 0.15883, 0.025998, 0.011074, 0.048091, 0.002002, 0.79852, 0.049512]
Predicted label: 8
Correct prediction
Energy consumption = 147.906589 pJ
sum error= 344
Actual label: 5
Output voltages: [0.010813, 0.0010753, 0.002729, 0.30177, 0.1586, 0.79873, 0.42454, 0.013773, 0.75322, 0.044836]
Predicted label: 5
Correct prediction
Energy consumption = 149.554172 pJ
sum error= 344
Actual label: 2
Output voltages: [0.45955, 0.13702, 0.79879, 0.28422, 0.013561, 0.0012406, 0.37909, 0.013491, 0.56143, 0.015664]
Predicted label: 2
Correct prediction
Energy consumption = 147.180908 pJ
sum error= 344
Actual label: 3
Output voltages: [0.52769, 0.01522, 0.45024, 0.79879, 0.0090979, 0.0012852, 0.0058557, 0.0030558, 0.58421, 0.025525]
Predicted label: 3
Correct prediction
Energy consumption = 147.149886 pJ
sum error= 344
Actual label: 9
Output voltages: [0.25396, 0.0011042, 0.038546, 0.45375, 0.062612, 0.022855, 0.041962, 0.49819, 0.037455, 0.78776]
Predicted label: 9
Correct prediction
Energy consumption = 154.050094 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79856, 0.16449, 0.021157, 0.0022728, 0.011707, 0.0045765, 0.59659, 0.018923, 0.14724, 0.22446]
Predicted label: 0
Correct prediction
Energy consumption = 149.191691 pJ
sum error= 344
Actual label: 1
Output voltages: [0.01582, 0.79867, 0.16911, 0.061844, 0.094249, 0.024651, 0.044929, 0.28433, 0.053035, 0.016407]
Predicted label: 1
Correct prediction
Energy consumption = 166.272256 pJ
sum error= 344
Actual label: 9
Output voltages: [0.31201, 0.0054843, 0.024625, 0.013896, 0.11802, 0.05602, 0.023651, 0.39815, 0.26823, 0.79657]
Predicted label: 9
Correct prediction
Energy consumption = 157.551820 pJ
sum error= 344
Actual label: 1
Output voltages: [0.061103, 0.79878, 0.046638, 0.33607, 0.040789, 0.0027716, 0.051655, 0.078313, 0.28362, 0.094035]
Predicted label: 1
Correct prediction
Energy consumption = 165.259989 pJ
sum error= 344
Actual label: 5
Output voltages: [0.30419, 0.0013104, 0.0010664, 0.21738, 0.014828, 0.79877, 0.22906, 0.3021, 0.6186, 0.0093196]
Predicted label: 5
Correct prediction
Energy consumption = 155.834692 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 854 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 854 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 854 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.011251, 0.79853, 0.31953, 0.57436, 0.036112, 0.0015542, 0.1084, 0.055162, 0.01419, 0.048321]
Predicted label: 1
Correct prediction
Energy consumption = 166.286263 pJ
sum error= 344
Actual label: 7
Output voltages: [0.090133, 0.14639, 0.1042, 0.2858, 0.0010679, 0.0010661, 0.0012002, 0.79879, 0.52551, 0.46094]
Predicted label: 7
Correct prediction
Energy consumption = 152.991603 pJ
sum error= 344
Actual label: 6
Output voltages: [0.044659, 0.11678, 0.1123, 0.021696, 0.25842, 0.34269, 0.79878, 0.012761, 0.7359, 0.011741]
Predicted label: 6
Correct prediction
Energy consumption = 162.817756 pJ
sum error= 344
Actual label: 1
Output voltages: [0.048216, 0.79847, 0.30741, 0.46923, 0.02085, 0.021837, 0.056537, 0.065598, 0.007529, 0.11184]
Predicted label: 1
Correct prediction
Energy consumption = 163.645349 pJ
sum error= 344
Actual label: 2
Output voltages: [0.70791, 0.018924, 0.79833, 0.30417, 0.0012363, 0.0010691, 0.057002, 0.014331, 0.45007, 0.0029474]
Predicted label: 2
Correct prediction
Energy consumption = 146.049634 pJ
sum error= 344
Actual label: 1
Output voltages: [0.017687, 0.79857, 0.30758, 0.17045, 0.11244, 0.011905, 0.34909, 0.51536, 0.014489, 0.038228]
Predicted label: 1
Correct prediction
Energy consumption = 162.958994 pJ
sum error= 344
Actual label: 6
Output voltages: [0.13387, 0.13132, 0.040047, 0.021936, 0.60694, 0.59427, 0.79869, 0.020654, 0.73126, 0.0024599]
Predicted label: 6
Correct prediction
Energy consumption = 156.364796 pJ
sum error= 344
Actual label: 8
Output voltages: [0.31378, 0.012291, 0.05728, 0.071179, 0.050242, 0.033576, 0.026424, 0.0021012, 0.79875, 0.08795]
Predicted label: 8
Correct prediction
Energy consumption = 144.748900 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79872, 0.087946, 0.0068369, 0.015808, 0.0076041, 0.13773, 0.45332, 0.0059392, 0.095096, 0.25293]
Predicted label: 0
Correct prediction
Energy consumption = 151.941629 pJ
sum error= 344
Actual label: 1
Output voltages: [0.0085417, 0.79841, 0.056596, 0.06736, 0.011741, 0.0016839, 0.60446, 0.0035892, 0.1427, 0.059441]
Predicted label: 1
Correct prediction
Energy consumption = 156.873578 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 855 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 855 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 855 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.044571, 0.037748, 0.79875, 0.22164, 0.020455, 0.0012351, 0.0212, 0.17923, 0.061173, 0.032934]
Predicted label: 2
Correct prediction
Energy consumption = 146.478954 pJ
sum error= 344
Actual label: 3
Output voltages: [0.20377, 0.0054732, 0.22739, 0.79872, 0.024615, 0.010831, 0.030935, 0.0042062, 0.53499, 0.064708]
Predicted label: 3
Correct prediction
Energy consumption = 140.458874 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0014523, 0.0018965, 0.36032, 0.010266, 0.79859, 0.0014882, 0.098602, 0.094838, 0.036353, 0.048301]
Predicted label: 4
Correct prediction
Energy consumption = 155.165105 pJ
sum error= 344
Actual label: 5
Output voltages: [0.07464, 0.017452, 0.010617, 0.1306, 0.0032802, 0.79872, 0.10787, 0.24468, 0.51392, 0.016297]
Predicted label: 5
Correct prediction
Energy consumption = 152.134594 pJ
sum error= 344
Actual label: 6
Output voltages: [0.23393, 0.16529, 0.32242, 0.0055139, 0.25494, 0.063674, 0.79873, 0.0015465, 0.26986, 0.015469]
Predicted label: 6
Correct prediction
Energy consumption = 151.650524 pJ
sum error= 344
Actual label: 7
Output voltages: [0.056567, 0.010503, 0.039974, 0.19308, 0.0037953, 0.010645, 0.001084, 0.79861, 0.059894, 0.32356]
Predicted label: 7
Correct prediction
Energy consumption = 159.105005 pJ
sum error= 344
Actual label: 8
Output voltages: [0.028414, 0.011208, 0.064259, 0.15563, 0.0042403, 0.18428, 0.017887, 0.0027183, 0.79871, 0.21639]
Predicted label: 8
Correct prediction
Energy consumption = 149.373421 pJ
sum error= 344
Actual label: 9
Output voltages: [0.054543, 0.0178, 0.02656, 0.40234, 0.060719, 0.19562, 0.030129, 0.060023, 0.43984, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 147.006549 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79874, 0.12921, 0.0040794, 0.017959, 0.0099689, 0.30139, 0.75468, 0.028434, 0.2667, 0.010457]
Predicted label: 0
Correct prediction
Energy consumption = 159.599244 pJ
sum error= 344
Actual label: 1
Output voltages: [0.011877, 0.79842, 0.0014995, 0.034751, 0.018246, 0.019887, 0.4361, 0.019952, 0.43063, 0.028796]
Predicted label: 1
Correct prediction
Energy consumption = 161.034463 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 856 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 856 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 856 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.64552, 0.017273, 0.79832, 0.58801, 0.014088, 0.0012182, 0.0090979, 0.036465, 0.50336, 0.0035053]
Predicted label: 2
Correct prediction
Energy consumption = 154.107108 pJ
sum error= 344
Actual label: 3
Output voltages: [0.014188, 0.022503, 0.044924, 0.79829, 0.022738, 0.045897, 0.0013524, 0.033928, 0.77241, 0.12827]
Predicted label: 3
Correct prediction
Energy consumption = 138.254627 pJ
sum error= 344
Actual label: 4
Output voltages: [0.011506, 0.018783, 0.21162, 0.0047874, 0.79858, 0.0035975, 0.081105, 0.22623, 0.02394, 0.026443]
Predicted label: 4
Correct prediction
Energy consumption = 149.878275 pJ
sum error= 344
Actual label: 5
Output voltages: [0.028449, 0.0011838, 0.0030128, 0.60474, 0.031527, 0.79879, 0.10481, 0.14931, 0.7095, 0.19917]
Predicted label: 5
Correct prediction
Energy consumption = 143.392986 pJ
sum error= 344
Actual label: 6
Output voltages: [0.089341, 0.25375, 0.24496, 0.0012842, 0.22819, 0.13909, 0.79866, 0.0021767, 0.31709, 0.0086432]
Predicted label: 6
Correct prediction
Energy consumption = 154.310702 pJ
sum error= 344
Actual label: 7
Output voltages: [0.12932, 0.3952, 0.30031, 0.48508, 0.0010712, 0.0010939, 0.0056441, 0.79559, 0.24358, 0.39993]
Predicted label: 7
Correct prediction
Energy consumption = 164.941959 pJ
sum error= 344
Actual label: 8
Output voltages: [0.020671, 0.023221, 0.048752, 0.044091, 0.035593, 0.10952, 0.034772, 0.0072197, 0.79866, 0.039188]
Predicted label: 8
Correct prediction
Energy consumption = 154.086591 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79824, 0.036775, 0.03319, 0.024506, 0.0013339, 0.087963, 0.29788, 0.0018031, 0.061555, 0.047415]
Predicted label: 0
Correct prediction
Energy consumption = 154.322846 pJ
sum error= 344
Actual label: 1
Output voltages: [0.016041, 0.79844, 0.048123, 0.078315, 0.047675, 0.002637, 0.66836, 0.0025304, 0.17458, 0.13102]
Predicted label: 1
Correct prediction
Energy consumption = 159.985404 pJ
sum error= 344
Actual label: 2
Output voltages: [0.50705, 0.0017224, 0.79877, 0.44255, 0.0095405, 0.0014244, 0.025083, 0.058597, 0.47726, 0.0059848]
Predicted label: 2
Correct prediction
Energy consumption = 146.599621 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 857 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 857 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 857 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.065197, 0.017306, 0.057441, 0.79875, 0.028578, 0.030996, 0.0036566, 0.0051669, 0.73718, 0.04087]
Predicted label: 3
Correct prediction
Energy consumption = 150.836279 pJ
sum error= 344
Actual label: 5
Output voltages: [0.13934, 0.0014258, 0.0024795, 0.32476, 0.011075, 0.79874, 0.18999, 0.045818, 0.70217, 0.031716]
Predicted label: 5
Correct prediction
Energy consumption = 143.384757 pJ
sum error= 344
Actual label: 6
Output voltages: [0.042745, 0.20767, 0.18102, 0.0020116, 0.15946, 0.15077, 0.7987, 0.0015503, 0.33273, 0.0043749]
Predicted label: 6
Correct prediction
Energy consumption = 150.240631 pJ
sum error= 344
Actual label: 7
Output voltages: [0.48605, 0.1985, 0.030743, 0.40313, 0.010303, 0.038981, 0.001069, 0.7986, 0.021007, 0.29565]
Predicted label: 7
Correct prediction
Energy consumption = 159.928431 pJ
sum error= 344
Actual label: 8
Output voltages: [0.074273, 0.010693, 0.21967, 0.035069, 0.016824, 0.023125, 0.020789, 0.0070655, 0.79865, 0.040722]
Predicted label: 8
Correct prediction
Energy consumption = 145.996558 pJ
sum error= 344
Actual label: 1
Output voltages: [0.0027262, 0.7986, 0.13336, 0.19885, 0.011952, 0.0040099, 0.43971, 0.013096, 0.55528, 0.20354]
Predicted label: 1
Correct prediction
Energy consumption = 163.168695 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.071467, 0.010629, 0.010645, 0.11628, 0.04749, 0.7628, 0.0076545, 0.038221, 0.0543]
Predicted label: 0
Correct prediction
Energy consumption = 162.335821 pJ
sum error= 344
Actual label: 4
Output voltages: [0.011088, 0.0030719, 0.23808, 0.026588, 0.79862, 0.0010674, 0.024067, 0.14058, 0.013222, 0.05716]
Predicted label: 4
Correct prediction
Energy consumption = 156.002036 pJ
sum error= 344
Actual label: 5
Output voltages: [0.49041, 0.0021195, 0.0019562, 0.60033, 0.03534, 0.79878, 0.36217, 0.020258, 0.53365, 0.054249]
Predicted label: 5
Correct prediction
Energy consumption = 149.832155 pJ
sum error= 344
Actual label: 6
Output voltages: [0.15992, 0.25509, 0.3368, 0.0059294, 0.28729, 0.1166, 0.79869, 0.0013008, 0.26413, 0.022895]
Predicted label: 6
Correct prediction
Energy consumption = 145.474906 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 858 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 858 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 858 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.35751, 0.049143, 0.36101, 0.0013965, 0.35575, 0.28245, 0.79877, 0.0017034, 0.16874, 0.015636]
Predicted label: 6
Correct prediction
Energy consumption = 151.565917 pJ
sum error= 344
Actual label: 3
Output voltages: [0.16985, 0.022106, 0.084619, 0.79875, 0.017153, 0.001354, 0.0066764, 0.0042981, 0.64855, 0.034681]
Predicted label: 3
Correct prediction
Energy consumption = 147.131768 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0040414, 0.01377, 0.205, 0.027096, 0.79863, 0.0064048, 0.20165, 0.042557, 0.019547, 0.039881]
Predicted label: 4
Correct prediction
Energy consumption = 148.088072 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0043045, 0.0011894, 0.47267, 0.0076988, 0.79857, 0.0014359, 0.046714, 0.0099993, 0.053531, 0.12527]
Predicted label: 4
Correct prediction
Energy consumption = 144.731011 pJ
sum error= 344
Actual label: 2
Output voltages: [0.67582, 0.080807, 0.79879, 0.30088, 0.0021422, 0.00108, 0.22888, 0.0030616, 0.27998, 0.06168]
Predicted label: 2
Correct prediction
Energy consumption = 150.022404 pJ
sum error= 344
Actual label: 8
Output voltages: [0.024341, 0.031562, 0.10428, 0.090188, 0.0040752, 0.027413, 0.037122, 0.016935, 0.79869, 0.18406]
Predicted label: 8
Correct prediction
Energy consumption = 150.516828 pJ
sum error= 344
Actual label: 1
Output voltages: [0.0071356, 0.79848, 0.17849, 0.24592, 0.038246, 0.0021023, 0.74079, 0.016376, 0.18373, 0.050273]
Predicted label: 1
Correct prediction
Energy consumption = 164.480503 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79812, 0.090209, 0.011554, 0.0082448, 0.058323, 0.027091, 0.77397, 0.0043344, 0.05575, 0.020039]
Predicted label: 0
Correct prediction
Energy consumption = 157.733436 pJ
sum error= 344
Actual label: 6
Output voltages: [0.056873, 0.11633, 0.16348, 0.0059476, 0.42335, 0.22363, 0.79868, 0.0013201, 0.36672, 0.020306]
Predicted label: 6
Correct prediction
Energy consumption = 142.281502 pJ
sum error= 344
Actual label: 4
Output voltages: [0.004728, 0.0083734, 0.18739, 0.016576, 0.79865, 0.00382, 0.10339, 0.038973, 0.12853, 0.01124]
Predicted label: 4
Correct prediction
Energy consumption = 154.457684 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 859 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 859 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 859 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.041902, 0.016266, 0.14813, 0.17574, 0.080053, 0.071512, 0.059402, 0.11517, 0.22589, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 158.634634 pJ
sum error= 344
Actual label: 7
Output voltages: [0.14817, 0.56548, 0.025571, 0.54198, 0.0040274, 0.0011244, 0.0033124, 0.79765, 0.019052, 0.30182]
Predicted label: 7
Correct prediction
Energy consumption = 163.107124 pJ
sum error= 344
Actual label: 2
Output voltages: [0.39619, 0.033285, 0.79867, 0.041392, 0.0093614, 0.0010816, 0.03046, 0.018787, 0.36486, 0.0033548]
Predicted label: 2
Correct prediction
Energy consumption = 145.015415 pJ
sum error= 344
Actual label: 9
Output voltages: [0.25416, 0.0026313, 0.04685, 0.002971, 0.69811, 0.020716, 0.020409, 0.047761, 0.057955, 0.79854]
Predicted label: 9
Correct prediction
Energy consumption = 158.256141 pJ
sum error= 344
Actual label: 2
Output voltages: [0.52717, 0.013003, 0.79879, 0.13409, 0.017551, 0.0011049, 0.02176, 0.043954, 0.56417, 0.0053139]
Predicted label: 2
Correct prediction
Energy consumption = 156.442672 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.090886, 0.026671, 0.012066, 0.02146, 0.022452, 0.63611, 0.015171, 0.04913, 0.018632]
Predicted label: 0
Correct prediction
Energy consumption = 151.713714 pJ
sum error= 344
Actual label: 9
Output voltages: [0.32466, 0.030746, 0.018231, 0.3951, 0.4302, 0.064623, 0.23884, 0.035914, 0.032593, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 156.910683 pJ
sum error= 344
Actual label: 3
Output voltages: [0.031322, 0.022517, 0.32778, 0.79879, 0.012798, 0.031179, 0.0024436, 0.023778, 0.70609, 0.041076]
Predicted label: 3
Correct prediction
Energy consumption = 147.861991 pJ
sum error= 344
Actual label: 3
Output voltages: [0.29646, 0.0053283, 0.17015, 0.79873, 0.029048, 0.0027869, 0.017095, 0.0019012, 0.39413, 0.070228]
Predicted label: 3
Correct prediction
Energy consumption = 138.904725 pJ
sum error= 344
Actual label: 9
Output voltages: [0.1977, 0.014156, 0.045319, 0.28303, 0.40335, 0.0050394, 0.019298, 0.0025508, 0.10448, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 145.635354 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 860 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 860 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 860 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0098772, 0.79867, 0.60638, 0.1119, 0.029872, 0.001066, 0.39992, 0.004242, 0.11551, 0.032133]
Predicted label: 1
Correct prediction
Energy consumption = 161.649683 pJ
sum error= 344
Actual label: 5
Output voltages: [0.01715, 0.0012359, 0.0015737, 0.51318, 0.03704, 0.79758, 0.069852, 0.019735, 0.6884, 0.31968]
Predicted label: 5
Correct prediction
Energy consumption = 150.321770 pJ
sum error= 344
Actual label: 2
Output voltages: [0.61917, 0.0041099, 0.79855, 0.42459, 0.0037156, 0.0010797, 0.034704, 0.0086742, 0.49215, 0.0069132]
Predicted label: 2
Correct prediction
Energy consumption = 152.127397 pJ
sum error= 344
Actual label: 3
Output voltages: [0.75539, 0.0030567, 0.26399, 0.79878, 0.055418, 0.018229, 0.014624, 0.00591, 0.69973, 0.0080167]
Predicted label: 3
Correct prediction
Energy consumption = 139.398772 pJ
sum error= 344
Actual label: 1
Output voltages: [0.0047146, 0.79851, 0.028532, 0.11866, 0.034577, 0.0048617, 0.22012, 0.013827, 0.72108, 0.047769]
Predicted label: 1
Correct prediction
Energy consumption = 165.563956 pJ
sum error= 344
Actual label: 6
Output voltages: [0.14054, 0.27243, 0.20942, 0.0058108, 0.25581, 0.13985, 0.7987, 0.0017706, 0.22307, 0.010266]
Predicted label: 6
Correct prediction
Energy consumption = 152.336031 pJ
sum error= 344
Actual label: 7
Output voltages: [0.38587, 0.43713, 0.34603, 0.4521, 0.0022781, 0.0011338, 0.0010901, 0.79872, 0.055351, 0.33834]
Predicted label: 7
Correct prediction
Energy consumption = 164.073548 pJ
sum error= 344
Actual label: 3
Output voltages: [0.069295, 0.031033, 0.073069, 0.79789, 0.0020038, 0.036134, 0.010494, 0.018156, 0.786, 0.096445]
Predicted label: 3
Correct prediction
Energy consumption = 143.724654 pJ
sum error= 344
Actual label: 7
Output voltages: [0.085049, 0.046983, 0.03456, 0.40884, 0.0038316, 0.0025944, 0.001069, 0.79869, 0.12754, 0.6906]
Predicted label: 7
Correct prediction
Energy consumption = 155.240010 pJ
sum error= 344
Actual label: 8
Output voltages: [0.0049015, 0.039285, 0.11156, 0.030731, 0.030538, 0.01714, 0.0045777, 0.013503, 0.79874, 0.15707]
Predicted label: 8
Correct prediction
Energy consumption = 143.594175 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 861 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 861 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 861 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0062197, 0.0021595, 0.060943, 0.006709, 0.79866, 0.001811, 0.092627, 0.25842, 0.39085, 0.0063808]
Predicted label: 4
Correct prediction
Energy consumption = 156.201418 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79878, 0.089164, 0.018957, 0.037718, 0.03462, 0.0051323, 0.56341, 0.012369, 0.045225, 0.28932]
Predicted label: 0
Correct prediction
Energy consumption = 159.637530 pJ
sum error= 344
Actual label: 2
Output voltages: [0.37296, 0.030129, 0.79858, 0.042357, 0.014046, 0.0010678, 0.044195, 0.14804, 0.40059, 0.0070012]
Predicted label: 2
Correct prediction
Energy consumption = 140.479415 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0025269, 0.0045017, 0.20031, 0.15749, 0.7987, 0.0011971, 0.036023, 0.076554, 0.042946, 0.03945]
Predicted label: 4
Correct prediction
Energy consumption = 157.690835 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79872, 0.017174, 0.041101, 0.01047, 0.027449, 0.003585, 0.2708, 0.014639, 0.1084, 0.017779]
Predicted label: 0
Correct prediction
Energy consumption = 157.552901 pJ
sum error= 344
Actual label: 2
Output voltages: [0.49123, 0.012668, 0.77941, 0.76596, 0.019987, 0.0011648, 0.0054718, 0.011601, 0.61677, 0.0074555]
Predicted label: 2
Correct prediction
Energy consumption = 152.274981 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0076472, 0.04656, 0.0052853, 0.01249, 0.79877, 0.0042772, 0.0746, 0.14821, 0.072612, 0.06105]
Predicted label: 4
Correct prediction
Energy consumption = 163.020747 pJ
sum error= 344
Actual label: 7
Output voltages: [0.21115, 0.035861, 0.007975, 0.047951, 0.021804, 0.0051072, 0.00117, 0.79874, 0.035771, 0.43351]
Predicted label: 7
Correct prediction
Energy consumption = 147.825475 pJ
sum error= 344
Actual label: 8
Output voltages: [0.012709, 0.058665, 0.15526, 0.17011, 0.0069665, 0.021712, 0.03249, 0.029398, 0.79876, 0.30285]
Predicted label: 8
Correct prediction
Energy consumption = 146.289114 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79878, 0.17192, 0.054396, 0.026263, 0.0088877, 0.016907, 0.43927, 0.024244, 0.047128, 0.023792]
Predicted label: 0
Correct prediction
Energy consumption = 147.740534 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 862 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 862 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 862 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.063292, 0.039665, 0.044741, 0.14396, 0.014345, 0.012457, 0.0010664, 0.79855, 0.028484, 0.23096]
Predicted label: 7
Correct prediction
Energy consumption = 157.781781 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79878, 0.14358, 0.020818, 0.017594, 0.022558, 0.009034, 0.75878, 0.0098311, 0.22653, 0.018292]
Predicted label: 0
Correct prediction
Energy consumption = 154.363213 pJ
sum error= 344
Actual label: 6
Output voltages: [0.060478, 0.1696, 0.22898, 0.0030498, 0.090111, 0.20895, 0.7987, 0.003574, 0.35245, 0.0101]
Predicted label: 6
Correct prediction
Energy consumption = 144.685269 pJ
sum error= 344
Actual label: 9
Output voltages: [0.56922, 0.017849, 0.0035385, 0.049463, 0.75411, 0.040678, 0.093415, 0.033239, 0.029507, 0.79851]
Predicted label: 9
Correct prediction
Energy consumption = 165.400631 pJ
sum error= 344
Actual label: 3
Output voltages: [0.57427, 0.0064767, 0.032101, 0.79869, 0.020879, 0.045247, 0.0095059, 0.0092947, 0.34905, 0.030431]
Predicted label: 3
Correct prediction
Energy consumption = 146.519946 pJ
sum error= 344
Actual label: 2
Output voltages: [0.57896, 0.0082312, 0.79878, 0.13508, 0.23692, 0.001078, 0.022992, 0.01463, 0.61898, 0.035242]
Predicted label: 2
Correct prediction
Energy consumption = 143.453449 pJ
sum error= 344
Actual label: 4
Output voltages: [0.012479, 0.0019228, 0.34018, 0.011748, 0.79854, 0.0011059, 0.025827, 0.047355, 0.015574, 0.055272]
Predicted label: 4
Correct prediction
Energy consumption = 149.535001 pJ
sum error= 344
Actual label: 8
Output voltages: [0.015238, 0.046874, 0.032826, 0.051054, 0.037529, 0.055751, 0.010245, 0.014063, 0.79873, 0.17118]
Predicted label: 8
Correct prediction
Energy consumption = 152.546892 pJ
sum error= 344
Actual label: 6
Output voltages: [0.19382, 0.2211, 0.068672, 0.0013303, 0.27817, 0.35663, 0.79865, 0.0027992, 0.15209, 0.012924]
Predicted label: 6
Correct prediction
Energy consumption = 154.162935 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79874, 0.05822, 0.036445, 0.013608, 0.02046, 0.005855, 0.76136, 0.011723, 0.18812, 0.081056]
Predicted label: 0
Correct prediction
Energy consumption = 146.695699 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 863 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 863 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 863 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.099926, 0.001753, 0.01253, 0.69101, 0.012378, 0.79878, 0.042638, 0.107, 0.75667, 0.07486]
Predicted label: 5
Correct prediction
Energy consumption = 147.360188 pJ
sum error= 344
Actual label: 7
Output voltages: [0.061155, 0.036327, 0.025272, 0.24554, 0.02189, 0.0020586, 0.0011229, 0.79858, 0.053077, 0.17269]
Predicted label: 7
Correct prediction
Energy consumption = 150.357083 pJ
sum error= 344
Actual label: 5
Output voltages: [0.085507, 0.035162, 0.0023654, 0.54868, 0.0064711, 0.79763, 0.73849, 0.021505, 0.37125, 0.0058696]
Predicted label: 5
Correct prediction
Energy consumption = 144.524961 pJ
sum error= 344
Actual label: 1
Output voltages: [0.0071036, 0.79872, 0.2164, 0.4424, 0.0060472, 0.001123, 0.20886, 0.0466, 0.060133, 0.14581]
Predicted label: 1
Correct prediction
Energy consumption = 169.318856 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.027435, 0.036766, 0.022008, 0.023781, 0.0026887, 0.57987, 0.021789, 0.085472, 0.22161]
Predicted label: 0
Correct prediction
Energy consumption = 157.949858 pJ
sum error= 344
Actual label: 8
Output voltages: [0.0059017, 0.061667, 0.047742, 0.0054457, 0.026468, 0.0027333, 0.11422, 0.03789, 0.79877, 0.38793]
Predicted label: 8
Correct prediction
Energy consumption = 153.766258 pJ
sum error= 344
Actual label: 1
Output voltages: [0.011347, 0.79858, 0.023247, 0.04228, 0.032213, 0.0026324, 0.4318, 0.0015665, 0.28849, 0.025167]
Predicted label: 1
Correct prediction
Energy consumption = 155.796288 pJ
sum error= 344
Actual label: 6
Output voltages: [0.2235, 0.0042438, 0.10604, 0.0010693, 0.23676, 0.044543, 0.79848, 0.0033219, 0.48703, 0.0077601]
Predicted label: 6
Correct prediction
Energy consumption = 147.435505 pJ
sum error= 344
Actual label: 7
Output voltages: [0.1299, 0.024109, 0.033048, 0.05963, 0.0075523, 0.0062522, 0.0010738, 0.79848, 0.058139, 0.16741]
Predicted label: 7
Correct prediction
Energy consumption = 153.296075 pJ
sum error= 344
Actual label: 2
Output voltages: [0.74683, 0.0039318, 0.79872, 0.10718, 0.0014264, 0.0010941, 0.025517, 0.059314, 0.49754, 0.0060522]
Predicted label: 2
Correct prediction
Energy consumption = 141.597711 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 864 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 864 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 864 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.17395, 0.019904, 0.095255, 0.043607, 0.037588, 0.0058122, 0.021037, 0.016654, 0.34753, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 155.264479 pJ
sum error= 344
Actual label: 7
Output voltages: [0.073575, 0.052992, 0.039154, 0.06861, 0.010605, 0.0044713, 0.001066, 0.79862, 0.17338, 0.4118]
Predicted label: 7
Correct prediction
Energy consumption = 149.586828 pJ
sum error= 344
Actual label: 9
Output voltages: [0.29277, 0.033245, 0.027146, 0.18756, 0.28819, 0.06734, 0.045387, 0.011315, 0.081444, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 149.157491 pJ
sum error= 344
Actual label: 5
Output voltages: [0.059346, 0.0030925, 0.0082079, 0.66385, 0.024525, 0.79875, 0.098902, 0.034618, 0.65248, 0.15712]
Predicted label: 5
Correct prediction
Energy consumption = 145.589877 pJ
sum error= 344
Actual label: 6
Output voltages: [0.11892, 0.17053, 0.27188, 0.0099754, 0.22608, 0.2673, 0.79872, 0.0026897, 0.53079, 0.020612]
Predicted label: 6
Correct prediction
Energy consumption = 150.169069 pJ
sum error= 344
Actual label: 5
Output voltages: [0.06831, 0.0031266, 0.0067027, 0.51487, 0.012444, 0.79788, 0.047126, 0.029668, 0.74837, 0.39292]
Predicted label: 5
Correct prediction
Energy consumption = 145.965387 pJ
sum error= 344
Actual label: 2
Output voltages: [0.64377, 0.028001, 0.79877, 0.022605, 0.020243, 0.001205, 0.085704, 0.035584, 0.29284, 0.021809]
Predicted label: 2
Correct prediction
Energy consumption = 150.156270 pJ
sum error= 344
Actual label: 6
Output voltages: [0.050847, 0.21625, 0.038573, 0.010445, 0.16116, 0.5009, 0.79868, 0.0040479, 0.19765, 0.014468]
Predicted label: 6
Correct prediction
Energy consumption = 155.177100 pJ
sum error= 344
Actual label: 2
Output voltages: [0.48388, 0.0082052, 0.79845, 0.36173, 0.0069888, 0.0011813, 0.04448, 0.033188, 0.4569, 0.0074459]
Predicted label: 2
Correct prediction
Energy consumption = 148.666922 pJ
sum error= 344
Actual label: 8
Output voltages: [0.023094, 0.043359, 0.15507, 0.12197, 0.0017765, 0.045091, 0.0093998, 0.014652, 0.79867, 0.17853]
Predicted label: 8
Correct prediction
Energy consumption = 148.401743 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 865 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 865 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 865 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.02067, 0.79842, 0.01884, 0.057013, 0.10018, 0.016582, 0.7082, 0.0024838, 0.04954, 0.20575]
Predicted label: 1
Correct prediction
Energy consumption = 160.994953 pJ
sum error= 344
Actual label: 7
Output voltages: [0.23795, 0.034673, 0.030359, 0.38494, 0.019433, 0.0062281, 0.0010879, 0.79859, 0.019017, 0.37736]
Predicted label: 7
Correct prediction
Energy consumption = 153.532119 pJ
sum error= 344
Actual label: 5
Output voltages: [0.028721, 0.0026381, 0.0033412, 0.53963, 0.030158, 0.79879, 0.18268, 0.084727, 0.71746, 0.27364]
Predicted label: 5
Correct prediction
Energy consumption = 142.604560 pJ
sum error= 344
Actual label: 5
Output voltages: [0.041953, 0.019923, 0.036511, 0.43595, 0.0012183, 0.79879, 0.038596, 0.18813, 0.67909, 0.0017953]
Predicted label: 5
Correct prediction
Energy consumption = 134.323657 pJ
sum error= 344
Actual label: 7
Output voltages: [0.14214, 0.02116, 0.063776, 0.27093, 0.015474, 0.0014978, 0.0013041, 0.79864, 0.021001, 0.48603]
Predicted label: 7
Correct prediction
Energy consumption = 152.740094 pJ
sum error= 344
Actual label: 3
Output voltages: [0.70888, 0.040832, 0.028532, 0.79861, 0.0061304, 0.069306, 0.00664, 0.017678, 0.39614, 0.031012]
Predicted label: 3
Correct prediction
Energy consumption = 145.988077 pJ
sum error= 344
Actual label: 5
Output voltages: [0.1103, 0.0015304, 0.0019493, 0.29781, 0.0058893, 0.79879, 0.022174, 0.10681, 0.76513, 0.060277]
Predicted label: 5
Correct prediction
Energy consumption = 137.302817 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.23091, 0.029243, 0.034093, 0.0041322, 0.024642, 0.47572, 0.024149, 0.048014, 0.028986]
Predicted label: 0
Correct prediction
Energy consumption = 142.517924 pJ
sum error= 344
Actual label: 1
Output voltages: [0.018932, 0.79871, 0.40152, 0.051845, 0.037326, 0.0010668, 0.69658, 0.0023565, 0.1475, 0.020326]
Predicted label: 1
Correct prediction
Energy consumption = 162.495789 pJ
sum error= 344
Actual label: 1
Output voltages: [0.0089574, 0.79848, 0.097381, 0.0869, 0.052222, 0.0056317, 0.48127, 0.010467, 0.19636, 0.032832]
Predicted label: 1
Correct prediction
Energy consumption = 151.438466 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 866 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 866 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 866 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.095442, 0.021359, 0.064319, 0.79861, 0.017173, 0.016552, 0.0090689, 0.051121, 0.47075, 0.04875]
Predicted label: 3
Correct prediction
Energy consumption = 146.079201 pJ
sum error= 344
Actual label: 8
Output voltages: [0.024431, 0.011193, 0.060218, 0.13259, 0.012769, 0.12557, 0.014292, 0.0018374, 0.79879, 0.37379]
Predicted label: 8
Correct prediction
Energy consumption = 146.337010 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0025419, 0.0058954, 0.307, 0.016417, 0.79858, 0.0021974, 0.16679, 0.03268, 0.029337, 0.03014]
Predicted label: 4
Correct prediction
Energy consumption = 153.541737 pJ
sum error= 344
Actual label: 9
Output voltages: [0.19397, 0.023261, 0.037065, 0.038332, 0.080119, 0.037101, 0.012241, 0.042755, 0.47193, 0.79817]
Predicted label: 9
Correct prediction
Energy consumption = 150.584040 pJ
sum error= 344
Actual label: 4
Output voltages: [0.028349, 0.0026876, 0.26342, 0.0063723, 0.7987, 0.0010664, 0.11704, 0.06867, 0.1389, 0.027335]
Predicted label: 4
Correct prediction
Energy consumption = 149.635279 pJ
sum error= 344
Actual label: 5
Output voltages: [0.073472, 0.0024474, 0.001457, 0.2992, 0.063968, 0.79874, 0.055061, 0.063694, 0.70355, 0.11861]
Predicted label: 5
Correct prediction
Energy consumption = 149.325888 pJ
sum error= 344
Actual label: 1
Output voltages: [0.008695, 0.7985, 0.017225, 0.16907, 0.21566, 0.0027277, 0.25585, 0.025877, 0.27989, 0.06158]
Predicted label: 1
Correct prediction
Energy consumption = 170.283365 pJ
sum error= 344
Actual label: 8
Output voltages: [0.016803, 0.016512, 0.063825, 0.46531, 0.0013423, 0.32913, 0.015079, 0.0079805, 0.79876, 0.10486]
Predicted label: 8
Correct prediction
Energy consumption = 155.401948 pJ
sum error= 344
Actual label: 6
Output voltages: [0.052429, 0.26408, 0.27954, 0.0077626, 0.21437, 0.066125, 0.79867, 0.0018757, 0.41859, 0.023049]
Predicted label: 6
Correct prediction
Energy consumption = 149.924475 pJ
sum error= 344
Actual label: 8
Output voltages: [0.022771, 0.045023, 0.17749, 0.017161, 0.01034, 0.011418, 0.0094586, 0.03027, 0.79879, 0.30099]
Predicted label: 8
Correct prediction
Energy consumption = 149.550166 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 867 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 867 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 867 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.43179, 0.032135, 0.048088, 0.13272, 0.14139, 0.076338, 0.016683, 0.029775, 0.33323, 0.79808]
Predicted label: 9
Correct prediction
Energy consumption = 153.991058 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.11266, 0.1412, 0.016968, 0.0061422, 0.0016772, 0.36382, 0.010179, 0.034779, 0.18985]
Predicted label: 0
Correct prediction
Energy consumption = 150.035398 pJ
sum error= 344
Actual label: 1
Output voltages: [0.024077, 0.79863, 0.2224, 0.13757, 0.074613, 0.0011186, 0.39176, 0.0053176, 0.03877, 0.052294]
Predicted label: 1
Correct prediction
Energy consumption = 157.318900 pJ
sum error= 344
Actual label: 2
Output voltages: [0.53547, 0.028788, 0.79872, 0.22179, 0.0049556, 0.0011289, 0.036584, 0.16503, 0.48053, 0.01617]
Predicted label: 2
Correct prediction
Energy consumption = 149.687983 pJ
sum error= 344
Actual label: 3
Output voltages: [0.27216, 0.0071757, 0.24375, 0.79875, 0.041731, 0.0016252, 0.027249, 0.0042044, 0.51227, 0.033411]
Predicted label: 3
Correct prediction
Energy consumption = 149.023259 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0021922, 0.0086304, 0.055727, 0.014348, 0.79866, 0.0010659, 0.042211, 0.058544, 0.021507, 0.0318]
Predicted label: 4
Correct prediction
Energy consumption = 149.029486 pJ
sum error= 344
Actual label: 5
Output voltages: [0.020792, 0.0011521, 0.0075069, 0.18482, 0.0081277, 0.79353, 0.18135, 0.010875, 0.77331, 0.010709]
Predicted label: 5
Correct prediction
Energy consumption = 150.892290 pJ
sum error= 344
Actual label: 6
Output voltages: [0.067394, 0.059845, 0.32547, 0.0020566, 0.39576, 0.20588, 0.7987, 0.0015516, 0.2953, 0.0041518]
Predicted label: 6
Correct prediction
Energy consumption = 145.792117 pJ
sum error= 344
Actual label: 7
Output voltages: [0.074364, 0.069124, 0.033086, 0.29652, 0.0026995, 0.013082, 0.0010811, 0.79877, 0.14894, 0.37706]
Predicted label: 7
Correct prediction
Energy consumption = 153.563851 pJ
sum error= 344
Actual label: 8
Output voltages: [0.01107, 0.049819, 0.039086, 0.44803, 0.0017439, 0.021045, 0.0091015, 0.00464, 0.79877, 0.26551]
Predicted label: 8
Correct prediction
Energy consumption = 142.305682 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 868 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 868 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 868 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.25523, 0.016796, 0.1102, 0.048308, 0.075485, 0.0095812, 0.001711, 0.058367, 0.43328, 0.79791]
Predicted label: 9
Correct prediction
Energy consumption = 156.744685 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79855, 0.19715, 0.085693, 0.0020871, 0.0074385, 0.0015771, 0.49785, 0.041648, 0.075175, 0.45619]
Predicted label: 0
Correct prediction
Energy consumption = 143.320007 pJ
sum error= 344
Actual label: 1
Output voltages: [0.0086246, 0.79858, 0.01302, 0.0269, 0.22809, 0.0047353, 0.58012, 0.0026018, 0.33319, 0.22413]
Predicted label: 1
Correct prediction
Energy consumption = 160.813667 pJ
sum error= 344
Actual label: 2
Output voltages: [0.5864, 0.012922, 0.79874, 0.066576, 0.010973, 0.0010982, 0.025912, 0.18682, 0.50485, 0.010033]
Predicted label: 2
Correct prediction
Energy consumption = 152.014044 pJ
sum error= 344
Actual label: 3
Output voltages: [0.209, 0.015902, 0.57982, 0.79875, 0.012313, 0.0020495, 0.0089871, 0.0011887, 0.77168, 0.045211]
Predicted label: 3
Correct prediction
Energy consumption = 145.599930 pJ
sum error= 344
Actual label: 4
Output voltages: [0.013686, 0.011119, 0.34728, 0.0013874, 0.79873, 0.0011081, 0.25507, 0.13083, 0.006363, 0.028968]
Predicted label: 4
Correct prediction
Energy consumption = 152.653663 pJ
sum error= 344
Actual label: 5
Output voltages: [0.037247, 0.0011014, 0.0011065, 0.58866, 0.39924, 0.79871, 0.43504, 0.0055471, 0.75381, 0.00651]
Predicted label: 5
Correct prediction
Energy consumption = 143.382915 pJ
sum error= 344
Actual label: 6
Output voltages: [0.17713, 0.028124, 0.22793, 0.0010963, 0.43984, 0.056454, 0.79879, 0.0014473, 0.11022, 0.0035159]
Predicted label: 6
Correct prediction
Energy consumption = 141.997677 pJ
sum error= 344
Actual label: 7
Output voltages: [0.037831, 0.096339, 0.14058, 0.20281, 0.0048667, 0.0010665, 0.0011146, 0.79872, 0.51233, 0.13068]
Predicted label: 7
Correct prediction
Energy consumption = 160.739829 pJ
sum error= 344
Actual label: 8
Output voltages: [0.0094765, 0.063084, 0.22448, 0.19008, 0.0039597, 0.022925, 0.019105, 0.010895, 0.79871, 0.13646]
Predicted label: 8
Correct prediction
Energy consumption = 146.111312 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 869 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 869 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 869 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.33301, 0.015424, 0.02182, 0.023727, 0.061436, 0.005803, 0.0015013, 0.097828, 0.45913, 0.79817]
Predicted label: 9
Correct prediction
Energy consumption = 154.711720 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79878, 0.038098, 0.14581, 0.0046637, 0.022468, 0.0021452, 0.23084, 0.099192, 0.43647, 0.060575]
Predicted label: 0
Correct prediction
Energy consumption = 147.317339 pJ
sum error= 344
Actual label: 1
Output voltages: [0.04994, 0.79864, 0.026183, 0.024095, 0.11456, 0.0023804, 0.72399, 0.0013938, 0.19862, 0.020907]
Predicted label: 1
Correct prediction
Energy consumption = 159.578687 pJ
sum error= 344
Actual label: 2
Output voltages: [0.53695, 0.010017, 0.79879, 0.047652, 0.062874, 0.0010687, 0.042538, 0.048153, 0.42345, 0.015178]
Predicted label: 2
Correct prediction
Energy consumption = 147.859961 pJ
sum error= 344
Actual label: 3
Output voltages: [0.15209, 0.02011, 0.055049, 0.79873, 0.047259, 0.0065043, 0.011683, 0.0051877, 0.5543, 0.16257]
Predicted label: 3
Correct prediction
Energy consumption = 144.325029 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0027423, 0.0054493, 0.033254, 0.013313, 0.79863, 0.0010723, 0.035669, 0.045551, 0.052448, 0.023968]
Predicted label: 4
Correct prediction
Energy consumption = 148.769901 pJ
sum error= 344
Actual label: 5
Output voltages: [0.02942, 0.0068311, 0.0012074, 0.066245, 0.023445, 0.79864, 0.11357, 0.026891, 0.75397, 0.019387]
Predicted label: 5
Correct prediction
Energy consumption = 153.618265 pJ
sum error= 344
Actual label: 6
Output voltages: [0.076431, 0.22159, 0.54277, 0.0032376, 0.25596, 0.2051, 0.79867, 0.0019915, 0.24509, 0.01974]
Predicted label: 6
Correct prediction
Energy consumption = 146.255085 pJ
sum error= 344
Actual label: 7
Output voltages: [0.11114, 0.039414, 0.057424, 0.010032, 0.037174, 0.0011294, 0.0011985, 0.79866, 0.055742, 0.014156]
Predicted label: 7
Correct prediction
Energy consumption = 150.023472 pJ
sum error= 344
Actual label: 8
Output voltages: [0.028011, 0.029209, 0.058546, 0.46895, 0.011627, 0.0099658, 0.0075873, 0.031783, 0.79877, 0.065452]
Predicted label: 8
Correct prediction
Energy consumption = 146.195403 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 870 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 870 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 870 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.19956, 0.0046347, 0.017756, 0.013064, 0.041847, 0.014639, 0.0017529, 0.014092, 0.74485, 0.79447]
Predicted label: 9
Correct prediction
Energy consumption = 147.978298 pJ
sum error= 344
Actual label: 3
Output voltages: [0.54244, 0.026476, 0.12442, 0.79869, 0.016727, 0.015653, 0.0049814, 0.025846, 0.48031, 0.044813]
Predicted label: 3
Correct prediction
Energy consumption = 148.427734 pJ
sum error= 344
Actual label: 5
Output voltages: [0.045883, 0.0081857, 0.0043675, 0.39941, 0.0044439, 0.79879, 0.2366, 0.012759, 0.6326, 0.01343]
Predicted label: 5
Correct prediction
Energy consumption = 145.254915 pJ
sum error= 344
Actual label: 3
Output voltages: [0.74177, 0.010339, 0.69155, 0.79862, 0.0028668, 0.0015275, 0.024315, 0.0063594, 0.3986, 0.057722]
Predicted label: 3
Correct prediction
Energy consumption = 154.236637 pJ
sum error= 344
Actual label: 2
Output voltages: [0.41281, 0.052455, 0.79872, 0.18126, 0.024363, 0.0012123, 0.20299, 0.10202, 0.51751, 0.078112]
Predicted label: 2
Correct prediction
Energy consumption = 139.524801 pJ
sum error= 344
Actual label: 9
Output voltages: [0.27446, 0.0021566, 0.049724, 0.080161, 0.28907, 0.0088794, 0.0016415, 0.15289, 0.57713, 0.7981]
Predicted label: 9
Correct prediction
Energy consumption = 152.684331 pJ
sum error= 344
Actual label: 3
Output voltages: [0.45179, 0.021305, 0.1408, 0.79867, 0.059349, 0.0030471, 0.010922, 0.013923, 0.59654, 0.02073]
Predicted label: 3
Correct prediction
Energy consumption = 144.873906 pJ
sum error= 344
Actual label: 2
Output voltages: [0.44351, 0.0073115, 0.79869, 0.031352, 0.017554, 0.0010733, 0.03852, 0.068628, 0.70343, 0.0026921]
Predicted label: 2
Correct prediction
Energy consumption = 137.082285 pJ
sum error= 344
Actual label: 1
Output voltages: [0.011656, 0.79877, 0.15166, 0.037629, 0.20342, 0.0010707, 0.53479, 0.022866, 0.32889, 0.010383]
Predicted label: 1
Correct prediction
Energy consumption = 154.576091 pJ
sum error= 344
Actual label: 4
Output voltages: [0.020709, 0.008383, 0.1189, 0.0083733, 0.79851, 0.011335, 0.033318, 0.038648, 0.10335, 0.0050469]
Predicted label: 4
Correct prediction
Energy consumption = 152.213087 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 871 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 871 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 871 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.013717, 0.0010659, 0.002368, 0.21233, 0.17507, 0.79858, 0.46952, 0.0023417, 0.78045, 0.088345]
Predicted label: 5
Correct prediction
Energy consumption = 145.692996 pJ
sum error= 344
Actual label: 5
Output voltages: [0.011364, 0.0010982, 0.0023518, 0.276, 0.036022, 0.79754, 0.45102, 0.0034509, 0.76537, 0.029735]
Predicted label: 5
Correct prediction
Energy consumption = 135.795106 pJ
sum error= 344
Actual label: 2
Output voltages: [0.50475, 0.019007, 0.79869, 0.14099, 0.021115, 0.0010704, 0.029244, 0.045786, 0.56621, 0.0054161]
Predicted label: 2
Correct prediction
Energy consumption = 143.779906 pJ
sum error= 344
Actual label: 3
Output voltages: [0.41608, 0.017828, 0.1471, 0.79874, 0.01219, 0.0063373, 0.039273, 0.02684, 0.636, 0.027595]
Predicted label: 3
Correct prediction
Energy consumption = 143.171106 pJ
sum error= 344
Actual label: 2
Output voltages: [0.49987, 0.069936, 0.79877, 0.089393, 0.029707, 0.0012807, 0.062692, 0.099576, 0.34635, 0.03579]
Predicted label: 2
Correct prediction
Energy consumption = 143.390408 pJ
sum error= 344
Actual label: 1
Output voltages: [0.031228, 0.79871, 0.022517, 0.030893, 0.029026, 0.0011418, 0.69648, 0.0011548, 0.51399, 0.02024]
Predicted label: 1
Correct prediction
Energy consumption = 161.154478 pJ
sum error= 344
Actual label: 3
Output voltages: [0.71915, 0.0081052, 0.16866, 0.79879, 0.0018225, 0.0026754, 0.0077127, 0.014184, 0.27773, 0.031984]
Predicted label: 3
Correct prediction
Energy consumption = 146.490512 pJ
sum error= 344
Actual label: 9
Output voltages: [0.37301, 0.008436, 0.027347, 0.041826, 0.20378, 0.0059505, 0.0029681, 0.15191, 0.22835, 0.79827]
Predicted label: 9
Correct prediction
Energy consumption = 147.692174 pJ
sum error= 344
Actual label: 7
Output voltages: [0.022689, 0.16767, 0.75122, 0.023037, 0.014943, 0.0011138, 0.0012097, 0.79873, 0.41646, 0.21386]
Predicted label: 7
Correct prediction
Energy consumption = 143.350745 pJ
sum error= 344
Actual label: 2
Output voltages: [0.45221, 0.054403, 0.79862, 0.052729, 0.014776, 0.0010767, 0.055309, 0.071096, 0.29477, 0.025579]
Predicted label: 2
Correct prediction
Energy consumption = 138.596469 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 872 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 872 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 872 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.021654, 0.79866, 0.25663, 0.10885, 0.11217, 0.0012435, 0.55092, 0.0051269, 0.073317, 0.0098831]
Predicted label: 1
Correct prediction
Energy consumption = 159.466642 pJ
sum error= 344
Actual label: 2
Output voltages: [0.60142, 0.067675, 0.79877, 0.22364, 0.014186, 0.0012212, 0.046429, 0.043442, 0.55255, 0.011659]
Predicted label: 2
Correct prediction
Energy consumption = 142.741229 pJ
sum error= 344
Actual label: 8
Output voltages: [0.055441, 0.015786, 0.03968, 0.71357, 0.0011566, 0.031984, 0.012331, 0.0054823, 0.79868, 0.090189]
Predicted label: 8
Correct prediction
Energy consumption = 146.095405 pJ
sum error= 344
Actual label: 9
Output voltages: [0.046315, 0.016617, 0.012708, 0.033344, 0.028541, 0.0063164, 0.0011053, 0.036696, 0.74732, 0.79803]
Predicted label: 9
Correct prediction
Energy consumption = 148.903226 pJ
sum error= 344
Actual label: 1
Output voltages: [0.018994, 0.79868, 0.2274, 0.021993, 0.030605, 0.0010682, 0.68831, 0.01371, 0.29569, 0.007054]
Predicted label: 1
Correct prediction
Energy consumption = 159.180488 pJ
sum error= 344
Actual label: 8
Output voltages: [0.02646, 0.031857, 0.043781, 0.39655, 0.0029467, 0.042778, 0.00658, 0.0042741, 0.79878, 0.34003]
Predicted label: 8
Correct prediction
Energy consumption = 151.954882 pJ
sum error= 344
Actual label: 8
Output voltages: [0.018422, 0.017651, 0.073917, 0.10348, 0.010381, 0.1498, 0.083274, 0.0083243, 0.79877, 0.16737]
Predicted label: 8
Correct prediction
Energy consumption = 145.974452 pJ
sum error= 344
Actual label: 7
Output voltages: [0.074254, 0.10708, 0.07973, 0.057776, 0.0026641, 0.0012481, 0.0010837, 0.79864, 0.067296, 0.24296]
Predicted label: 7
Correct prediction
Energy consumption = 154.175199 pJ
sum error= 344
Actual label: 8
Output voltages: [0.013587, 0.024312, 0.085915, 0.44176, 0.0025457, 0.070464, 0.028981, 0.010439, 0.79877, 0.16153]
Predicted label: 8
Correct prediction
Energy consumption = 151.632409 pJ
sum error= 344
Actual label: 1
Output voltages: [0.036238, 0.7987, 0.065735, 0.034407, 0.037693, 0.0010692, 0.74558, 0.0012889, 0.16874, 0.021924]
Predicted label: 1
Correct prediction
Energy consumption = 154.090233 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 873 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 873 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 873 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.052466, 0.029249, 0.15953, 0.020555, 0.016531, 0.58397, 0.063066, 0.23762, 0.04692]
Predicted label: 0
Correct prediction
Energy consumption = 154.677362 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79878, 0.056247, 0.17442, 0.023376, 0.010897, 0.0018269, 0.5074, 0.0076542, 0.062758, 0.31062]
Predicted label: 0
Correct prediction
Energy consumption = 139.496350 pJ
sum error= 344
Actual label: 6
Output voltages: [0.052864, 0.042797, 0.51113, 0.0010783, 0.19493, 0.061809, 0.79879, 0.0017911, 0.41525, 0.0012702]
Predicted label: 6
Correct prediction
Energy consumption = 138.866663 pJ
sum error= 344
Actual label: 7
Output voltages: [0.16768, 0.15632, 0.041086, 0.2729, 0.0016056, 0.0014009, 0.0011158, 0.7987, 0.039547, 0.62384]
Predicted label: 7
Correct prediction
Energy consumption = 160.338221 pJ
sum error= 344
Actual label: 7
Output voltages: [0.22196, 0.068416, 0.29491, 0.06424, 0.0033586, 0.0010676, 0.0011141, 0.79856, 0.48267, 0.039581]
Predicted label: 7
Correct prediction
Energy consumption = 146.318863 pJ
sum error= 344
Actual label: 8
Output voltages: [0.012284, 0.028501, 0.014591, 0.19272, 0.0020079, 0.026413, 0.0066738, 0.0038101, 0.79859, 0.33786]
Predicted label: 8
Correct prediction
Energy consumption = 144.452729 pJ
sum error= 344
Actual label: 7
Output voltages: [0.081659, 0.01105, 0.010679, 0.082143, 0.030434, 0.0014893, 0.0010967, 0.79861, 0.45027, 0.6178]
Predicted label: 7
Correct prediction
Energy consumption = 148.197175 pJ
sum error= 344
Actual label: 5
Output voltages: [0.034226, 0.0043023, 0.0098162, 0.49598, 0.017349, 0.79877, 0.53472, 0.015823, 0.75316, 0.040918]
Predicted label: 5
Correct prediction
Energy consumption = 147.010906 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.010589, 0.073198, 0.003101, 0.14969, 0.0060794, 0.48489, 0.016201, 0.055479, 0.038839]
Predicted label: 0
Correct prediction
Energy consumption = 148.825435 pJ
sum error= 344
Actual label: 6
Output voltages: [0.078699, 0.062714, 0.19513, 0.01703, 0.39821, 0.28954, 0.79863, 0.0023581, 0.64646, 0.023885]
Predicted label: 6
Correct prediction
Energy consumption = 144.692066 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 874 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 874 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 874 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0040945, 0.79854, 0.021388, 0.012961, 0.011987, 0.004153, 0.46545, 0.0080502, 0.67683, 0.011738]
Predicted label: 1
Correct prediction
Energy consumption = 160.779822 pJ
sum error= 344
Actual label: 5
Output voltages: [0.022151, 0.0010737, 0.0018656, 0.33447, 0.072358, 0.79828, 0.32331, 0.006062, 0.70547, 0.056478]
Predicted label: 5
Correct prediction
Energy consumption = 150.472676 pJ
sum error= 344
Actual label: 7
Output voltages: [0.19267, 0.25666, 0.75297, 0.021339, 0.0010773, 0.0011355, 0.0014685, 0.79875, 0.38524, 0.019667]
Predicted label: 7
Correct prediction
Energy consumption = 156.897076 pJ
sum error= 344
Actual label: 4
Output voltages: [0.017918, 0.0085315, 0.030382, 0.0049463, 0.79879, 0.0046491, 0.22581, 0.15731, 0.18637, 0.0012013]
Predicted label: 4
Correct prediction
Energy consumption = 150.403863 pJ
sum error= 344
Actual label: 6
Output voltages: [0.25373, 0.034822, 0.13348, 0.012084, 0.24152, 0.42018, 0.79879, 0.0032972, 0.73123, 0.018121]
Predicted label: 6
Correct prediction
Energy consumption = 150.414251 pJ
sum error= 344
Actual label: 1
Output voltages: [0.055099, 0.79862, 0.12482, 0.045927, 0.046482, 0.0010676, 0.75954, 0.0012527, 0.036228, 0.043644]
Predicted label: 1
Correct prediction
Energy consumption = 157.091815 pJ
sum error= 344
Actual label: 2
Output voltages: [0.33522, 0.0020286, 0.79878, 0.29673, 0.027583, 0.0010671, 0.038967, 0.074218, 0.49494, 0.0031296]
Predicted label: 2
Correct prediction
Energy consumption = 143.081089 pJ
sum error= 344
Actual label: 5
Output voltages: [0.015511, 0.0010731, 0.0045751, 0.21678, 0.17769, 0.79878, 0.21197, 0.027583, 0.77791, 0.04275]
Predicted label: 5
Correct prediction
Energy consumption = 142.906200 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79875, 0.10604, 0.0097422, 0.02563, 0.03111, 0.014267, 0.52559, 0.0049088, 0.44299, 0.031643]
Predicted label: 0
Correct prediction
Energy consumption = 148.209092 pJ
sum error= 344
Actual label: 7
Output voltages: [0.1592, 0.041201, 0.038287, 0.043211, 0.0020527, 0.013767, 0.0010957, 0.79872, 0.11119, 0.6207]
Predicted label: 7
Correct prediction
Energy consumption = 151.524256 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 875 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 875 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 875 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.59076, 0.001671, 0.024146, 0.0089119, 0.33241, 0.013212, 0.0018536, 0.033584, 0.56733, 0.79795]
Predicted label: 9
Correct prediction
Energy consumption = 156.080848 pJ
sum error= 344
Actual label: 9
Output voltages: [0.44969, 0.0085744, 0.036463, 0.030559, 0.13169, 0.0093828, 0.0011661, 0.097098, 0.60507, 0.79657]
Predicted label: 9
Correct prediction
Energy consumption = 139.954399 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.055581, 0.28597, 0.015762, 0.0028409, 0.0024735, 0.40454, 0.010572, 0.083594, 0.15]
Predicted label: 0
Correct prediction
Energy consumption = 152.145289 pJ
sum error= 344
Actual label: 3
Output voltages: [0.72768, 0.0051912, 0.21281, 0.79879, 0.020532, 0.01197, 0.0019992, 0.011749, 0.48945, 0.0097098]
Predicted label: 3
Correct prediction
Energy consumption = 149.942644 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0023152, 0.0016328, 0.10282, 0.013565, 0.79863, 0.0010702, 0.27303, 0.077632, 0.029964, 0.02841]
Predicted label: 4
Correct prediction
Energy consumption = 147.975568 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0041807, 0.0047351, 0.045458, 0.021037, 0.79867, 0.0048812, 0.10346, 0.29322, 0.28649, 0.0020968]
Predicted label: 4
Correct prediction
Energy consumption = 141.422067 pJ
sum error= 344
Actual label: 8
Output voltages: [0.022794, 0.010278, 0.12667, 0.026553, 0.020388, 0.013655, 0.029428, 0.01169, 0.79877, 0.21773]
Predicted label: 8
Correct prediction
Energy consumption = 148.208279 pJ
sum error= 344
Actual label: 4
Output voltages: [0.015923, 0.0054796, 0.26968, 0.0018196, 0.79869, 0.0021071, 0.2792, 0.047709, 0.043153, 0.007915]
Predicted label: 4
Correct prediction
Energy consumption = 150.229298 pJ
sum error= 344
Actual label: 1
Output voltages: [0.013062, 0.79859, 0.028842, 0.27284, 0.0083784, 0.0015086, 0.76223, 0.040905, 0.1307, 0.019068]
Predicted label: 1
Correct prediction
Energy consumption = 153.685792 pJ
sum error= 344
Actual label: 8
Output voltages: [0.23943, 0.014198, 0.28531, 0.042291, 0.018583, 0.0020565, 0.050033, 0.021825, 0.79879, 0.062904]
Predicted label: 8
Correct prediction
Energy consumption = 156.838845 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 876 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 876 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 876 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.058455, 0.04181, 0.24702, 0.0061158, 0.28548, 0.12541, 0.79876, 0.001525, 0.54104, 0.0059259]
Predicted label: 6
Correct prediction
Energy consumption = 151.929442 pJ
sum error= 344
Actual label: 5
Output voltages: [0.13708, 0.0023012, 0.0012647, 0.2661, 0.0054745, 0.79879, 0.19161, 0.030018, 0.76286, 0.0070115]
Predicted label: 5
Correct prediction
Energy consumption = 147.407676 pJ
sum error= 344
Actual label: 9
Output voltages: [0.32991, 0.026523, 0.019532, 0.040292, 0.22411, 0.015978, 0.0017505, 0.012724, 0.3742, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 151.454799 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79875, 0.080951, 0.11881, 0.030144, 0.017715, 0.0011948, 0.53579, 0.012418, 0.11252, 0.10025]
Predicted label: 0
Correct prediction
Energy consumption = 154.095159 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.14459, 0.076774, 0.0076967, 0.0039432, 0.0033924, 0.50372, 0.028394, 0.044303, 0.19666]
Predicted label: 0
Correct prediction
Energy consumption = 138.326312 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.082587, 0.044311, 0.010032, 0.0051636, 0.0045115, 0.40004, 0.03281, 0.11903, 0.062811]
Predicted label: 0
Correct prediction
Energy consumption = 135.995937 pJ
sum error= 344
Actual label: 3
Output voltages: [0.7465, 0.0021089, 0.39568, 0.79879, 0.033767, 0.15539, 0.001215, 0.018061, 0.54094, 0.0063131]
Predicted label: 3
Correct prediction
Energy consumption = 148.483389 pJ
sum error= 344
Actual label: 7
Output voltages: [0.23524, 0.013115, 0.025455, 0.083526, 0.016253, 0.043683, 0.0011621, 0.79862, 0.31712, 0.30785]
Predicted label: 7
Correct prediction
Energy consumption = 150.128938 pJ
sum error= 344
Actual label: 1
Output voltages: [0.0060119, 0.79859, 0.39575, 0.048072, 0.23588, 0.0011922, 0.45459, 0.005651, 0.012616, 0.034811]
Predicted label: 1
Correct prediction
Energy consumption = 156.044506 pJ
sum error= 344
Actual label: 6
Output voltages: [0.12891, 0.01715, 0.13941, 0.0011442, 0.42012, 0.10123, 0.79877, 0.0014299, 0.49418, 0.0034751]
Predicted label: 6
Correct prediction
Energy consumption = 142.447937 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 877 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 877 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 877 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0011696, 0.002862, 0.049395, 0.026521, 0.7987, 0.0010768, 0.38314, 0.27011, 0.028131, 0.04724]
Predicted label: 4
Correct prediction
Energy consumption = 153.916308 pJ
sum error= 344
Actual label: 6
Output voltages: [0.25837, 0.051214, 0.27042, 0.0016637, 0.37474, 0.28201, 0.79871, 0.0018414, 0.39615, 0.0052619]
Predicted label: 6
Correct prediction
Energy consumption = 146.167578 pJ
sum error= 344
Actual label: 0
Output voltages: [0.7987, 0.064247, 0.03824, 0.016325, 0.025259, 0.012706, 0.38141, 0.011197, 0.29564, 0.13736]
Predicted label: 0
Correct prediction
Energy consumption = 146.221821 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0074869, 0.005451, 0.024189, 0.020598, 0.79872, 0.0024553, 0.15679, 0.13276, 0.029602, 0.0023423]
Predicted label: 4
Correct prediction
Energy consumption = 152.582706 pJ
sum error= 344
Actual label: 5
Output voltages: [0.0049471, 0.0011427, 0.010573, 0.38503, 0.027352, 0.79418, 0.28119, 0.0045859, 0.76874, 0.017486]
Predicted label: 5
Correct prediction
Energy consumption = 147.600449 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0081367, 0.0025648, 0.034857, 0.0055665, 0.79877, 0.0062271, 0.21397, 0.23111, 0.22902, 0.0011503]
Predicted label: 4
Correct prediction
Energy consumption = 153.375212 pJ
sum error= 344
Actual label: 1
Output voltages: [0.026538, 0.79859, 0.038731, 0.0096955, 0.11295, 0.0014134, 0.44991, 0.0104, 0.0919, 0.025301]
Predicted label: 1
Correct prediction
Energy consumption = 155.114666 pJ
sum error= 344
Actual label: 3
Output voltages: [0.15361, 0.033316, 0.031479, 0.79861, 0.013221, 0.0085136, 0.010247, 0.018579, 0.45829, 0.058251]
Predicted label: 3
Correct prediction
Energy consumption = 147.392454 pJ
sum error= 344
Actual label: 8
Output voltages: [0.025351, 0.042524, 0.039829, 0.42978, 0.0070673, 0.066015, 0.009094, 0.039596, 0.79879, 0.48645]
Predicted label: 8
Correct prediction
Energy consumption = 147.220352 pJ
sum error= 344
Actual label: 6
Output voltages: [0.068164, 0.063066, 0.43741, 0.0014067, 0.41514, 0.23148, 0.79872, 0.0028454, 0.33357, 0.0044555]
Predicted label: 6
Correct prediction
Energy consumption = 148.162175 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 878 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 878 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 878 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.21386, 0.025242, 0.04459, 0.79864, 0.030629, 0.0065808, 0.013765, 0.014842, 0.64532, 0.081737]
Predicted label: 3
Correct prediction
Energy consumption = 151.609866 pJ
sum error= 344
Actual label: 9
Output voltages: [0.23076, 0.02674, 0.054514, 0.10947, 0.049618, 0.087528, 0.010739, 0.042457, 0.29801, 0.79857]
Predicted label: 9
Correct prediction
Energy consumption = 147.335852 pJ
sum error= 344
Actual label: 9
Output voltages: [0.056331, 0.020361, 0.067627, 0.015451, 0.021866, 0.030663, 0.0062056, 0.041415, 0.77582, 0.7898]
Predicted label: 9
Correct prediction
Energy consumption = 139.559724 pJ
sum error= 344
Actual label: 5
Output voltages: [0.0065305, 0.0036557, 0.0078112, 0.34501, 0.029418, 0.79703, 0.19077, 0.0071822, 0.69947, 0.14675]
Predicted label: 5
Correct prediction
Energy consumption = 133.970311 pJ
sum error= 344
Actual label: 9
Output voltages: [0.36687, 0.0098654, 0.085752, 0.017153, 0.048206, 0.013185, 0.0054394, 0.049269, 0.59851, 0.79411]
Predicted label: 9
Correct prediction
Energy consumption = 152.819790 pJ
sum error= 344
Actual label: 3
Output voltages: [0.76564, 0.0017071, 0.3243, 0.79879, 0.014574, 0.0051322, 0.0014861, 0.028759, 0.31725, 0.0092024]
Predicted label: 3
Correct prediction
Energy consumption = 149.580464 pJ
sum error= 344
Actual label: 7
Output voltages: [0.33924, 0.01114, 0.014711, 0.13034, 0.0044129, 0.014768, 0.0011558, 0.79873, 0.57222, 0.55767]
Predicted label: 7
Correct prediction
Energy consumption = 148.781140 pJ
sum error= 344
Actual label: 8
Output voltages: [0.071882, 0.0052172, 0.037181, 0.55444, 0.0099858, 0.015037, 0.0016853, 0.0019832, 0.79866, 0.096162]
Predicted label: 8
Correct prediction
Energy consumption = 149.865155 pJ
sum error= 344
Actual label: 5
Output voltages: [0.032559, 0.0010771, 0.001491, 0.47176, 0.036553, 0.79879, 0.11635, 0.036067, 0.73098, 0.25524]
Predicted label: 5
Correct prediction
Energy consumption = 144.999607 pJ
sum error= 344
Actual label: 6
Output voltages: [0.16221, 0.15944, 0.11712, 0.0022273, 0.16543, 0.28695, 0.7987, 0.0012616, 0.22127, 0.021486]
Predicted label: 6
Correct prediction
Energy consumption = 146.607172 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 879 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 879 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 879 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0061008, 0.0026759, 0.042265, 0.013024, 0.7987, 0.0016812, 0.22314, 0.080935, 0.023367, 0.0082681]
Predicted label: 4
Correct prediction
Energy consumption = 151.338686 pJ
sum error= 344
Actual label: 7
Output voltages: [0.25879, 0.0029029, 0.019871, 0.34877, 0.0050231, 0.0073431, 0.0011634, 0.7986, 0.71351, 0.74112]
Predicted label: 7
Correct prediction
Energy consumption = 154.665953 pJ
sum error= 344
Actual label: 6
Output voltages: [0.087867, 0.032836, 0.24145, 0.0050869, 0.56932, 0.076081, 0.79877, 0.0010797, 0.3346, 0.018422]
Predicted label: 6
Correct prediction
Energy consumption = 149.265385 pJ
sum error= 344
Actual label: 2
Output voltages: [0.73467, 0.02524, 0.79879, 0.13481, 0.024861, 0.0010929, 0.060274, 0.039554, 0.5455, 0.020719]
Predicted label: 2
Correct prediction
Energy consumption = 146.783996 pJ
sum error= 344
Actual label: 2
Output voltages: [0.35673, 0.030449, 0.79878, 0.17147, 0.0247, 0.0012653, 0.050262, 0.18674, 0.34378, 0.060813]
Predicted label: 2
Correct prediction
Energy consumption = 138.182625 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79861, 0.062044, 0.21032, 0.011072, 0.03698, 0.0011075, 0.49934, 0.0027168, 0.34657, 0.19158]
Predicted label: 0
Correct prediction
Energy consumption = 148.181708 pJ
sum error= 344
Actual label: 9
Output voltages: [0.48994, 0.0042582, 0.031864, 0.020141, 0.41823, 0.027573, 0.0018369, 0.036213, 0.25988, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 152.159047 pJ
sum error= 344
Actual label: 4
Output voltages: [0.017828, 0.0071963, 0.047372, 0.016118, 0.79868, 0.0030975, 0.049187, 0.038154, 0.032866, 0.0036933]
Predicted label: 4
Correct prediction
Energy consumption = 145.548504 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79878, 0.13144, 0.23673, 0.011197, 0.0030382, 0.0019422, 0.42907, 0.0097704, 0.082802, 0.16768]
Predicted label: 0
Correct prediction
Energy consumption = 153.878273 pJ
sum error= 344
Actual label: 1
Output voltages: [0.041127, 0.7987, 0.205, 0.063037, 0.31625, 0.0018948, 0.77466, 0.0010739, 0.044679, 0.032789]
Predicted label: 1
Correct prediction
Energy consumption = 154.970797 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 880 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 880 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 880 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.62598, 0.0034338, 0.79877, 0.058426, 0.04097, 0.0011605, 0.038613, 0.05154, 0.62738, 0.0040748]
Predicted label: 2
Correct prediction
Energy consumption = 148.406471 pJ
sum error= 344
Actual label: 3
Output voltages: [0.31041, 0.026396, 0.080059, 0.79863, 0.035828, 0.011964, 0.0098906, 0.020775, 0.58277, 0.11579]
Predicted label: 3
Correct prediction
Energy consumption = 140.314578 pJ
sum error= 344
Actual label: 4
Output voltages: [0.025897, 0.0048511, 0.30065, 0.0015093, 0.7987, 0.0011935, 0.28855, 0.04975, 0.019751, 0.017667]
Predicted label: 4
Correct prediction
Energy consumption = 150.731782 pJ
sum error= 344
Actual label: 5
Output voltages: [0.02876, 0.0010761, 0.01209, 0.11306, 0.0083685, 0.79872, 0.31141, 0.0063918, 0.79377, 0.0013397]
Predicted label: 5
Correct prediction
Energy consumption = 149.519733 pJ
sum error= 344
Actual label: 6
Output voltages: [0.059872, 0.047794, 0.28312, 0.0045862, 0.4081, 0.2994, 0.79867, 0.0033109, 0.40969, 0.0070435]
Predicted label: 6
Correct prediction
Energy consumption = 143.428742 pJ
sum error= 344
Actual label: 7
Output voltages: [0.017196, 0.19515, 0.66009, 0.013462, 0.015193, 0.0010752, 0.0017371, 0.79863, 0.18405, 0.10929]
Predicted label: 7
Correct prediction
Energy consumption = 154.196478 pJ
sum error= 344
Actual label: 8
Output voltages: [0.025208, 0.16411, 0.015179, 0.037871, 0.010379, 0.034537, 0.043144, 0.03503, 0.79878, 0.043505]
Predicted label: 8
Correct prediction
Energy consumption = 146.479296 pJ
sum error= 344
Actual label: 9
Output voltages: [0.24907, 0.0090102, 0.0074793, 0.032669, 0.065276, 0.012004, 0.0045018, 0.022113, 0.45432, 0.79808]
Predicted label: 9
Correct prediction
Energy consumption = 149.686914 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.066941, 0.011288, 0.024532, 0.008677, 0.014267, 0.49553, 0.034569, 0.17415, 0.025163]
Predicted label: 0
Correct prediction
Energy consumption = 142.791973 pJ
sum error= 344
Actual label: 1
Output voltages: [0.17843, 0.79787, 0.19052, 0.026321, 0.58041, 0.0010676, 0.021684, 0.0027787, 0.028644, 0.037533]
Predicted label: 1
Correct prediction
Energy consumption = 152.422704 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 881 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 881 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 881 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36465, 0.14204, 0.79862, 0.086227, 0.013241, 0.0011305, 0.064526, 0.12277, 0.34942, 0.013508]
Predicted label: 2
Correct prediction
Energy consumption = 146.097404 pJ
sum error= 344
Actual label: 3
Output voltages: [0.25585, 0.016495, 0.2768, 0.79864, 0.18939, 0.010486, 0.024602, 0.017835, 0.61183, 0.08721]
Predicted label: 3
Correct prediction
Energy consumption = 142.757852 pJ
sum error= 344
Actual label: 4
Output voltages: [0.043939, 0.0037344, 0.42813, 0.0013164, 0.79869, 0.0053706, 0.11802, 0.059702, 0.029747, 0.010752]
Predicted label: 4
Correct prediction
Energy consumption = 146.667920 pJ
sum error= 344
Actual label: 5
Output voltages: [0.04419, 0.0010954, 0.0020013, 0.27219, 0.15957, 0.79875, 0.12679, 0.020556, 0.77743, 0.028755]
Predicted label: 5
Correct prediction
Energy consumption = 149.085806 pJ
sum error= 344
Actual label: 6
Output voltages: [0.034881, 0.063023, 0.043649, 0.37936, 0.40349, 0.041298, 0.79633, 0.011484, 0.1522, 0.0010939]
Predicted label: 6
Correct prediction
Energy consumption = 152.946656 pJ
sum error= 344
Actual label: 7
Output voltages: [0.52014, 0.023657, 0.27365, 0.12296, 0.013126, 0.0020726, 0.0011887, 0.79867, 0.39946, 0.11628]
Predicted label: 7
Correct prediction
Energy consumption = 157.534711 pJ
sum error= 344
Actual label: 8
Output voltages: [0.029587, 0.37776, 0.016211, 0.2008, 0.017918, 0.041815, 0.60483, 0.0025628, 0.79358, 0.03904]
Predicted label: 8
Correct prediction
Energy consumption = 148.317486 pJ
sum error= 344
Actual label: 9
Output voltages: [0.085324, 0.0098039, 0.036877, 0.053141, 0.040012, 0.0035028, 0.0017614, 0.050964, 0.61475, 0.79792]
Predicted label: 9
Correct prediction
Energy consumption = 146.304404 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79865, 0.038858, 0.055727, 0.01651, 0.014723, 0.011963, 0.27853, 0.043803, 0.032823, 0.044506]
Predicted label: 0
Correct prediction
Energy consumption = 142.315874 pJ
sum error= 344
Actual label: 1
Output voltages: [0.035434, 0.79877, 0.43365, 0.022755, 0.49093, 0.0011961, 0.42794, 0.020566, 0.091442, 0.01644]
Predicted label: 1
Correct prediction
Energy consumption = 149.919404 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 882 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 882 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 882 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.32323, 0.0012655, 0.79879, 0.10271, 0.0035615, 0.0010772, 0.005207, 0.34347, 0.75558, 0.0059126]
Predicted label: 2
Correct prediction
Energy consumption = 139.172569 pJ
sum error= 344
Actual label: 3
Output voltages: [0.70393, 0.014644, 0.067464, 0.79871, 0.0065846, 0.046335, 0.014192, 0.03151, 0.49255, 0.04916]
Predicted label: 3
Correct prediction
Energy consumption = 142.749683 pJ
sum error= 344
Actual label: 4
Output voltages: [0.031309, 0.17191, 0.047691, 0.0091847, 0.79877, 0.028015, 0.079855, 0.025948, 0.013503, 0.028182]
Predicted label: 4
Correct prediction
Energy consumption = 146.154616 pJ
sum error= 344
Actual label: 5
Output voltages: [0.12226, 0.0013866, 0.0013387, 0.27136, 0.0033733, 0.79859, 0.10687, 0.26619, 0.76872, 0.0023862]
Predicted label: 5
Correct prediction
Energy consumption = 149.081211 pJ
sum error= 344
Actual label: 6
Output voltages: [0.053238, 0.061828, 0.29292, 0.0010903, 0.22373, 0.14588, 0.79876, 0.0021873, 0.39447, 0.0022342]
Predicted label: 6
Correct prediction
Energy consumption = 142.097265 pJ
sum error= 344
Actual label: 7
Output voltages: [0.12715, 0.11705, 0.7499, 0.045722, 0.0094285, 0.0010665, 0.0011219, 0.79863, 0.23963, 0.091535]
Predicted label: 7
Correct prediction
Energy consumption = 153.321307 pJ
sum error= 344
Actual label: 8
Output voltages: [0.36303, 0.043491, 0.36045, 0.035194, 0.023637, 0.0011972, 0.14721, 0.0018637, 0.79842, 0.2606]
Predicted label: 8
Correct prediction
Energy consumption = 149.294874 pJ
sum error= 344
Actual label: 9
Output voltages: [0.11122, 0.018837, 0.043194, 0.032159, 0.023434, 0.013937, 0.0055647, 0.031192, 0.76461, 0.79752]
Predicted label: 9
Correct prediction
Energy consumption = 141.393375 pJ
sum error= 344
Actual label: 6
Output voltages: [0.21427, 0.030314, 0.14539, 0.01177, 0.37516, 0.22828, 0.79878, 0.0024372, 0.54084, 0.020063]
Predicted label: 6
Correct prediction
Energy consumption = 146.547095 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0078706, 0.010628, 0.24876, 0.020643, 0.7986, 0.0052998, 0.095019, 0.024864, 0.028508, 0.053365]
Predicted label: 4
Correct prediction
Energy consumption = 160.624245 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 883 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 883 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 883 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.36488, 0.013154, 0.79864, 0.028003, 0.034166, 0.0011262, 0.032452, 0.021822, 0.53757, 0.0048189]
Predicted label: 2
Correct prediction
Energy consumption = 140.258251 pJ
sum error= 344
Actual label: 6
Output voltages: [0.056226, 0.0459, 0.037334, 0.020631, 0.48365, 0.31736, 0.79875, 0.0024377, 0.70475, 0.0050782]
Predicted label: 6
Correct prediction
Energy consumption = 151.514823 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0044633, 0.0087282, 0.033258, 0.023638, 0.79866, 0.001066, 0.25731, 0.23266, 0.030348, 0.014715]
Predicted label: 4
Correct prediction
Energy consumption = 156.588875 pJ
sum error= 344
Actual label: 7
Output voltages: [0.1748, 0.079246, 0.017738, 0.15335, 0.020661, 0.021968, 0.0011401, 0.79867, 0.080388, 0.53869]
Predicted label: 7
Correct prediction
Energy consumption = 143.342725 pJ
sum error= 344
Actual label: 5
Output voltages: [0.076845, 0.0010784, 0.0014733, 0.34624, 0.03971, 0.7987, 0.61871, 0.0025983, 0.79084, 0.023739]
Predicted label: 5
Correct prediction
Energy consumption = 146.014966 pJ
sum error= 344
Actual label: 5
Output voltages: [0.024967, 0.001092, 0.0015561, 0.24161, 0.014186, 0.79261, 0.42219, 0.008323, 0.77548, 0.01811]
Predicted label: 5
Correct prediction
Energy consumption = 131.662201 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0032342, 0.0030117, 0.20281, 0.024919, 0.7986, 0.0045319, 0.32111, 0.30869, 0.022847, 0.0069468]
Predicted label: 4
Correct prediction
Energy consumption = 154.580265 pJ
sum error= 344
Actual label: 7
Output voltages: [0.28028, 0.012964, 0.014405, 0.039362, 0.027085, 0.006094, 0.0011123, 0.79868, 0.053563, 0.48095]
Predicted label: 7
Correct prediction
Energy consumption = 151.283753 pJ
sum error= 344
Actual label: 2
Output voltages: [0.072747, 0.062855, 0.79859, 0.039586, 0.01622, 0.0011015, 0.032259, 0.16359, 0.26992, 0.021805]
Predicted label: 2
Correct prediction
Energy consumption = 136.946549 pJ
sum error= 344
Actual label: 9
Output voltages: [0.33181, 0.013684, 0.032799, 0.036069, 0.083537, 0.02303, 0.0031744, 0.22563, 0.41311, 0.79787]
Predicted label: 9
Correct prediction
Energy consumption = 159.798888 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 884 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 884 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 884 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.33515, 0.025148, 0.083907, 0.79862, 0.028437, 0.012222, 0.015019, 0.016704, 0.66921, 0.031747]
Predicted label: 3
Correct prediction
Energy consumption = 145.428018 pJ
sum error= 344
Actual label: 9
Output voltages: [0.20952, 0.014135, 0.029149, 0.020402, 0.053052, 0.019821, 0.0052415, 0.034399, 0.71671, 0.7979]
Predicted label: 9
Correct prediction
Energy consumption = 144.958700 pJ
sum error= 344
Actual label: 3
Output voltages: [0.18688, 0.0024157, 0.11844, 0.79877, 0.15528, 0.026824, 0.016605, 0.0040566, 0.35969, 0.068136]
Predicted label: 3
Correct prediction
Energy consumption = 144.556937 pJ
sum error= 344
Actual label: 8
Output voltages: [0.026472, 0.10529, 0.22446, 0.029215, 0.0028616, 0.042679, 0.034326, 0.02779, 0.79875, 0.054209]
Predicted label: 8
Correct prediction
Energy consumption = 146.701049 pJ
sum error= 344
Actual label: 2
Output voltages: [0.33971, 0.017456, 0.79877, 0.04858, 0.034491, 0.001071, 0.034675, 0.0087621, 0.48305, 0.034441]
Predicted label: 2
Correct prediction
Energy consumption = 144.677417 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79874, 0.070634, 0.21094, 0.020439, 0.021931, 0.0012606, 0.44341, 0.03448, 0.25724, 0.029702]
Predicted label: 0
Correct prediction
Energy consumption = 154.831494 pJ
sum error= 344
Actual label: 9
Output voltages: [0.17197, 0.010583, 0.025038, 0.018154, 0.41849, 0.0029679, 0.0054686, 0.0055914, 0.4594, 0.79867]
Predicted label: 9
Correct prediction
Energy consumption = 156.261444 pJ
sum error= 344
Actual label: 5
Output voltages: [0.051385, 0.0011319, 0.0010957, 0.35757, 0.19926, 0.79878, 0.66537, 0.033645, 0.67457, 0.075821]
Predicted label: 5
Correct prediction
Energy consumption = 145.245223 pJ
sum error= 344
Actual label: 6
Output voltages: [0.030162, 0.017881, 0.24063, 0.0020459, 0.28145, 0.17334, 0.79876, 0.0022438, 0.66403, 0.0020313]
Predicted label: 6
Correct prediction
Energy consumption = 141.031167 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79867, 0.039345, 0.27541, 0.0033016, 0.015393, 0.0012869, 0.66544, 0.013641, 0.045031, 0.19242]
Predicted label: 0
Correct prediction
Energy consumption = 154.030368 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 885 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 885 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 885 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.007182, 0.79873, 0.1792, 0.06134, 0.072018, 0.0011416, 0.63059, 0.0059386, 0.27404, 0.029917]
Predicted label: 1
Correct prediction
Energy consumption = 157.109267 pJ
sum error= 344
Actual label: 0
Output voltages: [0.7987, 0.066519, 0.054588, 0.016743, 0.035548, 0.0091818, 0.15784, 0.077256, 0.05768, 0.19555]
Predicted label: 0
Correct prediction
Energy consumption = 148.819105 pJ
sum error= 344
Actual label: 6
Output voltages: [0.1398, 0.028662, 0.17588, 0.0035503, 0.40404, 0.23894, 0.79871, 0.0012144, 0.55306, 0.0059261]
Predicted label: 6
Correct prediction
Energy consumption = 144.518086 pJ
sum error= 344
Actual label: 5
Output voltages: [0.25648, 0.0010797, 0.0014654, 0.21444, 0.05145, 0.79869, 0.52467, 0.020955, 0.77936, 0.0020899]
Predicted label: 5
Correct prediction
Energy consumption = 145.007936 pJ
sum error= 344
Actual label: 3
Output voltages: [0.51815, 0.010562, 0.063052, 0.79867, 0.015682, 0.038495, 0.011615, 0.021409, 0.6157, 0.064228]
Predicted label: 3
Correct prediction
Energy consumption = 144.104589 pJ
sum error= 344
Actual label: 5
Output voltages: [0.087015, 0.0011755, 0.001145, 0.25472, 0.08137, 0.79875, 0.27891, 0.021385, 0.75891, 0.0234]
Predicted label: 5
Correct prediction
Energy consumption = 138.072987 pJ
sum error= 344
Actual label: 3
Output voltages: [0.43366, 0.012693, 0.054185, 0.79863, 0.038738, 0.020166, 0.01941, 0.015006, 0.55898, 0.1489]
Predicted label: 3
Correct prediction
Energy consumption = 141.963383 pJ
sum error= 344
Actual label: 8
Output voltages: [0.019573, 0.055744, 0.51383, 0.018061, 0.015045, 0.0041876, 0.024098, 0.019992, 0.79878, 0.12472]
Predicted label: 8
Correct prediction
Energy consumption = 148.747479 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79878, 0.042682, 0.083742, 0.032247, 0.033084, 0.002221, 0.55004, 0.02657, 0.080565, 0.14528]
Predicted label: 0
Correct prediction
Energy consumption = 148.799588 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79872, 0.01403, 0.0063658, 0.025796, 0.086536, 0.032737, 0.71993, 0.0442, 0.19743, 0.022928]
Predicted label: 0
Correct prediction
Energy consumption = 141.222612 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 886 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 886 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 886 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.61714, 0.033116, 0.040324, 0.79862, 0.031672, 0.014451, 0.016159, 0.01173, 0.58737, 0.10925]
Predicted label: 3
Correct prediction
Energy consumption = 148.776518 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0040584, 0.0052962, 0.25561, 0.008332, 0.79872, 0.0021809, 0.15286, 0.13045, 0.038256, 0.016763]
Predicted label: 4
Correct prediction
Energy consumption = 154.560292 pJ
sum error= 344
Actual label: 1
Output voltages: [0.0065797, 0.7986, 0.076137, 0.019413, 0.30422, 0.0014325, 0.2436, 0.018997, 0.034025, 0.038292]
Predicted label: 1
Correct prediction
Energy consumption = 153.608183 pJ
sum error= 344
Actual label: 5
Output voltages: [0.034987, 0.0011755, 0.0011724, 0.067159, 0.057081, 0.79879, 0.649, 0.010671, 0.78581, 0.020134]
Predicted label: 5
Correct prediction
Energy consumption = 153.079837 pJ
sum error= 344
Actual label: 3
Output voltages: [0.71791, 0.031265, 0.036838, 0.7987, 0.0065383, 0.016609, 0.018637, 0.010998, 0.38171, 0.030528]
Predicted label: 3
Correct prediction
Energy consumption = 147.046954 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79878, 0.044625, 0.15248, 0.0062402, 0.01353, 0.0022263, 0.51306, 0.004008, 0.062868, 0.19271]
Predicted label: 0
Correct prediction
Energy consumption = 153.407167 pJ
sum error= 344
Actual label: 8
Output voltages: [0.02067, 0.077194, 0.11072, 0.1285, 0.03672, 0.0047051, 0.034468, 0.021171, 0.79879, 0.23346]
Predicted label: 8
Correct prediction
Energy consumption = 153.190407 pJ
sum error= 344
Actual label: 3
Output voltages: [0.76224, 0.01402, 0.20729, 0.79879, 0.019567, 0.020013, 0.0098702, 0.0092392, 0.29665, 0.00476]
Predicted label: 3
Correct prediction
Energy consumption = 142.535005 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79878, 0.049436, 0.032155, 0.0055347, 0.005475, 0.0098321, 0.63853, 0.010669, 0.21287, 0.042639]
Predicted label: 0
Correct prediction
Energy consumption = 146.313585 pJ
sum error= 344
Actual label: 6
Output voltages: [0.037379, 0.19931, 0.28645, 0.0011891, 0.30277, 0.059772, 0.79872, 0.0012459, 0.37891, 0.002409]
Predicted label: 6
Correct prediction
Energy consumption = 137.693394 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 887 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 887 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 887 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.45015, 0.032274, 0.79878, 0.11984, 0.16293, 0.0011164, 0.033304, 0.01255, 0.40059, 0.020704]
Predicted label: 2
Correct prediction
Energy consumption = 144.628273 pJ
sum error= 344
Actual label: 7
Output voltages: [0.04949, 0.13833, 0.16404, 0.1035, 0.004355, 0.0013862, 0.0010969, 0.79854, 0.17708, 0.20786]
Predicted label: 7
Correct prediction
Energy consumption = 149.712568 pJ
sum error= 344
Actual label: 8
Output voltages: [0.23629, 0.026081, 0.41838, 0.058581, 0.0076191, 0.015515, 0.25247, 0.0045699, 0.79871, 0.021079]
Predicted label: 8
Correct prediction
Energy consumption = 149.999447 pJ
sum error= 344
Actual label: 1
Output voltages: [0.010868, 0.79878, 0.059025, 0.037612, 0.20312, 0.0012031, 0.27844, 0.014766, 0.034925, 0.046307]
Predicted label: 1
Correct prediction
Energy consumption = 155.457715 pJ
sum error= 344
Actual label: 7
Output voltages: [0.040254, 0.034132, 0.045173, 0.24216, 0.001753, 0.0015218, 0.001122, 0.79866, 0.3163, 0.25567]
Predicted label: 7
Correct prediction
Energy consumption = 151.107141 pJ
sum error= 344
Actual label: 1
Output voltages: [0.033482, 0.79879, 0.39075, 0.037549, 0.12829, 0.001141, 0.77535, 0.0010666, 0.021799, 0.038671]
Predicted label: 1
Correct prediction
Energy consumption = 154.277487 pJ
sum error= 344
Actual label: 3
Output voltages: [0.36731, 0.015317, 0.028877, 0.79868, 0.028168, 0.014198, 0.01293, 0.010378, 0.53234, 0.041411]
Predicted label: 3
Correct prediction
Energy consumption = 145.043919 pJ
sum error= 344
Actual label: 8
Output voltages: [0.032521, 0.024666, 0.25308, 0.03617, 0.01708, 0.021678, 0.014548, 0.0094134, 0.79871, 0.1315]
Predicted label: 8
Correct prediction
Energy consumption = 149.803408 pJ
sum error= 344
Actual label: 5
Output voltages: [0.022013, 0.0014736, 0.00169, 0.1454, 0.026757, 0.79878, 0.5579, 0.022993, 0.7259, 0.020964]
Predicted label: 5
Correct prediction
Energy consumption = 142.384579 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0016911, 0.018667, 0.021699, 0.032783, 0.79868, 0.0010791, 0.096436, 0.41464, 0.023458, 0.017317]
Predicted label: 4
Correct prediction
Energy consumption = 152.526835 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 888 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 888 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 888 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.61553, 0.085175, 0.79877, 0.34015, 0.015373, 0.0011657, 0.029707, 0.023835, 0.35138, 0.01118]
Predicted label: 2
Correct prediction
Energy consumption = 148.799405 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79872, 0.047735, 0.28362, 0.0074323, 0.036181, 0.0012992, 0.22081, 0.036202, 0.19229, 0.026759]
Predicted label: 0
Correct prediction
Energy consumption = 156.634589 pJ
sum error= 344
Actual label: 9
Output voltages: [0.19466, 0.0064078, 0.095428, 0.046915, 0.52241, 0.01557, 0.01406, 0.0039793, 0.3174, 0.79839]
Predicted label: 9
Correct prediction
Energy consumption = 156.353293 pJ
sum error= 344
Actual label: 7
Output voltages: [0.16731, 0.022988, 0.17816, 0.23366, 0.011996, 0.0018537, 0.001183, 0.79867, 0.58194, 0.21714]
Predicted label: 7
Correct prediction
Energy consumption = 151.023426 pJ
sum error= 344
Actual label: 6
Output voltages: [0.051004, 0.04743, 0.15956, 0.0010761, 0.33433, 0.15146, 0.79875, 0.0014231, 0.098322, 0.0092026]
Predicted label: 6
Correct prediction
Energy consumption = 154.350363 pJ
sum error= 344
Actual label: 7
Output voltages: [0.021229, 0.089686, 0.54202, 0.12905, 0.0018044, 0.0010666, 0.0011231, 0.79879, 0.4213, 0.32289]
Predicted label: 7
Correct prediction
Energy consumption = 153.692039 pJ
sum error= 344
Actual label: 4
Output voltages: [0.013014, 0.0023294, 0.44007, 0.020722, 0.79866, 0.0013553, 0.019335, 0.011455, 0.076213, 0.040803]
Predicted label: 4
Correct prediction
Energy consumption = 151.464482 pJ
sum error= 344
Actual label: 1
Output voltages: [0.025718, 0.79798, 0.060104, 0.010496, 0.55694, 0.0010961, 0.042771, 0.025827, 0.045135, 0.023425]
Predicted label: 1
Correct prediction
Energy consumption = 150.806848 pJ
sum error= 344
Actual label: 6
Output voltages: [0.034407, 0.034965, 0.39204, 0.0021605, 0.485, 0.1917, 0.79871, 0.0051447, 0.25991, 0.0048478]
Predicted label: 6
Correct prediction
Energy consumption = 145.702928 pJ
sum error= 344
Actual label: 2
Output voltages: [0.63027, 0.026783, 0.79879, 0.45974, 0.0059022, 0.0011871, 0.049827, 0.041715, 0.505, 0.041911]
Predicted label: 2
Correct prediction
Energy consumption = 142.915496 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 889 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 889 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 889 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.045707, 0.040189, 0.10975, 0.0027666, 0.33335, 0.19373, 0.79872, 0.0019557, 0.67003, 0.0071514]
Predicted label: 6
Correct prediction
Energy consumption = 143.298137 pJ
sum error= 344
Actual label: 7
Output voltages: [0.049161, 0.0662, 0.22336, 0.076898, 0.0052975, 0.0033553, 0.0011111, 0.79858, 0.28831, 0.4463]
Predicted label: 7
Correct prediction
Energy consumption = 157.409105 pJ
sum error= 344
Actual label: 1
Output voltages: [0.47292, 0.79875, 0.21802, 0.021954, 0.28044, 0.0044986, 0.026636, 0.016684, 0.0072583, 0.04642]
Predicted label: 1
Correct prediction
Energy consumption = 156.538414 pJ
sum error= 344
Actual label: 9
Output voltages: [0.39184, 0.026529, 0.02318, 0.072355, 0.19612, 0.030903, 0.0082587, 0.012521, 0.35913, 0.79869]
Predicted label: 9
Correct prediction
Energy consumption = 145.454266 pJ
sum error= 344
Actual label: 8
Output voltages: [0.011946, 0.055629, 0.2034, 0.042185, 0.0092688, 0.012279, 0.032066, 0.011211, 0.79866, 0.26103]
Predicted label: 8
Correct prediction
Energy consumption = 147.332521 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79876, 0.089822, 0.043163, 0.010167, 0.013492, 0.010255, 0.18048, 0.10894, 0.045219, 0.046847]
Predicted label: 0
Correct prediction
Energy consumption = 149.752696 pJ
sum error= 344
Actual label: 6
Output voltages: [0.14303, 0.049947, 0.4369, 0.0017831, 0.27276, 0.23088, 0.7987, 0.0034246, 0.17333, 0.012512]
Predicted label: 6
Correct prediction
Energy consumption = 144.084270 pJ
sum error= 344
Actual label: 9
Output voltages: [0.39608, 0.0031199, 0.036707, 0.012, 0.048334, 0.018007, 0.0022991, 0.02508, 0.53437, 0.79688]
Predicted label: 9
Correct prediction
Energy consumption = 149.021619 pJ
sum error= 344
Actual label: 4
Output voltages: [0.007726, 0.010236, 0.13401, 0.0066778, 0.79866, 0.0014222, 0.028348, 0.030148, 0.037, 0.034907]
Predicted label: 4
Correct prediction
Energy consumption = 151.483066 pJ
sum error= 344
Actual label: 9
Output voltages: [0.33327, 0.0050975, 0.028029, 0.01164, 0.23439, 0.0057786, 0.0021512, 0.0076723, 0.5046, 0.79579]
Predicted label: 9
Correct prediction
Energy consumption = 141.122459 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 890 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 890 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 890 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.062003, 0.011411, 0.023413, 0.047766, 0.063183, 0.018189, 0.0035247, 0.047377, 0.69827, 0.79667]
Predicted label: 9
Correct prediction
Energy consumption = 149.866155 pJ
sum error= 344
Actual label: 6
Output voltages: [0.30237, 0.18501, 0.23015, 0.0036998, 0.11373, 0.38856, 0.79876, 0.017863, 0.36722, 0.0050572]
Predicted label: 6
Correct prediction
Energy consumption = 152.223000 pJ
sum error= 344
Actual label: 2
Output voltages: [0.60366, 0.035017, 0.79875, 0.023249, 0.0085827, 0.0011925, 0.036899, 0.046259, 0.4015, 0.014616]
Predicted label: 2
Correct prediction
Energy consumption = 150.220172 pJ
sum error= 344
Actual label: 3
Output voltages: [0.38153, 0.026508, 0.20389, 0.79875, 0.01921, 0.031231, 0.019957, 0.010891, 0.53075, 0.15693]
Predicted label: 3
Correct prediction
Energy consumption = 143.615296 pJ
sum error= 344
Actual label: 7
Output voltages: [0.62846, 0.02397, 0.0018536, 0.044903, 0.036272, 0.028691, 0.0016001, 0.79879, 0.036337, 0.39302]
Predicted label: 7
Correct prediction
Energy consumption = 146.554287 pJ
sum error= 344
Actual label: 1
Output voltages: [0.22506, 0.79877, 0.035338, 0.0065064, 0.64413, 0.0051291, 0.018831, 0.0069413, 0.28702, 0.026226]
Predicted label: 1
Correct prediction
Energy consumption = 155.168115 pJ
sum error= 344
Actual label: 9
Output voltages: [0.263, 0.012074, 0.0061068, 0.034993, 0.14782, 0.071108, 0.0060346, 0.0051511, 0.69722, 0.79772]
Predicted label: 9
Correct prediction
Energy consumption = 148.842108 pJ
sum error= 344
Actual label: 2
Output voltages: [0.65216, 0.0024313, 0.79879, 0.10416, 0.014735, 0.0010784, 0.017575, 0.031511, 0.48729, 0.0032044]
Predicted label: 2
Correct prediction
Energy consumption = 146.884087 pJ
sum error= 344
Actual label: 2
Output voltages: [0.21175, 0.015081, 0.79729, 0.052849, 0.33214, 0.0010852, 0.31316, 0.010847, 0.51294, 0.025862]
Predicted label: 2
Correct prediction
Energy consumption = 139.767337 pJ
sum error= 344
Actual label: 5
Output voltages: [0.034398, 0.0011259, 0.0036341, 0.45666, 0.017077, 0.79677, 0.24612, 0.030585, 0.77936, 0.030702]
Predicted label: 5
Correct prediction
Energy consumption = 146.813073 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 891 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 891 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 891 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.37825, 0.0020999, 0.043405, 0.79876, 0.16792, 0.036111, 0.011146, 0.005396, 0.64315, 0.036621]
Predicted label: 3
Correct prediction
Energy consumption = 152.190967 pJ
sum error= 344
Actual label: 7
Output voltages: [0.14103, 0.17171, 0.60146, 0.1481, 0.0016059, 0.0010763, 0.0011204, 0.79879, 0.16809, 0.44181]
Predicted label: 7
Correct prediction
Energy consumption = 149.343979 pJ
sum error= 344
Actual label: 8
Output voltages: [0.016483, 0.11909, 0.033239, 0.15813, 0.014364, 0.040866, 0.059081, 0.027758, 0.79879, 0.23607]
Predicted label: 8
Correct prediction
Energy consumption = 142.664342 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79873, 0.045238, 0.031379, 0.016446, 0.10387, 0.006267, 0.56635, 0.02566, 0.059976, 0.073994]
Predicted label: 0
Correct prediction
Energy consumption = 152.710861 pJ
sum error= 344
Actual label: 1
Output voltages: [0.015228, 0.79859, 0.037191, 0.040938, 0.053353, 0.0025274, 0.51183, 0.0052877, 0.059622, 0.034928]
Predicted label: 1
Correct prediction
Energy consumption = 152.068373 pJ
sum error= 344
Actual label: 2
Output voltages: [0.43304, 0.0078789, 0.79862, 0.36685, 0.02793, 0.0010694, 0.016292, 0.038399, 0.63169, 0.0021223]
Predicted label: 2
Correct prediction
Energy consumption = 142.845107 pJ
sum error= 344
Actual label: 3
Output voltages: [0.10586, 0.0124, 0.18541, 0.79877, 0.014787, 0.0043517, 0.0037977, 0.024195, 0.53741, 0.042682]
Predicted label: 3
Correct prediction
Energy consumption = 138.430594 pJ
sum error= 344
Actual label: 4
Output voltages: [0.010638, 0.0067795, 0.11748, 0.0099002, 0.79857, 0.0045145, 0.03504, 0.018699, 0.061984, 0.011988]
Predicted label: 4
Correct prediction
Energy consumption = 146.601068 pJ
sum error= 344
Actual label: 7
Output voltages: [0.38196, 0.02597, 0.015085, 0.56682, 0.023916, 0.10371, 0.0011371, 0.79878, 0.40266, 0.36816]
Predicted label: 7
Correct prediction
Energy consumption = 146.193625 pJ
sum error= 344
Actual label: 8
Output voltages: [0.013443, 0.031944, 0.046147, 0.047744, 0.042085, 0.020056, 0.016222, 0.024413, 0.79867, 0.12132]
Predicted label: 8
Correct prediction
Energy consumption = 141.761904 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 892 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 892 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 892 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.47596, 0.020771, 0.056785, 0.044425, 0.16284, 0.059941, 0.0060663, 0.039516, 0.41722, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 150.714524 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79875, 0.027265, 0.060891, 0.019188, 0.021483, 0.0037438, 0.35517, 0.029029, 0.1295, 0.044248]
Predicted label: 0
Correct prediction
Energy consumption = 145.152167 pJ
sum error= 344
Actual label: 1
Output voltages: [0.054712, 0.7985, 0.39961, 0.0013124, 0.018677, 0.0045641, 0.40013, 0.0011927, 0.73562, 0.14187]
Predicted label: 1
Correct prediction
Energy consumption = 143.295827 pJ
sum error= 344
Actual label: 2
Output voltages: [0.49213, 0.0032128, 0.79878, 0.24374, 0.0054205, 0.0010741, 0.027136, 0.030367, 0.42813, 0.0043261]
Predicted label: 2
Correct prediction
Energy consumption = 148.059235 pJ
sum error= 344
Actual label: 3
Output voltages: [0.35799, 0.017523, 0.14037, 0.79863, 0.039367, 0.014597, 0.011189, 0.039447, 0.70416, 0.073524]
Predicted label: 3
Correct prediction
Energy consumption = 141.370667 pJ
sum error= 344
Actual label: 4
Output voltages: [0.031692, 0.011481, 0.39882, 0.019159, 0.79866, 0.0013875, 0.0649, 0.40115, 0.010655, 0.011259]
Predicted label: 4
Correct prediction
Energy consumption = 151.061552 pJ
sum error= 344
Actual label: 7
Output voltages: [0.21213, 0.014591, 0.1335, 0.014407, 0.057939, 0.017925, 0.0011698, 0.79863, 0.057136, 0.49949]
Predicted label: 7
Correct prediction
Energy consumption = 150.556712 pJ
sum error= 344
Actual label: 8
Output voltages: [0.049519, 0.04787, 0.29669, 0.038957, 0.007429, 0.090905, 0.013452, 0.0050305, 0.79869, 0.033943]
Predicted label: 8
Correct prediction
Energy consumption = 147.627918 pJ
sum error= 344
Actual label: 9
Output voltages: [0.33376, 0.0082367, 0.024964, 0.021264, 0.034897, 0.030392, 0.0063635, 0.050551, 0.67683, 0.79798]
Predicted label: 9
Correct prediction
Energy consumption = 139.483288 pJ
sum error= 344
Actual label: 0
Output voltages: [0.7987, 0.051868, 0.025997, 0.011479, 0.022082, 0.014859, 0.38744, 0.029882, 0.066982, 0.027194]
Predicted label: 0
Correct prediction
Energy consumption = 137.224934 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 893 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 893 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 893 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.023704, 0.79865, 0.13829, 0.036601, 0.54168, 0.0013562, 0.065666, 0.010432, 0.08591, 0.030917]
Predicted label: 1
Correct prediction
Energy consumption = 149.825141 pJ
sum error= 344
Actual label: 7
Output voltages: [0.47683, 0.022093, 0.047055, 0.023892, 0.062836, 0.0018411, 0.0011208, 0.79856, 0.0451, 0.026837]
Predicted label: 7
Correct prediction
Energy consumption = 145.307068 pJ
sum error= 344
Actual label: 8
Output voltages: [0.023168, 0.065927, 0.31154, 0.013686, 0.0060973, 0.0035019, 0.030075, 0.0085473, 0.79879, 0.36676]
Predicted label: 8
Correct prediction
Energy consumption = 140.479731 pJ
sum error= 344
Actual label: 9
Output voltages: [0.14414, 0.012809, 0.040918, 0.012615, 0.034197, 0.022144, 0.0019435, 0.028461, 0.75978, 0.79702]
Predicted label: 9
Correct prediction
Energy consumption = 136.376870 pJ
sum error= 344
Actual label: 8
Output voltages: [0.0033164, 0.15152, 0.2232, 0.042272, 0.021538, 0.010751, 0.014589, 0.023883, 0.79875, 0.21021]
Predicted label: 8
Correct prediction
Energy consumption = 144.249702 pJ
sum error= 344
Actual label: 9
Output voltages: [0.25762, 0.022916, 0.031531, 0.04651, 0.16545, 0.014213, 0.010114, 0.020431, 0.39512, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 148.102154 pJ
sum error= 344
Actual label: 2
Output voltages: [0.50083, 0.017903, 0.79863, 0.029186, 0.0084352, 0.0010868, 0.078168, 0.030618, 0.42818, 0.0096443]
Predicted label: 2
Correct prediction
Energy consumption = 146.137214 pJ
sum error= 344
Actual label: 6
Output voltages: [0.035508, 0.034945, 0.39626, 0.0010678, 0.58969, 0.047266, 0.79878, 0.0011589, 0.27208, 0.0023138]
Predicted label: 6
Correct prediction
Energy consumption = 145.870675 pJ
sum error= 344
Actual label: 1
Output voltages: [0.058237, 0.79879, 0.0067282, 0.0085194, 0.18549, 0.0027182, 0.25576, 0.0051029, 0.25835, 0.039925]
Predicted label: 1
Correct prediction
Energy consumption = 152.128567 pJ
sum error= 344
Actual label: 3
Output voltages: [0.25885, 0.03045, 0.24405, 0.79873, 0.0090944, 0.0026151, 0.0068141, 0.011559, 0.4387, 0.019937]
Predicted label: 3
Correct prediction
Energy consumption = 147.294596 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 894 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 894 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 894 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.20085, 0.0011952, 0.016845, 0.39829, 0.1964, 0.79879, 0.29489, 0.010399, 0.77287, 0.0073503]
Predicted label: 5
Correct prediction
Energy consumption = 141.798203 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0036867, 0.011925, 0.031401, 0.18474, 0.79879, 0.020525, 0.027787, 0.034465, 0.038824, 0.012595]
Predicted label: 4
Correct prediction
Energy consumption = 141.388760 pJ
sum error= 344
Actual label: 8
Output voltages: [0.030046, 0.35346, 0.28699, 0.042426, 0.031188, 0.0013536, 0.0032516, 0.0012985, 0.79848, 0.061909]
Predicted label: 8
Correct prediction
Energy consumption = 145.231477 pJ
sum error= 344
Actual label: 2
Output voltages: [0.31593, 0.074488, 0.79872, 0.37111, 0.0046757, 0.0011429, 0.077117, 0.032704, 0.31284, 0.0070061]
Predicted label: 2
Correct prediction
Energy consumption = 144.463487 pJ
sum error= 344
Actual label: 6
Output voltages: [0.1218, 0.012379, 0.08091, 0.0015169, 0.33005, 0.15174, 0.79879, 0.0010849, 0.69293, 0.0060992]
Predicted label: 6
Correct prediction
Energy consumption = 147.135015 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0053328, 0.0064511, 0.021802, 0.030566, 0.7986, 0.0045686, 0.051217, 0.032628, 0.10966, 0.015189]
Predicted label: 4
Correct prediction
Energy consumption = 144.374695 pJ
sum error= 344
Actual label: 3
Output voltages: [0.35274, 0.011444, 0.019819, 0.79865, 0.035128, 0.035881, 0.024458, 0.0020651, 0.40094, 0.074738]
Predicted label: 3
Correct prediction
Energy consumption = 146.711376 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0031204, 0.027131, 0.063617, 0.032018, 0.79871, 0.0013328, 0.022986, 0.039958, 0.048658, 0.015003]
Predicted label: 4
Correct prediction
Energy consumption = 144.635825 pJ
sum error= 344
Actual label: 5
Output voltages: [0.16831, 0.003295, 0.0011098, 0.57072, 0.14176, 0.79873, 0.18827, 0.011655, 0.35707, 0.0088704]
Predicted label: 5
Correct prediction
Energy consumption = 135.180599 pJ
sum error= 344
Actual label: 9
Output voltages: [0.59457, 0.018592, 0.013151, 0.19859, 0.23874, 0.10048, 0.014873, 0.039244, 0.58703, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 139.123608 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 895 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 895 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 895 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.5895, 0.018111, 0.79873, 0.047693, 0.015329, 0.0011649, 0.029049, 0.024177, 0.48909, 0.0053485]
Predicted label: 2
Correct prediction
Energy consumption = 144.500399 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79861, 0.035201, 0.034957, 0.014218, 0.023179, 0.024995, 0.058289, 0.046432, 0.078705, 0.020701]
Predicted label: 0
Correct prediction
Energy consumption = 152.253127 pJ
sum error= 344
Actual label: 3
Output voltages: [0.20794, 0.024846, 0.60558, 0.79209, 0.0015068, 0.0069348, 0.0015376, 0.0036793, 0.40414, 0.12966]
Predicted label: 3
Correct prediction
Energy consumption = 150.278329 pJ
sum error= 344
Actual label: 9
Output voltages: [0.11773, 0.0059621, 0.028286, 0.014654, 0.043624, 0.0031766, 0.0032809, 0.012708, 0.65629, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 139.721878 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0081142, 0.013538, 0.046342, 0.025712, 0.79865, 0.031263, 0.38628, 0.062335, 0.11342, 0.0060651]
Predicted label: 4
Correct prediction
Energy consumption = 141.566533 pJ
sum error= 344
Actual label: 9
Output voltages: [0.27088, 0.018703, 0.018517, 0.044278, 0.028468, 0.0094068, 0.002043, 0.025763, 0.54957, 0.79856]
Predicted label: 9
Correct prediction
Energy consumption = 140.297676 pJ
sum error= 344
Actual label: 7
Output voltages: [0.032505, 0.1403, 0.38909, 0.062292, 0.0020226, 0.0031787, 0.0012036, 0.79835, 0.50732, 0.23678]
Predicted label: 7
Correct prediction
Energy consumption = 147.303854 pJ
sum error= 344
Actual label: 3
Output voltages: [0.30718, 0.013815, 0.063843, 0.79865, 0.017003, 0.15301, 0.020637, 0.079299, 0.73654, 0.040071]
Predicted label: 3
Correct prediction
Energy consumption = 143.341936 pJ
sum error= 344
Actual label: 8
Output voltages: [0.00238, 0.11252, 0.021032, 0.28353, 0.0017573, 0.099822, 0.0023217, 0.068695, 0.79868, 0.04497]
Predicted label: 8
Correct prediction
Energy consumption = 142.615297 pJ
sum error= 344
Actual label: 7
Output voltages: [0.098462, 0.19119, 0.1058, 0.096728, 0.032205, 0.0060211, 0.0010674, 0.79861, 0.036359, 0.23346]
Predicted label: 7
Correct prediction
Energy consumption = 144.477143 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 896 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 896 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 896 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0039524, 0.0052191, 0.091054, 0.019106, 0.7986, 0.0026497, 0.038054, 0.026523, 0.15209, 0.011455]
Predicted label: 4
Correct prediction
Energy consumption = 147.440700 pJ
sum error= 344
Actual label: 4
Output voltages: [0.030827, 0.010261, 0.44802, 0.0071036, 0.79868, 0.0097719, 0.33364, 0.11644, 0.051467, 0.0041554]
Predicted label: 4
Correct prediction
Energy consumption = 133.496275 pJ
sum error= 344
Actual label: 9
Output voltages: [0.079223, 0.02815, 0.035406, 0.18392, 0.10132, 0.025796, 0.0013988, 0.02691, 0.41401, 0.7982]
Predicted label: 9
Correct prediction
Energy consumption = 149.320926 pJ
sum error= 344
Actual label: 8
Output voltages: [0.00254, 0.046419, 0.068978, 0.027911, 0.026563, 0.021366, 0.007032, 0.041853, 0.79874, 0.22832]
Predicted label: 8
Correct prediction
Energy consumption = 136.600284 pJ
sum error= 344
Actual label: 5
Output voltages: [0.015756, 0.0011052, 0.0014552, 0.41564, 0.058338, 0.79879, 0.22738, 0.01911, 0.72967, 0.11247]
Predicted label: 5
Correct prediction
Energy consumption = 140.738390 pJ
sum error= 344
Actual label: 8
Output voltages: [0.0083366, 0.061278, 0.15614, 0.17507, 0.0038029, 0.036427, 0.023593, 0.23767, 0.79867, 0.024991]
Predicted label: 8
Correct prediction
Energy consumption = 145.157023 pJ
sum error= 344
Actual label: 2
Output voltages: [0.38399, 0.21293, 0.79862, 0.31167, 0.023406, 0.0010984, 0.21892, 0.040104, 0.26181, 0.024648]
Predicted label: 2
Correct prediction
Energy consumption = 142.773456 pJ
sum error= 344
Actual label: 6
Output voltages: [0.014262, 0.0044031, 0.051284, 0.0068953, 0.057039, 0.5429, 0.7986, 0.0026215, 0.79152, 0.014393]
Predicted label: 6
Correct prediction
Energy consumption = 151.594341 pJ
sum error= 344
Actual label: 6
Output voltages: [0.058865, 0.021193, 0.056115, 0.019956, 0.41088, 0.44506, 0.79879, 0.0039747, 0.71025, 0.01206]
Predicted label: 6
Correct prediction
Energy consumption = 137.488596 pJ
sum error= 344
Actual label: 2
Output voltages: [0.3919, 0.019944, 0.79869, 0.061211, 0.067289, 0.00107, 0.042264, 0.032786, 0.43527, 0.023805]
Predicted label: 2
Correct prediction
Energy consumption = 142.044704 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 897 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 897 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 897 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.17805, 0.0062425, 0.39987, 0.79879, 0.0088771, 0.001197, 0.0034308, 0.031815, 0.63892, 0.030386]
Predicted label: 3
Correct prediction
Energy consumption = 144.449406 pJ
sum error= 344
Actual label: 1
Output voltages: [0.10431, 0.79879, 0.035259, 0.0050038, 0.19062, 0.0022458, 0.36665, 0.0039554, 0.095069, 0.0018636]
Predicted label: 1
Correct prediction
Energy consumption = 147.186118 pJ
sum error= 344
Actual label: 3
Output voltages: [0.42491, 0.0017701, 0.5576, 0.79878, 0.015461, 0.020326, 0.030761, 0.038889, 0.78503, 0.017115]
Predicted label: 3
Correct prediction
Energy consumption = 148.010019 pJ
sum error= 344
Actual label: 2
Output voltages: [0.019347, 0.098334, 0.79878, 0.077883, 0.021147, 0.001071, 0.1682, 0.026229, 0.73866, 0.031781]
Predicted label: 2
Correct prediction
Energy consumption = 136.276613 pJ
sum error= 344
Actual label: 7
Output voltages: [0.75879, 0.013237, 0.032516, 0.02461, 0.040775, 0.0024033, 0.001067, 0.79875, 0.15473, 0.036924]
Predicted label: 7
Correct prediction
Energy consumption = 145.416589 pJ
sum error= 344
Actual label: 3
Output voltages: [0.53815, 0.017826, 0.048081, 0.79875, 0.048884, 0.082283, 0.0061085, 0.0013118, 0.46443, 0.050413]
Predicted label: 3
Correct prediction
Energy consumption = 140.107798 pJ
sum error= 344
Actual label: 1
Output voltages: [0.046305, 0.79877, 0.1676, 0.017758, 0.42729, 0.0026261, 0.12192, 0.028401, 0.12319, 0.0014373]
Predicted label: 1
Correct prediction
Energy consumption = 149.157061 pJ
sum error= 344
Actual label: 9
Output voltages: [0.49734, 0.020002, 0.021914, 0.041529, 0.064479, 0.0049087, 0.0023334, 0.031407, 0.60774, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 150.446365 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79858, 0.038965, 0.04442, 0.012094, 0.021416, 0.018674, 0.31555, 0.02014, 0.11597, 0.033838]
Predicted label: 0
Correct prediction
Energy consumption = 137.718931 pJ
sum error= 344
Actual label: 1
Output voltages: [0.011532, 0.79871, 0.098208, 0.011179, 0.035933, 0.0096632, 0.65096, 0.001533, 0.4959, 0.011529]
Predicted label: 1
Correct prediction
Energy consumption = 145.477556 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 898 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 898 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 898 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.040097, 0.79875, 0.58444, 0.017944, 0.44157, 0.0010926, 0.10159, 0.006545, 0.021687, 0.02841]
Predicted label: 1
Correct prediction
Energy consumption = 150.743935 pJ
sum error= 344
Actual label: 3
Output voltages: [0.16117, 0.011527, 0.036047, 0.79877, 0.0073571, 0.10056, 0.0046495, 0.0097368, 0.77921, 0.019697]
Predicted label: 3
Correct prediction
Energy consumption = 137.964438 pJ
sum error= 344
Actual label: 5
Output voltages: [0.23839, 0.0012625, 0.0011037, 0.26043, 0.32292, 0.79872, 0.038449, 0.019933, 0.69646, 0.010604]
Predicted label: 5
Correct prediction
Energy consumption = 133.593953 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.037043, 0.056071, 0.013554, 0.0047904, 0.0014691, 0.7273, 0.032143, 0.19934, 0.24447]
Predicted label: 0
Correct prediction
Energy consumption = 133.814439 pJ
sum error= 344
Actual label: 7
Output voltages: [0.051364, 0.36583, 0.13727, 0.040436, 0.044125, 0.0010903, 0.001097, 0.79869, 0.030848, 0.039669]
Predicted label: 7
Correct prediction
Energy consumption = 155.601225 pJ
sum error= 344
Actual label: 8
Output voltages: [0.0025226, 0.087398, 0.18348, 0.052048, 0.003845, 0.024852, 0.0099652, 0.029049, 0.79869, 0.13664]
Predicted label: 8
Correct prediction
Energy consumption = 145.990692 pJ
sum error= 344
Actual label: 1
Output voltages: [0.04529, 0.79878, 0.041736, 0.10453, 0.74884, 0.0013536, 0.1548, 0.0017686, 0.26881, 0.094928]
Predicted label: 1
Correct prediction
Energy consumption = 150.402876 pJ
sum error= 344
Actual label: 5
Output voltages: [0.12161, 0.0011148, 0.0010736, 0.22026, 0.03879, 0.79878, 0.046895, 0.049462, 0.76175, 0.017681]
Predicted label: 5
Correct prediction
Energy consumption = 149.572128 pJ
sum error= 344
Actual label: 1
Output voltages: [0.029627, 0.79879, 0.058305, 0.001138, 0.13483, 0.0017499, 0.31089, 0.0022593, 0.48639, 0.010509]
Predicted label: 1
Correct prediction
Energy consumption = 152.885231 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0056949, 0.0065346, 0.10549, 0.032668, 0.79871, 0.0030029, 0.043893, 0.10288, 0.13698, 0.013335]
Predicted label: 4
Correct prediction
Energy consumption = 140.073748 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 899 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 899 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 899 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.075329, 0.02024, 0.24253, 0.0095491, 0.54527, 0.13281, 0.79874, 0.0010857, 0.6331, 0.050594]
Predicted label: 6
Correct prediction
Energy consumption = 150.219234 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79873, 0.085303, 0.059137, 0.01673, 0.0069013, 0.013931, 0.44756, 0.021573, 0.048092, 0.038514]
Predicted label: 0
Correct prediction
Energy consumption = 147.705750 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79874, 0.047454, 0.12435, 0.0089666, 0.010867, 0.0039198, 0.40817, 0.016609, 0.044584, 0.022926]
Predicted label: 0
Correct prediction
Energy consumption = 130.811008 pJ
sum error= 344
Actual label: 4
Output voltages: [0.0050082, 0.025516, 0.18904, 0.019513, 0.79858, 0.0060003, 0.1455, 0.17239, 0.035389, 0.0289]
Predicted label: 4
Correct prediction
Energy consumption = 149.321937 pJ
sum error= 344
Actual label: 9
Output voltages: [0.32046, 0.0020006, 0.030821, 0.026187, 0.48807, 0.0026499, 0.0038945, 0.0094011, 0.43361, 0.79801]
Predicted label: 9
Correct prediction
Energy consumption = 137.349976 pJ
sum error= 344
Actual label: 1
Output voltages: [0.023083, 0.79879, 0.050547, 0.058712, 0.35841, 0.00114, 0.38389, 0.025196, 0.12192, 0.0068437]
Predicted label: 1
Correct prediction
Energy consumption = 152.800782 pJ
sum error= 344
Actual label: 6
Output voltages: [0.21178, 0.027699, 0.075474, 0.0012712, 0.46544, 0.042811, 0.79877, 0.001111, 0.57901, 0.0023195]
Predicted label: 6
Correct prediction
Energy consumption = 139.134623 pJ
sum error= 344
Actual label: 6
Output voltages: [0.158, 0.024659, 0.1624, 0.0055525, 0.48972, 0.3739, 0.79876, 0.0010673, 0.40619, 0.025203]
Predicted label: 6
Correct prediction
Energy consumption = 139.712305 pJ
sum error= 344
Actual label: 9
Output voltages: [0.21123, 0.002394, 0.059841, 0.011849, 0.038293, 0.0031249, 0.0012125, 0.013679, 0.77064, 0.78555]
Predicted label: 9
Correct prediction
Energy consumption = 138.324018 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79874, 0.049415, 0.011451, 0.01268, 0.0033071, 0.021865, 0.52502, 0.016825, 0.25691, 0.023567]
Predicted label: 0
Correct prediction
Energy consumption = 141.279704 pJ
sum error= 344
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 900 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 900 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 900 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.50748, 0.012601, 0.12251, 0.051325, 0.028766, 0.0010704, 0.001066, 0.79878, 0.14605, 0.097158]
Predicted label: 7
Correct prediction
Energy consumption = 149.402707 pJ
sum error= 344
Actual label: 6
Output voltages: [0.042467, 0.02267, 0.19062, 0.010972, 0.4574, 0.26739, 0.79873, 0.0010884, 0.74711, 0.039499]
Predicted label: 6
Correct prediction
Energy consumption = 139.515682 pJ
sum error= 344
Actual label: 1
Output voltages: [0.017182, 0.79874, 0.050379, 0.0066053, 0.031804, 0.0090057, 0.5247, 0.015567, 0.69238, 0.019379]
Predicted label: 1
Correct prediction
Energy consumption = 145.778045 pJ
sum error= 344
Actual label: 1
Output voltages: [0.01413, 0.79879, 0.059946, 0.0016419, 0.13066, 0.0010696, 0.22476, 0.0012609, 0.34152, 0.1121]
Predicted label: 1
Correct prediction
Energy consumption = 132.661678 pJ
sum error= 344
Actual label: 0
Output voltages: [0.79879, 0.020248, 0.094895, 0.014563, 0.0088603, 0.0026112, 0.53915, 0.18537, 0.060456, 0.039867]
Predicted label: 0
Correct prediction
Energy consumption = 142.164295 pJ
sum error= 344
Actual label: 1
Output voltages: [0.020199, 0.79644, 0.051155, 0.0025618, 0.18194, 0.0012292, 0.075826, 0.0013891, 0.74922, 0.22709]
Predicted label: 1
Correct prediction
Energy consumption = 148.392631 pJ
sum error= 344
Actual label: 2
Output voltages: [0.42287, 0.011184, 0.79879, 0.19199, 0.0035417, 0.0011961, 0.014993, 0.22661, 0.73701, 0.001932]
Predicted label: 2
Correct prediction
Energy consumption = 138.579932 pJ
sum error= 344
Actual label: 3
Output voltages: [0.084466, 0.0063131, 0.2563, 0.79878, 0.001525, 0.017345, 0.0020086, 0.028281, 0.78701, 0.0022707]
Predicted label: 3
Correct prediction
Energy consumption = 132.818542 pJ
sum error= 344
Actual label: 4
Output voltages: [0.036904, 0.002121, 0.039725, 0.0050391, 0.79873, 0.0096588, 0.29619, 0.01271, 0.085447, 0.0023816]
Predicted label: 4
Correct prediction
Energy consumption = 142.347448 pJ
sum error= 344
Actual label: 7
Output voltages: [0.071936, 0.012446, 0.79762, 0.28074, 0.010791, 0.0010995, 0.0034973, 0.51813, 0.77721, 0.0011879]
Predicted label: 2
Wrong prediction!
Energy consumption = 143.674408 pJ
sum error= 345
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 901 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 901 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 901 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.23381, 0.028277, 0.79704, 0.42201, 0.0010749, 0.0010701, 0.070846, 0.020765, 0.76162, 0.0010963]
Predicted label: 2
Correct prediction
Energy consumption = 146.242766 pJ
sum error= 345
Actual label: 3
Output voltages: [0.58494, 0.0010666, 0.28566, 0.79876, 0.020259, 0.1158, 0.0015285, 0.020764, 0.77286, 0.0012198]
Predicted label: 3
Correct prediction
Energy consumption = 131.574847 pJ
sum error= 345
Actual label: 4
Output voltages: [0.056595, 0.007353, 0.19444, 0.0018809, 0.79876, 0.0010766, 0.044256, 0.22436, 0.042317, 0.018765]
Predicted label: 4
Correct prediction
Energy consumption = 140.283725 pJ
sum error= 345
Actual label: 5
Output voltages: [0.2305, 0.0011462, 0.012249, 0.11987, 0.022058, 0.79879, 0.46002, 0.0084865, 0.75912, 0.00118]
Predicted label: 5
Correct prediction
Energy consumption = 132.803215 pJ
sum error= 345
Actual label: 6
Output voltages: [0.20262, 0.0020853, 0.048935, 0.0022213, 0.31685, 0.17694, 0.79723, 0.0010661, 0.74779, 0.0064901]
Predicted label: 6
Correct prediction
Energy consumption = 130.413683 pJ
sum error= 345
Actual label: 7
Output voltages: [0.043065, 0.024765, 0.78691, 0.38433, 0.013361, 0.001195, 0.0031264, 0.74901, 0.54864, 0.018169]
Predicted label: 2
Wrong prediction!
Energy consumption = 146.218280 pJ
sum error= 346
Actual label: 0
Output voltages: [0.79706, 0.010698, 0.062353, 0.0014608, 0.067431, 0.013172, 0.77234, 0.10585, 0.034341, 0.0017042]
Predicted label: 0
Correct prediction
Energy consumption = 135.485902 pJ
sum error= 346
Actual label: 1
Output voltages: [0.0010677, 0.79877, 0.038534, 0.031187, 0.25112, 0.0011536, 0.15545, 0.021952, 0.2607, 0.028429]
Predicted label: 1
Correct prediction
Energy consumption = 142.584094 pJ
sum error= 346
Actual label: 2
Output voltages: [0.11122, 0.0076485, 0.79878, 0.38843, 0.0058955, 0.0012123, 0.019159, 0.15474, 0.51071, 0.0048717]
Predicted label: 2
Correct prediction
Energy consumption = 135.912710 pJ
sum error= 346
Actual label: 7
Output voltages: [0.028426, 0.0038956, 0.75878, 0.058022, 0.0064546, 0.0011466, 0.0018371, 0.79753, 0.7177, 0.003204]
Predicted label: 7
Correct prediction
Energy consumption = 133.965005 pJ
sum error= 346
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 902 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 902 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 902 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.019304, 0.012937, 0.012933, 0.31201, 0.0035309, 0.21949, 0.015385, 0.0012246, 0.79879, 0.18872]
Predicted label: 8
Correct prediction
Energy consumption = 150.345929 pJ
sum error= 346
Actual label: 6
Output voltages: [0.066761, 0.04007, 0.43253, 0.0011283, 0.40244, 0.0053615, 0.79874, 0.0011421, 0.2719, 0.0058586]
Predicted label: 6
Correct prediction
Energy consumption = 137.156101 pJ
sum error= 346
Actual label: 3
Output voltages: [0.070828, 0.001066, 0.75611, 0.79857, 0.0011352, 0.016817, 0.0091128, 0.072548, 0.60951, 0.0027048]
Predicted label: 3
Correct prediction
Energy consumption = 138.764468 pJ
sum error= 346
Actual label: 9
Output voltages: [0.43421, 0.0018735, 0.03362, 0.042831, 0.30106, 0.019523, 0.0011088, 0.16482, 0.40528, 0.79489]
Predicted label: 9
Correct prediction
Energy consumption = 142.470255 pJ
sum error= 346
Actual label: 7
Output voltages: [0.038195, 0.013801, 0.79299, 0.2001, 0.003978, 0.0011883, 0.0023929, 0.79866, 0.74249, 0.025605]
Predicted label: 7
Correct prediction
Energy consumption = 136.880486 pJ
sum error= 346
Actual label: 1
Output voltages: [0.019023, 0.7987, 0.028395, 0.021182, 0.058849, 0.002055, 0.73854, 0.0025189, 0.41932, 0.021725]
Predicted label: 1
Correct prediction
Energy consumption = 147.781019 pJ
sum error= 346
Actual label: 9
Output voltages: [0.28236, 0.012067, 0.003843, 0.22183, 0.28563, 0.0934, 0.05247, 0.021694, 0.1914, 0.79761]
Predicted label: 9
Correct prediction
Energy consumption = 139.963669 pJ
sum error= 346
Actual label: 3
Output voltages: [0.051002, 0.009078, 0.38827, 0.79878, 0.019863, 0.024831, 0.002632, 0.020656, 0.74308, 0.013217]
Predicted label: 3
Correct prediction
Energy consumption = 140.033171 pJ
sum error= 346
Actual label: 9
Output voltages: [0.44308, 0.002534, 0.0080917, 0.018562, 0.015782, 0.047271, 0.0017472, 0.080485, 0.69433, 0.78291]
Predicted label: 9
Correct prediction
Energy consumption = 141.084911 pJ
sum error= 346
Actual label: 6
Output voltages: [0.063908, 0.0017971, 0.28465, 0.0019422, 0.5596, 0.32754, 0.79869, 0.0010668, 0.64491, 0.020499]
Predicted label: 6
Correct prediction
Energy consumption = 143.111719 pJ
sum error= 346
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 903 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 903 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 903 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.45476, 0.79878, 0.22075, 0.027451, 0.3169, 0.0010689, 0.1161, 0.051462, 0.0013833, 0.099927]
Predicted label: 1
Correct prediction
Energy consumption = 160.461722 pJ
sum error= 346
Actual label: 7
Output voltages: [0.040507, 0.019657, 0.59993, 0.12964, 0.12324, 0.0011656, 0.0026629, 0.79879, 0.074507, 0.18034]
Predicted label: 7
Correct prediction
Energy consumption = 145.838688 pJ
sum error= 346
Actual label: 2
Output voltages: [0.25041, 0.010791, 0.79879, 0.062859, 0.0038771, 0.0012087, 0.20197, 0.025306, 0.65961, 0.0094922]
Predicted label: 2
Correct prediction
Energy consumption = 136.096227 pJ
sum error= 346
Actual label: 4
Output voltages: [0.0067323, 0.0055514, 0.048605, 0.0037088, 0.79866, 0.011024, 0.19089, 0.31509, 0.18148, 0.0087164]
Predicted label: 4
Correct prediction
Energy consumption = 148.814754 pJ
sum error= 346
Actual label: 4
Output voltages: [0.0015769, 0.021515, 0.032234, 0.016101, 0.79874, 0.0022076, 0.11729, 0.48441, 0.043178, 0.0022347]
Predicted label: 4
Correct prediction
Energy consumption = 136.618679 pJ
sum error= 346
Actual label: 5
Output voltages: [0.044645, 0.022253, 0.0010706, 0.1741, 0.16965, 0.79868, 0.090356, 0.020983, 0.7792, 0.0017656]
Predicted label: 5
Correct prediction
Energy consumption = 142.025023 pJ
sum error= 346
Actual label: 7
Output voltages: [0.024474, 0.51689, 0.78443, 0.22352, 0.0069088, 0.0011669, 0.0012392, 0.77886, 0.21946, 0.026999]
Predicted label: 2
Wrong prediction!
Energy consumption = 148.325856 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79875, 0.011057, 0.028579, 0.0061643, 0.071319, 0.024339, 0.64944, 0.029366, 0.0271, 0.25965]
Predicted label: 0
Correct prediction
Energy consumption = 141.977387 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79878, 0.024395, 0.15925, 0.0023355, 0.030748, 0.021296, 0.74894, 0.2993, 0.021571, 0.027758]
Predicted label: 0
Correct prediction
Energy consumption = 126.369009 pJ
sum error= 347
Actual label: 1
Output voltages: [0.014478, 0.79877, 0.28321, 0.0089322, 0.24803, 0.0091346, 0.67423, 0.0016272, 0.41787, 0.028396]
Predicted label: 1
Correct prediction
Energy consumption = 153.341038 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 904 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 904 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 904 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.32122, 0.0028833, 0.025226, 0.02681, 0.20847, 0.76935, 0.79813, 0.0010911, 0.61088, 0.036808]
Predicted label: 6
Correct prediction
Energy consumption = 146.035832 pJ
sum error= 347
Actual label: 6
Output voltages: [0.39836, 0.037528, 0.039574, 0.002227, 0.15193, 0.30157, 0.79868, 0.0011833, 0.18921, 0.011872]
Predicted label: 6
Correct prediction
Energy consumption = 130.863209 pJ
sum error= 347
Actual label: 8
Output voltages: [0.010423, 0.026769, 0.065138, 0.012184, 0.024519, 0.017704, 0.020719, 0.0018227, 0.79869, 0.25034]
Predicted label: 8
Correct prediction
Energy consumption = 142.137778 pJ
sum error= 347
Actual label: 2
Output voltages: [0.31019, 0.091611, 0.79873, 0.16971, 0.00697, 0.0012771, 0.10105, 0.025983, 0.39159, 0.023516]
Predicted label: 2
Correct prediction
Energy consumption = 140.991014 pJ
sum error= 347
Actual label: 7
Output voltages: [0.036352, 0.0034452, 0.78208, 0.015678, 0.011386, 0.0011972, 0.0074075, 0.79877, 0.36516, 0.034875]
Predicted label: 7
Correct prediction
Energy consumption = 140.001976 pJ
sum error= 347
Actual label: 7
Output voltages: [0.011783, 0.025883, 0.77276, 0.040257, 0.040583, 0.0011297, 0.0021469, 0.79878, 0.24245, 0.031315]
Predicted label: 7
Correct prediction
Energy consumption = 132.459936 pJ
sum error= 347
Actual label: 2
Output voltages: [0.065202, 0.0040877, 0.79868, 0.34399, 0.0015561, 0.0011118, 0.014229, 0.30478, 0.7773, 0.0018528]
Predicted label: 2
Correct prediction
Energy consumption = 130.514873 pJ
sum error= 347
Actual label: 4
Output voltages: [0.010927, 0.020224, 0.02282, 0.0016358, 0.79878, 0.0011898, 0.25933, 0.59448, 0.059034, 0.0070831]
Predicted label: 4
Correct prediction
Energy consumption = 149.131777 pJ
sum error= 347
Actual label: 2
Output voltages: [0.31207, 0.045452, 0.79874, 0.043694, 0.01572, 0.0012379, 0.32851, 0.042635, 0.72736, 0.032084]
Predicted label: 2
Correct prediction
Energy consumption = 149.069127 pJ
sum error= 347
Actual label: 1
Output voltages: [0.0097299, 0.79874, 0.16164, 0.0056683, 0.12982, 0.0078835, 0.66947, 0.0048226, 0.63892, 0.034386]
Predicted label: 1
Correct prediction
Energy consumption = 148.827287 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 905 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 905 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 905 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.14003, 0.0050294, 0.17073, 0.0016996, 0.23039, 0.063219, 0.79869, 0.0011021, 0.62732, 0.0098529]
Predicted label: 6
Correct prediction
Energy consumption = 148.716689 pJ
sum error= 347
Actual label: 1
Output voltages: [0.013288, 0.79844, 0.0025165, 0.30438, 0.17089, 0.0010712, 0.2499, 0.0031912, 0.56728, 0.021644]
Predicted label: 1
Correct prediction
Energy consumption = 161.610207 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79875, 0.1388, 0.016934, 0.013054, 0.014008, 0.012061, 0.46743, 0.019499, 0.15087, 0.029861]
Predicted label: 0
Correct prediction
Energy consumption = 145.345561 pJ
sum error= 347
Actual label: 6
Output voltages: [0.083452, 0.055815, 0.28323, 0.0012157, 0.44734, 0.032489, 0.79872, 0.0010817, 0.18347, 0.011243]
Predicted label: 6
Correct prediction
Energy consumption = 141.261347 pJ
sum error= 347
Actual label: 9
Output voltages: [0.53665, 0.0056403, 0.023625, 0.04689, 0.10362, 0.025109, 0.0010891, 0.49166, 0.41129, 0.79501]
Predicted label: 9
Correct prediction
Energy consumption = 151.533182 pJ
sum error= 347
Actual label: 8
Output voltages: [0.015917, 0.01213, 0.053847, 0.21851, 0.0013179, 0.15747, 0.026755, 0.030411, 0.79874, 0.030899]
Predicted label: 8
Correct prediction
Energy consumption = 150.176711 pJ
sum error= 347
Actual label: 3
Output voltages: [0.26616, 0.0049453, 0.10925, 0.79873, 0.011293, 0.27746, 0.004825, 0.024148, 0.6329, 0.0094855]
Predicted label: 3
Correct prediction
Energy consumption = 144.873540 pJ
sum error= 347
Actual label: 9
Output voltages: [0.11314, 0.0093381, 0.011686, 0.11814, 0.024639, 0.0086052, 0.0011358, 0.037897, 0.73996, 0.79806]
Predicted label: 9
Correct prediction
Energy consumption = 143.523492 pJ
sum error= 347
Actual label: 6
Output voltages: [0.10812, 0.022394, 0.23534, 0.0010692, 0.30417, 0.062087, 0.79879, 0.0017439, 0.30937, 0.0023082]
Predicted label: 6
Correct prediction
Energy consumption = 145.039293 pJ
sum error= 347
Actual label: 3
Output voltages: [0.14072, 0.0034059, 0.10531, 0.79871, 0.019505, 0.34516, 0.0096234, 0.020517, 0.76195, 0.008636]
Predicted label: 3
Correct prediction
Energy consumption = 142.690962 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 906 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 906 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 906 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79873, 0.040711, 0.36197, 0.011288, 0.0020728, 0.0091461, 0.22188, 0.0099143, 0.039463, 0.088159]
Predicted label: 0
Correct prediction
Energy consumption = 153.214099 pJ
sum error= 347
Actual label: 1
Output voltages: [0.033247, 0.7985, 0.079661, 0.083799, 0.001305, 0.00197, 0.48159, 0.0099671, 0.19524, 0.038131]
Predicted label: 1
Correct prediction
Energy consumption = 157.891963 pJ
sum error= 347
Actual label: 2
Output voltages: [0.061396, 0.092215, 0.79832, 0.018984, 0.01723, 0.0013914, 0.39899, 0.0439, 0.53143, 0.039291]
Predicted label: 2
Correct prediction
Energy consumption = 151.218469 pJ
sum error= 347
Actual label: 3
Output voltages: [0.16121, 0.4472, 0.37476, 0.79877, 0.01782, 0.0011638, 0.008927, 0.014965, 0.17054, 0.044945]
Predicted label: 3
Correct prediction
Energy consumption = 144.939610 pJ
sum error= 347
Actual label: 4
Output voltages: [0.02036, 0.023341, 0.034805, 0.0012266, 0.79863, 0.017752, 0.070812, 0.081768, 0.10524, 0.031697]
Predicted label: 4
Correct prediction
Energy consumption = 155.005754 pJ
sum error= 347
Actual label: 5
Output voltages: [0.038242, 0.0010853, 0.0037557, 0.41486, 0.029396, 0.79874, 0.071345, 0.087851, 0.76045, 0.17158]
Predicted label: 5
Correct prediction
Energy consumption = 150.374876 pJ
sum error= 347
Actual label: 6
Output voltages: [0.03858, 0.044353, 0.30345, 0.0033818, 0.15285, 0.44516, 0.79871, 0.014785, 0.70711, 0.0085377]
Predicted label: 6
Correct prediction
Energy consumption = 142.884063 pJ
sum error= 347
Actual label: 7
Output voltages: [0.09558, 0.031056, 0.045103, 0.0058572, 0.13833, 0.024466, 0.0010941, 0.7985, 0.12302, 0.056466]
Predicted label: 7
Correct prediction
Energy consumption = 162.118046 pJ
sum error= 347
Actual label: 8
Output voltages: [0.016068, 0.019415, 0.13135, 0.057879, 0.0085656, 0.037778, 0.018748, 0.025874, 0.79866, 0.060931]
Predicted label: 8
Correct prediction
Energy consumption = 147.981259 pJ
sum error= 347
Actual label: 9
Output voltages: [0.54509, 0.0055316, 0.016527, 0.01354, 0.38691, 0.009677, 0.0067292, 0.0099154, 0.17215, 0.79872]
Predicted label: 9
Correct prediction
Energy consumption = 144.294114 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 907 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 907 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 907 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79878, 0.13216, 0.036224, 0.014389, 0.0043008, 0.012523, 0.59955, 0.026644, 0.086885, 0.047831]
Predicted label: 0
Correct prediction
Energy consumption = 147.895682 pJ
sum error= 347
Actual label: 1
Output voltages: [0.070947, 0.79749, 0.19129, 0.033852, 0.027284, 0.0011402, 0.47808, 0.001469, 0.43609, 0.045075]
Predicted label: 1
Correct prediction
Energy consumption = 156.922306 pJ
sum error= 347
Actual label: 2
Output voltages: [0.26809, 0.2227, 0.79878, 0.44797, 0.036648, 0.0011671, 0.4052, 0.0041256, 0.52266, 0.16849]
Predicted label: 2
Correct prediction
Energy consumption = 151.040211 pJ
sum error= 347
Actual label: 3
Output voltages: [0.37295, 0.0055124, 0.13188, 0.79879, 0.0013427, 0.041884, 0.0058028, 0.33263, 0.76721, 0.023318]
Predicted label: 3
Correct prediction
Energy consumption = 137.877214 pJ
sum error= 347
Actual label: 4
Output voltages: [0.022649, 0.008352, 0.037482, 0.0010958, 0.79874, 0.02495, 0.7094, 0.027657, 0.35444, 0.0083274]
Predicted label: 4
Correct prediction
Energy consumption = 161.200370 pJ
sum error= 347
Actual label: 5
Output voltages: [0.14732, 0.0010664, 0.0012111, 0.29553, 0.15843, 0.79873, 0.24573, 0.038669, 0.77993, 0.061954]
Predicted label: 5
Correct prediction
Energy consumption = 143.396460 pJ
sum error= 347
Actual label: 6
Output voltages: [0.089347, 0.017638, 0.40212, 0.021309, 0.2333, 0.457, 0.7987, 0.0010749, 0.54257, 0.016923]
Predicted label: 6
Correct prediction
Energy consumption = 144.358547 pJ
sum error= 347
Actual label: 7
Output voltages: [0.17934, 0.15732, 0.052623, 0.075953, 0.014153, 0.0013395, 0.0010978, 0.79868, 0.45345, 0.49366]
Predicted label: 7
Correct prediction
Energy consumption = 160.469694 pJ
sum error= 347
Actual label: 8
Output voltages: [0.031022, 0.015303, 0.098716, 0.046088, 0.0074106, 0.036614, 0.061649, 0.013658, 0.79877, 0.14003]
Predicted label: 8
Correct prediction
Energy consumption = 145.491752 pJ
sum error= 347
Actual label: 9
Output voltages: [0.18379, 0.005032, 0.03569, 0.10063, 0.62579, 0.044118, 0.041398, 0.0012515, 0.099859, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 150.313686 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 908 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 908 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 908 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79879, 0.061613, 0.042399, 0.0039566, 0.0039242, 0.0088642, 0.49444, 0.0096013, 0.27358, 0.085922]
Predicted label: 0
Correct prediction
Energy consumption = 148.022165 pJ
sum error= 347
Actual label: 1
Output voltages: [0.013686, 0.79858, 0.028716, 0.057579, 0.051641, 0.002488, 0.39032, 0.001546, 0.46686, 0.040706]
Predicted label: 1
Correct prediction
Energy consumption = 160.229884 pJ
sum error= 347
Actual label: 2
Output voltages: [0.028292, 0.13644, 0.79804, 0.11479, 0.0055649, 0.0012724, 0.42297, 0.0021809, 0.70794, 0.022177]
Predicted label: 2
Correct prediction
Energy consumption = 147.066197 pJ
sum error= 347
Actual label: 3
Output voltages: [0.42368, 0.030893, 0.057219, 0.79866, 0.050544, 0.0031549, 0.020938, 0.007739, 0.73761, 0.044199]
Predicted label: 3
Correct prediction
Energy consumption = 141.650342 pJ
sum error= 347
Actual label: 4
Output voltages: [0.20013, 0.0013961, 0.17576, 0.0011095, 0.79879, 0.0011876, 0.24506, 0.020167, 0.31508, 0.0026629]
Predicted label: 4
Correct prediction
Energy consumption = 153.157801 pJ
sum error= 347
Actual label: 5
Output voltages: [0.021229, 0.0011013, 0.017174, 0.069054, 0.033646, 0.79834, 0.038944, 0.04642, 0.78647, 0.16532]
Predicted label: 5
Correct prediction
Energy consumption = 144.679696 pJ
sum error= 347
Actual label: 6
Output voltages: [0.057655, 0.073654, 0.14513, 0.003527, 0.25951, 0.20266, 0.79874, 0.001071, 0.32625, 0.017419]
Predicted label: 6
Correct prediction
Energy consumption = 141.345907 pJ
sum error= 347
Actual label: 7
Output voltages: [0.063606, 0.043802, 0.038196, 0.0159, 0.026189, 0.0019562, 0.0010826, 0.7986, 0.29593, 0.072528]
Predicted label: 7
Correct prediction
Energy consumption = 157.126959 pJ
sum error= 347
Actual label: 8
Output voltages: [0.034541, 0.030207, 0.03212, 0.29468, 0.012131, 0.21439, 0.29605, 0.0018515, 0.79878, 0.27714]
Predicted label: 8
Correct prediction
Energy consumption = 153.141383 pJ
sum error= 347
Actual label: 9
Output voltages: [0.16274, 0.029953, 0.012842, 0.10928, 0.15315, 0.016131, 0.011054, 0.022134, 0.24455, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 145.790768 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 909 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 909 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 909 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0017964, 0.79864, 0.040152, 0.24069, 0.1042, 0.0013072, 0.062495, 0.015298, 0.27761, 0.16292]
Predicted label: 1
Correct prediction
Energy consumption = 166.281655 pJ
sum error= 347
Actual label: 6
Output voltages: [0.24879, 0.03555, 0.34871, 0.0031758, 0.35983, 0.41929, 0.79871, 0.0024992, 0.446, 0.012284]
Predicted label: 6
Correct prediction
Energy consumption = 155.027413 pJ
sum error= 347
Actual label: 8
Output voltages: [0.051971, 0.0085721, 0.010231, 0.40818, 0.0024802, 0.069784, 0.0031805, 0.0020372, 0.79877, 0.29228]
Predicted label: 8
Correct prediction
Energy consumption = 156.626345 pJ
sum error= 347
Actual label: 9
Output voltages: [0.5501, 0.0085293, 0.036505, 0.074896, 0.12539, 0.010675, 0.0060878, 0.052809, 0.11022, 0.79312]
Predicted label: 9
Correct prediction
Energy consumption = 150.678632 pJ
sum error= 347
Actual label: 9
Output voltages: [0.24763, 0.015767, 0.41223, 0.048091, 0.070562, 0.016129, 0.0096303, 0.061147, 0.20222, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 145.709081 pJ
sum error= 347
Actual label: 0
Output voltages: [0.7984, 0.025138, 0.026942, 0.0028896, 0.0013877, 0.0087368, 0.69497, 0.0046408, 0.20602, 0.05]
Predicted label: 0
Correct prediction
Energy consumption = 151.430593 pJ
sum error= 347
Actual label: 1
Output voltages: [0.0063014, 0.79858, 0.046227, 0.035855, 0.01858, 0.0021646, 0.66297, 0.0048534, 0.15708, 0.041887]
Predicted label: 1
Correct prediction
Energy consumption = 158.621623 pJ
sum error= 347
Actual label: 2
Output voltages: [0.29751, 0.18531, 0.79813, 0.28034, 0.033526, 0.0012352, 0.41109, 0.0034814, 0.61127, 0.052012]
Predicted label: 2
Correct prediction
Energy consumption = 148.072484 pJ
sum error= 347
Actual label: 4
Output voltages: [0.011334, 0.0098591, 0.21238, 0.0059098, 0.79861, 0.011386, 0.15655, 0.20931, 0.039106, 0.023513]
Predicted label: 4
Correct prediction
Energy consumption = 156.211889 pJ
sum error= 347
Actual label: 4
Output voltages: [0.0054485, 0.0023565, 0.040556, 0.0066925, 0.79852, 0.0089613, 0.24722, 0.096961, 0.15389, 0.03105]
Predicted label: 4
Correct prediction
Energy consumption = 139.684613 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 910 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 910 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 910 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.17051, 0.029385, 0.2472, 0.79878, 0.013515, 0.0011444, 0.0094754, 0.001656, 0.5618, 0.10517]
Predicted label: 3
Correct prediction
Energy consumption = 147.528054 pJ
sum error= 347
Actual label: 7
Output voltages: [0.050763, 0.047271, 0.21765, 0.23011, 0.0037047, 0.0015044, 0.0026438, 0.79856, 0.034452, 0.34392]
Predicted label: 7
Correct prediction
Energy consumption = 150.383587 pJ
sum error= 347
Actual label: 4
Output voltages: [0.0077727, 0.0067397, 0.03698, 0.0058471, 0.79867, 0.0031692, 0.2733, 0.34776, 0.043617, 0.0060644]
Predicted label: 4
Correct prediction
Energy consumption = 151.761993 pJ
sum error= 347
Actual label: 4
Output voltages: [0.038277, 0.0099185, 0.18098, 0.010006, 0.79864, 0.002178, 0.53738, 0.042066, 0.015875, 0.008098]
Predicted label: 4
Correct prediction
Energy consumption = 147.511652 pJ
sum error= 347
Actual label: 4
Output voltages: [0.0014212, 0.0045764, 0.021901, 0.0046853, 0.79861, 0.0016, 0.14117, 0.45376, 0.078688, 0.030426]
Predicted label: 4
Correct prediction
Energy consumption = 143.257072 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79865, 0.078609, 0.034092, 0.0066486, 0.0077729, 0.0020848, 0.75003, 0.017002, 0.13212, 0.1008]
Predicted label: 0
Correct prediction
Energy consumption = 150.402566 pJ
sum error= 347
Actual label: 3
Output voltages: [0.38382, 0.021754, 0.088323, 0.79871, 0.043869, 0.0015019, 0.006048, 0.013466, 0.61692, 0.017592]
Predicted label: 3
Correct prediction
Energy consumption = 148.415841 pJ
sum error= 347
Actual label: 8
Output voltages: [0.027812, 0.026443, 0.047121, 0.043347, 0.011395, 0.039888, 0.014925, 0.01818, 0.79875, 0.1773]
Predicted label: 8
Correct prediction
Energy consumption = 148.647787 pJ
sum error= 347
Actual label: 7
Output voltages: [0.5588, 0.011926, 0.0034625, 0.032071, 0.15091, 0.2254, 0.0010923, 0.79864, 0.11803, 0.38264]
Predicted label: 7
Correct prediction
Energy consumption = 150.777748 pJ
sum error= 347
Actual label: 5
Output voltages: [0.019217, 0.0010746, 0.0022038, 0.047098, 0.034351, 0.79757, 0.055048, 0.014427, 0.78654, 0.094826]
Predicted label: 5
Correct prediction
Energy consumption = 140.340894 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 911 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 911 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 911 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0054712, 0.026424, 0.40801, 0.32328, 0.020031, 0.0052267, 0.021916, 0.020687, 0.79806, 0.18914]
Predicted label: 8
Correct prediction
Energy consumption = 152.275552 pJ
sum error= 347
Actual label: 2
Output voltages: [0.54363, 0.038188, 0.79874, 0.35532, 0.020257, 0.0012093, 0.1914, 0.0097156, 0.66049, 0.013706]
Predicted label: 2
Correct prediction
Energy consumption = 149.407431 pJ
sum error= 347
Actual label: 1
Output voltages: [0.0084738, 0.79873, 0.023287, 0.019162, 0.62458, 0.17974, 0.76306, 0.0016743, 0.065087, 0.027149]
Predicted label: 1
Correct prediction
Energy consumption = 158.869294 pJ
sum error= 347
Actual label: 7
Output voltages: [0.023512, 0.073238, 0.03226, 0.0012144, 0.048607, 0.0021024, 0.0058168, 0.79857, 0.30524, 0.13977]
Predicted label: 7
Correct prediction
Energy consumption = 156.976846 pJ
sum error= 347
Actual label: 5
Output voltages: [0.10248, 0.0010748, 0.0011971, 0.36997, 0.025438, 0.7985, 0.14082, 0.044932, 0.77572, 0.034396]
Predicted label: 5
Correct prediction
Energy consumption = 144.178572 pJ
sum error= 347
Actual label: 3
Output voltages: [0.32331, 0.017782, 0.029744, 0.79868, 0.014941, 0.013095, 0.013319, 0.006499, 0.67249, 0.051898]
Predicted label: 3
Correct prediction
Energy consumption = 145.887930 pJ
sum error= 347
Actual label: 8
Output voltages: [0.2924, 0.022315, 0.40426, 0.019959, 0.0039746, 0.012426, 0.10542, 0.0022449, 0.79868, 0.16009]
Predicted label: 8
Correct prediction
Energy consumption = 149.942357 pJ
sum error= 347
Actual label: 5
Output voltages: [0.076246, 0.0010685, 0.0011197, 0.71206, 0.0039178, 0.7982, 0.13039, 0.055506, 0.66161, 0.0037482]
Predicted label: 5
Correct prediction
Energy consumption = 151.129212 pJ
sum error= 347
Actual label: 2
Output voltages: [0.32372, 0.040665, 0.79877, 0.1025, 0.023201, 0.0012767, 0.30021, 0.022341, 0.51316, 0.026842]
Predicted label: 2
Correct prediction
Energy consumption = 147.417999 pJ
sum error= 347
Actual label: 5
Output voltages: [0.020469, 0.0010678, 0.013035, 0.19757, 0.018429, 0.79834, 0.06558, 0.025121, 0.78779, 0.039946]
Predicted label: 5
Correct prediction
Energy consumption = 142.250290 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 912 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 912 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 912 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0061772, 0.79872, 0.10781, 0.045661, 0.11948, 0.0010995, 0.44483, 0.0024094, 0.32976, 0.034176]
Predicted label: 1
Correct prediction
Energy consumption = 170.627235 pJ
sum error= 347
Actual label: 1
Output voltages: [0.0058254, 0.79867, 0.22673, 0.033255, 0.018319, 0.0010667, 0.74512, 0.0017379, 0.18546, 0.0078089]
Predicted label: 1
Correct prediction
Energy consumption = 146.394478 pJ
sum error= 347
Actual label: 6
Output voltages: [0.041273, 0.040674, 0.08538, 0.0016036, 0.30498, 0.30114, 0.79879, 0.0012942, 0.33662, 0.0022593]
Predicted label: 6
Correct prediction
Energy consumption = 143.327799 pJ
sum error= 347
Actual label: 2
Output voltages: [0.20083, 0.021184, 0.79781, 0.47639, 0.00821, 0.0012924, 0.16116, 0.01936, 0.63656, 0.011994]
Predicted label: 2
Correct prediction
Energy consumption = 140.846359 pJ
sum error= 347
Actual label: 1
Output voltages: [0.072424, 0.79857, 0.36542, 0.10732, 0.04137, 0.0012756, 0.73252, 0.0018668, 0.03652, 0.025796]
Predicted label: 1
Correct prediction
Energy consumption = 161.749879 pJ
sum error= 347
Actual label: 3
Output voltages: [0.27311, 0.029487, 0.14227, 0.79858, 0.038611, 0.012708, 0.010395, 0.022285, 0.69486, 0.036445]
Predicted label: 3
Correct prediction
Energy consumption = 145.878475 pJ
sum error= 347
Actual label: 8
Output voltages: [0.24741, 0.01383, 0.062079, 0.19941, 0.049383, 0.013297, 0.62696, 0.0042833, 0.79879, 0.041628]
Predicted label: 8
Correct prediction
Energy consumption = 150.157517 pJ
sum error= 347
Actual label: 6
Output voltages: [0.035498, 0.024121, 0.34878, 0.004458, 0.25984, 0.20093, 0.79878, 0.0047353, 0.47223, 0.001517]
Predicted label: 6
Correct prediction
Energy consumption = 150.355706 pJ
sum error= 347
Actual label: 4
Output voltages: [0.0073434, 0.059799, 0.11007, 0.0078211, 0.79859, 0.015753, 0.39909, 0.26777, 0.062112, 0.02113]
Predicted label: 4
Correct prediction
Energy consumption = 152.418786 pJ
sum error= 347
Actual label: 2
Output voltages: [0.17626, 0.53209, 0.79831, 0.59399, 0.012479, 0.0012493, 0.36578, 0.0020915, 0.5855, 0.058938]
Predicted label: 2
Correct prediction
Energy consumption = 151.982038 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 913 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 913 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 913 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.39213, 0.46414, 0.41015, 0.0034096, 0.027924, 0.025813, 0.79879, 0.0013576, 0.57199, 0.011768]
Predicted label: 6
Correct prediction
Energy consumption = 154.218694 pJ
sum error= 347
Actual label: 2
Output voltages: [0.20612, 0.068716, 0.7987, 0.027739, 0.0050333, 0.0013086, 0.14044, 0.24126, 0.42969, 0.028383]
Predicted label: 2
Correct prediction
Energy consumption = 147.029522 pJ
sum error= 347
Actual label: 5
Output voltages: [0.045459, 0.0010827, 0.0090677, 0.35148, 0.046103, 0.79877, 0.34054, 0.029903, 0.77839, 0.0696]
Predicted label: 5
Correct prediction
Energy consumption = 149.512037 pJ
sum error= 347
Actual label: 5
Output voltages: [0.043204, 0.0011086, 0.0017968, 0.30874, 0.021728, 0.79839, 0.071975, 0.024158, 0.78512, 0.014338]
Predicted label: 5
Correct prediction
Energy consumption = 136.507867 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79875, 0.057496, 0.35796, 0.012759, 0.0021386, 0.0072577, 0.26709, 0.025215, 0.1407, 0.048122]
Predicted label: 0
Correct prediction
Energy consumption = 145.648363 pJ
sum error= 347
Actual label: 2
Output voltages: [0.36993, 0.095326, 0.79878, 0.062053, 0.025928, 0.0011574, 0.31909, 0.0028103, 0.4879, 0.046483]
Predicted label: 2
Correct prediction
Energy consumption = 141.748211 pJ
sum error= 347
Actual label: 8
Output voltages: [0.030167, 0.0066968, 0.040144, 0.045783, 0.026427, 0.04324, 0.011004, 0.009676, 0.79877, 0.1873]
Predicted label: 8
Correct prediction
Energy consumption = 149.687717 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79876, 0.070417, 0.036193, 0.025602, 0.0016153, 0.011474, 0.66369, 0.027959, 0.23266, 0.02377]
Predicted label: 0
Correct prediction
Energy consumption = 153.818476 pJ
sum error= 347
Actual label: 6
Output voltages: [0.086726, 0.13909, 0.15331, 0.0021086, 0.21716, 0.41429, 0.79869, 0.0015789, 0.12283, 0.025062]
Predicted label: 6
Correct prediction
Energy consumption = 140.634549 pJ
sum error= 347
Actual label: 8
Output voltages: [0.0023626, 0.053784, 0.033097, 0.42755, 0.55902, 0.015433, 0.42412, 0.0010939, 0.7672, 0.049652]
Predicted label: 8
Correct prediction
Energy consumption = 158.900254 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 914 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 914 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 914 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.029277, 0.79855, 0.052897, 0.14153, 0.26456, 0.0051299, 0.35108, 0.0015242, 0.21233, 0.037838]
Predicted label: 1
Correct prediction
Energy consumption = 163.877363 pJ
sum error= 347
Actual label: 7
Output voltages: [0.35517, 0.0030413, 0.0047964, 0.02044, 0.26226, 0.024898, 0.0010713, 0.79862, 0.36427, 0.099955]
Predicted label: 7
Correct prediction
Energy consumption = 154.541713 pJ
sum error= 347
Actual label: 9
Output voltages: [0.56027, 0.014129, 0.034061, 0.046376, 0.39583, 0.0107, 0.0079285, 0.022458, 0.043854, 0.79878]
Predicted label: 9
Correct prediction
Energy consumption = 152.032099 pJ
sum error= 347
Actual label: 1
Output voltages: [0.0057128, 0.79858, 0.014569, 0.1913, 0.28023, 0.0017326, 0.49677, 0.0089654, 0.26194, 0.28652]
Predicted label: 1
Correct prediction
Energy consumption = 167.011027 pJ
sum error= 347
Actual label: 9
Output voltages: [0.37667, 0.032755, 0.032476, 0.20854, 0.17958, 0.041327, 0.017778, 0.033229, 0.28052, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 157.851032 pJ
sum error= 347
Actual label: 2
Output voltages: [0.39888, 0.10221, 0.79879, 0.048113, 0.021046, 0.0013094, 0.36561, 0.019602, 0.50102, 0.028553]
Predicted label: 2
Correct prediction
Energy consumption = 148.481315 pJ
sum error= 347
Actual label: 6
Output voltages: [0.2839, 0.027047, 0.19571, 0.019975, 0.1076, 0.34586, 0.79876, 0.0011783, 0.55881, 0.14946]
Predicted label: 6
Correct prediction
Energy consumption = 149.752038 pJ
sum error= 347
Actual label: 7
Output voltages: [0.19131, 0.013621, 0.032508, 0.021591, 0.039436, 0.012622, 0.0010711, 0.79844, 0.2182, 0.19651]
Predicted label: 7
Correct prediction
Energy consumption = 158.742412 pJ
sum error= 347
Actual label: 6
Output voltages: [0.32849, 0.025399, 0.051822, 0.0020767, 0.351, 0.32093, 0.79871, 0.020226, 0.71279, 0.0038314]
Predicted label: 6
Correct prediction
Energy consumption = 154.065069 pJ
sum error= 347
Actual label: 6
Output voltages: [0.048411, 0.074462, 0.13067, 0.0024455, 0.17489, 0.17571, 0.79876, 0.010083, 0.73239, 0.015203]
Predicted label: 6
Correct prediction
Energy consumption = 138.576084 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 915 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 915 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 915 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.038018, 0.012453, 0.034945, 0.041141, 0.04728, 0.11536, 0.33999, 0.0042736, 0.79879, 0.15963]
Predicted label: 8
Correct prediction
Energy consumption = 154.329650 pJ
sum error= 347
Actual label: 7
Output voltages: [0.34852, 0.0021978, 0.013028, 0.032832, 0.043462, 0.15064, 0.0010813, 0.79857, 0.2939, 0.3018]
Predicted label: 7
Correct prediction
Energy consumption = 158.340421 pJ
sum error= 347
Actual label: 4
Output voltages: [0.018991, 0.0045598, 0.26115, 0.0046912, 0.79859, 0.0017768, 0.29241, 0.055206, 0.020755, 0.012969]
Predicted label: 4
Correct prediction
Energy consumption = 151.887767 pJ
sum error= 347
Actual label: 9
Output voltages: [0.25104, 0.0056112, 0.011977, 0.019076, 0.065328, 0.01122, 0.0026701, 0.032088, 0.52068, 0.79502]
Predicted label: 9
Correct prediction
Energy consumption = 152.721455 pJ
sum error= 347
Actual label: 2
Output voltages: [0.34386, 0.068249, 0.79871, 0.12929, 0.035683, 0.0012262, 0.52418, 0.023065, 0.57774, 0.060634]
Predicted label: 2
Correct prediction
Energy consumption = 148.239679 pJ
sum error= 347
Actual label: 1
Output voltages: [0.0061466, 0.79846, 0.031883, 0.048425, 0.024454, 0.0058704, 0.74245, 0.0067089, 0.45505, 0.031183]
Predicted label: 1
Correct prediction
Energy consumption = 153.173713 pJ
sum error= 347
Actual label: 3
Output voltages: [0.68161, 0.037094, 0.017268, 0.79861, 0.014741, 0.063368, 0.02698, 0.034311, 0.23141, 0.04538]
Predicted label: 3
Correct prediction
Energy consumption = 152.050177 pJ
sum error= 347
Actual label: 3
Output voltages: [0.29791, 0.017217, 0.063774, 0.79868, 0.020542, 0.0029773, 0.0090441, 0.0097349, 0.51296, 0.033987]
Predicted label: 3
Correct prediction
Energy consumption = 132.225674 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79798, 0.0049899, 0.10458, 0.0035748, 0.015274, 0.0011271, 0.056499, 0.077073, 0.035504, 0.66789]
Predicted label: 0
Correct prediction
Energy consumption = 137.081281 pJ
sum error= 347
Actual label: 5
Output voltages: [0.045329, 0.0010812, 0.0085374, 0.42057, 0.02672, 0.79879, 0.13273, 0.1542, 0.77377, 0.074787]
Predicted label: 5
Correct prediction
Energy consumption = 139.553885 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 916 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 916 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 916 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.23282, 0.0019978, 0.0031632, 0.26863, 0.013314, 0.79874, 0.30971, 0.016914, 0.76192, 0.0032206]
Predicted label: 5
Correct prediction
Energy consumption = 149.371982 pJ
sum error= 347
Actual label: 8
Output voltages: [0.24869, 0.003898, 0.031684, 0.31189, 0.0090229, 0.49849, 0.33644, 0.0013019, 0.79879, 0.21376]
Predicted label: 8
Correct prediction
Energy consumption = 144.613451 pJ
sum error= 347
Actual label: 0
Output voltages: [0.7983, 0.0082189, 0.033031, 0.0050049, 0.042165, 0.0017112, 0.59586, 0.046238, 0.29937, 0.032724]
Predicted label: 0
Correct prediction
Energy consumption = 154.652376 pJ
sum error= 347
Actual label: 3
Output voltages: [0.21606, 0.016648, 0.70602, 0.78758, 0.0037418, 0.0011277, 0.04227, 0.010914, 0.76591, 0.04386]
Predicted label: 3
Correct prediction
Energy consumption = 152.302652 pJ
sum error= 347
Actual label: 7
Output voltages: [0.12379, 0.02282, 0.011911, 0.052038, 0.012383, 0.0395, 0.0010664, 0.79867, 0.12983, 0.55298]
Predicted label: 7
Correct prediction
Energy consumption = 154.898232 pJ
sum error= 347
Actual label: 9
Output voltages: [0.1977, 0.029985, 0.0073274, 0.1319, 0.6226, 0.14602, 0.063961, 0.01668, 0.031927, 0.79861]
Predicted label: 9
Correct prediction
Energy consumption = 144.662829 pJ
sum error= 347
Actual label: 7
Output voltages: [0.21646, 0.0011533, 0.002762, 0.071779, 0.03931, 0.039568, 0.0010662, 0.79857, 0.29802, 0.17523]
Predicted label: 7
Correct prediction
Energy consumption = 154.111271 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79874, 0.04506, 0.03039, 0.015597, 0.0017514, 0.035027, 0.32126, 0.033765, 0.14752, 0.020519]
Predicted label: 0
Correct prediction
Energy consumption = 154.857070 pJ
sum error= 347
Actual label: 2
Output voltages: [0.026752, 0.2352, 0.79614, 0.1936, 0.02331, 0.0010892, 0.28322, 0.0018299, 0.77874, 0.019232]
Predicted label: 2
Correct prediction
Energy consumption = 151.159160 pJ
sum error= 347
Actual label: 7
Output voltages: [0.020002, 0.0035515, 0.057302, 0.037854, 0.066026, 0.006661, 0.0014145, 0.79854, 0.62272, 0.1376]
Predicted label: 7
Correct prediction
Energy consumption = 162.713217 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 917 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 917 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 917 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.1761, 0.040634, 0.026531, 0.22784, 0.49159, 0.037556, 0.013635, 0.0070875, 0.16615, 0.79864]
Predicted label: 9
Correct prediction
Energy consumption = 154.366645 pJ
sum error= 347
Actual label: 1
Output voltages: [0.005643, 0.79854, 0.030193, 0.022468, 0.016932, 0.0014702, 0.50079, 0.0023617, 0.33036, 0.018616]
Predicted label: 1
Correct prediction
Energy consumption = 160.809973 pJ
sum error= 347
Actual label: 7
Output voltages: [0.24473, 0.0013908, 0.0011363, 0.020448, 0.62552, 0.12648, 0.0035682, 0.79878, 0.32617, 0.052535]
Predicted label: 7
Correct prediction
Energy consumption = 165.352008 pJ
sum error= 347
Actual label: 8
Output voltages: [0.004696, 0.098457, 0.11673, 0.038855, 0.02193, 0.0057507, 0.022562, 0.11377, 0.79877, 0.11771]
Predicted label: 8
Correct prediction
Energy consumption = 144.878043 pJ
sum error= 347
Actual label: 0
Output voltages: [0.7987, 0.10504, 0.034903, 0.012769, 0.0058982, 0.015396, 0.43669, 0.039349, 0.12659, 0.015083]
Predicted label: 0
Correct prediction
Energy consumption = 147.333662 pJ
sum error= 347
Actual label: 3
Output voltages: [0.55655, 0.010714, 0.29524, 0.79877, 0.020215, 0.0011299, 0.0072108, 0.0027339, 0.41992, 0.032844]
Predicted label: 3
Correct prediction
Energy consumption = 150.589431 pJ
sum error= 347
Actual label: 5
Output voltages: [0.043214, 0.0011613, 0.002204, 0.13047, 0.017289, 0.79207, 0.15882, 0.038488, 0.77452, 0.044408]
Predicted label: 5
Correct prediction
Energy consumption = 139.344662 pJ
sum error= 347
Actual label: 3
Output voltages: [0.4526, 0.013442, 0.10078, 0.79869, 0.11813, 0.004465, 0.01607, 0.0037712, 0.70749, 0.027718]
Predicted label: 3
Correct prediction
Energy consumption = 141.617844 pJ
sum error= 347
Actual label: 6
Output voltages: [0.17951, 0.04732, 0.11759, 0.0016157, 0.33844, 0.26664, 0.79872, 0.001231, 0.55919, 0.0075243]
Predicted label: 6
Correct prediction
Energy consumption = 148.049414 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79838, 0.16828, 0.039949, 0.0076741, 0.0061804, 0.0018406, 0.53639, 0.045548, 0.323, 0.53952]
Predicted label: 0
Correct prediction
Energy consumption = 141.470022 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 918 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 918 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 918 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.042981, 0.79847, 0.32729, 0.001079, 0.027691, 0.0064418, 0.062333, 0.0030845, 0.73707, 0.035189]
Predicted label: 1
Correct prediction
Energy consumption = 151.562448 pJ
sum error= 347
Actual label: 2
Output voltages: [0.030525, 0.06022, 0.79878, 0.11652, 0.0029031, 0.001145, 0.027043, 0.028084, 0.67929, 0.02484]
Predicted label: 2
Correct prediction
Energy consumption = 145.093705 pJ
sum error= 347
Actual label: 3
Output voltages: [0.38219, 0.022507, 0.093147, 0.79876, 0.006204, 0.0021105, 0.0033148, 0.021075, 0.44822, 0.021692]
Predicted label: 3
Correct prediction
Energy consumption = 138.663167 pJ
sum error= 347
Actual label: 4
Output voltages: [0.0061374, 0.0023711, 0.033879, 0.098694, 0.79867, 0.010774, 0.065933, 0.042236, 0.22037, 0.26511]
Predicted label: 4
Correct prediction
Energy consumption = 138.187937 pJ
sum error= 347
Actual label: 5
Output voltages: [0.008368, 0.0064258, 0.0041663, 0.36128, 0.01615, 0.79879, 0.44278, 0.0087488, 0.70126, 0.012849]
Predicted label: 5
Correct prediction
Energy consumption = 144.511155 pJ
sum error= 347
Actual label: 6
Output voltages: [0.13362, 0.037635, 0.022582, 0.0044351, 0.065301, 0.17546, 0.79851, 0.037025, 0.78023, 0.0073217]
Predicted label: 6
Correct prediction
Energy consumption = 140.715149 pJ
sum error= 347
Actual label: 7
Output voltages: [0.36357, 0.026971, 0.049597, 0.024701, 0.22014, 0.0011378, 0.0010923, 0.79863, 0.40772, 0.01703]
Predicted label: 7
Correct prediction
Energy consumption = 148.770215 pJ
sum error= 347
Actual label: 8
Output voltages: [0.0041242, 0.14115, 0.09758, 0.022422, 0.024813, 0.012743, 0.015322, 0.020874, 0.79879, 0.45906]
Predicted label: 8
Correct prediction
Energy consumption = 143.069226 pJ
sum error= 347
Actual label: 9
Output voltages: [0.36021, 0.012176, 0.047751, 0.14493, 0.47166, 0.0017394, 0.0011893, 0.0079742, 0.2175, 0.79676]
Predicted label: 9
Correct prediction
Energy consumption = 145.604635 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79864, 0.093801, 0.018162, 0.019648, 0.020453, 0.017151, 0.69232, 0.018327, 0.14746, 0.0097571]
Predicted label: 0
Correct prediction
Energy consumption = 144.204380 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 919 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 919 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 919 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0074599, 0.79878, 0.03551, 0.0064869, 0.011916, 0.0020327, 0.44808, 0.003169, 0.68547, 0.029888]
Predicted label: 1
Correct prediction
Energy consumption = 149.530312 pJ
sum error= 347
Actual label: 2
Output voltages: [0.26607, 0.094619, 0.79878, 0.24201, 0.0019049, 0.001261, 0.20479, 0.0090758, 0.36751, 0.00909]
Predicted label: 2
Correct prediction
Energy consumption = 142.079030 pJ
sum error= 347
Actual label: 3
Output voltages: [0.087812, 0.0041643, 0.036558, 0.79874, 0.037893, 0.023513, 0.0090818, 0.020803, 0.73646, 0.040597]
Predicted label: 3
Correct prediction
Energy consumption = 139.220379 pJ
sum error= 347
Actual label: 4
Output voltages: [0.048177, 0.023311, 0.0089848, 0.0042898, 0.79872, 0.026682, 0.014404, 0.12858, 0.23722, 0.0039759]
Predicted label: 4
Correct prediction
Energy consumption = 141.359340 pJ
sum error= 347
Actual label: 5
Output voltages: [0.25062, 0.0017837, 0.0013312, 0.15575, 0.025858, 0.79878, 0.47677, 0.0181, 0.44533, 0.0022862]
Predicted label: 5
Correct prediction
Energy consumption = 139.499044 pJ
sum error= 347
Actual label: 6
Output voltages: [0.25597, 0.02753, 0.034319, 0.0026784, 0.29117, 0.31917, 0.79877, 0.0076381, 0.70936, 0.0075495]
Predicted label: 6
Correct prediction
Energy consumption = 139.850732 pJ
sum error= 347
Actual label: 7
Output voltages: [0.075574, 0.033888, 0.097341, 0.15661, 0.090449, 0.030239, 0.0011619, 0.79879, 0.13935, 0.61036]
Predicted label: 7
Correct prediction
Energy consumption = 146.009615 pJ
sum error= 347
Actual label: 8
Output voltages: [0.10616, 0.048121, 0.1074, 0.034849, 0.04683, 0.046594, 0.0071844, 0.021537, 0.79879, 0.028618]
Predicted label: 8
Correct prediction
Energy consumption = 139.702598 pJ
sum error= 347
Actual label: 9
Output voltages: [0.37159, 0.002179, 0.025866, 0.023018, 0.066695, 0.028328, 0.0010866, 0.013894, 0.69598, 0.79574]
Predicted label: 9
Correct prediction
Energy consumption = 133.816617 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79862, 0.046253, 0.043567, 0.0055747, 0.015659, 0.0092971, 0.44947, 0.0336, 0.17861, 0.024102]
Predicted label: 0
Correct prediction
Energy consumption = 136.519378 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 920 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 920 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 920 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0016635, 0.79875, 0.25321, 0.016198, 0.37124, 0.0039966, 0.43522, 0.001066, 0.092306, 0.058909]
Predicted label: 1
Correct prediction
Energy consumption = 150.441193 pJ
sum error= 347
Actual label: 2
Output voltages: [0.17025, 0.010534, 0.79879, 0.22352, 0.0055911, 0.0011191, 0.22128, 0.033924, 0.73712, 0.012405]
Predicted label: 2
Correct prediction
Energy consumption = 144.677310 pJ
sum error= 347
Actual label: 3
Output voltages: [0.028549, 0.024295, 0.44115, 0.79733, 0.020334, 0.0021356, 0.0010824, 0.010613, 0.53043, 0.20398]
Predicted label: 3
Correct prediction
Energy consumption = 140.684970 pJ
sum error= 347
Actual label: 4
Output voltages: [0.012378, 0.010343, 0.030024, 0.0029143, 0.79855, 0.014068, 0.051061, 0.037683, 0.086024, 0.033651]
Predicted label: 4
Correct prediction
Energy consumption = 138.050028 pJ
sum error= 347
Actual label: 7
Output voltages: [0.30034, 0.042017, 0.033966, 0.074389, 0.0012446, 0.0035999, 0.0012466, 0.79879, 0.063059, 0.30044]
Predicted label: 7
Correct prediction
Energy consumption = 147.790456 pJ
sum error= 347
Actual label: 8
Output voltages: [0.12309, 0.11404, 0.22126, 0.01028, 0.039181, 0.001217, 0.24684, 0.001586, 0.79717, 0.4004]
Predicted label: 8
Correct prediction
Energy consumption = 141.092889 pJ
sum error= 347
Actual label: 9
Output voltages: [0.2919, 0.01107, 0.005212, 0.212, 0.30514, 0.011816, 0.0053341, 0.0051388, 0.46558, 0.79817]
Predicted label: 9
Correct prediction
Energy consumption = 134.502992 pJ
sum error= 347
Actual label: 6
Output voltages: [0.46238, 0.036312, 0.14884, 0.0029639, 0.22112, 0.026363, 0.79825, 0.0044601, 0.73119, 0.0067563]
Predicted label: 6
Correct prediction
Energy consumption = 148.578007 pJ
sum error= 347
Actual label: 4
Output voltages: [0.0037219, 0.011862, 0.082103, 0.20888, 0.79879, 0.0017284, 0.0072102, 0.024014, 0.032752, 0.054624]
Predicted label: 4
Correct prediction
Energy consumption = 149.621321 pJ
sum error= 347
Actual label: 2
Output voltages: [0.57712, 0.029007, 0.79876, 0.16003, 0.019433, 0.0012234, 0.034582, 0.15916, 0.54509, 0.0085728]
Predicted label: 2
Correct prediction
Energy consumption = 142.358050 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 921 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 921 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 921 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.2837, 0.155, 0.29651, 0.0021157, 0.16193, 0.01427, 0.79871, 0.0066902, 0.27328, 0.032741]
Predicted label: 6
Correct prediction
Energy consumption = 150.093409 pJ
sum error= 347
Actual label: 4
Output voltages: [0.010302, 0.023586, 0.03894, 0.07035, 0.7865, 0.0010678, 0.0013135, 0.007456, 0.32251, 0.67432]
Predicted label: 4
Correct prediction
Energy consumption = 150.610641 pJ
sum error= 347
Actual label: 7
Output voltages: [0.54509, 0.046474, 0.044308, 0.01333, 0.061666, 0.024559, 0.0010892, 0.79876, 0.23502, 0.23599]
Predicted label: 7
Correct prediction
Energy consumption = 142.951710 pJ
sum error= 347
Actual label: 8
Output voltages: [0.047976, 0.017596, 0.032317, 0.13148, 0.004205, 0.039885, 0.02581, 0.0036907, 0.79874, 0.081843]
Predicted label: 8
Correct prediction
Energy consumption = 148.576135 pJ
sum error= 347
Actual label: 9
Output voltages: [0.51842, 0.011456, 0.024075, 0.041752, 0.40561, 0.0019511, 0.0013264, 0.023219, 0.50949, 0.79737]
Predicted label: 9
Correct prediction
Energy consumption = 137.889175 pJ
sum error= 347
Actual label: 2
Output voltages: [0.21671, 0.04121, 0.7986, 0.039128, 0.0031536, 0.0010682, 0.042763, 0.096324, 0.48695, 0.0058638]
Predicted label: 2
Correct prediction
Energy consumption = 137.952772 pJ
sum error= 347
Actual label: 9
Output voltages: [0.021903, 0.007693, 0.024286, 0.035512, 0.20489, 0.0080906, 0.0013061, 0.031457, 0.75867, 0.79517]
Predicted label: 9
Correct prediction
Energy consumption = 145.832418 pJ
sum error= 347
Actual label: 3
Output voltages: [0.20402, 0.0020208, 0.22158, 0.79878, 0.0018502, 0.004497, 0.0235, 0.02911, 0.72897, 0.0017693]
Predicted label: 3
Correct prediction
Energy consumption = 140.891791 pJ
sum error= 347
Actual label: 9
Output voltages: [0.58568, 0.011025, 0.042235, 0.025428, 0.34563, 0.012081, 0.002305, 0.0095885, 0.44537, 0.79757]
Predicted label: 9
Correct prediction
Energy consumption = 143.279335 pJ
sum error= 347
Actual label: 3
Output voltages: [0.14126, 0.011548, 0.028253, 0.79865, 0.015496, 0.097266, 0.0021496, 0.0078968, 0.47, 0.024931]
Predicted label: 3
Correct prediction
Energy consumption = 139.688449 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 922 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 922 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 922 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79875, 0.0408, 0.064418, 0.0075645, 0.008161, 0.009734, 0.38024, 0.024529, 0.056775, 0.011069]
Predicted label: 0
Correct prediction
Energy consumption = 146.823228 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79586, 0.015559, 0.092661, 0.093038, 0.049739, 0.0010868, 0.026053, 0.0055703, 0.65916, 0.23404]
Predicted label: 0
Correct prediction
Energy consumption = 138.108835 pJ
sum error= 347
Actual label: 1
Output voltages: [0.0025958, 0.79867, 0.034546, 0.0017112, 0.015731, 0.0038111, 0.36224, 0.0065023, 0.64072, 0.024386]
Predicted label: 1
Correct prediction
Energy consumption = 139.047173 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79853, 0.079646, 0.19148, 0.013398, 0.0019647, 0.0013966, 0.48421, 0.019753, 0.060697, 0.31958]
Predicted label: 0
Correct prediction
Energy consumption = 137.499970 pJ
sum error= 347
Actual label: 4
Output voltages: [0.024468, 0.036026, 0.1069, 0.026157, 0.7986, 0.0019241, 0.03894, 0.044775, 0.030609, 0.023518]
Predicted label: 4
Correct prediction
Energy consumption = 149.611000 pJ
sum error= 347
Actual label: 2
Output voltages: [0.035151, 0.51871, 0.79878, 0.045529, 0.0011081, 0.0010928, 0.018766, 0.25299, 0.69701, 0.023192]
Predicted label: 2
Correct prediction
Energy consumption = 142.810891 pJ
sum error= 347
Actual label: 6
Output voltages: [0.064721, 0.024711, 0.20755, 0.0010912, 0.35535, 0.025697, 0.79879, 0.0013047, 0.62661, 0.0033255]
Predicted label: 6
Correct prediction
Energy consumption = 138.956071 pJ
sum error= 347
Actual label: 3
Output voltages: [0.18468, 0.019825, 0.35617, 0.79878, 0.0028192, 0.0075997, 0.0054946, 0.0030791, 0.76056, 0.0063882]
Predicted label: 3
Correct prediction
Energy consumption = 138.222306 pJ
sum error= 347
Actual label: 5
Output voltages: [0.12808, 0.001066, 0.0010672, 0.41032, 0.036919, 0.79879, 0.27865, 0.017439, 0.55147, 0.039595]
Predicted label: 5
Correct prediction
Energy consumption = 138.603471 pJ
sum error= 347
Actual label: 3
Output voltages: [0.082064, 0.034788, 0.053925, 0.7987, 0.0097684, 0.024648, 0.0013723, 0.0044231, 0.64927, 0.033293]
Predicted label: 3
Correct prediction
Energy consumption = 138.027927 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 923 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 923 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 923 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79869, 0.069868, 0.030023, 0.013096, 0.016776, 0.017369, 0.47752, 0.01988, 0.17508, 0.044553]
Predicted label: 0
Correct prediction
Energy consumption = 148.741771 pJ
sum error= 347
Actual label: 3
Output voltages: [0.20457, 0.011044, 0.039196, 0.79877, 0.045806, 0.0072862, 0.011447, 0.020755, 0.551, 0.038581]
Predicted label: 3
Correct prediction
Energy consumption = 146.206397 pJ
sum error= 347
Actual label: 4
Output voltages: [0.025267, 0.0020877, 0.13517, 0.0041303, 0.79859, 0.018077, 0.15045, 0.32727, 0.053146, 0.0043284]
Predicted label: 4
Correct prediction
Energy consumption = 138.516639 pJ
sum error= 347
Actual label: 1
Output voltages: [0.013316, 0.79869, 0.70993, 0.03471, 0.31035, 0.0011029, 0.42088, 0.0082747, 0.022847, 0.011625]
Predicted label: 1
Correct prediction
Energy consumption = 145.289001 pJ
sum error= 347
Actual label: 5
Output voltages: [0.017053, 0.0010695, 0.0010841, 0.35182, 0.21783, 0.79877, 0.48314, 0.044802, 0.54679, 0.022248]
Predicted label: 5
Correct prediction
Energy consumption = 143.302003 pJ
sum error= 347
Actual label: 3
Output voltages: [0.36791, 0.024181, 0.058556, 0.79866, 0.01186, 0.031786, 0.0051055, 0.0057308, 0.73162, 0.015952]
Predicted label: 3
Correct prediction
Energy consumption = 138.312128 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79861, 0.054778, 0.12676, 0.027809, 0.033972, 0.0067985, 0.22274, 0.011522, 0.7366, 0.072775]
Predicted label: 0
Correct prediction
Energy consumption = 146.453620 pJ
sum error= 347
Actual label: 8
Output voltages: [0.025294, 0.0033402, 0.17582, 0.024149, 0.028869, 0.015034, 0.0076751, 0.0067375, 0.79879, 0.061778]
Predicted label: 8
Correct prediction
Energy consumption = 141.118398 pJ
sum error= 347
Actual label: 3
Output voltages: [0.16334, 0.0028693, 0.446, 0.79879, 0.014955, 0.0017287, 0.012171, 0.0011198, 0.68907, 0.024685]
Predicted label: 3
Correct prediction
Energy consumption = 133.671323 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79869, 0.16832, 0.018648, 0.018867, 0.026031, 0.025447, 0.46981, 0.010658, 0.14344, 0.040095]
Predicted label: 0
Correct prediction
Energy consumption = 143.006076 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 924 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 924 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 924 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.067171, 0.0352, 0.25263, 0.0011736, 0.27456, 0.10494, 0.79876, 0.0038032, 0.51728, 0.01354]
Predicted label: 6
Correct prediction
Energy consumption = 148.425136 pJ
sum error= 347
Actual label: 1
Output voltages: [0.12219, 0.7977, 0.39851, 0.010409, 0.68492, 0.0010944, 0.039511, 0.018939, 0.035021, 0.027651]
Predicted label: 1
Correct prediction
Energy consumption = 148.653709 pJ
sum error= 347
Actual label: 7
Output voltages: [0.44893, 0.011708, 0.030129, 0.022867, 0.1524, 0.021051, 0.0010683, 0.79865, 0.042688, 0.091059]
Predicted label: 7
Correct prediction
Energy consumption = 150.174986 pJ
sum error= 347
Actual label: 8
Output voltages: [0.35813, 0.02695, 0.4038, 0.0068142, 0.048553, 0.0011491, 0.00715, 0.014792, 0.79869, 0.42172]
Predicted label: 8
Correct prediction
Energy consumption = 149.376604 pJ
sum error= 347
Actual label: 0
Output voltages: [0.79867, 0.12437, 0.028296, 0.011073, 0.011613, 0.010233, 0.49525, 0.066463, 0.20561, 0.030423]
Predicted label: 0
Correct prediction
Energy consumption = 137.745391 pJ
sum error= 347
Actual label: 9
Output voltages: [0.76846, 0.0017757, 0.019415, 0.04187, 0.62641, 0.015726, 0.0025836, 0.0078473, 0.16622, 0.7827]
Predicted label: 9
Correct prediction
Energy consumption = 140.534160 pJ
sum error= 347
Actual label: 2
Output voltages: [0.23475, 0.044984, 0.79871, 0.10898, 0.0074492, 0.0012657, 0.20976, 0.1624, 0.57568, 0.038961]
Predicted label: 2
Correct prediction
Energy consumption = 146.387971 pJ
sum error= 347
Actual label: 6
Output voltages: [0.066628, 0.029284, 0.27445, 0.0012179, 0.4244, 0.048652, 0.79875, 0.0025134, 0.44891, 0.0061634]
Predicted label: 6
Correct prediction
Energy consumption = 142.088597 pJ
sum error= 347
Actual label: 7
Output voltages: [0.2232, 0.33035, 0.0038949, 0.21392, 0.14238, 0.0010735, 0.0039564, 0.79877, 0.11124, 0.14498]
Predicted label: 7
Correct prediction
Energy consumption = 153.329892 pJ
sum error= 347
Actual label: 1
Output voltages: [0.0030148, 0.79871, 0.0060285, 0.0020523, 0.15142, 0.015302, 0.30545, 0.0019833, 0.49687, 0.046151]
Predicted label: 1
Correct prediction
Energy consumption = 150.243150 pJ
sum error= 347
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 925 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 925 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 925 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.51519, 0.021573, 0.018145, 0.12502, 0.20285, 0.0070766, 0.0071665, 0.032049, 0.50826, 0.79815]
Predicted label: 9
Correct prediction
Energy consumption = 142.409421 pJ
sum error= 347
Actual label: 6
Output voltages: [0.053624, 0.035767, 0.15242, 0.0019263, 0.1416, 0.18149, 0.79876, 0.0075429, 0.60405, 0.0097361]
Predicted label: 6
Correct prediction
Energy consumption = 146.000028 pJ
sum error= 347
Actual label: 9
Output voltages: [0.70381, 0.0026484, 0.027599, 0.31974, 0.75694, 0.011081, 0.0012872, 0.011907, 0.12312, 0.79461]
Predicted label: 9
Correct prediction
Energy consumption = 146.893814 pJ
sum error= 347
Actual label: 4
Output voltages: [0.031045, 0.0041762, 0.042344, 0.11063, 0.76633, 0.24404, 0.24024, 0.0055853, 0.7802, 0.023691]
Predicted label: 8
Wrong prediction!
Energy consumption = 142.072900 pJ
sum error= 348
Actual label: 9
Output voltages: [0.065173, 0.0020456, 0.0063531, 0.027975, 0.27007, 0.0071868, 0.0010926, 0.01846, 0.73201, 0.79777]
Predicted label: 9
Correct prediction
Energy consumption = 145.862493 pJ
sum error= 348
Actual label: 9
Output voltages: [0.31429, 0.014435, 0.013303, 0.097614, 0.28267, 0.014323, 0.0022838, 0.01815, 0.51768, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 131.753259 pJ
sum error= 348
Actual label: 6
Output voltages: [0.043263, 0.033054, 0.40256, 0.00107, 0.3026, 0.034101, 0.79879, 0.0017835, 0.54814, 0.0019432]
Predicted label: 6
Correct prediction
Energy consumption = 146.841577 pJ
sum error= 348
Actual label: 7
Output voltages: [0.043996, 0.31858, 0.25383, 0.031982, 0.025664, 0.0011396, 0.0010921, 0.79867, 0.063329, 0.23948]
Predicted label: 7
Correct prediction
Energy consumption = 145.496406 pJ
sum error= 348
Actual label: 1
Output voltages: [0.010116, 0.79877, 0.33172, 0.0094515, 0.030956, 0.0012031, 0.59687, 0.0010754, 0.24602, 0.037785]
Predicted label: 1
Correct prediction
Energy consumption = 143.505918 pJ
sum error= 348
Actual label: 2
Output voltages: [0.12516, 0.010429, 0.78111, 0.5208, 0.0011817, 0.0010758, 0.039242, 0.01132, 0.68848, 0.0014937]
Predicted label: 2
Correct prediction
Energy consumption = 140.112284 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 926 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 926 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 926 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.1017, 0.0011088, 0.001066, 0.33565, 0.019035, 0.79877, 0.18922, 0.016589, 0.74181, 0.0053636]
Predicted label: 5
Correct prediction
Energy consumption = 141.681077 pJ
sum error= 348
Actual label: 3
Output voltages: [0.24848, 0.0082156, 0.18666, 0.79877, 0.011525, 0.0082555, 0.004254, 0.10792, 0.61947, 0.055107]
Predicted label: 3
Correct prediction
Energy consumption = 142.107353 pJ
sum error= 348
Actual label: 7
Output voltages: [0.04835, 0.084682, 0.035128, 0.27178, 0.029634, 0.01338, 0.0011647, 0.79876, 0.11936, 0.39949]
Predicted label: 7
Correct prediction
Energy consumption = 142.927528 pJ
sum error= 348
Actual label: 8
Output voltages: [0.0017333, 0.084605, 0.19421, 0.086695, 0.0050366, 0.0030058, 0.035205, 0.017978, 0.79876, 0.057953]
Predicted label: 8
Correct prediction
Energy consumption = 141.924142 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79874, 0.13855, 0.019071, 0.020823, 0.0061556, 0.02626, 0.56741, 0.02537, 0.047204, 0.020057]
Predicted label: 0
Correct prediction
Energy consumption = 145.199352 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0064717, 0.79849, 0.58765, 0.52921, 0.031502, 0.0077165, 0.48192, 0.024899, 0.01639, 0.37696]
Predicted label: 1
Correct prediction
Energy consumption = 168.123448 pJ
sum error= 348
Actual label: 2
Output voltages: [0.49685, 0.0095104, 0.79875, 0.041364, 0.0067489, 0.0010956, 0.026253, 0.055897, 0.56118, 0.0075489]
Predicted label: 2
Correct prediction
Energy consumption = 147.191502 pJ
sum error= 348
Actual label: 4
Output voltages: [0.0067887, 0.033864, 0.052487, 0.00268, 0.79877, 0.057283, 0.023836, 0.27981, 0.087323, 0.15857]
Predicted label: 4
Correct prediction
Energy consumption = 159.390181 pJ
sum error= 348
Actual label: 5
Output voltages: [0.017228, 0.0016806, 0.012102, 0.15658, 0.014755, 0.77375, 0.040959, 0.0027168, 0.76502, 0.28112]
Predicted label: 5
Correct prediction
Energy consumption = 144.062205 pJ
sum error= 348
Actual label: 6
Output voltages: [0.19755, 0.023503, 0.33341, 0.0025432, 0.19726, 0.3078, 0.79878, 0.0026433, 0.35571, 0.0047573]
Predicted label: 6
Correct prediction
Energy consumption = 146.840366 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 927 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 927 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 927 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.035944, 0.29371, 0.25038, 0.051232, 0.0031297, 0.0010664, 0.001386, 0.79861, 0.21053, 0.22364]
Predicted label: 7
Correct prediction
Energy consumption = 156.354087 pJ
sum error= 348
Actual label: 8
Output voltages: [0.0086378, 0.017936, 0.047757, 0.090901, 0.012592, 0.020249, 0.051925, 0.0034603, 0.79876, 0.1802]
Predicted label: 8
Correct prediction
Energy consumption = 148.172566 pJ
sum error= 348
Actual label: 9
Output voltages: [0.4015, 0.033082, 0.016054, 0.057286, 0.089643, 0.014428, 0.0023977, 0.025058, 0.31778, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 151.477056 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79877, 0.069834, 0.055267, 0.0198, 0.0058657, 0.006459, 0.4071, 0.012887, 0.059666, 0.030441]
Predicted label: 0
Correct prediction
Energy consumption = 148.884853 pJ
sum error= 348
Actual label: 1
Output voltages: [0.023239, 0.79834, 0.03971, 0.049346, 0.0079558, 0.0042594, 0.73231, 0.012913, 0.2165, 0.10864]
Predicted label: 1
Correct prediction
Energy consumption = 158.741815 pJ
sum error= 348
Actual label: 3
Output voltages: [0.35363, 0.014745, 0.057349, 0.79869, 0.021558, 0.0083864, 0.033163, 0.010761, 0.41942, 0.04693]
Predicted label: 3
Correct prediction
Energy consumption = 151.700780 pJ
sum error= 348
Actual label: 4
Output voltages: [0.011348, 0.021519, 0.20156, 0.010489, 0.79858, 0.011105, 0.14178, 0.035753, 0.035113, 0.032799]
Predicted label: 4
Correct prediction
Energy consumption = 153.569801 pJ
sum error= 348
Actual label: 5
Output voltages: [0.017879, 0.002934, 0.0041696, 0.3765, 0.049864, 0.79684, 0.14579, 0.0039405, 0.63752, 0.10935]
Predicted label: 5
Correct prediction
Energy consumption = 147.516211 pJ
sum error= 348
Actual label: 6
Output voltages: [0.055608, 0.18142, 0.32071, 0.003893, 0.22434, 0.22218, 0.79866, 0.0025686, 0.35794, 0.013723]
Predicted label: 6
Correct prediction
Energy consumption = 142.947274 pJ
sum error= 348
Actual label: 7
Output voltages: [0.21634, 0.024279, 0.02704, 0.03115, 0.0173, 0.0024278, 0.0010883, 0.79859, 0.31052, 0.23441]
Predicted label: 7
Correct prediction
Energy consumption = 160.783568 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 928 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 928 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 928 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.049837, 0.0014276, 0.19378, 0.027409, 0.0015227, 0.78206, 0.17968, 0.0016629, 0.79811, 0.013277]
Predicted label: 8
Correct prediction
Energy consumption = 150.739463 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79872, 0.12291, 0.031853, 0.018577, 0.024502, 0.023275, 0.48684, 0.044855, 0.22874, 0.042545]
Predicted label: 0
Correct prediction
Energy consumption = 143.459596 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0034725, 0.79846, 0.043939, 0.055154, 0.025673, 0.0046144, 0.65286, 0.0038273, 0.50078, 0.041431]
Predicted label: 1
Correct prediction
Energy consumption = 165.204593 pJ
sum error= 348
Actual label: 3
Output voltages: [0.045493, 0.026385, 0.050512, 0.79862, 0.021576, 0.001705, 0.020652, 0.013253, 0.43623, 0.182]
Predicted label: 3
Correct prediction
Energy consumption = 150.122745 pJ
sum error= 348
Actual label: 4
Output voltages: [0.0040212, 0.036552, 0.31308, 0.020896, 0.79863, 0.017253, 0.25435, 0.36734, 0.022054, 0.075042]
Predicted label: 4
Correct prediction
Energy consumption = 158.603331 pJ
sum error= 348
Actual label: 7
Output voltages: [0.12625, 0.0033628, 0.044854, 0.76409, 0.0012182, 0.030187, 0.0012246, 0.79875, 0.52721, 0.41449]
Predicted label: 7
Correct prediction
Energy consumption = 148.390196 pJ
sum error= 348
Actual label: 8
Output voltages: [0.024652, 0.0029644, 0.027693, 0.070826, 0.0084457, 0.56241, 0.049512, 0.0038797, 0.79877, 0.054268]
Predicted label: 8
Correct prediction
Energy consumption = 143.770772 pJ
sum error= 348
Actual label: 9
Output voltages: [0.028654, 0.020778, 0.046789, 0.19694, 0.037987, 0.018673, 0.017186, 0.16467, 0.6426, 0.79839]
Predicted label: 9
Correct prediction
Energy consumption = 148.593504 pJ
sum error= 348
Actual label: 7
Output voltages: [0.16322, 0.015048, 0.31408, 0.37752, 0.0079333, 0.0025478, 0.0010976, 0.79863, 0.43058, 0.26087]
Predicted label: 7
Correct prediction
Energy consumption = 148.650142 pJ
sum error= 348
Actual label: 5
Output voltages: [0.034897, 0.0044017, 0.02708, 0.40288, 0.019015, 0.79601, 0.016636, 0.0034442, 0.78107, 0.22939]
Predicted label: 5
Correct prediction
Energy consumption = 143.709522 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 929 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 929 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 929 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.098556, 0.020766, 0.0021178, 0.12907, 0.24983, 0.79877, 0.37818, 0.0052413, 0.17047, 0.14105]
Predicted label: 5
Correct prediction
Energy consumption = 144.878820 pJ
sum error= 348
Actual label: 1
Output voltages: [0.24832, 0.79879, 0.59047, 0.17489, 0.21677, 0.0011999, 0.02212, 0.0083538, 0.027497, 0.035381]
Predicted label: 1
Correct prediction
Energy consumption = 172.842106 pJ
sum error= 348
Actual label: 9
Output voltages: [0.50903, 0.021639, 0.019942, 0.027914, 0.058221, 0.015187, 0.0018683, 0.024799, 0.40551, 0.7986]
Predicted label: 9
Correct prediction
Energy consumption = 157.640897 pJ
sum error= 348
Actual label: 9
Output voltages: [0.029488, 0.0060791, 0.013079, 0.31808, 0.051618, 0.0023364, 0.0033322, 0.24281, 0.66649, 0.78568]
Predicted label: 9
Correct prediction
Energy consumption = 147.489007 pJ
sum error= 348
Actual label: 7
Output voltages: [0.17753, 0.030467, 0.034812, 0.037596, 0.0357, 0.010262, 0.0010806, 0.7985, 0.32927, 0.282]
Predicted label: 7
Correct prediction
Energy consumption = 148.912686 pJ
sum error= 348
Actual label: 1
Output voltages: [0.11247, 0.79867, 0.3297, 0.034016, 0.41145, 0.001207, 0.69565, 0.0069337, 0.013416, 0.032109]
Predicted label: 1
Correct prediction
Energy consumption = 162.911766 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79815, 0.046488, 0.049626, 0.0035102, 0.0051063, 0.0038848, 0.70971, 0.15258, 0.016543, 0.14829]
Predicted label: 0
Correct prediction
Energy consumption = 136.321079 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79815, 0.15537, 0.31334, 0.022422, 0.0012416, 0.0011727, 0.43067, 0.055133, 0.26405, 0.13117]
Predicted label: 0
Correct prediction
Energy consumption = 134.131699 pJ
sum error= 348
Actual label: 5
Output voltages: [0.017899, 0.0010795, 0.0011226, 0.31479, 0.03169, 0.79871, 0.10118, 0.10583, 0.71098, 0.050548]
Predicted label: 5
Correct prediction
Energy consumption = 152.876515 pJ
sum error= 348
Actual label: 9
Output voltages: [0.19285, 0.024183, 0.026988, 0.035079, 0.061864, 0.024078, 0.0026789, 0.067893, 0.4169, 0.79855]
Predicted label: 9
Correct prediction
Energy consumption = 144.528218 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 930 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 930 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 930 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.32758, 0.014993, 0.014492, 0.25169, 0.025, 0.031072, 0.001084, 0.79862, 0.069833, 0.41751]
Predicted label: 7
Correct prediction
Energy consumption = 151.182558 pJ
sum error= 348
Actual label: 1
Output voltages: [0.018613, 0.79838, 0.10071, 0.043253, 0.022593, 0.0089457, 0.44124, 0.0062175, 0.34907, 0.040426]
Predicted label: 1
Correct prediction
Energy consumption = 166.857791 pJ
sum error= 348
Actual label: 7
Output voltages: [0.38857, 0.047648, 0.084122, 0.11245, 0.01744, 0.0017566, 0.0010694, 0.79871, 0.14388, 0.38174]
Predicted label: 7
Correct prediction
Energy consumption = 154.847708 pJ
sum error= 348
Actual label: 2
Output voltages: [0.58633, 0.013656, 0.79493, 0.75704, 0.0016495, 0.0011196, 0.037842, 0.036423, 0.73293, 0.064487]
Predicted label: 2
Correct prediction
Energy consumption = 149.606597 pJ
sum error= 348
Actual label: 2
Output voltages: [0.65959, 0.016747, 0.79821, 0.42145, 0.0075621, 0.0011014, 0.12235, 0.038894, 0.70522, 0.034086]
Predicted label: 2
Correct prediction
Energy consumption = 140.452395 pJ
sum error= 348
Actual label: 3
Output voltages: [0.49325, 0.08004, 0.063499, 0.79865, 0.010065, 0.0018381, 0.028462, 0.010511, 0.33077, 0.03347]
Predicted label: 3
Correct prediction
Energy consumption = 142.646743 pJ
sum error= 348
Actual label: 6
Output voltages: [0.23794, 0.032664, 0.31932, 0.0024627, 0.27465, 0.21063, 0.7987, 0.0044466, 0.45619, 0.033143]
Predicted label: 6
Correct prediction
Energy consumption = 137.597356 pJ
sum error= 348
Actual label: 8
Output voltages: [0.029054, 0.017132, 0.057986, 0.2303, 0.004722, 0.016612, 0.039654, 0.012206, 0.79874, 0.30595]
Predicted label: 8
Correct prediction
Energy consumption = 152.552531 pJ
sum error= 348
Actual label: 3
Output voltages: [0.74246, 0.023921, 0.047895, 0.79866, 0.0096623, 0.14768, 0.013549, 0.017118, 0.38775, 0.12653]
Predicted label: 3
Correct prediction
Energy consumption = 152.660905 pJ
sum error= 348
Actual label: 2
Output voltages: [0.26891, 0.010058, 0.79831, 0.48837, 0.0076022, 0.0011893, 0.031409, 0.22792, 0.40335, 0.029318]
Predicted label: 2
Correct prediction
Energy consumption = 144.844365 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 931 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 931 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 931 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79877, 0.097452, 0.16086, 0.0091086, 0.0018516, 0.003501, 0.34225, 0.02307, 0.30159, 0.059706]
Predicted label: 0
Correct prediction
Energy consumption = 147.725397 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79335, 0.028989, 0.32859, 0.018454, 0.017022, 0.0011537, 0.717, 0.01053, 0.32865, 0.035328]
Predicted label: 0
Correct prediction
Energy consumption = 139.104329 pJ
sum error= 348
Actual label: 6
Output voltages: [0.064942, 0.036508, 0.056368, 0.009655, 0.24547, 0.28388, 0.79869, 0.0016442, 0.52121, 0.01871]
Predicted label: 6
Correct prediction
Energy consumption = 137.261554 pJ
sum error= 348
Actual label: 1
Output voltages: [0.053917, 0.79864, 0.19824, 0.022011, 0.022276, 0.001066, 0.75369, 0.0011771, 0.2216, 0.04797]
Predicted label: 1
Correct prediction
Energy consumption = 161.142583 pJ
sum error= 348
Actual label: 7
Output voltages: [0.11901, 0.1813, 0.14643, 0.43415, 0.0038144, 0.0030817, 0.001068, 0.79865, 0.42953, 0.59796]
Predicted label: 7
Correct prediction
Energy consumption = 159.877337 pJ
sum error= 348
Actual label: 5
Output voltages: [0.025897, 0.011008, 0.0021633, 0.080425, 0.033435, 0.79868, 0.018342, 0.0010822, 0.7545, 0.097909]
Predicted label: 5
Correct prediction
Energy consumption = 149.016624 pJ
sum error= 348
Actual label: 8
Output voltages: [0.052906, 0.019585, 0.074902, 0.37694, 0.0017891, 0.14983, 0.0093676, 0.0084321, 0.79878, 0.26876]
Predicted label: 8
Correct prediction
Energy consumption = 139.693083 pJ
sum error= 348
Actual label: 6
Output voltages: [0.10852, 0.04668, 0.16446, 0.022646, 0.12489, 0.25227, 0.79877, 0.0032146, 0.43869, 0.16576]
Predicted label: 6
Correct prediction
Energy consumption = 143.807715 pJ
sum error= 348
Actual label: 2
Output voltages: [0.73445, 0.009874, 0.79872, 0.65474, 0.012274, 0.0011142, 0.021171, 0.27171, 0.63621, 0.052167]
Predicted label: 2
Correct prediction
Energy consumption = 154.115059 pJ
sum error= 348
Actual label: 9
Output voltages: [0.43142, 0.0082445, 0.016383, 0.018213, 0.19223, 0.011029, 0.001773, 0.10584, 0.42619, 0.79782]
Predicted label: 9
Correct prediction
Energy consumption = 155.215502 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 932 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 932 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 932 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.050794, 0.0079204, 0.039668, 0.014521, 0.79869, 0.0010732, 0.032291, 0.044651, 0.2147, 0.20515]
Predicted label: 4
Correct prediction
Energy consumption = 160.302189 pJ
sum error= 348
Actual label: 8
Output voltages: [0.039107, 0.044522, 0.047772, 0.40117, 0.0013272, 0.031047, 0.0066121, 0.0030906, 0.79871, 0.22624]
Predicted label: 8
Correct prediction
Energy consumption = 151.654058 pJ
sum error= 348
Actual label: 8
Output voltages: [0.022901, 0.038526, 0.39784, 0.039424, 0.031446, 0.021239, 0.027622, 0.0066882, 0.79876, 0.11706]
Predicted label: 8
Correct prediction
Energy consumption = 143.695024 pJ
sum error= 348
Actual label: 7
Output voltages: [0.31738, 0.022802, 0.006194, 0.16029, 0.035659, 0.014303, 0.0010662, 0.79867, 0.19468, 0.61574]
Predicted label: 7
Correct prediction
Energy consumption = 157.610293 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0018, 0.79854, 0.022011, 0.009736, 0.029296, 0.010518, 0.65027, 0.0056234, 0.50293, 0.023751]
Predicted label: 1
Correct prediction
Energy consumption = 163.390917 pJ
sum error= 348
Actual label: 0
Output voltages: [0.79673, 0.060631, 0.26705, 0.0040355, 0.0014694, 0.001066, 0.43813, 0.014297, 0.16302, 0.1109]
Predicted label: 0
Correct prediction
Energy consumption = 151.394196 pJ
sum error= 348
Actual label: 8
Output voltages: [0.018232, 0.015034, 0.11032, 0.40053, 0.0012208, 0.27613, 0.017621, 0.004472, 0.79874, 0.06274]
Predicted label: 8
Correct prediction
Energy consumption = 148.051090 pJ
sum error= 348
Actual label: 7
Output voltages: [0.15435, 0.024883, 0.0060765, 0.12242, 0.025137, 0.01547, 0.0012791, 0.79878, 0.28981, 0.76005]
Predicted label: 7
Correct prediction
Energy consumption = 155.494883 pJ
sum error= 348
Actual label: 7
Output voltages: [0.061006, 0.006241, 0.021293, 0.28661, 0.0065005, 0.017718, 0.0011668, 0.79866, 0.43184, 0.39978]
Predicted label: 7
Correct prediction
Energy consumption = 139.465763 pJ
sum error= 348
Actual label: 5
Output voltages: [0.14261, 0.0014992, 0.0016716, 0.27367, 0.033053, 0.79879, 0.033371, 0.014666, 0.78561, 0.040147]
Predicted label: 5
Correct prediction
Energy consumption = 143.052589 pJ
sum error= 348
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 933 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 933 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 933 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.011561, 0.021873, 0.061354, 0.32915, 0.0054426, 0.21518, 0.061141, 0.010852, 0.79877, 0.04089]
Predicted label: 8
Correct prediction
Energy consumption = 153.533203 pJ
sum error= 348
Actual label: 5
Output voltages: [0.010666, 0.0010671, 0.0010763, 0.46716, 0.13276, 0.79586, 0.17, 0.021863, 0.53745, 0.42371]
Predicted label: 5
Correct prediction
Energy consumption = 145.865718 pJ
sum error= 348
Actual label: 3
Output voltages: [0.57122, 0.016161, 0.13264, 0.7986, 0.021763, 0.010714, 0.017998, 0.015504, 0.48609, 0.036863]
Predicted label: 3
Correct prediction
Energy consumption = 148.269089 pJ
sum error= 348
Actual label: 4
Output voltages: [0.0040617, 0.013082, 0.22444, 0.0036636, 0.79872, 0.001067, 0.031403, 0.036363, 0.035712, 0.34034]
Predicted label: 4
Correct prediction
Energy consumption = 161.443693 pJ
sum error= 348
Actual label: 6
Output voltages: [0.05084, 0.017253, 0.14236, 0.00268, 0.44082, 0.19763, 0.79879, 0.0030518, 0.49575, 0.0016199]
Predicted label: 6
Correct prediction
Energy consumption = 147.382528 pJ
sum error= 348
Actual label: 1
Output voltages: [0.0079745, 0.79865, 0.33611, 0.77339, 0.0090322, 0.0015057, 0.025177, 0.047904, 0.010249, 0.3802]
Predicted label: 1
Correct prediction
Energy consumption = 161.057889 pJ
sum error= 348
Actual label: 1
Output voltages: [0.060726, 0.79834, 0.052362, 0.21286, 0.0048196, 0.0027762, 0.73724, 0.0033295, 0.038732, 0.30029]
Predicted label: 1
Correct prediction
Energy consumption = 152.895237 pJ
sum error= 348
Actual label: 5
Output voltages: [0.0027106, 0.0076488, 0.0052591, 0.39702, 0.040339, 0.79749, 0.046213, 0.03115, 0.71127, 0.23192]
Predicted label: 5
Correct prediction
Energy consumption = 155.512584 pJ
sum error= 348
Actual label: 5
Output voltages: [0.032115, 0.00833, 0.023201, 0.57779, 0.0018251, 0.77001, 0.0015828, 0.007286, 0.79618, 0.046494]
Predicted label: 8
Wrong prediction!
Energy consumption = 135.899008 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79878, 0.14516, 0.34091, 0.040758, 0.0010715, 0.0285, 0.20829, 0.023311, 0.37569, 0.013672]
Predicted label: 0
Correct prediction
Energy consumption = 148.313187 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 934 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 934 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 934 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.25918, 0.32225, 0.049199, 0.28412, 0.0013365, 0.0011418, 0.0010712, 0.79871, 0.22734, 0.48247]
Predicted label: 7
Correct prediction
Energy consumption = 163.070983 pJ
sum error= 349
Actual label: 2
Output voltages: [0.36014, 0.0026547, 0.79782, 0.48297, 0.007023, 0.0011415, 0.026652, 0.041464, 0.60955, 0.044933]
Predicted label: 2
Correct prediction
Energy consumption = 149.789169 pJ
sum error= 349
Actual label: 3
Output voltages: [0.7591, 0.13592, 0.36988, 0.79879, 0.0011126, 0.26528, 0.003463, 0.025519, 0.021656, 0.028898]
Predicted label: 3
Correct prediction
Energy consumption = 141.915154 pJ
sum error= 349
Actual label: 6
Output voltages: [0.23701, 0.09649, 0.22529, 0.0094005, 0.22761, 0.38916, 0.79875, 0.0017544, 0.37925, 0.027715]
Predicted label: 6
Correct prediction
Energy consumption = 149.699390 pJ
sum error= 349
Actual label: 4
Output voltages: [0.0041968, 0.011959, 0.33513, 0.019425, 0.79868, 0.0042203, 0.1457, 0.017107, 0.018177, 0.20909]
Predicted label: 4
Correct prediction
Energy consumption = 156.733158 pJ
sum error= 349
Actual label: 1
Output voltages: [0.0090846, 0.79856, 0.17808, 0.051874, 0.28813, 0.0021376, 0.51036, 0.0209, 0.34577, 0.057706]
Predicted label: 1
Correct prediction
Energy consumption = 166.503884 pJ
sum error= 349
Actual label: 2
Output voltages: [0.61474, 0.013732, 0.79878, 0.47412, 0.025447, 0.0011007, 0.056486, 0.092416, 0.75771, 0.03792]
Predicted label: 2
Correct prediction
Energy consumption = 149.178689 pJ
sum error= 349
Actual label: 4
Output voltages: [0.0070703, 0.0044868, 0.20151, 0.012867, 0.79861, 0.001677, 0.083426, 0.03073, 0.028759, 0.040156]
Predicted label: 4
Correct prediction
Energy consumption = 155.360069 pJ
sum error= 349
Actual label: 1
Output voltages: [0.17166, 0.79868, 0.27981, 0.14814, 0.051188, 0.001141, 0.39458, 0.0039762, 0.17027, 0.02776]
Predicted label: 1
Correct prediction
Energy consumption = 165.495773 pJ
sum error= 349
Actual label: 5
Output voltages: [0.041059, 0.0017327, 0.01178, 0.2187, 0.017871, 0.79876, 0.42113, 0.03232, 0.74156, 0.017628]
Predicted label: 5
Correct prediction
Energy consumption = 156.115826 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 935 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 935 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 935 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.012734, 0.0059834, 0.35938, 0.0096838, 0.79874, 0.0010844, 0.038909, 0.22526, 0.027376, 0.22797]
Predicted label: 4
Correct prediction
Energy consumption = 154.006063 pJ
sum error= 349
Actual label: 2
Output voltages: [0.37602, 0.011391, 0.7957, 0.46618, 0.011702, 0.0012251, 0.11325, 0.082529, 0.6023, 0.09163]
Predicted label: 2
Correct prediction
Energy consumption = 155.046883 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79874, 0.17223, 0.094939, 0.0098837, 0.010445, 0.015977, 0.45535, 0.019361, 0.034414, 0.057648]
Predicted label: 0
Correct prediction
Energy consumption = 146.900982 pJ
sum error= 349
Actual label: 4
Output voltages: [0.025114, 0.005749, 0.26834, 0.026731, 0.79875, 0.0011762, 0.0498, 0.23249, 0.048679, 0.15089]
Predicted label: 4
Correct prediction
Energy consumption = 161.323180 pJ
sum error= 349
Actual label: 8
Output voltages: [0.014486, 0.014918, 0.30611, 0.042999, 0.019194, 0.015199, 0.040538, 0.012891, 0.7987, 0.059185]
Predicted label: 8
Correct prediction
Energy consumption = 151.836165 pJ
sum error= 349
Actual label: 6
Output voltages: [0.062535, 0.083329, 0.32908, 0.011034, 0.34444, 0.23452, 0.79865, 0.010477, 0.35504, 0.017007]
Predicted label: 6
Correct prediction
Energy consumption = 146.775125 pJ
sum error= 349
Actual label: 1
Output voltages: [0.012865, 0.79836, 0.059574, 0.019894, 0.0063549, 0.010176, 0.6113, 0.022838, 0.47087, 0.019926]
Predicted label: 1
Correct prediction
Energy consumption = 163.719805 pJ
sum error= 349
Actual label: 9
Output voltages: [0.042717, 0.0064703, 0.015028, 0.020034, 0.31004, 0.0064451, 0.0025327, 0.010544, 0.50919, 0.79838]
Predicted label: 9
Correct prediction
Energy consumption = 152.459773 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79879, 0.14744, 0.039649, 0.015314, 0.0046794, 0.0082391, 0.53943, 0.017212, 0.11575, 0.064225]
Predicted label: 0
Correct prediction
Energy consumption = 149.992839 pJ
sum error= 349
Actual label: 2
Output voltages: [0.73084, 0.0052451, 0.79859, 0.29099, 0.0058608, 0.0010691, 0.034459, 0.22923, 0.73634, 0.0032489]
Predicted label: 2
Correct prediction
Energy consumption = 145.359886 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 936 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 936 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 936 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.035757, 0.0012337, 0.0022428, 0.44568, 0.011357, 0.79879, 0.14029, 0.028905, 0.64297, 0.06094]
Predicted label: 5
Correct prediction
Energy consumption = 148.581893 pJ
sum error= 349
Actual label: 6
Output voltages: [0.047632, 0.094743, 0.29269, 0.0045797, 0.15961, 0.3748, 0.79868, 0.0050509, 0.44222, 0.017241]
Predicted label: 6
Correct prediction
Energy consumption = 144.362026 pJ
sum error= 349
Actual label: 9
Output voltages: [0.34004, 0.018184, 0.034598, 0.031753, 0.065485, 0.024414, 0.0040532, 0.092279, 0.47657, 0.79775]
Predicted label: 9
Correct prediction
Energy consumption = 153.642438 pJ
sum error= 349
Actual label: 3
Output voltages: [0.28579, 0.025086, 0.052756, 0.79869, 0.027793, 0.012563, 0.019502, 0.0081371, 0.48924, 0.17269]
Predicted label: 3
Correct prediction
Energy consumption = 150.961168 pJ
sum error= 349
Actual label: 6
Output voltages: [0.18147, 0.032513, 0.27755, 0.0013867, 0.45473, 0.011225, 0.79878, 0.0010751, 0.20723, 0.021522]
Predicted label: 6
Correct prediction
Energy consumption = 145.054531 pJ
sum error= 349
Actual label: 3
Output voltages: [0.31013, 0.021625, 0.034199, 0.79871, 0.014679, 0.028402, 0.0068301, 0.017637, 0.53555, 0.043841]
Predicted label: 3
Correct prediction
Energy consumption = 157.821841 pJ
sum error= 349
Actual label: 6
Output voltages: [0.025152, 0.014006, 0.20251, 0.0030394, 0.41909, 0.022349, 0.79879, 0.0013375, 0.3606, 0.026165]
Predicted label: 6
Correct prediction
Energy consumption = 144.812983 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79879, 0.096155, 0.034211, 0.011508, 0.0035603, 0.0044815, 0.55233, 0.020288, 0.093942, 0.043574]
Predicted label: 0
Correct prediction
Energy consumption = 144.907117 pJ
sum error= 349
Actual label: 1
Output voltages: [0.010694, 0.79852, 0.056482, 0.026636, 0.17034, 0.0070489, 0.21774, 0.0079004, 0.15655, 0.19022]
Predicted label: 1
Correct prediction
Energy consumption = 164.035917 pJ
sum error= 349
Actual label: 2
Output voltages: [0.47173, 0.00261, 0.79736, 0.38299, 0.016244, 0.0012, 0.013934, 0.023945, 0.33018, 0.025949]
Predicted label: 2
Correct prediction
Energy consumption = 147.019602 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 937 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 937 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 937 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.35829, 0.057518, 0.25613, 0.79877, 0.0019459, 0.0013731, 0.020757, 0.005783, 0.5979, 0.024137]
Predicted label: 3
Correct prediction
Energy consumption = 145.872123 pJ
sum error= 349
Actual label: 4
Output voltages: [0.0028106, 0.020914, 0.1338, 0.0045027, 0.79868, 0.0084608, 0.052559, 0.032577, 0.030125, 0.37257]
Predicted label: 4
Correct prediction
Energy consumption = 156.551576 pJ
sum error= 349
Actual label: 5
Output voltages: [0.037596, 0.0010728, 0.0023157, 0.3697, 0.056791, 0.79879, 0.32936, 0.048839, 0.78563, 0.035081]
Predicted label: 5
Correct prediction
Energy consumption = 147.849885 pJ
sum error= 349
Actual label: 6
Output voltages: [0.046676, 0.049684, 0.24122, 0.0022655, 0.34647, 0.2922, 0.79867, 0.0067683, 0.41414, 0.0080225]
Predicted label: 6
Correct prediction
Energy consumption = 140.988912 pJ
sum error= 349
Actual label: 7
Output voltages: [0.069999, 0.0089076, 0.032523, 0.051236, 0.040104, 0.025403, 0.0010682, 0.79848, 0.025232, 0.087088]
Predicted label: 7
Correct prediction
Energy consumption = 157.617229 pJ
sum error= 349
Actual label: 8
Output voltages: [0.17711, 0.017969, 0.13199, 0.29008, 0.0024611, 0.0025916, 0.31022, 0.0012704, 0.79861, 0.040989]
Predicted label: 8
Correct prediction
Energy consumption = 150.419846 pJ
sum error= 349
Actual label: 9
Output voltages: [0.2933, 0.028904, 0.025564, 0.17809, 0.1464, 0.17922, 0.018439, 0.022165, 0.13544, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 153.005188 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79876, 0.018658, 0.14699, 0.0199, 0.0014106, 0.019307, 0.31201, 0.060348, 0.17346, 0.024744]
Predicted label: 0
Correct prediction
Energy consumption = 139.979925 pJ
sum error= 349
Actual label: 1
Output voltages: [0.020288, 0.79868, 0.15789, 0.11224, 0.30601, 0.0038232, 0.17766, 0.0020863, 0.067035, 0.041289]
Predicted label: 1
Correct prediction
Energy consumption = 163.492077 pJ
sum error= 349
Actual label: 2
Output voltages: [0.37481, 0.0054389, 0.79875, 0.056624, 0.0031141, 0.0010772, 0.070041, 0.054244, 0.7462, 0.0028646]
Predicted label: 2
Correct prediction
Energy consumption = 148.934859 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 938 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 938 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 938 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.23343, 0.007213, 0.22115, 0.79866, 0.0153, 0.0012791, 0.03923, 0.23702, 0.336, 0.024035]
Predicted label: 3
Correct prediction
Energy consumption = 143.581303 pJ
sum error= 349
Actual label: 4
Output voltages: [0.0046618, 0.044017, 0.05088, 0.0033676, 0.79865, 0.0099653, 0.022139, 0.25407, 0.043637, 0.11492]
Predicted label: 4
Correct prediction
Energy consumption = 157.441090 pJ
sum error= 349
Actual label: 5
Output voltages: [0.0088072, 0.0015333, 0.0011019, 0.28358, 0.60739, 0.71756, 0.15451, 0.0011207, 0.5633, 0.22445]
Predicted label: 5
Correct prediction
Energy consumption = 142.511522 pJ
sum error= 349
Actual label: 6
Output voltages: [0.041899, 0.10006, 0.57215, 0.0010789, 0.42062, 0.26666, 0.79873, 0.0013046, 0.50394, 0.0056292]
Predicted label: 6
Correct prediction
Energy consumption = 140.670391 pJ
sum error= 349
Actual label: 7
Output voltages: [0.045621, 0.029943, 0.035118, 0.016749, 0.020507, 0.0028373, 0.001079, 0.79856, 0.18848, 0.2725]
Predicted label: 7
Correct prediction
Energy consumption = 150.747955 pJ
sum error= 349
Actual label: 8
Output voltages: [0.057092, 0.034151, 0.25099, 0.55176, 0.0011221, 0.26195, 0.75479, 0.0010785, 0.79788, 0.036496]
Predicted label: 8
Correct prediction
Energy consumption = 155.818170 pJ
sum error= 349
Actual label: 9
Output voltages: [0.051272, 0.018346, 0.03558, 0.02921, 0.044401, 0.0057474, 0.0053987, 0.051442, 0.57966, 0.79347]
Predicted label: 9
Correct prediction
Energy consumption = 147.824728 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79877, 0.067523, 0.047543, 0.019438, 0.0032612, 0.0083833, 0.59516, 0.034123, 0.29245, 0.026579]
Predicted label: 0
Correct prediction
Energy consumption = 144.078607 pJ
sum error= 349
Actual label: 1
Output voltages: [0.015999, 0.79835, 0.048409, 0.067397, 0.028083, 0.0077878, 0.68956, 0.018972, 0.094563, 0.20668]
Predicted label: 1
Correct prediction
Energy consumption = 160.667945 pJ
sum error= 349
Actual label: 2
Output voltages: [0.68796, 0.0074317, 0.79875, 0.17914, 0.017197, 0.0011132, 0.20742, 0.04428, 0.71566, 0.028909]
Predicted label: 2
Correct prediction
Energy consumption = 150.191441 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 939 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 939 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 939 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.25304, 0.024545, 0.06423, 0.79869, 0.028251, 0.0012895, 0.016447, 0.0528, 0.65163, 0.033219]
Predicted label: 3
Correct prediction
Energy consumption = 144.128395 pJ
sum error= 349
Actual label: 5
Output voltages: [0.12523, 0.0010992, 0.0010767, 0.38694, 0.51141, 0.79876, 0.2485, 0.020661, 0.76731, 0.028129]
Predicted label: 5
Correct prediction
Energy consumption = 142.935887 pJ
sum error= 349
Actual label: 6
Output voltages: [0.040639, 0.0444, 0.42595, 0.0041614, 0.046062, 0.067693, 0.79877, 0.012833, 0.066815, 0.027388]
Predicted label: 6
Correct prediction
Energy consumption = 137.828348 pJ
sum error= 349
Actual label: 7
Output voltages: [0.062086, 0.061963, 0.18116, 0.033374, 0.0058424, 0.0075919, 0.0057352, 0.79837, 0.061062, 0.10064]
Predicted label: 7
Correct prediction
Energy consumption = 155.599378 pJ
sum error= 349
Actual label: 8
Output voltages: [0.015902, 0.010073, 0.057817, 0.029632, 0.0022243, 0.03794, 0.11416, 0.0044893, 0.79879, 0.1471]
Predicted label: 8
Correct prediction
Energy consumption = 144.692313 pJ
sum error= 349
Actual label: 1
Output voltages: [0.050892, 0.79858, 0.14035, 0.13786, 0.04967, 0.0013775, 0.23514, 0.0027725, 0.036885, 0.21567]
Predicted label: 1
Correct prediction
Energy consumption = 164.907077 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79875, 0.03355, 0.05706, 0.0079395, 0.019872, 0.0020423, 0.67686, 0.021656, 0.10999, 0.077745]
Predicted label: 0
Correct prediction
Energy consumption = 142.243696 pJ
sum error= 349
Actual label: 9
Output voltages: [0.053626, 0.031781, 0.061929, 0.15068, 0.020517, 0.0080011, 0.011388, 0.16715, 0.55962, 0.79853]
Predicted label: 9
Correct prediction
Energy consumption = 154.694782 pJ
sum error= 349
Actual label: 5
Output voltages: [0.1555, 0.0010733, 0.0022355, 0.45043, 0.081178, 0.79878, 0.10866, 0.047284, 0.76996, 0.036509]
Predicted label: 5
Correct prediction
Energy consumption = 143.299328 pJ
sum error= 349
Actual label: 7
Output voltages: [0.50449, 0.042041, 0.002889, 0.020067, 0.038177, 0.026449, 0.0015438, 0.79878, 0.038389, 0.59494]
Predicted label: 7
Correct prediction
Energy consumption = 154.753246 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 940 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 940 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 940 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.023187, 0.0010794, 0.0012721, 0.35269, 0.039552, 0.79357, 0.14893, 0.019773, 0.78474, 0.013557]
Predicted label: 5
Correct prediction
Energy consumption = 151.815068 pJ
sum error= 349
Actual label: 1
Output voltages: [0.017616, 0.79847, 0.020866, 0.14121, 0.038906, 0.0039873, 0.22504, 0.025282, 0.03653, 0.10411]
Predicted label: 1
Correct prediction
Energy consumption = 168.701847 pJ
sum error= 349
Actual label: 8
Output voltages: [0.020924, 0.018925, 0.32163, 0.16043, 0.0078017, 0.3695, 0.028305, 0.019969, 0.79875, 0.016228]
Predicted label: 8
Correct prediction
Energy consumption = 155.846771 pJ
sum error= 349
Actual label: 6
Output voltages: [0.21287, 0.14902, 0.033826, 0.010055, 0.25617, 0.34353, 0.79872, 0.0019103, 0.49005, 0.011801]
Predicted label: 6
Correct prediction
Energy consumption = 148.704812 pJ
sum error= 349
Actual label: 9
Output voltages: [0.19051, 0.0052001, 0.015633, 0.022751, 0.19249, 0.048569, 0.0078693, 0.078853, 0.36828, 0.79833]
Predicted label: 9
Correct prediction
Energy consumption = 153.686923 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79879, 0.059149, 0.022394, 0.0056693, 0.037347, 0.018123, 0.68966, 0.0028633, 0.036952, 0.052859]
Predicted label: 0
Correct prediction
Energy consumption = 150.443981 pJ
sum error= 349
Actual label: 4
Output voltages: [0.02427, 0.031701, 0.28792, 0.004598, 0.79879, 0.0011633, 0.015813, 0.068152, 0.018051, 0.497]
Predicted label: 4
Correct prediction
Energy consumption = 158.501267 pJ
sum error= 349
Actual label: 1
Output voltages: [0.02151, 0.79862, 0.041815, 0.1339, 0.28512, 0.020608, 0.6138, 0.0011414, 0.061213, 0.18788]
Predicted label: 1
Correct prediction
Energy consumption = 163.519932 pJ
sum error= 349
Actual label: 9
Output voltages: [0.32042, 0.0023445, 0.020387, 0.18405, 0.52758, 0.1317, 0.042252, 0.013556, 0.056444, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 152.780595 pJ
sum error= 349
Actual label: 3
Output voltages: [0.34482, 0.026471, 0.28323, 0.79868, 0.011372, 0.013996, 0.010594, 0.0038709, 0.72817, 0.024853]
Predicted label: 3
Correct prediction
Energy consumption = 140.435179 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 941 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 941 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 941 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.18392, 0.0066376, 0.015769, 0.61081, 0.001066, 0.48953, 0.020594, 0.0036402, 0.79878, 0.43632]
Predicted label: 8
Correct prediction
Energy consumption = 150.910854 pJ
sum error= 349
Actual label: 4
Output voltages: [0.01061, 0.0075529, 0.092642, 0.012778, 0.7987, 0.0011803, 0.12379, 0.028111, 0.056403, 0.030827]
Predicted label: 4
Correct prediction
Energy consumption = 155.791788 pJ
sum error= 349
Actual label: 4
Output voltages: [0.010894, 0.0029052, 0.036947, 0.011588, 0.79874, 0.0018792, 0.12569, 0.38298, 0.22612, 0.0037142]
Predicted label: 4
Correct prediction
Energy consumption = 145.395822 pJ
sum error= 349
Actual label: 7
Output voltages: [0.19155, 0.2247, 0.59096, 0.044059, 0.0071874, 0.0012236, 0.0024737, 0.79879, 0.30328, 0.083845]
Predicted label: 7
Correct prediction
Energy consumption = 156.679806 pJ
sum error= 349
Actual label: 0
Output voltages: [0.79879, 0.0026408, 0.10529, 0.0091538, 0.028761, 0.010892, 0.25459, 0.020137, 0.045763, 0.032274]
Predicted label: 0
Correct prediction
Energy consumption = 155.417872 pJ
sum error= 349
Actual label: 1
Output voltages: [0.022634, 0.79847, 0.065549, 0.022776, 0.01512, 0.0017198, 0.39338, 0.017175, 0.48818, 0.034336]
Predicted label: 1
Correct prediction
Energy consumption = 162.931062 pJ
sum error= 349
Actual label: 9
Output voltages: [0.30171, 0.0074496, 0.018329, 0.43565, 0.04511, 0.30289, 0.016757, 0.10368, 0.1447, 0.7985]
Predicted label: 9
Correct prediction
Energy consumption = 156.062772 pJ
sum error= 349
Actual label: 2
Output voltages: [0.44291, 0.023527, 0.79868, 0.026218, 0.010403, 0.0010729, 0.038052, 0.027651, 0.58924, 0.0013868]
Predicted label: 2
Correct prediction
Energy consumption = 153.013255 pJ
sum error= 349
Actual label: 8
Output voltages: [0.035566, 0.041362, 0.27902, 0.061843, 0.0129, 0.0029972, 0.041861, 0.0013521, 0.79879, 0.30244]
Predicted label: 8
Correct prediction
Energy consumption = 147.969175 pJ
sum error= 349
Actual label: 7
Output voltages: [0.45258, 0.12058, 0.0069976, 0.39593, 0.015656, 0.060085, 0.001119, 0.79869, 0.046489, 0.24432]
Predicted label: 7
Correct prediction
Energy consumption = 157.565574 pJ
sum error= 349
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 942 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 942 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 942 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.024529, 0.052646, 0.19713, 0.063437, 0.0073428, 0.0049959, 0.01446, 0.0095564, 0.79874, 0.32416]
Predicted label: 8
Correct prediction
Energy consumption = 149.107466 pJ
sum error= 349
Actual label: 2
Output voltages: [0.69654, 0.036623, 0.79879, 0.25482, 0.0011024, 0.0010659, 0.013381, 0.16124, 0.3891, 0.020052]
Predicted label: 2
Correct prediction
Energy consumption = 143.830195 pJ
sum error= 349
Actual label: 5
Output voltages: [0.0024796, 0.0011171, 0.0062694, 0.77903, 0.43498, 0.32768, 0.49225, 0.012794, 0.52015, 0.018315]
Predicted label: 3
Wrong prediction!
Energy consumption = 149.150871 pJ
sum error= 350
Actual label: 9
Output voltages: [0.22828, 0.018513, 0.037353, 0.073384, 0.21975, 0.025575, 0.014045, 0.31213, 0.072368, 0.79832]
Predicted label: 9
Correct prediction
Energy consumption = 148.199176 pJ
sum error= 350
Actual label: 6
Output voltages: [0.054938, 0.040978, 0.1189, 0.0039352, 0.33693, 0.36955, 0.79872, 0.0047694, 0.45343, 0.0039013]
Predicted label: 6
Correct prediction
Energy consumption = 148.357081 pJ
sum error= 350
Actual label: 0
Output voltages: [0.78946, 0.0063811, 0.078982, 0.0012106, 0.0070422, 0.017123, 0.70523, 0.002122, 0.2895, 0.022846]
Predicted label: 0
Correct prediction
Energy consumption = 145.294194 pJ
sum error= 350
Actual label: 6
Output voltages: [0.086493, 0.015321, 0.079164, 0.0016311, 0.29141, 0.035424, 0.79828, 0.0092905, 0.046951, 0.042287]
Predicted label: 6
Correct prediction
Energy consumption = 136.959689 pJ
sum error= 350
Actual label: 5
Output voltages: [0.031018, 0.0010661, 0.0010788, 0.36002, 0.30169, 0.79873, 0.59909, 0.0036954, 0.7708, 0.045331]
Predicted label: 5
Correct prediction
Energy consumption = 144.018881 pJ
sum error= 350
Actual label: 5
Output voltages: [0.013488, 0.0011094, 0.0014224, 0.41834, 0.18413, 0.79439, 0.24097, 0.011634, 0.74799, 0.047577]
Predicted label: 5
Correct prediction
Energy consumption = 137.313531 pJ
sum error= 350
Actual label: 3
Output voltages: [0.20477, 0.031373, 0.074031, 0.79871, 0.0198, 0.002541, 0.005386, 0.0084503, 0.71218, 0.024807]
Predicted label: 3
Correct prediction
Energy consumption = 137.151214 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 943 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 943 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 943 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.64115, 0.016372, 0.50828, 0.79879, 0.0048628, 0.015295, 0.0097591, 0.013784, 0.35435, 0.016836]
Predicted label: 3
Correct prediction
Energy consumption = 143.788386 pJ
sum error= 350
Actual label: 3
Output voltages: [0.42251, 0.0085913, 0.19906, 0.79877, 0.0051107, 0.0083628, 0.0076233, 0.0031564, 0.70615, 0.01746]
Predicted label: 3
Correct prediction
Energy consumption = 136.353584 pJ
sum error= 350
Actual label: 9
Output voltages: [0.38755, 0.048427, 0.0090868, 0.58879, 0.32182, 0.014, 0.029165, 0.017637, 0.070671, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 148.019310 pJ
sum error= 350
Actual label: 8
Output voltages: [0.055026, 0.027282, 0.20871, 0.0081545, 0.0032276, 0.021938, 0.27964, 0.012853, 0.79879, 0.30108]
Predicted label: 8
Correct prediction
Energy consumption = 152.467314 pJ
sum error= 350
Actual label: 1
Output voltages: [0.015171, 0.79862, 0.2915, 0.07942, 0.037056, 0.0010663, 0.60183, 0.0010918, 0.13581, 0.42806]
Predicted label: 1
Correct prediction
Energy consumption = 166.214286 pJ
sum error= 350
Actual label: 1
Output voltages: [0.017753, 0.79835, 0.023118, 0.23094, 0.0055843, 0.01197, 0.61756, 0.0048449, 0.040343, 0.063659]
Predicted label: 1
Correct prediction
Energy consumption = 154.171177 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79879, 0.2702, 0.12622, 0.026259, 0.0042925, 0.021861, 0.35954, 0.012972, 0.15376, 0.1326]
Predicted label: 0
Correct prediction
Energy consumption = 158.865831 pJ
sum error= 350
Actual label: 6
Output voltages: [0.029976, 0.10326, 0.25421, 0.0020743, 0.1097, 0.1384, 0.79873, 0.0097227, 0.31883, 0.0032564]
Predicted label: 6
Correct prediction
Energy consumption = 143.335902 pJ
sum error= 350
Actual label: 1
Output voltages: [0.014782, 0.79846, 0.10304, 0.056521, 0.028201, 0.003825, 0.49449, 0.0078434, 0.20296, 0.027899]
Predicted label: 1
Correct prediction
Energy consumption = 158.699529 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79719, 0.016034, 0.047526, 0.0028607, 0.0062035, 0.0016383, 0.67503, 0.024211, 0.10244, 0.045171]
Predicted label: 0
Correct prediction
Energy consumption = 153.661767 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 944 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 944 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 944 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79858, 0.041782, 0.025139, 0.010687, 0.001215, 0.015429, 0.61241, 0.0068374, 0.28436, 0.01779]
Predicted label: 0
Correct prediction
Energy consumption = 147.216715 pJ
sum error= 350
Actual label: 6
Output voltages: [0.16213, 0.21204, 0.31437, 0.0064189, 0.22543, 0.23607, 0.79869, 0.003587, 0.21245, 0.021517]
Predicted label: 6
Correct prediction
Energy consumption = 144.508678 pJ
sum error= 350
Actual label: 2
Output voltages: [0.30958, 0.0010923, 0.79862, 0.43684, 0.02043, 0.0010668, 0.037321, 0.19537, 0.72929, 0.041362]
Predicted label: 2
Correct prediction
Energy consumption = 142.356881 pJ
sum error= 350
Actual label: 1
Output voltages: [0.019219, 0.7985, 0.017811, 0.15707, 0.038339, 0.025249, 0.33369, 0.0059899, 0.29463, 0.16867]
Predicted label: 1
Correct prediction
Energy consumption = 169.109686 pJ
sum error= 350
Actual label: 1
Output voltages: [0.026911, 0.79857, 0.12572, 0.029964, 0.29315, 0.011051, 0.23476, 0.0069666, 0.011697, 0.17753]
Predicted label: 1
Correct prediction
Energy consumption = 155.857356 pJ
sum error= 350
Actual label: 3
Output voltages: [0.37401, 0.031849, 0.048689, 0.79861, 0.017402, 0.0045383, 0.026762, 0.036637, 0.54019, 0.02972]
Predicted label: 3
Correct prediction
Energy consumption = 140.609513 pJ
sum error= 350
Actual label: 2
Output voltages: [0.022205, 0.004346, 0.79878, 0.39955, 0.073038, 0.001132, 0.060601, 0.29615, 0.35249, 0.019093]
Predicted label: 2
Correct prediction
Energy consumption = 132.662711 pJ
sum error= 350
Actual label: 7
Output voltages: [0.26056, 0.032013, 0.039413, 0.018404, 0.048671, 0.0086637, 0.0017742, 0.79847, 0.16532, 0.043923]
Predicted label: 7
Correct prediction
Energy consumption = 156.495888 pJ
sum error= 350
Actual label: 7
Output voltages: [0.011711, 0.3409, 0.046981, 0.020004, 0.041581, 0.0011305, 0.0022661, 0.79869, 0.029706, 0.31201]
Predicted label: 7
Correct prediction
Energy consumption = 145.773301 pJ
sum error= 350
Actual label: 8
Output voltages: [0.023246, 0.0068121, 0.04721, 0.058592, 0.0065005, 0.023394, 0.0049995, 0.027519, 0.79879, 0.4418]
Predicted label: 8
Correct prediction
Energy consumption = 141.872438 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 945 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 945 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 945 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.15994, 0.009669, 0.20761, 0.3626, 0.0039382, 0.040268, 0.41719, 0.0026521, 0.79874, 0.020595]
Predicted label: 8
Correct prediction
Energy consumption = 153.926152 pJ
sum error= 350
Actual label: 7
Output voltages: [0.13644, 0.018625, 0.012693, 0.069379, 0.021677, 0.012334, 0.0010864, 0.79862, 0.085243, 0.30546]
Predicted label: 7
Correct prediction
Energy consumption = 155.484358 pJ
sum error= 350
Actual label: 8
Output voltages: [0.011721, 0.014568, 0.23906, 0.097431, 0.0026507, 0.20812, 0.16899, 0.015063, 0.79877, 0.039575]
Predicted label: 8
Correct prediction
Energy consumption = 148.336611 pJ
sum error= 350
Actual label: 4
Output voltages: [0.019868, 0.024353, 0.24513, 0.0078951, 0.79865, 0.0048715, 0.034646, 0.034423, 0.038318, 0.044528]
Predicted label: 4
Correct prediction
Energy consumption = 154.297384 pJ
sum error= 350
Actual label: 6
Output voltages: [0.025954, 0.078311, 0.46556, 0.0010733, 0.45231, 0.054753, 0.79873, 0.0012689, 0.17776, 0.003967]
Predicted label: 6
Correct prediction
Energy consumption = 140.144785 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79791, 0.080442, 0.28303, 0.0027821, 0.0040605, 0.011424, 0.31043, 0.0092709, 0.0076988, 0.071879]
Predicted label: 0
Correct prediction
Energy consumption = 148.261808 pJ
sum error= 350
Actual label: 2
Output voltages: [0.18514, 0.015034, 0.79879, 0.32484, 0.0018297, 0.0011885, 0.062232, 0.74796, 0.44407, 0.06013]
Predicted label: 2
Correct prediction
Energy consumption = 138.754543 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79819, 0.043316, 0.027526, 0.014416, 0.0088682, 0.012362, 0.74518, 0.0057367, 0.20546, 0.035874]
Predicted label: 0
Correct prediction
Energy consumption = 155.088865 pJ
sum error= 350
Actual label: 7
Output voltages: [0.45531, 0.01243, 0.20613, 0.003791, 0.032668, 0.0041302, 0.0010678, 0.79865, 0.040573, 0.045701]
Predicted label: 7
Correct prediction
Energy consumption = 149.681459 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79879, 0.090361, 0.028762, 0.0048862, 0.015773, 0.0065289, 0.48601, 0.0051551, 0.043464, 0.32679]
Predicted label: 0
Correct prediction
Energy consumption = 148.888051 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 946 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 946 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 946 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.051036, 0.023543, 0.1144, 0.79874, 0.0068044, 0.001113, 0.011579, 0.01171, 0.74142, 0.022136]
Predicted label: 3
Correct prediction
Energy consumption = 141.277759 pJ
sum error= 350
Actual label: 6
Output voltages: [0.069265, 0.031121, 0.067325, 0.0087187, 0.55377, 0.40182, 0.79873, 0.0015, 0.68243, 0.014215]
Predicted label: 6
Correct prediction
Energy consumption = 145.285295 pJ
sum error= 350
Actual label: 8
Output voltages: [0.017435, 0.019997, 0.062519, 0.014985, 0.022979, 0.021766, 0.034144, 0.012175, 0.7987, 0.12202]
Predicted label: 8
Correct prediction
Energy consumption = 152.207794 pJ
sum error= 350
Actual label: 7
Output voltages: [0.25967, 0.0018815, 0.0095909, 0.037015, 0.030143, 0.013703, 0.0011186, 0.79878, 0.61312, 0.19944]
Predicted label: 7
Correct prediction
Energy consumption = 154.294406 pJ
sum error= 350
Actual label: 1
Output voltages: [0.0034997, 0.79849, 0.022502, 0.036993, 0.011432, 0.0055013, 0.51872, 0.0092394, 0.45569, 0.038957]
Predicted label: 1
Correct prediction
Energy consumption = 163.865421 pJ
sum error= 350
Actual label: 5
Output voltages: [0.06802, 0.0029442, 0.0038283, 0.53564, 0.019839, 0.79878, 0.21686, 0.010164, 0.38884, 0.012989]
Predicted label: 5
Correct prediction
Energy consumption = 155.649613 pJ
sum error= 350
Actual label: 9
Output voltages: [0.20336, 0.0075365, 0.0033477, 0.1382, 0.23759, 0.0013124, 0.0012087, 0.0099924, 0.46172, 0.79802]
Predicted label: 9
Correct prediction
Energy consumption = 151.291193 pJ
sum error= 350
Actual label: 9
Output voltages: [0.25397, 0.0086492, 0.051751, 0.013096, 0.14985, 0.0081305, 0.0072484, 0.0069118, 0.54757, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 141.345322 pJ
sum error= 350
Actual label: 3
Output voltages: [0.29757, 0.012432, 0.4192, 0.79875, 0.0078211, 0.0036939, 0.0020101, 0.0049338, 0.7749, 0.0060639]
Predicted label: 3
Correct prediction
Energy consumption = 141.855097 pJ
sum error= 350
Actual label: 7
Output voltages: [0.16047, 0.028307, 0.0016984, 0.45619, 0.012167, 0.021478, 0.001093, 0.79877, 0.047933, 0.25619]
Predicted label: 7
Correct prediction
Energy consumption = 154.559147 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 947 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 947 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 947 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.50272, 0.0019621, 0.79878, 0.052734, 0.0066042, 0.0011241, 0.043132, 0.038147, 0.66137, 0.0042482]
Predicted label: 2
Correct prediction
Energy consumption = 147.054705 pJ
sum error= 350
Actual label: 4
Output voltages: [0.0081606, 0.03145, 0.049106, 0.013348, 0.79866, 0.0026435, 0.2293, 0.028329, 0.031791, 0.044024]
Predicted label: 4
Correct prediction
Energy consumption = 150.794821 pJ
sum error= 350
Actual label: 9
Output voltages: [0.24561, 0.0025005, 0.014422, 0.019789, 0.5352, 0.073638, 0.088716, 0.28177, 0.15508, 0.79876]
Predicted label: 9
Correct prediction
Energy consumption = 146.345487 pJ
sum error= 350
Actual label: 4
Output voltages: [0.0092683, 0.0081734, 0.23992, 0.0079987, 0.79862, 0.0011576, 0.03835, 0.012681, 0.027667, 0.24885]
Predicted label: 4
Correct prediction
Energy consumption = 149.828928 pJ
sum error= 350
Actual label: 3
Output voltages: [0.40604, 0.0056695, 0.18456, 0.79874, 0.019413, 0.049376, 0.0075994, 0.024111, 0.59472, 0.11812]
Predicted label: 3
Correct prediction
Energy consumption = 155.439706 pJ
sum error= 350
Actual label: 6
Output voltages: [0.14935, 0.032038, 0.16799, 0.0010706, 0.38556, 0.39906, 0.79876, 0.0014344, 0.41634, 0.029792]
Predicted label: 6
Correct prediction
Energy consumption = 146.810190 pJ
sum error= 350
Actual label: 2
Output voltages: [0.24418, 0.048252, 0.79865, 0.041922, 0.0089164, 0.0010669, 0.14579, 0.022258, 0.67455, 0.020741]
Predicted label: 2
Correct prediction
Energy consumption = 138.605673 pJ
sum error= 350
Actual label: 2
Output voltages: [0.099605, 0.0011227, 0.79877, 0.18626, 0.049573, 0.0010712, 0.0051303, 0.19678, 0.72001, 0.0076963]
Predicted label: 2
Correct prediction
Energy consumption = 125.414092 pJ
sum error= 350
Actual label: 5
Output voltages: [0.030283, 0.013775, 0.0016533, 0.36885, 0.048832, 0.79872, 0.15268, 0.001437, 0.76424, 0.0035433]
Predicted label: 5
Correct prediction
Energy consumption = 152.407256 pJ
sum error= 350
Actual label: 3
Output voltages: [0.33495, 0.047981, 0.16404, 0.79866, 0.011975, 0.011115, 0.0028747, 0.017766, 0.7552, 0.021176]
Predicted label: 3
Correct prediction
Energy consumption = 143.042765 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 948 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 948 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 948 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.3698, 0.034016, 0.79863, 0.034605, 0.018977, 0.0011346, 0.13977, 0.016174, 0.3823, 0.013047]
Predicted label: 2
Correct prediction
Energy consumption = 146.983651 pJ
sum error= 350
Actual label: 5
Output voltages: [0.03006, 0.0016222, 0.0030649, 0.36109, 0.034103, 0.79865, 0.038806, 0.030414, 0.76463, 0.0038805]
Predicted label: 5
Correct prediction
Energy consumption = 146.610012 pJ
sum error= 350
Actual label: 5
Output voltages: [0.050381, 0.0030323, 0.0050285, 0.77487, 0.05757, 0.79866, 0.012094, 0.012267, 0.73098, 0.016572]
Predicted label: 5
Correct prediction
Energy consumption = 139.634462 pJ
sum error= 350
Actual label: 9
Output voltages: [0.083401, 0.019526, 0.026514, 0.041873, 0.044623, 0.017559, 0.0017013, 0.023718, 0.69899, 0.79739]
Predicted label: 9
Correct prediction
Energy consumption = 150.628655 pJ
sum error= 350
Actual label: 4
Output voltages: [0.011019, 0.013078, 0.044895, 0.0093907, 0.79874, 0.0020675, 0.10809, 0.073169, 0.16922, 0.0099409]
Predicted label: 4
Correct prediction
Energy consumption = 147.435996 pJ
sum error= 350
Actual label: 1
Output voltages: [0.016069, 0.79878, 0.016201, 0.010864, 0.36019, 0.0022927, 0.12168, 0.0032021, 0.37745, 0.2113]
Predicted label: 1
Correct prediction
Energy consumption = 156.412650 pJ
sum error= 350
Actual label: 7
Output voltages: [0.14028, 0.056532, 0.21415, 0.33686, 0.019002, 0.085004, 0.0012152, 0.79854, 0.047502, 0.37489]
Predicted label: 7
Correct prediction
Energy consumption = 149.728873 pJ
sum error= 350
Actual label: 2
Output voltages: [0.38169, 0.02175, 0.79874, 0.1884, 0.01281, 0.001066, 0.055977, 0.036273, 0.3064, 0.013874]
Predicted label: 2
Correct prediction
Energy consumption = 142.957253 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79878, 0.035774, 0.034328, 0.011555, 0.0033771, 0.0045156, 0.61614, 0.043437, 0.10376, 0.051433]
Predicted label: 0
Correct prediction
Energy consumption = 138.951694 pJ
sum error= 350
Actual label: 1
Output voltages: [0.0089118, 0.79864, 0.35729, 0.03058, 0.12834, 0.0010714, 0.3228, 0.0051254, 0.1933, 0.010792]
Predicted label: 1
Correct prediction
Energy consumption = 167.380989 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 949 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 949 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 949 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.039787, 0.20797, 0.79852, 0.035353, 0.002935, 0.0011223, 0.022489, 0.040738, 0.59315, 0.031119]
Predicted label: 2
Correct prediction
Energy consumption = 149.241432 pJ
sum error= 350
Actual label: 3
Output voltages: [0.26879, 0.023157, 0.04775, 0.79871, 0.018977, 0.013939, 0.0088473, 0.37573, 0.57265, 0.14842]
Predicted label: 3
Correct prediction
Energy consumption = 148.066904 pJ
sum error= 350
Actual label: 4
Output voltages: [0.038448, 0.0020689, 0.73205, 0.060994, 0.79877, 0.021123, 0.053837, 0.002321, 0.30067, 0.64696]
Predicted label: 4
Correct prediction
Energy consumption = 149.654571 pJ
sum error= 350
Actual label: 5
Output voltages: [0.022014, 0.0010704, 0.0017296, 0.037699, 0.19716, 0.79685, 0.031339, 0.01055, 0.78996, 0.1444]
Predicted label: 5
Correct prediction
Energy consumption = 143.887583 pJ
sum error= 350
Actual label: 6
Output voltages: [0.048758, 0.079929, 0.64971, 0.0010699, 0.22126, 0.033984, 0.79877, 0.0033573, 0.041292, 0.021937]
Predicted label: 6
Correct prediction
Energy consumption = 147.552001 pJ
sum error= 350
Actual label: 7
Output voltages: [0.22005, 0.063009, 0.015074, 0.017991, 0.0069997, 0.0014478, 0.001066, 0.79878, 0.040382, 0.7657]
Predicted label: 7
Correct prediction
Energy consumption = 157.793269 pJ
sum error= 350
Actual label: 8
Output voltages: [0.0095841, 0.18168, 0.16174, 0.049326, 0.008174, 0.02363, 0.015497, 0.34856, 0.79867, 0.043204]
Predicted label: 8
Correct prediction
Energy consumption = 143.909609 pJ
sum error= 350
Actual label: 9
Output voltages: [0.043664, 0.020811, 0.017071, 0.037534, 0.0065398, 0.008358, 0.0016072, 0.06607, 0.76385, 0.78873]
Predicted label: 9
Correct prediction
Energy consumption = 144.121107 pJ
sum error= 350
Actual label: 0
Output voltages: [0.79879, 0.10802, 0.025028, 0.0040195, 0.011306, 0.0063862, 0.57502, 0.0085294, 0.063915, 0.059544]
Predicted label: 0
Correct prediction
Energy consumption = 144.722520 pJ
sum error= 350
Actual label: 1
Output voltages: [0.017092, 0.79852, 0.17296, 0.37865, 0.021048, 0.0011157, 0.74285, 0.018713, 0.039294, 0.019588]
Predicted label: 1
Correct prediction
Energy consumption = 163.532974 pJ
sum error= 350
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 950 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 950 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 950 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.14806, 0.014038, 0.79879, 0.03347, 0.015724, 0.0010704, 0.013917, 0.58638, 0.54571, 0.009807]
Predicted label: 2
Correct prediction
Energy consumption = 146.927576 pJ
sum error= 350
Actual label: 3
Output voltages: [0.037032, 0.02609, 0.044302, 0.79872, 0.015697, 0.0016706, 0.010313, 0.045273, 0.64471, 0.034995]
Predicted label: 3
Correct prediction
Energy consumption = 142.456467 pJ
sum error= 350
Actual label: 4
Output voltages: [0.013016, 0.0042012, 0.026959, 0.0012582, 0.79874, 0.0026682, 0.11933, 0.18524, 0.5908, 0.0031919]
Predicted label: 4
Correct prediction
Energy consumption = 153.544475 pJ
sum error= 350
Actual label: 5
Output voltages: [0.012096, 0.0010661, 0.0018577, 0.11704, 0.050842, 0.78986, 0.26149, 0.014637, 0.75882, 0.067979]
Predicted label: 5
Correct prediction
Energy consumption = 143.670786 pJ
sum error= 350
Actual label: 6
Output voltages: [0.035467, 0.11805, 0.11548, 0.0081421, 0.19263, 0.44216, 0.79869, 0.0015418, 0.42064, 0.020523]
Predicted label: 6
Correct prediction
Energy consumption = 139.561490 pJ
sum error= 350
Actual label: 7
Output voltages: [0.47485, 0.024612, 0.75197, 0.55061, 0.0010737, 0.001158, 0.004834, 0.70787, 0.5833, 0.1491]
Predicted label: 2
Wrong prediction!
Energy consumption = 152.188269 pJ
sum error= 351
Actual label: 8
Output voltages: [0.015835, 0.030776, 0.16087, 0.039823, 0.011257, 0.0044355, 0.0238, 0.22204, 0.79873, 0.11741]
Predicted label: 8
Correct prediction
Energy consumption = 139.099789 pJ
sum error= 351
Actual label: 9
Output voltages: [0.067345, 0.024842, 0.017016, 0.02667, 0.017014, 0.011435, 0.001299, 0.019662, 0.75102, 0.7965]
Predicted label: 9
Correct prediction
Energy consumption = 145.449339 pJ
sum error= 351
Actual label: 0
Output voltages: [0.79842, 0.01213, 0.015513, 0.0092786, 0.02227, 0.0014342, 0.065737, 0.0037487, 0.56481, 0.0098135]
Predicted label: 0
Correct prediction
Energy consumption = 142.040617 pJ
sum error= 351
Actual label: 1
Output voltages: [0.065806, 0.79678, 0.053074, 0.02266, 0.2292, 0.0010768, 0.54123, 0.00113, 0.041723, 0.069281]
Predicted label: 1
Correct prediction
Energy consumption = 157.836550 pJ
sum error= 351
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 951 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 951 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 951 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.52042, 0.0073108, 0.79874, 0.15588, 0.0041622, 0.0010955, 0.016596, 0.29293, 0.74495, 0.0013249]
Predicted label: 2
Correct prediction
Energy consumption = 150.567829 pJ
sum error= 351
Actual label: 3
Output voltages: [0.32899, 0.017125, 0.047344, 0.79859, 0.0043841, 0.1547, 0.008153, 0.039382, 0.52711, 0.017737]
Predicted label: 3
Correct prediction
Energy consumption = 151.028241 pJ
sum error= 351
Actual label: 4
Output voltages: [0.0048787, 0.013257, 0.13668, 0.015725, 0.79876, 0.0022437, 0.057869, 0.10854, 0.044532, 0.024983]
Predicted label: 4
Correct prediction
Energy consumption = 149.359922 pJ
sum error= 351
Actual label: 5
Output voltages: [0.0065184, 0.0011012, 0.0011472, 0.047406, 0.50679, 0.7595, 0.49392, 0.12757, 0.78621, 0.004123]
Predicted label: 8
Wrong prediction!
Energy consumption = 141.088952 pJ
sum error= 352
Actual label: 6
Output voltages: [0.11244, 0.20001, 0.20725, 0.0053291, 0.22064, 0.15456, 0.79871, 0.0011129, 0.36561, 0.01034]
Predicted label: 6
Correct prediction
Energy consumption = 140.741710 pJ
sum error= 352
Actual label: 7
Output voltages: [0.077296, 0.14317, 0.41211, 0.078081, 0.0021424, 0.0011557, 0.0010933, 0.79864, 0.74728, 0.054041]
Predicted label: 7
Correct prediction
Energy consumption = 154.522143 pJ
sum error= 352
Actual label: 8
Output voltages: [0.022907, 0.013414, 0.19787, 0.038353, 0.019541, 0.028879, 0.010553, 0.023793, 0.79862, 0.033055]
Predicted label: 8
Correct prediction
Energy consumption = 141.208846 pJ
sum error= 352
Actual label: 9
Output voltages: [0.03962, 0.010864, 0.031513, 0.0081042, 0.5914, 0.0011201, 0.0011181, 0.018628, 0.52692, 0.76397]
Predicted label: 9
Correct prediction
Energy consumption = 148.336031 pJ
sum error= 352
Actual label: 1
Output voltages: [0.035326, 0.79861, 0.21954, 0.27929, 0.22403, 0.002009, 0.66457, 0.010468, 0.093588, 0.080901]
Predicted label: 1
Correct prediction
Energy consumption = 157.940024 pJ
sum error= 352
Actual label: 0
Output voltages: [0.79865, 0.041271, 0.16268, 0.004078, 0.014637, 0.0012542, 0.57553, 0.011363, 0.24751, 0.14426]
Predicted label: 0
Correct prediction
Energy consumption = 149.953869 pJ
sum error= 352
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 952 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 952 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 952 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.010402, 0.79868, 0.0022306, 0.042997, 0.30829, 0.0012482, 0.27856, 0.0016391, 0.29434, 0.41366]
Predicted label: 1
Correct prediction
Energy consumption = 163.102149 pJ
sum error= 352
Actual label: 2
Output voltages: [0.34757, 0.006201, 0.79805, 0.23248, 0.024527, 0.0012311, 0.033148, 0.040692, 0.70774, 0.027183]
Predicted label: 2
Correct prediction
Energy consumption = 144.007862 pJ
sum error= 352
Actual label: 7
Output voltages: [0.085184, 0.056377, 0.036054, 0.022019, 0.0032152, 0.014862, 0.0010989, 0.7985, 0.15432, 0.054174]
Predicted label: 7
Correct prediction
Energy consumption = 149.562355 pJ
sum error= 352
Actual label: 5
Output voltages: [0.026718, 0.0010674, 0.0047153, 0.11045, 0.023175, 0.79663, 0.057713, 0.026246, 0.72752, 0.049191]
Predicted label: 5
Correct prediction
Energy consumption = 141.982468 pJ
sum error= 352
Actual label: 3
Output voltages: [0.55978, 0.021674, 0.058567, 0.79868, 0.0028081, 0.027154, 0.0040311, 0.027275, 0.36319, 0.016472]
Predicted label: 3
Correct prediction
Energy consumption = 144.330401 pJ
sum error= 352
Actual label: 4
Output voltages: [0.0019304, 0.0091155, 0.0083569, 0.0017007, 0.79867, 0.0014378, 0.36972, 0.51062, 0.046891, 0.0056887]
Predicted label: 4
Correct prediction
Energy consumption = 142.854504 pJ
sum error= 352
Actual label: 4
Output voltages: [0.0076149, 0.016458, 0.12483, 0.0059636, 0.79871, 0.020346, 0.42349, 0.40204, 0.13756, 0.0045068]
Predicted label: 4
Correct prediction
Energy consumption = 137.468646 pJ
sum error= 352
Actual label: 0
Output voltages: [0.7925, 0.017986, 0.15564, 0.0028972, 0.016205, 0.0010962, 0.76867, 0.011502, 0.36354, 0.043166]
Predicted label: 0
Correct prediction
Energy consumption = 149.022187 pJ
sum error= 352
Actual label: 0
Output voltages: [0.79871, 0.054285, 0.093743, 0.0097742, 0.01391, 0.0039331, 0.50065, 0.025987, 0.12384, 0.022603]
Predicted label: 0
Correct prediction
Energy consumption = 134.921944 pJ
sum error= 352
Actual label: 6
Output voltages: [0.16084, 0.050281, 0.20166, 0.0041345, 0.37817, 0.42319, 0.79871, 0.0064805, 0.50531, 0.006539]
Predicted label: 6
Correct prediction
Energy consumption = 146.073667 pJ
sum error= 352
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 953 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 953 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 953 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.03344, 0.010669, 0.009873, 0.013909, 0.024721, 0.0078504, 0.019317, 0.017529, 0.75898, 0.78097]
Predicted label: 9
Correct prediction
Energy consumption = 156.933703 pJ
sum error= 352
Actual label: 6
Output voltages: [0.055839, 0.039206, 0.38559, 0.0016978, 0.31618, 0.22665, 0.79869, 0.0038189, 0.31095, 0.0034946]
Predicted label: 6
Correct prediction
Energy consumption = 148.242784 pJ
sum error= 352
Actual label: 6
Output voltages: [0.29718, 0.064296, 0.14085, 0.0015504, 0.29492, 0.17795, 0.79878, 0.0014353, 0.25943, 0.018161]
Predicted label: 6
Correct prediction
Energy consumption = 135.808748 pJ
sum error= 352
Actual label: 5
Output voltages: [0.025898, 0.0010885, 0.0010927, 0.24492, 0.31222, 0.79874, 0.46101, 0.013162, 0.77236, 0.010764]
Predicted label: 5
Correct prediction
Energy consumption = 135.067378 pJ
sum error= 352
Actual label: 7
Output voltages: [0.53843, 0.0093551, 0.043198, 0.62661, 0.0056096, 0.0088618, 0.0011585, 0.79874, 0.055278, 0.45028]
Predicted label: 7
Correct prediction
Energy consumption = 152.817875 pJ
sum error= 352
Actual label: 2
Output voltages: [0.39504, 0.024705, 0.79745, 0.0031302, 0.054628, 0.0013114, 0.038792, 0.0070067, 0.79089, 0.11583]
Predicted label: 2
Correct prediction
Energy consumption = 143.429985 pJ
sum error= 352
Actual label: 3
Output voltages: [0.041033, 0.069435, 0.052843, 0.79878, 0.0048701, 0.0016005, 0.010776, 0.033166, 0.60797, 0.13226]
Predicted label: 3
Correct prediction
Energy consumption = 143.537184 pJ
sum error= 352
Actual label: 4
Output voltages: [0.0030692, 0.0239, 0.013009, 0.013801, 0.79868, 0.0020032, 0.029511, 0.039523, 0.096313, 0.01526]
Predicted label: 4
Correct prediction
Energy consumption = 150.850058 pJ
sum error= 352
Actual label: 4
Output voltages: [0.0010675, 0.21749, 0.020514, 0.0010664, 0.79665, 0.01473, 0.030298, 0.27031, 0.42997, 0.078402]
Predicted label: 4
Correct prediction
Energy consumption = 142.351612 pJ
sum error= 352
Actual label: 9
Output voltages: [0.034811, 0.015453, 0.010526, 0.020234, 0.017387, 0.0016241, 0.0018144, 0.053276, 0.78666, 0.79684]
Predicted label: 9
Correct prediction
Energy consumption = 138.357386 pJ
sum error= 352
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 954 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 954 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 954 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.0045208, 0.75984, 0.0099851, 0.3169, 0.046023, 0.0011337, 0.025733, 0.0011658, 0.60882, 0.55089]
Predicted label: 1
Correct prediction
Energy consumption = 155.492588 pJ
sum error= 352
Actual label: 4
Output voltages: [0.0027299, 0.16574, 0.027322, 0.0018928, 0.79171, 0.039689, 0.18267, 0.010752, 0.41019, 0.023542]
Predicted label: 4
Correct prediction
Energy consumption = 149.155079 pJ
sum error= 352
Actual label: 0
Output voltages: [0.79141, 0.0243, 0.38079, 0.3131, 0.0011326, 0.0057393, 0.018893, 0.03181, 0.77901, 0.027014]
Predicted label: 0
Correct prediction
Energy consumption = 155.261427 pJ
sum error= 352
Actual label: 7
Output voltages: [0.22565, 0.021347, 0.028015, 0.1142, 0.0018121, 0.010035, 0.001245, 0.79871, 0.27502, 0.4391]
Predicted label: 7
Correct prediction
Energy consumption = 150.284752 pJ
sum error= 352
Actual label: 9
Output voltages: [0.21297, 0.0054671, 0.054933, 0.10097, 0.2156, 0.016205, 0.0060362, 0.30047, 0.46475, 0.78851]
Predicted label: 9
Correct prediction
Energy consumption = 142.962143 pJ
sum error= 352
Actual label: 5
Output voltages: [0.021548, 0.0010806, 0.0010775, 0.55896, 0.033723, 0.79879, 0.061276, 0.025397, 0.72628, 0.0042144]
Predicted label: 5
Correct prediction
Energy consumption = 139.387001 pJ
sum error= 352
Actual label: 7
Output voltages: [0.51514, 0.013703, 0.020329, 0.035369, 0.015497, 0.013269, 0.0010682, 0.79874, 0.52802, 0.016039]
Predicted label: 7
Correct prediction
Energy consumption = 146.812139 pJ
sum error= 352
Actual label: 2
Output voltages: [0.6013, 0.0012646, 0.79876, 0.16661, 0.012308, 0.0010673, 0.022952, 0.06606, 0.68925, 0.002486]
Predicted label: 2
Correct prediction
Energy consumption = 145.509825 pJ
sum error= 352
Actual label: 3
Output voltages: [0.33588, 0.0087832, 0.28516, 0.7987, 0.047845, 0.0062565, 0.011884, 0.047921, 0.65618, 0.050094]
Predicted label: 3
Correct prediction
Energy consumption = 140.068715 pJ
sum error= 352
Actual label: 1
Output voltages: [0.064525, 0.79864, 0.20829, 0.020127, 0.29645, 0.0010919, 0.35504, 0.013874, 0.04066, 0.055757]
Predicted label: 1
Correct prediction
Energy consumption = 165.417691 pJ
sum error= 352
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 955 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 955 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 955 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.023544, 0.037371, 0.12514, 0.0038911, 0.79878, 0.0015932, 0.48446, 0.20146, 0.03224, 0.024714]
Predicted label: 4
Correct prediction
Energy consumption = 156.841670 pJ
sum error= 352
Actual label: 4
Output voltages: [0.0020235, 0.01331, 0.029551, 0.027765, 0.7987, 0.0010662, 0.093267, 0.24194, 0.01893, 0.025345]
Predicted label: 4
Correct prediction
Energy consumption = 150.958893 pJ
sum error= 352
Actual label: 0
Output voltages: [0.79829, 0.09091, 0.15625, 0.025009, 0.0037993, 0.0037894, 0.60676, 0.12699, 0.49976, 0.10392]
Predicted label: 0
Correct prediction
Energy consumption = 161.894382 pJ
sum error= 352
Actual label: 9
Output voltages: [0.43953, 0.0074941, 0.030781, 0.021881, 0.3497, 0.0084651, 0.0078383, 0.0070355, 0.62467, 0.79829]
Predicted label: 9
Correct prediction
Energy consumption = 149.059976 pJ
sum error= 352
Actual label: 9
Output voltages: [0.061035, 0.0017646, 0.04319, 0.0089151, 0.19389, 0.0017061, 0.0011185, 0.050077, 0.75886, 0.78349]
Predicted label: 9
Correct prediction
Energy consumption = 142.233856 pJ
sum error= 352
Actual label: 6
Output voltages: [0.065987, 0.028678, 0.29402, 0.0085767, 0.13759, 0.5901, 0.79873, 0.0091122, 0.4347, 0.01902]
Predicted label: 6
Correct prediction
Energy consumption = 147.639699 pJ
sum error= 352
Actual label: 1
Output voltages: [0.1337, 0.79573, 0.12657, 0.025191, 0.047893, 0.0011314, 0.44436, 0.0010663, 0.13496, 0.023607]
Predicted label: 1
Correct prediction
Energy consumption = 158.518252 pJ
sum error= 352
Actual label: 8
Output voltages: [0.026126, 0.011434, 0.18465, 0.044333, 0.013494, 0.018982, 0.010793, 0.076016, 0.79867, 0.016514]
Predicted label: 8
Correct prediction
Energy consumption = 145.801219 pJ
sum error= 352
Actual label: 3
Output voltages: [0.036902, 0.11667, 0.21575, 0.79866, 0.017044, 0.021623, 0.0027387, 0.022786, 0.53022, 0.16318]
Predicted label: 3
Correct prediction
Energy consumption = 141.168859 pJ
sum error= 352
Actual label: 3
Output voltages: [0.6653, 0.020505, 0.63967, 0.79854, 0.0046843, 0.0010828, 0.0010717, 0.022726, 0.52409, 0.018606]
Predicted label: 3
Correct prediction
Energy consumption = 141.233791 pJ
sum error= 352
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 956 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 956 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 956 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.06977, 0.19691, 0.53515, 0.11708, 0.0010916, 0.0011277, 0.0010781, 0.79875, 0.77009, 0.2863]
Predicted label: 7
Correct prediction
Energy consumption = 152.064765 pJ
sum error= 352
Actual label: 3
Output voltages: [0.12315, 0.017994, 0.080849, 0.79867, 0.020592, 0.0041657, 0.0077131, 0.028912, 0.48949, 0.054692]
Predicted label: 3
Correct prediction
Energy consumption = 138.753779 pJ
sum error= 352
Actual label: 9
Output voltages: [0.10483, 0.0065655, 0.029531, 0.011572, 0.26543, 0.0034159, 0.0026366, 0.032892, 0.52911, 0.7923]
Predicted label: 9
Correct prediction
Energy consumption = 149.620594 pJ
sum error= 352
Actual label: 8
Output voltages: [0.055297, 0.021824, 0.29929, 0.085542, 0.01938, 0.13437, 0.061201, 0.022617, 0.79871, 0.015494]
Predicted label: 8
Correct prediction
Energy consumption = 142.551743 pJ
sum error= 352
Actual label: 8
Output voltages: [0.028767, 0.032698, 0.32147, 0.21764, 0.0027433, 0.018932, 0.21434, 0.0605, 0.7987, 0.0062605]
Predicted label: 8
Correct prediction
Energy consumption = 138.063606 pJ
sum error= 352
Actual label: 4
Output voltages: [0.0077003, 0.054185, 0.018757, 0.0018072, 0.79878, 0.013557, 0.67712, 0.35666, 0.081485, 0.029546]
Predicted label: 4
Correct prediction
Energy consumption = 157.396818 pJ
sum error= 352
Actual label: 7
Output voltages: [0.053097, 0.15834, 0.14504, 0.39139, 0.0012492, 0.0011876, 0.0012606, 0.79879, 0.40157, 0.41825]
Predicted label: 7
Correct prediction
Energy consumption = 148.070085 pJ
sum error= 352
Actual label: 7
Output voltages: [0.045709, 0.15112, 0.031979, 0.15651, 0.0025943, 0.0015059, 0.0010953, 0.79863, 0.036276, 0.18189]
Predicted label: 7
Correct prediction
Energy consumption = 139.194424 pJ
sum error= 352
Actual label: 6
Output voltages: [0.2416, 0.058212, 0.35543, 0.013897, 0.20914, 0.33087, 0.79867, 0.0047633, 0.25906, 0.045695]
Predicted label: 6
Correct prediction
Energy consumption = 151.999738 pJ
sum error= 352
Actual label: 2
Output voltages: [0.19005, 0.41229, 0.7987, 0.22234, 0.010618, 0.0012232, 0.17781, 0.017371, 0.26939, 0.078107]
Predicted label: 2
Correct prediction
Energy consumption = 151.211251 pJ
sum error= 352
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 957 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 957 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 957 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.032058, 0.79865, 0.16916, 0.016968, 0.15123, 0.0011938, 0.69823, 0.0049914, 0.18611, 0.019918]
Predicted label: 1
Correct prediction
Energy consumption = 160.927676 pJ
sum error= 352
Actual label: 9
Output voltages: [0.24747, 0.0080443, 0.015413, 0.0085683, 0.048889, 0.017332, 0.0012343, 0.013336, 0.74117, 0.79258]
Predicted label: 9
Correct prediction
Energy consumption = 148.035828 pJ
sum error= 352
Actual label: 8
Output voltages: [0.011479, 0.0073797, 0.038478, 0.14901, 0.029629, 0.056429, 0.084523, 0.0023931, 0.79876, 0.26205]
Predicted label: 8
Correct prediction
Energy consumption = 144.354383 pJ
sum error= 352
Actual label: 7
Output voltages: [0.046557, 0.15863, 0.5924, 0.043228, 0.0019505, 0.0011393, 0.0010984, 0.79874, 0.76075, 0.028357]
Predicted label: 7
Correct prediction
Energy consumption = 145.564053 pJ
sum error= 352
Actual label: 8
Output voltages: [0.031454, 0.021551, 0.1493, 0.040318, 0.019639, 0.032843, 0.028743, 0.013078, 0.79864, 0.060759]
Predicted label: 8
Correct prediction
Energy consumption = 142.784514 pJ
sum error= 352
Actual label: 8
Output voltages: [0.042538, 0.051946, 0.11794, 0.40912, 0.0022022, 0.044472, 0.015604, 0.0026103, 0.79873, 0.38916]
Predicted label: 8
Correct prediction
Energy consumption = 138.375114 pJ
sum error= 352
Actual label: 7
Output voltages: [0.070035, 0.026901, 0.020219, 0.12596, 0.033156, 0.0010756, 0.001305, 0.79707, 0.30266, 0.27778]
Predicted label: 7
Correct prediction
Energy consumption = 159.025860 pJ
sum error= 352
Actual label: 2
Output voltages: [0.081249, 0.2034, 0.79835, 0.025638, 0.013578, 0.0013833, 0.040231, 0.48366, 0.39322, 0.006576]
Predicted label: 2
Correct prediction
Energy consumption = 147.824934 pJ
sum error= 352
Actual label: 2
Output voltages: [0.27455, 0.030601, 0.7986, 0.010509, 0.0044399, 0.0011156, 0.080055, 0.29802, 0.72984, 0.0043257]
Predicted label: 2
Correct prediction
Energy consumption = 131.312741 pJ
sum error= 352
Actual label: 3
Output voltages: [0.31365, 0.016876, 0.11869, 0.79874, 0.038306, 0.034696, 0.031722, 0.0032885, 0.48674, 0.0559]
Predicted label: 3
Correct prediction
Energy consumption = 143.446400 pJ
sum error= 352
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 958 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 958 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 958 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.44356, 0.0065961, 0.0094869, 0.041743, 0.19092, 0.0030887, 0.0014112, 0.0059428, 0.44394, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 154.608137 pJ
sum error= 352
Actual label: 3
Output voltages: [0.15804, 0.01867, 0.35577, 0.79871, 0.018779, 0.010499, 0.0065874, 0.054218, 0.47253, 0.041009]
Predicted label: 3
Correct prediction
Energy consumption = 144.600148 pJ
sum error= 352
Actual label: 3
Output voltages: [0.44835, 0.013248, 0.044662, 0.79868, 0.01118, 0.029409, 0.007442, 0.013998, 0.60418, 0.032306]
Predicted label: 3
Correct prediction
Energy consumption = 135.795794 pJ
sum error= 352
Actual label: 5
Output voltages: [0.055117, 0.0010668, 0.0011027, 0.65762, 0.055235, 0.7985, 0.035335, 0.018882, 0.65626, 0.02199]
Predicted label: 5
Correct prediction
Energy consumption = 139.546766 pJ
sum error= 352
Actual label: 5
Output voltages: [0.20722, 0.0011535, 0.0021071, 0.039448, 0.018551, 0.79869, 0.046997, 0.042115, 0.7805, 0.0029874]
Predicted label: 5
Correct prediction
Energy consumption = 134.256915 pJ
sum error= 352
Actual label: 0
Output voltages: [0.7982, 0.16586, 0.033273, 0.022311, 0.0050581, 0.004065, 0.73701, 0.040601, 0.15256, 0.049257]
Predicted label: 0
Correct prediction
Energy consumption = 150.607113 pJ
sum error= 352
Actual label: 7
Output voltages: [0.43446, 0.011934, 0.22373, 0.46232, 0.0044205, 0.0012326, 0.0011216, 0.79877, 0.12843, 0.021805]
Predicted label: 7
Correct prediction
Energy consumption = 152.499304 pJ
sum error= 352
Actual label: 9
Output voltages: [0.34922, 0.0080283, 0.041098, 0.41157, 0.78713, 0.0012574, 0.0020957, 0.043488, 0.040174, 0.79304]
Predicted label: 9
Correct prediction
Energy consumption = 148.695116 pJ
sum error= 352
Actual label: 5
Output voltages: [0.017665, 0.0010676, 0.013206, 0.044317, 0.014296, 0.79499, 0.068328, 0.0030818, 0.78323, 0.02959]
Predicted label: 5
Correct prediction
Energy consumption = 146.595774 pJ
sum error= 352
Actual label: 6
Output voltages: [0.01274, 0.027087, 0.40607, 0.0021842, 0.17453, 0.25249, 0.79874, 0.0073814, 0.41389, 0.0024261]
Predicted label: 6
Correct prediction
Energy consumption = 147.452500 pJ
sum error= 352
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 959 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 959 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 959 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.035023, 0.0012289, 0.0049766, 0.22635, 0.02727, 0.79841, 0.11918, 0.003037, 0.77459, 0.0062341]
Predicted label: 5
Correct prediction
Energy consumption = 145.264968 pJ
sum error= 352
Actual label: 1
Output voltages: [0.31831, 0.79442, 0.025929, 0.032317, 0.62786, 0.0011872, 0.51193, 0.0011324, 0.33935, 0.18709]
Predicted label: 1
Correct prediction
Energy consumption = 157.543004 pJ
sum error= 352
Actual label: 4
Output voltages: [0.012229, 0.0018628, 0.03803, 0.0010749, 0.79879, 0.0030497, 0.32771, 0.2999, 0.64425, 0.0022624]
Predicted label: 4
Correct prediction
Energy consumption = 144.897619 pJ
sum error= 352
Actual label: 1
Output voltages: [0.019924, 0.79875, 0.030846, 0.013124, 0.25106, 0.0010713, 0.56603, 0.00118, 0.044733, 0.048951]
Predicted label: 1
Correct prediction
Energy consumption = 158.720025 pJ
sum error= 352
Actual label: 1
Output voltages: [0.035263, 0.79219, 0.0038628, 0.01531, 0.63678, 0.0036875, 0.73056, 0.0010867, 0.73077, 0.093664]
Predicted label: 1
Correct prediction
Energy consumption = 147.601817 pJ
sum error= 352
Actual label: 2
Output voltages: [0.1866, 0.0042076, 0.79845, 0.068522, 0.021216, 0.0010659, 0.080983, 0.71544, 0.77136, 0.001291]
Predicted label: 2
Correct prediction
Energy consumption = 138.930680 pJ
sum error= 352
Actual label: 8
Output voltages: [0.18809, 0.0047058, 0.022617, 0.2256, 0.0010691, 0.031106, 0.0011388, 0.023701, 0.79856, 0.40353]
Predicted label: 8
Correct prediction
Energy consumption = 138.028763 pJ
sum error= 352
Actual label: 2
Output voltages: [0.583, 0.020205, 0.79877, 0.06232, 0.02577, 0.0010866, 0.012519, 0.015976, 0.45902, 0.01398]
Predicted label: 2
Correct prediction
Energy consumption = 141.353717 pJ
sum error= 352
Actual label: 6
Output voltages: [0.055861, 0.02714, 0.31701, 0.0011951, 0.27358, 0.2404, 0.79877, 0.0036288, 0.40691, 0.0029197]
Predicted label: 6
Correct prediction
Energy consumption = 146.620826 pJ
sum error= 352
Actual label: 1
Output voltages: [0.025396, 0.79873, 0.01286, 0.28748, 0.032387, 0.0017767, 0.71296, 0.0082916, 0.055305, 0.023941]
Predicted label: 1
Correct prediction
Energy consumption = 158.657925 pJ
sum error= 352
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 960 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 960 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 960 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.052539, 0.0012041, 0.0012108, 0.19815, 0.23821, 0.76596, 0.26821, 0.0019226, 0.7813, 0.012136]
Predicted label: 8
Wrong prediction!
Energy consumption = 140.219732 pJ
sum error= 353
Actual label: 0
Output voltages: [0.79876, 0.036515, 0.1072, 0.01636, 0.011398, 0.0044775, 0.49108, 0.048951, 0.090455, 0.047429]
Predicted label: 0
Correct prediction
Energy consumption = 148.655688 pJ
sum error= 353
Actual label: 1
Output voltages: [0.036301, 0.7987, 0.16708, 0.19444, 0.45595, 0.0011173, 0.33584, 0.011615, 0.023117, 0.042014]
Predicted label: 1
Correct prediction
Energy consumption = 159.947723 pJ
sum error= 353
Actual label: 2
Output voltages: [0.32589, 0.084196, 0.7987, 0.21695, 0.024887, 0.0011483, 0.26074, 0.038484, 0.37074, 0.16246]
Predicted label: 2
Correct prediction
Energy consumption = 137.269552 pJ
sum error= 353
Actual label: 3
Output voltages: [0.16563, 0.016102, 0.28678, 0.79878, 0.050868, 0.019629, 0.12739, 0.014422, 0.38457, 0.017912]
Predicted label: 3
Correct prediction
Energy consumption = 145.200891 pJ
sum error= 353
Actual label: 4
Output voltages: [0.079858, 0.0054804, 0.54593, 0.046357, 0.79877, 0.0012903, 0.0029806, 0.20044, 0.036207, 0.046827]
Predicted label: 4
Correct prediction
Energy consumption = 142.850329 pJ
sum error= 353
Actual label: 5
Output voltages: [0.31048, 0.014893, 0.0012062, 0.58964, 0.033596, 0.79867, 0.14322, 0.012642, 0.42146, 0.011795]
Predicted label: 5
Correct prediction
Energy consumption = 141.037254 pJ
sum error= 353
Actual label: 6
Output voltages: [0.2184, 0.39894, 0.16994, 0.031853, 0.029905, 0.18104, 0.79837, 0.011863, 0.41311, 0.0021601]
Predicted label: 6
Correct prediction
Energy consumption = 143.710531 pJ
sum error= 353
Actual label: 7
Output voltages: [0.43743, 0.0087464, 0.23471, 0.46103, 0.0019335, 0.0010972, 0.001094, 0.79874, 0.050594, 0.51352]
Predicted label: 7
Correct prediction
Energy consumption = 154.546507 pJ
sum error= 353
Actual label: 8
Output voltages: [0.01621, 0.084031, 0.22432, 0.071174, 0.022903, 0.011441, 0.02973, 0.0082236, 0.79874, 0.29017]
Predicted label: 8
Correct prediction
Energy consumption = 133.785108 pJ
sum error= 353
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 961 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 961 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 961 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.054088, 0.014065, 0.020214, 0.31169, 0.0047416, 0.013423, 0.0010972, 0.19096, 0.75063, 0.78686]
Predicted label: 9
Correct prediction
Energy consumption = 150.127272 pJ
sum error= 353
Actual label: 0
Output voltages: [0.79879, 0.027118, 0.029164, 0.0054822, 0.012447, 0.010054, 0.53263, 0.012914, 0.055148, 0.03225]
Predicted label: 0
Correct prediction
Energy consumption = 143.139022 pJ
sum error= 353
Actual label: 1
Output voltages: [0.0020106, 0.78762, 0.59737, 0.67623, 0.5824, 0.0012504, 0.0084461, 0.047804, 0.024926, 0.71582]
Predicted label: 1
Correct prediction
Energy consumption = 153.837370 pJ
sum error= 353
Actual label: 2
Output voltages: [0.14438, 0.13385, 0.79871, 0.3537, 0.039939, 0.0012527, 0.17367, 0.01966, 0.62071, 0.28457]
Predicted label: 2
Correct prediction
Energy consumption = 138.700143 pJ
sum error= 353
Actual label: 3
Output voltages: [0.72795, 0.001213, 0.15796, 0.79877, 0.032524, 0.29342, 0.0016146, 0.026282, 0.49283, 0.0013347]
Predicted label: 3
Correct prediction
Energy consumption = 136.958277 pJ
sum error= 353
Actual label: 4
Output voltages: [0.013015, 0.0018342, 0.19221, 0.0031948, 0.79872, 0.0016686, 0.075539, 0.24942, 0.13324, 0.015361]
Predicted label: 4
Correct prediction
Energy consumption = 146.033881 pJ
sum error= 353
Actual label: 5
Output voltages: [0.013362, 0.0011741, 0.0018385, 0.56008, 0.018183, 0.79879, 0.23703, 0.033671, 0.76449, 0.0097614]
Predicted label: 5
Correct prediction
Energy consumption = 142.521426 pJ
sum error= 353
Actual label: 6
Output voltages: [0.1279, 0.034423, 0.22047, 0.0060182, 0.62162, 0.033425, 0.79878, 0.0064199, 0.3991, 0.0030564]
Predicted label: 6
Correct prediction
Energy consumption = 143.978354 pJ
sum error= 353
Actual label: 7
Output voltages: [0.51451, 0.10555, 0.79735, 0.029503, 0.0010837, 0.0011507, 0.013536, 0.79439, 0.13987, 0.026536]
Predicted label: 2
Wrong prediction!
Energy consumption = 150.032710 pJ
sum error= 354
Actual label: 8
Output voltages: [0.16324, 0.018415, 0.34571, 0.032495, 0.0061683, 0.029782, 0.010866, 0.0092032, 0.79871, 0.096799]
Predicted label: 8
Correct prediction
Energy consumption = 138.374653 pJ
sum error= 354
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 962 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 962 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 962 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.053393, 0.0021541, 0.0011425, 0.045684, 0.39416, 0.022326, 0.0018872, 0.64463, 0.36979, 0.75978]
Predicted label: 9
Correct prediction
Energy consumption = 153.851498 pJ
sum error= 354
Actual label: 0
Output voltages: [0.79877, 0.060138, 0.0076467, 0.017346, 0.021916, 0.034871, 0.64713, 0.028313, 0.18587, 0.029744]
Predicted label: 0
Correct prediction
Energy consumption = 145.171802 pJ
sum error= 354
Actual label: 1
Output voltages: [0.0023843, 0.79877, 0.34502, 0.056855, 0.61505, 0.0010925, 0.41343, 0.025266, 0.38191, 0.29343]
Predicted label: 1
Correct prediction
Energy consumption = 159.264628 pJ
sum error= 354
Actual label: 2
Output voltages: [0.2488, 0.13017, 0.79879, 0.29212, 0.024263, 0.0011921, 0.021652, 0.12796, 0.43923, 0.0076101]
Predicted label: 2
Correct prediction
Energy consumption = 143.207743 pJ
sum error= 354
Actual label: 3
Output voltages: [0.021372, 0.0078159, 0.32168, 0.79876, 0.0061081, 0.0024957, 0.014018, 0.0026713, 0.79047, 0.021775]
Predicted label: 3
Correct prediction
Energy consumption = 133.265890 pJ
sum error= 354
Actual label: 4
Output voltages: [0.048354, 0.0010804, 0.28246, 0.020451, 0.79812, 0.0010674, 0.0012685, 0.009514, 0.082175, 0.65752]
Predicted label: 4
Correct prediction
Energy consumption = 148.261182 pJ
sum error= 354
Actual label: 5
Output voltages: [0.12056, 0.0030081, 0.001066, 0.61153, 0.049219, 0.7987, 0.11701, 0.0039267, 0.43446, 0.0033792]
Predicted label: 5
Correct prediction
Energy consumption = 140.534904 pJ
sum error= 354
Actual label: 6
Output voltages: [0.073227, 0.017088, 0.32483, 0.015834, 0.73057, 0.035751, 0.7981, 0.0031548, 0.57352, 0.0010739]
Predicted label: 6
Correct prediction
Energy consumption = 137.596639 pJ
sum error= 354
Actual label: 7
Output voltages: [0.70413, 0.01156, 0.66588, 0.05225, 0.0016322, 0.0010859, 0.0019456, 0.79861, 0.55684, 0.032324]
Predicted label: 7
Correct prediction
Energy consumption = 146.001967 pJ
sum error= 354
Actual label: 8
Output voltages: [0.024706, 0.0026418, 0.12951, 0.0085614, 0.08241, 0.10114, 0.041261, 0.0020348, 0.79873, 0.011325]
Predicted label: 8
Correct prediction
Energy consumption = 133.972265 pJ
sum error= 354
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 963 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 963 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 963 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.014553, 0.024358, 0.22523, 0.047173, 0.0050259, 0.018054, 0.026726, 0.030786, 0.79865, 0.045669]
Predicted label: 8
Correct prediction
Energy consumption = 150.170891 pJ
sum error= 354
Actual label: 0
Output voltages: [0.79804, 0.086532, 0.21316, 0.033388, 0.016698, 0.0017552, 0.49571, 0.0079374, 0.3484, 0.047283]
Predicted label: 0
Correct prediction
Energy consumption = 150.715652 pJ
sum error= 354
Actual label: 6
Output voltages: [0.092615, 0.04657, 0.19654, 0.012324, 0.21562, 0.32356, 0.79879, 0.0017782, 0.53445, 0.0045533]
Predicted label: 6
Correct prediction
Energy consumption = 136.811473 pJ
sum error= 354
Actual label: 0
Output voltages: [0.79879, 0.028309, 0.038373, 0.021934, 0.054651, 0.0011912, 0.05857, 0.030903, 0.49314, 0.034765]
Predicted label: 0
Correct prediction
Energy consumption = 143.066698 pJ
sum error= 354
Actual label: 0
Output voltages: [0.65441, 0.18397, 0.066515, 0.18875, 0.0013229, 0.0011886, 0.50265, 0.001069, 0.79075, 0.030128]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.560349 pJ
sum error= 355
Actual label: 2
Output voltages: [0.35486, 0.13086, 0.79864, 0.19762, 0.021137, 0.0011111, 0.25577, 0.14246, 0.18792, 0.13667]
Predicted label: 2
Correct prediction
Energy consumption = 140.712046 pJ
sum error= 355
Actual label: 3
Output voltages: [0.46302, 0.016854, 0.054844, 0.79879, 0.012576, 0.40116, 0.024734, 0.040936, 0.39811, 0.0038525]
Predicted label: 3
Correct prediction
Energy consumption = 142.628808 pJ
sum error= 355
Actual label: 7
Output voltages: [0.57923, 0.01058, 0.1042, 0.29438, 0.001199, 0.0011021, 0.0010795, 0.79879, 0.42535, 0.14244]
Predicted label: 7
Correct prediction
Energy consumption = 140.958536 pJ
sum error= 355
Actual label: 9
Output voltages: [0.60793, 0.021659, 0.017502, 0.021791, 0.015232, 0.023274, 0.0015176, 0.24034, 0.51147, 0.79786]
Predicted label: 9
Correct prediction
Energy consumption = 141.085264 pJ
sum error= 355
Actual label: 4
Output voltages: [0.0041139, 0.010804, 0.02262, 0.0056068, 0.79854, 0.0012977, 0.04339, 0.27628, 0.10501, 0.0077034]
Predicted label: 4
Correct prediction
Energy consumption = 149.857655 pJ
sum error= 355
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 964 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 964 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 964 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.040821, 0.22782, 0.74958, 0.15748, 0.0016197, 0.0010852, 0.0010872, 0.79871, 0.44768, 0.33828]
Predicted label: 7
Correct prediction
Energy consumption = 150.004482 pJ
sum error= 355
Actual label: 1
Output voltages: [0.10081, 0.79875, 0.022706, 0.080601, 0.76502, 0.0010751, 0.24387, 0.0010736, 0.031277, 0.35615]
Predicted label: 1
Correct prediction
Energy consumption = 155.363212 pJ
sum error= 355
Actual label: 9
Output voltages: [0.63691, 0.002119, 0.04949, 0.03395, 0.28992, 0.022786, 0.0031598, 0.33693, 0.11061, 0.79594]
Predicted label: 9
Correct prediction
Energy consumption = 147.236648 pJ
sum error= 355
Actual label: 1
Output voltages: [0.052085, 0.7974, 0.039971, 0.22508, 0.51586, 0.0011504, 0.0010704, 0.025005, 0.0562, 0.16852]
Predicted label: 1
Correct prediction
Energy consumption = 152.233031 pJ
sum error= 355
Actual label: 7
Output voltages: [0.39258, 0.040991, 0.17551, 0.38276, 0.0050602, 0.0011709, 0.0010698, 0.79866, 0.040232, 0.30194]
Predicted label: 7
Correct prediction
Energy consumption = 145.771470 pJ
sum error= 355
Actual label: 1
Output voltages: [0.014595, 0.79878, 0.029773, 0.00978, 0.74269, 0.0010661, 0.014332, 0.046089, 0.013171, 0.15582]
Predicted label: 1
Correct prediction
Energy consumption = 154.595908 pJ
sum error= 355
Actual label: 4
Output voltages: [0.014218, 0.010979, 0.019309, 0.025179, 0.79879, 0.0011405, 0.019726, 0.53656, 0.39652, 0.014234]
Predicted label: 4
Correct prediction
Energy consumption = 139.072916 pJ
sum error= 355
Actual label: 0
Output voltages: [0.79877, 0.061755, 0.036493, 0.021356, 0.0085221, 0.012934, 0.42294, 0.15915, 0.0545, 0.027438]
Predicted label: 0
Correct prediction
Energy consumption = 148.219719 pJ
sum error= 355
Actual label: 0
Output voltages: [0.79875, 0.045612, 0.13961, 0.0090124, 0.012764, 0.0017891, 0.32103, 0.054401, 0.18773, 0.019557]
Predicted label: 0
Correct prediction
Energy consumption = 132.114957 pJ
sum error= 355
Actual label: 1
Output voltages: [0.0030215, 0.79878, 0.17653, 0.065508, 0.1265, 0.001066, 0.051994, 0.0068188, 0.16863, 0.15885]
Predicted label: 1
Correct prediction
Energy consumption = 141.290653 pJ
sum error= 355
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 965 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 965 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 965 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.68612, 0.032794, 0.0070104, 0.072681, 0.13676, 0.076566, 0.0020078, 0.79859, 0.021861, 0.05085]
Predicted label: 7
Correct prediction
Energy consumption = 148.873701 pJ
sum error= 355
Actual label: 5
Output voltages: [0.018946, 0.012922, 0.0011192, 0.68541, 0.029493, 0.79871, 0.031341, 0.013864, 0.39634, 0.0067757]
Predicted label: 5
Correct prediction
Energy consumption = 139.092952 pJ
sum error= 355
Actual label: 7
Output voltages: [0.18903, 0.047104, 0.43612, 0.13026, 0.023816, 0.0036917, 0.00189, 0.7974, 0.034881, 0.73891]
Predicted label: 7
Correct prediction
Energy consumption = 149.667512 pJ
sum error= 355
Actual label: 1
Output voltages: [0.013802, 0.79771, 0.082767, 0.024753, 0.28221, 0.0011155, 0.021881, 0.0070174, 0.23103, 0.22638]
Predicted label: 1
Correct prediction
Energy consumption = 155.438058 pJ
sum error= 355
Actual label: 3
Output voltages: [0.56285, 0.0096358, 0.046995, 0.79867, 0.0065385, 0.040953, 0.0024092, 0.022708, 0.64471, 0.0078664]
Predicted label: 3
Correct prediction
Energy consumption = 137.831134 pJ
sum error= 355
Actual label: 3
Output voltages: [0.017093, 0.0015059, 0.058141, 0.79879, 0.013533, 0.40772, 0.014922, 0.012148, 0.75425, 0.025611]
Predicted label: 3
Correct prediction
Energy consumption = 129.975935 pJ
sum error= 355
Actual label: 3
Output voltages: [0.57986, 0.0010689, 0.68254, 0.79738, 0.014567, 0.29672, 0.0011472, 0.0091047, 0.68444, 0.0017249]
Predicted label: 3
Correct prediction
Energy consumption = 124.579806 pJ
sum error= 355
Actual label: 1
Output voltages: [0.026629, 0.79878, 0.54049, 0.0049576, 0.39883, 0.0010971, 0.40643, 0.0018969, 0.11429, 0.10879]
Predicted label: 1
Correct prediction
Energy consumption = 157.966151 pJ
sum error= 355
Actual label: 6
Output voltages: [0.043703, 0.015937, 0.49374, 0.0013022, 0.2991, 0.22918, 0.79878, 0.0078637, 0.69128, 0.0017702]
Predicted label: 6
Correct prediction
Energy consumption = 139.354044 pJ
sum error= 355
Actual label: 9
Output voltages: [0.23502, 0.023697, 0.022246, 0.10009, 0.15209, 0.010271, 0.0076188, 0.024398, 0.48654, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 154.446687 pJ
sum error= 355
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 966 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 966 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 966 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.37871, 0.039026, 0.30554, 0.01864, 0.01574, 0.0010731, 0.001393, 0.79869, 0.05281, 0.015389]
Predicted label: 7
Correct prediction
Energy consumption = 149.633288 pJ
sum error= 355
Actual label: 1
Output voltages: [0.015686, 0.79873, 0.029612, 0.032796, 0.49127, 0.0010838, 0.22377, 0.0017043, 0.32186, 0.14853]
Predicted label: 1
Correct prediction
Energy consumption = 156.605568 pJ
sum error= 355
Actual label: 3
Output voltages: [0.075328, 0.0055536, 0.68353, 0.79854, 0.016322, 0.0017522, 0.013088, 0.0058343, 0.78827, 0.010374]
Predicted label: 3
Correct prediction
Energy consumption = 140.141235 pJ
sum error= 355
Actual label: 0
Output voltages: [0.79818, 0.016738, 0.15568, 0.0049185, 0.041406, 0.0028322, 0.47772, 0.10622, 0.31015, 0.012151]
Predicted label: 0
Correct prediction
Energy consumption = 146.121814 pJ
sum error= 355
Actual label: 2
Output voltages: [0.40054, 0.023268, 0.79861, 0.046105, 0.0075196, 0.0011621, 0.0041661, 0.77546, 0.58092, 0.046489]
Predicted label: 2
Correct prediction
Energy consumption = 135.074395 pJ
sum error= 355
Actual label: 6
Output voltages: [0.13471, 0.01374, 0.069967, 0.0028375, 0.48554, 0.14586, 0.79875, 0.0019698, 0.68936, 0.0097813]
Predicted label: 6
Correct prediction
Energy consumption = 141.607072 pJ
sum error= 355
Actual label: 0
Output voltages: [0.79851, 0.011978, 0.1773, 0.016751, 0.039834, 0.0011006, 0.27825, 0.01071, 0.37059, 0.04024]
Predicted label: 0
Correct prediction
Energy consumption = 147.123525 pJ
sum error= 355
Actual label: 8
Output voltages: [0.0085639, 0.06193, 0.28853, 0.033799, 0.007417, 0.022409, 0.0070778, 0.03696, 0.7987, 0.1204]
Predicted label: 8
Correct prediction
Energy consumption = 148.878648 pJ
sum error= 355
Actual label: 9
Output voltages: [0.34838, 0.028502, 0.023039, 0.04004, 0.14281, 0.0099927, 0.0032249, 0.0042616, 0.45287, 0.79879]
Predicted label: 9
Correct prediction
Energy consumption = 147.116829 pJ
sum error= 355
Actual label: 4
Output voltages: [0.0023633, 0.056114, 0.013727, 0.32962, 0.79836, 0.0056817, 0.001188, 0.028317, 0.010242, 0.37736]
Predicted label: 4
Correct prediction
Energy consumption = 143.035298 pJ
sum error= 355
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 967 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 967 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 967 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.054177, 0.026815, 0.046848, 0.79877, 0.006669, 0.042131, 0.0021058, 0.0041464, 0.70509, 0.019879]
Predicted label: 3
Correct prediction
Energy consumption = 141.518763 pJ
sum error= 355
Actual label: 5
Output voltages: [0.048732, 0.013327, 0.0011305, 0.31547, 0.041553, 0.79877, 0.095918, 0.0019223, 0.55122, 0.027456]
Predicted label: 5
Correct prediction
Energy consumption = 140.070758 pJ
sum error= 355
Actual label: 4
Output voltages: [0.011864, 0.0059362, 0.023916, 0.019689, 0.79868, 0.0064075, 0.26927, 0.18065, 0.18444, 0.011009]
Predicted label: 4
Correct prediction
Energy consumption = 153.374187 pJ
sum error= 355
Actual label: 8
Output voltages: [0.03704, 0.006063, 0.043946, 0.05789, 0.011502, 0.031564, 0.0094199, 0.0091931, 0.79876, 0.054613]
Predicted label: 8
Correct prediction
Energy consumption = 140.564661 pJ
sum error= 355
Actual label: 1
Output voltages: [0.021059, 0.79879, 0.4336, 0.0025136, 0.5709, 0.0014323, 0.28897, 0.022053, 0.27797, 0.067689]
Predicted label: 1
Correct prediction
Energy consumption = 156.981006 pJ
sum error= 355
Actual label: 5
Output voltages: [0.38688, 0.0013456, 0.0011211, 0.38961, 0.036586, 0.79871, 0.22615, 0.014292, 0.54413, 0.043672]
Predicted label: 5
Correct prediction
Energy consumption = 142.531568 pJ
sum error= 355
Actual label: 9
Output voltages: [0.2451, 0.014233, 0.013118, 0.27331, 0.35805, 0.011524, 0.0030224, 0.0087234, 0.41377, 0.79868]
Predicted label: 9
Correct prediction
Energy consumption = 139.950064 pJ
sum error= 355
Actual label: 0
Output voltages: [0.79876, 0.019426, 0.51575, 0.062616, 0.032718, 0.0011041, 0.11706, 0.036718, 0.28889, 0.032625]
Predicted label: 0
Correct prediction
Energy consumption = 145.713280 pJ
sum error= 355
Actual label: 6
Output voltages: [0.19587, 0.018442, 0.63058, 0.0013035, 0.58022, 0.18016, 0.7979, 0.005549, 0.065171, 0.0011022]
Predicted label: 6
Correct prediction
Energy consumption = 139.021091 pJ
sum error= 355
Actual label: 6
Output voltages: [0.0042767, 0.6858, 0.078423, 0.71217, 0.036339, 0.60167, 0.59204, 0.022447, 0.0016702, 0.0010974]
Predicted label: 3
Wrong prediction!
Energy consumption = 138.509221 pJ
sum error= 356
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 968 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 968 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 968 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.051564, 0.0097596, 0.047477, 0.79874, 0.0092224, 0.001785, 0.0072806, 0.013117, 0.73631, 0.041908]
Predicted label: 3
Correct prediction
Energy consumption = 146.190358 pJ
sum error= 356
Actual label: 8
Output voltages: [0.040048, 0.023155, 0.076341, 0.46555, 0.0011903, 0.31927, 0.0051957, 0.0074163, 0.79869, 0.12462]
Predicted label: 8
Correct prediction
Energy consumption = 143.993332 pJ
sum error= 356
Actual label: 1
Output voltages: [0.017982, 0.79879, 0.44724, 0.22991, 0.089039, 0.0010803, 0.04953, 0.0016873, 0.22869, 0.14518]
Predicted label: 1
Correct prediction
Energy consumption = 162.364850 pJ
sum error= 356
Actual label: 4
Output voltages: [0.0087202, 0.0067162, 0.024953, 0.056935, 0.79871, 0.0010715, 0.011474, 0.024937, 0.23321, 0.13352]
Predicted label: 4
Correct prediction
Energy consumption = 152.299771 pJ
sum error= 356
Actual label: 7
Output voltages: [0.74165, 0.017505, 0.0057523, 0.039914, 0.27764, 0.024817, 0.0010871, 0.79865, 0.04129, 0.021694]
Predicted label: 7
Correct prediction
Energy consumption = 145.540395 pJ
sum error= 356
Actual label: 5
Output voltages: [0.19915, 0.0010916, 0.0010661, 0.51643, 0.4982, 0.79873, 0.23458, 0.021675, 0.14053, 0.072992]
Predicted label: 5
Correct prediction
Energy consumption = 141.309739 pJ
sum error= 356
Actual label: 2
Output voltages: [0.4144, 0.38233, 0.79879, 0.64432, 0.018724, 0.0012537, 0.030767, 0.053351, 0.063531, 0.04297]
Predicted label: 2
Correct prediction
Energy consumption = 147.316915 pJ
sum error= 356
Actual label: 0
Output voltages: [0.79682, 0.38097, 0.06918, 0.22207, 0.0010786, 0.0036538, 0.57438, 0.0037684, 0.46064, 0.033846]
Predicted label: 0
Correct prediction
Energy consumption = 156.770545 pJ
sum error= 356
Actual label: 0
Output voltages: [0.7987, 0.024406, 0.013357, 0.013432, 0.021314, 0.027335, 0.2528, 0.075541, 0.25455, 0.025665]
Predicted label: 0
Correct prediction
Energy consumption = 136.544006 pJ
sum error= 356
Actual label: 1
Output voltages: [0.013452, 0.79873, 0.16039, 0.02213, 0.74754, 0.001151, 0.08863, 0.0089891, 0.022889, 0.33215]
Predicted label: 1
Correct prediction
Energy consumption = 156.097735 pJ
sum error= 356
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 969 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 969 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 969 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.62144, 0.017282, 0.023326, 0.068606, 0.016718, 0.0018511, 0.0010661, 0.79872, 0.11561, 0.13753]
Predicted label: 7
Correct prediction
Energy consumption = 151.491115 pJ
sum error= 356
Actual label: 8
Output voltages: [0.02371, 0.023149, 0.059842, 0.28428, 0.0015558, 0.11915, 0.0095323, 0.015312, 0.79868, 0.040498]
Predicted label: 8
Correct prediction
Energy consumption = 141.287422 pJ
sum error= 356
Actual label: 9
Output voltages: [0.25239, 0.04149, 0.035402, 0.4643, 0.027092, 0.0045308, 0.0011027, 0.7986, 0.59784, 0.57652]
Predicted label: 7
Wrong prediction!
Energy consumption = 158.330865 pJ
sum error= 357
Actual label: 6
Output voltages: [0.082782, 0.025072, 0.042833, 0.0062881, 0.01229, 0.32882, 0.79879, 0.011923, 0.76918, 0.011522]
Predicted label: 6
Correct prediction
Energy consumption = 143.102405 pJ
sum error= 357
Actual label: 8
Output voltages: [0.024734, 0.0029057, 0.34439, 0.34669, 0.0040822, 0.017308, 0.0011395, 0.013224, 0.79878, 0.02332]
Predicted label: 8
Correct prediction
Energy consumption = 141.983079 pJ
sum error= 357
Actual label: 8
Output voltages: [0.020961, 0.022333, 0.021176, 0.58161, 0.0012583, 0.041157, 0.0078951, 0.0035663, 0.79879, 0.18203]
Predicted label: 8
Correct prediction
Energy consumption = 134.841289 pJ
sum error= 357
Actual label: 2
Output voltages: [0.14085, 0.20549, 0.79878, 0.15079, 0.0066336, 0.0012086, 0.021632, 0.040374, 0.3476, 0.041406]
Predicted label: 2
Correct prediction
Energy consumption = 146.308078 pJ
sum error= 357
Actual label: 3
Output voltages: [0.15697, 0.0081348, 0.035252, 0.79862, 0.047835, 0.018348, 0.036666, 0.060524, 0.76541, 0.022964]
Predicted label: 3
Correct prediction
Energy consumption = 133.834141 pJ
sum error= 357
Actual label: 6
Output voltages: [0.081021, 0.24147, 0.022892, 0.067529, 0.051316, 0.54478, 0.60031, 0.22607, 0.15059, 0.0014995]
Predicted label: 6
Correct prediction
Energy consumption = 141.500410 pJ
sum error= 357
Actual label: 1
Output voltages: [0.051949, 0.76997, 0.36479, 0.0012693, 0.72447, 0.0010787, 0.022958, 0.0056055, 0.28035, 0.054768]
Predicted label: 1
Correct prediction
Energy consumption = 161.910814 pJ
sum error= 357
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 970 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 970 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 970 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.0038491, 0.010215, 0.79836, 0.22354, 0.021323, 0.0011413, 0.11015, 0.56263, 0.6004, 0.040436]
Predicted label: 2
Correct prediction
Energy consumption = 140.359720 pJ
sum error= 357
Actual label: 9
Output voltages: [0.35201, 0.076143, 0.022935, 0.040125, 0.038473, 0.20279, 0.042261, 0.13709, 0.078271, 0.79874]
Predicted label: 9
Correct prediction
Energy consumption = 160.062141 pJ
sum error= 357
Actual label: 5
Output voltages: [0.34049, 0.0010774, 0.0012199, 0.46955, 0.016306, 0.79864, 0.22823, 0.28305, 0.50508, 0.0050677]
Predicted label: 5
Correct prediction
Energy consumption = 140.762456 pJ
sum error= 357
Actual label: 2
Output voltages: [0.42384, 0.15784, 0.79873, 0.062232, 0.050951, 0.0011715, 0.33694, 0.022757, 0.23726, 0.10528]
Predicted label: 2
Correct prediction
Energy consumption = 146.673324 pJ
sum error= 357
Actual label: 0
Output voltages: [0.79877, 0.047052, 0.0231, 0.017647, 0.095563, 0.0082603, 0.38761, 0.017434, 0.39426, 0.2594]
Predicted label: 0
Correct prediction
Energy consumption = 151.807549 pJ
sum error= 357
Actual label: 1
Output voltages: [0.0078367, 0.79857, 0.057725, 0.06301, 0.0099728, 0.001085, 0.71165, 0.016322, 0.041849, 0.020108]
Predicted label: 1
Correct prediction
Energy consumption = 153.645847 pJ
sum error= 357
Actual label: 2
Output voltages: [0.19584, 0.12896, 0.79879, 0.59565, 0.0027322, 0.0011209, 0.29516, 0.043455, 0.038594, 0.0075589]
Predicted label: 2
Correct prediction
Energy consumption = 146.291057 pJ
sum error= 357
Actual label: 3
Output voltages: [0.37069, 0.0071985, 0.056477, 0.79865, 0.024723, 0.0052243, 0.018118, 0.015326, 0.64522, 0.02327]
Predicted label: 3
Correct prediction
Energy consumption = 139.411148 pJ
sum error= 357
Actual label: 4
Output voltages: [0.018181, 0.0082739, 0.06386, 0.0082894, 0.79872, 0.0039004, 0.24284, 0.021876, 0.10378, 0.0065485]
Predicted label: 4
Correct prediction
Energy consumption = 150.059384 pJ
sum error= 357
Actual label: 5
Output voltages: [0.25187, 0.011552, 0.0016664, 0.30969, 0.042949, 0.79879, 0.74703, 0.00416, 0.67923, 0.0031661]
Predicted label: 5
Correct prediction
Energy consumption = 140.069396 pJ
sum error= 357
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 971 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 971 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 971 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.69458, 0.023624, 0.042165, 0.0010977, 0.51331, 0.12919, 0.79877, 0.0011337, 0.41628, 0.02459]
Predicted label: 6
Correct prediction
Energy consumption = 146.536752 pJ
sum error= 357
Actual label: 7
Output voltages: [0.26399, 0.0020829, 0.009437, 0.020166, 0.7562, 0.0049597, 0.001222, 0.79879, 0.12564, 0.047803]
Predicted label: 7
Correct prediction
Energy consumption = 158.416301 pJ
sum error= 357
Actual label: 8
Output voltages: [0.052171, 0.048594, 0.19319, 0.059506, 0.0077255, 0.29418, 0.058362, 0.0045413, 0.79873, 0.019821]
Predicted label: 8
Correct prediction
Energy consumption = 148.523967 pJ
sum error= 357
Actual label: 9
Output voltages: [0.18084, 0.015199, 0.028903, 0.027893, 0.047791, 0.0091788, 0.011748, 0.03051, 0.71294, 0.79871]
Predicted label: 9
Correct prediction
Energy consumption = 135.621598 pJ
sum error= 357
Actual label: 0
Output voltages: [0.79706, 0.080833, 0.0037131, 0.024226, 0.0050739, 0.024473, 0.73706, 0.022928, 0.22389, 0.054136]
Predicted label: 0
Correct prediction
Energy consumption = 145.551588 pJ
sum error= 357
Actual label: 1
Output voltages: [0.016436, 0.79822, 0.13141, 0.13106, 0.34083, 0.0011842, 0.12247, 0.02985, 0.053303, 0.17731]
Predicted label: 1
Correct prediction
Energy consumption = 155.146937 pJ
sum error= 357
Actual label: 2
Output voltages: [0.79837, 0.28648, 0.78285, 0.60855, 0.0046123, 0.014951, 0.071845, 0.037504, 0.0032998, 0.021019]
Predicted label: 0
Wrong prediction!
Energy consumption = 157.292013 pJ
sum error= 358
Actual label: 3
Output voltages: [0.15151, 0.020222, 0.059076, 0.79862, 0.012904, 0.031676, 0.015663, 0.0097897, 0.74448, 0.032076]
Predicted label: 3
Correct prediction
Energy consumption = 147.295757 pJ
sum error= 358
Actual label: 4
Output voltages: [0.0024592, 0.0030055, 0.044459, 0.0091707, 0.79867, 0.001505, 0.60615, 0.28894, 0.27675, 0.016671]
Predicted label: 4
Correct prediction
Energy consumption = 150.471046 pJ
sum error= 358
Actual label: 5
Output voltages: [0.68665, 0.021051, 0.0015607, 0.64582, 0.0014725, 0.78343, 0.46365, 0.0017922, 0.47383, 0.0023233]
Predicted label: 5
Correct prediction
Energy consumption = 152.398096 pJ
sum error= 358
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 972 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 972 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 972 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.054237, 0.0013043, 0.011237, 0.037345, 0.1076, 0.72414, 0.78583, 0.0010675, 0.75093, 0.039668]
Predicted label: 6
Correct prediction
Energy consumption = 142.372006 pJ
sum error= 358
Actual label: 7
Output voltages: [0.040706, 0.039701, 0.028933, 0.2971, 0.0037999, 0.016852, 0.0011432, 0.79874, 0.24601, 0.64611]
Predicted label: 7
Correct prediction
Energy consumption = 151.843276 pJ
sum error= 358
Actual label: 8
Output voltages: [0.038377, 0.038593, 0.017731, 0.14307, 0.015652, 0.21178, 0.26942, 0.0035753, 0.79875, 0.017321]
Predicted label: 8
Correct prediction
Energy consumption = 149.476225 pJ
sum error= 358
Actual label: 9
Output voltages: [0.55324, 0.0033642, 0.027251, 0.015745, 0.27547, 0.012543, 0.0027115, 0.03233, 0.55162, 0.79854]
Predicted label: 9
Correct prediction
Energy consumption = 140.403013 pJ
sum error= 358
Actual label: 0
Output voltages: [0.79866, 0.051277, 0.037671, 0.018888, 0.021223, 0.033297, 0.42024, 0.060051, 0.062965, 0.02217]
Predicted label: 0
Correct prediction
Energy consumption = 135.026581 pJ
sum error= 358
Actual label: 1
Output voltages: [0.059333, 0.79879, 0.036203, 0.0016525, 0.2461, 0.0011509, 0.20456, 0.032215, 0.15835, 0.0012984]
Predicted label: 1
Correct prediction
Energy consumption = 149.684191 pJ
sum error= 358
Actual label: 2
Output voltages: [0.4798, 0.32856, 0.79879, 0.17007, 0.0016272, 0.0012304, 0.39977, 0.016734, 0.13275, 0.023329]
Predicted label: 2
Correct prediction
Energy consumption = 141.371784 pJ
sum error= 358
Actual label: 3
Output voltages: [0.23109, 0.0098017, 0.032371, 0.79871, 0.023939, 0.17826, 0.0022635, 0.019642, 0.71687, 0.02106]
Predicted label: 3
Correct prediction
Energy consumption = 140.890268 pJ
sum error= 358
Actual label: 4
Output voltages: [0.01806, 0.035604, 0.065731, 0.0046375, 0.79865, 0.001841, 0.10085, 0.031585, 0.022436, 0.031231]
Predicted label: 4
Correct prediction
Energy consumption = 146.387599 pJ
sum error= 358
Actual label: 5
Output voltages: [0.68435, 0.024327, 0.0028045, 0.018158, 0.36985, 0.79128, 0.79637, 0.0017948, 0.034908, 0.022938]
Predicted label: 6
Wrong prediction!
Energy consumption = 141.122060 pJ
sum error= 359
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 973 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 973 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 973 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.15547, 0.003467, 0.027436, 0.011375, 0.27821, 0.47717, 0.79858, 0.0011159, 0.76241, 0.015507]
Predicted label: 6
Correct prediction
Energy consumption = 144.325926 pJ
sum error= 359
Actual label: 7
Output voltages: [0.066339, 0.054755, 0.31035, 0.0090191, 0.24752, 0.0011486, 0.0012015, 0.79879, 0.29442, 0.11477]
Predicted label: 7
Correct prediction
Energy consumption = 145.012979 pJ
sum error= 359
Actual label: 8
Output voltages: [0.034333, 0.0036261, 0.024069, 0.32827, 0.0010848, 0.50966, 0.082367, 0.0095754, 0.79876, 0.048589]
Predicted label: 8
Correct prediction
Energy consumption = 145.859347 pJ
sum error= 359
Actual label: 9
Output voltages: [0.2662, 0.0012884, 0.025489, 0.0075559, 0.011653, 0.0091711, 0.0010967, 0.045622, 0.79547, 0.77877]
Predicted label: 8
Wrong prediction!
Energy consumption = 140.165606 pJ
sum error= 360
Actual label: 7
Output voltages: [0.44745, 0.073393, 0.016827, 0.085025, 0.18892, 0.017245, 0.0015191, 0.79879, 0.059345, 0.44092]
Predicted label: 7
Correct prediction
Energy consumption = 150.423987 pJ
sum error= 360
Actual label: 4
Output voltages: [0.0077855, 0.1103, 0.027955, 0.08415, 0.79879, 0.0010669, 0.049844, 0.052241, 0.036159, 0.12629]
Predicted label: 4
Correct prediction
Energy consumption = 140.738226 pJ
sum error= 360
Actual label: 6
Output voltages: [0.2376, 0.0016175, 0.0090831, 0.053804, 0.11477, 0.77869, 0.78332, 0.0011098, 0.64961, 0.057144]
Predicted label: 6
Correct prediction
Energy consumption = 140.422203 pJ
sum error= 360
Actual label: 1
Output voltages: [0.0091507, 0.79862, 0.16364, 0.030651, 0.23164, 0.012021, 0.61165, 0.02718, 0.078527, 0.070116]
Predicted label: 1
Correct prediction
Energy consumption = 158.585658 pJ
sum error= 360
Actual label: 4
Output voltages: [0.11365, 0.10982, 0.028302, 0.056311, 0.79466, 0.0011918, 0.0062647, 0.021997, 0.19748, 0.043151]
Predicted label: 4
Correct prediction
Energy consumption = 143.969984 pJ
sum error= 360
Actual label: 0
Output voltages: [0.79878, 0.016859, 0.077272, 0.006399, 0.011346, 0.0029947, 0.060131, 0.027318, 0.42849, 0.03069]
Predicted label: 0
Correct prediction
Energy consumption = 149.918395 pJ
sum error= 360
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 974 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 974 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 974 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.32285, 0.02182, 0.021316, 0.030297, 0.16606, 0.028386, 0.0036172, 0.016689, 0.59448, 0.79805]
Predicted label: 9
Correct prediction
Energy consumption = 141.840157 pJ
sum error= 360
Actual label: 9
Output voltages: [0.71947, 0.019348, 0.0015679, 0.039525, 0.46183, 0.0038235, 0.0058169, 0.031225, 0.046923, 0.78431]
Predicted label: 9
Correct prediction
Energy consumption = 137.878856 pJ
sum error= 360
Actual label: 3
Output voltages: [0.20777, 0.012651, 0.19917, 0.79873, 0.0046468, 0.04984, 0.0031923, 0.017549, 0.69158, 0.026473]
Predicted label: 3
Correct prediction
Energy consumption = 144.313431 pJ
sum error= 360
Actual label: 7
Output voltages: [0.015169, 0.083381, 0.07495, 0.038117, 0.19836, 0.0011194, 0.0010916, 0.79866, 0.18828, 0.027409]
Predicted label: 7
Correct prediction
Energy consumption = 145.155432 pJ
sum error= 360
Actual label: 8
Output voltages: [0.0061244, 0.29718, 0.080722, 0.033564, 0.0429, 0.02187, 0.62082, 0.01052, 0.79618, 0.09684]
Predicted label: 8
Correct prediction
Energy consumption = 147.259804 pJ
sum error= 360
Actual label: 4
Output voltages: [0.29897, 0.029238, 0.75034, 0.0070629, 0.78502, 0.0014647, 0.12433, 0.016707, 0.079926, 0.050561]
Predicted label: 4
Correct prediction
Energy consumption = 143.980160 pJ
sum error= 360
Actual label: 7
Output voltages: [0.25244, 0.044817, 0.1535, 0.051316, 0.065431, 0.013301, 0.0010753, 0.79861, 0.031925, 0.40238]
Predicted label: 7
Correct prediction
Energy consumption = 148.188378 pJ
sum error= 360
Actual label: 5
Output voltages: [0.42165, 0.023929, 0.0072065, 0.38525, 0.0084058, 0.79567, 0.74273, 0.0069769, 0.039464, 0.16692]
Predicted label: 5
Correct prediction
Energy consumption = 141.329859 pJ
sum error= 360
Actual label: 8
Output voltages: [0.45756, 0.0019167, 0.031111, 0.17088, 0.045832, 0.28449, 0.27336, 0.0048684, 0.7987, 0.0028545]
Predicted label: 8
Correct prediction
Energy consumption = 142.092462 pJ
sum error= 360
Actual label: 5
Output voltages: [0.24599, 0.0017984, 0.0027647, 0.3478, 0.048373, 0.79876, 0.76461, 0.0051577, 0.49877, 0.013859]
Predicted label: 5
Correct prediction
Energy consumption = 139.257722 pJ
sum error= 360
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 975 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 975 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 975 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.050399, 0.014678, 0.17561, 0.79867, 0.015836, 0.036589, 0.0076538, 0.018201, 0.61505, 0.041858]
Predicted label: 3
Correct prediction
Energy consumption = 150.300627 pJ
sum error= 360
Actual label: 2
Output voltages: [0.62167, 0.16552, 0.79879, 0.26544, 0.012349, 0.001101, 0.31669, 0.018634, 0.29294, 0.1304]
Predicted label: 2
Correct prediction
Energy consumption = 147.800418 pJ
sum error= 360
Actual label: 2
Output voltages: [0.31003, 0.042689, 0.79879, 0.22874, 0.042709, 0.0010851, 0.29802, 0.0027396, 0.21584, 0.054786]
Predicted label: 2
Correct prediction
Energy consumption = 138.799759 pJ
sum error= 360
Actual label: 0
Output voltages: [0.7987, 0.043534, 0.016243, 0.010042, 0.013808, 0.018822, 0.42112, 0.060418, 0.27961, 0.036476]
Predicted label: 0
Correct prediction
Energy consumption = 139.837454 pJ
sum error= 360
Actual label: 5
Output voltages: [0.47281, 0.032338, 0.0030844, 0.051524, 0.066915, 0.76112, 0.79164, 0.0010659, 0.042616, 0.0055345]
Predicted label: 6
Wrong prediction!
Energy consumption = 141.241324 pJ
sum error= 361
Actual label: 8
Output voltages: [0.18409, 0.011322, 0.028569, 0.032366, 0.005085, 0.74905, 0.28873, 0.01784, 0.79857, 0.0010695]
Predicted label: 8
Correct prediction
Energy consumption = 142.888600 pJ
sum error= 361
Actual label: 6
Output voltages: [0.10631, 0.013349, 0.47695, 0.0025052, 0.084111, 0.063369, 0.79866, 0.0011622, 0.71192, 0.037763]
Predicted label: 6
Correct prediction
Energy consumption = 133.855480 pJ
sum error= 361
Actual label: 0
Output voltages: [0.79879, 0.024012, 0.074418, 0.015227, 0.047196, 0.0027378, 0.10564, 0.011129, 0.46683, 0.034524]
Predicted label: 0
Correct prediction
Energy consumption = 148.721427 pJ
sum error= 361
Actual label: 3
Output voltages: [0.6667, 0.0053978, 0.052439, 0.79868, 0.033654, 0.43804, 0.0017208, 0.022083, 0.49423, 0.030134]
Predicted label: 3
Correct prediction
Energy consumption = 145.794800 pJ
sum error= 361
Actual label: 8
Output voltages: [0.011518, 0.023174, 0.096851, 0.3263, 0.0017988, 0.19679, 0.013712, 0.0070255, 0.79872, 0.16506]
Predicted label: 8
Correct prediction
Energy consumption = 146.929770 pJ
sum error= 361
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 976 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 976 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 976 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.010405, 0.79859, 0.0023008, 0.019803, 0.46363, 0.0095856, 0.6933, 0.020928, 0.024019, 0.15694]
Predicted label: 1
Correct prediction
Energy consumption = 154.804907 pJ
sum error= 361
Actual label: 0
Output voltages: [0.79879, 0.067685, 0.081905, 0.010921, 0.01225, 0.0059773, 0.56173, 0.16595, 0.38852, 0.031712]
Predicted label: 0
Correct prediction
Energy consumption = 146.648922 pJ
sum error= 361
Actual label: 3
Output voltages: [0.36853, 0.0016584, 0.36763, 0.79829, 0.045321, 0.027044, 0.010966, 0.0098316, 0.79149, 0.056898]
Predicted label: 3
Correct prediction
Energy consumption = 154.458614 pJ
sum error= 361
Actual label: 0
Output voltages: [0.79879, 0.061188, 0.023399, 0.049694, 0.026073, 0.0097085, 0.57652, 0.0514, 0.2817, 0.023803]
Predicted label: 0
Correct prediction
Energy consumption = 145.006107 pJ
sum error= 361
Actual label: 4
Output voltages: [0.063177, 0.048355, 0.028754, 0.035818, 0.79879, 0.0011272, 0.019043, 0.0048431, 0.050835, 0.043182]
Predicted label: 4
Correct prediction
Energy consumption = 147.804235 pJ
sum error= 361
Actual label: 7
Output voltages: [0.21941, 0.057005, 0.018382, 0.16907, 0.053949, 0.0093959, 0.0014098, 0.79877, 0.11397, 0.52692]
Predicted label: 7
Correct prediction
Energy consumption = 150.901136 pJ
sum error= 361
Actual label: 4
Output voltages: [0.033893, 0.021259, 0.034305, 0.021008, 0.79868, 0.0011255, 0.03715, 0.03019, 0.086911, 0.085164]
Predicted label: 4
Correct prediction
Energy consumption = 140.437153 pJ
sum error= 361
Actual label: 9
Output voltages: [0.16413, 0.011381, 0.031787, 0.031849, 0.14555, 0.0076899, 0.01014, 0.011167, 0.49217, 0.79702]
Predicted label: 9
Correct prediction
Energy consumption = 139.595370 pJ
sum error= 361
Actual label: 2
Output voltages: [0.7885, 0.0017435, 0.61294, 0.027074, 0.01651, 0.0011169, 0.0068457, 0.046661, 0.75889, 0.036441]
Predicted label: 0
Wrong prediction!
Energy consumption = 141.034692 pJ
sum error= 362
Actual label: 9
Output voltages: [0.25837, 0.0098267, 0.0033434, 0.013305, 0.049915, 0.0071184, 0.0015459, 0.0065982, 0.56527, 0.79859]
Predicted label: 9
Correct prediction
Energy consumption = 145.788021 pJ
sum error= 362
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 977 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 977 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 977 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.79508, 0.022903, 0.017248, 0.018115, 0.025466, 0.34986, 0.7667, 0.19674, 0.022936, 0.0075262]
Predicted label: 0
Wrong prediction!
Energy consumption = 145.818232 pJ
sum error= 363
Actual label: 7
Output voltages: [0.31623, 0.023782, 0.012847, 0.27349, 0.11297, 0.018383, 0.0014454, 0.79875, 0.06086, 0.43661]
Predicted label: 7
Correct prediction
Energy consumption = 149.104287 pJ
sum error= 363
Actual label: 1
Output voltages: [0.01095, 0.79868, 0.27468, 0.0099044, 0.039275, 0.0026761, 0.62591, 0.0013114, 0.43096, 0.016523]
Predicted label: 1
Correct prediction
Energy consumption = 150.264066 pJ
sum error= 363
Actual label: 7
Output voltages: [0.20649, 0.12496, 0.1666, 0.025096, 0.3776, 0.00107, 0.0010689, 0.79871, 0.04826, 0.034094]
Predicted label: 7
Correct prediction
Energy consumption = 146.059597 pJ
sum error= 363
Actual label: 1
Output voltages: [0.019939, 0.79875, 0.33588, 0.019683, 0.66729, 0.0011099, 0.31554, 0.012794, 0.0293, 0.0070483]
Predicted label: 1
Correct prediction
Energy consumption = 149.002186 pJ
sum error= 363
Actual label: 6
Output voltages: [0.3149, 0.027278, 0.071457, 0.0030449, 0.47587, 0.059784, 0.79877, 0.0010717, 0.75306, 0.0064954]
Predicted label: 6
Correct prediction
Energy consumption = 138.597754 pJ
sum error= 363
Actual label: 6
Output voltages: [0.094375, 0.0058318, 0.13244, 0.032337, 0.055086, 0.47236, 0.79879, 0.0011552, 0.36438, 0.10542]
Predicted label: 6
Correct prediction
Energy consumption = 127.284356 pJ
sum error= 363
Actual label: 5
Output voltages: [0.76585, 0.0033124, 0.0010696, 0.070932, 0.12088, 0.79708, 0.52797, 0.0064108, 0.056697, 0.0044607]
Predicted label: 5
Correct prediction
Energy consumption = 132.244209 pJ
sum error= 363
Actual label: 6
Output voltages: [0.45006, 0.0091653, 0.038805, 0.065414, 0.050391, 0.75654, 0.79816, 0.0013244, 0.62025, 0.043236]
Predicted label: 6
Correct prediction
Energy consumption = 141.219056 pJ
sum error= 363
Actual label: 2
Output voltages: [0.78935, 0.0010828, 0.6966, 0.36748, 0.001081, 0.0027979, 0.0026701, 0.30998, 0.66876, 0.026437]
Predicted label: 0
Wrong prediction!
Energy consumption = 149.572371 pJ
sum error= 364
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 978 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 978 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 978 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.50299, 0.0084756, 0.11729, 0.024007, 0.0030459, 0.26194, 0.0012586, 0.053326, 0.79876, 0.0028535]
Predicted label: 8
Correct prediction
Energy consumption = 147.629055 pJ
sum error= 364
Actual label: 7
Output voltages: [0.15526, 0.0075611, 0.063077, 0.0010659, 0.32996, 0.011278, 0.0010817, 0.79183, 0.38116, 0.24934]
Predicted label: 7
Correct prediction
Energy consumption = 137.695256 pJ
sum error= 364
Actual label: 6
Output voltages: [0.26669, 0.0011347, 0.1134, 0.014123, 0.22636, 0.58162, 0.79628, 0.0010668, 0.64021, 0.041312]
Predicted label: 6
Correct prediction
Energy consumption = 142.303056 pJ
sum error= 364
Actual label: 4
Output voltages: [0.019039, 0.10426, 0.096651, 0.12594, 0.79879, 0.0011142, 0.02691, 0.095678, 0.008132, 0.040821]
Predicted label: 4
Correct prediction
Energy consumption = 149.316423 pJ
sum error= 364
Actual label: 9
Output voltages: [0.34831, 0.012528, 0.012058, 0.071168, 0.37984, 0.0052336, 0.0036081, 0.0099658, 0.28582, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 145.487194 pJ
sum error= 364
Actual label: 9
Output voltages: [0.23471, 0.028209, 0.015049, 0.074432, 0.33461, 0.0096514, 0.0022352, 0.0028476, 0.34373, 0.7987]
Predicted label: 9
Correct prediction
Energy consumption = 138.396465 pJ
sum error= 364
Actual label: 5
Output voltages: [0.24603, 0.025879, 0.0010675, 0.28005, 0.024579, 0.7987, 0.41711, 0.0024273, 0.32539, 0.023394]
Predicted label: 5
Correct prediction
Energy consumption = 145.606812 pJ
sum error= 364
Actual label: 3
Output voltages: [0.23578, 0.014658, 0.040073, 0.79866, 0.010003, 0.031183, 0.0038955, 0.0070099, 0.65786, 0.03373]
Predicted label: 3
Correct prediction
Energy consumption = 145.255782 pJ
sum error= 364
Actual label: 7
Output voltages: [0.063979, 0.058066, 0.19784, 0.015505, 0.017199, 0.0010761, 0.0011354, 0.79863, 0.042389, 0.21535]
Predicted label: 7
Correct prediction
Energy consumption = 136.784268 pJ
sum error= 364
Actual label: 4
Output voltages: [0.048979, 0.036437, 0.29362, 0.029961, 0.79867, 0.0011049, 0.049343, 0.011714, 0.027191, 0.044714]
Predicted label: 4
Correct prediction
Energy consumption = 144.223262 pJ
sum error= 364
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 979 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 979 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 979 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.77916, 0.045259, 0.023818, 0.79872, 0.0068204, 0.038005, 0.0016086, 0.37246, 0.26411, 0.019406]
Predicted label: 3
Correct prediction
Energy consumption = 150.121116 pJ
sum error= 364
Actual label: 0
Output voltages: [0.79879, 0.37576, 0.12862, 0.0031901, 0.016783, 0.0030814, 0.21506, 0.027843, 0.19559, 0.039791]
Predicted label: 0
Correct prediction
Energy consumption = 150.247303 pJ
sum error= 364
Actual label: 4
Output voltages: [0.43692, 0.31416, 0.038621, 0.096919, 0.77344, 0.0012473, 0.0071573, 0.048061, 0.0028077, 0.73397]
Predicted label: 4
Correct prediction
Energy consumption = 147.596066 pJ
sum error= 364
Actual label: 6
Output voltages: [0.029855, 0.0040992, 0.021423, 0.016239, 0.14645, 0.69868, 0.79815, 0.0046881, 0.78381, 0.0046765]
Predicted label: 6
Correct prediction
Energy consumption = 147.343088 pJ
sum error= 364
Actual label: 6
Output voltages: [0.10333, 0.021645, 0.413, 0.0011354, 0.26195, 0.21573, 0.79874, 0.0011128, 0.52455, 0.030345]
Predicted label: 6
Correct prediction
Energy consumption = 133.491597 pJ
sum error= 364
Actual label: 1
Output voltages: [0.022832, 0.79878, 0.37144, 0.019411, 0.13619, 0.0052741, 0.55943, 0.0013577, 0.42191, 0.0021921]
Predicted label: 1
Correct prediction
Energy consumption = 147.024540 pJ
sum error= 364
Actual label: 1
Output voltages: [0.083878, 0.79862, 0.32731, 0.00265, 0.67147, 0.0017982, 0.49762, 0.0010678, 0.12604, 0.031749]
Predicted label: 1
Correct prediction
Energy consumption = 136.494954 pJ
sum error= 364
Actual label: 3
Output voltages: [0.41649, 0.026819, 0.041482, 0.79875, 0.006962, 0.041923, 0.011237, 0.005872, 0.76409, 0.022782]
Predicted label: 3
Correct prediction
Energy consumption = 153.871943 pJ
sum error= 364
Actual label: 2
Output voltages: [0.1399, 0.048938, 0.79868, 0.072343, 0.03023, 0.0011262, 0.065085, 0.043423, 0.40268, 0.034765]
Predicted label: 2
Correct prediction
Energy consumption = 139.381547 pJ
sum error= 364
Actual label: 1
Output voltages: [0.042519, 0.79876, 0.20396, 0.0017612, 0.075755, 0.0027642, 0.31236, 0.0011022, 0.088454, 0.01048]
Predicted label: 1
Correct prediction
Energy consumption = 142.637029 pJ
sum error= 364
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 980 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 980 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 980 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.7769, 0.02852, 0.041271, 0.0047056, 0.0142, 0.0091699, 0.73273, 0.3419, 0.032404, 0.59837]
Predicted label: 0
Correct prediction
Energy consumption = 146.298290 pJ
sum error= 364
Actual label: 0
Output voltages: [0.79879, 0.060601, 0.031039, 0.020538, 0.040909, 0.014153, 0.49773, 0.0034755, 0.095161, 0.27454]
Predicted label: 0
Correct prediction
Energy consumption = 142.182713 pJ
sum error= 364
Actual label: 1
Output voltages: [0.0093169, 0.79855, 0.31558, 0.010266, 0.10515, 0.017222, 0.63887, 0.0015614, 0.27884, 0.016017]
Predicted label: 1
Correct prediction
Energy consumption = 157.229495 pJ
sum error= 364
Actual label: 2
Output voltages: [0.25082, 0.0011136, 0.79835, 0.079536, 0.01209, 0.0011904, 0.041593, 0.14193, 0.77453, 0.0053347]
Predicted label: 2
Correct prediction
Energy consumption = 148.057593 pJ
sum error= 364
Actual label: 3
Output voltages: [0.04296, 0.0023181, 0.064845, 0.79876, 0.029929, 0.065667, 0.024046, 0.0053314, 0.49019, 0.047148]
Predicted label: 3
Correct prediction
Energy consumption = 145.409909 pJ
sum error= 364
Actual label: 4
Output voltages: [0.0094931, 0.02958, 0.051548, 0.014733, 0.79875, 0.0018203, 0.26186, 0.087402, 0.019367, 0.0062836]
Predicted label: 4
Correct prediction
Energy consumption = 154.036918 pJ
sum error= 364
Actual label: 7
Output voltages: [0.051842, 0.0098039, 0.025066, 0.019454, 0.024995, 0.0046339, 0.0010664, 0.79866, 0.29754, 0.48313]
Predicted label: 7
Correct prediction
Energy consumption = 154.668642 pJ
sum error= 364
Actual label: 8
Output voltages: [0.033444, 0.1522, 0.09907, 0.25642, 0.017743, 0.0068854, 0.026547, 0.0019845, 0.79868, 0.23576]
Predicted label: 8
Correct prediction
Energy consumption = 145.549910 pJ
sum error= 364
Actual label: 9
Output voltages: [0.3368, 0.022107, 0.0046981, 0.029113, 0.75792, 0.0067196, 0.0025576, 0.57589, 0.14027, 0.74964]
Predicted label: 4
Wrong prediction!
Energy consumption = 150.516809 pJ
sum error= 365
Actual label: 0
Output voltages: [0.79873, 0.092898, 0.025151, 0.026626, 0.017574, 0.020034, 0.19825, 0.011199, 0.36523, 0.081545]
Predicted label: 0
Correct prediction
Energy consumption = 152.245893 pJ
sum error= 365
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 981 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 981 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 981 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23064, 0.79867, 0.16229, 0.010009, 0.1979, 0.0056606, 0.27255, 0.0020436, 0.043139, 0.033779]
Predicted label: 1
Correct prediction
Energy consumption = 162.724958 pJ
sum error= 365
Actual label: 2
Output voltages: [0.032332, 0.019867, 0.79867, 0.08638, 0.0010875, 0.0011157, 0.010967, 0.5868, 0.73914, 0.0083108]
Predicted label: 2
Correct prediction
Energy consumption = 142.433477 pJ
sum error= 365
Actual label: 3
Output voltages: [0.071878, 0.022566, 0.059232, 0.79874, 0.040103, 0.36509, 0.038178, 0.017037, 0.4904, 0.018201]
Predicted label: 3
Correct prediction
Energy consumption = 147.856055 pJ
sum error= 365
Actual label: 4
Output voltages: [0.0029192, 0.037356, 0.037285, 0.0056662, 0.79877, 0.0011436, 0.49421, 0.095927, 0.0042881, 0.023503]
Predicted label: 4
Correct prediction
Energy consumption = 151.818158 pJ
sum error= 365
Actual label: 5
Output voltages: [0.063393, 0.062556, 0.011585, 0.038941, 0.0021883, 0.79873, 0.11549, 0.015285, 0.7985, 0.014084]
Predicted label: 5
Correct prediction
Energy consumption = 162.910113 pJ
sum error= 365
Actual label: 6
Output voltages: [0.25063, 0.0056899, 0.0052452, 0.038185, 0.04117, 0.78478, 0.79784, 0.0015851, 0.47566, 0.047011]
Predicted label: 6
Correct prediction
Energy consumption = 143.949714 pJ
sum error= 365
Actual label: 7
Output voltages: [0.42351, 0.025662, 0.37593, 0.045043, 0.012097, 0.0011612, 0.0011432, 0.79861, 0.044881, 0.039346]
Predicted label: 7
Correct prediction
Energy consumption = 156.390752 pJ
sum error= 365
Actual label: 8
Output voltages: [0.19859, 0.047046, 0.10054, 0.37205, 0.018948, 0.017554, 0.027638, 0.0010905, 0.79761, 0.067613]
Predicted label: 8
Correct prediction
Energy consumption = 154.237584 pJ
sum error= 365
Actual label: 0
Output voltages: [0.79879, 0.016505, 0.027492, 0.0057661, 0.016331, 0.010129, 0.10627, 0.030364, 0.57673, 0.030435]
Predicted label: 0
Correct prediction
Energy consumption = 143.161313 pJ
sum error= 365
Actual label: 1
Output voltages: [0.0018526, 0.79879, 0.025545, 0.0086936, 0.17303, 0.0012229, 0.087768, 0.010186, 0.5276, 0.053149]
Predicted label: 1
Correct prediction
Energy consumption = 150.832999 pJ
sum error= 365
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 982 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 982 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 982 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.43659, 0.042144, 0.79878, 0.25818, 0.021664, 0.0011824, 0.45091, 0.015446, 0.72906, 0.096468]
Predicted label: 2
Correct prediction
Energy consumption = 149.849884 pJ
sum error= 365
Actual label: 3
Output voltages: [0.7398, 0.020164, 0.10965, 0.79876, 0.01148, 0.021439, 0.0032216, 0.0086948, 0.50486, 0.010315]
Predicted label: 3
Correct prediction
Energy consumption = 137.951945 pJ
sum error= 365
Actual label: 4
Output voltages: [0.0046591, 0.057711, 0.025784, 0.038195, 0.79875, 0.0019603, 0.26816, 0.44867, 0.023629, 0.0032114]
Predicted label: 4
Correct prediction
Energy consumption = 153.225868 pJ
sum error= 365
Actual label: 7
Output voltages: [0.28238, 0.15622, 0.46897, 0.47404, 0.0014682, 0.0010868, 0.0010723, 0.7976, 0.080678, 0.37783]
Predicted label: 7
Correct prediction
Energy consumption = 152.822104 pJ
sum error= 365
Actual label: 8
Output voltages: [0.058331, 0.016815, 0.026252, 0.68416, 0.0015379, 0.10917, 0.22977, 0.0025525, 0.79878, 0.08223]
Predicted label: 8
Correct prediction
Energy consumption = 154.291434 pJ
sum error= 365
Actual label: 9
Output voltages: [0.078029, 0.013988, 0.028097, 0.346, 0.049181, 0.0027399, 0.0015731, 0.14439, 0.4635, 0.79796]
Predicted label: 9
Correct prediction
Energy consumption = 146.199855 pJ
sum error= 365
Actual label: 0
Output voltages: [0.789, 0.036789, 0.14692, 0.032437, 0.0064711, 0.001107, 0.67113, 0.015407, 0.28507, 0.070363]
Predicted label: 0
Correct prediction
Energy consumption = 158.090365 pJ
sum error= 365
Actual label: 8
Output voltages: [0.012712, 0.12481, 0.032665, 0.2882, 0.006523, 0.004086, 0.32644, 0.012006, 0.79878, 0.20503]
Predicted label: 8
Correct prediction
Energy consumption = 154.199859 pJ
sum error= 365
Actual label: 3
Output voltages: [0.050352, 0.022911, 0.36417, 0.7986, 0.013328, 0.044072, 0.0088411, 0.0017996, 0.59956, 0.046214]
Predicted label: 3
Correct prediction
Energy consumption = 156.284564 pJ
sum error= 365
Actual label: 9
Output voltages: [0.51029, 0.011074, 0.019054, 0.039993, 0.50198, 0.0081061, 0.00951, 0.0040143, 0.22241, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 146.976474 pJ
sum error= 365
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 983 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 983 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 983 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.029599, 0.023965, 0.0015628, 0.047181, 0.01343, 0.79869, 0.22794, 0.023534, 0.75427, 0.022419]
Predicted label: 5
Correct prediction
Energy consumption = 155.054982 pJ
sum error= 365
Actual label: 5
Output voltages: [0.026402, 0.48971, 0.0010836, 0.74113, 0.0092187, 0.79871, 0.20765, 0.029852, 0.7255, 0.00647]
Predicted label: 5
Correct prediction
Energy consumption = 147.342508 pJ
sum error= 365
Actual label: 2
Output voltages: [0.37802, 0.10045, 0.79861, 0.12758, 0.008799, 0.0013898, 0.29963, 0.23504, 0.59462, 0.014385]
Predicted label: 2
Correct prediction
Energy consumption = 148.010786 pJ
sum error= 365
Actual label: 6
Output voltages: [0.034147, 0.051038, 0.1113, 0.0027296, 0.26415, 0.1909, 0.79879, 0.0019757, 0.76176, 0.0048468]
Predicted label: 6
Correct prediction
Energy consumption = 147.482033 pJ
sum error= 365
Actual label: 8
Output voltages: [0.049191, 0.032093, 0.17253, 0.1944, 0.001147, 0.11958, 0.50166, 0.0051408, 0.79865, 0.040005]
Predicted label: 8
Correct prediction
Energy consumption = 147.306267 pJ
sum error= 365
Actual label: 4
Output voltages: [0.017197, 0.027051, 0.099564, 0.0026323, 0.79876, 0.00114, 0.29008, 0.033165, 0.29871, 0.0092056]
Predicted label: 4
Correct prediction
Energy consumption = 148.558409 pJ
sum error= 365
Actual label: 1
Output voltages: [0.016353, 0.79874, 0.013396, 0.0078992, 0.66721, 0.017373, 0.44953, 0.0020854, 0.24416, 0.18121]
Predicted label: 1
Correct prediction
Energy consumption = 155.332703 pJ
sum error= 365
Actual label: 7
Output voltages: [0.11418, 0.029918, 0.27026, 0.046607, 0.0043887, 0.0012428, 0.0011909, 0.79876, 0.34164, 0.23931]
Predicted label: 7
Correct prediction
Energy consumption = 159.540980 pJ
sum error= 365
Actual label: 1
Output voltages: [0.14059, 0.79876, 0.001108, 0.02754, 0.72095, 0.0078885, 0.064976, 0.0010847, 0.25657, 0.51093]
Predicted label: 1
Correct prediction
Energy consumption = 159.353393 pJ
sum error= 365
Actual label: 2
Output voltages: [0.37185, 0.15, 0.79147, 0.28582, 0.0011488, 0.0011674, 0.022818, 0.65436, 0.61862, 0.036927]
Predicted label: 2
Correct prediction
Energy consumption = 149.909784 pJ
sum error= 365
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 984 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 984 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 984 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.45903, 0.005074, 0.19484, 0.79879, 0.039321, 0.065941, 0.010017, 0.0052807, 0.53283, 0.029127]
Predicted label: 3
Correct prediction
Energy consumption = 150.276596 pJ
sum error= 365
Actual label: 5
Output voltages: [0.15305, 0.066011, 0.0010711, 0.35003, 0.021968, 0.79859, 0.66105, 0.0095951, 0.34836, 0.0047464]
Predicted label: 5
Correct prediction
Energy consumption = 152.061873 pJ
sum error= 365
Actual label: 6
Output voltages: [0.17177, 0.011372, 0.047263, 0.003412, 0.31017, 0.064114, 0.79855, 0.0010755, 0.63416, 0.002735]
Predicted label: 6
Correct prediction
Energy consumption = 135.490671 pJ
sum error= 365
Actual label: 9
Output voltages: [0.19261, 0.0075131, 0.0156, 0.30722, 0.20273, 0.001271, 0.010963, 0.036185, 0.32054, 0.79875]
Predicted label: 9
Correct prediction
Energy consumption = 144.916336 pJ
sum error= 365
Actual label: 1
Output voltages: [0.036436, 0.7984, 0.02731, 0.051541, 0.049591, 0.0030976, 0.62755, 0.010775, 0.025032, 0.041772]
Predicted label: 1
Correct prediction
Energy consumption = 160.539441 pJ
sum error= 365
Actual label: 1
Output voltages: [0.055447, 0.7987, 0.016655, 0.0071906, 0.311, 0.0025087, 0.29364, 0.02434, 0.18435, 0.15816]
Predicted label: 1
Correct prediction
Energy consumption = 150.321859 pJ
sum error= 365
Actual label: 1
Output voltages: [0.036767, 0.79878, 0.022807, 0.017927, 0.50512, 0.0011413, 0.062848, 0.14778, 0.019128, 0.33571]
Predicted label: 1
Correct prediction
Energy consumption = 146.637783 pJ
sum error= 365
Actual label: 2
Output voltages: [0.037246, 0.48652, 0.79879, 0.032986, 0.0028824, 0.0012659, 0.031794, 0.57335, 0.40373, 0.034614]
Predicted label: 2
Correct prediction
Energy consumption = 146.411350 pJ
sum error= 365
Actual label: 1
Output voltages: [0.0073916, 0.79864, 0.023449, 0.0075776, 0.23588, 0.0027836, 0.54472, 0.0038447, 0.35175, 0.045003]
Predicted label: 1
Correct prediction
Energy consumption = 149.199548 pJ
sum error= 365
Actual label: 2
Output voltages: [0.37218, 0.2556, 0.79876, 0.30581, 0.0038329, 0.0012476, 0.079314, 0.0071407, 0.49468, 0.0092842]
Predicted label: 2
Correct prediction
Energy consumption = 144.489582 pJ
sum error= 365
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 985 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 985 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 985 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79574, 0.026039, 0.12442, 0.01494, 0.0088802, 0.0041653, 0.7185, 0.014312, 0.56843, 0.28759]
Predicted label: 0
Correct prediction
Energy consumption = 144.985711 pJ
sum error= 365
Actual label: 7
Output voltages: [0.11601, 0.014658, 0.04015, 0.29684, 0.0039033, 0.0033887, 0.0011721, 0.79867, 0.32653, 0.39316]
Predicted label: 7
Correct prediction
Energy consumption = 151.051516 pJ
sum error= 365
Actual label: 7
Output voltages: [0.044852, 0.32792, 0.062133, 0.2659, 0.0018075, 0.0017631, 0.0010676, 0.79867, 0.078994, 0.57332]
Predicted label: 7
Correct prediction
Energy consumption = 136.709581 pJ
sum error= 365
Actual label: 5
Output voltages: [0.017164, 0.017681, 0.026413, 0.046527, 0.0021334, 0.79874, 0.020237, 0.0023753, 0.79869, 0.0023283]
Predicted label: 5
Correct prediction
Energy consumption = 155.409926 pJ
sum error= 365
Actual label: 8
Output voltages: [0.056587, 0.02941, 0.015406, 0.21035, 0.018295, 0.22639, 0.36595, 0.0018321, 0.79873, 0.08639]
Predicted label: 8
Correct prediction
Energy consumption = 142.910708 pJ
sum error= 365
Actual label: 2
Output voltages: [0.17213, 0.2203, 0.79844, 0.47759, 0.0011518, 0.0011522, 0.26011, 0.016647, 0.65341, 0.0066016]
Predicted label: 2
Correct prediction
Energy consumption = 149.698324 pJ
sum error= 365
Actual label: 9
Output voltages: [0.046347, 0.0010664, 0.001066, 0.013403, 0.097069, 0.79601, 0.030596, 0.19869, 0.19292, 0.3576]
Predicted label: 5
Wrong prediction!
Energy consumption = 151.000121 pJ
sum error= 366
Actual label: 8
Output voltages: [0.013875, 0.159, 0.018339, 0.36488, 0.001172, 0.043691, 0.047804, 0.0044979, 0.79879, 0.29882]
Predicted label: 8
Correct prediction
Energy consumption = 144.088999 pJ
sum error= 366
Actual label: 6
Output voltages: [0.44392, 0.2384, 0.0022157, 0.3102, 0.015914, 0.37125, 0.79696, 0.038649, 0.72544, 0.0012575]
Predicted label: 6
Correct prediction
Energy consumption = 151.763675 pJ
sum error= 366
Actual label: 7
Output voltages: [0.079846, 0.017081, 0.029498, 0.034059, 0.018603, 0.0063944, 0.00107, 0.79856, 0.075344, 0.39335]
Predicted label: 7
Correct prediction
Energy consumption = 152.465634 pJ
sum error= 366
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 986 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 986 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 986 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 3
Output voltages: [0.36924, 0.0027476, 0.1452, 0.79879, 0.015626, 0.31841, 0.0030873, 0.0047549, 0.65037, 0.0048798]
Predicted label: 3
Correct prediction
Energy consumption = 150.002906 pJ
sum error= 366
Actual label: 4
Output voltages: [0.016633, 0.010122, 0.36799, 0.0042654, 0.79877, 0.0011605, 0.57432, 0.046244, 0.013866, 0.020131]
Predicted label: 4
Correct prediction
Energy consumption = 146.338489 pJ
sum error= 366
Actual label: 6
Output voltages: [0.11171, 0.026768, 0.015275, 0.046481, 0.044376, 0.30157, 0.72766, 0.011573, 0.79875, 0.0010717]
Predicted label: 8
Wrong prediction!
Energy consumption = 150.724225 pJ
sum error= 367
Actual label: 8
Output voltages: [0.26509, 0.02682, 0.03979, 0.71616, 0.0010661, 0.039397, 0.2324, 0.0083764, 0.79812, 0.094412]
Predicted label: 8
Correct prediction
Energy consumption = 151.471128 pJ
sum error= 367
Actual label: 7
Output voltages: [0.11199, 0.2301, 0.17909, 0.018485, 0.023851, 0.0011003, 0.0010802, 0.79875, 0.054935, 0.2106]
Predicted label: 7
Correct prediction
Energy consumption = 148.051220 pJ
sum error= 367
Actual label: 0
Output voltages: [0.79874, 0.029341, 0.30155, 0.015757, 0.016586, 0.0034525, 0.041601, 0.033675, 0.19214, 0.14104]
Predicted label: 0
Correct prediction
Energy consumption = 149.004398 pJ
sum error= 367
Actual label: 4
Output voltages: [0.018616, 0.0019779, 0.6723, 0.009554, 0.79872, 0.0031425, 0.54832, 0.37487, 0.014235, 0.0075682]
Predicted label: 4
Correct prediction
Energy consumption = 144.639478 pJ
sum error= 367
Actual label: 2
Output voltages: [0.19632, 0.039059, 0.79875, 0.022925, 0.0010847, 0.0011512, 0.013557, 0.77452, 0.74412, 0.0019761]
Predicted label: 2
Correct prediction
Energy consumption = 140.645863 pJ
sum error= 367
Actual label: 7
Output voltages: [0.019275, 0.28666, 0.57456, 0.024313, 0.0063212, 0.0010753, 0.0011075, 0.79873, 0.19883, 0.23668]
Predicted label: 7
Correct prediction
Energy consumption = 140.825818 pJ
sum error= 367
Actual label: 7
Output voltages: [0.035831, 0.12222, 0.18331, 0.0053629, 0.0016645, 0.0011161, 0.0011221, 0.79879, 0.74104, 0.37177]
Predicted label: 7
Correct prediction
Energy consumption = 135.962875 pJ
sum error= 367
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 987 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 987 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 987 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.010034, 0.0080881, 0.0012739, 0.29324, 0.027083, 0.79869, 0.44205, 0.012249, 0.70103, 0.0052191]
Predicted label: 5
Correct prediction
Energy consumption = 156.391563 pJ
sum error= 367
Actual label: 4
Output voltages: [0.0045365, 0.0085435, 0.095438, 0.0019206, 0.79867, 0.001472, 0.36997, 0.050233, 0.02613, 0.013107]
Predicted label: 4
Correct prediction
Energy consumption = 151.267863 pJ
sum error= 367
Actual label: 3
Output voltages: [0.5909, 0.043643, 0.038509, 0.7987, 0.0066503, 0.0066947, 0.095891, 0.015049, 0.51937, 0.022879]
Predicted label: 3
Correct prediction
Energy consumption = 149.625827 pJ
sum error= 367
Actual label: 4
Output voltages: [0.046871, 0.0018132, 0.26372, 0.0041857, 0.79871, 0.001856, 0.77312, 0.024808, 0.0438, 0.012825]
Predicted label: 4
Correct prediction
Energy consumption = 144.251292 pJ
sum error= 367
Actual label: 2
Output voltages: [0.24028, 0.075946, 0.79588, 0.39422, 0.0010875, 0.0013769, 0.032463, 0.35088, 0.66816, 0.027811]
Predicted label: 2
Correct prediction
Energy consumption = 154.666644 pJ
sum error= 367
Actual label: 8
Output voltages: [0.0097324, 0.023562, 0.094315, 0.12862, 0.01909, 0.026694, 0.026359, 0.012897, 0.79877, 0.21368]
Predicted label: 8
Correct prediction
Energy consumption = 143.832327 pJ
sum error= 367
Actual label: 1
Output voltages: [0.00828, 0.7986, 0.042229, 0.027164, 0.27818, 0.0013159, 0.24074, 0.0025449, 0.090094, 0.094893]
Predicted label: 1
Correct prediction
Energy consumption = 152.631585 pJ
sum error= 367
Actual label: 5
Output voltages: [0.27921, 0.016356, 0.0010784, 0.19516, 0.0015976, 0.79865, 0.41428, 0.036497, 0.46512, 0.0021692]
Predicted label: 5
Correct prediction
Energy consumption = 152.611067 pJ
sum error= 367
Actual label: 1
Output voltages: [0.12144, 0.79866, 0.050719, 0.19264, 0.21032, 0.0017111, 0.42443, 0.0023983, 0.0075976, 0.02632]
Predicted label: 1
Correct prediction
Energy consumption = 156.827587 pJ
sum error= 367
Actual label: 0
Output voltages: [0.77905, 0.037125, 0.23345, 0.0091884, 0.51476, 0.0011145, 0.51525, 0.0012119, 0.75212, 0.31926]
Predicted label: 0
Correct prediction
Energy consumption = 154.124142 pJ
sum error= 367
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 988 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 988 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 988 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.023884, 0.039633, 0.79663, 0.32735, 0.0015892, 0.0010669, 0.033661, 0.031343, 0.78352, 0.026485]
Predicted label: 2
Correct prediction
Energy consumption = 153.984031 pJ
sum error= 367
Actual label: 3
Output voltages: [0.18786, 0.017624, 0.091629, 0.79878, 0.019582, 0.26761, 0.041719, 0.0019409, 0.26981, 0.058818]
Predicted label: 3
Correct prediction
Energy consumption = 149.594057 pJ
sum error= 367
Actual label: 3
Output voltages: [0.11304, 0.0083717, 0.027505, 0.79872, 0.021361, 0.023359, 0.039218, 0.001489, 0.42985, 0.18175]
Predicted label: 3
Correct prediction
Energy consumption = 136.956826 pJ
sum error= 367
Actual label: 5
Output voltages: [0.025281, 0.050851, 0.058536, 0.46349, 0.0014636, 0.76362, 0.72387, 0.001066, 0.65633, 0.0027453]
Predicted label: 5
Correct prediction
Energy consumption = 150.503009 pJ
sum error= 367
Actual label: 7
Output voltages: [0.034114, 0.098778, 0.032225, 0.0090597, 0.044714, 0.0012641, 0.0010867, 0.79863, 0.08753, 0.041794]
Predicted label: 7
Correct prediction
Energy consumption = 147.876732 pJ
sum error= 367
Actual label: 0
Output voltages: [0.7986, 0.046936, 0.030542, 0.0182, 0.010809, 0.0058248, 0.31272, 0.010312, 0.63731, 0.027596]
Predicted label: 0
Correct prediction
Energy consumption = 151.238718 pJ
sum error= 367
Actual label: 6
Output voltages: [0.18769, 0.03494, 0.10068, 0.0028926, 0.73486, 0.086964, 0.79879, 0.001268, 0.29326, 0.0012799]
Predicted label: 6
Correct prediction
Energy consumption = 143.329492 pJ
sum error= 367
Actual label: 8
Output voltages: [0.020648, 0.15027, 0.0087009, 0.19747, 0.03155, 0.031721, 0.74949, 0.010838, 0.79879, 0.011908]
Predicted label: 8
Correct prediction
Energy consumption = 146.536717 pJ
sum error= 367
Actual label: 6
Output voltages: [0.496, 0.051455, 0.021411, 0.038171, 0.22656, 0.018601, 0.79105, 0.016082, 0.74386, 0.0041357]
Predicted label: 6
Correct prediction
Energy consumption = 149.789710 pJ
sum error= 367
Actual label: 3
Output voltages: [0.37619, 0.024714, 0.13721, 0.79868, 0.029277, 0.0049444, 0.003903, 0.23373, 0.57833, 0.020703]
Predicted label: 3
Correct prediction
Energy consumption = 151.843947 pJ
sum error= 367
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 989 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 989 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 989 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 9
Output voltages: [0.34774, 0.0010666, 0.0010736, 0.02987, 0.17642, 0.49206, 0.3332, 0.079437, 0.28319, 0.75353]
Predicted label: 9
Correct prediction
Energy consumption = 145.878850 pJ
sum error= 367
Actual label: 9
Output voltages: [0.053405, 0.014246, 0.014017, 0.70653, 0.041714, 0.12477, 0.014274, 0.76328, 0.021925, 0.7855]
Predicted label: 9
Correct prediction
Energy consumption = 140.915666 pJ
sum error= 367
Actual label: 8
Output voltages: [0.032224, 0.0017331, 0.24391, 0.018215, 0.0062058, 0.15795, 0.015236, 0.0047385, 0.79621, 0.35175]
Predicted label: 8
Correct prediction
Energy consumption = 139.554294 pJ
sum error= 367
Actual label: 2
Output voltages: [0.27183, 0.017364, 0.79876, 0.28644, 0.0025356, 0.0012532, 0.042968, 0.50071, 0.74643, 0.0018313]
Predicted label: 2
Correct prediction
Energy consumption = 139.352665 pJ
sum error= 367
Actual label: 7
Output voltages: [0.026695, 0.50681, 0.63245, 0.025594, 0.0091456, 0.0010963, 0.0011398, 0.79877, 0.055423, 0.039146]
Predicted label: 7
Correct prediction
Energy consumption = 140.465073 pJ
sum error= 367
Actual label: 7
Output voltages: [0.13691, 0.06117, 0.7753, 0.0079059, 0.013838, 0.0012062, 0.0020296, 0.79873, 0.15343, 0.036969]
Predicted label: 7
Correct prediction
Energy consumption = 134.619581 pJ
sum error= 367
Actual label: 1
Output voltages: [0.18878, 0.79875, 0.013796, 0.13398, 0.51202, 0.0018611, 0.26376, 0.0076758, 0.019489, 0.046859]
Predicted label: 1
Correct prediction
Energy consumption = 149.927835 pJ
sum error= 367
Actual label: 0
Output voltages: [0.79879, 0.17387, 0.047259, 0.019524, 0.22356, 0.002832, 0.46029, 0.0023364, 0.19416, 0.028632]
Predicted label: 0
Correct prediction
Energy consumption = 144.883113 pJ
sum error= 367
Actual label: 1
Output voltages: [0.010238, 0.79865, 0.19187, 0.0083069, 0.02905, 0.0048563, 0.74784, 0.024775, 0.35201, 0.017149]
Predicted label: 1
Correct prediction
Energy consumption = 148.270434 pJ
sum error= 367
Actual label: 7
Output voltages: [0.02803, 0.0253, 0.058678, 0.043345, 0.0072633, 0.0079346, 0.0010696, 0.79861, 0.30804, 0.35137]
Predicted label: 7
Correct prediction
Energy consumption = 152.748655 pJ
sum error= 367
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 990 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 990 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 990 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.0091791, 0.033168, 0.042925, 0.30115, 0.0017531, 0.17318, 0.022745, 0.033071, 0.79874, 0.026336]
Predicted label: 8
Correct prediction
Energy consumption = 148.428234 pJ
sum error= 367
Actual label: 9
Output voltages: [0.41063, 0.0058412, 0.018433, 0.02233, 0.064761, 0.033225, 0.0021196, 0.015265, 0.66399, 0.79829]
Predicted label: 9
Correct prediction
Energy consumption = 143.371229 pJ
sum error= 367
Actual label: 0
Output voltages: [0.79879, 0.0078739, 0.044117, 0.012479, 0.057319, 0.010719, 0.57668, 0.28832, 0.22653, 0.01901]
Predicted label: 0
Correct prediction
Energy consumption = 147.371602 pJ
sum error= 367
Actual label: 1
Output voltages: [0.079248, 0.79878, 0.13341, 0.0088945, 0.37165, 0.00108, 0.51172, 0.014605, 0.16208, 0.0086177]
Predicted label: 1
Correct prediction
Energy consumption = 149.039499 pJ
sum error= 367
Actual label: 2
Output voltages: [0.78945, 0.0015615, 0.56896, 0.012083, 0.0038575, 0.014168, 0.54921, 0.027434, 0.72504, 0.054543]
Predicted label: 0
Wrong prediction!
Energy consumption = 140.993472 pJ
sum error= 368
Actual label: 3
Output voltages: [0.036973, 0.013972, 0.55119, 0.78428, 0.0038772, 0.0011071, 0.001078, 0.51834, 0.68914, 0.16204]
Predicted label: 3
Correct prediction
Energy consumption = 142.800292 pJ
sum error= 368
Actual label: 4
Output voltages: [0.0014005, 0.02295, 0.42128, 0.14922, 0.79879, 0.0035715, 0.33332, 0.061167, 0.026091, 0.013613]
Predicted label: 4
Correct prediction
Energy consumption = 141.055454 pJ
sum error= 368
Actual label: 5
Output voltages: [0.35178, 0.0012598, 0.0011184, 0.097065, 0.20283, 0.79869, 0.38609, 0.00323, 0.65506, 0.007355]
Predicted label: 5
Correct prediction
Energy consumption = 141.701432 pJ
sum error= 368
Actual label: 6
Output voltages: [0.026446, 0.04828, 0.31636, 0.0035924, 0.2961, 0.071231, 0.79871, 0.0040548, 0.59777, 0.0045228]
Predicted label: 6
Correct prediction
Energy consumption = 137.178947 pJ
sum error= 368
Actual label: 7
Output voltages: [0.2762, 0.030604, 0.021309, 0.03167, 0.11295, 0.001748, 0.0010789, 0.79879, 0.08858, 0.33773]
Predicted label: 7
Correct prediction
Energy consumption = 153.208003 pJ
sum error= 368
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 991 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 991 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 991 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.046783, 0.15326, 0.02153, 0.032916, 0.013853, 0.22483, 0.32843, 0.0055616, 0.79879, 0.0097108]
Predicted label: 8
Correct prediction
Energy consumption = 157.049476 pJ
sum error= 368
Actual label: 0
Output voltages: [0.79863, 0.023373, 0.21378, 0.03274, 0.0065689, 0.0011501, 0.33516, 0.031847, 0.075965, 0.11071]
Predicted label: 0
Correct prediction
Energy consumption = 140.748765 pJ
sum error= 368
Actual label: 1
Output voltages: [0.022409, 0.79821, 0.25285, 0.01834, 0.33779, 0.0010986, 0.3184, 0.0014336, 0.15488, 0.041041]
Predicted label: 1
Correct prediction
Energy consumption = 144.665706 pJ
sum error= 368
Actual label: 2
Output voltages: [0.19195, 0.0029698, 0.79865, 0.047557, 0.0042646, 0.0011553, 0.012351, 0.20097, 0.78017, 0.0080347]
Predicted label: 2
Correct prediction
Energy consumption = 140.437767 pJ
sum error= 368
Actual label: 3
Output voltages: [0.05686, 0.083673, 0.41597, 0.79873, 0.0034206, 0.0030941, 0.0012367, 0.032304, 0.73362, 0.076698]
Predicted label: 3
Correct prediction
Energy consumption = 139.448321 pJ
sum error= 368
Actual label: 4
Output voltages: [0.0012292, 0.042346, 0.0087391, 0.0023749, 0.79874, 0.04418, 0.2382, 0.21485, 0.088312, 0.0094276]
Predicted label: 4
Correct prediction
Energy consumption = 145.982503 pJ
sum error= 368
Actual label: 7
Output voltages: [0.46705, 0.011375, 0.1744, 0.039004, 0.025607, 0.0011374, 0.0010716, 0.79872, 0.049771, 0.010841]
Predicted label: 7
Correct prediction
Energy consumption = 149.576607 pJ
sum error= 368
Actual label: 8
Output voltages: [0.056673, 0.040785, 0.13373, 0.078298, 0.023605, 0.028116, 0.0093455, 0.018897, 0.79873, 0.31051]
Predicted label: 8
Correct prediction
Energy consumption = 141.727734 pJ
sum error= 368
Actual label: 9
Output voltages: [0.23995, 0.010199, 0.024184, 0.040377, 0.051427, 0.059726, 0.021184, 0.029712, 0.27706, 0.79728]
Predicted label: 9
Correct prediction
Energy consumption = 149.321371 pJ
sum error= 368
Actual label: 7
Output voltages: [0.26073, 0.024252, 0.3855, 0.0011015, 0.26959, 0.0010794, 0.0010813, 0.79878, 0.040499, 0.023416]
Predicted label: 7
Correct prediction
Energy consumption = 145.359196 pJ
sum error= 368
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 992 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 992 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 992 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 8
Output voltages: [0.023391, 0.055789, 0.29055, 0.18971, 0.0052991, 0.012523, 0.015742, 0.0072209, 0.79867, 0.025362]
Predicted label: 8
Correct prediction
Energy consumption = 151.831712 pJ
sum error= 368
Actual label: 6
Output voltages: [0.041438, 0.0080891, 0.34359, 0.0011138, 0.2473, 0.34014, 0.79871, 0.0011071, 0.44801, 0.0021112]
Predicted label: 6
Correct prediction
Energy consumption = 150.259446 pJ
sum error= 368
Actual label: 4
Output voltages: [0.0027189, 0.025016, 0.024643, 0.0090193, 0.79879, 0.0010731, 0.0050765, 0.0057755, 0.18429, 0.36603]
Predicted label: 4
Correct prediction
Energy consumption = 145.739829 pJ
sum error= 368
Actual label: 1
Output voltages: [0.01214, 0.79878, 0.43152, 0.006755, 0.36157, 0.0015898, 0.25042, 0.0022195, 0.14464, 0.025474]
Predicted label: 1
Correct prediction
Energy consumption = 149.825332 pJ
sum error= 368
Actual label: 9
Output voltages: [0.56535, 0.0017413, 0.016779, 0.1224, 0.18441, 0.051049, 0.0016573, 0.20514, 0.55851, 0.79356]
Predicted label: 9
Correct prediction
Energy consumption = 141.864581 pJ
sum error= 368
Actual label: 3
Output voltages: [0.0589, 0.0013434, 0.11595, 0.79879, 0.0059285, 0.031934, 0.003594, 0.018448, 0.68532, 0.020438]
Predicted label: 3
Correct prediction
Energy consumption = 137.719328 pJ
sum error= 368
Actual label: 8
Output voltages: [0.076107, 0.047965, 0.045928, 0.4409, 0.0027218, 0.074153, 0.097791, 0.052088, 0.79877, 0.0042662]
Predicted label: 8
Correct prediction
Energy consumption = 145.318397 pJ
sum error= 368
Actual label: 4
Output voltages: [0.0048839, 0.024878, 0.43997, 0.089383, 0.7987, 0.0011706, 0.049768, 0.048992, 0.0015733, 0.066076]
Predicted label: 4
Correct prediction
Energy consumption = 145.893366 pJ
sum error= 368
Actual label: 4
Output voltages: [0.0034895, 0.064836, 0.1477, 0.098305, 0.79872, 0.0043838, 0.043849, 0.18074, 0.021433, 0.039234]
Predicted label: 4
Correct prediction
Energy consumption = 138.166572 pJ
sum error= 368
Actual label: 7
Output voltages: [0.027003, 0.094235, 0.099954, 0.034139, 0.013637, 0.0012683, 0.0010985, 0.79864, 0.038686, 0.14272]
Predicted label: 7
Correct prediction
Energy consumption = 143.737741 pJ
sum error= 368
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 993 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 993 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 993 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 0
Output voltages: [0.79864, 0.20846, 0.12673, 0.041645, 0.0034218, 0.0119, 0.36551, 0.020379, 0.14508, 0.0065475]
Predicted label: 0
Correct prediction
Energy consumption = 157.638790 pJ
sum error= 368
Actual label: 1
Output voltages: [0.0064804, 0.79867, 0.21889, 0.12527, 0.46672, 0.0010873, 0.12341, 0.011179, 0.051386, 0.067497]
Predicted label: 1
Correct prediction
Energy consumption = 161.278228 pJ
sum error= 368
Actual label: 9
Output voltages: [0.4278, 0.028244, 0.062253, 0.1833, 0.052838, 0.014389, 0.11514, 0.03042, 0.042112, 0.79877]
Predicted label: 9
Correct prediction
Energy consumption = 152.413239 pJ
sum error= 368
Actual label: 2
Output voltages: [0.29375, 0.033313, 0.79858, 0.027375, 0.0093094, 0.0010691, 0.054805, 0.022781, 0.4474, 0.010769]
Predicted label: 2
Correct prediction
Energy consumption = 146.160994 pJ
sum error= 368
Actual label: 8
Output voltages: [0.013235, 0.11731, 0.031264, 0.58669, 0.0012701, 0.043691, 0.0014468, 0.024538, 0.79879, 0.35761]
Predicted label: 8
Correct prediction
Energy consumption = 151.514465 pJ
sum error= 368
Actual label: 7
Output voltages: [0.05573, 0.060363, 0.042646, 0.10715, 0.010351, 0.0011662, 0.0012895, 0.79879, 0.040969, 0.5755]
Predicted label: 7
Correct prediction
Energy consumption = 152.014665 pJ
sum error= 368
Actual label: 8
Output voltages: [0.031323, 0.012641, 0.018743, 0.17861, 0.0017836, 0.16272, 0.01852, 0.0082127, 0.79878, 0.16895]
Predicted label: 8
Correct prediction
Energy consumption = 148.068167 pJ
sum error= 368
Actual label: 2
Output voltages: [0.42669, 0.0045765, 0.79872, 0.025218, 0.013255, 0.001085, 0.049063, 0.042579, 0.62678, 0.0028254]
Predicted label: 2
Correct prediction
Energy consumption = 140.569689 pJ
sum error= 368
Actual label: 6
Output voltages: [0.27523, 0.077795, 0.24702, 0.009994, 0.35618, 0.038627, 0.79878, 0.001697, 0.56112, 0.0067716]
Predicted label: 6
Correct prediction
Energy consumption = 142.976121 pJ
sum error= 368
Actual label: 0
Output voltages: [0.79879, 0.030672, 0.023974, 0.012101, 0.01044, 0.0048191, 0.7436, 0.019527, 0.30067, 0.061359]
Predicted label: 0
Correct prediction
Energy consumption = 131.483671 pJ
sum error= 368
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 994 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 994 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 994 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 6
Output voltages: [0.098456, 0.075431, 0.42117, 0.0010662, 0.1852, 0.044947, 0.79879, 0.0028902, 0.5363, 0.0013924]
Predicted label: 6
Correct prediction
Energy consumption = 146.241878 pJ
sum error= 368
Actual label: 5
Output voltages: [0.33579, 0.0010839, 0.040461, 0.74562, 0.0054753, 0.76346, 0.38668, 0.014586, 0.78218, 0.020182]
Predicted label: 8
Wrong prediction!
Energy consumption = 148.453157 pJ
sum error= 369
Actual label: 3
Output voltages: [0.082797, 0.016704, 0.029627, 0.79879, 0.014552, 0.010295, 0.0058162, 0.013812, 0.74338, 0.025746]
Predicted label: 3
Correct prediction
Energy consumption = 136.123797 pJ
sum error= 369
Actual label: 3
Output voltages: [0.039776, 0.020638, 0.29828, 0.79864, 0.0013401, 0.0019739, 0.0089242, 0.027753, 0.76269, 0.0076855]
Predicted label: 3
Correct prediction
Energy consumption = 131.633781 pJ
sum error= 369
Actual label: 3
Output voltages: [0.024806, 0.015625, 0.073578, 0.5221, 0.11395, 0.0022549, 0.0046857, 0.0026358, 0.79839, 0.027893]
Predicted label: 8
Wrong prediction!
Energy consumption = 133.062542 pJ
sum error= 370
Actual label: 9
Output voltages: [0.22022, 0.0078332, 0.0022623, 0.056136, 0.74415, 0.0079146, 0.0012711, 0.0043194, 0.093005, 0.79483]
Predicted label: 9
Correct prediction
Energy consumption = 144.658429 pJ
sum error= 370
Actual label: 1
Output voltages: [0.0039807, 0.79861, 0.032554, 0.018317, 0.030179, 0.0017984, 0.58949, 0.035384, 0.24403, 0.025995]
Predicted label: 1
Correct prediction
Energy consumption = 154.557972 pJ
sum error= 370
Actual label: 4
Output voltages: [0.051322, 0.02698, 0.21591, 0.007526, 0.79877, 0.0016985, 0.78891, 0.19279, 0.0076962, 0.016513]
Predicted label: 4
Correct prediction
Energy consumption = 145.786158 pJ
sum error= 370
Actual label: 0
Output voltages: [0.79871, 0.094366, 0.012652, 0.014546, 0.0028205, 0.0084895, 0.46607, 0.032914, 0.24876, 0.033694]
Predicted label: 0
Correct prediction
Energy consumption = 147.900497 pJ
sum error= 370
Actual label: 6
Output voltages: [0.042476, 0.038741, 0.25884, 0.0021981, 0.36149, 0.32803, 0.79869, 0.0046831, 0.63845, 0.0068196]
Predicted label: 6
Correct prediction
Energy consumption = 144.903323 pJ
sum error= 370
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 995 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 995 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 995 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 1
Output voltages: [0.23975, 0.79879, 0.040991, 0.0012525, 0.054717, 0.0027675, 0.071895, 0.0018749, 0.054409, 0.048085]
Predicted label: 1
Correct prediction
Energy consumption = 155.819416 pJ
sum error= 370
Actual label: 0
Output voltages: [0.79879, 0.0065727, 0.085732, 0.24993, 0.018913, 0.0067601, 0.01564, 0.14055, 0.42021, 0.017618]
Predicted label: 0
Correct prediction
Energy consumption = 148.760880 pJ
sum error= 370
Actual label: 0
Output voltages: [0.79875, 0.024043, 0.12681, 0.026632, 0.026373, 0.0037178, 0.27404, 0.025049, 0.1525, 0.28991]
Predicted label: 0
Correct prediction
Energy consumption = 139.987131 pJ
sum error= 370
Actual label: 6
Output voltages: [0.20993, 0.083893, 0.2771, 0.0012541, 0.1904, 0.094165, 0.79879, 0.001514, 0.64296, 0.0019566]
Predicted label: 6
Correct prediction
Energy consumption = 139.836329 pJ
sum error= 370
Actual label: 2
Output voltages: [0.13599, 0.001398, 0.7955, 0.63928, 0.0015526, 0.0011653, 0.026096, 0.17026, 0.75767, 0.0024095]
Predicted label: 2
Correct prediction
Energy consumption = 145.917715 pJ
sum error= 370
Actual label: 1
Output voltages: [0.0042765, 0.79879, 0.35591, 0.015874, 0.017305, 0.0010789, 0.52092, 0.0017673, 0.27915, 0.017206]
Predicted label: 1
Correct prediction
Energy consumption = 145.181963 pJ
sum error= 370
Actual label: 1
Output voltages: [0.18997, 0.79775, 0.42646, 0.009833, 0.79315, 0.0023996, 0.26817, 0.0015231, 0.20618, 0.035684]
Predicted label: 1
Correct prediction
Energy consumption = 140.813238 pJ
sum error= 370
Actual label: 7
Output voltages: [0.034892, 0.056478, 0.085868, 0.13081, 0.018371, 0.001431, 0.0010675, 0.79867, 0.016102, 0.049856]
Predicted label: 7
Correct prediction
Energy consumption = 145.830532 pJ
sum error= 370
Actual label: 7
Output voltages: [0.02766, 0.24649, 0.40896, 0.031526, 0.0052405, 0.0011863, 0.0011705, 0.79879, 0.28933, 0.17009]
Predicted label: 7
Correct prediction
Energy consumption = 138.608914 pJ
sum error= 370
Actual label: 8
Output voltages: [0.018007, 0.38519, 0.21375, 0.079887, 0.0067899, 0.0098489, 0.02771, 0.088114, 0.79868, 0.13011]
Predicted label: 8
Correct prediction
Energy consumption = 148.337283 pJ
sum error= 370
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 996 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 996 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 996 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 4
Output voltages: [0.0073735, 0.0066605, 0.078015, 0.012727, 0.79862, 0.0029675, 0.10304, 0.045187, 0.048505, 0.011719]
Predicted label: 4
Correct prediction
Energy consumption = 154.133730 pJ
sum error= 370
Actual label: 6
Output voltages: [0.031469, 0.03053, 0.18355, 0.003545, 0.3002, 0.2846, 0.79871, 0.0035431, 0.71828, 0.0047202]
Predicted label: 6
Correct prediction
Energy consumption = 145.848007 pJ
sum error= 370
Actual label: 0
Output voltages: [0.79697, 0.041559, 0.034227, 0.030662, 0.63879, 0.0016736, 0.05183, 0.021082, 0.4372, 0.032959]
Predicted label: 0
Correct prediction
Energy consumption = 145.693054 pJ
sum error= 370
Actual label: 7
Output voltages: [0.31345, 0.01022, 0.012824, 0.41213, 0.0025353, 0.044276, 0.0011539, 0.79875, 0.39688, 0.32808]
Predicted label: 7
Correct prediction
Energy consumption = 149.036299 pJ
sum error= 370
Actual label: 0
Output voltages: [0.79868, 0.017157, 0.25404, 0.0138, 0.020865, 0.0010871, 0.31861, 0.017185, 0.39216, 0.023579]
Predicted label: 0
Correct prediction
Energy consumption = 144.019347 pJ
sum error= 370
Actual label: 3
Output voltages: [0.21954, 0.0019102, 0.034509, 0.79875, 0.028853, 0.27149, 0.0076763, 0.014828, 0.76935, 0.029501]
Predicted label: 3
Correct prediction
Energy consumption = 147.175126 pJ
sum error= 370
Actual label: 6
Output voltages: [0.14534, 0.0103, 0.41984, 0.0010877, 0.34018, 0.0735, 0.79873, 0.0020315, 0.24857, 0.0021941]
Predicted label: 6
Correct prediction
Energy consumption = 141.606901 pJ
sum error= 370
Actual label: 8
Output voltages: [0.034335, 0.06338, 0.1595, 0.31981, 0.002247, 0.021486, 0.0159, 0.003207, 0.79876, 0.034376]
Predicted label: 8
Correct prediction
Energy consumption = 150.484811 pJ
sum error= 370
Actual label: 7
Output voltages: [0.059116, 0.073549, 0.64137, 0.014113, 0.0093335, 0.0010877, 0.0010855, 0.79866, 0.050171, 0.056426]
Predicted label: 7
Correct prediction
Energy consumption = 151.737977 pJ
sum error= 370
Actual label: 1
Output voltages: [0.17533, 0.79867, 0.028049, 0.046853, 0.64153, 0.0016157, 0.3494, 0.020933, 0.0059076, 0.055949]
Predicted label: 1
Correct prediction
Energy consumption = 153.013891 pJ
sum error= 370
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 997 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 997 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 997 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 5
Output voltages: [0.18852, 0.010573, 0.0082762, 0.42791, 0.0028596, 0.77446, 0.75429, 0.001068, 0.40396, 0.0082397]
Predicted label: 5
Correct prediction
Energy consumption = 148.348385 pJ
sum error= 370
Actual label: 2
Output voltages: [0.41873, 0.0097894, 0.79874, 0.041096, 0.01464, 0.0011569, 0.043125, 0.059502, 0.66955, 0.024964]
Predicted label: 2
Correct prediction
Energy consumption = 139.179486 pJ
sum error= 370
Actual label: 4
Output voltages: [0.0079052, 0.026621, 0.029378, 0.011458, 0.79873, 0.00133, 0.14489, 0.015283, 0.062982, 0.019282]
Predicted label: 4
Correct prediction
Energy consumption = 152.479310 pJ
sum error= 370
Actual label: 9
Output voltages: [0.35415, 0.031729, 0.030163, 0.051992, 0.29657, 0.013815, 0.0031459, 0.0024035, 0.30515, 0.79798]
Predicted label: 9
Correct prediction
Energy consumption = 138.737236 pJ
sum error= 370
Actual label: 4
Output voltages: [0.0058641, 0.028571, 0.19147, 0.03689, 0.79878, 0.0014265, 0.058386, 0.04537, 0.01993, 0.0031607]
Predicted label: 4
Correct prediction
Energy consumption = 144.880454 pJ
sum error= 370
Actual label: 3
Output voltages: [0.065532, 0.0027853, 0.71249, 0.79678, 0.002123, 0.0069997, 0.010077, 0.015791, 0.79152, 0.0058434]
Predicted label: 3
Correct prediction
Energy consumption = 140.776086 pJ
sum error= 370
Actual label: 6
Output voltages: [0.081199, 0.025927, 0.0625, 0.0073967, 0.44496, 0.21607, 0.79879, 0.0017665, 0.71207, 0.0090737]
Predicted label: 6
Correct prediction
Energy consumption = 146.305633 pJ
sum error= 370
Actual label: 4
Output voltages: [0.15339, 0.0064196, 0.0985, 0.017884, 0.79876, 0.0010852, 0.11057, 0.024099, 0.045331, 0.0019507]
Predicted label: 4
Correct prediction
Energy consumption = 142.887376 pJ
sum error= 370
Actual label: 1
Output voltages: [0.16765, 0.79848, 0.63198, 0.0019745, 0.52985, 0.001092, 0.094528, 0.098798, 0.048827, 0.098803]
Predicted label: 1
Correct prediction
Energy consumption = 151.643757 pJ
sum error= 370
Actual label: 7
Output voltages: [0.42392, 0.050085, 0.013395, 0.28499, 0.028898, 0.024335, 0.0020168, 0.79864, 0.15953, 0.19905]
Predicted label: 7
Correct prediction
Energy consumption = 147.795721 pJ
sum error= 370
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 998 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 998 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 998 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 2
Output voltages: [0.33353, 0.0036216, 0.79879, 0.048659, 0.0011707, 0.0010732, 0.0255, 0.074809, 0.74938, 0.003175]
Predicted label: 2
Correct prediction
Energy consumption = 147.534082 pJ
sum error= 370
Actual label: 6
Output voltages: [0.135, 0.083963, 0.19185, 0.011254, 0.048508, 0.17997, 0.79879, 0.0022288, 0.62735, 0.0024861]
Predicted label: 6
Correct prediction
Energy consumption = 139.688449 pJ
sum error= 370
Actual label: 5
Output voltages: [0.051746, 0.015617, 0.15128, 0.013991, 0.029303, 0.55052, 0.79766, 0.0010784, 0.044153, 0.015076]
Predicted label: 6
Wrong prediction!
Energy consumption = 146.725409 pJ
sum error= 371
Actual label: 0
Output voltages: [0.79878, 0.12919, 0.032269, 0.032286, 0.01299, 0.025491, 0.6024, 0.026222, 0.15476, 0.023518]
Predicted label: 0
Correct prediction
Energy consumption = 150.159932 pJ
sum error= 371
Actual label: 1
Output voltages: [0.040843, 0.79864, 0.26376, 0.20609, 0.39936, 0.0021889, 0.65731, 0.011889, 0.033253, 0.024886]
Predicted label: 1
Correct prediction
Energy consumption = 166.125266 pJ
sum error= 371
Actual label: 2
Output voltages: [0.52548, 0.25043, 0.79875, 0.022584, 0.004485, 0.0012883, 0.12135, 0.37009, 0.46121, 0.0079388]
Predicted label: 2
Correct prediction
Energy consumption = 146.306764 pJ
sum error= 371
Actual label: 3
Output voltages: [0.14899, 0.0346, 0.060209, 0.79869, 0.023145, 0.0057709, 0.0060348, 0.016753, 0.64947, 0.10526]
Predicted label: 3
Correct prediction
Energy consumption = 144.642940 pJ
sum error= 371
Actual label: 4
Output voltages: [0.0015289, 0.0033866, 0.023908, 0.047123, 0.79878, 0.001095, 0.068098, 0.045337, 0.080619, 0.0071834]
Predicted label: 4
Correct prediction
Energy consumption = 151.759332 pJ
sum error= 371
Actual label: 5
Output voltages: [0.033404, 0.0012397, 0.0014048, 0.55327, 0.012974, 0.79876, 0.17859, 0.019857, 0.79472, 0.0060844]
Predicted label: 5
Correct prediction
Energy consumption = 146.058637 pJ
sum error= 371
Actual label: 6
Output voltages: [0.14843, 0.039502, 0.031535, 0.003934, 0.19069, 0.25527, 0.79879, 0.013069, 0.73885, 0.010207]
Predicted label: 6
Correct prediction
Energy consumption = 141.820649 pJ
sum error= 371
Calling mapIMAC.mapIMAC with the following arguments:

nodes: [400, 120, 84, 10]
length: 4
hpar: [13, 4, 3]
vpar: [4, 3, 1]
metal: 2.6999999999999997e-08
T: 2.2e-08
H: 2e-08
L: 1.35e-07
W: 1.0799999999999999e-07
D: 4.5e-08
eps: 1.7707999999999997e-10
rho: 1.9e-08
weight_var: 0.0
testnum_per_batch: 10
data_dir: data
Horizontal partitions Layer: 1: [1:31] | [32:62] | [63:93] | [94:124] | [125:155] | [156:186] | [187:216] | [217:247] | [248:278] | [279:309] | [310:340] | [341:371] | [372:401]
Difference: [31 31 31 31 31 31 30 31 31 31 31 31 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 1: [1:30] | [31:60] | [61:90] | [91:120]
Difference: [30 30 30 30]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 1
Horizontal partitions Layer: 2: [1:31] | [32:61] | [62:91] | [92:121]
Difference: [31 30 30 30]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 2: [1:28] | [29:56] | [57:84]
Difference: [28 28 28]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 2
Horizontal partitions Layer: 3: [1:29] | [30:57] | [58:85]
Difference: [29 28 28]
Note: Last Horizontal Partition gets the bias line
Vertical partitions Layer: 3: [1:10]
Difference: [10]
Note: Each Vertical Guy gets own bias. Each Partition's initial wire connects to vdd
writing layer 3
Running Classifier
Batch: 999 Run Layer: 1
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_1_neurons.psf
Batch: 999 Run Layer: 2
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_2_neurons.psf
Batch: 999 Run Layer: 3
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_crossbar.psf
Convert to PSF
Read PSF
Decoding: test_spice/full_layer_3_neurons.psf
Actual label: 7
Output voltages: [0.035485, 0.39857, 0.51046, 0.01613, 0.011347, 0.0012017, 0.0011127, 0.79879, 0.48846, 0.15465]
Predicted label: 7
Correct prediction
Energy consumption = 159.073109 pJ
sum error= 371
Actual label: 8
Output voltages: [0.026189, 0.010504, 0.32985, 0.2088, 0.010416, 0.61805, 0.052155, 0.010247, 0.79865, 0.040699]
Predicted label: 8
Correct prediction
Energy consumption = 149.944007 pJ
sum error= 371
Actual label: 9
Output voltages: [0.11422, 0.0073518, 0.0052464, 0.013174, 0.59206, 0.02927, 0.025814, 0.010652, 0.34325, 0.79803]
Predicted label: 9
Correct prediction
Energy consumption = 151.189448 pJ
sum error= 371
Actual label: 0
Output voltages: [0.78817, 0.032797, 0.056792, 0.01904, 0.023359, 0.0010836, 0.60271, 0.014509, 0.502, 0.025516]
Predicted label: 0
Correct prediction
Energy consumption = 143.718141 pJ
sum error= 371
Actual label: 1
Output voltages: [0.018871, 0.79875, 0.58202, 0.059857, 0.16008, 0.0011231, 0.42997, 0.0042284, 0.19249, 0.045063]
Predicted label: 1
Correct prediction
Energy consumption = 160.725952 pJ
sum error= 371
Actual label: 2
Output voltages: [0.05948, 0.10918, 0.79878, 0.044695, 0.0061265, 0.001254, 0.049311, 0.04656, 0.30962, 0.042576]
Predicted label: 2
Correct prediction
Energy consumption = 147.231450 pJ
sum error= 371
Actual label: 3
Output voltages: [0.31727, 0.023137, 0.13434, 0.79871, 0.015313, 0.0084018, 0.023304, 0.0024816, 0.46933, 0.057141]
Predicted label: 3
Correct prediction
Energy consumption = 148.213259 pJ
sum error= 371
Actual label: 4
Output voltages: [0.002142, 0.0061044, 0.032256, 0.022383, 0.79866, 0.0037093, 0.22579, 0.27837, 0.1706, 0.0024475]
Predicted label: 4
Correct prediction
Energy consumption = 150.579869 pJ
sum error= 371
Actual label: 5
Output voltages: [0.28641, 0.0011313, 0.0015705, 0.21818, 0.080415, 0.79878, 0.53272, 0.013683, 0.78406, 0.0038263]
Predicted label: 5
Correct prediction
Energy consumption = 144.824992 pJ
sum error= 371
Actual label: 6
Output voltages: [0.23127, 0.011415, 0.36084, 0.0018338, 0.434, 0.037583, 0.79874, 0.0013293, 0.35242, 0.013968]
Predicted label: 6
Correct prediction
Energy consumption = 137.392274 pJ
sum error= 371
End-to-End CSV Created: 5_10_2025_full_run.csv
Total area = 3401.58464 m^2
Task completed!
Total error= 371
error rate = 0.037100
accuracy = 96.290000%
Program Execution Time = 16 hours 23 minutes 49 seconds
real	983m49.991s
user	999m9.333s
sys	22m53.290s
